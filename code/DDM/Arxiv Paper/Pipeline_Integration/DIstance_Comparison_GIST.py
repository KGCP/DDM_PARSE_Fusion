from transformers import AutoModel, AutoTokenizer
import torch

# Load model and Tokenizer
model_name = "avsolatorio/GIST-Embedding-v0"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# embedding function
def get_embedding(text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    embeddings = outputs.last_hidden_state[:, 0, :]
    return embeddings

# define two parts remain embedding
text1_parts = [
    "In terms of knowledge graph completion, what are the key challenges in ensuring accuracy and completeness?"

]

# text2_parts = [
#     "BCI Ontology: A Context -based Sense and Actuation Model for Brain -Computer Interactions Sergio José Rodríguez Méndez, John K. Zao Pervasive Embedded Technology (PET) Lab, Computer Science Department, National Chiao Tung University (NCTU) , Hsinchu, Taiwan, R.O.C.1 { srodriguez, jkzao }@pet.cs.nctu.edu.tw Abstract. Key developments in wear able sensors, wireless network s, and distrib- uted computing will largely enable Brain -Computer Interaction (BCI) as a pow- erful, natural and intuitive mainstream human -computer interaction in real -world activities. BCI systems annotate the sensed signals in order to classify the analy- sis of brain states/dynamics in diverse daily -life circumstances. There is",
#     "dimension of challenge, but also adds to utility. A good learning algorithm should scale gracefully so that discovered constraints are relatively more certain than those that are missed. SHACL EARNER establishes a benchmark for this problem. In future work we will validate the shapes we learn with SHACL EARNER via formal human-expert evaluation and further extend the expressivity of the shapes we can discover. We also propose to redesign the SHACL EARNER algorithm for a MapReduce implementation to handle extremely massive KGs with tens of billions of facts, such as the most recent version of Wikidata. Acknowledgements The authors acknowledge",
#     "An Analysis of Links in Wikidata Armin Haller1(B), Axel Polleres2, Daniil Dobriy2, Nicolas Ferranti2, and Sergio J. Rodr ´ıguez M ´endez1 1Australian National University, Canberra, ACT 2601, Australia {armin.haller,sergio.rodriguezmendez }@anu.edu.au 2Vienna University of Economics and Business, Vienna, Austria {axel.polleres,daniil.dobriy,nicolas.nicolas }@wu.ac.at Abstract. Wikidata has become one of the most prominent open knowledge graphs (KGs) on the Web. Relying on a community of users with different exper-tise, this cross-domain KG is directly related to other data sources. This paper investigates how Wikidata is linked to other data sources in the Linked Data ecosystem. To this end, we adapt previous deﬁnitions of ontology",
#     "matrix and vector operations. 120 P . Ghiasnezhad Omran et al. / SHACLearner Our experiments show that SHACL EARNER can mine IOP rules of various lengths, cardinalities, and qualities from three massive real-world benchmark KGs including Yago, Wikidata and DBpedia. Learning shape constraints from schema-free knowledge-bases, such as most modern KGs, is a challenging task. The challenge starts from the formalism of constraints that determine the scope of knowledge that could be acquired. The next challenge is to design an efﬁcient learning method. Dealing with uncertainty in the constraints and thelearning process adds an extra dimension of challenge, but also",
#     "the Republic of China. BCI Ontology: A Context -based Sense and Actuation Model 33 states. Lack of training data from individual users and comparable features among dif- ferent users often hamper the accuracy and usefulness of BCI systems in real -world applicatio ns. In a project in the research area of Advanced Computational Approaches under the Cognition and Neuroergonomics Collaborative Technology Alliance (CaN - CTA) program sponsored by the U.S. Army Research Laboratory (ARL) [1], the Per- vasive Embedding Technol ogies (PET) Lab in the National Chiao -Tung University (NCTU) in Taiwan has the chance to work with the Swartz"
# ]

text2_parts = [
    "Knowledge Graphs (KGs) are a convenient technology to model and store massive quantities of weakly-structured data.The power of KGs arises from a data-first approach.They allow information to be added in a relatively arbitrary manner as structural constraints are few; unlike, for example, relational databases where type, not-null, and key constraints abound to enforce a kind of completeness.However, the intended scope of KGs is usually poorly defined and they fail to record relevant entities, as well as relevant relationships for the entities they do record [20].This is just like in Wikipedia, where some topics are more richly covered than others.Even for the same topic area, say movie actors for instance, we have much better coverage for the movies produced in some countries than we do for others [17].KGs are often (semi-) automatically built from unstructured sources such as Wikipedia articles.The building methods are prone to asserting some erroneous facts, while missing some others.Techniques have been developed for knowledge graph completion and rule learning to curate KGs automatically [17].In these approaches, models, often expressed as logical rules or vector embeddings, are learnt from a given KG.The models are then used for curating tasks including link prediction that predict missing facts about extant entities.Rule learning methods for KGs [9,7,22,15,30,11] consider Closed (non-existential) rules which are used to predict a fact that instantiates the triple at the head of the rule.For example, consider a rule defining a relationship between citizenship and the residence of a person, citizenOfðx; yÞ livesInðx; zÞ ^ locatedInðz; yÞ.Using this rule, someone’s citizenship can be inferred from facts about a person’s city of residence and the nation in which that city is located.In Closed rules all head variables occur in the body of the rule and all variables appear at least twice.Thus, there can be no variable quantified existentially in the head of the rule.Closed rules enable inference of specific facts that, if true, are missing from the KG.They draw attention to a potential missing fact only if the fact is able to be inferred by the learnt rule.KG completion in this way predicts answers for known unknowns.In this paper we consider, for the first time, the problem of rule-based knowledge graph completion that guides the discovery of unknown unknowns 1.Generally, in knowledge graph completion, a specific missing fact is predicted.In contrast, we predict the existence of missing facts even when an entity involved in the missing fact may be absent from the KG.We propose learning open path rules (OP) from which we infer open-ended questions (e.g. citizenOfðAnn; ?Þ) instead of facts (e.g. citizenOfðAnn; AustraliaÞ).Traditional knowledge graph completion is then done by answering the actively generated questions.The proposed OP rule formalism is a fragment of the language of existential rules [3] which is expressive enough to adduce queries yet suitable for our scalable embedding-based rule mining system.OP rules provide evidence that a fact is missing even when there is evidence for only one entity of the pair, and a question is generated accordingly.The queries adduced from OP rules identify that a new fact is needed when the answer is not known.The answer might be an entity already present the KG, or absent from it.In the latter case, a query could be posed to a user engaged in a curating task or to a Web question–answering engine.In particular, an answer to the question could introduce new entities to the KG, and by this the approach addresses a previously unstudied direction in knowledge graph completion, that is missing entities.The process of OP rule learning and adducing queries from OP rules is not an alternative to link prediction; it complements traditional link prediction by providing relevant queries to link predictors and can, for the first time, make knowledge graph completion fully automatic.For example, consider the OP rule, citizenOfðx; yÞ studiesInðx; zÞ.This rule implies that if we know an entity x studies in an institute z, then x is a citizen of somewhere (y).If the body of this rule is instantiated like studiesInðSam; ANUÞ we can infer the query citizenOfðSam; ?Þ.Our work addresses a long-standing gap in traditional link prediction systems (e.g. [4,18,29,22,23]), that use the KG to propose missing facts, but need to be seeded with queries about potential missing facts.Conventionally, for evaluating link predictors, these queries are trivially generated from test facts that are held out from the KG in the hope that a high-performing predictor will rediscover the held-out (and thereby missing) facts.However, once a link predictor is deployed over a working KG, test facts cannot be held out, and re-discovery of held-out facts is unproductive, so whence does a query arise to drive the link predictor?We propose that the queries we derive from our OP rules can be used to generate the queries that link predictors need to repair working KGs.Arbitrary queries are of little use; queries need to be relevant in order to be useful.For example, consider the fact presidentOfðObama;USAÞ, held back from training data for a link predictor.Conventionally, this known-missing fact is used to generate the following two relevant queries presidentOfð?;USAÞ and presidentOfðObama; ?Þ.Instead when a link predictor is asked an irrelevant query like presidentOfðCeline Dion; ?Þ, it will try to rank a set of entities (countries) to answer this query even though no correct answer exists either inside or outside the KG.In summary, by learning OP rules to derive queries we address the following problems in traditional knowledge graph completion: identifying a missing fact even when there is no pattern (such as a closed rule) that fully instantiates the fact in the KG; generating relevant queries that can serve as input to link predictors to complete the KG (which is feasible when the correct answer is an entity extant in the KG); and generating queries that can introduce missing entities into the KG (although this requires answer sources beyond current link predictors).The contributions of this paper are as follows, greatly extending early explorations published in [10].We present a novel method for learning open path rules from a KG.These are existential rules with a different form to the usual closed path rules that are conventionally used for knowledge graph completion tasks.We propose an algorithm, OPRL, for learning these rules, including novel fitness criteria for discarding poor rules early, and efficient vector computation of formal quality criteria.We show that, together with KG sampling, our algorithm is effective over very large KGs.As such, we introduce a first solution to the problem of active knowledge graph completion (AKGC), where we aim, instead of suggesting missing facts, to ask the best questions to complete a KG.The rest of the paper is structured as follows.After presenting some foundations in Section 2, we describe our target language for learning in Section 3, including the formalism of OP rules.Section 4 proposes the OP rule learning method OPRL that includes a novel embedding-based heuristic function and evaluation method.Section 5 presents the process for generating relevant queries derived from the learnt OP rules.In Section 6 we formalise the new quality notion of query relevance and discuss the results of a range of experiments with our novel OPRL.In Section 7, we present the work in the literature related to link prediction and active knowledge graph completion."
    "Hyper-parameter tuning is a signiﬁcant step in applying data mining models, and the Bayesian Optimization tool  is applied.The ﬁrst step to implement Bayesian Optimization is to deﬁne the data mining model, such as the RF classiﬁer and its parameters and corresponding bounds.In addition, we also need to implement the scoring method and the cross-validation setup.Secondly, the maximize method is used to run the technique with n_iter and init_points parameters.The n_iter is deﬁned for the number of steps to run the optimization function.The more steps, the easier it is to ﬁnd the best accuracy value.The init_points is deﬁned for random exploration on the parameter space, which helps to explore the diversity of the space.Finally, the parameter values for each accuracy are listed, highlighting the best combination of the parameter and the target value."
    "However, the power of KGs comes from their data-first approach, enabling contributors to extend a KG in a relatively arbitrary manner.By contrast, a relational database typically employs not-null and other schema-based constraints that require some attributes to be instantiated in a defined way at all times.Large KGs are typically populated by automatic and semi-automatic methods using non-structured sources such as Wikipedia that are prone to errors of omission (i.e., incompleteness) and commission (i.e., falsity).Both kinds of errors can be highlighted for correction by a careful application of schema constraints.However, such constraints are commonly unavailable and, if available, uncertain and frequently violated in a KG for valid reasons, arising from the intended data-first approach of KG applications."
    "Unlike earlier work in rule mining for KG completion, for our active knowledge graph completion task we mine open path (OP) rules of the following form: Ptðx; z0Þ P1ðz0; z1Þ ^ P2ðz1; z2Þ ^ ... ^ PnðznETX 1; yÞ ð2Þ.Each Pi and Pt are predicates in the KG and each of fx; zi; yg are variables; x and y are free while the zis are bound.Unlike CP rules, OP rules do not necessarily form a looping path over variables, but can have a more linear shape.From an OP rule, two CP rules are logical consequences: one for each unification of free variable y with a variable of the head Pt.However, the OP rule is not a consequence of any CP rule; OP rules are strictly more expressive than CP rules.While every instantiation of a CP rule is also an instantiation of a corresponding OP rule, OP rules admit instantiations that cannot be instantiations of any CP rule.From an instantiation of the body of an OP rule, we can not infer a fact, but only a question.For example, the following OP rule, citizenOfðx;tÞ livesInðx; zÞ, states that if an entity, x, lives in z, then that entity is citizen of somewhere (t).By instantiating the body of this rule as follows, livesInðBronte; CanberraÞ, we could infer the query, citizenOfðBronte; ?Þ.To assess the quality of our mined open path rules, we introduce open path standard confidence (OPSC) and open path head coverage (OPHC) derived from the closed path forms (Definition 2).Definition 3 (open path: OPsupp, OPSC, OPHC): Let r be an OP rule of the form (2).Let r; e; e0; ei; bodyr; Pt be as given in Definition 1 but adapted straightforwardly to the open path rule case.Then a pair of entities ðe; e0Þ satisfies the body of r, denoted bodyrðe; e0Þ, if there exist entities e1; ... ; enETX 1 in the KG such that P1ðe; e1Þ; P2ðe1; e2Þ; ... ; PnðenETX 1; e0Þ are facts in the KG.A pair ðe0; eÞ satisfies the head of r, denoted Ptðe0; eÞ, if Ptðe0; eÞ is a fact in the KG.The open path support, open path standard confidence, and open path head coverage of r are given respectively by the KG.Then the support degree of r is defined as OPsuppðrÞ ¼ jfe : 9e0; e00s:t:bodyrðe; e0ÞandPtðe00; eÞgj OPSCðrÞ ¼ OPsuppðrÞ / jfe:9e0s:t:bodyrðe;e0Þgj OPHCðrÞ ¼ OPsuppðrÞ / jfe:9e0s:t:Ptðe0;eÞgj.For example, consider the OP rule, P1ðx; z0Þ P2ðz0; z1Þ ^ P3ðz1; yÞ.Assume we have 3 entities (fe3; e4; e5g) which can instantiate z0 to satisfy both P1ðx; z0Þ and P2ðz0; z1Þ ^ P3ðz1; yÞ.Assume the number of entities that can instantiate z0 to satisfy the head part is 5 (fe1; e2; e3; e4; e5g) and the number of entities that can instantiate z0 to satisfy the body part is 7 (fe3; e4; e5; e6; e7; e8; e9g).Hence, we have for this rule, OPsupp ¼ 3; OPSC ¼ 3/7 and OPHC ¼ 3/5."
    "Khairunizam et al.have conducted a similar study with the intention of addressing the challenge of how to increase the knowledge level of the computa- tional systems to recognize gestural information with regard to arm movements.In their research, they have tried to describe knowledge of the arm gestures and attempted to recognize it with a higher accuracy.This can be identiﬁed as an interesting study where the authors have used Qualisys motion capture (MOCAP) to capture the movement of the user’s right arm when they perform an arm gesture.However, their focus was mainly on recognizing geometrical HDGI-Ontology 115 gestures and the gesture set was limited to 5 geometrical shapes.Again, their ontological framework does not consider the mapping of other gestures that carry similar referents."
]

# 将每部分的多个段落组合成一个长文本
text1 = " ".join(text1_parts)
text2 = " ".join(text2_parts)

# 获取两段文本的嵌入
embedding1 = get_embedding(text1)
embedding2 = get_embedding(text2)

# 计算余弦相似度
cosine_similarity = torch.nn.functional.cosine_similarity(embedding1, embedding2)
print(f"Cosine Similarity: {cosine_similarity.item()}")
