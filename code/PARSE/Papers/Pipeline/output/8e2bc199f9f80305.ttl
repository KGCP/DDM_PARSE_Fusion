@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-8e2bc199f9f80305 a askg-onto:Paper ;
    rdfs:label "8e2bc199f9f80305"@en ;
    dc:title "8e2bc199f9f80305"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-8e2bc199f9f80305-Section-1,
        askg-data:Paper-8e2bc199f9f80305-Section-10,
        askg-data:Paper-8e2bc199f9f80305-Section-11,
        askg-data:Paper-8e2bc199f9f80305-Section-12,
        askg-data:Paper-8e2bc199f9f80305-Section-13,
        askg-data:Paper-8e2bc199f9f80305-Section-14,
        askg-data:Paper-8e2bc199f9f80305-Section-15,
        askg-data:Paper-8e2bc199f9f80305-Section-2,
        askg-data:Paper-8e2bc199f9f80305-Section-3,
        askg-data:Paper-8e2bc199f9f80305-Section-4,
        askg-data:Paper-8e2bc199f9f80305-Section-5,
        askg-data:Paper-8e2bc199f9f80305-Section-6,
        askg-data:Paper-8e2bc199f9f80305-Section-7,
        askg-data:Paper-8e2bc199f9f80305-Section-8,
        askg-data:Paper-8e2bc199f9f80305-Section-9 .

askg-data:Entity-%0Crac1y%09extsum_i1no_i%0Dho_c%09ext%09extbfv%09extbfp_i-ar%09extbfv%09extbfp_i%09ext rdfs:label "rac{1}{Y}	ext{sum}_{i=1}^{N}O_{i}\rho_{c}	ext{(}	extbf{v}(	extbf{p}_{i})-ar{	extbf{v}}(	extbf{p}_{i})	ext{)}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Cracddxf_yx%09extbfgx rdfs:label "rac{d}{dx}f_{Y}(x,	extbf{g}(x))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B8_ rdfs:label "θ ∗"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CE%B8__arg_min_lv_%CE%B8 rdfs:label "θ* ∈ arg min l(v, θ)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CE%BB_%CE%BB_p_%CE%BB_c_%CE%BB_s_%CE%BB_e rdfs:label "λ, λ_p, λ_c, λ_s, λ_e"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CE%BB_on_the_loss_terms rdfs:label "λ• on the loss terms"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CE%BBe_set_to_1000 rdfs:label "λe set to 1000"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CE%BBp_%CE%BBc_%CE%BBs_%CE%BBe_%CE%BBo_to_1_0_0_1000_1 rdfs:label "(λp, λc, λs, λe, λo) to (1, 0, 0, 1000, 1)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CF%81cz rdfs:label "ρc(z)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%81z%CE%B4 rdfs:label "ρ(z;δ)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%E2%84%9D%E2%81%B5 rdfs:label "ℝ⁵"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-0001 rdfs:label "0.001"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-069 rdfs:label "0.69"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-1020 rdfs:label "10−20"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-11871196 rdfs:label "1187–1196"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-12311237 rdfs:label "1231–1237"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-13 rdfs:label "[13]"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-134121 rdfs:label "134:1–21"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-137 rdfs:label "1.37"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-139143 rdfs:label "139–143"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-151158 rdfs:label "151–158"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-19 rdfs:label "19"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-194_training_images rdfs:label "194 training images"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-195_test_images rdfs:label "195 test images"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-1981 rdfs:label "1981"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1994 rdfs:label "1994"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-200 rdfs:label "200"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2002 rdfs:label "2002"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2008 rdfs:label "2008"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2009 rdfs:label "2009"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2009_ieee_conference_on_computer_vision_and_pattern_recognition rdfs:label "2009 IEEE Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2012_ieee_conference_on_computer_vision_and_pattern_recognition rdfs:label "2012 IEEE Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2013 rdfs:label "2013"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2014 rdfs:label "2014"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-22742282 rdfs:label "2274–2282"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-22_sequences rdfs:label "22 sequences"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-23032314 rdfs:label "2303–2314"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-24 rdfs:label "24"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-251_terr_026_rerr100m rdfs:label "2.51% terr, 0.26% rerr(°/100m)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-266 rdfs:label "26(6)"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-29_106_and_1_667_image_pairs rdfs:label "29 106 and 1 667 image pairs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-2_edition rdfs:label "2 edition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2nd_edition rdfs:label "2nd edition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-30 rdfs:label "30"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-31 rdfs:label "31"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-32 rdfs:label "32"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-34 rdfs:label "34"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-3412 rdfs:label "34(12)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-381395 rdfs:label "381–395"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-3cm rdfs:label "3cm"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-3d_object_reconstruction rdfs:label "3D Object Reconstruction"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-3d_reconstruction rdfs:label "3D reconstruction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-404 rdfs:label "4.04"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-4080_pixels rdfs:label "40–80 pixels"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-436 rdfs:label "4.36"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-540_pixels rdfs:label "5–40 pixels"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-568576 rdfs:label "568–576"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-57 rdfs:label "57"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-80120_pixels rdfs:label "80–120 pixels"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-87_060_consecutive_image_pairs rdfs:label "87 060 consecutive image pairs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-89348943 rdfs:label "8934–8943"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-a_loss_function rdfs:label "a loss function"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-a_promising_alternative rdfs:label "a promising alternative"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_researcher rdfs:label "a researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-a_unified_approach rdfs:label "a unified approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-action_recognition rdfs:label "action recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-action_recognition_in_videos rdfs:label "action recognition in videos"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-adam_w_harley rdfs:label "Adam W Harley"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-adjacent_frames rdfs:label "adjacent frames"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-advances_in_neural_information_processing_systems rdfs:label "Advances in Neural Information Processing Systems"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-ai_ethics rdfs:label "AI Ethics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-alexander_krull rdfs:label "Alexander Krull"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-algorithmic_implementation rdfs:label "algorithmic implementation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-allan_d_jepson rdfs:label "Allan D Jepson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-allen_hanson rdfs:label "Allen Hanson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-amos_et_al rdfs:label "Amos et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-anelia_angelova rdfs:label "Anelia Angelova"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-anoop_cherian rdfs:label "Anoop Cherian"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-another_image rdfs:label "another image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anurag_ranjan rdfs:label "Anurag Ranjan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-apparent_motion_of_pixels rdfs:label "apparent motion of pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-applied_to_the_problem rdfs:label "Applied to the problem"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-approaches rdfs:label "approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approaches_that_ignore_geometry rdfs:label "approaches that ignore geometry"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-approximately_20 rdfs:label "approximately 20%"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-appu_shaji rdfs:label "Appu Shaji"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-aravind_rajeswaran rdfs:label "Aravind Rajeswaran"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-arg_minyirn_fx_y rdfs:label "arg miny∈IRn f(x, y)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-argmax_hypothesis_selection rdfs:label "argmax hypothesis selection"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-ariel_gordon rdfs:label "Ariel Gordon"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-artificial_intelligence_171-3185203 rdfs:label "Artificial intelligence, 17(1-3):185–203"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-artificial_intelligence_and_statistics rdfs:label "Artificial Intelligence and Statistics"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-artificial_occlusions rdfs:label "artificial occlusions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arxiv rdfs:label "arXiv"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-arxiv160705447 rdfs:label "arXiv:1607.05447"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-arxiv190403848 rdfs:label "arXiv:1904.03848"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv190404998 rdfs:label "arXiv:1904.04998"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv190904630 rdfs:label "arXiv:1909.04630"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-arxiv190904866 rdfs:label "arXiv:1909.04866"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-arxiv_preprint_arxiv160705447 rdfs:label "arXiv preprint arXiv:1607.05447"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190209145 rdfs:label "arXiv preprint arXiv:1902.09145"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190403758 rdfs:label "arXiv preprint arXiv:1904.03758"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-arxiv_preprint_arxiv190403848 rdfs:label "arXiv preprint arXiv:1904.03848"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190801293 rdfs:label "arXiv preprint arXiv:1908.01293"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190810553 rdfs:label "arXiv preprint arXiv:1908.10553"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190904630 rdfs:label "arXiv preprint arXiv:1909.04630"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-asen_l rdfs:label "Asen L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-aurelien_lucchi rdfs:label "Aurelien Lucchi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-australian_centre_for_robotic_vision rdfs:label "Australian Centre for Robotic Vision"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-australian_government rdfs:label "Australian Government"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-australian_national_university rdfs:label "Australian National University"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-australian_research_council rdfs:label "Australian Research Council"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-autograd_package rdfs:label "Autograd package"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-automated_cartography rdfs:label "automated cartography"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-autonomous_driving rdfs:label "autonomous driving"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average_end_point_error_aepe rdfs:label "Average End Point Error (AEPE)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-average_relative_rotational_and_translational_errors rdfs:label "average relative rotational and translational errors"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-avinash_ravichandran rdfs:label "Avinash Ravichandran"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-back-propagate rdfs:label "back-propagate"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-back-propagate_gradients rdfs:label "back-propagate gradients"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-back-propagating_gradients rdfs:label "back-propagating gradients"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-back-propagation rdfs:label "back-propagation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-back-propagation_direction_of_the_gradients rdfs:label "back-propagation direction of the gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backbone_network rdfs:label "backbone network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-backpropagation rdfs:label "backpropagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backpropagation_through_the_optimization_layer rdfs:label "backpropagation through the optimization layer"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-baseline rdfs:label "baseline"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-baseline_approach rdfs:label "baseline approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-baseline_method rdfs:label "baseline method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-below rdfs:label "below"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-benchmark rdfs:label "benchmark"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-berthold_kp_horn rdfs:label "Berthold KP Horn"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-best_performing_model rdfs:label "best performing model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-bian_et_al rdfs:label "Bian et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bidirectional_census_loss rdfs:label "bidirectional census loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-bilateral_filtering rdfs:label "Bilateral filtering"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bilateral_filtering-based_optical_flow_estimation rdfs:label "Bilateral filtering-based optical flow estimation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bilevel_optimization rdfs:label "Bilevel optimization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bilinear_interpolation rdfs:label "bilinear interpolation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bin_liu rdfs:label "Bin Liu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bingbing_ni rdfs:label "Bingbing Ni"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bioinformatics rdfs:label "Bioinformatics"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-biological_molecules rdfs:label "Biological molecules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blue-green_arrows rdfs:label "blue-green arrows"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-book rdfs:label "book"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-brandon_amos rdfs:label "Brandon Amos"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-brian_g_schunck rdfs:label "Brian G Schunck"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-brightness_constancy_constraint rdfs:label "brightness constancy constraint"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-buckets rdfs:label "buckets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-bundle_adjustment rdfs:label "bundle adjustment"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-calibration rdfs:label "calibration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-cambridge_university_press rdfs:label "Cambridge University Press"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-camera_intrinsic_calibration_matrices rdfs:label "camera intrinsic calibration matrices"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-camera_matrices rdfs:label "camera matrices"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-camera_motion_estimates rdfs:label "camera motion estimates"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-camera_motion_network rdfs:label "camera motion network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-camera_pose rdfs:label "camera pose"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-caner_hazirbas rdfs:label "Caner Hazirbas"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-carsten_rother rdfs:label "Carsten Rother"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cen_rao rdfs:label "Cen Rao"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-census_transform rdfs:label "census transform"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-chain_rule rdfs:label "chain rule"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-challenging_data rdfs:label "challenging data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-challenging_scenes rdfs:label "challenging scenes"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-chamara_saroj_weerasekera rdfs:label "Chamara Saroj Weerasekera"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-charles_kervrann rdfs:label "Charles Kervrann"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chelsea_finn rdfs:label "Chelsea Finn"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-christoph_stiller rdfs:label "Christoph Stiller"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chunhua_shen rdfs:label "Chunhua Shen"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ci%0Dm_ackprimef_p_if_v_i rdfs:label "C(I^{\rm ackprime},{f p}_{i}+{f v}_{i})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cif_p_i rdfs:label "C(I,{f p}_{i})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-clement_godard rdfs:label "Clement Godard"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-clinical_trial rdfs:label "Clinical Trial"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-cnn_model rdfs:label "CNN model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-coarse-to-fine_refinement rdfs:label "coarse-to-fine refinement"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-coherent_motion_segmentation rdfs:label "Coherent motion segmentation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-communications_of_the_acm rdfs:label "Communications of the ACM"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-complex rdfs:label "complex"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complex_dependencies rdfs:label "complex dependencies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complex_dynamic_scene rdfs:label "complex dynamic scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complex_geometric_optimization_algorithm rdfs:label "complex geometric optimization algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-comprehensive_reviews rdfs:label "comprehensive reviews"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-computer_science rdfs:label "Computer Science"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-computer_vision_and_image_understanding rdfs:label "Computer Vision and Image Understanding"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-computer_vision_problems rdfs:label "computer vision problems"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-computing_the_essential_matrix rdfs:label "computing the essential matrix"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-computing_visual_correspondence rdfs:label "computing visual correspondence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant rdfs:label "constant"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-constant_factor rdfs:label "constant factor"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-continuous_function rdfs:label "continuous function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolution_layers rdfs:label "convolution layers"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-coordinate_of_the_corresponding_pixel rdfs:label "coordinate of the corresponding pixel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-correct_optical_flow rdfs:label "correct optical flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-correspondence_problem rdfs:label "correspondence problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-correspondences rdfs:label "correspondences"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-cost_volume rdfs:label "cost volume"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cost_volumes rdfs:label "cost volumes"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-cropping_the_input_images rdfs:label "cropping the input images"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-current_practices rdfs:label "current practices"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-d%CE%B8_dv rdfs:label "dθ ?/dV"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-data61_csiro rdfs:label "Data61 CSIRO"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-data61csiro rdfs:label "Data61/CSIRO"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-data_analysis rdfs:label "Data Analysis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-data_augmentation_technique rdfs:label "data augmentation technique"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-data_visualization rdfs:label "data visualization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-david_g_lowe rdfs:label "David G Lowe"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-david_mcallester rdfs:label "David McAllester"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-david_nister rdfs:label "David Nister"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-deep_declarative_networks rdfs:label "Deep declarative networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_feature_reconstruction rdfs:label "deep feature reconstruction"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning_model rdfs:label "deep learning model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_matching rdfs:label "deep matching"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_networks rdfs:label "deep networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_optical_flow_estimation rdfs:label "deep optical flow estimation"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-denis_fortun rdfs:label "Denis Fortun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dense_correspondences rdfs:label "dense correspondences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dense_field_of_displacement_vectors rdfs:label "dense field of displacement vectors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dense_optical_flow rdfs:label "dense optical flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dense_optical_flow_estimation rdfs:label "Dense optical flow estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dependencies rdfs:label "dependencies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth rdfs:label "depth"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-depth_and_ego-motion rdfs:label "depth and ego-motion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_from_videos_in_the_wild rdfs:label "Depth from videos in the wild"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-differentiable_convex_optimization rdfs:label "differentiable convex optimization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-differentiable_optimization_as_a_layer_in_neural_networks rdfs:label "Differentiable optimization as a layer in neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-differentiable_optimization_layer rdfs:label "differentiable optimization layer"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-differentiable_ransac rdfs:label "differentiable RANSAC"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-differentiable_ransac_for_camera_localization rdfs:label "Differentiable RANSAC for camera localization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-differentiating_argmin_and_argmax_problems rdfs:label "differentiating argmin and argmax problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-differentiating_both_sides_with_respect_to_x rdfs:label "differentiating both sides with respect to x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dinis_implicit_function_theorem rdfs:label "Dini's implicit function theorem"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-direct_automatic_differentiation rdfs:label "direct automatic differentiation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-disease_y rdfs:label "Disease Y"@en ;
    askg-onto:entityType "Disease"@en .

askg-data:Entity-displacement_vector rdfs:label "displacement vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-displacement_vectors rdfs:label "displacement vectors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dna rdfs:label "DNA"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-dontchev rdfs:label "Dontchev"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dsac rdfs:label "Dsac"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-dstflow rdfs:label "DSTFlow"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-dynamic_objects rdfs:label "dynamic objects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_parameter_separately rdfs:label "each parameter separately"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-edison_guo rdfs:label "Edison Guo"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ego-motion_estimation rdfs:label "ego-motion estimation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-embedded_robust_geometric_optimization_algorithm rdfs:label "embedded robust geometric optimization algorithm"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-end-to-end rdfs:label "end-to-end"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-end-to-end_manner rdfs:label "end-to-end manner"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-end-to-end_trainable_model rdfs:label "end-to-end trainable model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-end-to-end_training rdfs:label "end-to-end training"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-end-to-end_video_classification rdfs:label "end-to-end video classification"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-end_point_error_epe rdfs:label "End Point Error (EPE)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-epiflow rdfs:label "EPIFlow"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-epipolar_constraints rdfs:label "epipolar constraints"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-epipolar_geometric_constraint rdfs:label "epipolar geometric constraint"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-epipolar_line rdfs:label "epipolar line"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eric_brachmann rdfs:label "Eric Brachmann"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-erik_learned-_miller rdfs:label "Erik Learned- Miller"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-essential_matrices rdfs:label "essential matrices"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-essential_matrix_e rdfs:label "essential matrix E"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-essential_matrix_optimization_layer rdfs:label "essential matrix optimization layer"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-essential_matrix_parameters_%CE%B8 rdfs:label "essential matrix parameters θ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimate_of_the_camera_motion rdfs:label "estimate of the camera motion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimating_optical_flow rdfs:label "estimating optical flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimation_of_epipolar_geometry_and_optical_flow rdfs:label "estimation of epipolar geometry and optical flow"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-evaluation_criterion rdfs:label "evaluation criterion"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-exact_gradient rdfs:label "exact gradient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-existing_algorithms rdfs:label "existing algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-experiment_1 rdfs:label "Experiment_1"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-experiment_x rdfs:label "Experiment X"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-explicit_differentiation rdfs:label "explicit differentiation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-f_v%0Dm_bf_p_if_v_i rdfs:label "{f v}^{\rm b}({f p}_{i}+{f v}_{i})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_v%0Dm_ff_p_i rdfs:label "{f v}^{\rm f}({f p}_{i})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_xyx%09extbfgx rdfs:label "f_{XY}(x,	extbf{g}(x))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_y rdfs:label "f_Y"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_yx%09extbfgx rdfs:label "f_{Y}(x,	extbf{g}(x))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fast_inference_once_trained rdfs:label "fast inference once trained"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-feature-rich_regions rdfs:label "feature-rich regions"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-feature_warping rdfs:label "feature warping"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-featureless_or_repetitively-textured_regions rdfs:label "featureless or repetitively-textured regions"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-felix_endres rdfs:label "Felix Endres"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-figure_2 rdfs:label "Figure 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_and_second_derivatives rdfs:label "first and second derivatives"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_image rdfs:label "first image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_work rdfs:label "first work"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-five-point_motion_estimation rdfs:label "Five-point motion estimation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-five-point_relative_pose_problem rdfs:label "five-point relative pose problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-five-scale rdfs:label "five-scale"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-five_different_resolutions rdfs:label "five different resolutions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-five_points rdfs:label "five points"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-flow_estimation rdfs:label "flow estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flow_estimation_network rdfs:label "flow estimation network"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-flow_network_v_0 rdfs:label "Flow Network V 0"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-flow_predicted_by_the_student_network rdfs:label "flow predicted by the student network"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-flow_predicted_by_the_teacher_network rdfs:label "flow predicted by the teacher network"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-flownet rdfs:label "Flownet"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-flownet2-ft rdfs:label "FlowNet2-ft"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-flownet_20 rdfs:label "Flownet 2.0"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-focal_lengths rdfs:label "focal lengths"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-formulation rdfs:label "formulation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fortun_et_al rdfs:label "Fortun et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-forward-backward_consistency_loss rdfs:label "forward-backward consistency loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-forward-backward_consistency_prior rdfs:label "forward-backward consistency prior"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-forwardbackward_consistency_loss_lc rdfs:label "forwardbackward consistency loss Lc"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-four rdfs:label "four"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-fr1360 rdfs:label "fr1/360"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-fr2360_hemisphere rdfs:label "fr2/360 hemisphere"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-fr2pioneer_360 rdfs:label "fr2/pioneer 360"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-fr3teddy rdfs:label "fr3/teddy"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-frank_michel rdfs:label "Frank Michel"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fridtjof_stein rdfs:label "Fridtjof Stein"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-full_set_of_parameters rdfs:label "full set of parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fully-connected_layers rdfs:label "fully-connected layers"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-function_%CF%81 rdfs:label "function ρ(·)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gabriel_j_bros-__tow rdfs:label "Gabriel J Bros- ´ tow"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gang_xu rdfs:label "Gang Xu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gene_x rdfs:label "Gene X"@en ;
    askg-onto:entityType "Gene"@en .

askg-data:Entity-general_techniques rdfs:label "general techniques"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-generic_methods rdfs:label "Generic methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-genomics rdfs:label "Genomics"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-geometric_algorithms rdfs:label "geometric algorithms"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-geometric_constraint rdfs:label "geometric constraint"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometric_constraints rdfs:label "geometric constraints"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometric_estimation_algorithm rdfs:label "geometric estimation algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-geometric_loss rdfs:label "geometric loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-geometric_relationship rdfs:label "geometric relationship"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-geometrically-constrained_model rdfs:label "geometrically-constrained model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-geometry rdfs:label "geometry"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-geonet rdfs:label "Geonet"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-global_geometric_consistency rdfs:label "global geometric consistency"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-global_geometric_constraint rdfs:label "global geometric constraint"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-global_geometric_constraints rdfs:label "global geometric constraints"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-global_geometric_loss rdfs:label "global geometric loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-global_geometric_losses rdfs:label "global geometric losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-gordon_et_al rdfs:label "Gordon et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-gpu_routine rdfs:label "GPU routine"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-gpu_thread rdfs:label "GPU thread"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-gradient_computation rdfs:label "gradient computation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradient_of_the_upper-level_loss rdfs:label "gradient of the upper-level loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ground-truth rdfs:label "ground-truth"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-ground-truth_flow rdfs:label "ground-truth flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ground-truth_frame rdfs:label "ground-truth frame"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ground-truth_optical_flow rdfs:label "ground-truth optical flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gt_flow rdfs:label "GT flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h rdfs:label "H"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-handheld_slam rdfs:label "Handheld SLAM"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-handling_occlusions rdfs:label "handling occlusions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hanhan_li rdfs:label "Hanhan Li"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-harpreet_sawhney rdfs:label "Harpreet Sawhney"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-harsh_agarwal rdfs:label "Harsh Agarwal"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hartley__li_20 rdfs:label "Hartley & Li [20]"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-height_of_the_image rdfs:label "height of the image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hessian_fy_y_x_gx rdfs:label "Hessian fY Y (x, g(x))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hidden_variable_approach rdfs:label "hidden variable approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-highest_resolution rdfs:label "highest resolution"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-highly_occluded_scenes rdfs:label "highly occluded scenes"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-hongyuan_zha rdfs:label "Hongyuan Zha"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-horn rdfs:label "Horn"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-horn_and_schunck rdfs:label "Horn and Schunck"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hui_cheng rdfs:label "Hui Cheng"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hybrid_learning_idea rdfs:label "hybrid learning idea"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ieee_transactions_on_robotics rdfs:label "IEEE transactions on robotics"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-image_analysis rdfs:label "image analysis"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-image_edges rdfs:label "image edges"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_pair_i_and_i_0 rdfs:label "image pair I and I 0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_pairs rdfs:label "image pairs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-implicit_functions rdfs:label "Implicit Functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-implicit_gradients rdfs:label "implicit gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improving_computer_vision_models rdfs:label "improving computer vision models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-independently_moving_objects rdfs:label "independently moving objects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-indoor_slam_dataset rdfs:label "indoor SLAM dataset"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-inlier_threshold rdfs:label "inlier threshold"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-inlier_threshold_%CE%B4 rdfs:label "inlier threshold δ"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-input_image rdfs:label "Input image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_image_1 rdfs:label "Input image 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_image_2 rdfs:label "Input image 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-intelligent_data_augmentation_approach rdfs:label "intelligent data augmentation approach"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-international_conference_on_scale_space_and_variational_methods_in_computer_vision rdfs:label "International Conference on Scale Space and Variational Methods in Computer Vision"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-international_journal_of_computer_vision rdfs:label "International Journal of Computer Vision"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-irls rdfs:label "IRLS"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-irwh3 rdfs:label "IRW×H×3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterations rdfs:label "iterations"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-iterative rdfs:label "iterative"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iteratively_re-weighted_least_squares_irls rdfs:label "iteratively re-weighted least squares (IRLS)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-iteratively_reweighted_least_squares_irls_algorithm rdfs:label "iteratively reweighted least squares (IRLS) algorithm"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-j_yu_jason rdfs:label "J Yu Jason"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-j_zico_kolter rdfs:label "J Zico Kolter"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jacobian_and_hessian_matrices rdfs:label "Jacobian and Hessian matrices"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jamie_shotton rdfs:label "Jamie Shotton"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jan_kautz rdfs:label "Jan Kautz"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jia-bin_huang rdfs:label "Jia-Bin Huang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jia-wang_bian rdfs:label "Jia-Wang Bian"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jiangjian_xiao rdfs:label "Jiangjian Xiao"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jianping_shi rdfs:label "Jianping Shi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jianyuan_wang rdfs:label "Jianyuan Wang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jitendra_malik rdfs:label "Jitendra Malik"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jmlr rdfs:label "JMLR"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-john_woodfill rdfs:label "John Woodfill"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-joint_learning_of_depth_and_flow rdfs:label "joint learning of depth and flow"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-joint_learning_of_flow_motion_and_depth rdfs:label "joint learning of flow, motion and depth"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-joint_optical_flow_and_camera_motion_estimation rdfs:label "joint optical flow and camera motion estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-joint_optimization_approach rdfs:label "joint optimization approach"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-joint_optimization_problem rdfs:label "joint optimization problem"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-joint_recovery_of_the_fundamental_matrix_and_the_optical_flow rdfs:label "joint recovery of the fundamental matrix and the optical flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jointly_estimating_camera_motion_and_optical_flow rdfs:label "jointly estimating camera motion and optical flow"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-jonas_wulff rdfs:label "Jonas Wulff"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jose_maria_martinez_montiel rdfs:label "Jose Maria Martinez Montiel"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-joseph_weber rdfs:label "Joseph Weber"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-juan_d_tardos rdfs:label "Juan D Tardos"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-junchi_yan rdfs:label "Junchi Yan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-junhwa_hur rdfs:label "Junhwa Hur"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jurgen_sturm rdfs:label "Jurgen Sturm"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-justin_domke rdfs:label "Justin Domke"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-k rdfs:label "K"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-k_01pi_vi rdfs:label "K 0−1(p˜i +v˜i)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-k_0rt rdfs:label "K 0[R|t]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-karen_simonyan rdfs:label "Karen Simonyan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kartik_gupta rdfs:label "Kartik Gupta"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kaustav_kundu rdfs:label "Kaustav Kundu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kegan_gg_samuel rdfs:label "Kegan GG Samuel"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kejie_li rdfs:label "Kejie Li"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kevin_smith rdfs:label "Kevin Smith"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ki0 rdfs:label "K[I|0]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kitti rdfs:label "KITTI"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_2012 rdfs:label "KITTI 2012"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_2012_flow_dataset rdfs:label "KITTI 2012 Flow dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_2012_flow_subset rdfs:label "KITTI 2012 Flow subset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_2012_test_set rdfs:label "KITTI 2012 test set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_vision_benchmark_suite rdfs:label "KITTI vision benchmark suite"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_visual_odometry_vo_dataset rdfs:label "KITTI Visual Odometry (VO) dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_vo_sequences_9_and_10 rdfs:label "KITTI VO sequences 9 and 10"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-known_a_priori rdfs:label "known a priori"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-koichiro_yamaguchi rdfs:label "Koichiro Yamaguchi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-konstantinos_g_derpanis rdfs:label "Konstantinos G Derpanis"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kwonjoon_lee rdfs:label "Kwonjoon Lee"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-l_0 rdfs:label "L_{0}"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_c rdfs:label "L_c"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_ci rdfs:label "L_c^{i}"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_e rdfs:label "L_e"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_oi rdfs:label "L_o^{i}"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_p rdfs:label "L_p"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_pi rdfs:label "L_p^{i}"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_s rdfs:label "L_s"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_t rdfs:label "L_t"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-large_displacements rdfs:label "large displacements"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-large_network_parameters rdfs:label "large network parameters"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-large_optical_flows rdfs:label "large optical flows"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-large_volumes_of_ground-truth rdfs:label "large volumes of ground-truth"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-large_volumes_of_unlabelled_data rdfs:label "large volumes of unlabelled data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-laura_leal-taixe rdfs:label "Laura Leal-Taixe"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-laura_sevilla-lara rdfs:label "Laura Sevilla-Lara"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-layered_formulations rdfs:label "layered formulations"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-le rdfs:label "Le"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning-based_optical_flow_estimation rdfs:label "Learning-based optical flow estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_framework rdfs:label "learning framework"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_optical_flow_with_convolutional_networks rdfs:label "Learning optical flow with convolutional networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-left-right_consistency rdfs:label "left-right consistency"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lemma_1 rdfs:label "Lemma 1"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-levi_valgaerts rdfs:label "Levi Valgaerts"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-liang_zhao rdfs:label "Liang Zhao"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-literature rdfs:label "literature"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-liu_and_co-authors rdfs:label "Liu and co-authors"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-local_deformations rdfs:label "local deformations"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-local_matching rdfs:label "local matching"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-local_minima rdfs:label "local minima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-local_smoothness rdfs:label "local smoothness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-local_smoothness_constraints rdfs:label "local smoothness constraints"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-local_smoothness_losses rdfs:label "local smoothness losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-loss_function_l rdfs:label "loss function L"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-loss_functions rdfs:label "Loss functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-losses rdfs:label "losses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-losses_proposed_in_the_papers rdfs:label "losses proposed in the papers"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-lv%CE%B8 rdfs:label "l(v,θ)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lv_%CE%B8 rdfs:label "L(v, θ*)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning_model rdfs:label "Machine Learning Model"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-manjunath_narayana rdfs:label "Manjunath Narayana"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-map_estimates rdfs:label "MAP estimates"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-marc_pollefeys rdfs:label "Marc Pollefeys"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-marginal_improvements rdfs:label "marginal improvements"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-margret_keuper rdfs:label "Margret Keuper"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-marshall_f_tappen rdfs:label "Marshall F Tappen"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-martin_a_fischler rdfs:label "Martin A Fischler"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mathematical_relationship rdfs:label "Mathematical relationship"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-matrix_estimation rdfs:label "matrix estimation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-matrix_fy_y rdfs:label "matrix fY Y"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-matrix_hypothesis rdfs:label "matrix hypothesis"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-matrix_v rdfs:label "matrix V"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-matthew_brown rdfs:label "Matthew Brown"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-maxima rdfs:label "maxima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maximum_flow rdfs:label "maximum flow"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-method_z rdfs:label "Method Z"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-methods rdfs:label "methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-methods_that_directly_regress_camera_pose rdfs:label "methods that directly regress camera pose"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-methods_that_directly_regress_the_pose_using_a_network rdfs:label "methods that directly regress the pose using a network"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-methods_that_directly_use_a_network_to_predict_camera_poses rdfs:label "methods that directly use a network to predict camera poses"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mi rdfs:label "Mi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-miaomiao_liu rdfs:label "Miaomiao Liu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-michael_isnardi rdfs:label "Michael Isnardi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-michael_lyu rdfs:label "Michael Lyu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-michael_r_lyu rdfs:label "Michael R Lyu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-min_bai rdfs:label "Min Bai"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ming-ming_cheng rdfs:label "Ming-Ming Cheng"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ming-yu_liu rdfs:label "Ming-Yu Liu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-model_a rdfs:label "Model A"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-models rdfs:label "Models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-molecular_biology rdfs:label "Molecular Biology"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-monocular_dense_3d_reconstruction rdfs:label "Monocular dense 3D reconstruction"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-monocular_depth_estimation rdfs:label "monocular depth estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-monocular_epipolar_flow_estimation rdfs:label "Monocular epipolar flow estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-monocular_slam_system rdfs:label "monocular slam system"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-monocular_video rdfs:label "monocular video"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-more_accurate_camera_motion_estimates rdfs:label "more accurate camera motion estimates"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-motion rdfs:label "motion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-motion_blur rdfs:label "motion blur"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-motion_boundaries rdfs:label "motion boundaries"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-motion_evaluation rdfs:label "motion evaluation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-motion_segmentation rdfs:label "motion segmentation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-motion_smoothness rdfs:label "motion smoothness"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-mrf_models rdfs:label "MRF models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-multi-scale_losses rdfs:label "multi-scale losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-multi-scale_supervision rdfs:label "Multi-scale supervision"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multi-scale_training rdfs:label "multi-scale training"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multiple_view_geometry rdfs:label "Multiple View Geometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n rdfs:label "N"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-naiyan_wang rdfs:label "Naiyan Wang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-natural_language_processing rdfs:label "Natural Language Processing"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-network_architectures rdfs:label "network architectures"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-neural_networks rdfs:label "Neural Networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nikolas_engelhard rdfs:label "Nikolas Engelhard"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-nikolaus_mayer rdfs:label "Nikolaus Mayer"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-nils_papenberg rdfs:label "Nils Papenberg"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-noah_snavely rdfs:label "Noah Snavely"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-non-convex rdfs:label "non-convex"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-non-occluded_pixel rdfs:label "non-occluded pixel"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-non-occluded_pixels rdfs:label "non-occluded pixels"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-non-parametric_local_transforms rdfs:label "Non-parametric local transforms"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-nondifferentiable_ransac_procedure rdfs:label "nondifferentiable RANSAC procedure"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-nonsingular rdfs:label "nonsingular"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-nonsmooth_lower_level_problems rdfs:label "nonsmooth lower level problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normalized_coordinates rdfs:label "normalized coordinates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nucleic_acid rdfs:label "Nucleic acid"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-number_of_non-occluded_pixels rdfs:label "number of non-occluded pixels"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-oaflow rdfs:label "OAFlow"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-objective_function rdfs:label "objective function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-objective_function_is_below rdfs:label "objective function is below"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-occluded rdfs:label "occluded"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-occluded_and_nonoccluded_pixels rdfs:label "occluded and nonoccluded pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-occlusion rdfs:label "occlusion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-occlusion-aware_bidirectional_consistency rdfs:label "occlusion-aware bidirectional consistency"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-occlusion_aware_unsupervised_learning rdfs:label "Occlusion aware unsupervised learning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-occlusion_detection rdfs:label "occlusion detection"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-occlusion_estimation rdfs:label "occlusion estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-occlusion_loss rdfs:label "occlusion loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-occlusion_loss_function rdfs:label "occlusion loss function"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-occlusion_map rdfs:label "occlusion map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-odometry_comparison rdfs:label "odometry comparison"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-oi rdfs:label "Oi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oisin_mac_aodha rdfs:label "Oisin Mac Aodha"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-one-sided_epipolar_error rdfs:label "one-sided epipolar error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-one_image rdfs:label "one image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optical_flow_and_epipolar_geometry rdfs:label "optical flow and epipolar geometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optical_flow_computation rdfs:label "Optical flow computation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optical_flow_estimation_method rdfs:label "optical flow estimation method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-optical_flow_estimation_network rdfs:label "optical flow estimation network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-optical_flow_modeling rdfs:label "Optical flow modeling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optical_flow_modeling_and_computation rdfs:label "Optical flow modeling and computation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optical_flow_network rdfs:label "optical flow network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-optical_flow_orientations rdfs:label "optical flow orientations"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-optical_flow_performance rdfs:label "Optical flow performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-optical_flow_quality rdfs:label "optical flow quality"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-optimal_solution rdfs:label "optimal solution"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-optimality_condition_dfx_ydy__0 rdfs:label "optimality condition df(x, y)/dy = 0"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-optimization-based_modeling rdfs:label "optimization-based modeling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization_algorithm rdfs:label "optimization algorithm"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-optimization_layer rdfs:label "optimization layer"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-optimization_problems rdfs:label "optimization problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization_procedure rdfs:label "optimization procedure"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-optimizing_an_essential_matrix_from_the_predicted_optical_flow rdfs:label "optimizing an essential matrix from the predicted optical flow"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-optnet rdfs:label "Optnet"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-org rdfs:label "org"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-original_resolution rdfs:label "original resolution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-other_methods rdfs:label "other methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-other_optical_flow_networks rdfs:label "other optical flow networks"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-other_unsupervised_methods rdfs:label "other unsupervised methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-our rdfs:label "our"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-our_error rdfs:label "Our error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-our_flow_without_le rdfs:label "Our flow without Le"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-our_proposed_epipolar_loss rdfs:label "our proposed epipolar loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ours-_epipolar rdfs:label "Ours- Epipolar"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-ours-baseline_approach rdfs:label "Ours-Baseline approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-outdoor_road_scenes rdfs:label "outdoor road scenes"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-pan_ji rdfs:label "Pan Ji"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-paper_123 rdfs:label "Paper 123"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-papers rdfs:label "papers"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-paradigm rdfs:label "paradigm"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-parameterized_argmin_and_argmax_problems rdfs:label "parameterized argmin and argmax problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pascal_fua rdfs:label "Pascal Fua"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-patient_data rdfs:label "Patient Data"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-patrick_bouthemy rdfs:label "Patrick Bouthemy"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-patrick_van_der_smagt rdfs:label "Patrick Van Der Smagt"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pc rdfs:label "PC"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-peng_wang rdfs:label "Peng Wang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-peter_anderson rdfs:label "Peter Anderson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-peter_ochs rdfs:label "Peter Ochs"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-philip_hausser rdfs:label "Philip Hausser"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-philipp_fischer rdfs:label "Philipp Fischer"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-photometric_constancy rdfs:label "photometric constancy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-photometric_loss rdfs:label "photometric loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-photometric_loss_lp rdfs:label "photometric loss Lp"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-photometric_losses rdfs:label "photometric losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-photometric_smoothness_and_consistency_losses rdfs:label "photometric, smoothness and consistency losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-piece-wise_smoothness rdfs:label "piece-wise smoothness"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pipeline rdfs:label "pipeline"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-pixel_p rdfs:label "pixel p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel_p_0_i rdfs:label "pixel p 0 i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel_pi rdfs:label "pixel pi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixels rdfs:label "Pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-platform rdfs:label "Platform"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-point rdfs:label "point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pose rdfs:label "pose"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-previous_approaches rdfs:label "previous approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-previous_state-of-the-art_unsupervised_optical_flow_methods rdfs:label "previous state-of-the-art unsupervised optical flow methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-previous_unsupervised_optical_flow_methods rdfs:label "previous unsupervised optical flow methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-principal_point_position rdfs:label "principal point position"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-principles rdfs:label "principles"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probabilistic_selection rdfs:label "probabilistic selection"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-problem_in_computer_vision rdfs:label "problem in computer vision"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-problems rdfs:label "problems"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-procedure rdfs:label "procedure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proceedings_of_the_european_conference_on_computer_vision rdfs:label "Proceedings of the European Conference on Computer Vision"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-proceedings_of_the_ieee_international_conference_on_computer_vision rdfs:label "Proceedings of the IEEE International Conference on Computer Vision"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-process_b rdfs:label "Process B"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-proof rdfs:label "Proof"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposed_loss_functions rdfs:label "proposed loss functions"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-protein_synthesis rdfs:label "Protein synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pwc-net-ft rdfs:label "PWC-Net-ft"@en,
        "PWC-Net-ft*"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-pyramid rdfs:label "pyramid"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pytorch rdfs:label "PyTorch"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-quadratic_programs rdfs:label "quadratic programs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quality rdfs:label "quality"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-qunjie_zhou rdfs:label "Qunjie Zhou"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-r rdfs:label "R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-radhakrishna_achanta rdfs:label "Radhakrishna Achanta"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ramin_zabih rdfs:label "Ramin Zabih"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-random_forest rdfs:label "Random Forest"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_sample_consensus rdfs:label "Random sample consensus"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-raul_mur-artal rdfs:label "Raul Mur-Artal"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ravi_garg rdfs:label "Ravi Garg"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-reader rdfs:label "reader"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-real-time_prediction_possible rdfs:label "real-time prediction possible"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-real-world_scenes rdfs:label "real-world scenes"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-regions rdfs:label "regions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-regions_with_repetitive_features rdfs:label "regions with repetitive features"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-relative_rotation_error rdfs:label "relative rotation error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-relative_translation_error rdfs:label "relative translation error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-remarkably_good_results rdfs:label "remarkably good results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-rene_ranftl rdfs:label "Rene Ranftl"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-repetitive_patterns rdfs:label "repetitive patterns"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-research rdfs:label "Research"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_concept rdfs:label "research concept"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_concepts rdfs:label "research concepts"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_field_x rdfs:label "Research_Field_X"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_group_alpha rdfs:label "Research Group Alpha"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-research_method_a rdfs:label "Research_method_A"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-rgb-d_slam_systems rdfs:label "RGB-D SLAM systems"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-richard_i_hartley rdfs:label "Richard I Hartley"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rico_jonschkowski rdfs:label "Rico Jonschkowski"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rigid_body_segmentation rdfs:label "Rigid body segmentation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rigid_scene_optical_flow_estimation rdfs:label "rigid scene optical flow estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rna rdfs:label "RNA"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-robert_c_bolles rdfs:label "Robert C Bolles"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-robert_kaucic rdfs:label "Robert Kaucic"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-robot_slam rdfs:label "Robot SLAM"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-robust_algebraic_error_objective_function rdfs:label "robust algebraic error objective function"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-robust_census_losses rdfs:label "robust census losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-robust_lower-level_objective_function_l rdfs:label "robust lower-level objective function l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-robust_monocular_epipolar_flow_estimation rdfs:label "Robust monocular epipolar flow estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-robust_objective_function rdfs:label "robust objective function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rodrigo_santa_cruz rdfs:label "Rodrigo Santa Cruz"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rot rdfs:label "rot(·)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-rotation_error rdfs:label "rotation error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-rotation_part_of_tij rdfs:label "rotation part of ∆Tij"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rotation_r_and_translation_t_components rdfs:label "rotation R and translation t components"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rtx_2080_ti_gpu rdfs:label "RTX 2080 Ti GPU"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-sabine_susstrunk rdfs:label "Sabine Susstrunk"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-saddle_points rdfs:label "saddle points"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scale_information rdfs:label "scale information"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-scales rdfs:label "scales"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-schunck rdfs:label "Schunck"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-sebastian_nowozin rdfs:label "Sebastian Nowozin"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-section_4 rdfs:label "Section 4"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-self-supervised_learning_of_optical_flow rdfs:label "self-supervised learning of optical flow"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-selflow-ft rdfs:label "SelFlow-ft"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-selflow_30_error rdfs:label "SelFlow [30] error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-selflow_30_flow rdfs:label "SelFlow [30] flow"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-semantic_information rdfs:label "semantic information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-seminal_work rdfs:label "seminal work"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-sequences_9_and_10 rdfs:label "sequences 9 and 10"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-sergey_levine rdfs:label "Sergey Levine"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-several_terms rdfs:label "several terms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sham_kakade rdfs:label "Sham Kakade"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-simon_meister rdfs:label "Simon Meister"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-single_parameter rdfs:label "single parameter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-slam_system rdfs:label "SLAM system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-smooth_featureless_regions rdfs:label "smooth, featureless regions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-smooth_image_regions rdfs:label "smooth image regions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-smoothness_assumptions rdfs:label "smoothness assumptions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smoothness_losses rdfs:label "smoothness losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-solution rdfs:label "solution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-solution_mappings rdfs:label "Solution Mappings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparse_ground-truth_depth rdfs:label "sparse ground-truth depth"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-sparse_ground-truth_optical_flow rdfs:label "sparse ground-truth optical flow"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-spatial_pyramid_network rdfs:label "spatial pyramid network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-specific_steps rdfs:label "specific steps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-springer-verlag rdfs:label "Springer-Verlag"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-springer_science__business_media rdfs:label "Springer Science & Business Media"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-spynet-ft rdfs:label "SpyNet-ft"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-state-of-the-art_geometric_algorithms rdfs:label "state-of-the-art geometric algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-state-of-the-art_superpixel_methods rdfs:label "state-of-the-art superpixel methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-static rdfs:label "static"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stationary_point rdfs:label "stationary point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stationary_point_gx rdfs:label "stationary point g(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stationary_point_gx_of_f rdfs:label "stationary point g(x) of f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stationary_point_of_fx_y rdfs:label "stationary point of f(x, y)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stefan_gumhold rdfs:label "Stefan Gumhold"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-stefano_soatto rdfs:label "Stefano Soatto"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-stereo_motion_and_object_recognition rdfs:label "stereo, motion and object recognition"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-stopping_criteria rdfs:label "stopping criteria"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-student_model rdfs:label "student model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-study_on_disease_x rdfs:label "Study on Disease X"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-subhransu_maji rdfs:label "Subhransu Maji"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-subsequent_works rdfs:label "Subsequent works"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-successive_level rdfs:label "successive level"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sum_squared_distance rdfs:label "sum squared distance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-sun_et_al rdfs:label "Sun et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-supervised_deep_learning_approaches rdfs:label "supervised deep learning approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-supervised_deep_learning_task rdfs:label "supervised deep learning task"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-support_vector_machine rdfs:label "Support Vector Machine"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-symptom_y rdfs:label "Symptom Y"@en ;
    askg-onto:entityType "Symptom"@en .

askg-data:Entity-t rdfs:label "t"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-teacher_model rdfs:label "teacher model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-technique rdfs:label "Technique"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-technology_a rdfs:label "Technology A"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-tensorflow rdfs:label "TensorFlow"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-ternary_census_transform_c rdfs:label "ternary census transform C(·)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-test rdfs:label "test"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-test_correspondences rdfs:label "test correspondences"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-test_data rdfs:label "test data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-testing rdfs:label "testing"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-the_algorithmic_steps rdfs:label "the algorithmic steps"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-the_dataset rdfs:label "the dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-the_epipolar_loss_le rdfs:label "the epipolar loss Le"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_gradient rdfs:label "the gradient"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_ground-truth_odometry rdfs:label "the ground-truth odometry"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_i_th_pixel_that_is_occluded_in_the_synthetically-generated_image rdfs:label "the i th pixel that is occluded in the synthetically-generated image"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_international_journal_of_robotics_research rdfs:label "The International Journal of Robotics Research"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-the_method_used_to_solve_the_lower-level_problem rdfs:label "the method used to solve the lower-level problem"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-the_model rdfs:label "the model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-the_need_for_ground-truth_optical_flow_during_training rdfs:label "the need for ground-truth optical flow during training"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_number_of_such_pixels rdfs:label "the number of such pixels"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_poses_at_frames_i_j rdfs:label "the poses at frames (*i, j*)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_predicted_backward_optical_flow rdfs:label "the predicted backward optical flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_predicted_forward_optical_flow rdfs:label "the predicted forward optical flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_problem_under_consideration rdfs:label "the problem under consideration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_remainder rdfs:label "the remainder"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-the_robust_generalized_charbonnier_penalty_function rdfs:label "the robust generalized Charbonnier penalty function"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-the_same_losses rdfs:label "the same losses"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-theory_for_warping rdfs:label "theory for warping"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-theory_z rdfs:label "Theory_Z"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-thirty-first_aaai_conference_on_artificial_intelligence rdfs:label "Thirty-First AAAI Conference on Artificial Intelligence"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-thirty-second_aaai_conference_on_artificial_intelligence rdfs:label "Thirty-Second AAAI Conference on Artificial Intelligence"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-this_challenging_dataset rdfs:label "this challenging dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-thomas_pock rdfs:label "Thomas Pock"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-thread rdfs:label "thread"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tighter_constraints rdfs:label "tighter constraints"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-tij rdfs:label "∆Tij"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tinghui_zhou rdfs:label "Tinghui Zhou"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-tonmoy_saikia rdfs:label "Tonmoy Saikia"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-tool_z rdfs:label "Tool Z"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-torsten_sattler rdfs:label "Torsten Sattler"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-total_loss rdfs:label "total loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-total_number_of_pixels_in_image_i rdfs:label "total number of pixels in image I"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tr rdfs:label "[t]×R"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-traditional_methods rdfs:label "traditional methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-traditional_optical_flow_techniques rdfs:label "traditional optical flow techniques"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training rdfs:label "training"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_and_test_sets rdfs:label "training and test sets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_and_validation_data rdfs:label "training and validation data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_data rdfs:label "training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_deep_networks rdfs:label "training deep networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_the_baseline_network_with_the_teacher-student_strategy rdfs:label "training the baseline network with the teacher-student strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_the_student_network rdfs:label "training the student network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-trans rdfs:label "trans(·)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-translating_genetic_information rdfs:label "Translating genetic information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-translation_error rdfs:label "translation error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-translation_part_of_tij rdfs:label "translation part of ∆Tij"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-truncated_l2_penalty_function rdfs:label "truncated L2 penalty function"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-twice-differentiable rdfs:label "twice-differentiable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-two-stream_convolutional_networks rdfs:label "Two-stream convolutional networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-two_views_of_the_same_scene rdfs:label "two views of the same scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tyrrell_rockafellar rdfs:label "Tyrrell Rockafellar"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-undefined rdfs:label "undefined"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-university_of_science rdfs:label "University of Science"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unknown_cameras rdfs:label "unknown cameras"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unlabeled_data_distillation rdfs:label "unlabeled data distillation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unspecified_readiness_status rdfs:label "[unspecified readiness status]"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-unsupervised_deep_epipolar_flow rdfs:label "Unsupervised deep epipolar flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_deep_learning rdfs:label "Unsupervised deep learning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_depth_and_motion_learning_algorithms rdfs:label "unsupervised depth and motion learning algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-unsupervised_learning_approaches rdfs:label "Unsupervised learning approaches"@en,
        "unsupervised learning approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_learning_of_dense_depth_optical_flow_and_camera_pose rdfs:label "Unsupervised learning of dense depth, optical flow and camera pose"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_learning_of_depth_and_motion_from_videos rdfs:label "unsupervised learning of depth and motion from videos"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_learning_of_optical_flow rdfs:label "unsupervised learning of optical flow"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_loss_functions rdfs:label "unsupervised loss functions"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_monocular_depth_estimation rdfs:label "Unsupervised monocular depth estimation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_monocular_depth_learning rdfs:label "Unsupervised monocular depth learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_optical_flow_estimation rdfs:label "unsupervised optical flow estimation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_scale-consistent_depth_and_ego-motion_learning rdfs:label "Unsupervised scale-consistent depth and ego-motion learning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupervised_training_strategy rdfs:label "unsupervised training strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unsupflownet rdfs:label "UnsupFlownet"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-upper-level_loss_function_l rdfs:label "upper-level loss function L"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-using_epipolar_loss rdfs:label "using epipolar loss"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-variable-order_parametric_models rdfs:label "variable-order parametric models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-variational_analysis rdfs:label "Variational Analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variational_model rdfs:label "variational model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-variational_setting rdfs:label "variational setting"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-video rdfs:label "video"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-video_frames rdfs:label "video frames"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-visual_odometry rdfs:label "visual odometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vladimir_golkov rdfs:label "Vladimir Golkov"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-volume_1_pages_630633 rdfs:label "volume 1, pages 630–633"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-volume_6 rdfs:label "volume 6"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-w rdfs:label "W"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-warping rdfs:label "warping"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weak_perspective rdfs:label "weak perspective"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weber_and_malik rdfs:label "Weber and Malik"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wei_xu rdfs:label "Wei Xu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-wenjie_luo rdfs:label "Wenjie Luo"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-width_of_the_image rdfs:label "width of the image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wolfram_burgard rdfs:label "Wolfram Burgard"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-x_0i rdfs:label "x 0i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xiaodong_yang rdfs:label "Xiaodong Yang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xiaokang_yang rdfs:label "Xiaokang Yang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xiis rdfs:label "xiis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xu rdfs:label "Xu"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-xy_odometry_map rdfs:label "xy odometry map"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-xz_odometry_map rdfs:label "xz odometry map"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-y-axis_direction rdfs:label "y-axis direction"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-yamaguchi_et_al rdfs:label "Yamaguchi et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-yang_wang rdfs:label "Yang Wang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yao_lu rdfs:label "Yao Lu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-year rdfs:label "Year"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-yi_yang rdfs:label "Yi Yang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yuliang_zou rdfs:label "Yuliang Zou"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-z rdfs:label "Z"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-zelun_luo rdfs:label "Zelun Luo"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zero rdfs:label "zero"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-zhan_et_al rdfs:label "Zhan et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhang rdfs:label "Zhang"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhe_ren rdfs:label "Zhe Ren"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhengyou_zhang rdfs:label "Zhengyou Zhang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhenheng_yang rdfs:label "Zhenheng Yang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhichao_li rdfs:label "Zhichao Li"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhichao_yin rdfs:label "Zhichao Yin"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Paper-8e2bc199f9f80305-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "Joint Unsupervised Learning Of Optical Flow And Egomotion With Bi-Level Optimization"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-1-Paragraph-11 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Shihao Jiang1,2,3, Dylan Campbell1,2, Miaomiao Liu1,2, Stephen Gould1,2, Richard Hartley1,2 1Australian National University, 2Australian Centre for Robotic Vision, 3Data61/CSIRO"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-1-Paragraph-11-Sentence-111 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Shihao Jiang1,2,3, Dylan Campbell1,2, Miaomiao Liu1,2, Stephen Gould1,2, Richard Hartley1,2 1Australian National University, 2Australian Centre for Robotic Vision, 3Data61/CSIRO"@en ;
    askg-onto:inSentence "Shihao Jiang1,2,3, Dylan Campbell1,2, Miaomiao Liu1,2, Stephen Gould1,2, Richard Hartley1,2 1Australian National University, 2Australian Centre for Robotic Vision, 3Data61/CSIRO"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australian_centre_for_robotic_vision,
        askg-data:Entity-australian_national_university,
        askg-data:Entity-data61csiro,
        askg-data:Entity-dylan_campbell,
        askg-data:Entity-miaomiao_liu,
        askg-data:Entity-organization,
        askg-data:Entity-person,
        askg-data:Entity-richard_hartley,
        askg-data:Entity-shihao_jiang,
        askg-data:Entity-stephen_gould,
        askg-data:Entity-university .

askg-data:Paper-8e2bc199f9f80305-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "5.1. Implementation Details"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102 ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We use PWC-Net [44] as our backbone network. Note however that our approach is network-agnostic so other optical flow networks can also be used. Multi-scale supervision is applied to capture large optical flows, especially on the RGB-D SLAM dataset. We generate a five-scale image pyramid starting at the original resolution then halving and warping at each successive level. In the original implementation of PWC-Net [44], a five-level pyramid of optical flow maps is predicted with the highest resolution being a quarter of the original image resolution. Therefore we scale the predicted optical flow by four using bilinear interpolation to match the corresponding image pyramid. For all networks, the weights for the multi-scale losses (λ 1, λ2, λ3, λ4, λ5) were set to (1, 0.34, 0.31, 0.27, 0.08) as per Meister et al. [31], modulo a constant factor."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1011,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1012,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1013,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1014,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1015,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1016,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1017,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1018 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We use PWC-Net [44] as our backbone network."@en ;
    askg-onto:inSentence "We use PWC-Net [44] as our backbone network."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backbone_network,
        askg-data:Entity-pwc-net .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note however that our approach is network-agnostic so other optical flow networks can also be used."@en ;
    askg-onto:inSentence "Note however that our approach is network-agnostic so other optical flow networks can also be used."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow_networks,
        askg-data:Entity-other_optical_flow_networks .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Multi-scale supervision is applied to capture large optical flows, especially on the RGB-D SLAM dataset."@en ;
    askg-onto:inSentence "Multi-scale supervision is applied to capture large optical flows, especially on the RGB-D SLAM dataset."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-large_optical_flows,
        askg-data:Entity-multi-scale_supervision,
        askg-data:Entity-rgb-d_slam_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We generate a five-scale image pyramid starting at the original resolution then halving and warping at each successive level."@en ;
    askg-onto:inSentence "We generate a five-scale image pyramid starting at the original resolution then halving and warping at each successive level."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-five-scale,
        askg-data:Entity-image_pyramid,
        askg-data:Entity-original_resolution,
        askg-data:Entity-successive_level .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1015 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In the original implementation of PWC-Net [44], a five-level pyramid of optical flow maps is predicted with the highest resolution being a quarter of the original image resolution."@en ;
    askg-onto:inSentence "In the original implementation of PWC-Net [44], a five-level pyramid of optical flow maps is predicted with the highest resolution being a quarter of the original image resolution."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-pwc-net .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1016 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Therefore we scale the predicted optical flow by four using bilinear interpolation to match the corresponding image pyramid."@en ;
    askg-onto:inSentence "Therefore we scale the predicted optical flow by four using bilinear interpolation to match the corresponding image pyramid."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bilinear_interpolation,
        askg-data:Entity-four,
        askg-data:Entity-image_pyramid,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1017 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "For all networks, the weights for the multi-scale losses (λ 1, λ2, λ3, λ4, λ5) were set to (1, 0.34, 0.31, 0.27, 0.08) as per Meister et al."@en ;
    askg-onto:inSentence "For all networks, the weights for the multi-scale losses (λ 1, λ2, λ3, λ4, λ5) were set to (1, 0.34, 0.31, 0.27, 0.08) as per Meister et al."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-meister_et_al,
        askg-data:Entity-multi-scale_losses .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-101-Sentence-1018 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "[31], modulo a constant factor."@en ;
    askg-onto:inSentence "[31], modulo a constant factor."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-31,
        askg-data:Entity-constant_factor .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We train directly on the KITTI VO dataset and the RGBD SLAM dataset to obtain our baseline model. When training the baseline model on KITTI VO, we empirically set (λp, λc, λs, λe) to (1, 0.1, 0.1, 0). We then add the epipolar loss with λe set to 1000 to fine-tune the teacher model. When training the student model, we set (λp, λc, λs, λe, λo) to (1, 0, 0, 1000, 1), adding the occlusion loss. We used the same training strategy for the RGBD SLAM dataset, with (λp, λc, λs, λe, λo) set to (1, 0.1, 1, 100, 1). All experiments were run on a PC with a single 11GB RTX 2080 Ti GPU."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1021,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1022,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1023,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1024,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1025,
        askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1026 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We train directly on the KITTI VO dataset and the RGBD SLAM dataset to obtain our baseline model."@en ;
    askg-onto:inSentence "We train directly on the KITTI VO dataset and the RGBD SLAM dataset to obtain our baseline model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baseline_model,
        askg-data:Entity-kitti_vo_dataset,
        askg-data:Entity-rgbd_slam_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "When training the baseline model on KITTI VO, we empirically set (λp, λc, λs, λe) to (1, 0.1, 0.1, 0)."@en ;
    askg-onto:inSentence "When training the baseline model on KITTI VO, we empirically set (λp, λc, λs, λe) to (1, 0.1, 0.1, 0)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baseline_model,
        askg-data:Entity-kitti_vo .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We then add the epipolar loss with λe set to 1000 to fine-tune the teacher model."@en ;
    askg-onto:inSentence "We then add the epipolar loss with λe set to 1000 to fine-tune the teacher model."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BBe_set_to_1000,
        askg-data:Entity-epipolar_loss,
        askg-data:Entity-teacher_model,
        askg-data:Entity-using_epipolar_loss .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "When training the student model, we set (λp, λc, λs, λe, λo) to (1, 0, 0, 1000, 1), adding the occlusion loss."@en ;
    askg-onto:inSentence "When training the student model, we set (λp, λc, λs, λe, λo) to (1, 0, 0, 1000, 1), adding the occlusion loss."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BBp_%CE%BBc_%CE%BBs_%CE%BBe_%CE%BBo_to_1_0_0_1000_1,
        askg-data:Entity-occlusion_loss,
        askg-data:Entity-student_model .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We used the same training strategy for the RGBD SLAM dataset, with (λp, λc, λs, λe, λo) set to (1, 0.1, 1, 100, 1)."@en ;
    askg-onto:inSentence "We used the same training strategy for the RGBD SLAM dataset, with (λp, λc, λs, λe, λo) set to (1, 0.1, 1, 100, 1)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rgbd_slam_dataset,
        askg-data:Entity-training_strategy .

askg-data:Paper-8e2bc199f9f80305-Section-10-Paragraph-102-Sentence-1026 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "All experiments were run on a PC with a single 11GB RTX 2080 Ti GPU."@en ;
    askg-onto:inSentence "All experiments were run on a PC with a single 11GB RTX 2080 Ti GPU."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pc,
        askg-data:Entity-rtx_2080_ti_gpu .

askg-data:Paper-8e2bc199f9f80305-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "5.2. Essential Matrix Estimation"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-112,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-113,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-115 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "For estimating the essential matrix, we first obtain a robust initial estimate using RANSAC [12] and the five-point algorithm [28, 34]. We randomly sample 10 000 correspondences from the predicted optical flow and each GPU thread randomly selects five points on which to run the five-point algorithm [34]. Hence, each thread provides an essential matrix hypothesis for RANSAC. We select the essential matrix that has the most inliers, with respect to a set of 2 000 test correspondences, to initialize the iteratively reweighted least squares (IRLS) algorithm. IRLS iteratively minimizes our robust lower-level objective function l. The stopping criteria is when the objective function is below"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1112,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1113,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1114,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1115,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1116 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For estimating the essential matrix, we first obtain a robust initial estimate using RANSAC [12] and the five-point algorithm [28, 34]."@en ;
    askg-onto:inSentence "For estimating the essential matrix, we first obtain a robust initial estimate using RANSAC [12] and the five-point algorithm [28, 34]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-five-point_algorithm,
        askg-data:Entity-ransac .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We randomly sample 10 000 correspondences from the predicted optical flow and each GPU thread randomly selects five points on which to run the five-point algorithm [34]."@en ;
    askg-onto:inSentence "We randomly sample 10 000 correspondences from the predicted optical flow and each GPU thread randomly selects five points on which to run the five-point algorithm [34]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-correspondences,
        askg-data:Entity-five-point_algorithm,
        askg-data:Entity-five_points,
        askg-data:Entity-gpu_thread,
        askg-data:Entity-predicted_optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Hence, each thread provides an essential matrix hypothesis for RANSAC."@en ;
    askg-onto:inSentence "Hence, each thread provides an essential matrix hypothesis for RANSAC."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-matrix_hypothesis,
        askg-data:Entity-ransac,
        askg-data:Entity-thread .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We select the essential matrix that has the most inliers, with respect to a set of 2 000 test correspondences, to initialize the iteratively reweighted least squares (IRLS) algorithm."@en ;
    askg-onto:inSentence "We select the essential matrix that has the most inliers, with respect to a set of 2 000 test correspondences, to initialize the iteratively reweighted least squares (IRLS) algorithm."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-essential_matrix,
        askg-data:Entity-iteratively_reweighted_least_squares_irls_algorithm,
        askg-data:Entity-test_correspondences .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "IRLS iteratively minimizes our robust lower-level objective function l."@en ;
    askg-onto:inSentence "IRLS iteratively minimizes our robust lower-level objective function l."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-irls,
        askg-data:Entity-robust_lower-level_objective_function_l .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-111-Sentence-1116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The stopping criteria is when the objective function is below"@en ;
    askg-onto:inSentence "The stopping criteria is when the objective function is below"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-objective_function_is_below,
        askg-data:Entity-stopping_criteria .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-112 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "(a) Input image (b) Our flow (c) SelFlow [30] flow (d) Our error (e) SelFlow [30] error"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-112-Sentence-1121 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-112-Sentence-1121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) Input image (b) Our flow (c) SelFlow [30] flow (d) Our error (e) SelFlow [30] error"@en ;
    askg-onto:inSentence "(a) Input image (b) Our flow (c) SelFlow [30] flow (d) Our error (e) SelFlow [30] error"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_image,
        askg-data:Entity-our_error,
        askg-data:Entity-our_flow,
        askg-data:Entity-selflow_30_error,
        askg-data:Entity-selflow_30_flow .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-113 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-113-Sentence-1131 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-113-Sentence-1131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:inSentence "![6_image_0.png](6_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bioinformatics,
        askg-data:Entity-biological_molecules,
        askg-data:Entity-computer_science,
        askg-data:Entity-dna,
        askg-data:Entity-genomics,
        askg-data:Entity-molecular_biology,
        askg-data:Entity-nucleic_acid,
        askg-data:Entity-protein_synthesis,
        askg-data:Entity-research_field,
        askg-data:Entity-rna,
        askg-data:Entity-translating_genetic_information .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Figure 2. Qualitative results on the KITTI 2012 test set. We compare our method with SelFlow [30]. (a) The first image of the input image pair. (b) Optical flow predicted by our model. (c) Optical flow predicted by SelFlow. (d) Optical flow prediction error with respect to the ground-truth using our method. (e) Optical flow prediction error using SelFlow."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1141,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1142,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1143,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1144,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1145,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1146,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1147,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1148 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 2."@en ;
    askg-onto:inSentence "Figure 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-figure_2 .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Qualitative results on the KITTI 2012 test set."@en ;
    askg-onto:inSentence "Qualitative results on the KITTI 2012 test set."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-kitti_2012_test_set .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We compare our method with SelFlow [30]."@en ;
    askg-onto:inSentence "We compare our method with SelFlow [30]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-selflow .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(a) The first image of the input image pair."@en ;
    askg-onto:inSentence "(a) The first image of the input image pair."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_image,
        askg-data:Entity-image,
        askg-data:Entity-image_pair .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1145 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(b) Optical flow predicted by our model."@en ;
    askg-onto:inSentence "(b) Optical flow predicted by our model."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow,
        askg-data:Entity-our_model .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1146 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "(c) Optical flow predicted by SelFlow."@en ;
    askg-onto:inSentence "(c) Optical flow predicted by SelFlow."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow,
        askg-data:Entity-selflow .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1147 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "(d) Optical flow prediction error with respect to the ground-truth using our method."@en ;
    askg-onto:inSentence "(d) Optical flow prediction error with respect to the ground-truth using our method."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth,
        askg-data:Entity-optical_flow_prediction_error,
        askg-data:Entity-our_method .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-114-Sentence-1148 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "(e) Optical flow prediction error using SelFlow."@en ;
    askg-onto:inSentence "(e) Optical flow prediction error using SelFlow."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow_prediction_error,
        askg-data:Entity-selflow .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-115 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "10−20 or the number of iterations exceeds 200. The inlier threshold δ was empirically set to 0.001."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-115-Sentence-1151,
        askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-115-Sentence-1152 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-115-Sentence-1151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "10−20 or the number of iterations exceeds 200."@en ;
    askg-onto:inSentence "10−20 or the number of iterations exceeds 200."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1020,
        askg-data:Entity-200,
        askg-data:Entity-iterations .

askg-data:Paper-8e2bc199f9f80305-Section-11-Paragraph-115-Sentence-1152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The inlier threshold δ was empirically set to 0.001."@en ;
    askg-onto:inSentence "The inlier threshold δ was empirically set to 0.001."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0001,
        askg-data:Entity-inlier_threshold .

askg-data:Paper-8e2bc199f9f80305-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "5.3. Optical Flow Results"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126 ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Quantitative results for optical flow on the KITTI and RGB-D SLAM datasets are reported in Table 1. For ablation purposes, we also provide results for Ours-baseline, Ours-Epipolar, and Ours-Occlusion. Ours-baseline refers to the model that is only trained with Lp, Lc and Ls. Ours- Epipolar refers to the model that is trained with the same losses but also the epipolar loss Le. This is the result for our teacher network. Ours-Occlusion refers to training the baseline network with the teacher-student strategy described in Section 4, but without our proposed epipolar loss."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1211,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1212,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1213,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1214,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1215,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1216 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Quantitative results for optical flow on the KITTI and RGB-D SLAM datasets are reported in Table 1."@en ;
    askg-onto:inSentence "Quantitative results for optical flow on the KITTI and RGB-D SLAM datasets are reported in Table 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_dataset,
        askg-data:Entity-optical_flow,
        askg-data:Entity-rgb-d_slam_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For ablation purposes, we also provide results for Ours-baseline, Ours-Epipolar, and Ours-Occlusion."@en ;
    askg-onto:inSentence "For ablation purposes, we also provide results for Ours-baseline, Ours-Epipolar, and Ours-Occlusion."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ours-baseline,
        askg-data:Entity-ours-epipolar,
        askg-data:Entity-ours-occlusion,
        askg-data:Entity-results .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Ours-baseline refers to the model that is only trained with Lp, Lc and Ls."@en ;
    askg-onto:inSentence "Ours-baseline refers to the model that is only trained with Lp, Lc and Ls."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-ours-baseline .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Ours- Epipolar refers to the model that is trained with the same losses but also the epipolar loss Le."@en ;
    askg-onto:inSentence "Ours- Epipolar refers to the model that is trained with the same losses but also the epipolar loss Le."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ours-_epipolar,
        askg-data:Entity-the_epipolar_loss_le,
        askg-data:Entity-the_model,
        askg-data:Entity-the_same_losses .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This is the result for our teacher network."@en ;
    askg-onto:inSentence "This is the result for our teacher network."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-121-Sentence-1216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Ours-Occlusion refers to training the baseline network with the teacher-student strategy described in Section 4, but without our proposed epipolar loss."@en ;
    askg-onto:inSentence "Ours-Occlusion refers to training the baseline network with the teacher-student strategy described in Section 4, but without our proposed epipolar loss."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_proposed_epipolar_loss,
        askg-data:Entity-ours-occlusion,
        askg-data:Entity-section_4,
        askg-data:Entity-training_the_baseline_network_with_the_teacher-student_strategy .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For KITTI, our model outperforms previous unsupervised optical flow methods and achieves results very close to supervised methods. The ablation results indicate that the global geometric losses have a significant positive impact on the optical flow quality, decreasing error by approximately 20% on average compared to the baseline. We can also see that the data augmentation technique proposed by Liu et al. [30] only improves on the occluded pixels while our method improves on both the occluded and nonoccluded pixels. Note that compared with SelFlow [30], our method only uses two frames as input for training and testing while SelFlow uses five frames for training and three frames for testing. We show improved performance despite using fewer frames as input."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1221,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1222,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1223,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1224,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1225,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1226 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For KITTI, our model outperforms previous unsupervised optical flow methods and achieves results very close to supervised methods."@en ;
    askg-onto:inSentence "For KITTI, our model outperforms previous unsupervised optical flow methods and achieves results very close to supervised methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_model,
        askg-data:Entity-previous_unsupervised_optical_flow_methods,
        askg-data:Entity-supervised_methods .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The ablation results indicate that the global geometric losses have a significant positive impact on the optical flow quality, decreasing error by approximately 20% on average compared to the baseline."@en ;
    askg-onto:inSentence "The ablation results indicate that the global geometric losses have a significant positive impact on the optical flow quality, decreasing error by approximately 20% on average compared to the baseline."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approximately_20,
        askg-data:Entity-baseline,
        askg-data:Entity-error,
        askg-data:Entity-global_geometric_losses,
        askg-data:Entity-optical_flow_quality .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We can also see that the data augmentation technique proposed by Liu et al."@en ;
    askg-onto:inSentence "We can also see that the data augmentation technique proposed by Liu et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_augmentation_technique,
        askg-data:Entity-liu_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "[30] only improves on the occluded pixels while our method improves on both the occluded and nonoccluded pixels."@en ;
    askg-onto:inSentence "[30] only improves on the occluded pixels while our method improves on both the occluded and nonoccluded pixels."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-occluded_and_nonoccluded_pixels,
        askg-data:Entity-our_method .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Note that compared with SelFlow [30], our method only uses two frames as input for training and testing while SelFlow uses five frames for training and three frames for testing."@en ;
    askg-onto:inSentence "Note that compared with SelFlow [30], our method only uses two frames as input for training and testing while SelFlow uses five frames for training and three frames for testing."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_method,
        askg-data:Entity-selflow .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-122-Sentence-1226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We show improved performance despite using fewer frames as input."@en ;
    askg-onto:inSentence "We show improved performance despite using fewer frames as input."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-frames,
        askg-data:Entity-performance .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "For the RGB-D SLAM dataset, our model outperforms previous state-of-the-art unsupervised optical flow methods and has slightly lower performance compared to a supervised method. Note that the results of other unsupervised methods reported in the table share the same backbone network as ours and are pre-trained using our baseline approach. They are then finetuned with the proposed losses in the respective papers. The supervised method overfits on the training and validation data and therefore uses the test set to select the best performing model. We show that we also make significant improvements over the baseline method on this challenging dataset, indicating the usefulness of the global geometric constraint. This dataset has a much wider variety of camera motions than the KITTI"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1231,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1232,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1233,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1234,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1235,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1236 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For the RGB-D SLAM dataset, our model outperforms previous state-of-the-art unsupervised optical flow methods and has slightly lower performance compared to a supervised method."@en ;
    askg-onto:inSentence "For the RGB-D SLAM dataset, our model outperforms previous state-of-the-art unsupervised optical flow methods and has slightly lower performance compared to a supervised method."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-our_model,
        askg-data:Entity-previous_state-of-the-art_unsupervised_optical_flow_methods,
        askg-data:Entity-rgb-d_slam_dataset,
        askg-data:Entity-supervised_method .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that the results of other unsupervised methods reported in the table share the same backbone network as ours and are pre-trained using our baseline approach."@en ;
    askg-onto:inSentence "Note that the results of other unsupervised methods reported in the table share the same backbone network as ours and are pre-trained using our baseline approach."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baseline_approach,
        askg-data:Entity-other_unsupervised_methods,
        askg-data:Entity-ours,
        askg-data:Entity-unsupervised_methods .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "They are then finetuned with the proposed losses in the respective papers."@en ;
    askg-onto:inSentence "They are then finetuned with the proposed losses in the respective papers."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-losses,
        askg-data:Entity-papers .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1234 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The supervised method overfits on the training and validation data and therefore uses the test set to select the best performing model."@en ;
    askg-onto:inSentence "The supervised method overfits on the training and validation data and therefore uses the test set to select the best performing model."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_performing_model,
        askg-data:Entity-supervised_method,
        askg-data:Entity-test_set,
        askg-data:Entity-training_and_validation_data .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1235 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We show that we also make significant improvements over the baseline method on this challenging dataset, indicating the usefulness of the global geometric constraint."@en ;
    askg-onto:inSentence "We show that we also make significant improvements over the baseline method on this challenging dataset, indicating the usefulness of the global geometric constraint."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baseline_method,
        askg-data:Entity-global_geometric_constraint,
        askg-data:Entity-this_challenging_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-123-Sentence-1236 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This dataset has a much wider variety of camera motions than the KITTI"@en ;
    askg-onto:inSentence "This dataset has a much wider variety of camera motions than the KITTI"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motions,
        askg-data:Entity-dataset,
        askg-data:Entity-kitti .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Table 2. Odometry comparison for the KITTI VO dataset. We compare with an existing SLAM system and state-of-the-art unsupervised depth and motion learning algorithms. We report the translation error (%) and the rotation error (degrees per 100m)."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1241,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1242,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1243,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1244 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 2."@en ;
    askg-onto:inSentence "Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Odometry comparison for the KITTI VO dataset."@en ;
    askg-onto:inSentence "Odometry comparison for the KITTI VO dataset."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-kitti_vo_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1243 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We compare with an existing SLAM system and state-of-the-art unsupervised depth and motion learning algorithms."@en ;
    askg-onto:inSentence "We compare with an existing SLAM system and state-of-the-art unsupervised depth and motion learning algorithms."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-slam_system,
        askg-data:Entity-unsupervised_depth_and_motion_learning_algorithms .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-124-Sentence-1244 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We report the translation error (%) and the rotation error (degrees per 100m)."@en ;
    askg-onto:inSentence "We report the translation error (%) and the rotation error (degrees per 100m)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rotation_error,
        askg-data:Entity-translation_error .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "| | Seq. 9 | | Seq. 10 | | |--------------------|----------------|---------|-----------|----------------| | Method | terr(%) rerr( | ◦/100m) | terr(%) | rerr( ◦/100m) | | ORB\\-SLAM [32] | 2.51 | 0.26 | 2.10 | 0.48 | | Zhou et al. [57] | 17.72 | 6.82 | 36.57 | 17.69 | | Zhan et al. [54] | 6.87 | 3.60 | 7.87 | 3.41 | | Gordon et al. [17] | 3.10 | - | 5.40 | - | | Bian et al. [4] | 6.07 | 2.19 | 7.56 | 4.63 | | Ours | 4.36 | 0.69 | 4.04 | 1.37 |"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1251,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1252,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1253,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1254,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1255,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1256,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1257 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | Seq."@en ;
    askg-onto:inSentence "| | Seq."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-seq .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "9 | | Seq."@en ;
    askg-onto:inSentence "9 | | Seq."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-seq,
        askg-data:Entity-system .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1253 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "10 | | |--------------------|----------------|---------|-----------|----------------| | Method | terr(%) rerr( | ◦/100m) | terr(%) | rerr( ◦/100m) | | ORB\\-SLAM [32] | 2.51 | 0.26 | 2.10 | 0.48 | | Zhou et al."@en ;
    askg-onto:inSentence "10 | | |--------------------|----------------|---------|-----------|----------------| | Method | terr(%) rerr( | ◦/100m) | terr(%) | rerr( ◦/100m) | | ORB\\-SLAM [32] | 2.51 | 0.26 | 2.10 | 0.48 | | Zhou et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-251_terr_026_rerr100m,
        askg-data:Entity-orb-slam,
        askg-data:Entity-zhou_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1254 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "[57] | 17.72 | 6.82 | 36.57 | 17.69 | | Zhan et al."@en ;
    askg-onto:inSentence "[57] | 17.72 | 6.82 | 36.57 | 17.69 | | Zhan et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper,
        askg-data:Entity-zhan_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1255 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "[54] | 6.87 | 3.60 | 7.87 | 3.41 | | Gordon et al."@en ;
    askg-onto:inSentence "[54] | 6.87 | 3.60 | 7.87 | 3.41 | | Gordon et al."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gordon_et_al,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1256 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "[17] | 3.10 | - | 5.40 | - | | Bian et al."@en ;
    askg-onto:inSentence "[17] | 3.10 | - | 5.40 | - | | Bian et al."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bian_et_al,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-125-Sentence-1257 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "[4] | 6.07 | 2.19 | 7.56 | 4.63 | | Ours | 4.36 | 0.69 | 4.04 | 1.37 |"@en ;
    askg-onto:inSentence "[4] | 6.07 | 2.19 | 7.56 | 4.63 | | Ours | 4.36 | 0.69 | 4.04 | 1.37 |"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-069,
        askg-data:Entity-137,
        askg-data:Entity-404,
        askg-data:Entity-436,
        askg-data:Entity-ours .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "dataset, making optical flow estimation more difficult and camera motion estimation more helpful. Qualitative results for the RGB-D SLAM dataset are shown in Figure 3. They demonstrate that the brightness constancy and smoothness assumptions are insufficient to correctly resolve the flow in challenging scenarios."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126-Sentence-1261,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126-Sentence-1262,
        askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126-Sentence-1263 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126-Sentence-1261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "dataset, making optical flow estimation more difficult and camera motion estimation more helpful."@en ;
    askg-onto:inSentence "dataset, making optical flow estimation more difficult and camera motion estimation more helpful."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion_estimation,
        askg-data:Entity-optical_flow_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126-Sentence-1262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Qualitative results for the RGB-D SLAM dataset are shown in Figure 3."@en ;
    askg-onto:inSentence "Qualitative results for the RGB-D SLAM dataset are shown in Figure 3."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_3,
        askg-data:Entity-rgb-d_slam_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-12-Paragraph-126-Sentence-1263 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "They demonstrate that the brightness constancy and smoothness assumptions are insufficient to correctly resolve the flow in challenging scenarios."@en ;
    askg-onto:inSentence "They demonstrate that the brightness constancy and smoothness assumptions are insufficient to correctly resolve the flow in challenging scenarios."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brightness_constancy,
        askg-data:Entity-condition,
        askg-data:Entity-smoothness_assumptions .

askg-data:Paper-8e2bc199f9f80305-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "5.4. Ego-Motion Results"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131,
        askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We estimate the camera pose by decomposing our estimated essential matrix frame-by-frame, without any bundle adjustment, as opposed to ORB-SLAM [32]. Since our estimated essential matrix does not contain any scale information, we have to align our scale with the ground-truth frameby-frame. For fair comparison, we also align the scales of the compared methods [57, 54, 4]."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131-Sentence-1312,
        askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131-Sentence-1313 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We estimate the camera pose by decomposing our estimated essential matrix frame-by-frame, without any bundle adjustment, as opposed to ORB-SLAM [32]."@en ;
    askg-onto:inSentence "We estimate the camera pose by decomposing our estimated essential matrix frame-by-frame, without any bundle adjustment, as opposed to ORB-SLAM [32]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bundle_adjustment,
        askg-data:Entity-camera_pose,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-orb-slam .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Since our estimated essential matrix does not contain any scale information, we have to align our scale with the ground-truth frameby-frame."@en ;
    askg-onto:inSentence "Since our estimated essential matrix does not contain any scale information, we have to align our scale with the ground-truth frameby-frame."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-essential_matrix,
        askg-data:Entity-ground-truth_frame,
        askg-data:Entity-scale,
        askg-data:Entity-scale_information .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-131-Sentence-1313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For fair comparison, we also align the scales of the compared methods [57, 54, 4]."@en ;
    askg-onto:inSentence "For fair comparison, we also align the scales of the compared methods [57, 54, 4]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-scales .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The quantitative results for ego-motion estimation on KITTI VO are shown in Table 2. Our method of estimating the camera pose significantly outperforms methods that directly regress the pose using a network. Qualitative results for the odometry comparison are shown in Figure 4, from which we can see our algorithm achieves performance close to ORB-SLAM, up to scale."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132-Sentence-1321,
        askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132-Sentence-1322,
        askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132-Sentence-1323 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132-Sentence-1321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The quantitative results for ego-motion estimation on KITTI VO are shown in Table 2."@en ;
    askg-onto:inSentence "The quantitative results for ego-motion estimation on KITTI VO are shown in Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ego-motion_estimation,
        askg-data:Entity-kitti_vo .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132-Sentence-1322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Our method of estimating the camera pose significantly outperforms methods that directly regress the pose using a network."@en ;
    askg-onto:inSentence "Our method of estimating the camera pose significantly outperforms methods that directly regress the pose using a network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods_that_directly_regress_the_pose_using_a_network,
        askg-data:Entity-our_method .

askg-data:Paper-8e2bc199f9f80305-Section-13-Paragraph-132-Sentence-1323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Qualitative results for the odometry comparison are shown in Figure 4, from which we can see our algorithm achieves performance close to ORB-SLAM, up to scale."@en ;
    askg-onto:inSentence "Qualitative results for the odometry comparison are shown in Figure 4, from which we can see our algorithm achieves performance close to ORB-SLAM, up to scale."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-odometry_comparison,
        askg-data:Entity-orb-slam .

askg-data:Paper-8e2bc199f9f80305-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "6. Discussion And Conclusion"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-141,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-142,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-143,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-145,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-149 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this paper, we have proposed a pipeline that is able to learn optical flow and egomotion simultaneously in an unsupervised manner by incorporating global geometric constraints into an optical flow estimation network. In particular, our method uses the implicit differentiation tech-"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-141-Sentence-1411,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-141-Sentence-1412 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this paper, we have proposed a pipeline that is able to learn optical flow and egomotion simultaneously in an unsupervised manner by incorporating global geometric constraints into an optical flow estimation network."@en ;
    askg-onto:inSentence "In this paper, we have proposed a pipeline that is able to learn optical flow and egomotion simultaneously in an unsupervised manner by incorporating global geometric constraints into an optical flow estimation network."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-egomotion,
        askg-data:Entity-global_geometric_constraints,
        askg-data:Entity-model,
        askg-data:Entity-optical_flow,
        askg-data:Entity-optical_flow_estimation_network,
        askg-data:Entity-paper,
        askg-data:Entity-pipeline .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-141-Sentence-1412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In particular, our method uses the implicit differentiation tech-"@en ;
    askg-onto:inSentence "In particular, our method uses the implicit differentiation tech-"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-implicit_differentiation,
        askg-data:Entity-method .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-142 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "(a) Input image 1 (b) Input image 2 (c) GT flow (d) Our flow without Le (e) Our flow"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-142-Sentence-1421 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-142-Sentence-1421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) Input image 1 (b) Input image 2 (c) GT flow (d) Our flow without Le (e) Our flow"@en ;
    askg-onto:inSentence "(a) Input image 1 (b) Input image 2 (c) GT flow (d) Our flow without Le (e) Our flow"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flow,
        askg-data:Entity-gt_flow,
        askg-data:Entity-image,
        askg-data:Entity-input_image_1,
        askg-data:Entity-input_image_2,
        askg-data:Entity-our_flow,
        askg-data:Entity-our_flow_without_le .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-143 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-143-Sentence-1431 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-143-Sentence-1431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:inSentence "![7_image_0.png](7_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai_ethics,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_vision,
        askg-data:Entity-deep_learning,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-pytorch,
        askg-data:Entity-random_forest,
        askg-data:Entity-software,
        askg-data:Entity-support_vector_machine,
        askg-data:Entity-tensorflow .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Figure 3. Qualitative results on the RGBD-SLAM test set. The ground-truth flow is generated from the sparse ground-truth depth and the ground-truth pose provided by the dataset. The examples show that in cases of large motions, featureless regions and repetitive textures, the global geometric loss helps the network to learn to predict correct optical flow."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1441,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1442,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1443,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1444 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 3."@en ;
    askg-onto:inSentence "Figure 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_3,
        askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Qualitative results on the RGBD-SLAM test set."@en ;
    askg-onto:inSentence "Qualitative results on the RGBD-SLAM test set."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-qualitative_results,
        askg-data:Entity-rgbd-slam .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The ground-truth flow is generated from the sparse ground-truth depth and the ground-truth pose provided by the dataset."@en ;
    askg-onto:inSentence "The ground-truth flow is generated from the sparse ground-truth depth and the ground-truth pose provided by the dataset."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_flow,
        askg-data:Entity-ground-truth_pose,
        askg-data:Entity-sparse_ground-truth_depth,
        askg-data:Entity-the_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-144-Sentence-1444 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The examples show that in cases of large motions, featureless regions and repetitive textures, the global geometric loss helps the network to learn to predict correct optical flow."@en ;
    askg-onto:inSentence "The examples show that in cases of large motions, featureless regions and repetitive textures, the global geometric loss helps the network to learn to predict correct optical flow."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-correct_optical_flow,
        askg-data:Entity-global_geometric_loss,
        askg-data:Entity-network .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-145 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![7_image_1.png](7_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-145-Sentence-1451 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-145-Sentence-1451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![7_image_1.png](7_image_1.png)"@en ;
    askg-onto:inSentence "![7_image_1.png](7_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset_y,
        askg-data:Entity-experiment_1,
        askg-data:Entity-finding_1,
        askg-data:Entity-research_field_x,
        askg-data:Entity-research_method_a,
        askg-data:Entity-theory_z .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Figure 4. Qualitative results on KITTI VO sequences 9 and 10. For each sequence we provide the xz and xy odometry map. Second to ORB-SLAM, our method is closest to the ground-truth odometry. When visualizing the xy odometry map, it can be seen that unsupervised learning methods [57, 54, 4] have significant error in the y-axis direction, while our method has minimal error."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1461,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1462,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1463,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1464,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1465 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 4."@en ;
    askg-onto:inSentence "Figure 4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Qualitative results on KITTI VO sequences 9 and 10."@en ;
    askg-onto:inSentence "Qualitative results on KITTI VO sequences 9 and 10."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_vo_sequences_9_and_10,
        askg-data:Entity-qualitative_results .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1463 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For each sequence we provide the xz and xy odometry map."@en ;
    askg-onto:inSentence "For each sequence we provide the xz and xy odometry map."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-xy_odometry_map,
        askg-data:Entity-xz_odometry_map .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1464 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Second to ORB-SLAM, our method is closest to the ground-truth odometry."@en ;
    askg-onto:inSentence "Second to ORB-SLAM, our method is closest to the ground-truth odometry."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-orb-slam,
        askg-data:Entity-our_method,
        askg-data:Entity-the_ground-truth_odometry .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-146-Sentence-1465 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "When visualizing the xy odometry map, it can be seen that unsupervised learning methods [57, 54, 4] have significant error in the y-axis direction, while our method has minimal error."@en ;
    askg-onto:inSentence "When visualizing the xy odometry map, it can be seen that unsupervised learning methods [57, 54, 4] have significant error in the y-axis direction, while our method has minimal error."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_method,
        askg-data:Entity-unsupervised_learning_methods,
        askg-data:Entity-y-axis_direction .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "nique to allow back-propagating the gradients through a complicated geometric estimation algorithm without needing to compute the gradient for each algorithmic step. Given that the algorithm is complex, iterative, and involves a nondifferentiable RANSAC procedure, it would otherwise be impossible to train end-to-end. Unlike approaches such as differentiable RANSAC [6], we do not need to weaken any sub-components of the algorithm to make them easier for a network to compute, by for example, replacing the nondifferentiable argmax hypothesis selction with probabilistic selection. Moreover, our formulation allows us to estimate the *essential matrix* and back-propagate through this estimation layer. This gives a much tighter constraint than the fundamental matrix, having fewer degrees of freedom, and admits the use of state-of-the-art geometric algorithms. In contrast, the 8-point algorithm for estimating the fundamental matrix linearizes the problem and does not exploit the given knowledge of the intrinsic camera parameters, which can result in \"quite inaccurate\" estimation of focal lengths and thus epipolar constraints [22]. It has only been the algorithm of choice for network architectures because it has heretofore not been known how to back-propagate through an essential matrix estimation layer."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1471,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1472,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1473,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1474,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1475,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1476,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1477 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "nique to allow back-propagating the gradients through a complicated geometric estimation algorithm without needing to compute the gradient for each algorithmic step."@en ;
    askg-onto:inSentence "nique to allow back-propagating the gradients through a complicated geometric estimation algorithm without needing to compute the gradient for each algorithmic step."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-back-propagating_gradients,
        askg-data:Entity-geometric_estimation_algorithm .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given that the algorithm is complex, iterative, and involves a nondifferentiable RANSAC procedure, it would otherwise be impossible to train end-to-end."@en ;
    askg-onto:inSentence "Given that the algorithm is complex, iterative, and involves a nondifferentiable RANSAC procedure, it would otherwise be impossible to train end-to-end."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-complex,
        askg-data:Entity-end-to-end,
        askg-data:Entity-iterative,
        askg-data:Entity-nondifferentiable_ransac_procedure,
        askg-data:Entity-procedure,
        askg-data:Entity-ransac_procedure .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Unlike approaches such as differentiable RANSAC [6], we do not need to weaken any sub-components of the algorithm to make them easier for a network to compute, by for example, replacing the nondifferentiable argmax hypothesis selction with probabilistic selection."@en ;
    askg-onto:inSentence "Unlike approaches such as differentiable RANSAC [6], we do not need to weaken any sub-components of the algorithm to make them easier for a network to compute, by for example, replacing the nondifferentiable argmax hypothesis selction with probabilistic selection."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-argmax_hypothesis_selection,
        askg-data:Entity-differentiable_ransac,
        askg-data:Entity-probabilistic_selection .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1474 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, our formulation allows us to estimate the *essential matrix* and back-propagate through this estimation layer."@en ;
    askg-onto:inSentence "Moreover, our formulation allows us to estimate the *essential matrix* and back-propagate through this estimation layer."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-back-propagation,
        askg-data:Entity-essential_matrix .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1475 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This gives a much tighter constraint than the fundamental matrix, having fewer degrees of freedom, and admits the use of state-of-the-art geometric algorithms."@en ;
    askg-onto:inSentence "This gives a much tighter constraint than the fundamental matrix, having fewer degrees of freedom, and admits the use of state-of-the-art geometric algorithms."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fundamental_matrix,
        askg-data:Entity-state-of-the-art_geometric_algorithms .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1476 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In contrast, the 8-point algorithm for estimating the fundamental matrix linearizes the problem and does not exploit the given knowledge of the intrinsic camera parameters, which can result in \"quite inaccurate\" estimation of focal lengths and thus epipolar constraints [22]."@en ;
    askg-onto:inSentence "In contrast, the 8-point algorithm for estimating the fundamental matrix linearizes the problem and does not exploit the given knowledge of the intrinsic camera parameters, which can result in \"quite inaccurate\" estimation of focal lengths and thus epipolar constraints [22]."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8-point_algorithm,
        askg-data:Entity-epipolar_constraints,
        askg-data:Entity-focal_lengths,
        askg-data:Entity-fundamental_matrix,
        askg-data:Entity-problem .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-147-Sentence-1477 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "It has only been the algorithm of choice for network architectures because it has heretofore not been known how to back-propagate through an essential matrix estimation layer."@en ;
    askg-onto:inSentence "It has only been the algorithm of choice for network architectures because it has heretofore not been known how to back-propagate through an essential matrix estimation layer."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-back-propagate,
        askg-data:Entity-essential_matrix_estimation_layer,
        askg-data:Entity-network_architectures .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Our model produces state-of-the-art results for unsupervised learning of optical flow, including for challenging data on which existing algorithms are known to perform poorly. We have also demonstrated superior camera motion estimation by optimizing an essential matrix from the predicted optical flow, compared with unsupervised methods that directly regress camera pose. Our approach to including a geometric estimation layer in a deep learning framework can be adapted to many other problems. This work provides a case study that demonstrates the usefulness of implicit differentiation as a tool for improving computer vision models."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1481,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1482,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1483,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1484 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our model produces state-of-the-art results for unsupervised learning of optical flow, including for challenging data on which existing algorithms are known to perform poorly."@en ;
    askg-onto:inSentence "Our model produces state-of-the-art results for unsupervised learning of optical flow, including for challenging data on which existing algorithms are known to perform poorly."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-challenging_data,
        askg-data:Entity-existing_algorithms,
        askg-data:Entity-our_model,
        askg-data:Entity-state-of-the-art_results,
        askg-data:Entity-unsupervised_learning_of_optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1482 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We have also demonstrated superior camera motion estimation by optimizing an essential matrix from the predicted optical flow, compared with unsupervised methods that directly regress camera pose."@en ;
    askg-onto:inSentence "We have also demonstrated superior camera motion estimation by optimizing an essential matrix from the predicted optical flow, compared with unsupervised methods that directly regress camera pose."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion_estimation,
        askg-data:Entity-methods_that_directly_regress_camera_pose,
        askg-data:Entity-optimizing_an_essential_matrix_from_the_predicted_optical_flow,
        askg-data:Entity-unsupervised_methods .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1483 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our approach to including a geometric estimation layer in a deep learning framework can be adapted to many other problems."@en ;
    askg-onto:inSentence "Our approach to including a geometric estimation layer in a deep learning framework can be adapted to many other problems."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_framework,
        askg-data:Entity-geometric_estimation_layer .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-148-Sentence-1484 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This work provides a case study that demonstrates the usefulness of implicit differentiation as a tool for improving computer vision models."@en ;
    askg-onto:inSentence "This work provides a case study that demonstrates the usefulness of implicit differentiation as a tool for improving computer vision models."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-implicit_differentiation,
        askg-data:Entity-improving_computer_vision_models .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-149 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Acknowledgements Shihao Jiang would like to thank Suryansh Kumar, Yiran Zhong, Yao Lu and Kartik Gupta for helpful discussions. This research is supported in part by the Australian Government through the Australian Research Council and Data61 CSIRO."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-149-Sentence-1491,
        askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-149-Sentence-1492 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-149-Sentence-1491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Acknowledgements Shihao Jiang would like to thank Suryansh Kumar, Yiran Zhong, Yao Lu and Kartik Gupta for helpful discussions."@en ;
    askg-onto:inSentence "Acknowledgements Shihao Jiang would like to thank Suryansh Kumar, Yiran Zhong, Yao Lu and Kartik Gupta for helpful discussions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kartik_gupta,
        askg-data:Entity-shihao_jiang,
        askg-data:Entity-suryansh_kumar,
        askg-data:Entity-yao_lu,
        askg-data:Entity-yiran_zhong .

askg-data:Paper-8e2bc199f9f80305-Section-14-Paragraph-149-Sentence-1492 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This research is supported in part by the Australian Government through the Australian Research Council and Data61 CSIRO."@en ;
    askg-onto:inSentence "This research is supported in part by the Australian Government through the Australian Research Council and Data61 CSIRO."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australian_government,
        askg-data:Entity-australian_research_council,
        askg-data:Entity-data61_csiro .

askg-data:Paper-8e2bc199f9f80305-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "References"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "[1] Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Susstrunk. Slic superpix- ¨ els compared to state-of-the-art superpixel methods. IEEE transactions on pattern analysis and machine intelligence, 34(11):2274–2282, 2012. 5 [2] Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural networks. In Proceedings of the 34th International Conference on Machine Learning- Volume 70, pages 136–145. JMLR. org, 2017. 2 [3] Min Bai, Wenjie Luo, Kaustav Kundu, and Raquel Urtasun."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1511,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1512,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1513,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1514,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1515,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1516,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1517,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1518,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1519 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[1] Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Susstrunk."@en ;
    askg-onto:inSentence "[1] Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Susstrunk."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appu_shaji,
        askg-data:Entity-aurelien_lucchi,
        askg-data:Entity-kevin_smith,
        askg-data:Entity-pascal_fua,
        askg-data:Entity-person,
        askg-data:Entity-radhakrishna_achanta,
        askg-data:Entity-sabine_susstrunk .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Slic superpix- ¨ els compared to state-of-the-art superpixel methods."@en ;
    askg-onto:inSentence "Slic superpix- ¨ els compared to state-of-the-art superpixel methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-slic_superpixels,
        askg-data:Entity-state-of-the-art_superpixel_methods .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "IEEE transactions on pattern analysis and machine intelligence, 34(11):2274–2282, 2012."@en ;
    askg-onto:inSentence "IEEE transactions on pattern analysis and machine intelligence, 34(11):2274–2282, 2012."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11,
        askg-data:Entity-2012,
        askg-data:Entity-22742282,
        askg-data:Entity-34,
        askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "5 [2] Brandon Amos and J Zico Kolter."@en ;
    askg-onto:inSentence "5 [2] Brandon Amos and J Zico Kolter."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brandon_amos,
        askg-data:Entity-j_zico_kolter .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Optnet: Differentiable optimization as a layer in neural networks."@en ;
    askg-onto:inSentence "Optnet: Differentiable optimization as a layer in neural networks."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differentiable_optimization_as_a_layer_in_neural_networks,
        askg-data:Entity-optnet .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In Proceedings of the 34th International Conference on Machine Learning- Volume 70, pages 136–145."@en ;
    askg-onto:inSentence "In Proceedings of the 34th International Conference on Machine Learning- Volume 70, pages 136–145."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1517 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "JMLR."@en ;
    askg-onto:inSentence "JMLR."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jmlr,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1518 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "org, 2017."@en ;
    askg-onto:inSentence "org, 2017."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-org .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-151-Sentence-1519 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "2 [3] Min Bai, Wenjie Luo, Kaustav Kundu, and Raquel Urtasun."@en ;
    askg-onto:inSentence "2 [3] Min Bai, Wenjie Luo, Kaustav Kundu, and Raquel Urtasun."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-kaustav_kundu,
        askg-data:Entity-min_bai,
        askg-data:Entity-raquel_urtasun,
        askg-data:Entity-wenjie_luo .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Exploiting semantic information and deep matching for optical flow. In *European Conference on Computer Vision*, pages 154–170. Springer, 2016. 2 [4] Jia-Wang Bian, Zhichao Li, Naiyan Wang, Huangying Zhan, Chunhua Shen, Ming-Ming Cheng, and Ian Reid. Unsupervised scale-consistent depth and ego-motion learning from monocular video. *arXiv preprint arXiv:1908.10553*, 2019. 7, 8 [5] Michael J Black and Allan D Jepson. Estimating optical flow in segmented images using variable-order parametric models with local deformations. *IEEE Transactions on Pattern* Analysis and Machine Intelligence, 18(10):972–986, 1996. 1 [6] Eric Brachmann, Alexander Krull, Sebastian Nowozin, Jamie Shotton, Frank Michel, Stefan Gumhold, and Carsten Rother. Dsac - Differentiable RANSAC for camera localization. In *Proceedings of the IEEE Conference on Computer* Vision and Pattern Recognition, pages 6684–6692, 2017. 8 [7] Thomas Brox, Andres Bruhn, Nils Papenberg, and Joachim ´ Weickert. High accuracy optical flow estimation based on a theory for warping. In European Conference on Computer Vision, pages 25–36. Springer, 2004. 1 [8] Justin Domke. Generic methods for optimization-based modeling. In *Artificial Intelligence and Statistics*, pages 318–326, 2012. 4 [9] Asen L. Dontchev and R. Tyrrell Rockafellar. Implicit Functions and Solution Mappings: A View from Variational Analysis. Springer-Verlag, 2nd edition, 2014. 4 [10] Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser, Caner Hazirbas, Vladimir Golkov, Patrick Van Der Smagt, Daniel Cremers, and Thomas Brox. Flownet: Learning optical flow with convolutional networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 2758–2766, 2015. 1, 2 [11] Basura Fernando and Stephen Gould. Learning end-to-end video classification with rank-pooling. In International Conference on Machine Learning, pages 1187–1196, 2016. 2 [12] Martin A Fischler and Robert C Bolles. Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, 24(6):381–395, 1981. 3, 6 [13] Denis Fortun, Patrick Bouthemy, and Charles Kervrann. Optical flow modeling and computation: A survey. *Computer* Vision and Image Understanding, 134:1–21, 2015. 2 [14] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. Vision meets robotics: The KITTI dataset. The International Journal of Robotics Research, 32(11):1231– 1237, 2013. 5 [15] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the KITTI vision benchmark suite. In *2012 IEEE Conference on Computer Vision and* Pattern Recognition, pages 3354–3361. IEEE, 2012. 5 [16] Clement Godard, Oisin Mac Aodha, and Gabriel J Bros- ´ tow. Unsupervised monocular depth estimation with leftright consistency. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 270–279, 2017. 5 [17] Ariel Gordon, Hanhan Li, Rico Jonschkowski, and Anelia Angelova. Depth from videos in the wild: Unsupervised monocular depth learning from unknown cameras. arXiv preprint arXiv:1904.04998, 2019. 7 [18] Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo. On differentiating parameterized argmin and argmax problems with application to bi-level optimization. arXiv preprint arXiv:1607.05447, 2016. 2, 4 [19] Stephen Gould, Richard Hartley, and Dylan Campbell."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1521,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15210,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15211,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15212,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15213,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15214,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15215,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15216,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15217,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15218,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15219,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1522,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15220,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15221,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15222,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15223,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15224,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15225,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15226,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15227,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15228,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15229,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1523,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15230,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15231,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15232,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15233,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15234,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15235,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15236,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15237,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15238,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15239,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1524,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15240,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15241,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15242,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15243,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15244,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15245,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15246,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15247,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15248,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15249,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1525,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15250,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15251,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15252,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15253,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15254,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1526,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1527,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1528,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1529 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Exploiting semantic information and deep matching for optical flow."@en ;
    askg-onto:inSentence "Exploiting semantic information and deep matching for optical flow."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_matching,
        askg-data:Entity-optical_flow,
        askg-data:Entity-semantic_information .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "1 [6] Eric Brachmann, Alexander Krull, Sebastian Nowozin, Jamie Shotton, Frank Michel, Stefan Gumhold, and Carsten Rother."@en ;
    askg-onto:inSentence "1 [6] Eric Brachmann, Alexander Krull, Sebastian Nowozin, Jamie Shotton, Frank Michel, Stefan Gumhold, and Carsten Rother."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alexander_krull,
        askg-data:Entity-carsten_rother,
        askg-data:Entity-eric_brachmann,
        askg-data:Entity-frank_michel,
        askg-data:Entity-jamie_shotton,
        askg-data:Entity-person,
        askg-data:Entity-sebastian_nowozin,
        askg-data:Entity-stefan_gumhold .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15211 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Dsac - Differentiable RANSAC for camera localization."@en ;
    askg-onto:inSentence "Dsac - Differentiable RANSAC for camera localization."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differentiable_ransac_for_camera_localization,
        askg-data:Entity-dsac .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15212 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "In *Proceedings of the IEEE Conference on Computer* Vision and Pattern Recognition, pages 6684–6692, 2017."@en ;
    askg-onto:inSentence "In *Proceedings of the IEEE Conference on Computer* Vision and Pattern Recognition, pages 6684–6692, 2017."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15213 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "8 [7] Thomas Brox, Andres Bruhn, Nils Papenberg, and Joachim ´ Weickert."@en ;
    askg-onto:inSentence "8 [7] Thomas Brox, Andres Bruhn, Nils Papenberg, and Joachim ´ Weickert."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-andres_bruhn,
        askg-data:Entity-joachim_weickert,
        askg-data:Entity-nils_papenberg,
        askg-data:Entity-person,
        askg-data:Entity-thomas_brox .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15214 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "High accuracy optical flow estimation based on a theory for warping."@en ;
    askg-onto:inSentence "High accuracy optical flow estimation based on a theory for warping."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-theory_for_warping .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15215 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "In European Conference on Computer Vision, pages 25–36."@en ;
    askg-onto:inSentence "In European Conference on Computer Vision, pages 25–36."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15216 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Springer, 2004."@en ;
    askg-onto:inSentence "Springer, 2004."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2004,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15217 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "1 [8] Justin Domke."@en ;
    askg-onto:inSentence "1 [8] Justin Domke."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-justin_domke .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15218 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Generic methods for optimization-based modeling."@en ;
    askg-onto:inSentence "Generic methods for optimization-based modeling."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generic_methods,
        askg-data:Entity-optimization-based_modeling .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15219 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "In *Artificial Intelligence and Statistics*, pages 318–326, 2012."@en ;
    askg-onto:inSentence "In *Artificial Intelligence and Statistics*, pages 318–326, 2012."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence_and_statistics,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In *European Conference on Computer Vision*, pages 154–170."@en ;
    askg-onto:inSentence "In *European Conference on Computer Vision*, pages 154–170."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-european_conference_on_computer_vision,
        askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15220 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "4 [9] Asen L."@en ;
    askg-onto:inSentence "4 [9] Asen L."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asen_l,
        askg-data:Entity-author .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15221 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Dontchev and R."@en ;
    askg-onto:inSentence "Dontchev and R."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dontchev,
        askg-data:Entity-person,
        askg-data:Entity-r .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15222 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Tyrrell Rockafellar."@en ;
    askg-onto:inSentence "Tyrrell Rockafellar."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-tyrrell_rockafellar .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15223 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Implicit Functions and Solution Mappings: A View from Variational Analysis."@en ;
    askg-onto:inSentence "Implicit Functions and Solution Mappings: A View from Variational Analysis."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-implicit_functions,
        askg-data:Entity-research_field,
        askg-data:Entity-solution_mappings,
        askg-data:Entity-variational_analysis .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15224 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Springer-Verlag, 2nd edition, 2014."@en ;
    askg-onto:inSentence "Springer-Verlag, 2nd edition, 2014."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-2nd_edition,
        askg-data:Entity-springer-verlag .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15225 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "4 [10] Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser, Caner Hazirbas, Vladimir Golkov, Patrick Van Der Smagt, Daniel Cremers, and Thomas Brox."@en ;
    askg-onto:inSentence "4 [10] Alexey Dosovitskiy, Philipp Fischer, Eddy Ilg, Philip Hausser, Caner Hazirbas, Vladimir Golkov, Patrick Van Der Smagt, Daniel Cremers, and Thomas Brox."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alexey_dosovitskiy,
        askg-data:Entity-caner_hazirbas,
        askg-data:Entity-daniel_cremers,
        askg-data:Entity-eddy_ilg,
        askg-data:Entity-patrick_van_der_smagt,
        askg-data:Entity-person,
        askg-data:Entity-philip_hausser,
        askg-data:Entity-philipp_fischer,
        askg-data:Entity-thomas_brox,
        askg-data:Entity-vladimir_golkov .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15226 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Flownet: Learning optical flow with convolutional networks."@en ;
    askg-onto:inSentence "Flownet: Learning optical flow with convolutional networks."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flownet,
        askg-data:Entity-learning_optical_flow_with_convolutional_networks .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15227 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "In Proceedings of the IEEE International Conference on Computer Vision, pages 2758–2766, 2015."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE International Conference on Computer Vision, pages 2758–2766, 2015."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15228 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "1, 2 [11] Basura Fernando and Stephen Gould."@en ;
    askg-onto:inSentence "1, 2 [11] Basura Fernando and Stephen Gould."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-basura_fernando,
        askg-data:Entity-research,
        askg-data:Entity-stephen_gould .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15229 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Learning end-to-end video classification with rank-pooling."@en ;
    askg-onto:inSentence "Learning end-to-end video classification with rank-pooling."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-end-to-end_video_classification,
        askg-data:Entity-method .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Springer, 2016."@en ;
    askg-onto:inSentence "Springer, 2016."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15230 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "In International Conference on Machine Learning, pages 1187–1196, 2016."@en ;
    askg-onto:inSentence "In International Conference on Machine Learning, pages 1187–1196, 2016."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11871196,
        askg-data:Entity-2016,
        askg-data:Entity-conference .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15231 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "2 [12] Martin A Fischler and Robert C Bolles."@en ;
    askg-onto:inSentence "2 [12] Martin A Fischler and Robert C Bolles."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-martin_a_fischler,
        askg-data:Entity-paper,
        askg-data:Entity-robert_c_bolles .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15232 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography."@en ;
    askg-onto:inSentence "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automated_cartography,
        askg-data:Entity-image_analysis,
        askg-data:Entity-paradigm,
        askg-data:Entity-random_sample_consensus .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15233 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "Communications of the ACM, 24(6):381–395, 1981."@en ;
    askg-onto:inSentence "Communications of the ACM, 24(6):381–395, 1981."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-24,
        askg-data:Entity-381395,
        askg-data:Entity-6,
        askg-data:Entity-communications_of_the_acm .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15234 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "3, 6 [13] Denis Fortun, Patrick Bouthemy, and Charles Kervrann."@en ;
    askg-onto:inSentence "3, 6 [13] Denis Fortun, Patrick Bouthemy, and Charles Kervrann."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-charles_kervrann,
        askg-data:Entity-denis_fortun,
        askg-data:Entity-patrick_bouthemy .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15235 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Optical flow modeling and computation: A survey."@en ;
    askg-onto:inSentence "Optical flow modeling and computation: A survey."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-optical_flow_computation,
        askg-data:Entity-optical_flow_modeling,
        askg-data:Entity-optical_flow_modeling_and_computation,
        askg-data:Entity-paper,
        askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15236 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "*Computer* Vision and Image Understanding, 134:1–21, 2015."@en ;
    askg-onto:inSentence "*Computer* Vision and Image Understanding, 134:1–21, 2015."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-134121,
        askg-data:Entity-2015,
        askg-data:Entity-computer_vision_and_image_understanding,
        askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15237 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "2 [14] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun."@en ;
    askg-onto:inSentence "2 [14] Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-andreas_geiger,
        askg-data:Entity-christoph_stiller,
        askg-data:Entity-person,
        askg-data:Entity-philip_lenz,
        askg-data:Entity-raquel_urtasun .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15238 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "Vision meets robotics: The KITTI dataset."@en ;
    askg-onto:inSentence "Vision meets robotics: The KITTI dataset."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-kitti_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15239 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "The International Journal of Robotics Research, 32(11):1231– 1237, 2013."@en ;
    askg-onto:inSentence "The International Journal of Robotics Research, 32(11):1231– 1237, 2013."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11,
        askg-data:Entity-12311237,
        askg-data:Entity-32,
        askg-data:Entity-publication,
        askg-data:Entity-the_international_journal_of_robotics_research .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "2 [4] Jia-Wang Bian, Zhichao Li, Naiyan Wang, Huangying Zhan, Chunhua Shen, Ming-Ming Cheng, and Ian Reid."@en ;
    askg-onto:inSentence "2 [4] Jia-Wang Bian, Zhichao Li, Naiyan Wang, Huangying Zhan, Chunhua Shen, Ming-Ming Cheng, and Ian Reid."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chunhua_shen,
        askg-data:Entity-huangying_zhan,
        askg-data:Entity-ian_reid,
        askg-data:Entity-jia-wang_bian,
        askg-data:Entity-ming-ming_cheng,
        askg-data:Entity-naiyan_wang,
        askg-data:Entity-person,
        askg-data:Entity-zhichao_li .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15240 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "5 [15] Andreas Geiger, Philip Lenz, and Raquel Urtasun."@en ;
    askg-onto:inSentence "5 [15] Andreas Geiger, Philip Lenz, and Raquel Urtasun."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-andreas_geiger,
        askg-data:Entity-paper,
        askg-data:Entity-philip_lenz,
        askg-data:Entity-raquel_urtasun .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15241 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Are we ready for autonomous driving?"@en ;
    askg-onto:inSentence "Are we ready for autonomous driving?"^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-autonomous_driving,
        askg-data:Entity-unspecified_readiness_status .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15242 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "the KITTI vision benchmark suite."@en ;
    askg-onto:inSentence "the KITTI vision benchmark suite."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-kitti_vision_benchmark_suite .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15243 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "In *2012 IEEE Conference on Computer Vision and* Pattern Recognition, pages 3354–3361."@en ;
    askg-onto:inSentence "In *2012 IEEE Conference on Computer Vision and* Pattern Recognition, pages 3354–3361."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2012_ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15244 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "IEEE, 2012."@en ;
    askg-onto:inSentence "IEEE, 2012."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2012,
        askg-data:Entity-ieee .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15245 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "5 [16] Clement Godard, Oisin Mac Aodha, and Gabriel J Bros- ´ tow."@en ;
    askg-onto:inSentence "5 [16] Clement Godard, Oisin Mac Aodha, and Gabriel J Bros- ´ tow."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-clement_godard,
        askg-data:Entity-gabriel_j_bros-__tow,
        askg-data:Entity-oisin_mac_aodha,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15246 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "Unsupervised monocular depth estimation with leftright consistency."@en ;
    askg-onto:inSentence "Unsupervised monocular depth estimation with leftright consistency."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-left-right_consistency,
        askg-data:Entity-method,
        askg-data:Entity-unsupervised_monocular_depth_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15247 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 270–279, 2017."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 270–279, 2017."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-conference,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15248 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "5 [17] Ariel Gordon, Hanhan Li, Rico Jonschkowski, and Anelia Angelova."@en ;
    askg-onto:inSentence "5 [17] Ariel Gordon, Hanhan Li, Rico Jonschkowski, and Anelia Angelova."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anelia_angelova,
        askg-data:Entity-ariel_gordon,
        askg-data:Entity-author,
        askg-data:Entity-hanhan_li,
        askg-data:Entity-rico_jonschkowski .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15249 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "Depth from videos in the wild: Unsupervised monocular depth learning from unknown cameras."@en ;
    askg-onto:inSentence "Depth from videos in the wild: Unsupervised monocular depth learning from unknown cameras."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition,
        askg-data:Entity-depth_from_videos_in_the_wild,
        askg-data:Entity-method,
        askg-data:Entity-research_field,
        askg-data:Entity-unknown_cameras,
        askg-data:Entity-unsupervised_monocular_depth_learning .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Unsupervised scale-consistent depth and ego-motion learning from monocular video."@en ;
    askg-onto:inSentence "Unsupervised scale-consistent depth and ego-motion learning from monocular video."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-method,
        askg-data:Entity-monocular_video,
        askg-data:Entity-unsupervised_scale-consistent_depth_and_ego-motion_learning .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15250 a askg-onto:Sentence ;
    rdfs:label "Sentence 50"@en ;
    domo:Text "arXiv preprint arXiv:1904.04998, 2019."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1904.04998, 2019."^^xsd:string ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv190404998,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-paper,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15251 a askg-onto:Sentence ;
    rdfs:label "Sentence 51"@en ;
    domo:Text "7 [18] Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo."@en ;
    askg-onto:inSentence "7 [18] Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo."^^xsd:string ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anoop_cherian,
        askg-data:Entity-basura_fernando,
        askg-data:Entity-edison_guo,
        askg-data:Entity-person,
        askg-data:Entity-peter_anderson,
        askg-data:Entity-rodrigo_santa_cruz,
        askg-data:Entity-stephen_gould .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15252 a askg-onto:Sentence ;
    rdfs:label "Sentence 52"@en ;
    domo:Text "On differentiating parameterized argmin and argmax problems with application to bi-level optimization."@en ;
    askg-onto:inSentence "On differentiating parameterized argmin and argmax problems with application to bi-level optimization."^^xsd:string ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bi-level_optimization,
        askg-data:Entity-parameterized_argmin_and_argmax_problems .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15253 a askg-onto:Sentence ;
    rdfs:label "Sentence 53"@en ;
    domo:Text "arXiv preprint arXiv:1607.05447, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1607.05447, 2016."^^xsd:string ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-arxiv160705447,
        askg-data:Entity-arxiv_preprint_arxiv160705447,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-15254 a askg-onto:Sentence ;
    rdfs:label "Sentence 54"@en ;
    domo:Text "2, 4 [19] Stephen Gould, Richard Hartley, and Dylan Campbell."@en ;
    askg-onto:inSentence "2, 4 [19] Stephen Gould, Richard Hartley, and Dylan Campbell."^^xsd:string ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dylan_campbell,
        askg-data:Entity-person,
        askg-data:Entity-richard_hartley,
        askg-data:Entity-stephen_gould .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1526 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "*arXiv preprint arXiv:1908.10553*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1908.10553*, 2019."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv_preprint_arxiv190810553,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1527 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "7, 8 [5] Michael J Black and Allan D Jepson."@en ;
    askg-onto:inSentence "7, 8 [5] Michael J Black and Allan D Jepson."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-allan_d_jepson,
        askg-data:Entity-michael_j_black,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1528 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Estimating optical flow in segmented images using variable-order parametric models with local deformations."@en ;
    askg-onto:inSentence "Estimating optical flow in segmented images using variable-order parametric models with local deformations."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-estimating_optical_flow,
        askg-data:Entity-local_deformations,
        askg-data:Entity-optical_flow,
        askg-data:Entity-variable-order_parametric_models .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-152-Sentence-1529 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "*IEEE Transactions on Pattern* Analysis and Machine Intelligence, 18(10):972–986, 1996."@en ;
    askg-onto:inSentence "*IEEE Transactions on Pattern* Analysis and Machine Intelligence, 18(10):972–986, 1996."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Deep declarative networks: A new hope. *arXiv preprint* arXiv:1909.04866, 2019. 2 [20] Richard Hartley and Hongdong Li. An efficient hidden variable approach to minimal-case camera motion estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(12):2303–2314, 2012. 1, 3 [21] Richard Hartley and Andrew Zisserman. Multiple View Geometry in Computer Vision. Cambridge University Press, 2 edition, 2004. 1, 3 [22] Richard I Hartley and Robert Kaucic. Sensitivity of calibration to principal point position. In European Conference on Computer Vision, pages 433–446. Springer, 2002. 8 [23] Berthold KP Horn and Brian G Schunck. Determining optical flow. *Artificial intelligence*, 17(1-3):185–203, 1981. 1, 2 [24] Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, and Thomas Brox. Flownet 2.0: Evolution of optical flow estimation with deep networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2462–2470, 2017. 1, 2, 6 [25] J Yu Jason, Adam W Harley, and Konstantinos G Derpanis. Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness. In European Conference on Computer Vision Workshops, pages 3– 10. Springer, 2016. 1, 2, 6 [26] Suryansh Kumar, Yuchao Dai, and Hongdong Li. Monocular dense 3D reconstruction of a complex dynamic scene from two perspective frames. In Proceedings of the IEEE International Conference on Computer Vision, pages 4649–4657, 2017. 1 [27] Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto. Meta-learning with differentiable convex optimization. *arXiv preprint arXiv:1904.03758*, 2019. 2 [28] Hongdong Li and Richard Hartley. Five-point motion estimation made easy. In 18th International Conference on Pattern Recognition (ICPR'06), volume 1, pages 630–633. IEEE, 2006. 3, 6 [29] Pengpeng Liu, Irwin King, Michael R Lyu, and Jia Xu."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1531,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15310,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15311,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15312,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15313,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15314,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15315,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15316,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15317,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15318,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15319,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1532,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15320,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15321,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15322,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15323,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15324,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15325,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15326,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15327,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15328,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15329,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1533,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15330,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15331,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15332,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15333,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1534,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1535,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1536,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1537,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1538,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1539 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Deep declarative networks: A new hope."@en ;
    askg-onto:inSentence "Deep declarative networks: A new hope."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_declarative_networks,
        askg-data:Entity-model .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Sensitivity of calibration to principal point position."@en ;
    askg-onto:inSentence "Sensitivity of calibration to principal point position."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-calibration,
        askg-data:Entity-principal_point_position .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "In European Conference on Computer Vision, pages 433–446."@en ;
    askg-onto:inSentence "In European Conference on Computer Vision, pages 433–446."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Springer, 2002."@en ;
    askg-onto:inSentence "Springer, 2002."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "8 [23] Berthold KP Horn and Brian G Schunck."@en ;
    askg-onto:inSentence "8 [23] Berthold KP Horn and Brian G Schunck."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-berthold_kp_horn,
        askg-data:Entity-brian_g_schunck,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15314 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Determining optical flow."@en ;
    askg-onto:inSentence "Determining optical flow."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15315 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "*Artificial intelligence*, 17(1-3):185–203, 1981."@en ;
    askg-onto:inSentence "*Artificial intelligence*, 17(1-3):185–203, 1981."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1981,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-artificial_intelligence_171-3185203,
        askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15316 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "1, 2 [24] Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, and Thomas Brox."@en ;
    askg-onto:inSentence "1, 2 [24] Eddy Ilg, Nikolaus Mayer, Tonmoy Saikia, Margret Keuper, Alexey Dosovitskiy, and Thomas Brox."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alexey_dosovitskiy,
        askg-data:Entity-eddy_ilg,
        askg-data:Entity-margret_keuper,
        askg-data:Entity-nikolaus_mayer,
        askg-data:Entity-paper,
        askg-data:Entity-thomas_brox,
        askg-data:Entity-tonmoy_saikia .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15317 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Flownet 2.0: Evolution of optical flow estimation with deep networks."@en ;
    askg-onto:inSentence "Flownet 2.0: Evolution of optical flow estimation with deep networks."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flownet_20,
        askg-data:Entity-model .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15318 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2462–2470, 2017."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2462–2470, 2017."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15319 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "1, 2, 6 [25] J Yu Jason, Adam W Harley, and Konstantinos G Derpanis."@en ;
    askg-onto:inSentence "1, 2, 6 [25] J Yu Jason, Adam W Harley, and Konstantinos G Derpanis."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam_w_harley,
        askg-data:Entity-author,
        askg-data:Entity-j_yu_jason,
        askg-data:Entity-konstantinos_g_derpanis .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "*arXiv preprint* arXiv:1909.04866, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint* arXiv:1909.04866, 2019."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv190904866,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15320 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness."@en ;
    askg-onto:inSentence "Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brightness_constancy,
        askg-data:Entity-motion_smoothness,
        askg-data:Entity-optical_flow,
        askg-data:Entity-unsupervised_learning .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15321 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "In European Conference on Computer Vision Workshops, pages 3– 10."@en ;
    askg-onto:inSentence "In European Conference on Computer Vision Workshops, pages 3– 10."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15322 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Springer, 2016."@en ;
    askg-onto:inSentence "Springer, 2016."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15323 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "1, 2, 6 [26] Suryansh Kumar, Yuchao Dai, and Hongdong Li."@en ;
    askg-onto:inSentence "1, 2, 6 [26] Suryansh Kumar, Yuchao Dai, and Hongdong Li."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hongdong_li,
        askg-data:Entity-person,
        askg-data:Entity-suryansh_kumar,
        askg-data:Entity-yuchao_dai .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15324 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Monocular dense 3D reconstruction of a complex dynamic scene from two perspective frames."@en ;
    askg-onto:inSentence "Monocular dense 3D reconstruction of a complex dynamic scene from two perspective frames."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complex_dynamic_scene,
        askg-data:Entity-monocular_dense_3d_reconstruction .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15325 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "In Proceedings of the IEEE International Conference on Computer Vision, pages 4649–4657, 2017."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE International Conference on Computer Vision, pages 4649–4657, 2017."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings_of_the_ieee_international_conference_on_computer_vision .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15326 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "1 [27] Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto."@en ;
    askg-onto:inSentence "1 [27] Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-avinash_ravichandran,
        askg-data:Entity-kwonjoon_lee,
        askg-data:Entity-stefano_soatto,
        askg-data:Entity-subhransu_maji .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15327 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Meta-learning with differentiable convex optimization."@en ;
    askg-onto:inSentence "Meta-learning with differentiable convex optimization."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differentiable_convex_optimization,
        askg-data:Entity-meta-learning .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15328 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "*arXiv preprint arXiv:1904.03758*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1904.03758*, 2019."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv190403758,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15329 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "2 [28] Hongdong Li and Richard Hartley."@en ;
    askg-onto:inSentence "2 [28] Hongdong Li and Richard Hartley."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hongdong_li,
        askg-data:Entity-richard_hartley .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "2 [20] Richard Hartley and Hongdong Li."@en ;
    askg-onto:inSentence "2 [20] Richard Hartley and Hongdong Li."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hongdong_li,
        askg-data:Entity-person,
        askg-data:Entity-richard_hartley .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15330 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "Five-point motion estimation made easy."@en ;
    askg-onto:inSentence "Five-point motion estimation made easy."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-five-point_motion_estimation,
        askg-data:Entity-method .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15331 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "In 18th International Conference on Pattern Recognition (ICPR'06), volume 1, pages 630–633."@en ;
    askg-onto:inSentence "In 18th International Conference on Pattern Recognition (ICPR'06), volume 1, pages 630–633."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-volume_1_pages_630633 .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15332 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "IEEE, 2006."@en ;
    askg-onto:inSentence "IEEE, 2006."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2006,
        askg-data:Entity-ieee .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-15333 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "3, 6 [29] Pengpeng Liu, Irwin King, Michael R Lyu, and Jia Xu."@en ;
    askg-onto:inSentence "3, 6 [29] Pengpeng Liu, Irwin King, Michael R Lyu, and Jia Xu."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-irwin_king,
        askg-data:Entity-jia_xu,
        askg-data:Entity-michael_r_lyu,
        askg-data:Entity-pengpeng_liu .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "An efficient hidden variable approach to minimal-case camera motion estimation."@en ;
    askg-onto:inSentence "An efficient hidden variable approach to minimal-case camera motion estimation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion_estimation,
        askg-data:Entity-hidden_variable_approach,
        askg-data:Entity-method,
        askg-data:Entity-research_concept .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1535 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(12):2303–2314, 2012."@en ;
    askg-onto:inSentence "IEEE Transactions on Pattern Analysis and Machine Intelligence, 34(12):2303–2314, 2012."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2012,
        askg-data:Entity-23032314,
        askg-data:Entity-3412,
        askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1536 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "1, 3 [21] Richard Hartley and Andrew Zisserman."@en ;
    askg-onto:inSentence "1, 3 [21] Richard Hartley and Andrew Zisserman."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-andrew_zisserman,
        askg-data:Entity-richard_hartley .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1537 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Multiple View Geometry in Computer Vision."@en ;
    askg-onto:inSentence "Multiple View Geometry in Computer Vision."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision,
        askg-data:Entity-domain,
        askg-data:Entity-multiple_view_geometry,
        askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1538 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Cambridge University Press, 2 edition, 2004."@en ;
    askg-onto:inSentence "Cambridge University Press, 2 edition, 2004."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2004,
        askg-data:Entity-2_edition,
        askg-data:Entity-cambridge_university_press .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-153-Sentence-1539 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "1, 3 [22] Richard I Hartley and Robert Kaucic."@en ;
    askg-onto:inSentence "1, 3 [22] Richard I Hartley and Robert Kaucic."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-richard_i_hartley,
        askg-data:Entity-robert_kaucic .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Ddflow: Learning optical flow with unlabeled data distillation. *arXiv preprint arXiv:1902.09145*, 2019. 2, 5, 6 [30] Pengpeng Liu, Michael Lyu, Irwin King, and Jia Xu. Selflow: Self-supervised learning of optical flow. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4571–4580, 2019. 2, 4, 5, 6, 7 [31] Simon Meister, Junhwa Hur, and Stefan Roth. UnFlow: unsupervised learning of optical flow with a bidirectional census loss. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018. 2, 4, 6 [32] Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan D Tardos. Orb-slam: a versatile and accurate monocular slam system. *IEEE transactions on robotics*, 31(5):1147–1163, 2015. 7 [33] Manjunath Narayana, Allen Hanson, and Erik Learned- Miller. Coherent motion segmentation in moving camera videos using optical flow orientations. In Proceedings of the IEEE International Conference on Computer Vision, pages 1577–1584, 2013. 1 [34] David Nister. An efficient solution to the five-point relative ´ pose problem. *IEEE Transactions on Pattern Analysis and* Machine Intelligence, 26(6):0756–777, 2004. 3, 6 [35] Peter Ochs, Rene Ranftl, Thomas Brox, and Thomas Pock. ´ Bilevel optimization with nonsmooth lower level problems. In International Conference on Scale Space and Variational Methods in Computer Vision, pages 654–665. Springer, 2015. 4 [36] Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and Sergey Levine. Meta-learning with implicit gradients. arXiv preprint arXiv:1909.04630, 2019. 2 [37] Anurag Ranjan and Michael J Black. Optical flow estimation using a spatial pyramid network. In *Proceedings of the* IEEE Conference on Computer Vision and Pattern Recognition, pages 4161–4170, 2017. 6 [38] Zhe Ren, Junchi Yan, Bingbing Ni, Bin Liu, Xiaokang Yang, and Hongyuan Zha. Unsupervised deep learning for optical flow estimation. In Thirty-First AAAI Conference on Artificial Intelligence, 2017. 6 [39] Kegan GG Samuel and Marshall F Tappen. Learning optimized MAP estimates in continuously-valued MRF models. In Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 477–484. IEEE, 2009. 4 [40] Karen Simonyan and Andrew Zisserman. Two-stream convolutional networks for action recognition in videos. In Advances in Neural Information Processing Systems, pages 568–576, 2014. 1 [41] Fridtjof Stein. Efficient computation of optical flow using the census transform. In *Joint Pattern Recognition Symposium*, pages 79–86. Springer, 2004. 4 [42] Jurgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram ¨ Burgard, and Daniel Cremers. A benchmark for the evaluation of RGB-D SLAM systems. In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 573–580. IEEE, 2012. 5 [43] Deqing Sun, Stefan Roth, and Michael J Black. A quantitative analysis of current practices in optical flow estimation and the principles behind them. *International Journal of* Computer Vision, 106(2):115–137, 2014. 1, 5 [44] Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1541,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15410,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15411,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15412,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15413,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15414,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15415,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15416,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15417,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15418,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15419,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1542,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15420,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15421,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15422,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15423,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15424,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15425,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15426,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15427,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15428,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15429,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1543,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15430,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15431,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15432,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15433,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15434,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15435,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15436,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15437,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15438,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15439,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1544,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15440,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15441,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15442,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15443,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15444,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15445,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15446,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15447,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15448,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15449,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1545,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1546,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1547,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1548,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1549 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Ddflow: Learning optical flow with unlabeled data distillation."@en ;
    askg-onto:inSentence "Ddflow: Learning optical flow with unlabeled data distillation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ddflow,
        askg-data:Entity-optical_flow,
        askg-data:Entity-system,
        askg-data:Entity-unlabeled_data_distillation .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15410 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Orb-slam: a versatile and accurate monocular slam system."@en ;
    askg-onto:inSentence "Orb-slam: a versatile and accurate monocular slam system."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-monocular_slam_system,
        askg-data:Entity-orb-slam .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15411 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "*IEEE transactions on robotics*, 31(5):1147–1163, 2015."@en ;
    askg-onto:inSentence "*IEEE transactions on robotics*, 31(5):1147–1163, 2015."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_transactions_on_robotics,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15412 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "7 [33] Manjunath Narayana, Allen Hanson, and Erik Learned- Miller."@en ;
    askg-onto:inSentence "7 [33] Manjunath Narayana, Allen Hanson, and Erik Learned- Miller."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-allen_hanson,
        askg-data:Entity-author,
        askg-data:Entity-erik_learned-_miller,
        askg-data:Entity-manjunath_narayana .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15413 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Coherent motion segmentation in moving camera videos using optical flow orientations."@en ;
    askg-onto:inSentence "Coherent motion segmentation in moving camera videos using optical flow orientations."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coherent_motion_segmentation,
        askg-data:Entity-optical_flow_orientations .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15414 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "In Proceedings of the IEEE International Conference on Computer Vision, pages 1577–1584, 2013."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE International Conference on Computer Vision, pages 1577–1584, 2013."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15415 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "1 [34] David Nister."@en ;
    askg-onto:inSentence "1 [34] David Nister."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-david_nister,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15416 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "An efficient solution to the five-point relative ´ pose problem."@en ;
    askg-onto:inSentence "An efficient solution to the five-point relative ´ pose problem."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-five-point_relative_pose_problem,
        askg-data:Entity-method .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15417 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "*IEEE Transactions on Pattern Analysis and* Machine Intelligence, 26(6):0756–777, 2004."@en ;
    askg-onto:inSentence "*IEEE Transactions on Pattern Analysis and* Machine Intelligence, 26(6):0756–777, 2004."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-266,
        askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15418 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "3, 6 [35] Peter Ochs, Rene Ranftl, Thomas Brox, and Thomas Pock."@en ;
    askg-onto:inSentence "3, 6 [35] Peter Ochs, Rene Ranftl, Thomas Brox, and Thomas Pock."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-peter_ochs,
        askg-data:Entity-rene_ranftl,
        askg-data:Entity-thomas_brox,
        askg-data:Entity-thomas_pock .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15419 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "´ Bilevel optimization with nonsmooth lower level problems."@en ;
    askg-onto:inSentence "´ Bilevel optimization with nonsmooth lower level problems."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bilevel_optimization,
        askg-data:Entity-nonsmooth_lower_level_problems .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1542 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "*arXiv preprint arXiv:1902.09145*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1902.09145*, 2019."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv190209145,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15420 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "In International Conference on Scale Space and Variational Methods in Computer Vision, pages 654–665."@en ;
    askg-onto:inSentence "In International Conference on Scale Space and Variational Methods in Computer Vision, pages 654–665."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-international_conference_on_scale_space_and_variational_methods_in_computer_vision,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15421 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Springer, 2015."@en ;
    askg-onto:inSentence "Springer, 2015."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15422 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "4 [36] Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and Sergey Levine."@en ;
    askg-onto:inSentence "4 [36] Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and Sergey Levine."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aravind_rajeswaran,
        askg-data:Entity-chelsea_finn,
        askg-data:Entity-person,
        askg-data:Entity-sergey_levine,
        askg-data:Entity-sham_kakade .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15423 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Meta-learning with implicit gradients."@en ;
    askg-onto:inSentence "Meta-learning with implicit gradients."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-implicit_gradients,
        askg-data:Entity-meta-learning,
        askg-data:Entity-method .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15424 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "arXiv preprint arXiv:1909.04630, 2019."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1909.04630, 2019."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv190904630,
        askg-data:Entity-arxiv_preprint_arxiv190904630,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15425 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "2 [37] Anurag Ranjan and Michael J Black."@en ;
    askg-onto:inSentence "2 [37] Anurag Ranjan and Michael J Black."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anurag_ranjan,
        askg-data:Entity-michael_j_black .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15426 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Optical flow estimation using a spatial pyramid network."@en ;
    askg-onto:inSentence "Optical flow estimation using a spatial pyramid network."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-spatial_pyramid_network .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15427 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "In *Proceedings of the* IEEE Conference on Computer Vision and Pattern Recognition, pages 4161–4170, 2017."@en ;
    askg-onto:inSentence "In *Proceedings of the* IEEE Conference on Computer Vision and Pattern Recognition, pages 4161–4170, 2017."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-conference,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15428 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "6 [38] Zhe Ren, Junchi Yan, Bingbing Ni, Bin Liu, Xiaokang Yang, and Hongyuan Zha."@en ;
    askg-onto:inSentence "6 [38] Zhe Ren, Junchi Yan, Bingbing Ni, Bin Liu, Xiaokang Yang, and Hongyuan Zha."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bin_liu,
        askg-data:Entity-bingbing_ni,
        askg-data:Entity-hongyuan_zha,
        askg-data:Entity-junchi_yan,
        askg-data:Entity-xiaokang_yang,
        askg-data:Entity-zhe_ren .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15429 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Unsupervised deep learning for optical flow estimation."@en ;
    askg-onto:inSentence "Unsupervised deep learning for optical flow estimation."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-unsupervised_deep_learning .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1543 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "2, 5, 6 [30] Pengpeng Liu, Michael Lyu, Irwin King, and Jia Xu."@en ;
    askg-onto:inSentence "2, 5, 6 [30] Pengpeng Liu, Michael Lyu, Irwin King, and Jia Xu."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-irwin_king,
        askg-data:Entity-jia_xu,
        askg-data:Entity-michael_lyu,
        askg-data:Entity-pengpeng_liu,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15430 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "In Thirty-First AAAI Conference on Artificial Intelligence, 2017."@en ;
    askg-onto:inSentence "In Thirty-First AAAI Conference on Artificial Intelligence, 2017."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper,
        askg-data:Entity-thirty-first_aaai_conference_on_artificial_intelligence .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15431 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "6 [39] Kegan GG Samuel and Marshall F Tappen."@en ;
    askg-onto:inSentence "6 [39] Kegan GG Samuel and Marshall F Tappen."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kegan_gg_samuel,
        askg-data:Entity-marshall_f_tappen,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15432 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "Learning optimized MAP estimates in continuously-valued MRF models."@en ;
    askg-onto:inSentence "Learning optimized MAP estimates in continuously-valued MRF models."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-map_estimates,
        askg-data:Entity-mrf_models .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15433 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "In Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 477–484."@en ;
    askg-onto:inSentence "In Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 477–484."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2009_ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-proceedings .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15434 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "IEEE, 2009."@en ;
    askg-onto:inSentence "IEEE, 2009."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2009,
        askg-data:Entity-ieee .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15435 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "4 [40] Karen Simonyan and Andrew Zisserman."@en ;
    askg-onto:inSentence "4 [40] Karen Simonyan and Andrew Zisserman."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-andrew_zisserman,
        askg-data:Entity-karen_simonyan,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15436 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "Two-stream convolutional networks for action recognition in videos."@en ;
    askg-onto:inSentence "Two-stream convolutional networks for action recognition in videos."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_recognition_in_videos,
        askg-data:Entity-two-stream_convolutional_networks .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15437 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pages 568–576, 2014."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pages 568–576, 2014."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-568576,
        askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15438 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "1 [41] Fridtjof Stein."@en ;
    askg-onto:inSentence "1 [41] Fridtjof Stein."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fridtjof_stein,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15439 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "Efficient computation of optical flow using the census transform."@en ;
    askg-onto:inSentence "Efficient computation of optical flow using the census transform."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-census_transform,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1544 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Selflow: Self-supervised learning of optical flow."@en ;
    askg-onto:inSentence "Selflow: Self-supervised learning of optical flow."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-self-supervised_learning_of_optical_flow,
        askg-data:Entity-selflow .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15440 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "In *Joint Pattern Recognition Symposium*, pages 79–86."@en ;
    askg-onto:inSentence "In *Joint Pattern Recognition Symposium*, pages 79–86."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-joint_pattern_recognition_symposium,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15441 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Springer, 2004."@en ;
    askg-onto:inSentence "Springer, 2004."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2004,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15442 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "4 [42] Jurgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram ¨ Burgard, and Daniel Cremers."@en ;
    askg-onto:inSentence "4 [42] Jurgen Sturm, Nikolas Engelhard, Felix Endres, Wolfram ¨ Burgard, and Daniel Cremers."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-daniel_cremers,
        askg-data:Entity-felix_endres,
        askg-data:Entity-jurgen_sturm,
        askg-data:Entity-nikolas_engelhard,
        askg-data:Entity-person,
        askg-data:Entity-wolfram_burgard .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15443 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "A benchmark for the evaluation of RGB-D SLAM systems."@en ;
    askg-onto:inSentence "A benchmark for the evaluation of RGB-D SLAM systems."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-benchmark,
        askg-data:Entity-rgb-d_slam_systems .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15444 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 573–580."@en ;
    askg-onto:inSentence "In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pages 573–580."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15445 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "IEEE, 2012."@en ;
    askg-onto:inSentence "IEEE, 2012."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2012,
        askg-data:Entity-ieee .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15446 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "5 [43] Deqing Sun, Stefan Roth, and Michael J Black."@en ;
    askg-onto:inSentence "5 [43] Deqing Sun, Stefan Roth, and Michael J Black."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-deqing_sun,
        askg-data:Entity-michael_j_black,
        askg-data:Entity-stefan_roth .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15447 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "A quantitative analysis of current practices in optical flow estimation and the principles behind them."@en ;
    askg-onto:inSentence "A quantitative analysis of current practices in optical flow estimation and the principles behind them."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_practices,
        askg-data:Entity-method,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-principles .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15448 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "*International Journal of* Computer Vision, 106(2):115–137, 2014."@en ;
    askg-onto:inSentence "*International Journal of* Computer Vision, 106(2):115–137, 2014."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-international_journal_of_computer_vision,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-15449 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "1, 5 [44] Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz."@en ;
    askg-onto:inSentence "1, 5 [44] Deqing Sun, Xiaodong Yang, Ming-Yu Liu, and Jan Kautz."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deqing_sun,
        askg-data:Entity-jan_kautz,
        askg-data:Entity-ming-yu_liu,
        askg-data:Entity-person,
        askg-data:Entity-xiaodong_yang .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1545 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4571–4580, 2019."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4571–4580, 2019."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-paper,
        askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1546 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "2, 4, 5, 6, 7 [31] Simon Meister, Junhwa Hur, and Stefan Roth."@en ;
    askg-onto:inSentence "2, 4, 5, 6, 7 [31] Simon Meister, Junhwa Hur, and Stefan Roth."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-junhwa_hur,
        askg-data:Entity-person,
        askg-data:Entity-simon_meister,
        askg-data:Entity-stefan_roth .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1547 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "UnFlow: unsupervised learning of optical flow with a bidirectional census loss."@en ;
    askg-onto:inSentence "UnFlow: unsupervised learning of optical flow with a bidirectional census loss."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bidirectional_census_loss,
        askg-data:Entity-model,
        askg-data:Entity-unflow .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1548 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In Thirty-Second AAAI Conference on Artificial Intelligence, 2018."@en ;
    askg-onto:inSentence "In Thirty-Second AAAI Conference on Artificial Intelligence, 2018."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper,
        askg-data:Entity-thirty-second_aaai_conference_on_artificial_intelligence .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-154-Sentence-1549 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "2, 4, 6 [32] Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan D Tardos."@en ;
    askg-onto:inSentence "2, 4, 6 [32] Raul Mur-Artal, Jose Maria Martinez Montiel, and Juan D Tardos."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jose_maria_martinez_montiel,
        askg-data:Entity-juan_d_tardos,
        askg-data:Entity-paper,
        askg-data:Entity-raul_mur-artal .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "PWC-Net: CNNs for optical flow using pyramid, warping, and cost volume. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8934– 8943, 2018. 1, 2, 6 [45] Levi Valgaerts, Andres Bruhn, and Joachim Weickert. A ´ variational model for the joint recovery of the fundamental matrix and the optical flow. In Joint Pattern Recognition Symposium, pages 314–324. Springer, 2008. 2 [46] Yang Wang, Yi Yang, Zhenheng Yang, Liang Zhao, Peng Wang, and Wei Xu. Occlusion aware unsupervised learning of optical flow. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4884– 4893, 2018. 2, 6 [47] Joseph Weber and Jitendra Malik. Rigid body segmentation and shape description from dense optical flow under weak perspective. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(2):139–143, 1997. 2 [48] Jonas Wulff, Laura Sevilla-Lara, and Michael J Black. Optical flow in mostly rigid scenes. In *Proceedings of the IEEE* Conference on Computer Vision and Pattern Recognition, pages 4671–4680, 2017. 1 [49] Jiangjian Xiao, Hui Cheng, Harpreet Sawhney, Cen Rao, and Michael Isnardi. Bilateral filtering-based optical flow estimation with occlusion detection. In *European Conference* on Computer Vision, pages 211–224. Springer, 2006. 1 [50] Gang Xu and Zhengyou Zhang. Epipolar geometry in stereo, motion and object recognition: a unified approach, volume 6. Springer Science & Business Media, 2013. 2 [51] Koichiro Yamaguchi, David McAllester, and Raquel Urtasun. Robust monocular epipolar flow estimation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1862–1869, 2013. 2 [52] Zhichao Yin and Jianping Shi. Geonet: Unsupervised learning of dense depth, optical flow and camera pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1983–1992, 2018. 2 [53] Ramin Zabih and John Woodfill. Non-parametric local transforms for computing visual correspondence. In European Conference on Computer Vision, pages 151–158. Springer, 1994. 4 [54] Huangying Zhan, Ravi Garg, Chamara Saroj Weerasekera, Kejie Li, Harsh Agarwal, and Ian Reid. Unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 340–349, 2018. 7, 8 [55] Yiran Zhong, Pan Ji, Jianyuan Wang, Yuchao Dai, and Hongdong Li. Unsupervised deep epipolar flow for stationary or dynamic scenes. *arXiv preprint arXiv:1904.03848*, 2019. 1, 2, 6 [56] Qunjie Zhou, Torsten Sattler, Marc Pollefeys, and Laura Leal-Taixe. To learn or not to learn: Visual localization from essential matrices. *arXiv preprint arXiv:1908.01293*, 2019. 2 [57] Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe. Unsupervised learning of depth and ego-motion from video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1851–1858, 2017. 2, 7, 8 [58] Yuliang Zou, Zelun Luo, and Jia-Bin Huang. DF-Net: unsupervised joint learning of depth and flow using cross-task consistency. In Proceedings of the European Conference on Computer Vision, pages 36–53, 2018. 2, 6"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1551,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15510,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15511,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15512,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15513,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15514,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15515,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15516,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15517,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15518,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15519,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1552,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15520,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15521,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15522,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15523,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15524,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15525,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15526,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15527,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15528,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15529,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1553,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15530,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15531,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15532,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15533,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15534,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15535,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15536,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15537,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15538,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15539,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1554,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15540,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15541,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15542,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15543,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15544,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15545,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15546,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15547,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15548,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1555,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1556,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1557,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1558,
        askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1559 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "PWC-Net: CNNs for optical flow using pyramid, warping, and cost volume."@en ;
    askg-onto:inSentence "PWC-Net: CNNs for optical flow using pyramid, warping, and cost volume."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn_model,
        askg-data:Entity-cost_volume,
        askg-data:Entity-optical_flow,
        askg-data:Entity-pwc-net,
        askg-data:Entity-pyramid,
        askg-data:Entity-warping .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15510 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "2, 6 [47] Joseph Weber and Jitendra Malik."@en ;
    askg-onto:inSentence "2, 6 [47] Joseph Weber and Jitendra Malik."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jitendra_malik,
        askg-data:Entity-joseph_weber .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15511 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Rigid body segmentation and shape description from dense optical flow under weak perspective."@en ;
    askg-onto:inSentence "Rigid body segmentation and shape description from dense optical flow under weak perspective."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-condition,
        askg-data:Entity-dense_optical_flow,
        askg-data:Entity-method,
        askg-data:Entity-rigid_body_segmentation,
        askg-data:Entity-weak_perspective .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15512 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(2):139–143, 1997."@en ;
    askg-onto:inSentence "IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(2):139–143, 1997."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-139143,
        askg-data:Entity-19,
        askg-data:Entity-2,
        askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15513 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "2 [48] Jonas Wulff, Laura Sevilla-Lara, and Michael J Black."@en ;
    askg-onto:inSentence "2 [48] Jonas Wulff, Laura Sevilla-Lara, and Michael J Black."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jonas_wulff,
        askg-data:Entity-laura_sevilla-lara,
        askg-data:Entity-michael_j_black,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15514 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Optical flow in mostly rigid scenes."@en ;
    askg-onto:inSentence "Optical flow in mostly rigid scenes."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow,
        askg-data:Entity-rigid_scenes .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15515 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "In *Proceedings of the IEEE* Conference on Computer Vision and Pattern Recognition, pages 4671–4680, 2017."@en ;
    askg-onto:inSentence "In *Proceedings of the IEEE* Conference on Computer Vision and Pattern Recognition, pages 4671–4680, 2017."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15516 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "1 [49] Jiangjian Xiao, Hui Cheng, Harpreet Sawhney, Cen Rao, and Michael Isnardi."@en ;
    askg-onto:inSentence "1 [49] Jiangjian Xiao, Hui Cheng, Harpreet Sawhney, Cen Rao, and Michael Isnardi."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cen_rao,
        askg-data:Entity-harpreet_sawhney,
        askg-data:Entity-hui_cheng,
        askg-data:Entity-jiangjian_xiao,
        askg-data:Entity-michael_isnardi,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15517 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Bilateral filtering-based optical flow estimation with occlusion detection."@en ;
    askg-onto:inSentence "Bilateral filtering-based optical flow estimation with occlusion detection."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bilateral_filtering,
        askg-data:Entity-bilateral_filtering-based_optical_flow_estimation,
        askg-data:Entity-occlusion_detection,
        askg-data:Entity-optical_flow_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15518 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "In *European Conference* on Computer Vision, pages 211–224."@en ;
    askg-onto:inSentence "In *European Conference* on Computer Vision, pages 211–224."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15519 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Springer, 2006."@en ;
    askg-onto:inSentence "Springer, 2006."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2006,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8934– 8943, 2018."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8934– 8943, 2018."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-89348943,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15520 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "1 [50] Gang Xu and Zhengyou Zhang."@en ;
    askg-onto:inSentence "1 [50] Gang Xu and Zhengyou Zhang."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-gang_xu,
        askg-data:Entity-zhengyou_zhang .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15521 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Epipolar geometry in stereo, motion and object recognition: a unified approach, volume 6."@en ;
    askg-onto:inSentence "Epipolar geometry in stereo, motion and object recognition: a unified approach, volume 6."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_unified_approach,
        askg-data:Entity-epipolar_geometry,
        askg-data:Entity-stereo_motion_and_object_recognition,
        askg-data:Entity-volume_6 .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15522 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Springer Science & Business Media, 2013."@en ;
    askg-onto:inSentence "Springer Science & Business Media, 2013."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2013,
        askg-data:Entity-springer_science__business_media .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15523 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "2 [51] Koichiro Yamaguchi, David McAllester, and Raquel Urtasun."@en ;
    askg-onto:inSentence "2 [51] Koichiro Yamaguchi, David McAllester, and Raquel Urtasun."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-david_mcallester,
        askg-data:Entity-koichiro_yamaguchi,
        askg-data:Entity-person,
        askg-data:Entity-raquel_urtasun .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15524 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Robust monocular epipolar flow estimation."@en ;
    askg-onto:inSentence "Robust monocular epipolar flow estimation."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-monocular_epipolar_flow_estimation,
        askg-data:Entity-research_field,
        askg-data:Entity-robust_monocular_epipolar_flow_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15525 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1862–1869, 2013."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1862–1869, 2013."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15526 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "2 [52] Zhichao Yin and Jianping Shi."@en ;
    askg-onto:inSentence "2 [52] Zhichao Yin and Jianping Shi."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-jianping_shi,
        askg-data:Entity-zhichao_yin .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15527 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Geonet: Unsupervised learning of dense depth, optical flow and camera pose."@en ;
    askg-onto:inSentence "Geonet: Unsupervised learning of dense depth, optical flow and camera pose."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geonet,
        askg-data:Entity-system,
        askg-data:Entity-unsupervised_learning_of_dense_depth_optical_flow_and_camera_pose .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15528 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1983–1992, 2018."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1983–1992, 2018."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-conference,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication,
        askg-data:Entity-year .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15529 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "2 [53] Ramin Zabih and John Woodfill."@en ;
    askg-onto:inSentence "2 [53] Ramin Zabih and John Woodfill."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-john_woodfill,
        askg-data:Entity-ramin_zabih .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1553 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "1, 2, 6 [45] Levi Valgaerts, Andres Bruhn, and Joachim Weickert."@en ;
    askg-onto:inSentence "1, 2, 6 [45] Levi Valgaerts, Andres Bruhn, and Joachim Weickert."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-andres_bruhn,
        askg-data:Entity-joachim_weickert,
        askg-data:Entity-levi_valgaerts,
        askg-data:Entity-person .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15530 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "Non-parametric local transforms for computing visual correspondence."@en ;
    askg-onto:inSentence "Non-parametric local transforms for computing visual correspondence."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computing_visual_correspondence,
        askg-data:Entity-non-parametric_local_transforms .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15531 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "In European Conference on Computer Vision, pages 151–158."@en ;
    askg-onto:inSentence "In European Conference on Computer Vision, pages 151–158."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-151158,
        askg-data:Entity-conference,
        askg-data:Entity-european_conference_on_computer_vision .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15532 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "Springer, 1994."@en ;
    askg-onto:inSentence "Springer, 1994."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1994,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15533 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "4 [54] Huangying Zhan, Ravi Garg, Chamara Saroj Weerasekera, Kejie Li, Harsh Agarwal, and Ian Reid."@en ;
    askg-onto:inSentence "4 [54] Huangying Zhan, Ravi Garg, Chamara Saroj Weerasekera, Kejie Li, Harsh Agarwal, and Ian Reid."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chamara_saroj_weerasekera,
        askg-data:Entity-harsh_agarwal,
        askg-data:Entity-huangying_zhan,
        askg-data:Entity-ian_reid,
        askg-data:Entity-kejie_li,
        askg-data:Entity-person,
        askg-data:Entity-ravi_garg .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15534 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "Unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction."@en ;
    askg-onto:inSentence "Unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_feature_reconstruction,
        askg-data:Entity-monocular_depth_estimation,
        askg-data:Entity-unsupervised_learning,
        askg-data:Entity-visual_odometry .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15535 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 340–349, 2018."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 340–349, 2018."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15536 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "7, 8 [55] Yiran Zhong, Pan Ji, Jianyuan Wang, Yuchao Dai, and Hongdong Li."@en ;
    askg-onto:inSentence "7, 8 [55] Yiran Zhong, Pan Ji, Jianyuan Wang, Yuchao Dai, and Hongdong Li."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hongdong_li,
        askg-data:Entity-jianyuan_wang,
        askg-data:Entity-pan_ji,
        askg-data:Entity-paper,
        askg-data:Entity-yiran_zhong,
        askg-data:Entity-yuchao_dai .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15537 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "Unsupervised deep epipolar flow for stationary or dynamic scenes."@en ;
    askg-onto:inSentence "Unsupervised deep epipolar flow for stationary or dynamic scenes."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-unsupervised_deep_epipolar_flow .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15538 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "*arXiv preprint arXiv:1904.03848*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1904.03848*, 2019."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv,
        askg-data:Entity-arxiv190403848,
        askg-data:Entity-arxiv_preprint_arxiv190403848,
        askg-data:Entity-paper,
        askg-data:Entity-platform,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15539 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "1, 2, 6 [56] Qunjie Zhou, Torsten Sattler, Marc Pollefeys, and Laura Leal-Taixe."@en ;
    askg-onto:inSentence "1, 2, 6 [56] Qunjie Zhou, Torsten Sattler, Marc Pollefeys, and Laura Leal-Taixe."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-laura_leal-taixe,
        askg-data:Entity-marc_pollefeys,
        askg-data:Entity-person,
        askg-data:Entity-qunjie_zhou,
        askg-data:Entity-torsten_sattler .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1554 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "A ´ variational model for the joint recovery of the fundamental matrix and the optical flow."@en ;
    askg-onto:inSentence "A ´ variational model for the joint recovery of the fundamental matrix and the optical flow."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-joint_recovery_of_the_fundamental_matrix_and_the_optical_flow,
        askg-data:Entity-variational_model .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15540 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "To learn or not to learn: Visual localization from essential matrices."@en ;
    askg-onto:inSentence "To learn or not to learn: Visual localization from essential matrices."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-essential_matrices,
        askg-data:Entity-method,
        askg-data:Entity-visual_localization .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15541 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "*arXiv preprint arXiv:1908.01293*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1908.01293*, 2019."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv190801293,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15542 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "2 [57] Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe."@en ;
    askg-onto:inSentence "2 [57] Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-david_g_lowe,
        askg-data:Entity-matthew_brown,
        askg-data:Entity-noah_snavely,
        askg-data:Entity-tinghui_zhou .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15543 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "Unsupervised learning of depth and ego-motion from video."@en ;
    askg-onto:inSentence "Unsupervised learning of depth and ego-motion from video."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-depth_and_ego-motion,
        askg-data:Entity-method,
        askg-data:Entity-research_field,
        askg-data:Entity-unsupervised_learning,
        askg-data:Entity-video .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15544 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1851–1858, 2017."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1851–1858, 2017."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15545 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "2, 7, 8 [58] Yuliang Zou, Zelun Luo, and Jia-Bin Huang."@en ;
    askg-onto:inSentence "2, 7, 8 [58] Yuliang Zou, Zelun Luo, and Jia-Bin Huang."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jia-bin_huang,
        askg-data:Entity-person,
        askg-data:Entity-yuliang_zou,
        askg-data:Entity-zelun_luo .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15546 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "DF-Net: unsupervised joint learning of depth and flow using cross-task consistency."@en ;
    askg-onto:inSentence "DF-Net: unsupervised joint learning of depth and flow using cross-task consistency."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-df-net,
        askg-data:Entity-joint_learning_of_depth_and_flow,
        askg-data:Entity-model .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15547 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "In Proceedings of the European Conference on Computer Vision, pages 36–53, 2018."@en ;
    askg-onto:inSentence "In Proceedings of the European Conference on Computer Vision, pages 36–53, 2018."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-conference,
        askg-data:Entity-european_conference_on_computer_vision,
        askg-data:Entity-proceedings_of_the_european_conference_on_computer_vision,
        askg-data:Entity-publication .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-15548 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "2, 6"@en ;
    askg-onto:inSentence "2, 6"^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2,
        askg-data:Entity-6,
        askg-data:Entity-finding .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1555 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In Joint Pattern Recognition Symposium, pages 314–324."@en ;
    askg-onto:inSentence "In Joint Pattern Recognition Symposium, pages 314–324."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-joint_pattern_recognition_symposium,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1556 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Springer, 2008."@en ;
    askg-onto:inSentence "Springer, 2008."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2008,
        askg-data:Entity-springer .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1557 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "2 [46] Yang Wang, Yi Yang, Zhenheng Yang, Liang Zhao, Peng Wang, and Wei Xu."@en ;
    askg-onto:inSentence "2 [46] Yang Wang, Yi Yang, Zhenheng Yang, Liang Zhao, Peng Wang, and Wei Xu."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-liang_zhao,
        askg-data:Entity-peng_wang,
        askg-data:Entity-person,
        askg-data:Entity-wei_xu,
        askg-data:Entity-yang_wang,
        askg-data:Entity-yi_yang,
        askg-data:Entity-zhenheng_yang .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1558 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Occlusion aware unsupervised learning of optical flow."@en ;
    askg-onto:inSentence "Occlusion aware unsupervised learning of optical flow."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-occlusion_aware_unsupervised_learning,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-15-Paragraph-155-Sentence-1559 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4884– 4893, 2018."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4884– 4893, 2018."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings,
        askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition .

askg-data:Paper-8e2bc199f9f80305-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "Abstract"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We address the problem of joint optical flow and camera motion estimation in rigid scenes by incorporating geometric constraints into an unsupervised deep learning framework. Unlike existing approaches which rely on brightness constancy and local smoothness for optical flow estimation, we exploit the global relationship between optical flow and camera motion using epipolar geometry. In particular, we formulate the prediction of optical flow and camera motion as a bi-level optimization problem, consisting of an upper-level problem to estimate the flow that conforms to the predicted camera motion, and a lower-level problem to estimate the camera motion given the predicted optical flow. We use implicit differentiation to enable backpropagation through the lower-level geometric optimization layer independent of its implementation, allowing end-toend training of the network. With globally-enforced geometric constraints, we are able to improve the quality of the estimated optical flow in challenging scenarios, and obtain better camera motion estimates compared to other unsupervised learning methods."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-211,
        askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-212,
        askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-213,
        askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-214,
        askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-215 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We address the problem of joint optical flow and camera motion estimation in rigid scenes by incorporating geometric constraints into an unsupervised deep learning framework."@en ;
    askg-onto:inSentence "We address the problem of joint optical flow and camera motion estimation in rigid scenes by incorporating geometric constraints into an unsupervised deep learning framework."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometric_constraints,
        askg-data:Entity-joint_optical_flow_and_camera_motion_estimation,
        askg-data:Entity-problem,
        askg-data:Entity-unsupervised_deep_learning_framework .

askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Unlike existing approaches which rely on brightness constancy and local smoothness for optical flow estimation, we exploit the global relationship between optical flow and camera motion using epipolar geometry."@en ;
    askg-onto:inSentence "Unlike existing approaches which rely on brightness constancy and local smoothness for optical flow estimation, we exploit the global relationship between optical flow and camera motion using epipolar geometry."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brightness_constancy,
        askg-data:Entity-camera_motion,
        askg-data:Entity-epipolar_geometry,
        askg-data:Entity-local_smoothness,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In particular, we formulate the prediction of optical flow and camera motion as a bi-level optimization problem, consisting of an upper-level problem to estimate the flow that conforms to the predicted camera motion, and a lower-level problem to estimate the camera motion given the predicted optical flow."@en ;
    askg-onto:inSentence "In particular, we formulate the prediction of optical flow and camera motion as a bi-level optimization problem, consisting of an upper-level problem to estimate the flow that conforms to the predicted camera motion, and a lower-level problem to estimate the camera motion given the predicted optical flow."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-lower-level_problem,
        askg-data:Entity-optical_flow,
        askg-data:Entity-upper-level_problem .

askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We use implicit differentiation to enable backpropagation through the lower-level geometric optimization layer independent of its implementation, allowing end-toend training of the network."@en ;
    askg-onto:inSentence "We use implicit differentiation to enable backpropagation through the lower-level geometric optimization layer independent of its implementation, allowing end-toend training of the network."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backpropagation,
        askg-data:Entity-end-to-end_training,
        askg-data:Entity-geometric_optimization_layer,
        askg-data:Entity-implicit_differentiation,
        askg-data:Entity-network .

askg-data:Paper-8e2bc199f9f80305-Section-2-Paragraph-21-Sentence-215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "With globally-enforced geometric constraints, we are able to improve the quality of the estimated optical flow in challenging scenarios, and obtain better camera motion estimates compared to other unsupervised learning methods."@en ;
    askg-onto:inSentence "With globally-enforced geometric constraints, we are able to improve the quality of the estimated optical flow in challenging scenarios, and obtain better camera motion estimates compared to other unsupervised learning methods."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion_estimates,
        askg-data:Entity-optical_flow,
        askg-data:Entity-other_methods,
        askg-data:Entity-unsupervised_learning_methods .

askg-data:Paper-8e2bc199f9f80305-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "1. Introduction"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35 ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Dense optical flow estimation is a fundamental problem in computer vision for determining the apparent motion of pixels in an image as the camera and scene moves. It has broad applications in action recognition [40], 3D reconstruction [26], and motion segmentation [33]. The seminal work by Horn and Schunck [23] sets the foundation for solving optical flow estimation problems by enforcing brightness constancy and local smoothness constraints in a variational setting. In the last few decades, the quality of optical flow estimation has improved dramatically with the introduction of ideas such as piece-wise smoothness [5], coarse-to-fine refinement for large displacements [7], and layered formulations for handling occlusions [49]."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-311,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-312,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-313,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-314 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Dense optical flow estimation is a fundamental problem in computer vision for determining the apparent motion of pixels in an image as the camera and scene moves."@en ;
    askg-onto:inSentence "Dense optical flow estimation is a fundamental problem in computer vision for determining the apparent motion of pixels in an image as the camera and scene moves."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-apparent_motion_of_pixels,
        askg-data:Entity-computer_vision,
        askg-data:Entity-dense_optical_flow_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It has broad applications in action recognition [40], 3D reconstruction [26], and motion segmentation [33]."@en ;
    askg-onto:inSentence "It has broad applications in action recognition [40], 3D reconstruction [26], and motion segmentation [33]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_reconstruction,
        askg-data:Entity-action_recognition,
        askg-data:Entity-motion_segmentation .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The seminal work by Horn and Schunck [23] sets the foundation for solving optical flow estimation problems by enforcing brightness constancy and local smoothness constraints in a variational setting."@en ;
    askg-onto:inSentence "The seminal work by Horn and Schunck [23] sets the foundation for solving optical flow estimation problems by enforcing brightness constancy and local smoothness constraints in a variational setting."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brightness_constancy_and_local_smoothness_constraints,
        askg-data:Entity-horn_and_schunck,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-problems,
        askg-data:Entity-seminal_work,
        askg-data:Entity-variational_setting .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-31-Sentence-314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In the last few decades, the quality of optical flow estimation has improved dramatically with the introduction of ideas such as piece-wise smoothness [5], coarse-to-fine refinement for large displacements [7], and layered formulations for handling occlusions [49]."@en ;
    askg-onto:inSentence "In the last few decades, the quality of optical flow estimation has improved dramatically with the introduction of ideas such as piece-wise smoothness [5], coarse-to-fine refinement for large displacements [7], and layered formulations for handling occlusions [49]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coarse-to-fine_refinement,
        askg-data:Entity-handling_occlusions,
        askg-data:Entity-large_displacements,
        askg-data:Entity-layered_formulations,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-piece-wise_smoothness,
        askg-data:Entity-quality .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Like many problems in computer vision, approaches based on the supervised learning of convolutional neural networks (CNNs) now achieve the state-of-the-art results 1 for optical flow estimation [10, 24, 44]. However, the difficulty of obtaining large volumes of ground-truth optical flow limits the applicability of these approaches in many scenarios. Unsupervised learning approaches are a promising alternative, which encode brightness constancy and local smoothness constraints in a loss function for training deep networks [25]. While such constraints perform well in feature-rich regions, they often fail on challenging scenes with featureless or repetitively-textured regions."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-321,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-322,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-323,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-324 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Like many problems in computer vision, approaches based on the supervised learning of convolutional neural networks (CNNs) now achieve the state-of-the-art results 1 for optical flow estimation [10, 24, 44]."@en ;
    askg-onto:inSentence "Like many problems in computer vision, approaches based on the supervised learning of convolutional neural networks (CNNs) now achieve the state-of-the-art results 1 for optical flow estimation [10, 24, 44]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_neural_networks_cnns,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-problem_in_computer_vision,
        askg-data:Entity-state-of-the-art_results .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, the difficulty of obtaining large volumes of ground-truth optical flow limits the applicability of these approaches in many scenarios."@en ;
    askg-onto:inSentence "However, the difficulty of obtaining large volumes of ground-truth optical flow limits the applicability of these approaches in many scenarios."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-large_volumes_of_ground-truth,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Unsupervised learning approaches are a promising alternative, which encode brightness constancy and local smoothness constraints in a loss function for training deep networks [25]."@en ;
    askg-onto:inSentence "Unsupervised learning approaches are a promising alternative, which encode brightness constancy and local smoothness constraints in a loss function for training deep networks [25]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_loss_function,
        askg-data:Entity-a_promising_alternative,
        askg-data:Entity-brightness_constancy_and_local_smoothness_constraints,
        askg-data:Entity-deep_networks,
        askg-data:Entity-loss_function,
        askg-data:Entity-training_deep_networks,
        askg-data:Entity-unsupervised_learning_approaches .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-32-Sentence-324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "While such constraints perform well in feature-rich regions, they often fail on challenging scenes with featureless or repetitively-textured regions."@en ;
    askg-onto:inSentence "While such constraints perform well in feature-rich regions, they often fail on challenging scenes with featureless or repetitively-textured regions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-challenging_scenes,
        askg-data:Entity-constraints,
        askg-data:Entity-feature-rich_regions,
        askg-data:Entity-featureless_or_repetitively-textured_regions .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "To achieve more robust prediction and handle these cases more effectively, we exploit the geometric constraint between the optical flow and camera motion in an unsupervised learning framework. Specifically, we focus on optical flow estimation in mostly rigid scenes, where optical flow is predominantly caused by camera motion [43, 48]. Thus the displacement of corresponding pixels across images, i.e., the optical flow, satisfies the well-known epipolar constraint [21]. We formulate this as an epipolar geometric loss defined on an essential matrix determined from the optical flow. Compared to the fundamental matrix used in existing work [55], the essential matrix provides tighter constraints and can be obtained from state-of-the-art geometric algorithms [20] that provide more accurate camera motion estimates than, for example, the 8-point algorithm [21]."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-331,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-332,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-333,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-334,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-335 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To achieve more robust prediction and handle these cases more effectively, we exploit the geometric constraint between the optical flow and camera motion in an unsupervised learning framework."@en ;
    askg-onto:inSentence "To achieve more robust prediction and handle these cases more effectively, we exploit the geometric constraint between the optical flow and camera motion in an unsupervised learning framework."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-learning_framework,
        askg-data:Entity-optical_flow,
        askg-data:Entity-unsupervised_learning_framework .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Specifically, we focus on optical flow estimation in mostly rigid scenes, where optical flow is predominantly caused by camera motion [43, 48]."@en ;
    askg-onto:inSentence "Specifically, we focus on optical flow estimation in mostly rigid scenes, where optical flow is predominantly caused by camera motion [43, 48]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-optical_flow,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-rigid_scenes .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Thus the displacement of corresponding pixels across images, i.e., the optical flow, satisfies the well-known epipolar constraint [21]."@en ;
    askg-onto:inSentence "Thus the displacement of corresponding pixels across images, i.e., the optical flow, satisfies the well-known epipolar constraint [21]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_constraint,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-334 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We formulate this as an epipolar geometric loss defined on an essential matrix determined from the optical flow."@en ;
    askg-onto:inSentence "We formulate this as an epipolar geometric loss defined on an essential matrix determined from the optical flow."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometric_loss,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-33-Sentence-335 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Compared to the fundamental matrix used in existing work [55], the essential matrix provides tighter constraints and can be obtained from state-of-the-art geometric algorithms [20] that provide more accurate camera motion estimates than, for example, the 8-point algorithm [21]."@en ;
    askg-onto:inSentence "Compared to the fundamental matrix used in existing work [55], the essential matrix provides tighter constraints and can be obtained from state-of-the-art geometric algorithms [20] that provide more accurate camera motion estimates than, for example, the 8-point algorithm [21]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8-point_algorithm,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-geometric_algorithms,
        askg-data:Entity-more_accurate_camera_motion_estimates,
        askg-data:Entity-tighter_constraints .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "To compute the epipolar geometric loss we first require an estimate of the camera motion. As such, we formulate flow estimation as a bi-level optimization problem. The upper-level problem is to estimate the optical flow by minimizing the epipolar geometric loss as well as enforcing the standard brightness constancy constraint. The geometric loss is defined based on an *essential matrix* encoding of camera motion, which is obtained by solving a lowerlevel optimization problem that estimates the camera motion from the optical flow. To enable end-to-end training, we use implicit differentiation to back-propagate the gradient of the upper-level loss through the essential matrix estimation layer (the lower-level problem). An overview of our training pipeline is shown in Figure 1."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-341,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-342,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-343,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-344,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-345,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-346 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To compute the epipolar geometric loss we first require an estimate of the camera motion."@en ;
    askg-onto:inSentence "To compute the epipolar geometric loss we first require an estimate of the camera motion."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometric_loss,
        askg-data:Entity-estimate_of_the_camera_motion .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As such, we formulate flow estimation as a bi-level optimization problem."@en ;
    askg-onto:inSentence "As such, we formulate flow estimation as a bi-level optimization problem."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bi-level_optimization_problem,
        askg-data:Entity-flow_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The upper-level problem is to estimate the optical flow by minimizing the epipolar geometric loss as well as enforcing the standard brightness constancy constraint."@en ;
    askg-onto:inSentence "The upper-level problem is to estimate the optical flow by minimizing the epipolar geometric loss as well as enforcing the standard brightness constancy constraint."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brightness_constancy_constraint,
        askg-data:Entity-epipolar_geometric_loss,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-344 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The geometric loss is defined based on an *essential matrix* encoding of camera motion, which is obtained by solving a lowerlevel optimization problem that estimates the camera motion from the optical flow."@en ;
    askg-onto:inSentence "The geometric loss is defined based on an *essential matrix* encoding of camera motion, which is obtained by solving a lowerlevel optimization problem that estimates the camera motion from the optical flow."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-geometric_loss,
        askg-data:Entity-lower-level_optimization_problem,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-345 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To enable end-to-end training, we use implicit differentiation to back-propagate the gradient of the upper-level loss through the essential matrix estimation layer (the lower-level problem)."@en ;
    askg-onto:inSentence "To enable end-to-end training, we use implicit differentiation to back-propagate the gradient of the upper-level loss through the essential matrix estimation layer (the lower-level problem)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-essential_matrix_estimation_layer,
        askg-data:Entity-gradient_of_the_upper-level_loss,
        askg-data:Entity-implicit_differentiation,
        askg-data:Entity-lower-level_problem,
        askg-data:Entity-upper-level_loss .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-34-Sentence-346 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "An overview of our training pipeline is shown in Figure 1."@en ;
    askg-onto:inSentence "An overview of our training pipeline is shown in Figure 1."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_1,
        askg-data:Entity-training_pipeline .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Overall, our key technical contributions include: (1) the introduction of a geometric constraint into an unsupervised deep learning framework for optical flow and camera motion estimation, and (2) the formulation of an end-to-end trainable model with an embedded optimization layer that estimates the camera motion required for computing the epipolar loss. Importantly, our formulation allows backpropagation through the optimization layer regardless of the algorithmic implementation used for computing the essential matrix. We show that our geometrically-constrained model can accurately estimate optical flow satisfying the epipolar geometry. Our optical flow estimation method outperforms approaches that ignore geometry and produces remarkably good results on cases that previous approaches find challenging, such as featureless regions and regions with repetitive features. Our camera motion estimation also compares favourably against methods that directly use a network to predict camera poses."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-351,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-352,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-353,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-354,
        askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-355 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Overall, our key technical contributions include: (1) the introduction of a geometric constraint into an unsupervised deep learning framework for optical flow and camera motion estimation, and (2) the formulation of an end-to-end trainable model with an embedded optimization layer that estimates the camera motion required for computing the epipolar loss."@en ;
    askg-onto:inSentence "Overall, our key technical contributions include: (1) the introduction of a geometric constraint into an unsupervised deep learning framework for optical flow and camera motion estimation, and (2) the formulation of an end-to-end trainable model with an embedded optimization layer that estimates the camera motion required for computing the epipolar loss."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-end-to-end_trainable_model,
        askg-data:Entity-epipolar_loss,
        askg-data:Entity-geometric_constraint,
        askg-data:Entity-unsupervised_deep_learning_framework .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Importantly, our formulation allows backpropagation through the optimization layer regardless of the algorithmic implementation used for computing the essential matrix."@en ;
    askg-onto:inSentence "Importantly, our formulation allows backpropagation through the optimization layer regardless of the algorithmic implementation used for computing the essential matrix."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithmic_implementation,
        askg-data:Entity-backpropagation_through_the_optimization_layer,
        askg-data:Entity-computing_the_essential_matrix,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-formulation,
        askg-data:Entity-optimization_layer .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-353 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We show that our geometrically-constrained model can accurately estimate optical flow satisfying the epipolar geometry."@en ;
    askg-onto:inSentence "We show that our geometrically-constrained model can accurately estimate optical flow satisfying the epipolar geometry."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometry,
        askg-data:Entity-geometrically-constrained_model,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-354 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our optical flow estimation method outperforms approaches that ignore geometry and produces remarkably good results on cases that previous approaches find challenging, such as featureless regions and regions with repetitive features."@en ;
    askg-onto:inSentence "Our optical flow estimation method outperforms approaches that ignore geometry and produces remarkably good results on cases that previous approaches find challenging, such as featureless regions and regions with repetitive features."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches_that_ignore_geometry,
        askg-data:Entity-featureless_regions,
        askg-data:Entity-optical_flow_estimation_method,
        askg-data:Entity-previous_approaches,
        askg-data:Entity-regions_with_repetitive_features,
        askg-data:Entity-remarkably_good_results .

askg-data:Paper-8e2bc199f9f80305-Section-3-Paragraph-35-Sentence-355 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Our camera motion estimation also compares favourably against methods that directly use a network to predict camera poses."@en ;
    askg-onto:inSentence "Our camera motion estimation also compares favourably against methods that directly use a network to predict camera poses."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion_estimation,
        askg-data:Entity-methods_that_directly_use_a_network_to_predict_camera_poses .

askg-data:Paper-8e2bc199f9f80305-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "2. Related Work"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-45,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-48,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Learning-based optical flow estimation. Optical flow estimation has been studied extensively since the pioneering work of Horn and Schunck [23]. The reader is directed to Fortun et al. [13] and Sun et al. [44] for comprehensive reviews of the literature. Recent approaches formulate optical flow estimation as a supervised deep learning task. Compared to traditional methods, convolutional neural networks (CNNs) have the advantage of fast inference once trained, making real-time prediction possible. For example, PWC- Net [44], building on previous supervised optical flow networks [10, 24], incorporated traditional optical flow techniques into the network such as cost volumes and feature warping, and achieved better performance than traditional methods with a shorter running time."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-413,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-414,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-415,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-416,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-417,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-418 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Learning-based optical flow estimation."@en ;
    askg-onto:inSentence "Learning-based optical flow estimation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning-based_optical_flow_estimation,
        askg-data:Entity-method .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Optical flow estimation has been studied extensively since the pioneering work of Horn and Schunck [23]."@en ;
    askg-onto:inSentence "Optical flow estimation has been studied extensively since the pioneering work of Horn and Schunck [23]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-horn,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-research_field,
        askg-data:Entity-schunck .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The reader is directed to Fortun et al."@en ;
    askg-onto:inSentence "The reader is directed to Fortun et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fortun_et_al,
        askg-data:Entity-reader .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "[13] and Sun et al."@en ;
    askg-onto:inSentence "[13] and Sun et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-13,
        askg-data:Entity-sun_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "[44] for comprehensive reviews of the literature."@en ;
    askg-onto:inSentence "[44] for comprehensive reviews of the literature."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-comprehensive_reviews,
        askg-data:Entity-literature .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Recent approaches formulate optical flow estimation as a supervised deep learning task."@en ;
    askg-onto:inSentence "Recent approaches formulate optical flow estimation as a supervised deep learning task."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-supervised_deep_learning_task .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-417 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Compared to traditional methods, convolutional neural networks (CNNs) have the advantage of fast inference once trained, making real-time prediction possible."@en ;
    askg-onto:inSentence "Compared to traditional methods, convolutional neural networks (CNNs) have the advantage of fast inference once trained, making real-time prediction possible."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_neural_networks_cnns,
        askg-data:Entity-fast_inference_once_trained,
        askg-data:Entity-real-time_prediction_possible .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-41-Sentence-418 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "For example, PWC- Net [44], building on previous supervised optical flow networks [10, 24], incorporated traditional optical flow techniques into the network such as cost volumes and feature warping, and achieved better performance than traditional methods with a shorter running time."@en ;
    askg-onto:inSentence "For example, PWC- Net [44], building on previous supervised optical flow networks [10, 24], incorporated traditional optical flow techniques into the network such as cost volumes and feature warping, and achieved better performance than traditional methods with a shorter running time."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cost_volumes,
        askg-data:Entity-feature_warping,
        askg-data:Entity-method,
        askg-data:Entity-optical_flow_networks,
        askg-data:Entity-pwc-net,
        askg-data:Entity-system,
        askg-data:Entity-traditional_methods,
        askg-data:Entity-traditional_optical_flow_techniques .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Despite strong results, supervised deep learning approaches are limited by the need for ground-truth optical flow during training, which is difficult to obtain for real-world scenes. Unsupervised learning instead allows the network to be trained on large volumes of unlabelled data. Several unsupervised loss functions have been proposed, including photometric constancy and local smoothness losses [25], and occlusion-aware bidirectional consistency and robust census losses [31]. Other works explicitly reason about occlusion [46], or synthetically augment data for better occlusion estimation [29, 30]. All of these approaches rely on local matching so cannot handle smooth image regions. Our work is built on some of these previous works, but also enforces global geometric consistency, allowing it to better handle smooth, featureless regions."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-421,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-422,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-423,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-424,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-425,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-426 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Despite strong results, supervised deep learning approaches are limited by the need for ground-truth optical flow during training, which is difficult to obtain for real-world scenes."@en ;
    askg-onto:inSentence "Despite strong results, supervised deep learning approaches are limited by the need for ground-truth optical flow during training, which is difficult to obtain for real-world scenes."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_optical_flow,
        askg-data:Entity-real-world_scenes,
        askg-data:Entity-supervised_deep_learning_approaches,
        askg-data:Entity-the_need_for_ground-truth_optical_flow_during_training .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Unsupervised learning instead allows the network to be trained on large volumes of unlabelled data."@en ;
    askg-onto:inSentence "Unsupervised learning instead allows the network to be trained on large volumes of unlabelled data."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-large_volumes_of_unlabelled_data,
        askg-data:Entity-unsupervised_learning .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Several unsupervised loss functions have been proposed, including photometric constancy and local smoothness losses [25], and occlusion-aware bidirectional consistency and robust census losses [31]."@en ;
    askg-onto:inSentence "Several unsupervised loss functions have been proposed, including photometric constancy and local smoothness losses [25], and occlusion-aware bidirectional consistency and robust census losses [31]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-local_smoothness_losses,
        askg-data:Entity-occlusion-aware_bidirectional_consistency,
        askg-data:Entity-photometric_constancy,
        askg-data:Entity-robust_census_losses,
        askg-data:Entity-unsupervised_loss_functions .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Other works explicitly reason about occlusion [46], or synthetically augment data for better occlusion estimation [29, 30]."@en ;
    askg-onto:inSentence "Other works explicitly reason about occlusion [46], or synthetically augment data for better occlusion estimation [29, 30]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-occlusion,
        askg-data:Entity-occlusion_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "All of these approaches rely on local matching so cannot handle smooth image regions."@en ;
    askg-onto:inSentence "All of these approaches rely on local matching so cannot handle smooth image regions."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-local_matching,
        askg-data:Entity-smooth_image_regions .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-42-Sentence-426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Our work is built on some of these previous works, but also enforces global geometric consistency, allowing it to better handle smooth, featureless regions."@en ;
    askg-onto:inSentence "Our work is built on some of these previous works, but also enforces global geometric consistency, allowing it to better handle smooth, featureless regions."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-global_geometric_consistency,
        askg-data:Entity-smooth_featureless_regions .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Optical Flow and Epipolar Geometry. There has been an extensive study on the relationship between optical flow and epipolar geometry and their applications. Weber and Malik [47] first applied epipolar geometry to estimate and track independently moving objects from optical flow."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43-Sentence-431,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43-Sentence-432,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43-Sentence-433 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43-Sentence-431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Optical Flow and Epipolar Geometry."@en ;
    askg-onto:inSentence "Optical Flow and Epipolar Geometry."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-epipolar_geometry,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43-Sentence-432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "There has been an extensive study on the relationship between optical flow and epipolar geometry and their applications."@en ;
    askg-onto:inSentence "There has been an extensive study on the relationship between optical flow and epipolar geometry and their applications."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometry,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-43-Sentence-433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Weber and Malik [47] first applied epipolar geometry to estimate and track independently moving objects from optical flow."@en ;
    askg-onto:inSentence "Weber and Malik [47] first applied epipolar geometry to estimate and track independently moving objects from optical flow."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometry,
        askg-data:Entity-independently_moving_objects,
        askg-data:Entity-optical_flow,
        askg-data:Entity-weber_and_malik .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Early works have also been reviewed in the book by Xu and Zhang [50], which propose to look at the correspondence problem from the standpoint of epipolar geometry. Difficult 2-D search problem can be simplified to a 1-D search problem under the assumption that the epipolar geometry is known *a priori*, which is also demonstrated later by Yamaguchi et al. [51] on the problem of rigid scene optical flow estimation. In contrast, rather than treating the estimated epipolar geometry as known *a priori* and imposing a hard constraint, we propose a soft constraint between optical flow and epipolar geometry, and a joint optimization approach between the two in a deep learning context. Our idea is similar to [45] in that we couple the estimation of epipolar geometry and optical flow to solve a joint optimization problem. However, we propose a method that can be endto-end trainable in an unsupervised learning framework."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-441,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-442,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-443,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-444,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-445,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-446 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Early works have also been reviewed in the book by Xu and Zhang [50], which propose to look at the correspondence problem from the standpoint of epipolar geometry."@en ;
    askg-onto:inSentence "Early works have also been reviewed in the book by Xu and Zhang [50], which propose to look at the correspondence problem from the standpoint of epipolar geometry."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-book,
        askg-data:Entity-correspondence_problem,
        askg-data:Entity-epipolar_geometry,
        askg-data:Entity-geometry,
        askg-data:Entity-xu,
        askg-data:Entity-zhang .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Difficult 2-D search problem can be simplified to a 1-D search problem under the assumption that the epipolar geometry is known *a priori*, which is also demonstrated later by Yamaguchi et al."@en ;
    askg-onto:inSentence "Difficult 2-D search problem can be simplified to a 1-D search problem under the assumption that the epipolar geometry is known *a priori*, which is also demonstrated later by Yamaguchi et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometry,
        askg-data:Entity-yamaguchi_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "[51] on the problem of rigid scene optical flow estimation."@en ;
    askg-onto:inSentence "[51] on the problem of rigid scene optical flow estimation."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_flow,
        askg-data:Entity-rigid_scene_optical_flow_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-444 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In contrast, rather than treating the estimated epipolar geometry as known *a priori* and imposing a hard constraint, we propose a soft constraint between optical flow and epipolar geometry, and a joint optimization approach between the two in a deep learning context."@en ;
    askg-onto:inSentence "In contrast, rather than treating the estimated epipolar geometry as known *a priori* and imposing a hard constraint, we propose a soft constraint between optical flow and epipolar geometry, and a joint optimization approach between the two in a deep learning context."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_context,
        askg-data:Entity-epipolar_geometry,
        askg-data:Entity-joint_optimization_approach,
        askg-data:Entity-known_a_priori,
        askg-data:Entity-optical_flow,
        askg-data:Entity-optical_flow_and_epipolar_geometry .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-445 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Our idea is similar to [45] in that we couple the estimation of epipolar geometry and optical flow to solve a joint optimization problem."@en ;
    askg-onto:inSentence "Our idea is similar to [45] in that we couple the estimation of epipolar geometry and optical flow to solve a joint optimization problem."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometry,
        askg-data:Entity-estimation_of_epipolar_geometry_and_optical_flow,
        askg-data:Entity-joint_optimization_problem,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-44-Sentence-446 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "However, we propose a method that can be endto-end trainable in an unsupervised learning framework."@en ;
    askg-onto:inSentence "However, we propose a method that can be endto-end trainable in an unsupervised learning framework."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-unsupervised_learning_framework .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-45 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Recently, there have been works that leverage epipolar geometry in unsupervised learning framework [3, 55] with the aim of handling multiple motions. We instead focus on static scenes and demonstrate how to back-propagate the gradients of the loss function through the geometric estimation layer and train the network in an end-to-end manner."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-45-Sentence-451,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-45-Sentence-452 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-45-Sentence-451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Recently, there have been works that leverage epipolar geometry in unsupervised learning framework [3, 55] with the aim of handling multiple motions."@en ;
    askg-onto:inSentence "Recently, there have been works that leverage epipolar geometry in unsupervised learning framework [3, 55] with the aim of handling multiple motions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometry,
        askg-data:Entity-unsupervised_learning_framework .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-45-Sentence-452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We instead focus on static scenes and demonstrate how to back-propagate the gradients of the loss function through the geometric estimation layer and train the network in an end-to-end manner."@en ;
    askg-onto:inSentence "We instead focus on static scenes and demonstrate how to back-propagate the gradients of the loss function through the geometric estimation layer and train the network in an end-to-end manner."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-end-to-end_manner,
        askg-data:Entity-geometric_estimation_layer,
        askg-data:Entity-gradients,
        askg-data:Entity-loss_function,
        askg-data:Entity-network .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Unsupervised Learning of Camera Motion. Another line of works that has gained popularity in recent years is unsupervised learning of depth and motion from videos since the first work of Zhou et al. [57]. Subsequent works adopted the idea of joint learning of flow, motion and depth and witnessed marginal improvements at the cost of large network parameters [52, 58]. All previous works use a camera motion network to directly regress motion from two images, whereas we propose a hybrid method: asking a network to infer dense correspondences (optical flow), and then use optimization to solve for the camera motion. This hybrid learning idea has also been investigated by Zhou et al. [56] in the context of visual localization."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-461,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-462,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-463,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-464,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-465,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-466,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-467 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Unsupervised Learning of Camera Motion."@en ;
    askg-onto:inSentence "Unsupervised Learning of Camera Motion."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-unsupervised_learning .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Another line of works that has gained popularity in recent years is unsupervised learning of depth and motion from videos since the first work of Zhou et al."@en ;
    askg-onto:inSentence "Another line of works that has gained popularity in recent years is unsupervised learning of depth and motion from videos since the first work of Zhou et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_work,
        askg-data:Entity-research_field,
        askg-data:Entity-unsupervised_learning_of_depth_and_motion_from_videos,
        askg-data:Entity-zhou_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-463 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "[57]."@en ;
    askg-onto:inSentence "[57]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-57,
        askg-data:Entity-research_concepts .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-464 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Subsequent works adopted the idea of joint learning of flow, motion and depth and witnessed marginal improvements at the cost of large network parameters [52, 58]."@en ;
    askg-onto:inSentence "Subsequent works adopted the idea of joint learning of flow, motion and depth and witnessed marginal improvements at the cost of large network parameters [52, 58]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-joint_learning_of_flow_motion_and_depth,
        askg-data:Entity-large_network_parameters,
        askg-data:Entity-marginal_improvements,
        askg-data:Entity-subsequent_works .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-465 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "All previous works use a camera motion network to directly regress motion from two images, whereas we propose a hybrid method: asking a network to infer dense correspondences (optical flow), and then use optimization to solve for the camera motion."@en ;
    askg-onto:inSentence "All previous works use a camera motion network to directly regress motion from two images, whereas we propose a hybrid method: asking a network to infer dense correspondences (optical flow), and then use optimization to solve for the camera motion."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-camera_motion_network,
        askg-data:Entity-dense_correspondences,
        askg-data:Entity-motion,
        askg-data:Entity-network,
        askg-data:Entity-optical_flow,
        askg-data:Entity-optimization .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-466 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This hybrid learning idea has also been investigated by Zhou et al."@en ;
    askg-onto:inSentence "This hybrid learning idea has also been investigated by Zhou et al."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hybrid_learning_idea,
        askg-data:Entity-zhou_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-46-Sentence-467 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "[56] in the context of visual localization."@en ;
    askg-onto:inSentence "[56] in the context of visual localization."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_field,
        askg-data:Entity-visual_localization .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Differentiable optimization. A few recent works embed optimization problems as layers within a deep learning model [2, 11, 27, 36]. These layers encode complex dependencies and constraints that cannot be easily learned by convolution or fully-connected layers. It is apparently non-trivial to back-propagate gradients through these layers. However, Gould et al. [18, 19] addressed this problem and provided general techniques for differentiating argmin and argmax problems (both constrained and unconstrained). Amos et al. [2] proposed a differentiable optimization layer but was limited to quadratic programs. These techniques relating to differentiable optimization have been used to solve several computer vision problems, such as video classification [11] and meta-learning [27, 36]. In this work, we embed an epipolar geometric constraint into a deep learning framework via bi-level optimization, jointly estimating camera motion and optical flow in an unsupervised fashion."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-471,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-4710,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-472,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-473,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-474,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-475,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-476,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-477,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-478,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-479 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Differentiable optimization."@en ;
    askg-onto:inSentence "Differentiable optimization."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differentiable_optimization,
        askg-data:Entity-research_field .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-4710 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "In this work, we embed an epipolar geometric constraint into a deep learning framework via bi-level optimization, jointly estimating camera motion and optical flow in an unsupervised fashion."@en ;
    askg-onto:inSentence "In this work, we embed an epipolar geometric constraint into a deep learning framework via bi-level optimization, jointly estimating camera motion and optical flow in an unsupervised fashion."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bi-level_optimization,
        askg-data:Entity-camera_motion,
        askg-data:Entity-deep_learning_framework,
        askg-data:Entity-epipolar_geometric_constraint,
        askg-data:Entity-jointly_estimating_camera_motion_and_optical_flow,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A few recent works embed optimization problems as layers within a deep learning model [2, 11, 27, 36]."@en ;
    askg-onto:inSentence "A few recent works embed optimization problems as layers within a deep learning model [2, 11, 27, 36]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_model,
        askg-data:Entity-optimization_problems .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "These layers encode complex dependencies and constraints that cannot be easily learned by convolution or fully-connected layers."@en ;
    askg-onto:inSentence "These layers encode complex dependencies and constraints that cannot be easily learned by convolution or fully-connected layers."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complex_dependencies,
        askg-data:Entity-constraints,
        askg-data:Entity-convolution_layers,
        askg-data:Entity-dependencies,
        askg-data:Entity-fully-connected_layers,
        askg-data:Entity-layers .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-474 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "It is apparently non-trivial to back-propagate gradients through these layers."@en ;
    askg-onto:inSentence "It is apparently non-trivial to back-propagate gradients through these layers."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradients,
        askg-data:Entity-layers .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-475 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "However, Gould et al."@en ;
    askg-onto:inSentence "However, Gould et al."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gould_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-476 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "[18, 19] addressed this problem and provided general techniques for differentiating argmin and argmax problems (both constrained and unconstrained)."@en ;
    askg-onto:inSentence "[18, 19] addressed this problem and provided general techniques for differentiating argmin and argmax problems (both constrained and unconstrained)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differentiating_argmin_and_argmax_problems,
        askg-data:Entity-general_techniques .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-477 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Amos et al."@en ;
    askg-onto:inSentence "Amos et al."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-amos_et_al,
        askg-data:Entity-paper .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-478 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "[2] proposed a differentiable optimization layer but was limited to quadratic programs."@en ;
    askg-onto:inSentence "[2] proposed a differentiable optimization layer but was limited to quadratic programs."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differentiable_optimization_layer,
        askg-data:Entity-quadratic_programs .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-47-Sentence-479 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "These techniques relating to differentiable optimization have been used to solve several computer vision problems, such as video classification [11] and meta-learning [27, 36]."@en ;
    askg-onto:inSentence "These techniques relating to differentiable optimization have been used to solve several computer vision problems, such as video classification [11] and meta-learning [27, 36]."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision_problems,
        askg-data:Entity-differentiable_optimization,
        askg-data:Entity-meta-learning .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-48 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "![2_image_0.png](2_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-48-Sentence-481 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-48-Sentence-481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![2_image_0.png](2_image_0.png)"@en ;
    askg-onto:inSentence "![2_image_0.png](2_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-clinical_trial,
        askg-data:Entity-data_analysis,
        askg-data:Entity-dataset_y,
        askg-data:Entity-disease_y,
        askg-data:Entity-experiment_x,
        askg-data:Entity-finding_1,
        askg-data:Entity-gene_x,
        askg-data:Entity-machine_learning_model,
        askg-data:Entity-method_z,
        askg-data:Entity-model_a,
        askg-data:Entity-paper_123,
        askg-data:Entity-patient_data,
        askg-data:Entity-process_b,
        askg-data:Entity-research_group_alpha,
        askg-data:Entity-study_on_disease_x,
        askg-data:Entity-symptom_y,
        askg-data:Entity-technology_a,
        askg-data:Entity-tool_z,
        askg-data:Entity-university_of_science .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "I Flow Network V 0 I Optimization Figure 1. Overview of our optical flow and egomotion training pipeline. With implicit differentiation, the gradient can be back-propagated through a complex geometric optimization algorithm. The blue-green arrows show the back-propagation direction of the gradients. The input images are denoted by I and I 0and the predicted optical flow from the network is denoted by V. The estimated flow is then fed into a geometric optimization layer and outputs an essential matrix that best fits the optical flow E(θ ∗), parametrized by θ ∗. The essential matrix (egomotion) and the predicted flow are used to compute the upper-level loss for training the network."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-491,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-492,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-493,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-494,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-495,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-496,
        askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-497 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "I Flow Network V 0 I Optimization Figure 1."@en ;
    askg-onto:inSentence "I Flow Network V 0 I Optimization Figure 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flow_network_v_0,
        askg-data:Entity-optimization .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-492 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Overview of our optical flow and egomotion training pipeline."@en ;
    askg-onto:inSentence "Overview of our optical flow and egomotion training pipeline."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-egomotion,
        askg-data:Entity-optical_flow,
        askg-data:Entity-training_pipeline .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-493 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "With implicit differentiation, the gradient can be back-propagated through a complex geometric optimization algorithm."@en ;
    askg-onto:inSentence "With implicit differentiation, the gradient can be back-propagated through a complex geometric optimization algorithm."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complex_geometric_optimization_algorithm,
        askg-data:Entity-implicit_differentiation .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-494 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The blue-green arrows show the back-propagation direction of the gradients."@en ;
    askg-onto:inSentence "The blue-green arrows show the back-propagation direction of the gradients."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-back-propagation_direction_of_the_gradients,
        askg-data:Entity-blue-green_arrows .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-495 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The input images are denoted by I and I 0and the predicted optical flow from the network is denoted by V."@en ;
    askg-onto:inSentence "The input images are denoted by I and I 0and the predicted optical flow from the network is denoted by V."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-i,
        askg-data:Entity-i_0,
        askg-data:Entity-input_images,
        askg-data:Entity-network,
        askg-data:Entity-v .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-496 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The estimated flow is then fed into a geometric optimization layer and outputs an essential matrix that best fits the optical flow E(θ ∗), parametrized by θ ∗."@en ;
    askg-onto:inSentence "The estimated flow is then fed into a geometric optimization layer and outputs an essential matrix that best fits the optical flow E(θ ∗), parametrized by θ ∗."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B8_,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-geometric_optimization_layer,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-4-Paragraph-49-Sentence-497 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The essential matrix (egomotion) and the predicted flow are used to compute the upper-level loss for training the network."@en ;
    askg-onto:inSentence "The essential matrix (egomotion) and the predicted flow are used to compute the upper-level loss for training the network."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-egomotion,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-network,
        askg-data:Entity-predicted_flow,
        askg-data:Entity-upper-level_loss .

askg-data:Paper-8e2bc199f9f80305-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "3. Bi-Level Optimization For Optical Flow And Essential Matrix Estimation"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We define optical flow as a dense field of displacement vectors, where the displacement vector at each pixel coordinate in one image points to the coordinate of the corresponding pixel in another image. Let a pixel coordinate in image I ∈ IRW×H×3 be denoted by p = (*u, v*) and the corresponding pixel in the other image I 0 by p 0 = (u 0, v0). We assume that I and I 0are two views of the same scene, typically consecutive frames from a video sequence. The optical flow between I and I 0is then the matrix V = [v1*, . . . ,* vN ] ∈ IR2×N of displacement vectors vi = p 0 i − pi for every pixel piin image I and corresponding pixel p 0 iin image I 0. Here N = W H is the total number of pixels in image I."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-511,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-512,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-513,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-514,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-515,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-516,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-517,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-518 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We define optical flow as a dense field of displacement vectors, where the displacement vector at each pixel coordinate in one image points to the coordinate of the corresponding pixel in another image."@en ;
    askg-onto:inSentence "We define optical flow as a dense field of displacement vectors, where the displacement vector at each pixel coordinate in one image points to the coordinate of the corresponding pixel in another image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-another_image,
        askg-data:Entity-coordinate_of_the_corresponding_pixel,
        askg-data:Entity-dense_field_of_displacement_vectors,
        askg-data:Entity-displacement_vector,
        askg-data:Entity-one_image,
        askg-data:Entity-optical_flow,
        askg-data:Entity-pixel,
        askg-data:Entity-pixel_coordinate .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let a pixel coordinate in image I ∈ IRW×H×3 be denoted by p = (*u, v*) and the corresponding pixel in the other image I 0 by p 0 = (u 0, v0)."@en ;
    askg-onto:inSentence "Let a pixel coordinate in image I ∈ IRW×H×3 be denoted by p = (*u, v*) and the corresponding pixel in the other image I 0 by p 0 = (u 0, v0)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_i,
        askg-data:Entity-image_i_0,
        askg-data:Entity-irwh3,
        askg-data:Entity-p,
        askg-data:Entity-p_0,
        askg-data:Entity-pixel,
        askg-data:Entity-pixel_coordinate .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We assume that I and I 0are two views of the same scene, typically consecutive frames from a video sequence."@en ;
    askg-onto:inSentence "We assume that I and I 0are two views of the same scene, typically consecutive frames from a video sequence."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-i,
        askg-data:Entity-i_0,
        askg-data:Entity-two_views_of_the_same_scene .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The optical flow between I and I 0is then the matrix V = [v1*, ."@en ;
    askg-onto:inSentence "The optical flow between I and I 0is then the matrix V = [v1*, ."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-i,
        askg-data:Entity-i_0,
        askg-data:Entity-matrix_v,
        askg-data:Entity-metric,
        askg-data:Entity-optical_flow,
        askg-data:Entity-tool .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-company,
        askg-data:Entity-dataset,
        askg-data:Entity-domain,
        askg-data:Entity-experiment,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-paper,
        askg-data:Entity-research_field,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-research_field,
        askg-data:Entity-study,
        askg-data:Entity-technique .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-517 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text ",* vN ] ∈ IR2×N of displacement vectors vi = p 0 i − pi for every pixel piin image I and corresponding pixel p 0 iin image I 0."@en ;
    askg-onto:inSentence ",* vN ] ∈ IR2×N of displacement vectors vi = p 0 i − pi for every pixel piin image I and corresponding pixel p 0 iin image I 0."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-displacement_vectors,
        askg-data:Entity-image_i,
        askg-data:Entity-image_i_0,
        askg-data:Entity-pixel_p_0_i,
        askg-data:Entity-pixel_pi .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-51-Sentence-518 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Here N = W H is the total number of pixels in image I."@en ;
    askg-onto:inSentence "Here N = W H is the total number of pixels in image I."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h,
        askg-data:Entity-height_of_the_image,
        askg-data:Entity-i,
        askg-data:Entity-image,
        askg-data:Entity-n,
        askg-data:Entity-total_number_of_pixels_in_image_i,
        askg-data:Entity-w,
        askg-data:Entity-width_of_the_image .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Given the camera intrinsic calibration matrices K and K 0 for the image pair I and I 0, we can obtain the normalized coordinates as x = K −1p˜ and x 0 = K 0−1p˜ 0, where p˜ = (*u, v,* 1)> is the pixel p expressed in homogeneous coordinates. Corresponding points x ↔ x 0in normalized coordinates satisfy the geometric relationship x 0>Ex = 0, known as the *epipolar constraint*. For camera matrices P = K[I|0] and P 0 = K 0[R|t], the essential matrix can be decomposed into rotation R and translation t components as E = [t]×R with t known up to scale [21]. We address the problem of incorporating this epipolar constraint into an optimization procedure for deep optical flow estimation."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-521,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-522,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-523,
        askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-524 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Given the camera intrinsic calibration matrices K and K 0 for the image pair I and I 0, we can obtain the normalized coordinates as x = K −1p˜ and x 0 = K 0−1p˜ 0, where p˜ = (*u, v,* 1)> is the pixel p expressed in homogeneous coordinates."@en ;
    askg-onto:inSentence "Given the camera intrinsic calibration matrices K and K 0 for the image pair I and I 0, we can obtain the normalized coordinates as x = K −1p˜ and x 0 = K 0−1p˜ 0, where p˜ = (*u, v,* 1)> is the pixel p expressed in homogeneous coordinates."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_intrinsic_calibration_matrices,
        askg-data:Entity-image_pair_i_and_i_0,
        askg-data:Entity-k,
        askg-data:Entity-k_0,
        askg-data:Entity-normalized_coordinates,
        askg-data:Entity-p,
        askg-data:Entity-pixel_p .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Corresponding points x ↔ x 0in normalized coordinates satisfy the geometric relationship x 0>Ex = 0, known as the *epipolar constraint*."@en ;
    askg-onto:inSentence "Corresponding points x ↔ x 0in normalized coordinates satisfy the geometric relationship x 0>Ex = 0, known as the *epipolar constraint*."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_constraint,
        askg-data:Entity-geometric_relationship .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For camera matrices P = K[I|0] and P 0 = K 0[R|t], the essential matrix can be decomposed into rotation R and translation t components as E = [t]×R with t known up to scale [21]."@en ;
    askg-onto:inSentence "For camera matrices P = K[I|0] and P 0 = K 0[R|t], the essential matrix can be decomposed into rotation R and translation t components as E = [t]×R with t known up to scale [21]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_matrices,
        askg-data:Entity-e,
        askg-data:Entity-essential_matrix,
        askg-data:Entity-k_0rt,
        askg-data:Entity-ki0,
        askg-data:Entity-p,
        askg-data:Entity-p_0,
        askg-data:Entity-rotation_r_and_translation_t_components,
        askg-data:Entity-scale,
        askg-data:Entity-t,
        askg-data:Entity-tr .

askg-data:Paper-8e2bc199f9f80305-Section-5-Paragraph-52-Sentence-524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We address the problem of incorporating this epipolar constraint into an optimization procedure for deep optical flow estimation."@en ;
    askg-onto:inSentence "We address the problem of incorporating this epipolar constraint into an optimization procedure for deep optical flow estimation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_optical_flow_estimation,
        askg-data:Entity-epipolar_constraint,
        askg-data:Entity-optimization_procedure .

askg-data:Paper-8e2bc199f9f80305-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "3.1. Optimizing An Epipolar Loss Function"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-61,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-62,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-64,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-66,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-67,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We formulate optical flow estimation as a bi-level optimization problem, with an upper-level problem that is solved subject to constraints enforced by a lower-level problem, given by"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-61-Sentence-611 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We formulate optical flow estimation as a bi-level optimization problem, with an upper-level problem that is solved subject to constraints enforced by a lower-level problem, given by"@en ;
    askg-onto:inSentence "We formulate optical flow estimation as a bi-level optimization problem, with an upper-level problem that is solved subject to constraints enforced by a lower-level problem, given by"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bi-level_optimization_problem,
        askg-data:Entity-constraints,
        askg-data:Entity-lower-level_problem,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-upper-level_problem .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\begin{array}{r l}{{\\mathrm{minimize}}}&{{L(\\mathbf{v},\\boldsymbol{\\theta}^{\\star})}}\\\\ {{\\underset{\\mathbf{v}}{\\mathrm{subject~to}}}}&{{\\boldsymbol{\\theta}^{\\star}\\in\\operatorname{arg\\,min}l(\\mathbf{v},\\boldsymbol{\\theta})}}\\\\ {{}}&{{\\boldsymbol{\\theta}\\in\\mathbb{R}^{5}}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-62-Sentence-621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{r l}{{\\mathrm{minimize}}}&{{L(\\mathbf{v},\\boldsymbol{\\theta}^{\\star})}}\\\\ {{\\underset{\\mathbf{v}}{\\mathrm{subject~to}}}}&{{\\boldsymbol{\\theta}^{\\star}\\in\\operatorname{arg\\,min}l(\\mathbf{v},\\boldsymbol{\\theta})}}\\\\ {{}}&{{\\boldsymbol{\\theta}\\in\\mathbb{R}^{5}}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{r l}{{\\mathrm{minimize}}}&{{L(\\mathbf{v},\\boldsymbol{\\theta}^{\\star})}}\\\\ {{\\underset{\\mathbf{v}}{\\mathrm{subject~to}}}}&{{\\boldsymbol{\\theta}^{\\star}\\in\\operatorname{arg\\,min}l(\\mathbf{v},\\boldsymbol{\\theta})}}\\\\ {{}}&{{\\boldsymbol{\\theta}\\in\\mathbb{R}^{5}}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B8__arg_min_lv_%CE%B8,
        askg-data:Entity-%E2%84%9D%E2%81%B5,
        askg-data:Entity-lv_%CE%B8 .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "where θ ∈ IR5is the minimal parametrization of E given in Hartley & Li [20]. The upper-level loss function L comprises several terms, which is fully described in Section 4. To encourage the optical flow to satisfy the epipolar geometry, one of the terms in L is the one-sided epipolar error, given by the global geometric loss function"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63-Sentence-631,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63-Sentence-632,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63-Sentence-633 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where θ ∈ IR5is the minimal parametrization of E given in Hartley & Li [20]."@en ;
    askg-onto:inSentence "where θ ∈ IR5is the minimal parametrization of E given in Hartley & Li [20]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B8,
        askg-data:Entity-e,
        askg-data:Entity-hartley__li_20 .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63-Sentence-632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The upper-level loss function L comprises several terms, which is fully described in Section 4."@en ;
    askg-onto:inSentence "The upper-level loss function L comprises several terms, which is fully described in Section 4."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-several_terms,
        askg-data:Entity-upper-level_loss_function_l .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-63-Sentence-633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To encourage the optical flow to satisfy the epipolar geometry, one of the terms in L is the one-sided epipolar error, given by the global geometric loss function"@en ;
    askg-onto:inSentence "To encourage the optical flow to satisfy the epipolar geometry, one of the terms in L is the one-sided epipolar error, given by the global geometric loss function"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_geometry,
        askg-data:Entity-global_geometric_loss_function,
        askg-data:Entity-one-sided_epipolar_error,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-64 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$L_{\\mathrm{e}}(\\mathbf{V},\\boldsymbol{\\theta^{\\star}})=\\sum_{i=1}^{N}{\\frac{(\\mathbf{x}_{i}^{\\prime}\\top\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i})^{2}}{[\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i}]_{1}^{2}+[\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i}]_{2}^{2}}}$$ $$(3)$$ 22(3) where the essential matrix E is a function of its parameters θ ?and [Ex]j denotes the j th component of the 3-vector Ex."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-64-Sentence-641 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-64-Sentence-641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{\\mathrm{e}}(\\mathbf{V},\\boldsymbol{\\theta^{\\star}})=\\sum_{i=1}^{N}{\\frac{(\\mathbf{x}_{i}^{\\prime}\\top\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i})^{2}}{[\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i}]_{1}^{2}+[\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i}]_{2}^{2}}}$$ $$(3)$$ 22(3) where the essential matrix E is a function of its parameters θ ?and [Ex]j denotes the j th component of the 3-vector Ex."@en ;
    askg-onto:inSentence "$$L_{\\mathrm{e}}(\\mathbf{V},\\boldsymbol{\\theta^{\\star}})=\\sum_{i=1}^{N}{\\frac{(\\mathbf{x}_{i}^{\\prime}\\top\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i})^{2}}{[\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i}]_{1}^{2}+[\\mathbf{E}(\\boldsymbol{\\theta^{\\star}})\\mathbf{x}_{i}]_{2}^{2}}}$$ $$(3)$$ 22(3) where the essential matrix E is a function of its parameters θ ?and [Ex]j denotes the j th component of the 3-vector Ex."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-essential_matrix_e .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "This error measures the sum squared distance of each point x 0to its corresponding epipolar line Ex. Note that xiis constant and x 0i = K 0−1(p˜i +v˜i) is a function of the optical flow V. The optimal essential matrix parameters θ ?also depend on the optical flow V. We formulate essential matrix estimation as a lower-level optimization problem (2), with a robust algebraic error objective function given by"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-651,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-652,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-653,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-654 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This error measures the sum squared distance of each point x 0to its corresponding epipolar line Ex."@en ;
    askg-onto:inSentence "This error measures the sum squared distance of each point x 0to its corresponding epipolar line Ex."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_line,
        askg-data:Entity-error,
        askg-data:Entity-point,
        askg-data:Entity-sum_squared_distance .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that xiis constant and x 0i = K 0−1(p˜i +v˜i) is a function of the optical flow V."@en ;
    askg-onto:inSentence "Note that xiis constant and x 0i = K 0−1(p˜i +v˜i) is a function of the optical flow V."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constant,
        askg-data:Entity-k_0,
        askg-data:Entity-k_01pi_vi,
        askg-data:Entity-optical_flow_v,
        askg-data:Entity-x_0i,
        askg-data:Entity-xiis .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-653 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The optimal essential matrix parameters θ ?also depend on the optical flow V."@en ;
    askg-onto:inSentence "The optimal essential matrix parameters θ ?also depend on the optical flow V."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-essential_matrix_parameters_%CE%B8,
        askg-data:Entity-optical_flow_v .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-65-Sentence-654 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We formulate essential matrix estimation as a lower-level optimization problem (2), with a robust algebraic error objective function given by"@en ;
    askg-onto:inSentence "We formulate essential matrix estimation as a lower-level optimization problem (2), with a robust algebraic error objective function given by"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lower-level_optimization_problem,
        askg-data:Entity-matrix_estimation,
        askg-data:Entity-robust_algebraic_error_objective_function .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-66 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$\\begin{array}{l l}{{l(\\mathbf{v},\\boldsymbol{\\theta})=\\sum_{i=1}^{N}\\rho\\left(\\mathbf{x}_{i}^{\\prime\\top}\\mathbf{E}(\\boldsymbol{\\theta})\\mathbf{x}_{i}\\right),}}\\\\ {{\\rho(z;\\delta)=\\begin{cases}{\\frac{1}{2}}z^{2},&{\\mathrm{if}}\\ |z|<\\delta\\\\ {\\frac{1}{2}}\\delta^{2},&{\\mathrm{otherwise.}}\\end{cases}}\\end{array}$$ $$(4)$$ $$\\left({\\boldsymbol{S}}\\right)$$ $$(\\mathbf{l})$$ $$(2)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-66-Sentence-661 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-66-Sentence-661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l l}{{l(\\mathbf{v},\\boldsymbol{\\theta})=\\sum_{i=1}^{N}\\rho\\left(\\mathbf{x}_{i}^{\\prime\\top}\\mathbf{E}(\\boldsymbol{\\theta})\\mathbf{x}_{i}\\right),}}\\\\ {{\\rho(z;\\delta)=\\begin{cases}{\\frac{1}{2}}z^{2},&{\\mathrm{if}}\\ |z|<\\delta\\\\ {\\frac{1}{2}}\\delta^{2},&{\\mathrm{otherwise.}}\\end{cases}}\\end{array}$$ $$(4)$$ $$\\left({\\boldsymbol{S}}\\right)$$ $$(\\mathbf{l})$$ $$(2)$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{l l}{{l(\\mathbf{v},\\boldsymbol{\\theta})=\\sum_{i=1}^{N}\\rho\\left(\\mathbf{x}_{i}^{\\prime\\top}\\mathbf{E}(\\boldsymbol{\\theta})\\mathbf{x}_{i}\\right),}}\\\\ {{\\rho(z;\\delta)=\\begin{cases}{\\frac{1}{2}}z^{2},&{\\mathrm{if}}\\ |z|<\\delta\\\\ {\\frac{1}{2}}\\delta^{2},&{\\mathrm{otherwise.}}\\end{cases}}\\end{array}$$ $$(4)$$ $$\\left({\\boldsymbol{S}}\\right)$$ $$(\\mathbf{l})$$ $$(2)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%81z%CE%B4,
        askg-data:Entity-lv%CE%B8 .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-67 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "The robust function ρ(·) is a truncated L2 penalty function with an inlier threshold δ."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-67-Sentence-671 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-67-Sentence-671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The robust function ρ(·) is a truncated L2 penalty function with an inlier threshold δ."@en ;
    askg-onto:inSentence "The robust function ρ(·) is a truncated L2 penalty function with an inlier threshold δ."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function_%CF%81,
        askg-data:Entity-inlier_threshold_%CE%B4,
        askg-data:Entity-truncated_l2_penalty_function .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "To solve the bi-level optimization problem (1) within a deep learning context, we need to back-propagate gradients through the essential matrix optimization layer. During the forward pass, for each image pair we solve problem (2) using iteratively re-weighted least squares (IRLS) to minimize the robust objective function l (4). However, this function is non-convex with many local minima. Hence, we first obtain a robust initial estimate of the essential matrix parameters using RANSAC [12] with the five-point algorithm [28, 34], which we have implemented as an efficient GPU routine."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-681,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-682,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-683,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-684 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To solve the bi-level optimization problem (1) within a deep learning context, we need to back-propagate gradients through the essential matrix optimization layer."@en ;
    askg-onto:inSentence "To solve the bi-level optimization problem (1) within a deep learning context, we need to back-propagate gradients through the essential matrix optimization layer."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-back-propagate_gradients,
        askg-data:Entity-bi-level_optimization_problem,
        askg-data:Entity-deep_learning_context,
        askg-data:Entity-essential_matrix_optimization_layer .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-682 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "During the forward pass, for each image pair we solve problem (2) using iteratively re-weighted least squares (IRLS) to minimize the robust objective function l (4)."@en ;
    askg-onto:inSentence "During the forward pass, for each image pair we solve problem (2) using iteratively re-weighted least squares (IRLS) to minimize the robust objective function l (4)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iteratively_re-weighted_least_squares_irls,
        askg-data:Entity-robust_objective_function .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-683 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, this function is non-convex with many local minima."@en ;
    askg-onto:inSentence "However, this function is non-convex with many local minima."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function,
        askg-data:Entity-non-convex .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-68-Sentence-684 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Hence, we first obtain a robust initial estimate of the essential matrix parameters using RANSAC [12] with the five-point algorithm [28, 34], which we have implemented as an efficient GPU routine."@en ;
    askg-onto:inSentence "Hence, we first obtain a robust initial estimate of the essential matrix parameters using RANSAC [12] with the five-point algorithm [28, 34], which we have implemented as an efficient GPU routine."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-five-point_algorithm,
        askg-data:Entity-gpu_routine,
        askg-data:Entity-ransac .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "During the backward pass we need to compute dθ ?/dV, which amounts to differentiating the arg min function. This can be achieved using implicit differentiation described below. As we will see, the gradient computation is agnostic to the method used to solve the lower-level problem, and only requires that a solution be found. Importantly, this means that we do not need to back-propagate through the specific steps of the optimization algorithm."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-691,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-692,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-693,
        askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-694 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "During the backward pass we need to compute dθ ?/dV, which amounts to differentiating the arg min function."@en ;
    askg-onto:inSentence "During the backward pass we need to compute dθ ?/dV, which amounts to differentiating the arg min function."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arg_min_function,
        askg-data:Entity-d%CE%B8_dv .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-692 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This can be achieved using implicit differentiation described below."@en ;
    askg-onto:inSentence "This can be achieved using implicit differentiation described below."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-below,
        askg-data:Entity-implicit_differentiation .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-693 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As we will see, the gradient computation is agnostic to the method used to solve the lower-level problem, and only requires that a solution be found."@en ;
    askg-onto:inSentence "As we will see, the gradient computation is agnostic to the method used to solve the lower-level problem, and only requires that a solution be found."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradient_computation,
        askg-data:Entity-lower-level_problem,
        askg-data:Entity-solution,
        askg-data:Entity-the_method_used_to_solve_the_lower-level_problem .

askg-data:Paper-8e2bc199f9f80305-Section-6-Paragraph-69-Sentence-694 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Importantly, this means that we do not need to back-propagate through the specific steps of the optimization algorithm."@en ;
    askg-onto:inSentence "Importantly, this means that we do not need to back-propagate through the specific steps of the optimization algorithm."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimization_algorithm,
        askg-data:Entity-specific_steps .

askg-data:Paper-8e2bc199f9f80305-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "3.2. Implicit Differentiation"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-710,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-75,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-76,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-77,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-79 ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Robustly estimating the essential matrix—via the lowerlevel optimization problem in (2)—does not have an analytic solution and involves a non-differentiable RANSAC procedure to mitigate the effect of outliers. Obtaining the gradient would therefore not be possible using explicit differentiation or direct automatic differentiation. However, since the objective function of the lower-level optimization problem in (2) is twice-differentiable, we can compute the gradient of the arg min function using implicit differentiation knowing only the optimal solution (and not how it was obtained) [18, 39, 8, 35]. The key result, a special case of Dini's implicit function theorem [9, p19] applied to the optimality condition df(x, y)/dy = 0, is given below for completeness."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-711,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-712,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-713,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-714 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Robustly estimating the essential matrix—via the lowerlevel optimization problem in (2)—does not have an analytic solution and involves a non-differentiable RANSAC procedure to mitigate the effect of outliers."@en ;
    askg-onto:inSentence "Robustly estimating the essential matrix—via the lowerlevel optimization problem in (2)—does not have an analytic solution and involves a non-differentiable RANSAC procedure to mitigate the effect of outliers."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-essential_matrix,
        askg-data:Entity-ransac_procedure .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Obtaining the gradient would therefore not be possible using explicit differentiation or direct automatic differentiation."@en ;
    askg-onto:inSentence "Obtaining the gradient would therefore not be possible using explicit differentiation or direct automatic differentiation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-direct_automatic_differentiation,
        askg-data:Entity-explicit_differentiation,
        askg-data:Entity-gradient .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, since the objective function of the lower-level optimization problem in (2) is twice-differentiable, we can compute the gradient of the arg min function using implicit differentiation knowing only the optimal solution (and not how it was obtained) [18, 39, 8, 35]."@en ;
    askg-onto:inSentence "However, since the objective function of the lower-level optimization problem in (2) is twice-differentiable, we can compute the gradient of the arg min function using implicit differentiation knowing only the optimal solution (and not how it was obtained) [18, 39, 8, 35]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arg_min_function,
        askg-data:Entity-implicit_differentiation,
        askg-data:Entity-lower-level_optimization_problem,
        askg-data:Entity-optimal_solution,
        askg-data:Entity-twice-differentiable .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-71-Sentence-714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The key result, a special case of Dini's implicit function theorem [9, p19] applied to the optimality condition df(x, y)/dy = 0, is given below for completeness."@en ;
    askg-onto:inSentence "The key result, a special case of Dini's implicit function theorem [9, p19] applied to the optimality condition df(x, y)/dy = 0, is given below for completeness."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dinis_implicit_function_theorem,
        askg-data:Entity-optimality_condition_dfx_ydy__0 .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-710 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "with all terms evaluated at (V, θ ?). This defines the exact gradient of loss function L constrained by (2)."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-710-Sentence-7101,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-710-Sentence-7102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-710-Sentence-7101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "with all terms evaluated at (V, θ ?)."@en ;
    askg-onto:inSentence "with all terms evaluated at (V, θ ?)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-710-Sentence-7102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This defines the exact gradient of loss function L constrained by (2)."@en ;
    askg-onto:inSentence "This defines the exact gradient of loss function L constrained by (2)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-exact_gradient,
        askg-data:Entity-loss_function_l .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Lemma 1: (Gould et al. [18]) Let f : IR × IRn → IR be a continuous function with first and second derivatives. Set g(x) to be a stationary point of f(x, y) with respect to y, for example g(x) ∈ arg miny∈IRn f(x, y), and let the Hessian fY Y (x, g(x)) be nonsingular. Then the vector derivative of g with respect to x is"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-721,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-722,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-723,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-724 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Lemma 1: (Gould et al."@en ;
    askg-onto:inSentence "Lemma 1: (Gould et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gould_et_al,
        askg-data:Entity-lemma_1 .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "[18]) Let f : IR × IRn → IR be a continuous function with first and second derivatives."@en ;
    askg-onto:inSentence "[18]) Let f : IR × IRn → IR be a continuous function with first and second derivatives."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-continuous_function,
        askg-data:Entity-f,
        askg-data:Entity-first_and_second_derivatives .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Set g(x) to be a stationary point of f(x, y) with respect to y, for example g(x) ∈ arg miny∈IRn f(x, y), and let the Hessian fY Y (x, g(x)) be nonsingular."@en ;
    askg-onto:inSentence "Set g(x) to be a stationary point of f(x, y) with respect to y, for example g(x) ∈ arg miny∈IRn f(x, y), and let the Hessian fY Y (x, g(x)) be nonsingular."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arg_minyirn_fx_y,
        askg-data:Entity-gx,
        askg-data:Entity-hessian_fy_y_x_gx,
        askg-data:Entity-nonsingular,
        askg-data:Entity-stationary_point_of_fx_y .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-72-Sentence-724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Then the vector derivative of g with respect to x is"@en ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$\\frac{\\mathrm{d}\\mathbf{g}}{\\mathrm{d}x}=-f_{YY}(x,\\mathbf{g}(x))^{-1}f_{XY}(x,\\mathbf{g}(x))\\tag{6}$$ where $f_{YY}(x,\\mathbf{y})\\doteq\\frac{\\partial^{2}f(x,\\mathbf{y})}{\\partial\\mathbf{y}^{2}}\\in\\mathrm{I\\!R}^{n\\times n}$ and $f_{XY}(x,\\mathbf{y})\\doteq\\frac{\\partial^{2}f(x,\\mathbf{y})}{\\partial x\\partial\\mathbf{y}}\\in\\mathrm{I\\!R}^{n}$. Proof. The derivative of f with respect to y, evaluated at the stationary point g(x), is zero by definition. The result follows by differentiating both sides with respect to x using the chain rule, i.e.,"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-731,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-732,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-733,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-734 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\frac{\\mathrm{d}\\mathbf{g}}{\\mathrm{d}x}=-f_{YY}(x,\\mathbf{g}(x))^{-1}f_{XY}(x,\\mathbf{g}(x))\\tag{6}$$ where $f_{YY}(x,\\mathbf{y})\\doteq\\frac{\\partial^{2}f(x,\\mathbf{y})}{\\partial\\mathbf{y}^{2}}\\in\\mathrm{I\\!R}^{n\\times n}$ and $f_{XY}(x,\\mathbf{y})\\doteq\\frac{\\partial^{2}f(x,\\mathbf{y})}{\\partial x\\partial\\mathbf{y}}\\in\\mathrm{I\\!R}^{n}$."@en ;
    askg-onto:inSentence "$$\\frac{\\mathrm{d}\\mathbf{g}}{\\mathrm{d}x}=-f_{YY}(x,\\mathbf{g}(x))^{-1}f_{XY}(x,\\mathbf{g}(x))\\tag{6}$$ where $f_{YY}(x,\\mathbf{y})\\doteq\\frac{\\partial^{2}f(x,\\mathbf{y})}{\\partial\\mathbf{y}^{2}}\\in\\mathrm{I\\!R}^{n\\times n}$ and $f_{XY}(x,\\mathbf{y})\\doteq\\frac{\\partial^{2}f(x,\\mathbf{y})}{\\partial x\\partial\\mathbf{y}}\\in\\mathrm{I\\!R}^{n}$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Proof."@en ;
    askg-onto:inSentence "Proof."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proof,
        askg-data:Entity-theory .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The derivative of f with respect to y, evaluated at the stationary point g(x), is zero by definition."@en ;
    askg-onto:inSentence "The derivative of f with respect to y, evaluated at the stationary point g(x), is zero by definition."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-gx,
        askg-data:Entity-stationary_point,
        askg-data:Entity-y,
        askg-data:Entity-zero .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-73-Sentence-734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The result follows by differentiating both sides with respect to x using the chain rule, i.e.,"@en ;
    askg-onto:inSentence "The result follows by differentiating both sides with respect to x using the chain rule, i.e.,"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chain_rule,
        askg-data:Entity-differentiating_both_sides_with_respect_to_x .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$f_{Y}(x,\\mathbf{g}(x))\\doteq\\left.\\frac{\\mathrm{d}f(x,\\mathbf{y})}{\\mathrm{d}\\mathbf{y}}\\right|_{\\mathbf{y}=\\mathbf{g}(x)}=\\mathbf{0}$$ $$\\frac{\\mathrm{d}}{\\mathrm{d}x}f_{Y}(x,\\mathbf{g}(x))=\\mathbf{0}$$ $$\\therefore\\ \\ f_{XY}(x,\\mathbf{g}(x))+f_{YY}(x,\\mathbf{g}(x))\\frac{\\mathrm{d}\\mathbf{g}}{\\mathrm{d}x}=\\mathbf{0}$$ and rearranging the terms. (7) $\\binom{8}{}$ . = 0 (7) $$(9)$$ $\\square$ = 0 (9) For brevity we have shown the derivative with respect to a single parameter. For multiple parameters, the derivative can be computed with respect to each parameter separately."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-741,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-742,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-743,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-744 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$f_{Y}(x,\\mathbf{g}(x))\\doteq\\left.\\frac{\\mathrm{d}f(x,\\mathbf{y})}{\\mathrm{d}\\mathbf{y}}\\right|_{\\mathbf{y}=\\mathbf{g}(x)}=\\mathbf{0}$$ $$\\frac{\\mathrm{d}}{\\mathrm{d}x}f_{Y}(x,\\mathbf{g}(x))=\\mathbf{0}$$ $$\\therefore\\ \\ f_{XY}(x,\\mathbf{g}(x))+f_{YY}(x,\\mathbf{g}(x))\\frac{\\mathrm{d}\\mathbf{g}}{\\mathrm{d}x}=\\mathbf{0}$$ and rearranging the terms."@en ;
    askg-onto:inSentence "$$f_{Y}(x,\\mathbf{g}(x))\\doteq\\left.\\frac{\\mathrm{d}f(x,\\mathbf{y})}{\\mathrm{d}\\mathbf{y}}\\right|_{\\mathbf{y}=\\mathbf{g}(x)}=\\mathbf{0}$$ $$\\frac{\\mathrm{d}}{\\mathrm{d}x}f_{Y}(x,\\mathbf{g}(x))=\\mathbf{0}$$ $$\\therefore\\ \\ f_{XY}(x,\\mathbf{g}(x))+f_{YY}(x,\\mathbf{g}(x))\\frac{\\mathrm{d}\\mathbf{g}}{\\mathrm{d}x}=\\mathbf{0}$$ and rearranging the terms."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Cracddxf_yx%09extbfgx,
        askg-data:Entity-derivative,
        askg-data:Entity-f_xyx%09extbfgx,
        askg-data:Entity-f_y,
        askg-data:Entity-f_yx%09extbfgx,
        askg-data:Entity-function,
        askg-data:Entity-mathematical_relationship .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-742 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(7) $\\binom{8}{}$ ."@en ;
    askg-onto:inSentence "(7) $\\binom{8}{}$ ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-743 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "= 0 (7) $$(9)$$ $\\square$ = 0 (9) For brevity we have shown the derivative with respect to a single parameter."@en ;
    askg-onto:inSentence "= 0 (7) $$(9)$$ $\\square$ = 0 (9) For brevity we have shown the derivative with respect to a single parameter."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-derivative,
        askg-data:Entity-single_parameter .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-74-Sentence-744 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For multiple parameters, the derivative can be computed with respect to each parameter separately."@en ;
    askg-onto:inSentence "For multiple parameters, the derivative can be computed with respect to each parameter separately."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-derivative,
        askg-data:Entity-each_parameter_separately .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-75 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Here, the matrix fY Y need only be inverted or decomposed once for the full set of parameters. It is also worth noting that the gradient is valid for any stationary point g(x) of f, including local minima, maxima and saddle points."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-75-Sentence-751,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-75-Sentence-752 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-75-Sentence-751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Here, the matrix fY Y need only be inverted or decomposed once for the full set of parameters."@en ;
    askg-onto:inSentence "Here, the matrix fY Y need only be inverted or decomposed once for the full set of parameters."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-full_set_of_parameters,
        askg-data:Entity-matrix_fy_y .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-75-Sentence-752 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It is also worth noting that the gradient is valid for any stationary point g(x) of f, including local minima, maxima and saddle points."@en ;
    askg-onto:inSentence "It is also worth noting that the gradient is valid for any stationary point g(x) of f, including local minima, maxima and saddle points."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradient,
        askg-data:Entity-local_minima,
        askg-data:Entity-maxima,
        askg-data:Entity-saddle_points,
        askg-data:Entity-stationary_point_gx,
        askg-data:Entity-stationary_point_gx_of_f .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-76 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Applied to the problem under consideration, we get"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-76-Sentence-761 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-76-Sentence-761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Applied to the problem under consideration, we get"@en ;
    askg-onto:inSentence "Applied to the problem under consideration, we get"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-applied_to_the_problem,
        askg-data:Entity-the_problem_under_consideration .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-77 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$\\frac{\\mathrm{d}\\theta^{\\star}}{\\mathrm{d}V}=-\\left(\\frac{\\partial^{2}l(\\mathbf{V},\\theta^{\\star}(\\mathbf{V}))}{\\partial\\Theta^{2}}\\right)^{-1}\\frac{\\partial^{2}l(\\mathbf{V},\\theta^{\\star}(\\mathbf{V}))}{\\partial V\\partial\\Theta}.\\tag{10}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-77-Sentence-771 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-77-Sentence-771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\frac{\\mathrm{d}\\theta^{\\star}}{\\mathrm{d}V}=-\\left(\\frac{\\partial^{2}l(\\mathbf{V},\\theta^{\\star}(\\mathbf{V}))}{\\partial\\Theta^{2}}\\right)^{-1}\\frac{\\partial^{2}l(\\mathbf{V},\\theta^{\\star}(\\mathbf{V}))}{\\partial V\\partial\\Theta}.\\tag{10}$$"@en ;
    askg-onto:inSentence "$$\\frac{\\mathrm{d}\\theta^{\\star}}{\\mathrm{d}V}=-\\left(\\frac{\\partial^{2}l(\\mathbf{V},\\theta^{\\star}(\\mathbf{V}))}{\\partial\\Theta^{2}}\\right)^{-1}\\frac{\\partial^{2}l(\\mathbf{V},\\theta^{\\star}(\\mathbf{V}))}{\\partial V\\partial\\Theta}.\\tag{10}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B8,
        askg-data:Entity-l .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Automatic differentiation, such as the Autograd package in PyTorch, can be used to compute the necessary Jacobian and Hessian matrices. Observe from (10) that although we require θ ?to be a stationary point of l, the computation of the gradient is independent of the algorithmic steps used to determine θ ?and hence E. Thus to be clear, automatic differentiation, if used, is applied to the objective function itself and not the algorithmic procedure used to find its minimum, different from standard usage in deep learning models. The total derivative of L in problem (1) is then"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-781,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-782,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-783,
        askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-784 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-781 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Automatic differentiation, such as the Autograd package in PyTorch, can be used to compute the necessary Jacobian and Hessian matrices."@en ;
    askg-onto:inSentence "Automatic differentiation, such as the Autograd package in PyTorch, can be used to compute the necessary Jacobian and Hessian matrices."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-autograd_package,
        askg-data:Entity-automatic_differentiation,
        askg-data:Entity-jacobian_and_hessian_matrices,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-tool .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-782 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Observe from (10) that although we require θ ?to be a stationary point of l, the computation of the gradient is independent of the algorithmic steps used to determine θ ?and hence E."@en ;
    askg-onto:inSentence "Observe from (10) that although we require θ ?to be a stationary point of l, the computation of the gradient is independent of the algorithmic steps used to determine θ ?and hence E."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-the_algorithmic_steps,
        askg-data:Entity-the_gradient .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-783 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Thus to be clear, automatic differentiation, if used, is applied to the objective function itself and not the algorithmic procedure used to find its minimum, different from standard usage in deep learning models."@en ;
    askg-onto:inSentence "Thus to be clear, automatic differentiation, if used, is applied to the objective function itself and not the algorithmic procedure used to find its minimum, different from standard usage in deep learning models."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_differentiation,
        askg-data:Entity-objective_function .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-78-Sentence-784 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The total derivative of L in problem (1) is then"@en ;
    askg-onto:inSentence "The total derivative of L in problem (1) is then"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-l .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-79 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$$\\frac{\\mathrm{d}L(\\mathbf{V},\\boldsymbol{\\theta}^{\\star}(\\mathbf{V}))}{\\mathrm{d}\\mathbf{V}}=\\frac{\\partial L}{\\partial\\mathbf{V}}+\\frac{\\partial L}{\\partial\\boldsymbol{\\theta}^{\\star}}\\frac{\\mathrm{d}\\boldsymbol{\\theta}^{\\star}}{\\mathrm{d}\\mathbf{V}}\\tag{11}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-79-Sentence-791 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-7-Paragraph-79-Sentence-791 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\frac{\\mathrm{d}L(\\mathbf{V},\\boldsymbol{\\theta}^{\\star}(\\mathbf{V}))}{\\mathrm{d}\\mathbf{V}}=\\frac{\\partial L}{\\partial\\mathbf{V}}+\\frac{\\partial L}{\\partial\\boldsymbol{\\theta}^{\\star}}\\frac{\\mathrm{d}\\boldsymbol{\\theta}^{\\star}}{\\mathrm{d}\\mathbf{V}}\\tag{11}$$"@en ;
    askg-onto:inSentence "$$\\frac{\\mathrm{d}L(\\mathbf{V},\\boldsymbol{\\theta}^{\\star}(\\mathbf{V}))}{\\mathrm{d}\\mathbf{V}}=\\frac{\\partial L}{\\partial\\mathbf{V}}+\\frac{\\partial L}{\\partial\\boldsymbol{\\theta}^{\\star}}\\frac{\\mathrm{d}\\boldsymbol{\\theta}^{\\star}}{\\mathrm{d}\\mathbf{V}}\\tag{11}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l .

askg-data:Paper-8e2bc199f9f80305-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "4. Unsupervised Optical Flow Estimation"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-810,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-811,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-813,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-814,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-815,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-816,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-83,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-84,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-85,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-86,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-87,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-89 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Now that we have a means of incorporating a global geometric loss function and a geometric estimation layer into an end-to-end learning framework, we can present our full training pipeline as shown in Figure 1. At a high level, our network computes the optical flow from a pair of images and then estimates the camera motion using an embedded robust geometric optimization algorithm. The estimated camera motion is used to self-supervise the optical flow network, alongside standard photometric, smoothness and consistency losses. This approach can be used to enhance any state-of-the-art flow estimation network, which is currently the approach of Liu et al. [30]. As such, we use their unsupervised training strategy, which can be viewed as an intelligent data augmentation approach, in order to improve performance in highly occluded scenes."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-811,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-812,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-813,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-814,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-815,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-816 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Now that we have a means of incorporating a global geometric loss function and a geometric estimation layer into an end-to-end learning framework, we can present our full training pipeline as shown in Figure 1."@en ;
    askg-onto:inSentence "Now that we have a means of incorporating a global geometric loss function and a geometric estimation layer into an end-to-end learning framework, we can present our full training pipeline as shown in Figure 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_1,
        askg-data:Entity-geometric_estimation_layer,
        askg-data:Entity-global_geometric_loss_function,
        askg-data:Entity-training_pipeline .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "At a high level, our network computes the optical flow from a pair of images and then estimates the camera motion using an embedded robust geometric optimization algorithm."@en ;
    askg-onto:inSentence "At a high level, our network computes the optical flow from a pair of images and then estimates the camera motion using an embedded robust geometric optimization algorithm."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-camera_motion,
        askg-data:Entity-embedded_robust_geometric_optimization_algorithm,
        askg-data:Entity-network,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The estimated camera motion is used to self-supervise the optical flow network, alongside standard photometric, smoothness and consistency losses."@en ;
    askg-onto:inSentence "The estimated camera motion is used to self-supervise the optical flow network, alongside standard photometric, smoothness and consistency losses."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motion,
        askg-data:Entity-optical_flow_network,
        askg-data:Entity-photometric_smoothness_and_consistency_losses .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This approach can be used to enhance any state-of-the-art flow estimation network, which is currently the approach of Liu et al."@en ;
    askg-onto:inSentence "This approach can be used to enhance any state-of-the-art flow estimation network, which is currently the approach of Liu et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flow_estimation_network,
        askg-data:Entity-liu_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "[30]."@en ;
    askg-onto:inSentence "[30]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30 .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-81-Sentence-816 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "As such, we use their unsupervised training strategy, which can be viewed as an intelligent data augmentation approach, in order to improve performance in highly occluded scenes."@en ;
    askg-onto:inSentence "As such, we use their unsupervised training strategy, which can be viewed as an intelligent data augmentation approach, in order to improve performance in highly occluded scenes."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-highly_occluded_scenes,
        askg-data:Entity-intelligent_data_augmentation_approach,
        askg-data:Entity-performance,
        askg-data:Entity-unsupervised_training_strategy .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-810 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "$$L_{0}=\\frac{1}{Y}\\sum_{i=1}^{N}O_{i}\\,\\rho_{\\rm c}\\left({\\bf v}({\\bf p}_{i})-\\bar{\\bf v}({\\bf p}_{i})\\right),\\tag{15}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-810-Sentence-8101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-810-Sentence-8101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{0}=\\frac{1}{Y}\\sum_{i=1}^{N}O_{i}\\,\\rho_{\\rm c}\\left({\\bf v}({\\bf p}_{i})-\\bar{\\bf v}({\\bf p}_{i})\\right),\\tag{15}$$"@en ;
    askg-onto:inSentence "$$L_{0}=\\frac{1}{Y}\\sum_{i=1}^{N}O_{i}\\,\\rho_{\\rm c}\\left({\\bf v}({\\bf p}_{i})-\\bar{\\bf v}({\\bf p}_{i})\\right),\\tag{15}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Crac1y%09extsum_i1no_i%0Dho_c%09ext%09extbfv%09extbfp_i-ar%09extbfv%09extbfp_i%09ext,
        askg-data:Entity-l_0 .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-811 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "where V denotes the flow predicted by the student network and V˜ denotes the flow predicted by the teacher network."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-811-Sentence-8111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-811-Sentence-8111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where V denotes the flow predicted by the student network and V˜ denotes the flow predicted by the teacher network."@en ;
    askg-onto:inSentence "where V denotes the flow predicted by the student network and V˜ denotes the flow predicted by the teacher network."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flow_predicted_by_the_student_network,
        askg-data:Entity-flow_predicted_by_the_teacher_network,
        askg-data:Entity-v .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "We also apply multi-scale training at five different resolutions to handle large motions. The epipolar loss is only applied at the highest resolution. With weights λ• on the loss terms, our total loss for the teacher network is"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812-Sentence-8121,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812-Sentence-8122,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812-Sentence-8123 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812-Sentence-8121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We also apply multi-scale training at five different resolutions to handle large motions."@en ;
    askg-onto:inSentence "We also apply multi-scale training at five different resolutions to handle large motions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-five_different_resolutions,
        askg-data:Entity-multi-scale_training .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812-Sentence-8122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The epipolar loss is only applied at the highest resolution."@en ;
    askg-onto:inSentence "The epipolar loss is only applied at the highest resolution."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_loss,
        askg-data:Entity-highest_resolution .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-812-Sentence-8123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "With weights λ• on the loss terms, our total loss for the teacher network is"@en ;
    askg-onto:inSentence "With weights λ• on the loss terms, our total loss for the teacher network is"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB_on_the_loss_terms,
        askg-data:Entity-teacher_network .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-813 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "$$L_{\\rm t}=\\sum_{i=1}^{5}\\lambda^{i}\\left(\\lambda_{\\rm p}L_{\\rm p}^{i}+\\lambda_{\\rm c}L_{\\rm c}^{i}+\\lambda_{\\rm s}L_{\\rm s}^{i}\\right)+\\lambda_{\\rm e}L_{\\rm e},\\tag{16}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-813-Sentence-8131 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-813-Sentence-8131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{\\rm t}=\\sum_{i=1}^{5}\\lambda^{i}\\left(\\lambda_{\\rm p}L_{\\rm p}^{i}+\\lambda_{\\rm c}L_{\\rm c}^{i}+\\lambda_{\\rm s}L_{\\rm s}^{i}\\right)+\\lambda_{\\rm e}L_{\\rm e},\\tag{16}$$"@en ;
    askg-onto:inSentence "$$L_{\\rm t}=\\sum_{i=1}^{5}\\lambda^{i}\\left(\\lambda_{\\rm p}L_{\\rm p}^{i}+\\lambda_{\\rm c}L_{\\rm c}^{i}+\\lambda_{\\rm s}L_{\\rm s}^{i}\\right)+\\lambda_{\\rm e}L_{\\rm e},\\tag{16}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB_%CE%BB_p_%CE%BB_c_%CE%BB_s_%CE%BB_e,
        askg-data:Entity-l_t .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-814 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "and the total loss for the student network is"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-814-Sentence-8141 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-814-Sentence-8141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and the total loss for the student network is"@en ;
    askg-onto:inSentence "and the total loss for the student network is"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-student_network,
        askg-data:Entity-total_loss .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-815 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "$$L_{\\rm s}=\\sum_{i=1}^{5}\\lambda^{i}\\left(\\lambda_{\\rm p}L_{\\rm p}^{i}+\\lambda_{\\rm c}L_{\\rm c}^{i}+\\lambda_{\\rm s}L_{\\rm s}^{i}+\\lambda_{\\rm o}L_{\\rm o}^{i}\\right)+\\lambda_{\\rm e}L_{\\rm e}.\\tag{17}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-815-Sentence-8151 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-815-Sentence-8151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{\\rm s}=\\sum_{i=1}^{5}\\lambda^{i}\\left(\\lambda_{\\rm p}L_{\\rm p}^{i}+\\lambda_{\\rm c}L_{\\rm c}^{i}+\\lambda_{\\rm s}L_{\\rm s}^{i}+\\lambda_{\\rm o}L_{\\rm o}^{i}\\right)+\\lambda_{\\rm e}L_{\\rm e}.\\tag{17}$$"@en ;
    askg-onto:inSentence "$$L_{\\rm s}=\\sum_{i=1}^{5}\\lambda^{i}\\left(\\lambda_{\\rm p}L_{\\rm p}^{i}+\\lambda_{\\rm c}L_{\\rm c}^{i}+\\lambda_{\\rm s}L_{\\rm s}^{i}+\\lambda_{\\rm o}L_{\\rm o}^{i}\\right)+\\lambda_{\\rm e}L_{\\rm e}.\\tag{17}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l_ci,
        askg-data:Entity-l_e,
        askg-data:Entity-l_oi,
        askg-data:Entity-l_pi,
        askg-data:Entity-l_s,
        askg-data:Entity-metric .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-816 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "Note that Le refers to the epipolar loss defined in (3)."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-816-Sentence-8161 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-816-Sentence-8161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Note that Le refers to the epipolar loss defined in (3)."@en ;
    askg-onto:inSentence "Note that Le refers to the epipolar loss defined in (3)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epipolar_loss,
        askg-data:Entity-le .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Loss functions: Similar to previous works, we use brightness constancy and local smoothness constraints by proposing photometric and smoothness losses. Following Meister et al. [31], we apply a ternary census transform C(·) on the input images, which is robust to real-world violations of the brightness constancy constraint [53, 41]. Since brightness constancy does not hold for occluded pixels, we estimate an occlusion map based on the forward-backward consistency prior [31] and only apply the photometric loss on non-occluded pixels. For these pixels, we also apply a forward-backward consistency loss, to encourage consistent optical flow in both directions."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-821,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-822,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-823,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-824,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-825 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Loss functions: Similar to previous works, we use brightness constancy and local smoothness constraints by proposing photometric and smoothness losses."@en ;
    askg-onto:inSentence "Loss functions: Similar to previous works, we use brightness constancy and local smoothness constraints by proposing photometric and smoothness losses."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brightness_constancy,
        askg-data:Entity-brightness_constancy_and_local_smoothness_constraints,
        askg-data:Entity-local_smoothness_constraints,
        askg-data:Entity-loss_functions,
        askg-data:Entity-photometric_losses,
        askg-data:Entity-smoothness_losses .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Following Meister et al."@en ;
    askg-onto:inSentence "Following Meister et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-meister_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "[31], we apply a ternary census transform C(·) on the input images, which is robust to real-world violations of the brightness constancy constraint [53, 41]."@en ;
    askg-onto:inSentence "[31], we apply a ternary census transform C(·) on the input images, which is robust to real-world violations of the brightness constancy constraint [53, 41]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_images,
        askg-data:Entity-ternary_census_transform_c .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-824 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Since brightness constancy does not hold for occluded pixels, we estimate an occlusion map based on the forward-backward consistency prior [31] and only apply the photometric loss on non-occluded pixels."@en ;
    askg-onto:inSentence "Since brightness constancy does not hold for occluded pixels, we estimate an occlusion map based on the forward-backward consistency prior [31] and only apply the photometric loss on non-occluded pixels."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-forward-backward_consistency_prior,
        askg-data:Entity-non-occluded_pixels,
        askg-data:Entity-occlusion_map,
        askg-data:Entity-photometric_loss .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-82-Sentence-825 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For these pixels, we also apply a forward-backward consistency loss, to encourage consistent optical flow in both directions."@en ;
    askg-onto:inSentence "For these pixels, we also apply a forward-backward consistency loss, to encourage consistent optical flow in both directions."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-forward-backward_consistency_loss,
        askg-data:Entity-optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-83 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Let Miindicate whether the i th pixel is non-occluded and let Z =PN i=1 Mi be the number of non-occluded pixels. We define the photometric loss Lp and the forwardbackward consistency loss Lc as follows:"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-83-Sentence-831,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-83-Sentence-832 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-83-Sentence-831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Let Miindicate whether the i th pixel is non-occluded and let Z =PN i=1 Mi be the number of non-occluded pixels."@en ;
    askg-onto:inSentence "Let Miindicate whether the i th pixel is non-occluded and let Z =PN i=1 Mi be the number of non-occluded pixels."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mi,
        askg-data:Entity-non-occluded_pixel,
        askg-data:Entity-number_of_non-occluded_pixels,
        askg-data:Entity-z .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-83-Sentence-832 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We define the photometric loss Lp and the forwardbackward consistency loss Lc as follows:"@en ;
    askg-onto:inSentence "We define the photometric loss Lp and the forwardbackward consistency loss Lc as follows:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-forwardbackward_consistency_loss_lc,
        askg-data:Entity-photometric_loss_lp .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-84 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$L_{\\rm p}=\\frac{1}{Z}\\sum_{i=1}^{N}M_{i}\\,\\rho_{\\rm c}\\left(C(I,{\\bf p}_{i})-C(I^{\\prime},{\\bf p}_{i}+{\\bf v}_{i})\\right)\\tag{12}$$ $$L_{\\rm c}=\\frac{1}{Z}\\sum_{i=1}^{N}M_{i}\\,\\rho_{\\rm c}\\left({\\bf v}^{\\rm f}({\\bf p}_{i})+{\\bf v}^{\\rm b}({\\bf p}_{i}+{\\bf v}_{i})\\right)\\tag{13}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-84-Sentence-841 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-84-Sentence-841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{\\rm p}=\\frac{1}{Z}\\sum_{i=1}^{N}M_{i}\\,\\rho_{\\rm c}\\left(C(I,{\\bf p}_{i})-C(I^{\\prime},{\\bf p}_{i}+{\\bf v}_{i})\\right)\\tag{12}$$ $$L_{\\rm c}=\\frac{1}{Z}\\sum_{i=1}^{N}M_{i}\\,\\rho_{\\rm c}\\left({\\bf v}^{\\rm f}({\\bf p}_{i})+{\\bf v}^{\\rm b}({\\bf p}_{i}+{\\bf v}_{i})\\right)\\tag{13}$$"@en ;
    askg-onto:inSentence "$$L_{\\rm p}=\\frac{1}{Z}\\sum_{i=1}^{N}M_{i}\\,\\rho_{\\rm c}\\left(C(I,{\\bf p}_{i})-C(I^{\\prime},{\\bf p}_{i}+{\\bf v}_{i})\\right)\\tag{12}$$ $$L_{\\rm c}=\\frac{1}{Z}\\sum_{i=1}^{N}M_{i}\\,\\rho_{\\rm c}\\left({\\bf v}^{\\rm f}({\\bf p}_{i})+{\\bf v}^{\\rm b}({\\bf p}_{i}+{\\bf v}_{i})\\right)\\tag{13}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ci%0Dm_ackprimef_p_if_v_i,
        askg-data:Entity-cif_p_i,
        askg-data:Entity-concept,
        askg-data:Entity-f_v%0Dm_bf_p_if_v_i,
        askg-data:Entity-f_v%0Dm_ff_p_i,
        askg-data:Entity-l_c,
        askg-data:Entity-l_p,
        askg-data:Entity-metric .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-85 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "where ρc(z) = 1n Pn i=1(z 2 i + 2) γis the element-wise average of the robust generalized Charbonnier penalty function [43] with = 10−3and γ = 0.45, and V fand V bare the predicted forward and backward optical flow, indexed by image space coordinates."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-85-Sentence-851 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-85-Sentence-851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where ρc(z) = 1n Pn i=1(z 2 i + 2) γis the element-wise average of the robust generalized Charbonnier penalty function [43] with = 10−3and γ = 0.45, and V fand V bare the predicted forward and backward optical flow, indexed by image space coordinates."@en ;
    askg-onto:inSentence "where ρc(z) = 1n Pn i=1(z 2 i + 2) γis the element-wise average of the robust generalized Charbonnier penalty function [43] with = 10−3and γ = 0.45, and V fand V bare the predicted forward and backward optical flow, indexed by image space coordinates."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%81cz,
        askg-data:Entity-the_predicted_backward_optical_flow,
        askg-data:Entity-the_predicted_forward_optical_flow,
        askg-data:Entity-the_robust_generalized_charbonnier_penalty_function .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-86 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "To encourage the predicted optical flow to be locally smooth, we apply an edge-aware smoothness loss [16], based on the assumption that motion boundaries often coincide with image edges. The smoothness loss is defined"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-86-Sentence-861,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-86-Sentence-862 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-86-Sentence-861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To encourage the predicted optical flow to be locally smooth, we apply an edge-aware smoothness loss [16], based on the assumption that motion boundaries often coincide with image edges."@en ;
    askg-onto:inSentence "To encourage the predicted optical flow to be locally smooth, we apply an edge-aware smoothness loss [16], based on the assumption that motion boundaries often coincide with image edges."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_edges,
        askg-data:Entity-motion_boundaries,
        askg-data:Entity-optical_flow,
        askg-data:Entity-smoothness_loss .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-86-Sentence-862 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The smoothness loss is defined"@en ;
    askg-onto:inSentence "The smoothness loss is defined"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-smoothness_loss,
        askg-data:Entity-undefined .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-87 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$L_{\\rm s}=\\frac{1}{2N}\\sum_{i=1}^{N}\\left(\\sum_{a\\in\\{u,v\\}}e^{-\\frac{\\alpha}{3}\\left\\|\\frac{\\partial I({\\bf p}_{i})}{\\partial a}\\right\\|_{1}}\\left\\|\\frac{\\partial{\\bf v}_{i}}{\\partial a}\\right\\|_{1}\\right).\\tag{14}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-87-Sentence-871 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-87-Sentence-871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{\\rm s}=\\frac{1}{2N}\\sum_{i=1}^{N}\\left(\\sum_{a\\in\\{u,v\\}}e^{-\\frac{\\alpha}{3}\\left\\|\\frac{\\partial I({\\bf p}_{i})}{\\partial a}\\right\\|_{1}}\\left\\|\\frac{\\partial{\\bf v}_{i}}{\\partial a}\\right\\|_{1}\\right).\\tag{14}$$"@en ;
    askg-onto:inSentence "$$L_{\\rm s}=\\frac{1}{2N}\\sum_{i=1}^{N}\\left(\\sum_{a\\in\\{u,v\\}}e^{-\\frac{\\alpha}{3}\\left\\|\\frac{\\partial I({\\bf p}_{i})}{\\partial a}\\right\\|_{1}}\\left\\|\\frac{\\partial{\\bf v}_{i}}{\\partial a}\\right\\|_{1}\\right).\\tag{14}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-metric .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Training strategy: We adopt the training strategy of Liu and co-authors [30, 29] by having a teacher network and a student network in order to artificially generate occlusions and apply supervision on these regions. The teacher network is first trained until convergence with the proposed loss functions. The output of this network is then used to supervise the training of a student network, whose weights are initialized from the teacher network. Following Liu et al. [30], we generate occluded regions by computing SLIC superpixels [1] and replacing randomly-selected superpixels with random noise. Another source of generated occlusions comes from randomly cropping the input images [29]. Pixels warped outside of the cropped image frame are considered to be occluded. These artificial occlusions are only used in the student network, where the output of the teacher network is able to supervise the predicted flow. This makes it possible for the student network to learn to estimate flow more accurately in occluded regions."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-881,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-882,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-883,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-884,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-885,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-886,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-887,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-888,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-889 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-881 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Training strategy: We adopt the training strategy of Liu and co-authors [30, 29] by having a teacher network and a student network in order to artificially generate occlusions and apply supervision on these regions."@en ;
    askg-onto:inSentence "Training strategy: We adopt the training strategy of Liu and co-authors [30, 29] by having a teacher network and a student network in order to artificially generate occlusions and apply supervision on these regions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-liu_and_co-authors,
        askg-data:Entity-occlusions,
        askg-data:Entity-regions,
        askg-data:Entity-student_network,
        askg-data:Entity-teacher_network,
        askg-data:Entity-training_strategy .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-882 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The teacher network is first trained until convergence with the proposed loss functions."@en ;
    askg-onto:inSentence "The teacher network is first trained until convergence with the proposed loss functions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proposed_loss_functions,
        askg-data:Entity-teacher_network .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-883 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The output of this network is then used to supervise the training of a student network, whose weights are initialized from the teacher network."@en ;
    askg-onto:inSentence "The output of this network is then used to supervise the training of a student network, whose weights are initialized from the teacher network."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network,
        askg-data:Entity-student_network,
        askg-data:Entity-teacher_network .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-884 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Following Liu et al."@en ;
    askg-onto:inSentence "Following Liu et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-liu_et_al .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-885 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "[30], we generate occluded regions by computing SLIC superpixels [1] and replacing randomly-selected superpixels with random noise."@en ;
    askg-onto:inSentence "[30], we generate occluded regions by computing SLIC superpixels [1] and replacing randomly-selected superpixels with random noise."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-occluded_regions,
        askg-data:Entity-slic_superpixels .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-886 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Another source of generated occlusions comes from randomly cropping the input images [29]."@en ;
    askg-onto:inSentence "Another source of generated occlusions comes from randomly cropping the input images [29]."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cropping_the_input_images,
        askg-data:Entity-occlusions .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-887 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Pixels warped outside of the cropped image frame are considered to be occluded."@en ;
    askg-onto:inSentence "Pixels warped outside of the cropped image frame are considered to be occluded."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-occluded,
        askg-data:Entity-pixels .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-888 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "These artificial occlusions are only used in the student network, where the output of the teacher network is able to supervise the predicted flow."@en ;
    askg-onto:inSentence "These artificial occlusions are only used in the student network, where the output of the teacher network is able to supervise the predicted flow."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_occlusions,
        askg-data:Entity-predicted_flow,
        askg-data:Entity-student_network,
        askg-data:Entity-teacher_network .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-88-Sentence-889 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "This makes it possible for the student network to learn to estimate flow more accurately in occluded regions."@en ;
    askg-onto:inSentence "This makes it possible for the student network to learn to estimate flow more accurately in occluded regions."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flow,
        askg-data:Entity-occluded_regions,
        askg-data:Entity-student_network .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-89 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Let Oiindicate the i th pixel that is occluded in the synthetically-generated image but non-occluded in the original image, and let Y =PN i=1 Oi denote the number of such pixels. We define the occlusion loss function for training the student network as"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-89-Sentence-891,
        askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-89-Sentence-892 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-89-Sentence-891 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Let Oiindicate the i th pixel that is occluded in the synthetically-generated image but non-occluded in the original image, and let Y =PN i=1 Oi denote the number of such pixels."@en ;
    askg-onto:inSentence "Let Oiindicate the i th pixel that is occluded in the synthetically-generated image but non-occluded in the original image, and let Y =PN i=1 Oi denote the number of such pixels."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-oi,
        askg-data:Entity-the_i_th_pixel_that_is_occluded_in_the_synthetically-generated_image,
        askg-data:Entity-the_number_of_such_pixels,
        askg-data:Entity-y .

askg-data:Paper-8e2bc199f9f80305-Section-8-Paragraph-89-Sentence-892 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We define the occlusion loss function for training the student network as"@en ;
    askg-onto:inSentence "We define the occlusion loss function for training the student network as"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-occlusion_loss_function,
        askg-data:Entity-training_the_student_network .

askg-data:Paper-8e2bc199f9f80305-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "5. Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-93,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Datasets: We evaluate our method for unsupervised optical flow estimation on two datasets: the standard KITTI 2012 Flow dataset [15] and the more challenging RGB-D SLAM dataset [42]. The KITTI dataset [14] contains outdoor road scenes captured by a car-mounted stereo camera rig. Since we are only estimating rigid flow, we evaluate on the KITTI 2012 Flow subset [15], which has 194 training images with sparse ground-truth optical flow and 195 test images. We do not train on this data, instead we use the KITTI Visual Odometry (VO) dataset which has similar characteristics. This has 22 sequences with 87 060 consecutive image pairs. We leave out sequences 9 and 10 for motion evaluation and use the remainder for training. The RGB-D SLAM dataset [42] is an indoor SLAM dataset with ground-truth pose and depth, from which optical flow can be calculated. The dataset contains varied camera motions, many featureless regions, repetitive patterns, and motion blur, which are well-known to be challenging for optical flow estimation. We select all sequences from the Handheld SLAM, Robot SLAM, and 3D Object Reconstruction categories. We set aside \"fr1/360\", \"fr2/360 hemisphere\", \"fr2/pioneer 360\", and \"fr3/teddy\" for testing. While most of these sequences are static, we remove those few frames that contain dynamic objects. For the training data, we select image pairs with diverse flow ranges, randomly sampling equally from buckets with a maximum flow of 5–40 pixels, 40–80 pixels and 80–120 pixels. For the test data, we sub-sample the video frames such that the baseline between each image pair is at least 3cm. We obtain training and test sets of 29 106 and 1 667 image pairs."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-911,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9110,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9111,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9112,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9113,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9114,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-912,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-913,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-914,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-915,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-916,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-917,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-918,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-919 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Datasets: We evaluate our method for unsupervised optical flow estimation on two datasets: the standard KITTI 2012 Flow dataset [15] and the more challenging RGB-D SLAM dataset [42]."@en ;
    askg-onto:inSentence "Datasets: We evaluate our method for unsupervised optical flow estimation on two datasets: the standard KITTI 2012 Flow dataset [15] and the more challenging RGB-D SLAM dataset [42]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_2012_flow_dataset,
        askg-data:Entity-rgb-d_slam_dataset,
        askg-data:Entity-unsupervised_optical_flow_estimation .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "We set aside \"fr1/360\", \"fr2/360 hemisphere\", \"fr2/pioneer 360\", and \"fr3/teddy\" for testing."@en ;
    askg-onto:inSentence "We set aside \"fr1/360\", \"fr2/360 hemisphere\", \"fr2/pioneer 360\", and \"fr3/teddy\" for testing."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fr1360,
        askg-data:Entity-fr2360_hemisphere,
        askg-data:Entity-fr2pioneer_360,
        askg-data:Entity-fr3teddy,
        askg-data:Entity-testing .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "While most of these sequences are static, we remove those few frames that contain dynamic objects."@en ;
    askg-onto:inSentence "While most of these sequences are static, we remove those few frames that contain dynamic objects."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_objects,
        askg-data:Entity-frames,
        askg-data:Entity-sequences,
        askg-data:Entity-static .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "For the training data, we select image pairs with diverse flow ranges, randomly sampling equally from buckets with a maximum flow of 5–40 pixels, 40–80 pixels and 80–120 pixels."@en ;
    askg-onto:inSentence "For the training data, we select image pairs with diverse flow ranges, randomly sampling equally from buckets with a maximum flow of 5–40 pixels, 40–80 pixels and 80–120 pixels."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4080_pixels,
        askg-data:Entity-540_pixels,
        askg-data:Entity-80120_pixels,
        askg-data:Entity-buckets,
        askg-data:Entity-image_pairs,
        askg-data:Entity-maximum_flow,
        askg-data:Entity-training_data .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "For the test data, we sub-sample the video frames such that the baseline between each image pair is at least 3cm."@en ;
    askg-onto:inSentence "For the test data, we sub-sample the video frames such that the baseline between each image pair is at least 3cm."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3cm,
        askg-data:Entity-image_pair,
        askg-data:Entity-test_data,
        askg-data:Entity-video_frames .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-9114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "We obtain training and test sets of 29 106 and 1 667 image pairs."@en ;
    askg-onto:inSentence "We obtain training and test sets of 29 106 and 1 667 image pairs."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-29_106_and_1_667_image_pairs,
        askg-data:Entity-training_and_test_sets .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The KITTI dataset [14] contains outdoor road scenes captured by a car-mounted stereo camera rig."@en ;
    askg-onto:inSentence "The KITTI dataset [14] contains outdoor road scenes captured by a car-mounted stereo camera rig."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_dataset,
        askg-data:Entity-outdoor_road_scenes .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Since we are only estimating rigid flow, we evaluate on the KITTI 2012 Flow subset [15], which has 194 training images with sparse ground-truth optical flow and 195 test images."@en ;
    askg-onto:inSentence "Since we are only estimating rigid flow, we evaluate on the KITTI 2012 Flow subset [15], which has 194 training images with sparse ground-truth optical flow and 195 test images."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-194_training_images,
        askg-data:Entity-195_test_images,
        askg-data:Entity-dataset,
        askg-data:Entity-kitti_2012_flow_subset,
        askg-data:Entity-metric,
        askg-data:Entity-sparse_ground-truth_optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We do not train on this data, instead we use the KITTI Visual Odometry (VO) dataset which has similar characteristics."@en ;
    askg-onto:inSentence "We do not train on this data, instead we use the KITTI Visual Odometry (VO) dataset which has similar characteristics."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-kitti_visual_odometry_vo_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-915 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This has 22 sequences with 87 060 consecutive image pairs."@en ;
    askg-onto:inSentence "This has 22 sequences with 87 060 consecutive image pairs."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-22_sequences,
        askg-data:Entity-87_060_consecutive_image_pairs .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-916 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We leave out sequences 9 and 10 for motion evaluation and use the remainder for training."@en ;
    askg-onto:inSentence "We leave out sequences 9 and 10 for motion evaluation and use the remainder for training."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-motion_evaluation,
        askg-data:Entity-sequences_9_and_10,
        askg-data:Entity-the_remainder,
        askg-data:Entity-training .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-917 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The RGB-D SLAM dataset [42] is an indoor SLAM dataset with ground-truth pose and depth, from which optical flow can be calculated."@en ;
    askg-onto:inSentence "The RGB-D SLAM dataset [42] is an indoor SLAM dataset with ground-truth pose and depth, from which optical flow can be calculated."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth,
        askg-data:Entity-ground-truth_pose,
        askg-data:Entity-indoor_slam_dataset,
        askg-data:Entity-optical_flow,
        askg-data:Entity-rgb-d_slam_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-918 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "The dataset contains varied camera motions, many featureless regions, repetitive patterns, and motion blur, which are well-known to be challenging for optical flow estimation."@en ;
    askg-onto:inSentence "The dataset contains varied camera motions, many featureless regions, repetitive patterns, and motion blur, which are well-known to be challenging for optical flow estimation."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_motions,
        askg-data:Entity-featureless_regions,
        askg-data:Entity-motion_blur,
        askg-data:Entity-optical_flow_estimation,
        askg-data:Entity-repetitive_patterns .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-91-Sentence-919 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "We select all sequences from the Handheld SLAM, Robot SLAM, and 3D Object Reconstruction categories."@en ;
    askg-onto:inSentence "We select all sequences from the Handheld SLAM, Robot SLAM, and 3D Object Reconstruction categories."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_object_reconstruction,
        askg-data:Entity-handheld_slam,
        askg-data:Entity-robot_slam,
        askg-data:Entity-sequences .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Metrics: For optical flow, we provide a comparison with a range of recent supervised and unsupervised methods using the standard Average End Point Error (AEPE) metric, given by AEPE =1N PN i=1 kv i − v igtk, where v iis the predicted flow at the i th pixel, v igt is the ground-truth flow, and N is the number of ground-truth pixels. For camera motion evaluation, we use the standard KITTI VO dataset evaluation criterion [15], which evaluates on sub-sequences of length (100, 200, *. . .* , 800) meters, and report the average relative rotational and translational errors for the test"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-921,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-922,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-923,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-924 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Metrics: For optical flow, we provide a comparison with a range of recent supervised and unsupervised methods using the standard Average End Point Error (AEPE) metric, given by AEPE =1N PN i=1 kv i − v igtk, where v iis the predicted flow at the i th pixel, v igt is the ground-truth flow, and N is the number of ground-truth pixels."@en ;
    askg-onto:inSentence "Metrics: For optical flow, we provide a comparison with a range of recent supervised and unsupervised methods using the standard Average End Point Error (AEPE) metric, given by AEPE =1N PN i=1 kv i − v igtk, where v iis the predicted flow at the i th pixel, v igt is the ground-truth flow, and N is the number of ground-truth pixels."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_end_point_error_aepe,
        askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-optical_flow,
        askg-data:Entity-supervised_methods,
        askg-data:Entity-unsupervised_methods .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For camera motion evaluation, we use the standard KITTI VO dataset evaluation criterion [15], which evaluates on sub-sequences of length (100, 200, *."@en ;
    askg-onto:inSentence "For camera motion evaluation, we use the standard KITTI VO dataset evaluation criterion [15], which evaluates on sub-sequences of length (100, 200, *."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_criterion,
        askg-data:Entity-kitti_vo_dataset .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company,
        askg-data:Entity-dataset,
        askg-data:Entity-model,
        askg-data:Entity-paper,
        askg-data:Entity-person,
        askg-data:Entity-research_field,
        askg-data:Entity-software,
        askg-data:Entity-study .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-92-Sentence-924 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text ".* , 800) meters, and report the average relative rotational and translational errors for the test"@en ;
    askg-onto:inSentence ".* , 800) meters, and report the average relative rotational and translational errors for the test"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_relative_rotational_and_translational_errors,
        askg-data:Entity-test .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-93 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "| | | KITTI 2012 (all) | | | KITTI 2012 (noc) | | RGBD\\-SLAM | |-------|--------------------|--------------------|-------|--------|--------------------|------------|--------------| | | Method | train | test | train | test | validation | test | | | SpyNet\\-ft [37] | (4.13) | 4.10 | - | 2.00 | - | - | | sed | FlowNet2\\-ft [24] | (1.28) | 1.80 | - | 1.00 | - | - | | vi er | PWC\\-Net [44] | 4.14 | - | - | - | 4.84 | 5.41 | | up S | PWC\\-Net\\-ft [44] | (1.45) | 1.70 | - | 0.90 | 1.22 | 6.71 | | | PWC\\-Net\\-ft* [44] | - | - | - | - | 3.64 | 5.05∗ | | | SelFlow\\-ft [30] | (0.76) | 1.50 | - | - | - | - | | | UnsupFlownet [25] | 11.30 | 9.90 | 4.30 | 4.60 | - | - | | | DSTFlow [38] | 10.43 | 12.40 | 3.29 | 4.00 | - | - | | | DF\\-Net [58] | 3.54 | 4.40 | - | - | - | - | | | UnFlow [31] | 3.29 | - | 1.26 | - | - | - | | sed | OAFlow [46] | 3.55 | 4.20 | - | - | - | - | | rvi | EPIFlow [55] | (2.51) | 3.40 | (0.99) | 1.30 | 5.16† | 6.54† | | e up | DDFlow [29] | 2.35 | 3.00 | 1.02 | 1.10 | 5.01† | 6.51† | | s Un | SelFlow [30] | 1.69 | 2.20 | 0.91 | 1.00 | 4.95† | 6.47† | | | Ours\\-Baseline | 3.49 | - | 1.24 | - | 5.44 | 6.89 | | | Ours\\-Epipolar | 2.61 | - | 0.99 | - | 4.82 | 6.33 | | | Ours\\-Occlusion | 1.97 | - | 1.19 | - | 4.95 | 6.47 | | Ours | | 1.56 | 1.90 | 0.94 | 1.00 | 4.63 | 6.12 |"@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-93-Sentence-931 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-93-Sentence-931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | | KITTI 2012 (all) | | | KITTI 2012 (noc) | | RGBD\\-SLAM | |-------|--------------------|--------------------|-------|--------|--------------------|------------|--------------| | | Method | train | test | train | test | validation | test | | | SpyNet\\-ft [37] | (4.13) | 4.10 | - | 2.00 | - | - | | sed | FlowNet2\\-ft [24] | (1.28) | 1.80 | - | 1.00 | - | - | | vi er | PWC\\-Net [44] | 4.14 | - | - | - | 4.84 | 5.41 | | up S | PWC\\-Net\\-ft [44] | (1.45) | 1.70 | - | 0.90 | 1.22 | 6.71 | | | PWC\\-Net\\-ft* [44] | - | - | - | - | 3.64 | 5.05∗ | | | SelFlow\\-ft [30] | (0.76) | 1.50 | - | - | - | - | | | UnsupFlownet [25] | 11.30 | 9.90 | 4.30 | 4.60 | - | - | | | DSTFlow [38] | 10.43 | 12.40 | 3.29 | 4.00 | - | - | | | DF\\-Net [58] | 3.54 | 4.40 | - | - | - | - | | | UnFlow [31] | 3.29 | - | 1.26 | - | - | - | | sed | OAFlow [46] | 3.55 | 4.20 | - | - | - | - | | rvi | EPIFlow [55] | (2.51) | 3.40 | (0.99) | 1.30 | 5.16† | 6.54† | | e up | DDFlow [29] | 2.35 | 3.00 | 1.02 | 1.10 | 5.01† | 6.51† | | s Un | SelFlow [30] | 1.69 | 2.20 | 0.91 | 1.00 | 4.95† | 6.47† | | | Ours\\-Baseline | 3.49 | - | 1.24 | - | 5.44 | 6.89 | | | Ours\\-Epipolar | 2.61 | - | 0.99 | - | 4.82 | 6.33 | | | Ours\\-Occlusion | 1.97 | - | 1.19 | - | 4.95 | 6.47 | | Ours | | 1.56 | 1.90 | 0.94 | 1.00 | 4.63 | 6.12 |"@en ;
    askg-onto:inSentence "| | | KITTI 2012 (all) | | | KITTI 2012 (noc) | | RGBD\\-SLAM | |-------|--------------------|--------------------|-------|--------|--------------------|------------|--------------| | | Method | train | test | train | test | validation | test | | | SpyNet\\-ft [37] | (4.13) | 4.10 | - | 2.00 | - | - | | sed | FlowNet2\\-ft [24] | (1.28) | 1.80 | - | 1.00 | - | - | | vi er | PWC\\-Net [44] | 4.14 | - | - | - | 4.84 | 5.41 | | up S | PWC\\-Net\\-ft [44] | (1.45) | 1.70 | - | 0.90 | 1.22 | 6.71 | | | PWC\\-Net\\-ft* [44] | - | - | - | - | 3.64 | 5.05∗ | | | SelFlow\\-ft [30] | (0.76) | 1.50 | - | - | - | - | | | UnsupFlownet [25] | 11.30 | 9.90 | 4.30 | 4.60 | - | - | | | DSTFlow [38] | 10.43 | 12.40 | 3.29 | 4.00 | - | - | | | DF\\-Net [58] | 3.54 | 4.40 | - | - | - | - | | | UnFlow [31] | 3.29 | - | 1.26 | - | - | - | | sed | OAFlow [46] | 3.55 | 4.20 | - | - | - | - | | rvi | EPIFlow [55] | (2.51) | 3.40 | (0.99) | 1.30 | 5.16† | 6.54† | | e up | DDFlow [29] | 2.35 | 3.00 | 1.02 | 1.10 | 5.01† | 6.51† | | s Un | SelFlow [30] | 1.69 | 2.20 | 0.91 | 1.00 | 4.95† | 6.47† | | | Ours\\-Baseline | 3.49 | - | 1.24 | - | 5.44 | 6.89 | | | Ours\\-Epipolar | 2.61 | - | 0.99 | - | 4.82 | 6.33 | | | Ours\\-Occlusion | 1.97 | - | 1.19 | - | 4.95 | 6.47 | | Ours | | 1.56 | 1.90 | 0.94 | 1.00 | 4.63 | 6.12 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ddflow,
        askg-data:Entity-df-net,
        askg-data:Entity-dstflow,
        askg-data:Entity-epiflow,
        askg-data:Entity-flownet2-ft,
        askg-data:Entity-method,
        askg-data:Entity-oaflow,
        askg-data:Entity-ours,
        askg-data:Entity-ours-baseline,
        askg-data:Entity-ours-epipolar,
        askg-data:Entity-ours-occlusion,
        askg-data:Entity-pwc-net,
        askg-data:Entity-pwc-net-ft,
        askg-data:Entity-selflow,
        askg-data:Entity-selflow-ft,
        askg-data:Entity-spynet-ft,
        askg-data:Entity-unflow,
        askg-data:Entity-unsupflownet .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Table 1. Optical flow performance comparison on the KITTI 2012 and RGBD-SLAM datasets. We report the mean End Point Error (EPE) of the predicted optical flow. Parentheses and the suffix -ft indicate that the models were fine-tuned on the data, missing entries (–) indicate that the results were not reported, asterisks (∗) indicate that the method uses the test set to select the best performing model, and daggers (†) indicate that the results are pre-trained with the Ours-Baseline approach and finetuned with the losses proposed in the papers."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-941,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-942,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-943,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-944 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 1."@en ;
    askg-onto:inSentence "Table 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-942 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Optical flow performance comparison on the KITTI 2012 and RGBD-SLAM datasets."@en ;
    askg-onto:inSentence "Optical flow performance comparison on the KITTI 2012 and RGBD-SLAM datasets."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_2012,
        askg-data:Entity-optical_flow_performance,
        askg-data:Entity-rgbd-slam .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-943 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We report the mean End Point Error (EPE) of the predicted optical flow."@en ;
    askg-onto:inSentence "We report the mean End Point Error (EPE) of the predicted optical flow."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-end_point_error_epe,
        askg-data:Entity-predicted_optical_flow .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-94-Sentence-944 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Parentheses and the suffix -ft indicate that the models were fine-tuned on the data, missing entries (–) indicate that the results were not reported, asterisks (∗) indicate that the method uses the test set to select the best performing model, and daggers (†) indicate that the results are pre-trained with the Ours-Baseline approach and finetuned with the losses proposed in the papers."@en ;
    askg-onto:inSentence "Parentheses and the suffix -ft indicate that the models were fine-tuned on the data, missing entries (–) indicate that the results were not reported, asterisks (∗) indicate that the method uses the test set to select the best performing model, and daggers (†) indicate that the results are pre-trained with the Ours-Baseline approach and finetuned with the losses proposed in the papers."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-losses_proposed_in_the_papers,
        askg-data:Entity-method,
        askg-data:Entity-models,
        askg-data:Entity-ours-baseline_approach,
        askg-data:Entity-results,
        askg-data:Entity-test_set .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "sequences 9 and 10 in Table 2. Let ∆Tij ∈ SE(3) denote the delta pose difference between the estimated pose and the ground-truth pose given a pair of adjacent frames i and j. The delta pose difference is given by ∆Tij = (T −1 gt,iTgt,j ) −1(T −1 iTj ), where Ti and Tj denote the poses at frames (*i, j*). The relative translation error is given by t ierr =1N Pij ktrans(∆Tij )k and relative rotation error is given by rerr = 1 N Pij arccos(0.5(trace(rot(∆Tij )) − 1)), where trans(·) and rot(·) extract the translation and the rotation parts of ∆Tij ."@en ;
    askg-onto:hasSentence askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-951,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-952,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-953,
        askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-954 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "sequences 9 and 10 in Table 2."@en ;
    askg-onto:inSentence "sequences 9 and 10 in Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-952 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let ∆Tij ∈ SE(3) denote the delta pose difference between the estimated pose and the ground-truth pose given a pair of adjacent frames i and j."@en ;
    askg-onto:inSentence "Let ∆Tij ∈ SE(3) denote the delta pose difference between the estimated pose and the ground-truth pose given a pair of adjacent frames i and j."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adjacent_frames,
        askg-data:Entity-delta_pose_difference,
        askg-data:Entity-pose,
        askg-data:Entity-tij .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-953 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The delta pose difference is given by ∆Tij = (T −1 gt,iTgt,j ) −1(T −1 iTj ), where Ti and Tj denote the poses at frames (*i, j*)."@en ;
    askg-onto:inSentence "The delta pose difference is given by ∆Tij = (T −1 gt,iTgt,j ) −1(T −1 iTj ), where Ti and Tj denote the poses at frames (*i, j*)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-delta_pose_difference,
        askg-data:Entity-the_poses_at_frames_i_j .

askg-data:Paper-8e2bc199f9f80305-Section-9-Paragraph-95-Sentence-954 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The relative translation error is given by t ierr =1N Pij ktrans(∆Tij )k and relative rotation error is given by rerr = 1 N Pij arccos(0.5(trace(rot(∆Tij )) − 1)), where trans(·) and rot(·) extract the translation and the rotation parts of ∆Tij ."@en ;
    askg-onto:inSentence "The relative translation error is given by t ierr =1N Pij ktrans(∆Tij )k and relative rotation error is given by rerr = 1 N Pij arccos(0.5(trace(rot(∆Tij )) − 1)), where trans(·) and rot(·) extract the translation and the rotation parts of ∆Tij ."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-relative_rotation_error,
        askg-data:Entity-relative_translation_error,
        askg-data:Entity-rot,
        askg-data:Entity-rotation_part_of_tij,
        askg-data:Entity-trans,
        askg-data:Entity-translation_part_of_tij .

askg-data:Entity-%CE%B8 rdfs:label "θ"@en,
        "θ∗"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-11 rdfs:label "11"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2 rdfs:label "2"@en ;
    askg-onto:entityType "Concept"@en,
        "Index"@en .

askg-data:Entity-2006 rdfs:label "2006"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2015 rdfs:label "2015"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-6 rdfs:label "6"@en ;
    askg-onto:entityType "Concept"@en,
        "Index"@en .

askg-data:Entity-8-point_algorithm rdfs:label "8-point algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-alexey_dosovitskiy rdfs:label "Alexey Dosovitskiy"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-andreas_geiger rdfs:label "Andreas Geiger"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-andres_bruhn rdfs:label "Andres Bruhn"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-andrew_zisserman rdfs:label "Andrew Zisserman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-arg_min_function rdfs:label "arg min function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en,
        "Artificial intelligence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arxiv_preprint rdfs:label "arXiv preprint"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-automatic_differentiation rdfs:label "Automatic differentiation"@en,
        "automatic differentiation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-baseline_model rdfs:label "baseline model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-basura_fernando rdfs:label "Basura Fernando"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bi-level_optimization rdfs:label "bi-level optimization"@en ;
    askg-onto:entityType "Method"@en,
        "Research Field"@en .

askg-data:Entity-camera_motions rdfs:label "camera motions"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-company rdfs:label "Company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-convolutional_neural_networks_cnns rdfs:label "convolutional neural networks (CNNs)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-daniel_cremers rdfs:label "Daniel Cremers"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dataset_y rdfs:label "Dataset Y"@en,
        "Dataset_Y"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-ddflow rdfs:label "DDFlow"@en,
        "Ddflow"@en ;
    askg-onto:entityType "Model"@en,
        "Tool"@en .

askg-data:Entity-deep_learning_context rdfs:label "deep learning context"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-deep_learning_framework rdfs:label "deep learning framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-delta_pose_difference rdfs:label "delta pose difference"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-deqing_sun rdfs:label "Deqing Sun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-df-net rdfs:label "DF-Net"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-differentiable_optimization rdfs:label "Differentiable optimization"@en,
        "differentiable optimization"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-domain rdfs:label "Domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-dylan_campbell rdfs:label "Dylan Campbell"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-e rdfs:label "E"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eddy_ilg rdfs:label "Eddy Ilg"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-error rdfs:label "error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-essential_matrix_estimation_layer rdfs:label "essential matrix estimation layer"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-experiment rdfs:label "Experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-f rdfs:label "f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-featureless_regions rdfs:label "featureless regions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-figure_1 rdfs:label "Figure 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_3 rdfs:label "Figure 3"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-finding rdfs:label "Finding"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-finding_1 rdfs:label "Finding 1"@en,
        "Finding_1"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-flow rdfs:label "Flow"@en,
        "flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-frames rdfs:label "frames"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-function rdfs:label "Function"@en,
        "function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fundamental_matrix rdfs:label "fundamental matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometric_optimization_layer rdfs:label "geometric optimization layer"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-global_geometric_loss_function rdfs:label "global geometric loss function"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-gould_et_al rdfs:label "Gould et al."@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-gradient rdfs:label "gradient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradients rdfs:label "gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ground-truth_pose rdfs:label "ground-truth pose"@en ;
    askg-onto:entityType "Dataset"@en,
        "Metric"@en .

askg-data:Entity-gx rdfs:label "g(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-huangying_zhan rdfs:label "Huangying Zhan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ian_reid rdfs:label "Ian Reid"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-image_i rdfs:label "image I"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-image_i_0 rdfs:label "image I 0"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-image_pair rdfs:label "image pair"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_pyramid rdfs:label "image pyramid"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_images rdfs:label "input images"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-irwin_king rdfs:label "Irwin King"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jia_xu rdfs:label "Jia Xu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-joachim_weickert rdfs:label "Joachim Weickert"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-joint_pattern_recognition_symposium rdfs:label "Joint Pattern Recognition Symposium"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-k_0 rdfs:label "K 0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kitti_vo rdfs:label "KITTI VO"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-layers rdfs:label "layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_function rdfs:label "loss function"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-meister_et_al rdfs:label "Meister et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-occluded_regions rdfs:label "occluded regions"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-occlusions rdfs:label "occlusions"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-optical_flow_networks rdfs:label "optical flow networks"@en ;
    askg-onto:entityType "Method"@en,
        "System"@en .

askg-data:Entity-optical_flow_prediction_error rdfs:label "Optical flow prediction error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-optical_flow_v rdfs:label "optical flow V"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization rdfs:label "Optimization"@en,
        "optimization"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-organization rdfs:label "Organization"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-our_flow rdfs:label "Our flow"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-ours-epipolar rdfs:label "Ours-Epipolar"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-p_0 rdfs:label "P 0"@en,
        "p 0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pengpeng_liu rdfs:label "Pengpeng Liu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-performance rdfs:label "performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-philip_lenz rdfs:label "Philip Lenz"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pixel rdfs:label "pixel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel_coordinate rdfs:label "pixel coordinate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-predicted_flow rdfs:label "predicted flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-predicted_optical_flow rdfs:label "predicted optical flow"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-problem rdfs:label "problem"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-qualitative_results rdfs:label "Qualitative results"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-ransac_procedure rdfs:label "RANSAC procedure"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-results rdfs:label "Results"@en,
        "results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-rgbd-slam rdfs:label "RGBD-SLAM"@en ;
    askg-onto:entityType "Dataset"@en,
        "System"@en .

askg-data:Entity-rgbd_slam_dataset rdfs:label "RGBD SLAM dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-rigid_scenes rdfs:label "rigid scenes"@en ;
    askg-onto:entityType "Condition"@en,
        "Domain"@en .

askg-data:Entity-scale rdfs:label "scale"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-seq rdfs:label "Seq."@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-sequences rdfs:label "sequences"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-shihao_jiang rdfs:label "Shihao Jiang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-slic_superpixels rdfs:label "SLIC superpixels"@en,
        "Slic superpixels"@en ;
    askg-onto:entityType "Method"@en,
        "Tool"@en .

askg-data:Entity-smoothness_loss rdfs:label "smoothness loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-software rdfs:label "Software"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-state-of-the-art_results rdfs:label "state-of-the-art results"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-stefan_roth rdfs:label "Stefan Roth"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-study rdfs:label "Study"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-supervised_method rdfs:label "supervised method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-supervised_methods rdfs:label "supervised methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-suryansh_kumar rdfs:label "Suryansh Kumar"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-test_set rdfs:label "test set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-theory rdfs:label "Theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-training_strategy rdfs:label "training strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-unflow rdfs:label "UnFlow"@en ;
    askg-onto:entityType "Model"@en,
        "Software"@en .

askg-data:Entity-university rdfs:label "University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unsupervised_deep_learning_framework rdfs:label "unsupervised deep learning framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-unsupervised_learning_methods rdfs:label "unsupervised learning methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-upper-level_loss rdfs:label "upper-level loss"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-upper-level_problem rdfs:label "upper-level problem"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-v rdfs:label "V"@en,
        "V˜"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-visual_localization rdfs:label "Visual localization"@en,
        "visual localization"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-y rdfs:label "Y"@en,
        "y"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-yiran_zhong rdfs:label "Yiran Zhong"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yuchao_dai rdfs:label "Yuchao Dai"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-2004 rdfs:label "2004"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2018 rdfs:label "2018"@en ;
    askg-onto:entityType "Domain"@en,
        "Publication"@en .

askg-data:Entity-2019 rdfs:label "2019"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-bi-level_optimization_problem rdfs:label "bi-level optimization problem"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-brightness_constancy_and_local_smoothness_constraints rdfs:label "brightness constancy and local smoothness constraints"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-computer_vision rdfs:label "Computer Vision"@en,
        "computer vision"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-condition rdfs:label "Condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-constraints rdfs:label "constraints"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-derivative rdfs:label "Derivative"@en,
        "derivative"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-egomotion rdfs:label "egomotion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-epipolar_constraint rdfs:label "epipolar constraint"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-epipolar_geometric_loss rdfs:label "epipolar geometric loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-european_conference_on_computer_vision rdfs:label "European Conference on Computer Vision"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-five-point_algorithm rdfs:label "five-point algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-geometric_estimation_layer rdfs:label "geometric estimation layer"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-i_0 rdfs:label "I 0"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Person"@en .

askg-data:Entity-image rdfs:label "Image"@en,
        "image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kitti_dataset rdfs:label "KITTI dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_vo_dataset rdfs:label "KITTI VO dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-l rdfs:label "L"@en,
        "l"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-liu_et_al rdfs:label "Liu et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-lower-level_optimization_problem rdfs:label "lower-level optimization problem"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-meta-learning rdfs:label "Meta-learning"@en,
        "meta-learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-ours rdfs:label "Ours"@en,
        "ours"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-ours-baseline rdfs:label "Ours-Baseline"@en,
        "Ours-baseline"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-ours-occlusion rdfs:label "Ours-Occlusion"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-p rdfs:label "P"@en,
        "p"@en,
        "p˜"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ransac rdfs:label "RANSAC"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-tool rdfs:label "Tool"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-training_pipeline rdfs:label "training pipeline"@en ;
    askg-onto:entityType "Framework"@en,
        "System"@en .

askg-data:Entity-unsupervised_learning_framework rdfs:label "unsupervised learning framework"@en ;
    askg-onto:entityType "Framework"@en,
        "Method"@en .

askg-data:Entity-unsupervised_methods rdfs:label "unsupervised methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-zhou_et_al rdfs:label "Zhou et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-2012 rdfs:label "2012"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2016 rdfs:label "2016"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2017 rdfs:label "2017"@en ;
    askg-onto:entityType "Domain"@en,
        "Paper"@en,
        "Publication"@en .

askg-data:Entity-brightness_constancy rdfs:label "brightness constancy"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-camera_motion_estimation rdfs:label "camera motion estimation"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-data rdfs:label "Data"@en,
        "data"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-epipolar_loss rdfs:label "epipolar loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-hongdong_li rdfs:label "Hongdong Li"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-i rdfs:label "I"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Person"@en .

askg-data:Entity-ieee rdfs:label "IEEE"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-lower-level_problem rdfs:label "lower-level problem"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-michael_j_black rdfs:label "Michael J Black"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-our_model rdfs:label "Our model"@en,
        "our model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-proceedings rdfs:label "Proceedings"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-raquel_urtasun rdfs:label "Raquel Urtasun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-stephen_gould rdfs:label "Stephen Gould"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-system rdfs:label "System"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-thomas_brox rdfs:label "Thomas Brox"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-algorithm rdfs:label "algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence rdfs:label "IEEE Transactions on Pattern Analysis and Machine Intelligence"@en,
        "IEEE transactions on pattern analysis and machine intelligence"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-orb-slam rdfs:label "ORB-SLAM"@en,
        "Orb-slam"@en ;
    askg-onto:entityType "Method"@en,
        "System"@en .

askg-data:Entity-pwc-net rdfs:label "PWC-Net"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-richard_hartley rdfs:label "Richard Hartley"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-student_network rdfs:label "student network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-teacher_network rdfs:label "teacher network"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-unsupervised_learning rdfs:label "Unsupervised Learning"@en,
        "Unsupervised learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-our_method rdfs:label "our method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition rdfs:label "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Article"@en,
        "Paper"@en,
        "Publication"@en .

askg-data:Entity-rgb-d_slam_dataset rdfs:label "RGB-D SLAM dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-selflow rdfs:label "SelFlow"@en,
        "Selflow"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition rdfs:label "IEEE Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Organization"@en,
        "Paper"@en,
        "Publication"@en .

askg-data:Entity-implicit_differentiation rdfs:label "implicit differentiation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-metric rdfs:label "Metric"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-conference rdfs:label "Conference"@en ;
    askg-onto:entityType "Domain"@en,
        "Research Field"@en .

askg-data:Entity-network rdfs:label "network"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-springer rdfs:label "Springer"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-model rdfs:label "Model"@en,
        "model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-camera_motion rdfs:label "Camera Motion"@en,
        "camera motion"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-concept rdfs:label "Concept"@en,
        "concept"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-epipolar_geometry rdfs:label "Epipolar Geometry"@en,
        "Epipolar geometry"@en,
        "epipolar geometry"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-essential_matrix rdfs:label "essential matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Dataset"@en,
        "Domain"@en .

askg-data:Entity-optical_flow_estimation rdfs:label "Optical flow estimation"@en,
        "optical flow estimation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-author rdfs:label "Author"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-research_field rdfs:label "Research Field"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-publication rdfs:label "Publication"@en ;
    askg-onto:entityType "Publication"@en,
        "Research Field"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Research Field"@en .

askg-data:Entity-person rdfs:label "Person"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-paper rdfs:label "Paper"@en,
        "paper"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-optical_flow rdfs:label "Optical Flow"@en,
        "Optical flow"@en,
        "optical flow"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Metric"@en .

