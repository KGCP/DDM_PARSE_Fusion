@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-54ff6fb7db5b9fad a askg-onto:Paper ;
    rdfs:label "54ff6fb7db5b9fad"@en ;
    dc:title "54ff6fb7db5b9fad"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-54ff6fb7db5b9fad-Section-1,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10,
        askg-data:Paper-54ff6fb7db5b9fad-Section-11,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15,
        askg-data:Paper-54ff6fb7db5b9fad-Section-16,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9 .

askg-data:Entity- rdfs:label "✓"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-%09extdlt%09extotimes%09extxl-1t rdfs:label "(	ext{D}^{l})^{T}	ext{otimes}(	ext{x}^{l-1})^{T}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extfrakg rdfs:label "${	extfrak{g}}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Aepsilon_jlk_dl_%09ensor_xl-1 rdfs:label """
epsilon J^{l,K} D^{l} 	ensor x^{l-1}"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac%09extpartial_%09extxl%09extpartial_%09extwl rdfs:label "rac{	ext{partial} 	ext{x}^{l}}{	ext{partial} 	ext{W}^{l}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac%0Crac%09extpartial_%09extxl%09extpartial_%09extxl-1 rdfs:label "rac{rac{	ext{partial} 	ext{x}^{l}}{	ext{partial} 	ext{x}^{l-1}}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac1%09au%09extjlk%09extdl%09imes%09extxl-1 rdfs:label "rac{1}{	au}	ext{J}^{l,K}	ext{D}^{l}	imes	ext{x}^{l-1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac1%09au%09extjlk%09extdlt%09imes%09extxl-1t rdfs:label "(rac{1}{	au}	ext{J}^{l,K}	ext{D}^{l})^{T}	imes(	ext{x}^{l-1})^{T}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3__%CE%B1%CF%88 rdfs:label "γ = αψ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3__10 rdfs:label "γ = 1.0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B4 rdfs:label "δ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B4ij rdfs:label "δij"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BA__984 rdfs:label "κ¯ = 98.4%"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-%CF%84%E2%82%81%E2%81%B1 rdfs:label "τ₁ⁱ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%86w1x_0__b_1 rdfs:label "φ(W1x 0 + b 1)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%86wl1%CF%86wl2 rdfs:label "φ(Wl−1φ(Wl−2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0__b_1 rdfs:label "0 + b 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-10000-layer_vanilla_convolutional_neural_networks rdfs:label "10,000-layer vanilla convolutional neural networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-103e03 rdfs:label "1.03e+03"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-10_sparsity rdfs:label "10% sparsity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-10k rdfs:label "10**k"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1101_errors_ rdfs:label "11.01 errors (%)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-1158 rdfs:label "11.58"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-1169_errors_ rdfs:label "11.69 errors (%)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-1198 rdfs:label "11.98"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-1322 rdfs:label "13.22"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-14_image_1png rdfs:label "14_image_1.png"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-16 rdfs:label "16"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-1993 rdfs:label "1993"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1__%CF%83j___%C7%AB rdfs:label "|1 − σj | ≤ ǫ"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-1k_iteration rdfs:label "1k iteration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2 rdfs:label "2"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2006 rdfs:label "2006"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2014 rdfs:label "2014"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-20k rdfs:label "20k"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-20k_iterations rdfs:label "20k iterations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-230e01 rdfs:label "2.30e+01"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-246e07 rdfs:label "2.46e−07"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-25k rdfs:label "25k"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-277 rdfs:label "2.77"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-294 rdfs:label "2.94"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-300 rdfs:label "3.00"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-32_filters rdfs:label "32 filters"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-367e04 rdfs:label "3.67e+04"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-3d_printing rdfs:label "3D Printing"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-4 rdfs:label "4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-449e01 rdfs:label "4.49e−01"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-4k_iteration rdfs:label "4k iteration"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-5 rdfs:label "5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-503 rdfs:label "5.03"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-574e04 rdfs:label "5.74e−04"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7 rdfs:label "7"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-753 rdfs:label "7.53"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-821 rdfs:label "8.21"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-825_errors_ rdfs:label "8.25 errors (%)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-876 rdfs:label "8.76"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-882_errors_ rdfs:label "8.82 errors (%)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-906 rdfs:label "9.06"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-907 rdfs:label "9.07"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-97 rdfs:label "97%"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-999 rdfs:label "9.99"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9_image_0png rdfs:label "9_image_0.png"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a-b-c rdfs:label "{A}-{B}-{C}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a__b_t rdfs:label "(A ⊗ B) T"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_better_model rdfs:label "a better model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-a_desired_sparsity_level rdfs:label "a desired sparsity level"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_larger_residual_block rdfs:label "a larger residual block"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_mathematical_expression rdfs:label "a mathematical expression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_mathematical_object rdfs:label "a mathematical object"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_network rdfs:label "a network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_pretrained_model rdfs:label "a pretrained model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-a_range_of_networks rdfs:label "a range of networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_reduced_number_of_residual_blocks rdfs:label "a reduced number of residual blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_study rdfs:label "a study"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-aaron_van_den_oord rdfs:label "Aaron van den Oord"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-accuracy rdfs:label "accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-accuracy_drop rdfs:label "accuracy drop"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-activation_function_in_resnets rdfs:label "activation function in ResNets"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-activation_functions rdfs:label "activation functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ad-hoc_intuition rdfs:label "ad-hoc intuition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-additional_results rdfs:label "ADDITIONAL RESULTS"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-additive_manufacturing rdfs:label "Additive Manufacturing"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-ai_ethics rdfs:label "AI Ethics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ai_research_group rdfs:label "AI Research Group"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-aistats_2018 rdfs:label "AISTATS 2018"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-all_layers rdfs:label "all layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_learnable_parameters rdfs:label "all learnable parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_networks rdfs:label "All networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_tested_architectures rdfs:label "all tested architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-amartya_sanyal rdfs:label "Amartya Sanyal"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-an_interplay_between_gradients_and_weights rdfs:label "an interplay between gradients and weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-andrew_m_saxe rdfs:label "Andrew M Saxe"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-antisymmetric_sigmoidal_activation_functions rdfs:label "antisymmetric sigmoidal activation functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anueduau rdfs:label "@anu.edu.au"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-any_activation_function rdfs:label "any activation function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anything_specific_for_a_particular_case rdfs:label "anything specific for a particular case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-appendix_a rdfs:label "Appendix A"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approach rdfs:label "approach"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-architecture rdfs:label "architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-architecture_sculpting rdfs:label "architecture sculpting"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-architecture_specification rdfs:label "architecture specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-architectures_that_yield_better_performance_than_standard_pre-designed_architectures rdfs:label "architectures that yield better performance than standard pre-designed architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-aspects rdfs:label "aspects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-at__bt rdfs:label "AT ⊗ BT"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-australian_national_university rdfs:label "Australian National University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-australian_research_council_centre_of_excellence_for_robotic_vision rdfs:label "Australian Research Council Centre of Excellence for Robotic Vision"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-automation rdfs:label "Automation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-b rdfs:label "B"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b_l1 rdfs:label "b l−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b_l2 rdfs:label "b l−2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backward_propagation_of_the_error_signal rdfs:label "backward propagation of the error signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-base_dense_network rdfs:label "base dense network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-base_model rdfs:label "base model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-base_network rdfs:label "base network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-base_network_resnet20 rdfs:label "base network (ResNet20)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-basic_filter_size rdfs:label "basic filter size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_normalization_bn_layers rdfs:label "batch normalization (BN) layers"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-before rdfs:label "before"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-before_pruning rdfs:label "before pruning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ben_poole rdfs:label "Ben Poole"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-best_generalization_errors rdfs:label "best generalization errors"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-best_performance rdfs:label "best performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-best_pruning_results rdfs:label "best pruning results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-best_results_across_all_tested_architectures rdfs:label "best results across all tested architectures"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-better_performance_than_standard_pre-designed_architectures rdfs:label "better performance than standard pre-designed architectures"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-better_signal_propagation rdfs:label "better signal propagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-biases rdfs:label "biases"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-bl rdfs:label "b^l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-black0white1_pixels rdfs:label "black(0)/white(1) pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-block_size rdfs:label "Block size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bn rdfs:label "BN"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-bulky_network rdfs:label "bulky network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c1 rdfs:label "c=1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c_j rdfs:label "c_{j}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c_signal_propagation_in_sparse_networks rdfs:label "C SIGNAL PROPAGATION IN SPARSE NETWORKS"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-calculus rdfs:label "calculus"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cancer_research rdfs:label "Cancer Research"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-catastrophic_pruning_failure rdfs:label "catastrophic pruning failure"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-cell_type rdfs:label "Cell Type"@en ;
    askg-onto:entityType "Cell Type"@en .

askg-data:Entity-chain_rule_of_differentiation rdfs:label "chain rule of differentiation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cj rdfs:label "cj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cl rdfs:label "C^l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classification rdfs:label "classification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-clinical_trials rdfs:label "Clinical Trials"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-close_to_zero_loss_around_10k_iterations rdfs:label "close to zero loss around 10k iterations"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-cn rdfs:label "CN"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-common_explanation rdfs:label "common explanation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-company_r rdfs:label "Company R"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-complete rdfs:label "complete"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complete_disconnection_of_signal_paths rdfs:label "complete disconnection of signal paths"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-completely_disconnected_networks rdfs:label "completely disconnected networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complexity_of_the_model rdfs:label "complexity of the model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compressed_networks rdfs:label "compressed networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compressed_neural_networks rdfs:label "compressed neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compressing_deep_neural_networks rdfs:label "compressing deep neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computational_and_memory_requirements rdfs:label "computational and memory requirements"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computer_science rdfs:label "computer science"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-condition_number rdfs:label "Condition Number"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-conditions rdfs:label "conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-connection_sensitivities_cs rdfs:label "connection sensitivities (CS)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-connection_sensitivity_based_pruning rdfs:label "connection sensitivity based pruning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-connection_sensitivity_based_pruning_methods rdfs:label "connection sensitivity based pruning methods"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-connection_sensitivity_cs rdfs:label "connection sensitivity (CS)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-connection_sensitivity_measurement rdfs:label "connection sensitivity measurement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-connection_sensitivity_measurements rdfs:label "connection sensitivity measurements"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-connection_sensitivity_pruning rdfs:label "connection sensitivity pruning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-connectivity_parameters rdfs:label "connectivity parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-continual_learning rdfs:label "continual learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convergence_to_a_minimum rdfs:label "convergence to a minimum"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolutional_neural_network rdfs:label "convolutional neural network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-corresponding_jacobians rdfs:label "corresponding Jacobians"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-corresponding_weights rdfs:label "corresponding weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cvpr_2016 rdfs:label "CVPR 2016"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-data-free rdfs:label "data-free"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_analysis rdfs:label "Data Analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_integration rdfs:label "data integration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_processing rdfs:label "data processing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_science rdfs:label "Data Science"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-database rdfs:label "Database"@en ;
    askg-onto:entityType "Database"@en .

askg-data:Entity-datafree_method rdfs:label "datafree method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dataset_1 rdfs:label "Dataset 1"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-dataset_error rdfs:label "Dataset Error"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-decayed_learning_rate rdfs:label "decayed learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decreased_trainability_of_compressed_networks rdfs:label "decreased trainability of compressed networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dedicated_implementation_for_sparsity rdfs:label "dedicated implementation for sparsity"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_compression rdfs:label "Deep compression"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_feedforward_neural_networks rdfs:label "deep feedforward neural networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_information_propagation rdfs:label "Deep information propagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_linear_neural_networks rdfs:label "deep linear neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_networks rdfs:label "deep networks"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-deep_residual_learning rdfs:label "Deep residual learning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deeper rdfs:label "deeper"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-definition_1 rdfs:label "Definition 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degradation rdfs:label "degradation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-delta rdfs:label "delta"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dense_base_model rdfs:label "dense base model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-dense_reference_network rdfs:label "dense reference network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deriving_properties_on_the_initialization rdfs:label "deriving properties on the initialization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-destruction_of_dynamical_isometry rdfs:label "destruction of dynamical isometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-diagonal_matrix rdfs:label "diagonal matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-diagonal_matrix_dl rdfs:label "diagonal matrix Dl"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-difference_in_convergence_speed rdfs:label "difference in convergence speed"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-different_%CE%B3 rdfs:label "different γ**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_methods rdfs:label "different methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-difficulty rdfs:label "difficulty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dimensionality_reduction rdfs:label "Dimensionality Reduction"@en,
        "dimensionality reduction"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-discussions rdfs:label "discussions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dl__i rdfs:label "Dl = I"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dlij rdfs:label "Dlij"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-document rdfs:label "Document"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain rdfs:label "Domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-dwl_tdwl rdfs:label "(DWl) T(DWl)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_column_of_errors rdfs:label "each column of errors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_layer rdfs:label "each layer"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-early_phase_of_training rdfs:label "early phase of training"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-early_training_phase rdfs:label "early training phase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-edward_lockhart rdfs:label "Edward Lockhart"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-effective_pruning rdfs:label "effective pruning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-effective_pruning_results rdfs:label "effective pruning results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-efficient_backprop_neural_networks_tricks_of_the_trade rdfs:label "Efficient backprop. Neural Networks: Tricks of the Trade"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-empirical_distribution_of_the_pre-activations rdfs:label "empirical distribution of the pre-activations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-enforcing_approximate_dynamical_isometry rdfs:label "Enforcing approximate dynamical isometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_11 rdfs:label "Equation 11"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_2 rdfs:label "Equation 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_8 rdfs:label "Equation 8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equipment rdfs:label "Equipment"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-equivalent_1 rdfs:label "Equivalent 1"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-equivalent_3 rdfs:label "Equivalent 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-erich_elsen rdfs:label "Erich Elsen"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-error_category rdfs:label "Error Category"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-error_signals rdfs:label "error signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-error_vector rdfs:label "error vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-errors rdfs:label "errors"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-evaluation rdfs:label "evaluation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-exact_dynamical_isometry rdfs:label "exact dynamical isometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiment_y rdfs:label "Experiment Y"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-exponential_expressivity rdfs:label "Exponential expressivity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-extended_training_results rdfs:label "extended training results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-extreme_sparsity_levels rdfs:label "extreme sparsity levels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-extremely_large rdfs:label "extremely large"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-f_dl rdfs:label "${f D}^{l}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_g_f_wlt rdfs:label "${f g}_{{f w}^{l}}^{T}"@en,
        "${f g}_{{f w}^{l}}^{T}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_jlk rdfs:label "${f J}^{l,K}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_xl-1 rdfs:label "${f x}^{l-1}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-failure_cases rdfs:label "failure cases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-faithful_connection_sensitivity rdfs:label "faithful connection sensitivity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-faithful_lw rdfs:label "faithful ∂L/∂w"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fashion-mnist rdfs:label "Fashion-MNIST"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-fast rdfs:label "fast"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feed-forward rdfs:label "feed-forward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feedforward_dynamics rdfs:label "feedforward dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_5 rdfs:label "Figure 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-filter_multiplier rdfs:label "filter multiplier"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-findings rdfs:label "findings"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-first_and_second rdfs:label "first and second"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-first_demonstration rdfs:label "first demonstration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fiveai rdfs:label "FiveAI"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-fixed_point_q_ rdfs:label "fixed point q ∗"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-florian_stimberg rdfs:label "Florian Stimberg"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-following rdfs:label "following"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-forward_propagation_of_the_input_signal rdfs:label "forward propagation of the input signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-frankle__carbin rdfs:label "Frankle & Carbin"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-full_derivation rdfs:label "full derivation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-full_rank_capacity rdfs:label "full rank capacity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fully-connected_feed-forward_neural_network rdfs:label "fully-connected, feed-forward neural network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_work rdfs:label "future work"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g_jf_w%0Acal_d rdfs:label """g_{j}({f w};{
cal D})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g_wlt rdfs:label "g_{w^{l}}^{T}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gaussian_distribution rdfs:label "Gaussian distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ge_yang rdfs:label "Ge Yang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ge_yang_and_samuel_schoenholz rdfs:label "Ge Yang and Samuel Schoenholz"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-gene rdfs:label "Gene"@en ;
    askg-onto:entityType "Gene"@en .

askg-data:Entity-genevieve_b rdfs:label "Genevieve B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-geoffrey_e_hinton rdfs:label "Geoffrey E Hinton"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-geoffrey_hinton rdfs:label "Geoffrey Hinton"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-gj rdfs:label "gj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-global_threshold rdfs:label "global threshold"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-glorot__bengio_2010 rdfs:label "Glorot & Bengio, 2010"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-good_accuracy rdfs:label "good accuracy"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-good_generalization_errors rdfs:label "good generalization errors"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-gradient_term_lwj rdfs:label "gradient term ∂L/∂wj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradient_update_steps rdfs:label "gradient update steps"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-gradient_yx rdfs:label "gradient ∂y/∂x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradients_lw rdfs:label "gradients ∂L/∂w"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradients_scaled_by_the_weights rdfs:label "gradients scaled by the weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-greg_yang rdfs:label "Greg Yang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ground-truth_labels rdfs:label "ground-truth labels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gt rdfs:label "GT"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h_l rdfs:label "h l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-han_et_al rdfs:label "Han et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hand-designed_architectures rdfs:label "hand-designed architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-having_as_many_singular_values_as_possible_near_1 rdfs:label "having as many singular values as possible near 1"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-he_et_al rdfs:label "He et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-he_et_al_2015 rdfs:label "He et al., 2015"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-head rdfs:label "head"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-health_care rdfs:label "health care"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-high_sparsity rdfs:label "high sparsity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high_sparsity_level rdfs:label "high sparsity level"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-higher_errors rdfs:label "higher errors"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-hinton__salakhutdinov rdfs:label "Hinton & Salakhutdinov"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hl rdfs:label "h^l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hl_i rdfs:label "h^{l}_{i}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-how_signal_propagation_affects_the_gradients rdfs:label "how signal propagation affects the gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-httpsgithubcomnamhoonleespp-public rdfs:label "https://github.com/namhoonlee/spp-public"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-huffman_coding rdfs:label "huffman coding"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-huizi_mao rdfs:label "Huizi Mao"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-human-level_performance rdfs:label "human-level performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-iccv rdfs:label "ICCV"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iccv_2015 rdfs:label "ICCV 2015"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-icml_2018 rdfs:label "ICML, 2018"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-identically rdfs:label "identically"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-identity rdfs:label "identity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-if_specified rdfs:label "if specified"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-il rdfs:label "I^l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_classification rdfs:label "image classification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-imagenet_classification rdfs:label "imagenet classification"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-impact rdfs:label "impact"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-important_question rdfs:label "important question"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-increased_computational_and_memory_efficiency rdfs:label "increased computational and memory efficiency"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-index rdfs:label "Index"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-inductive_bias rdfs:label "inductive bias"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inferior_trainability rdfs:label "inferior trainability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-init rdfs:label "Init."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_condition rdfs:label "initial condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-initial_jacobians rdfs:label "initial Jacobians"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_learning_rate rdfs:label "initial learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initialization_conditions rdfs:label "initialization conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-initialization_method rdfs:label "initialization method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-initialization_methods rdfs:label "initialization methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-initialization_scheme rdfs:label "initialization scheme"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-initialization_schemes rdfs:label "initialization schemes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input-output_jacobian rdfs:label "input-output Jacobian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_signals rdfs:label "input signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-integer rdfs:label "integer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-interesting_results rdfs:label "interesting results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-interpretation_of_gradients rdfs:label "interpretation of gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-isometrically_through_the_network rdfs:label "isometrically through the network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-j rdfs:label "J"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-j_kl rdfs:label "J k,l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-j_l1l__x_l_xl1__r_nlnl1 rdfs:label "J l−1,l = ∂x l ∂xl−1 ∈ R Nl×Nl−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jacek_tabor rdfs:label "Jacek Tabor"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jacobian_from_layer_k_to_layer_l rdfs:label "Jacobian from layer k to layer l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jacobian_from_the_input_to_layer_l1 rdfs:label "Jacobian from the input to layer l−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jacobian_j_0k rdfs:label "Jacobian (J 0,K)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jacobian_matrix rdfs:label "Jacobian matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jacobian_norms_kjk1 rdfs:label "Jacobian norms kJk1"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-jacobian_norms_kjk2 rdfs:label "Jacobian norms kJk2"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-james_l_mcclelland rdfs:label "James L McClelland"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-jl-1l rdfs:label "J^{l-1,l}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jonathan_frankle rdfs:label "Jonathan Frankle"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-justin_gilmer rdfs:label "Justin Gilmer"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-k-layer_mlp_networks rdfs:label "K-layer MLP networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-k__k_f rdfs:label "k · k_F"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-k_layers rdfs:label "K layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kalchbrenner_et_al rdfs:label "Kalchbrenner et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-karen_simonyan rdfs:label "Karen Simonyan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-keeping_top-%CE%BA_salient_parameters rdfs:label "keeping top-κ salient parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-klaus-robert_m%C3%BCller rdfs:label "Klaus-Robert Müller"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-knowledge_acquisition rdfs:label "knowledge acquisition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-knowledge_graph_building rdfs:label "knowledge graph building"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-knowledge_representation rdfs:label "knowledge representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-koray_kavukcuoglu rdfs:label "Koray Kavukcuoglu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kronecker_delta rdfs:label "Kronecker delta"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l rdfs:label "l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l%C3%A9on_bottou rdfs:label "Léon Bottou"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-l-relu rdfs:label "l-relu"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-large_neural_network_models rdfs:label "large neural network models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-large_sparse_networks rdfs:label "large sparse networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layer_l rdfs:label "layer l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layer_l_-_1 rdfs:label "layer l - 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layer_l_to_l__1 rdfs:label "layer l to l − 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layers rdfs:label "layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layers_of_random_weights rdfs:label "layers of random weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise rdfs:label "layerwise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_dynamical_isometry_ldi rdfs:label "layerwise dynamical isometry (LDI)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-layerwise_jacobian rdfs:label "layerwise Jacobian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_jacobians rdfs:label "layerwise Jacobians"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_orthogonal rdfs:label "layerwise orthogonal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_orthogonal_initialization rdfs:label "layerwise orthogonal initialization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_orthogonality rdfs:label "layerwise orthogonality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_scalar rdfs:label "layerwise scalar"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_sparsity_patterns rdfs:label "layerwise sparsity patterns"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_thresholding rdfs:label "layerwise thresholding"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-lcwd rdfs:label "L(c∘w;D)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi-cs-ais rdfs:label "LDI-CS-AIS"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-ldi-cs_mag_rand rdfs:label "LDI-{CS, Mag, Rand}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi-cs_rand rdfs:label "LDI-{CS, Rand}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi-mag rdfs:label "LDI-Mag"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-ldi-rand rdfs:label "LDI-Rand"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi_results rdfs:label "LDI results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-leaky-relu rdfs:label "Leaky-ReLU"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-leaky-relu_activation_function rdfs:label "Leaky-ReLU activation function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_capability rdfs:label "learning capability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_in_deep_linear_neural_networks rdfs:label "learning in deep linear neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_of_01 rdfs:label "learning rate of 0.1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lechao_xiao rdfs:label "Lechao Xiao"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lecun rdfs:label "LeCun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lenet rdfs:label "LeNet"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-less_than_a_few_seconds_on_a_modern_computer rdfs:label "less than a few seconds on a modern computer"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-lf_c%0Aodotf_w%0Acal_d rdfs:label """L({f c}
odot{f w};{
cal D})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_network rdfs:label "linear network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_region_of_the_nonlinear_function_%CF%86 rdfs:label "linear region of the nonlinear function φ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_region_of_the_nonlinearity rdfs:label "linear region of the nonlinearity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_l rdfs:label "loss L"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_term rdfs:label "loss term"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lottery_ticket_hypothesis rdfs:label "lottery ticket hypothesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-low_sparsity_regime rdfs:label "low sparsity regime"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-lower_errors rdfs:label "lower errors"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-lower_standard_deviations rdfs:label "lower standard deviations"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-lowest_orthogonality_scores rdfs:label "lowest orthogonality scores"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-lowest_test_error rdfs:label "lowest test error"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-lwd rdfs:label "L(w;D)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lwj_wj rdfs:label "∂L/∂wj wj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning_algorithm rdfs:label "Machine Learning Algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-machine_learning_algorithms rdfs:label "Machine Learning Algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-maciej_a_nowak rdfs:label "Maciej A Nowak"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-magnitude rdfs:label "magnitude"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-magnitude_mag rdfs:label "magnitude (Mag)"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-magnitude_of_parameters rdfs:label "magnitude of parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maithra_raghu rdfs:label "Maithra Raghu"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-manufacturing rdfs:label "Manufacturing"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-mathematical_expression rdfs:label "Mathematical Expression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathematical_expressions rdfs:label "mathematical expressions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathematics rdfs:label "mathematics"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-matrix_of_dimension_y-size__x-size rdfs:label "matrix of dimension y-size × x-size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-matrix_operations rdfs:label "matrix operations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maximum_and_minimum_jacobian_singular_values rdfs:label "maximum and minimum Jacobian singular values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maximum_depth rdfs:label "maximum depth"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean-field_theory rdfs:label "mean-field theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-mean_field_approximation rdfs:label "mean field approximation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean_field_residual_networks rdfs:label "Mean field residual networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean_field_theory_of_cnns rdfs:label "mean field theory of cnns"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-mean_singular_values rdfs:label "mean singular values"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mean_squared_singular_value_of_a_networks_input-output_jacobian rdfs:label "mean squared singular value of a network's input-output Jacobian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-meaningful_entities rdfs:label "meaningful entities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-means_to_formulate_as_an_optimization_problem rdfs:label "means to formulate as an optimization problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-medical_imaging rdfs:label "Medical Imaging"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-method_z rdfs:label "Method Z"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-metric rdfs:label "Metric"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-michael_carbin rdfs:label "Michael Carbin"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mini-batch rdfs:label "mini-batch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mini-batch_size rdfs:label "mini-batch size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-minimum rdfs:label "minimum"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mlp rdfs:label "MLP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-mlp_networks rdfs:label "MLP networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model_category rdfs:label "Model category"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-models rdfs:label "models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-models_equivalents_123 rdfs:label "models (Equivalents 1,2,3)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-models_of_superior_performance rdfs:label "models of superior performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-moderate_changes_in_the_jacobian_singular_values rdfs:label "moderate changes in the Jacobian singular values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-modern_architectures rdfs:label "modern architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-modern_networks rdfs:label "modern networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-modifications rdfs:label "modifications"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-molecule rdfs:label "Molecule"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-molecules rdfs:label "molecules"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-more_parameters rdfs:label "more parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-much_slowly rdfs:label "much slowly"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-multilayer_perceptron_networks_mlp rdfs:label "multilayer perceptron networks (MLP)"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-n_0_q rdfs:label "N (0, q∗)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-naively_pruning rdfs:label "naively pruning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-nal_kalchbrenner rdfs:label "Nal Kalchbrenner"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-namhoon rdfs:label "namhoon"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-nature_2015 rdfs:label "Nature, 2015"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-network_at_initialization rdfs:label "network at initialization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_is_deepershallower rdfs:label "network is deeper/shallower"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_models_for_image_classification_tasks rdfs:label "network models for image classification tasks"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-network_pruned_using_connection_sensitivity rdfs:label "network pruned using connection sensitivity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_weights rdfs:label "network weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_architecture_search rdfs:label "neural architecture search"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_audio_synthesis rdfs:label "neural audio synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_network_compression rdfs:label "neural network compression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neuron rdfs:label "neuron"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neuron_i rdfs:label "neuron i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-pruned_dense_network rdfs:label "non-pruned dense network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-standard_arbitrarily-designed_architectures rdfs:label "non-standard arbitrarily-designed architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-uniformly_and_sparsely rdfs:label "non-uniformly and sparsely"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nonlinear_activation_functions rdfs:label "nonlinear activation functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nonlinear_dynamics rdfs:label "nonlinear dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nonlinear_network_parameters rdfs:label "nonlinear network parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nonlinearity rdfs:label "nonlinearity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nonuniform_over_different_layers rdfs:label "nonuniform over different layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normalization_factors rdfs:label "normalization factors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-norman_casagrande rdfs:label "Norman Casagrande"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-not_concentrated rdfs:label "not concentrated"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-notice rdfs:label "Notice"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_output_neurons rdfs:label "number of output neurons"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_update_steps rdfs:label "number of update steps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-objective_in_equation_8 rdfs:label "objective in Equation 8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-of_little_practical_use rdfs:label "of little practical use"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_w rdfs:label "optimal W∗"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization_and_signal_propagation rdfs:label "optimization and signal propagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-organization_a rdfs:label "Organization A"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-organizations rdfs:label "organizations"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-orr rdfs:label "Orr"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-orthogonal_initialization_schemes rdfs:label "orthogonal initialization schemes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-orthogonal_initialization_with_enforced_approximate_isometry_method_ldi-ai rdfs:label "orthogonal initialization with enforced approximate isometry method (LDI-AI)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-os rdfs:label "OS"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-output_neurons rdfs:label "output neurons"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-over_10 rdfs:label "over 10"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-overall_process rdfs:label "overall process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-overparameterized_network rdfs:label "overparameterized network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-paper rdfs:label "Paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-parameter rdfs:label "Parameter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parameter_j rdfs:label "parameter j"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parameters_in_a_network rdfs:label "parameters in a network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parameters_in_each_layer rdfs:label "parameters in each layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parameters_in_the_network rdfs:label "parameters in the network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-particular_case rdfs:label "particular case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pascanu_et_al rdfs:label "Pascanu et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-pennington_et_al_2017 rdfs:label "Pennington et al. (2017)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-performance_of_pruned_networks rdfs:label "performance of pruned networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-person_x rdfs:label "Person X"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-philip_h rdfs:label "Philip H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-philip_hs_torr rdfs:label "Philip HS Torr"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-piotr_warcho%C5%82 rdfs:label "Piotr Warchoł"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-playing_games rdfs:label "playing games"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-poole_et_al rdfs:label "Poole et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-poole_et_al_2016 rdfs:label "Poole et al. 2016"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-poor_learning_capability rdfs:label "poor learning capability"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-poor_pruning_results rdfs:label "poor pruning results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-poor_signal_propagation rdfs:label "poor signal propagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-poorly_conditioned_initial_jacobians rdfs:label "poorly conditioned initial Jacobians"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-post-activations rdfs:label "post-activations"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-practice rdfs:label "practice"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pre-activations_h_l rdfs:label "pre-activations h l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pre-activations_h_lat_layer_l rdfs:label "pre-activations h lat layer l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pre-designed_architecture rdfs:label "pre-designed architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pre-shaped_architectures rdfs:label "pre-shaped architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-preactivations_of_wide_untrained_neural_networks_can_be_captured_as_a_gaussian_distribution rdfs:label "preactivations of wide, untrained neural networks can be captured as a Gaussian distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pretraining_requirement rdfs:label "pretraining requirement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-previous_layer rdfs:label "previous layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-problem_setup rdfs:label "Problem setup"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-procedure rdfs:label "Procedure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-product_development rdfs:label "Product Development"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-promising_avenue_for_compressing_deep_neural_networks rdfs:label "promising avenue for compressing deep neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposition_1 rdfs:label "Proposition 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-protein rdfs:label "Protein"@en ;
    askg-onto:entityType "Protein"@en .

askg-data:Entity-prototyping rdfs:label "Prototyping"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prune rdfs:label "Prune"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-prune_deep_neural_networks rdfs:label "prune deep neural networks"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-prune_traintest rdfs:label "prune train&test"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruned_parameters_to_the_total_number_of_parameters rdfs:label "pruned parameters to the total number of parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prunedretained_parameters rdfs:label "pruned/retained parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruning_algorithm rdfs:label "pruning algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-pruning_an_untrained_randomly_initialized_neural_network rdfs:label "pruning an untrained, randomly initialized neural network"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-pruning_at_initialization_regime rdfs:label "pruning at initialization regime"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_based_on_connection_sensitivity rdfs:label "pruning based on connection sensitivity"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_based_on_other_initialization_schemes rdfs:label "pruning based on other initialization schemes"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_cases rdfs:label "pruning cases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruning_criterion rdfs:label "pruning criterion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruning_neural_networks rdfs:label "pruning neural networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_neural_networks_at_initialization rdfs:label "pruning neural networks at initialization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_parameters rdfs:label "pruning parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruning_random_networks rdfs:label "pruning random networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_randomly_initialized_neural_networks rdfs:label "pruning randomly initialized neural networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_scheme rdfs:label "pruning scheme"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruning_wider_networks rdfs:label "pruning wider networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_with_supervision rdfs:label "pruning with supervision"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-puneet_dokania rdfs:label "Puneet Dokania"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pytorch rdfs:label "PyTorch"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-r__r rdfs:label "R → R"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_and_magnitude_based_pruning rdfs:label "random and magnitude based pruning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-random_network rdfs:label "random network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_or_magnitude_pruning rdfs:label "random or magnitude pruning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-random_rand rdfs:label "random (Rand)"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-random_weight_initializations rdfs:label "random weight initializations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_weights rdfs:label "random weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-randomly_initialized_networks rdfs:label "randomly initialized networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-randomly_initialized_neural_networks rdfs:label "randomly initialized neural networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-randomly_pruned_network rdfs:label "randomly pruned network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rapid_prototyping rdfs:label "Rapid Prototyping"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-rate rdfs:label "Rate"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-ratio rdfs:label "ratio"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-razvan_pascanu rdfs:label "Razvan Pascanu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-recent_findings rdfs:label "recent findings"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-recent_literature rdfs:label "recent literature"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-recent_work rdfs:label "recent work"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-rectifiers rdfs:label "rectifiers"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-recurrent_neural_networks rdfs:label "recurrent neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recursion_relation rdfs:label "recursion relation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reduced_capacity rdfs:label "reduced capacity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reed rdfs:label "Reed"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-relation rdfs:label "relation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relu rdfs:label "ReLU"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relu_activation_function rdfs:label "ReLU activation function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relu_and_leaky-relu_activation_functions rdfs:label "ReLU and Leaky-ReLU activation functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relu_nonlinearities rdfs:label "ReLU nonlinearities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-report_gen rdfs:label "report gen"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_findings rdfs:label "research findings"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-research_group_b rdfs:label "Research Group B"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-research_initiative rdfs:label "Research Initiative"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_methods rdfs:label "research methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_on_ai rdfs:label "Research on AI"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_paper rdfs:label "Research Paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-residual_networks rdfs:label "residual networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-residual_neural_networks rdfs:label "residual neural networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet20_he_et_al_2016 rdfs:label "ResNet20 (He et al., 2016)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnets rdfs:label "ResNets"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-result rdfs:label "Result"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-result_2 rdfs:label "Result 2"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-resulting_pruned_networks rdfs:label "resulting pruned networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-retained rdfs:label "retained"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-richard_hartley rdfs:label "Richard Hartley"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-robotsoxacuk rdfs:label "@robots.ox.ac.uk"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-royal_academy_of_engineering rdfs:label "Royal Academy of Engineering"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-ruslan_r_salakhutdinov rdfs:label "Ruslan R Salakhutdinov"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-russell_reed rdfs:label "Russell Reed"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-s rdfs:label "S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-s_jf_w%0Acal_d rdfs:label """s_{j}({f w};{
cal D})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-saliency_criterion rdfs:label "saliency criterion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sander_dieleman rdfs:label "Sander Dieleman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-saturating_error_signals rdfs:label "saturating error signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-saturating_lower_connection_sensitivities rdfs:label "saturating, lower connection sensitivities"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-scalar rdfs:label "scalar"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scale rdfs:label "scale"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scaled_gaussians rdfs:label "scaled Gaussians"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scenarios_with_no_labels rdfs:label "scenarios with no labels"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-scientists rdfs:label "scientists"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-sculpting rdfs:label "sculpting"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sculpting_arbitrarily-designed_architecture rdfs:label "sculpting arbitrarily-designed architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-seb_noury rdfs:label "Seb Noury"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-section_31 rdfs:label "section 3.1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-selu rdfs:label "selu"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-semantic_types rdfs:label "semantic types"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-setup rdfs:label "Setup"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-several rdfs:label "several"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sg_%CE%B3100 rdfs:label "SG (γ=100)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-sg_%CE%B3101 rdfs:label "SG (γ=101)"@en,
        "SG (γ=10−1)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-sg_%CE%B3102 rdfs:label "SG (γ=10−2)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-sg_%CE%B3103 rdfs:label "SG (γ=10−3)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-sg_%CE%B3104 rdfs:label "SG (γ=10−4)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-shape rdfs:label "Shape"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sigmoid rdfs:label "sigmoid"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal rdfs:label "signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal_propagation_capability rdfs:label "signal propagation capability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal_propagation_in_neural_networks_with_random_parameters rdfs:label "signal propagation in neural networks with random parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal_propagation_properties rdfs:label "signal propagation properties"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signals_can_travel_through_them rdfs:label "signals can travel through them"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signals_propagating_in_a_network_isometrically_with_minimal_amplification_or_attenuation rdfs:label "signals propagating in a network isometrically with minimal amplification or attenuation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single-shot rdfs:label "single-shot"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single-shot_network_pruning rdfs:label "Single-shot network pruning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-singular_value_%CF%83j rdfs:label "singular value σj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-singular_value_distribution rdfs:label "singular value distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-singular_values_of_j_l1l rdfs:label "singular values of J l−1,l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sj rdfs:label "sj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-small_dense_counterpart rdfs:label "small dense counterpart"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smaller_singular_values rdfs:label "smaller singular values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smaxsmin rdfs:label "smax/smin"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-snip rdfs:label "SNIP"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-softmax rdfs:label "softmax"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-softmaxraw rdfs:label "softmax/raw"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-some_degree rdfs:label "some degree"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-song_han rdfs:label "Song Han"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-sparse_mask rdfs:label "sparse mask"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparse_trainable_neural_networks rdfs:label "sparse, trainable neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparsity_%CE%BA__90 rdfs:label "sparsity κ¯ = 90%"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-sparsity_experiments rdfs:label "sparsity experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-sparsity_in_pruned_network_across_layers rdfs:label "Sparsity in pruned network (across layers)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparsity_level_%CE%BA rdfs:label "sparsity level κ¯"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparsity_level_%CE%BA__10__90 rdfs:label "sparsity level κ¯ = {10, .., 90}%"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparsity_level_increases rdfs:label "sparsity level increases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparsity_patterns rdfs:label "sparsity patterns"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparsity_topology rdfs:label "sparsity topology"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spectral_norm rdfs:label "spectral norm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spectral_universality rdfs:label "spectral universality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spp-public rdfs:label "spp-public"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-standard_deviations rdfs:label "standard deviations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-standard_pre-designed_architectures rdfs:label "standard pre-designed architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-standard_training_procedure rdfs:label "standard training procedure"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-stanis%C5%82aw_jastrz%C4%99bski rdfs:label "Stanisław Jastrzębski"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-state_l rdfs:label "state $l$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-step_1 rdfs:label "Step 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-step_2 rdfs:label "Step 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-step_3 rdfs:label "Step 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stephen_gould rdfs:label "Stephen Gould"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-stephengould rdfs:label "stephen.gould"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-stochasticity rdfs:label "stochasticity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-strongly_amplified_or_attenuated rdfs:label "strongly amplified or attenuated"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structure rdfs:label "Structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-study_w rdfs:label "Study W"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-subhaneil_lahiri rdfs:label "Subhaneil Lahiri"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-suboptimal rdfs:label "suboptimal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sufficient_condition rdfs:label "sufficient condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-supervised_learning rdfs:label "Supervised Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-supervised_loss rdfs:label "supervised loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-support_vector_machines rdfs:label "Support Vector Machines"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-survey rdfs:label "survey"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-symptom rdfs:label "Symptom"@en ;
    askg-onto:entityType "Symptom"@en .

askg-data:Entity-system rdfs:label "System"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-table_4 rdfs:label "Table 4"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-tail rdfs:label "tail"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tanh rdfs:label "tanh"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-target_distribution rdfs:label "target distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tarnowski_et_al rdfs:label "Tarnowski et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-task_of_pruning rdfs:label "task of pruning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tasks rdfs:label "tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tensor rdfs:label "tensor"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tensorflow rdfs:label "TensorFlow"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-text rdfs:label "text"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-thalaiyasingamajanthan rdfs:label "thalaiyasingam.ajanthan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-the_above rdfs:label "the above"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_broken_isometry rdfs:label "the broken isometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_change rdfs:label "the change"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_corresponding_connectivity_parameters rdfs:label "the corresponding connectivity parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_course_of_training rdfs:label "the course of training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_dense_network rdfs:label "the dense network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_existence_of_supervision_a_priori rdfs:label "the existence of supervision a priori"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_jacobian_from_layer_l_to_the_output rdfs:label "the Jacobian from layer l to the output"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_kronecker_product rdfs:label "the Kronecker product"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_procedure_for_finding_the_rescaling_%CF%83_2w_for_various_nonlinearities rdfs:label "the procedure for finding the rescaling σ 2w for various nonlinearities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_pruned rdfs:label "the pruned"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_pruned_network rdfs:label "the pruned network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_pruned_network_without_isometry rdfs:label "the pruned network without isometry"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-the_results_of_pruning rdfs:label "the results of pruning"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-the_same_number_of_residual_blocks rdfs:label "the same number of residual blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_same_width rdfs:label "the same width"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theoretical_understanding rdfs:label "theoretical understanding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theoretically_understand_pruning_at_initialization rdfs:label "theoretically understand pruning at initialization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this rdfs:label "this"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_direction rdfs:label "this direction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_experiment rdfs:label "this experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-this_work rdfs:label "This work"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-three_block_layers rdfs:label "three block layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tiny-iamgenet rdfs:label "Tiny-IamgeNet"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-tomas_mikolov rdfs:label "Tomas Mikolov"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-tool_q rdfs:label "Tool Q"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-top-%CE%BA rdfs:label "top-κ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-top-%CE%BA_parameters rdfs:label "top-κ parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trainability_in_sparse_neural_networks rdfs:label "trainability in sparse neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trainability_of_a_network rdfs:label "trainability of a network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trainability_of_the_compressed_network rdfs:label "trainability of the compressed network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trainability_of_the_sparse_networks rdfs:label "trainability of the sparse networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trainable_sparse_networks rdfs:label "trainable sparse networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trained_quantization rdfs:label "trained quantization"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-training_compressed_networks rdfs:label "training compressed networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_logs rdfs:label "training logs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_procedure rdfs:label "training procedure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_set rdfs:label "training set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_the_model rdfs:label "training the model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-transfer rdfs:label "transfer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transfer_of_sparsity_experiment_results rdfs:label "Transfer of sparsity experiment results"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transient_chaos rdfs:label "transient chaos"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triples rdfs:label "triples"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two-stage_orthogonalization_process rdfs:label "two-stage orthogonalization process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uncompressed_network rdfs:label "uncompressed network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underparameterized_network rdfs:label "underparameterized network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-uniform_distribution rdfs:label "uniform distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-universal_data_distribution rdfs:label "universal data distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-universal_sparse_topology rdfs:label "universal sparse topology"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-university_of_california rdfs:label "University of California"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-university_of_oxford rdfs:label "University of Oxford"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unknown_data_distribution rdfs:label "unknown data distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsup rdfs:label "unsup"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_loss rdfs:label "unsupervised loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_losses rdfs:label "unsupervised losses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_pruning_strategy rdfs:label "unsupervised pruning strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-untrained_networks rdfs:label "untrained networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-value_distribution rdfs:label "value distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variable rdfs:label "variable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variance_%CF%83 rdfs:label "variance σ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variance_scaling_initialization_schemes rdfs:label "variance scaling initialization schemes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variance_scaling_methods rdfs:label "variance scaling methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variance_scaling_schemes rdfs:label "variance scaling schemes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variance_scaling_vs rdfs:label "variance scaling (VS)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-variety_of_settings rdfs:label "variety of settings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-varying_sparsity_levels_%CE%BA rdfs:label "varying sparsity levels κ¯"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vectorized rdfs:label "vectorized"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vectorized_form rdfs:label "vectorized form"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-very_large__1e11 rdfs:label "very large (> 1e+11)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-vinay_rao rdfs:label "Vinay Rao"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-vs-cs rdfs:label "VS-CS"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w1x rdfs:label "W1x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-we rdfs:label "we"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-weight_matrix rdfs:label "weight matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_matrix_wl rdfs:label "weight matrix Wl"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_sampling_distribution rdfs:label "weight sampling distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-well-conditioned_jacobians rdfs:label "well-conditioned Jacobians"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-widening_factor_k rdfs:label "widening factor (k)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-widening_k rdfs:label "Widening (k)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wider rdfs:label "wider"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wider__shallower rdfs:label "wider & shallower"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-william_j_dally rdfs:label "William J Dally"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-winning_lottery_ticket rdfs:label "winning lottery ticket"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-without_supervision rdfs:label "without supervision"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wkb_1 rdfs:label "Wkb 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wkx_0 rdfs:label "Wkx 0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wl1 rdfs:label "Wl−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wl2 rdfs:label "Wl−2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wl_ij rdfs:label "W^{l}_{ij}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wl_twl rdfs:label "(Wl) TWl"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wl_twl%CF%832w__i rdfs:label "(Wl) TWl/σ2w = I"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wojciech_tarnowski rdfs:label "Wojciech Tarnowski"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-worst_case rdfs:label "worst case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x%E2%81%B0 rdfs:label "x⁰"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_l1 rdfs:label "x l−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_l__h_lfor_all rdfs:label "x l = h l**for all**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xavier_glorot rdfs:label "Xavier Glorot"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-xl rdfs:label "x^l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xl-1 rdfs:label "x^{l-1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xl-1_j rdfs:label "x^{l-1}_{j}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-y rdfs:label "Y"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-y_l1 rdfs:label "Y l−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-yang__schoenholz rdfs:label "Yang & Schoenholz"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-yang_et_al_2019 rdfs:label "Yang et al. (2019)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-yasaman_bahri rdfs:label "Yasaman Bahri"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Paper-54ff6fb7db5b9fad-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "A Signalpropagationp**Erspective For** Pruningneuralnetworks Ati**Nitialization**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Namhoon Lee 1, **Thalaiyasingam Ajanthan** 2, **Stephen Gould** 2, **Philip H. S. Torr** 1 1**University of Oxford** 2**Australian National University** 1{namhoon,phst}@robots.ox.ac.uk 2{thalaiyasingam.ajanthan, stephen.gould}@anu.edu.au"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11-Sentence-111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11-Sentence-112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11-Sentence-113 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Namhoon Lee 1, **Thalaiyasingam Ajanthan** 2, **Stephen Gould** 2, **Philip H."@en ;
    askg-onto:inSentence "Namhoon Lee 1, **Thalaiyasingam Ajanthan** 2, **Stephen Gould** 2, **Philip H."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-namhoon_lee,
        askg-data:Entity-philip_h,
        askg-data:Entity-stephen_gould,
        askg-data:Entity-thalaiyasingam_ajanthan .

askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11-Sentence-112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "S."@en ;
    askg-onto:inSentence "S."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s,
        askg-data:Entity-unknown .

askg-data:Paper-54ff6fb7db5b9fad-Section-1-Paragraph-11-Sentence-113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Torr** 1 1**University of Oxford** 2**Australian National University** 1{namhoon,phst}@robots.ox.ac.uk 2{thalaiyasingam.ajanthan, stephen.gould}@anu.edu.au"@en ;
    askg-onto:inSentence "Torr** 1 1**University of Oxford** 2**Australian National University** 1{namhoon,phst}@robots.ox.ac.uk 2{thalaiyasingam.ajanthan, stephen.gould}@anu.edu.au"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anueduau,
        askg-data:Entity-australian_national_university,
        askg-data:Entity-namhoon,
        askg-data:Entity-robotsoxacuk,
        askg-data:Entity-stephengould,
        askg-data:Entity-thalaiyasingamajanthan,
        askg-data:Entity-university_of_oxford .

askg-data:Paper-54ff6fb7db5b9fad-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "4 S**Ignal Propagation In Sparse Neural Networks**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1010,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1012,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1019,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-102,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-103,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-104,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-107,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109 ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "So far, we have shown empirically and theoretically that layerwise dynamical isometry can improve the process of pruning at initialization. One remaining question to address is the following: how well do signals propagate in the pruned sparse networks? In this section, we first examine the effect of sparsity on signal propagation after pruning. We find that **indeed pruning can break dynamical** isometry, degrading trainability of sparse networks. Then **we follow up to present a simple, but** effective data-free method to recover approximate dynamical isometry on sparse networks. Setup**. The overall process is summarized as follows: Step 1. Initialize a network with a variance** scaling (VS) or layerwise dynamical isometry (LDI) satisfying orthogonal initialization. Step 2. Prune at initialization for a sparsity level κ¯ **based on connection sensitivity (CS); we also test random** (Rand) and magnitude (Mag) based pruning for comparison. Step 3. (optional) Enforce approximate dynamical isometry, if specified. Step 4. Train the pruned sparse network using SGD. We measure signal propagation (e.g**., Jacobian singular values) on the sparse network right before Step 4, and** observe training behavior during Step 4. Different methods **are named as {A}-{B}-{C}, where A,** B, C stand for initialization scheme, pruning method, (optional) approximate isometry, respectively."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1011,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10110,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10115,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10116,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1012,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1013,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1014,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1015,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1016,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1017,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1018,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1019 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "So far, we have shown empirically and theoretically that layerwise dynamical isometry can improve the process of pruning at initialization."@en ;
    askg-onto:inSentence "So far, we have shown empirically and theoretically that layerwise dynamical isometry can improve the process of pruning at initialization."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-pruning_at_initialization .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Prune at initialization for a sparsity level κ¯ **based on connection sensitivity (CS); we also test random** (Rand) and magnitude (Mag) based pruning for comparison."@en ;
    askg-onto:inSentence "Prune at initialization for a sparsity level κ¯ **based on connection sensitivity (CS); we also test random** (Rand) and magnitude (Mag) based pruning for comparison."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_cs,
        askg-data:Entity-initialization,
        askg-data:Entity-magnitude_mag,
        askg-data:Entity-prune,
        askg-data:Entity-pruning,
        askg-data:Entity-random_rand,
        askg-data:Entity-sparsity_level_%CE%BA .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Step 3."@en ;
    askg-onto:inSentence "Step 3."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_processing,
        askg-data:Entity-method,
        askg-data:Entity-step_3,
        askg-data:Entity-triple_extraction .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "(optional) Enforce approximate dynamical isometry, if specified."@en ;
    askg-onto:inSentence "(optional) Enforce approximate dynamical isometry, if specified."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approximate_dynamical_isometry,
        askg-data:Entity-if_specified .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Step 4."@en ;
    askg-onto:inSentence "Step 4."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-process,
        askg-data:Entity-step_4 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Train the pruned sparse network using SGD."@en ;
    askg-onto:inSentence "Train the pruned sparse network using SGD."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruned_sparse_network,
        askg-data:Entity-sgd .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "We measure signal propagation (e.g**., Jacobian singular values) on the sparse network right before Step 4, and** observe training behavior during Step 4."@en ;
    askg-onto:inSentence "We measure signal propagation (e.g**., Jacobian singular values) on the sparse network right before Step 4, and** observe training behavior during Step 4."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jacobian_singular_values,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-step_4,
        askg-data:Entity-training_behavior .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-10116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Different methods **are named as {A}-{B}-{C}, where A,** B, C stand for initialization scheme, pruning method, (optional) approximate isometry, respectively."@en ;
    askg-onto:inSentence "Different methods **are named as {A}-{B}-{C}, where A,** B, C stand for initialization scheme, pruning method, (optional) approximate isometry, respectively."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-a-b-c,
        askg-data:Entity-approximate_isometry,
        askg-data:Entity-b,
        askg-data:Entity-c,
        askg-data:Entity-initialization_scheme,
        askg-data:Entity-pruning_method .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "One remaining question to address is the following: how well do signals propagate in the pruned sparse networks?"@en ;
    askg-onto:inSentence "One remaining question to address is the following: how well do signals propagate in the pruned sparse networks?"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruned_sparse_networks,
        askg-data:Entity-signals .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In this section, we first examine the effect of sparsity on signal propagation after pruning."@en ;
    askg-onto:inSentence "In this section, we first examine the effect of sparsity on signal propagation after pruning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sparsity .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We find that **indeed pruning can break dynamical** isometry, degrading trainability of sparse networks."@en ;
    askg-onto:inSentence "We find that **indeed pruning can break dynamical** isometry, degrading trainability of sparse networks."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-pruning,
        askg-data:Entity-sparse_networks,
        askg-data:Entity-trainability .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1015 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Then **we follow up to present a simple, but** effective data-free method to recover approximate dynamical isometry on sparse networks."@en ;
    askg-onto:inSentence "Then **we follow up to present a simple, but** effective data-free method to recover approximate dynamical isometry on sparse networks."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approximate_dynamical_isometry,
        askg-data:Entity-data-free_method,
        askg-data:Entity-sparse_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1016 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Setup**."@en ;
    askg-onto:inSentence "Setup**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-setup .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1017 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The overall process is summarized as follows: Step 1."@en ;
    askg-onto:inSentence "The overall process is summarized as follows: Step 1."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-overall_process,
        askg-data:Entity-step_1 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1018 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Initialize a network with a variance** scaling (VS) or layerwise dynamical isometry (LDI) satisfying orthogonal initialization."@en ;
    askg-onto:inSentence "Initialize a network with a variance** scaling (VS) or layerwise dynamical isometry (LDI) satisfying orthogonal initialization."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-layerwise_dynamical_isometry_ldi,
        askg-data:Entity-network,
        askg-data:Entity-orthogonal_initialization,
        askg-data:Entity-variance_scaling_vs .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-101-Sentence-1019 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Step 2."@en ;
    askg-onto:inSentence "Step 2."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-procedure,
        askg-data:Entity-step_2 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1010 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "$$({\\boldsymbol{\\delta}})$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1010-Sentence-10101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1010-Sentence-10101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$({\\boldsymbol{\\delta}})$$"@en ;
    askg-onto:inSentence "$$({\\boldsymbol{\\delta}})$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B4,
        askg-data:Entity-delta .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Table 2: Pruning results for various neural networks on different datasets. All networks are pruned at initialization for the sparsity κ¯ = 90**% based on connection sensitivity scores as in Lee et al. (2019).** We report orthogonality scores (OS) and generalization errors (Error) on CIFAR-10 (VGG16, ResNets) and Tiny-ImageNet (WRN16); all results are the average over 5 runs. The first **and second** best results are highlighted in each column of errors. The orthogonal initialization with enforced approximate isometry method (i.e**., LDI-AI) achieves the best results across all tested architectures.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10115 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 2: Pruning results for various neural networks on different datasets."@en ;
    askg-onto:inSentence "Table 2: Pruning results for various neural networks on different datasets."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "All networks are pruned at initialization for the sparsity κ¯ = 90**% based on connection sensitivity scores as in Lee et al."@en ;
    askg-onto:inSentence "All networks are pruned at initialization for the sparsity κ¯ = 90**% based on connection sensitivity scores as in Lee et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BA__90,
        askg-data:Entity-connection_sensitivity_scores,
        askg-data:Entity-lee_et_al,
        askg-data:Entity-networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2019).** We report orthogonality scores (OS) and generalization errors (Error) on CIFAR-10 (VGG16, ResNets) and Tiny-ImageNet (WRN16); all results are the average over 5 runs."@en ;
    askg-onto:inSentence "(2019).** We report orthogonality scores (OS) and generalization errors (Error) on CIFAR-10 (VGG16, ResNets) and Tiny-ImageNet (WRN16); all results are the average over 5 runs."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-generalization_errors,
        askg-data:Entity-orthogonality_scores,
        askg-data:Entity-resnets,
        askg-data:Entity-tiny-imagenet,
        askg-data:Entity-vgg16,
        askg-data:Entity-wrn16 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The first **and second** best results are highlighted in each column of errors."@en ;
    askg-onto:inSentence "The first **and second** best results are highlighted in each column of errors."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_results,
        askg-data:Entity-each_column_of_errors .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1011-Sentence-10115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The orthogonal initialization with enforced approximate isometry method (i.e**., LDI-AI) achieves the best results across all tested architectures.**"@en ;
    askg-onto:inSentence "The orthogonal initialization with enforced approximate isometry method (i.e**., LDI-AI) achieves the best results across all tested architectures.**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_results_across_all_tested_architectures,
        askg-data:Entity-orthogonal_initialization_with_enforced_approximate_isometry_method_ldi-ai .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1012 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "| | VGG16 | | | ResNet32 | | ResNet56 | ResNet110 | | | WRN16 | |----------------|---------|-------|------|------------|------|------------|-------------|-------|-------|---------| | Initialization | OS | Error | OS | Error | OS | Error | OS | Error | OS | Error | | VS\\-L | 13.72 | 8.16 | 4.50 | 11.96 | 4.64 | 10.43 | 4.65 | 9.13 | 11.99 | 45.08 | | VS\\-G | 13.60 | 8.18 | 4.55 | 11.89 | 4.67 | 10.60 | 4.67 | 9.17 | 11.50 | 44.56 | | VS\\-H | 15.44 | 8.36 | 4.41 | 12.21 | 4.44 | 10.63 | 4.39 | 9.08 | 13.49 | 46.62 | | LDI | 13.33 | 8.11 | 4.43 | 11.55 | 4.51 | 10.08 | 4.57 | 8.88 | 11.28 | 44.20 | | LDI\\-AI | 6.43 | 7.99 | 2.62 | 11.47 | 2.79 | 9.85 | 2.92 | 8.78 | 6.62 | 44.12 |"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1012-Sentence-10121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1012-Sentence-10121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | VGG16 | | | ResNet32 | | ResNet56 | ResNet110 | | | WRN16 | |----------------|---------|-------|------|------------|------|------------|-------------|-------|-------|---------| | Initialization | OS | Error | OS | Error | OS | Error | OS | Error | OS | Error | | VS\\-L | 13.72 | 8.16 | 4.50 | 11.96 | 4.64 | 10.43 | 4.65 | 9.13 | 11.99 | 45.08 | | VS\\-G | 13.60 | 8.18 | 4.55 | 11.89 | 4.67 | 10.60 | 4.67 | 9.17 | 11.50 | 44.56 | | VS\\-H | 15.44 | 8.36 | 4.41 | 12.21 | 4.44 | 10.63 | 4.39 | 9.08 | 13.49 | 46.62 | | LDI | 13.33 | 8.11 | 4.43 | 11.55 | 4.51 | 10.08 | 4.57 | 8.88 | 11.28 | 44.20 | | LDI\\-AI | 6.43 | 7.99 | 2.62 | 11.47 | 2.79 | 9.85 | 2.92 | 8.78 | 6.62 | 44.12 |"@en ;
    askg-onto:inSentence "| | VGG16 | | | ResNet32 | | ResNet56 | ResNet110 | | | WRN16 | |----------------|---------|-------|------|------------|------|------------|-------------|-------|-------|---------| | Initialization | OS | Error | OS | Error | OS | Error | OS | Error | OS | Error | | VS\\-L | 13.72 | 8.16 | 4.50 | 11.96 | 4.64 | 10.43 | 4.65 | 9.13 | 11.99 | 45.08 | | VS\\-G | 13.60 | 8.18 | 4.55 | 11.89 | 4.67 | 10.60 | 4.67 | 9.17 | 11.50 | 44.56 | | VS\\-H | 15.44 | 8.36 | 4.41 | 12.21 | 4.44 | 10.63 | 4.39 | 9.08 | 13.49 | 46.62 | | LDI | 13.33 | 8.11 | 4.43 | 11.55 | 4.51 | 10.08 | 4.57 | 8.88 | 11.28 | 44.20 | | LDI\\-AI | 6.43 | 7.99 | 2.62 | 11.47 | 2.79 | 9.85 | 2.92 | 8.78 | 6.62 | 44.12 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi,
        askg-data:Entity-ldi-ai,
        askg-data:Entity-model,
        askg-data:Entity-resnet110,
        askg-data:Entity-resnet32,
        askg-data:Entity-resnet56,
        askg-data:Entity-score,
        askg-data:Entity-vgg16,
        askg-data:Entity-vs-g,
        askg-data:Entity-vs-h,
        askg-data:Entity-vs-l,
        askg-data:Entity-wrn16 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "Table 3: Pruning results for VGG16 and ResNet32 with different activation functions on CIFAR-10. We report generalization errors (avg. over 5 runs), and the first and second **best results are highlighted.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013-Sentence-10131,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013-Sentence-10132,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013-Sentence-10133 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013-Sentence-10131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 3: Pruning results for VGG16 and ResNet32 with different activation functions on CIFAR-10."@en ;
    askg-onto:inSentence "Table 3: Pruning results for VGG16 and ResNet32 with different activation functions on CIFAR-10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-activation_functions,
        askg-data:Entity-cifar-10,
        askg-data:Entity-resnet32,
        askg-data:Entity-vgg16 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013-Sentence-10132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We report generalization errors (avg."@en ;
    askg-onto:inSentence "We report generalization errors (avg."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-avg,
        askg-data:Entity-generalization_errors .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1013-Sentence-10133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "over 5 runs), and the first and second **best results are highlighted.**"@en ;
    askg-onto:inSentence "over 5 runs), and the first and second **best results are highlighted.**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_results,
        askg-data:Entity-first_and_second .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "| | | VGG16 | | | ResNet32 | | | | | | | |----------------|------|---------|------|-------|------------|-------|-----------------|---------|------|------|------| | Initialization | tanh | l\\-relu | selu | tanh | l\\-relu | selu | Loss | Superv. | K=3 | K=5 | K=7 | | VS\\-L | 9.07 | 7.78 | 8.70 | 13.41 | 12.04 | 12.26 | | | | | | | VS\\-G | 9.06 | 7.84 | 8.82 | 13.44 | 12.02 | 12.32 | GT | ✓ | 2.46 | 2.43 | 2.61 | | VS\\-H | 9.99 | 8.43 | 9.09 | 13.12 | 11.66 | 12.21 | Pred. (raw) | ✗ | 3.31 | 3.38 | 3.60 | | LDI | 8.76 | 7.53 | 8.21 | 13.22 | 11.58 | 11.98 | Pred. (softmax) | ✗ | 3.11 | 3.37 | 3.56 | | LDI\\-AI | 8.72 | 7.47 | 8.20 | 13.14 | 11.51 | 11.68 | Unif. | ✗ | 2.77 | 2.77 | 2.94 |"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10141,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10142,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10143,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10144,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10145 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | | VGG16 | | | ResNet32 | | | | | | | |----------------|------|---------|------|-------|------------|-------|-----------------|---------|------|------|------| | Initialization | tanh | l\\-relu | selu | tanh | l\\-relu | selu | Loss | Superv."@en ;
    askg-onto:inSentence "| | | VGG16 | | | ResNet32 | | | | | | | |----------------|------|---------|------|-------|------------|-------|-----------------|---------|------|------|------| | Initialization | tanh | l\\-relu | selu | tanh | l\\-relu | selu | Loss | Superv."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-activation_function,
        askg-data:Entity-l-relu,
        askg-data:Entity-model,
        askg-data:Entity-paradigm,
        askg-data:Entity-resnet32,
        askg-data:Entity-selu,
        askg-data:Entity-supervised_learning,
        askg-data:Entity-tanh,
        askg-data:Entity-vgg16 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "| K=3 | K=5 | K=7 | | VS\\-L | 9.07 | 7.78 | 8.70 | 13.41 | 12.04 | 12.26 | | | | | | | VS\\-G | 9.06 | 7.84 | 8.82 | 13.44 | 12.02 | 12.32 | GT | ✓ | 2.46 | 2.43 | 2.61 | | VS\\-H | 9.99 | 8.43 | 9.09 | 13.12 | 11.66 | 12.21 | Pred."@en ;
    askg-onto:inSentence "| K=3 | K=5 | K=7 | | VS\\-L | 9.07 | 7.78 | 8.70 | 13.41 | 12.04 | 12.26 | | | | | | | VS\\-G | 9.06 | 7.84 | 8.82 | 13.44 | 12.02 | 12.32 | GT | ✓ | 2.46 | 2.43 | 2.61 | | VS\\-H | 9.99 | 8.43 | 9.09 | 13.12 | 11.66 | 12.21 | Pred."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-906,
        askg-data:Entity-907,
        askg-data:Entity-999,
        askg-data:Entity-gt,
        askg-data:Entity-vs-g,
        askg-data:Entity-vs-h,
        askg-data:Entity-vs-l .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(raw) | ✗ | 3.31 | 3.38 | 3.60 | | LDI | 8.76 | 7.53 | 8.21 | 13.22 | 11.58 | 11.98 | Pred."@en ;
    askg-onto:inSentence "(raw) | ✗ | 3.31 | 3.38 | 3.60 | | LDI | 8.76 | 7.53 | 8.21 | 13.22 | 11.58 | 11.98 | Pred."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1158,
        askg-data:Entity-1198,
        askg-data:Entity-1322,
        askg-data:Entity-753,
        askg-data:Entity-821,
        askg-data:Entity-876,
        askg-data:Entity-ldi .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(softmax) | ✗ | 3.11 | 3.37 | 3.56 | | LDI\\-AI | 8.72 | 7.47 | 8.20 | 13.14 | 11.51 | 11.68 | Unif."@en ;
    askg-onto:inSentence "(softmax) | ✗ | 3.11 | 3.37 | 3.56 | | LDI\\-AI | 8.72 | 7.47 | 8.20 | 13.14 | 11.51 | 11.68 | Unif."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-ldi-ai,
        askg-data:Entity-platform,
        askg-data:Entity-softmax .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1014-Sentence-10145 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "| ✗ | 2.77 | 2.77 | 2.94 |"@en ;
    askg-onto:inSentence "| ✗ | 2.77 | 2.77 | 2.94 |"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-277,
        askg-data:Entity-294 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Table 4: Unsupervised pruning results for K**-layer MLP networks on MNIST. All** networks are pruned for sparsity κ¯ **= 90**% at orthogonal initialization. We report generalization errors (avg. over 10 runs)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10151,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10152,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10153,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10154 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 4: Unsupervised pruning results for K**-layer MLP networks on MNIST."@en ;
    askg-onto:inSentence "Table 4: Unsupervised pruning results for K**-layer MLP networks on MNIST."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k-layer_mlp_networks,
        askg-data:Entity-mnist .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "All** networks are pruned for sparsity κ¯ **= 90**% at orthogonal initialization."@en ;
    askg-onto:inSentence "All** networks are pruned for sparsity κ¯ **= 90**% at orthogonal initialization."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initialization,
        askg-data:Entity-networks,
        askg-data:Entity-orthogonal,
        askg-data:Entity-sparsity_%CE%BA__90 .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We report generalization errors (avg."@en ;
    askg-onto:inSentence "We report generalization errors (avg."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-avg,
        askg-data:Entity-generalization_errors .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1015-Sentence-10154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "over 10 runs)."@en ;
    askg-onto:inSentence "over 10 runs)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-over_10,
        askg-data:Entity-runs .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "network (i.e., *approximate dynamical isometry***), and therefore, signal propagation on the sparse** network is likely to behave similarly to the dense network. As expected, the training performance increased significantly (e.g**., compare LDI-CS with LDI-CS-AI for trainability). This works more** dramatically for random pruning; i.e**., even for randomly pruned sparse networks, training speed** increases significantly, implying the benefit of ensuring signal propagation."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016-Sentence-10161,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016-Sentence-10162,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016-Sentence-10163 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016-Sentence-10161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "network (i.e., *approximate dynamical isometry***), and therefore, signal propagation on the sparse** network is likely to behave similarly to the dense network."@en ;
    askg-onto:inSentence "network (i.e., *approximate dynamical isometry***), and therefore, signal propagation on the sparse** network is likely to behave similarly to the dense network."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approximate_dynamical_isometry,
        askg-data:Entity-dense_network,
        askg-data:Entity-network,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sparse_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016-Sentence-10162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As expected, the training performance increased significantly (e.g**., compare LDI-CS with LDI-CS-AI for trainability)."@en ;
    askg-onto:inSentence "As expected, the training performance increased significantly (e.g**., compare LDI-CS with LDI-CS-AI for trainability)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-cs,
        askg-data:Entity-ldi-cs-ai .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1016-Sentence-10163 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This works more** dramatically for random pruning; i.e**., even for randomly pruned sparse networks, training speed** increases significantly, implying the benefit of ensuring signal propagation."@en ;
    askg-onto:inSentence "This works more** dramatically for random pruning; i.e**., even for randomly pruned sparse networks, training speed** increases significantly, implying the benefit of ensuring signal propagation."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-random_pruning,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sparse_networks,
        askg-data:Entity-training_speed .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "- *Structure* (LDI-Rand-AI vs. LDI-CS-AI). Even if the approximate dynamical isometry is enforced identically, the network pruned using connection sensitivity shows better trainability than the randomly pruned network. This potentially means that the sparse topology obtained by different pruning methods also matters, in addition to signal propagation characteristics."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10171,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10172,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10173,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10174 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- *Structure* (LDI-Rand-AI vs."@en ;
    askg-onto:inSentence "- *Structure* (LDI-Rand-AI vs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-rand-ai,
        askg-data:Entity-structure .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10172 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "LDI-CS-AI)."@en ;
    askg-onto:inSentence "LDI-CS-AI)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-cs-ai,
        askg-data:Entity-platform .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10173 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Even if the approximate dynamical isometry is enforced identically, the network pruned using connection sensitivity shows better trainability than the randomly pruned network."@en ;
    askg-onto:inSentence "Even if the approximate dynamical isometry is enforced identically, the network pruned using connection sensitivity shows better trainability than the randomly pruned network."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network_pruned_using_connection_sensitivity,
        askg-data:Entity-randomly_pruned_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1017-Sentence-10174 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This potentially means that the sparse topology obtained by different pruning methods also matters, in addition to signal propagation characteristics."@en ;
    askg-onto:inSentence "This potentially means that the sparse topology obtained by different pruning methods also matters, in addition to signal propagation characteristics."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_methods,
        askg-data:Entity-signal_propagation_characteristics,
        askg-data:Entity-sparse_topology .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "- *Overparameterization* **(LDI-Dense vs. LDI-{CS, Rand}-AI). Even though the singular values** are restored to a level close to before pruning with approximate isometry, the non-pruned dense network converges faster than pruned networks. We hypothesize that in addition to signal propagation, overparameterization helps in optimization taking less time to find a minimum."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10181,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10182,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10183,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10184 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- *Overparameterization* **(LDI-Dense vs."@en ;
    askg-onto:inSentence "- *Overparameterization* **(LDI-Dense vs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-dense,
        askg-data:Entity-overparameterization .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "LDI-{CS, Rand}-AI)."@en ;
    askg-onto:inSentence "LDI-{CS, Rand}-AI)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai,
        askg-data:Entity-ldi-cs_rand-ai .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Even though the singular values** are restored to a level close to before pruning with approximate isometry, the non-pruned dense network converges faster than pruned networks."@en ;
    askg-onto:inSentence "Even though the singular values** are restored to a level close to before pruning with approximate isometry, the non-pruned dense network converges faster than pruned networks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-before_pruning,
        askg-data:Entity-dense_network,
        askg-data:Entity-non-pruned_dense_network,
        askg-data:Entity-pruned_networks,
        askg-data:Entity-singular_values .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1018-Sentence-10184 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We hypothesize that in addition to signal propagation, overparameterization helps in optimization taking less time to find a minimum."@en ;
    askg-onto:inSentence "We hypothesize that in addition to signal propagation, overparameterization helps in optimization taking less time to find a minimum."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-minimum,
        askg-data:Entity-optimization,
        askg-data:Entity-overparameterization .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1019 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "While being simple and data free (thus fast), our signal propagation perspective not only can be used to improve trainability of sparse neural networks, but also **to complement a common explanation for** decreased trainability of compressed networks which is often attributed merely to a reduced capacity. Our results also extend to the case of convolutional neural network (see Figure 8 in Appendix C)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1019-Sentence-10191,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1019-Sentence-10192 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1019-Sentence-10191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "While being simple and data free (thus fast), our signal propagation perspective not only can be used to improve trainability of sparse neural networks, but also **to complement a common explanation for** decreased trainability of compressed networks which is often attributed merely to a reduced capacity."@en ;
    askg-onto:inSentence "While being simple and data free (thus fast), our signal propagation perspective not only can be used to improve trainability of sparse neural networks, but also **to complement a common explanation for** decreased trainability of compressed networks which is often attributed merely to a reduced capacity."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-common_explanation,
        askg-data:Entity-decreased_trainability_of_compressed_networks,
        askg-data:Entity-reduced_capacity,
        askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-trainability_of_sparse_neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-1019-Sentence-10192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Our results also extend to the case of convolutional neural network (see Figure 8 in Appendix C)."@en ;
    askg-onto:inSentence "Our results also extend to the case of convolutional neural network (see Figure 8 in Appendix C)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_neural_network,
        askg-data:Entity-neural_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-102 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We perform this on 7-layer linear and tanh MLP networks as before 3."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-102-Sentence-1021 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-102-Sentence-1021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We perform this on 7-layer linear and tanh MLP networks as before 3."@en ;
    askg-onto:inSentence "We perform this on 7-layer linear and tanh MLP networks as before 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7-layer_linear_and_tanh_mlp_networks,
        askg-data:Entity-this .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-103 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "3**We conduct the same experiments for ReLU and Leaky-ReLU activation functions (see Appendix C).**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-103-Sentence-1031 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-103-Sentence-1031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3**We conduct the same experiments for ReLU and Leaky-ReLU activation functions (see Appendix C).**"@en ;
    askg-onto:inSentence "3**We conduct the same experiments for ReLU and Leaky-ReLU activation functions (see Appendix C).**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-activation_function,
        askg-data:Entity-experiments,
        askg-data:Entity-leaky-relu,
        askg-data:Entity-relu .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-104 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-104-Sentence-1041 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-104-Sentence-1041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:inSentence "![6_image_0.png](6_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-article,
        askg-data:Entity-author,
        askg-data:Entity-condition,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-institution,
        askg-data:Entity-method,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Figure 2: (a) Signal propagation (mean Jacobian singular values) in sparse networks pruned for varying sparsity levels κ¯, and (b) training behavior of the sparse network at κ¯ = 90**%. Signal** propagation, pruning scheme, and overparameterization affect trainability of sparse neural networks. We train using SGD with the initial learning rate of 0.1 decayed by 1/10 at every 20k iterations. All results are the average over 10 runs. We provide other singular value statistics (max, min, std), accuracy plot, and extended training results for random and **magnitude pruning in Appendix C.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1051,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1052,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1053,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1054,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1055 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1051 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 2: (a) Signal propagation (mean Jacobian singular values) in sparse networks pruned for varying sparsity levels κ¯, and (b) training behavior of the sparse network at κ¯ = 90**%."@en ;
    askg-onto:inSentence "Figure 2: (a) Signal propagation (mean Jacobian singular values) in sparse networks pruned for varying sparsity levels κ¯, and (b) training behavior of the sparse network at κ¯ = 90**%."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BA__90,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sparse_network,
        askg-data:Entity-sparse_networks,
        askg-data:Entity-varying_sparsity_levels_%CE%BA .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1052 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Signal** propagation, pruning scheme, and overparameterization affect trainability of sparse neural networks."@en ;
    askg-onto:inSentence "Signal** propagation, pruning scheme, and overparameterization affect trainability of sparse neural networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-overparameterization,
        askg-data:Entity-pruning_scheme,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-trainability_of_sparse_neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1053 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We train using SGD with the initial learning rate of 0.1 decayed by 1/10 at every 20k iterations."@en ;
    askg-onto:inSentence "We train using SGD with the initial learning rate of 0.1 decayed by 1/10 at every 20k iterations."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-110,
        askg-data:Entity-20k_iterations,
        askg-data:Entity-decayed_learning_rate,
        askg-data:Entity-learning_rate_of_01,
        askg-data:Entity-sgd .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1054 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "All results are the average over 10 runs."@en ;
    askg-onto:inSentence "All results are the average over 10 runs."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10_runs,
        askg-data:Entity-results .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-105-Sentence-1055 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We provide other singular value statistics (max, min, std), accuracy plot, and extended training results for random and **magnitude pruning in Appendix C.**"@en ;
    askg-onto:inSentence "We provide other singular value statistics (max, min, std), accuracy plot, and extended training results for random and **magnitude pruning in Appendix C.**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-extended_training_results,
        askg-data:Entity-magnitude_pruning,
        askg-data:Entity-singular_value_statistics .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Effect of pruning on signal propagation and trainability**. Let us first check signal propagation** measurements in the pruned networks (see Figure 2a). In general, Jacobian singular values decrease continuously as the sparsity level increases (except for {·}-{·**}-AI which we will explain later),** indicating that the more parameters are removed, the less faithful a network is likely to be with regard to propagating signals. Also, notice that the singular values drop more rapidly with random pruning compared to connection sensitivity based pruning methods (i.e., {·}-Rand vs. {·**}-CS).** This means that pruning using connection sensitivity is more robust to destruction of dynamical isometry and preserve better signal propagation in the sparse network than random pruning. We further note that, albeit marginal, layerwise dynamical isometry allows better signal propagation than variance scaling initialization, with relatively higher mean singular values and much lower standard deviations especially in the low sparsity regime (see Appendix C)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1061,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1062,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1063,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1064,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1065,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1066 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1061 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Effect of pruning on signal propagation and trainability**."@en ;
    askg-onto:inSentence "Effect of pruning on signal propagation and trainability**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-trainability .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1062 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let us first check signal propagation** measurements in the pruned networks (see Figure 2a)."@en ;
    askg-onto:inSentence "Let us first check signal propagation** measurements in the pruned networks (see Figure 2a)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruned_networks,
        askg-data:Entity-signal_propagation_measurements .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1063 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In general, Jacobian singular values decrease continuously as the sparsity level increases (except for {·}-{·**}-AI which we will explain later),** indicating that the more parameters are removed, the less faithful a network is likely to be with regard to propagating signals."@en ;
    askg-onto:inSentence "In general, Jacobian singular values decrease continuously as the sparsity level increases (except for {·}-{·**}-AI which we will explain later),** indicating that the more parameters are removed, the less faithful a network is likely to be with regard to propagating signals."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jacobian_singular_values,
        askg-data:Entity-sparsity_level_increases .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1064 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Also, notice that the singular values drop more rapidly with random pruning compared to connection sensitivity based pruning methods (i.e., {·}-Rand vs."@en ;
    askg-onto:inSentence "Also, notice that the singular values drop more rapidly with random pruning compared to connection sensitivity based pruning methods (i.e., {·}-Rand vs."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_based_pruning_methods,
        askg-data:Entity-random_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1065 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "{·**}-CS).** This means that pruning using connection sensitivity is more robust to destruction of dynamical isometry and preserve better signal propagation in the sparse network than random pruning."@en ;
    askg-onto:inSentence "{·**}-CS).** This means that pruning using connection sensitivity is more robust to destruction of dynamical isometry and preserve better signal propagation in the sparse network than random pruning."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-destruction_of_dynamical_isometry,
        askg-data:Entity-pruning,
        askg-data:Entity-random_pruning,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sparse_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-106-Sentence-1066 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We further note that, albeit marginal, layerwise dynamical isometry allows better signal propagation than variance scaling initialization, with relatively higher mean singular values and much lower standard deviations especially in the low sparsity regime (see Appendix C)."@en ;
    askg-onto:inSentence "We further note that, albeit marginal, layerwise dynamical isometry allows better signal propagation than variance scaling initialization, with relatively higher mean singular values and much lower standard deviations especially in the low sparsity regime (see Appendix C)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-better_signal_propagation,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-low_sparsity_regime,
        askg-data:Entity-lower_standard_deviations,
        askg-data:Entity-mean_singular_values,
        askg-data:Entity-variance_scaling_initialization .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-107 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Now, we look into the relation between signal propagation and trainability of the sparse networks."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-107-Sentence-1071 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-107-Sentence-1071 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Now, we look into the relation between signal propagation and trainability of the sparse networks."@en ;
    askg-onto:inSentence "Now, we look into the relation between signal propagation and trainability of the sparse networks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-signal_propagation,
        askg-data:Entity-trainability_of_the_sparse_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Figure 2b shows training behavior of the pruned networks (κ¯ = 90**%) obtained by different methods.** We can see a clear correlation between signal propagation capability of a network and its training performance; i.e**., the better a network propagates signals, the faster it converges during training.** For instance, compare the trainability of a network before and after pruning. That is, compared to LDI-Dense (κ¯ = 0), LDI-{CS, Mag, Rand} decrease the loss much slowly; random **pruning starts to** decrease the loss around 4k iteration, and finally reaches to **close to zero loss around 10k iterations** (see Appendix C), which is more than an order of magnitude slower than a network pruned by connection sensitivity. Recall that the pruned networks have much smaller singular values. Enforcing approximate dynamical isometry**. The observation above indicates that the better** signal propagation is ensured on sparse networks, the better their training performs. This motivates us to think of the following: what if we can *repair* **the broken isometry, before we start training** the pruned network, such that we can achieve trainability comparable to that of the dense network? Precisely, we consider the following:"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1081,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1082,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1083,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1084,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1085,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1086,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1087 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1081 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 2b shows training behavior of the pruned networks (κ¯ = 90**%) obtained by different methods.** We can see a clear correlation between signal propagation capability of a network and its training performance; i.e**., the better a network propagates signals, the faster it converges during training.** For instance, compare the trainability of a network before and after pruning."@en ;
    askg-onto:inSentence "Figure 2b shows training behavior of the pruned networks (κ¯ = 90**%) obtained by different methods.** We can see a clear correlation between signal propagation capability of a network and its training performance; i.e**., the better a network propagates signals, the faster it converges during training.** For instance, compare the trainability of a network before and after pruning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_methods,
        askg-data:Entity-network,
        askg-data:Entity-pruned_networks,
        askg-data:Entity-pruning,
        askg-data:Entity-signal_propagation_capability,
        askg-data:Entity-signals,
        askg-data:Entity-trainability_of_a_network,
        askg-data:Entity-training,
        askg-data:Entity-training_performance .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1082 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "That is, compared to LDI-Dense (κ¯ = 0), LDI-{CS, Mag, Rand} decrease the loss much slowly; random **pruning starts to** decrease the loss around 4k iteration, and finally reaches to **close to zero loss around 10k iterations** (see Appendix C), which is more than an order of magnitude slower than a network pruned by connection sensitivity."@en ;
    askg-onto:inSentence "That is, compared to LDI-Dense (κ¯ = 0), LDI-{CS, Mag, Rand} decrease the loss much slowly; random **pruning starts to** decrease the loss around 4k iteration, and finally reaches to **close to zero loss around 10k iterations** (see Appendix C), which is more than an order of magnitude slower than a network pruned by connection sensitivity."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0,
        askg-data:Entity-4k_iteration,
        askg-data:Entity-close_to_zero_loss_around_10k_iterations,
        askg-data:Entity-connection_sensitivity,
        askg-data:Entity-ldi-cs_mag_rand,
        askg-data:Entity-ldi-dense,
        askg-data:Entity-loss,
        askg-data:Entity-much_slowly,
        askg-data:Entity-network,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1083 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Recall that the pruned networks have much smaller singular values."@en ;
    askg-onto:inSentence "Recall that the pruned networks have much smaller singular values."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruned_networks,
        askg-data:Entity-smaller_singular_values .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1084 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Enforcing approximate dynamical isometry**."@en ;
    askg-onto:inSentence "Enforcing approximate dynamical isometry**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-enforcing_approximate_dynamical_isometry .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1085 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The observation above indicates that the better** signal propagation is ensured on sparse networks, the better their training performs."@en ;
    askg-onto:inSentence "The observation above indicates that the better** signal propagation is ensured on sparse networks, the better their training performs."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-signal_propagation,
        askg-data:Entity-sparse_networks,
        askg-data:Entity-training .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1086 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This motivates us to think of the following: what if we can *repair* **the broken isometry, before we start training** the pruned network, such that we can achieve trainability comparable to that of the dense network?"@en ;
    askg-onto:inSentence "This motivates us to think of the following: what if we can *repair* **the broken isometry, before we start training** the pruned network, such that we can achieve trainability comparable to that of the dense network?"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-the_broken_isometry,
        askg-data:Entity-the_dense_network,
        askg-data:Entity-the_pruned_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-108-Sentence-1087 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Precisely, we consider the following:"@en ;
    askg-onto:inSentence "Precisely, we consider the following:"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-following,
        askg-data:Entity-triple .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$$\\operatorname*{min}_{\\mathbf{W}^{l}}\\|(\\mathbf{C}^{l}\\odot\\mathbf{W}^{l})^{T}(\\mathbf{C}^{l}\\odot\\mathbf{W}^{l})-\\mathbf{I}^{l}\\|_{F}\\,,$$ lkF , (8) where Cl, Wl, I l**are the sparse mask obtained by pruning, the corresponding weights, the identity** matrix at layer l, respectively, and k · kF **is the Frobenius norm. We optimize this for all layers** identically using gradient descent. Given the sparsity topology Cland initial weights Wl, this datafree method attempts to find an optimal W∗**such that the combination of the sparse topology and** the weights to be layerwise orthogonal, potentially to the full rank capacity. This simple method (i.e., {·}-{·**}-AI, where AI is named for Approximate Isometry) turns out to be highly effective. The** results are provided in Figure 2, and we summarize our key findings below: - *Signal propagation* **(LDI-{CS, Rand} vs. LDI-{CS, Rand}-AI). The decreased singular values** (by pruning κ >¯ 0) bounce up dramatically and become close to the level before **pruning. This** means that orthogonality enforced by Equation 8 is achieved **in the sparse topology of the pruned**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1091,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1092,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1093,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1094,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1095,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1096,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1097,
        askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1098 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1091 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\operatorname*{min}_{\\mathbf{W}^{l}}\\|(\\mathbf{C}^{l}\\odot\\mathbf{W}^{l})^{T}(\\mathbf{C}^{l}\\odot\\mathbf{W}^{l})-\\mathbf{I}^{l}\\|_{F}\\,,$$ lkF , (8) where Cl, Wl, I l**are the sparse mask obtained by pruning, the corresponding weights, the identity** matrix at layer l, respectively, and k · kF **is the Frobenius norm."@en ;
    askg-onto:inSentence "$$\\operatorname*{min}_{\\mathbf{W}^{l}}\\|(\\mathbf{C}^{l}\\odot\\mathbf{W}^{l})^{T}(\\mathbf{C}^{l}\\odot\\mathbf{W}^{l})-\\mathbf{I}^{l}\\|_{F}\\,,$$ lkF , (8) where Cl, Wl, I l**are the sparse mask obtained by pruning, the corresponding weights, the identity** matrix at layer l, respectively, and k · kF **is the Frobenius norm."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cl,
        askg-data:Entity-corresponding_weights,
        askg-data:Entity-frobenius_norm,
        askg-data:Entity-identity_matrix,
        askg-data:Entity-il,
        askg-data:Entity-k__k_f,
        askg-data:Entity-sparse_mask,
        askg-data:Entity-wl .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1092 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We optimize this for all layers** identically using gradient descent."@en ;
    askg-onto:inSentence "We optimize this for all layers** identically using gradient descent."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_layers,
        askg-data:Entity-gradient_descent .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1093 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Given the sparsity topology Cland initial weights Wl, this datafree method attempts to find an optimal W∗**such that the combination of the sparse topology and** the weights to be layerwise orthogonal, potentially to the full rank capacity."@en ;
    askg-onto:inSentence "Given the sparsity topology Cland initial weights Wl, this datafree method attempts to find an optimal W∗**such that the combination of the sparse topology and** the weights to be layerwise orthogonal, potentially to the full rank capacity."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-datafree_method,
        askg-data:Entity-full_rank_capacity,
        askg-data:Entity-initial_weights,
        askg-data:Entity-layerwise_orthogonal,
        askg-data:Entity-method,
        askg-data:Entity-optimal_w,
        askg-data:Entity-sparse_topology,
        askg-data:Entity-sparsity_topology,
        askg-data:Entity-weights .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1094 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This simple method (i.e., {·}-{·**}-AI, where AI is named for Approximate Isometry) turns out to be highly effective."@en ;
    askg-onto:inSentence "This simple method (i.e., {·}-{·**}-AI, where AI is named for Approximate Isometry) turns out to be highly effective."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai,
        askg-data:Entity-approximate_isometry,
        askg-data:Entity-method .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1095 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The** results are provided in Figure 2, and we summarize our key findings below: - *Signal propagation* **(LDI-{CS, Rand} vs."@en ;
    askg-onto:inSentence "The** results are provided in Figure 2, and we summarize our key findings below: - *Signal propagation* **(LDI-{CS, Rand} vs."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-cs_rand,
        askg-data:Entity-signal_propagation .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1096 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "LDI-{CS, Rand}-AI)."@en ;
    askg-onto:inSentence "LDI-{CS, Rand}-AI)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai,
        askg-data:Entity-ldi-cs_rand-ai .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1097 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The decreased singular values** (by pruning κ >¯ 0) bounce up dramatically and become close to the level before **pruning."@en ;
    askg-onto:inSentence "The decreased singular values** (by pruning κ >¯ 0) bounce up dramatically and become close to the level before **pruning."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning,
        askg-data:Entity-singular_values .

askg-data:Paper-54ff6fb7db5b9fad-Section-10-Paragraph-109-Sentence-1098 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "This** means that orthogonality enforced by Equation 8 is achieved **in the sparse topology of the pruned**"@en ;
    askg-onto:inSentence "This** means that orthogonality enforced by Equation 8 is achieved **in the sparse topology of the pruned**"^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equation_8,
        askg-data:Entity-orthogonality,
        askg-data:Entity-sparse_topology,
        askg-data:Entity-the_pruned .

askg-data:Paper-54ff6fb7db5b9fad-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "5 V**Alidation And Extensions**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this section, we aim to demonstrate the efficacy of our signal propagation perspective on a wide variety of settings. We first evaluate the idea of employing layerwise dynamical isometry on various modern neural networks. In addition, we further study the role of supervision under the pruning at initialization regime, extending it to unsupervised pruning. Our results show that indeed, pruning can be approached from the signal propagation perspective at varying scale, bringing forth the notion of neural architecture sculpting. The experiment settings **used to generate the presented results are** detailed in Appendix B. The code can be found here: https://github.com/namhoonlee/spp-public."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1115,
        askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1116 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this section, we aim to demonstrate the efficacy of our signal propagation perspective on a wide variety of settings."@en ;
    askg-onto:inSentence "In this section, we aim to demonstrate the efficacy of our signal propagation perspective on a wide variety of settings."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-variety_of_settings .

askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We first evaluate the idea of employing layerwise dynamical isometry on various modern neural networks."@en ;
    askg-onto:inSentence "We first evaluate the idea of employing layerwise dynamical isometry on various modern neural networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-modern_neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In addition, we further study the role of supervision under the pruning at initialization regime, extending it to unsupervised pruning."@en ;
    askg-onto:inSentence "In addition, we further study the role of supervision under the pruning at initialization regime, extending it to unsupervised pruning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_at_initialization_regime,
        askg-data:Entity-supervision,
        askg-data:Entity-unsupervised_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our results show that indeed, pruning can be approached from the signal propagation perspective at varying scale, bringing forth the notion of neural architecture sculpting."@en ;
    askg-onto:inSentence "Our results show that indeed, pruning can be approached from the signal propagation perspective at varying scale, bringing forth the notion of neural architecture sculpting."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-neural_architecture_sculpting,
        askg-data:Entity-pruning,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The experiment settings **used to generate the presented results are** detailed in Appendix B."@en ;
    askg-onto:inSentence "The experiment settings **used to generate the presented results are** detailed in Appendix B."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiment_settings,
        askg-data:Entity-results .

askg-data:Paper-54ff6fb7db5b9fad-Section-11-Paragraph-111-Sentence-1116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The code can be found here: https://github.com/namhoonlee/spp-public."@en ;
    askg-onto:inSentence "The code can be found here: https://github.com/namhoonlee/spp-public."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-httpsgithubcomnamhoonleespp-public,
        askg-data:Entity-spp-public .

askg-data:Paper-54ff6fb7db5b9fad-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "5.1 E**Valuation On Various Neural Networks And Datasets**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121 ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Here, we verify that our signal propagation perspective for **pruning neural networks at initialization** is indeed valid, by evaluating further on various modern neural networks and datasets. To this end, we provide orthogonality scores (OS) and generalization errors of the sparse networks obtained by different methods and show that layerwise dynamical isometry with enforced approximate isometry results in the best performance; here, we define OS as 1l Pl k(Cl ⊙Wl) T(Cl ⊙Wl)−I lkF **, which** can be used to indicate how close are the weight matrices in each layer of the pruned network to being orthogonal. All results are the average of 5 runs, and we do not optimize anything specific for a particular case (see Appendix B for experiment settings). **The results are presented in Table 2.** The best **pruning results are achieved when the approximate dynamical isometry is enforced on the** pruned sparse network (i.e., LDI-AI), across all tested architectures. Also, the second best **results** are achieved with the orthogonal initialization that satisfies layerwise dynamical isometry (i.e**., LDI).** Looking closely, it is evident that there exists a high correlation between the orthogonality scores and the performance of pruned networks; i.e., the network initialized to have the lowest orthogonality scores achieves the best generalization errors after training. Note that the orthogonality scores being close to 0, by definition, states how faithful a network **will be with regard to letting signals** propagate without being amplified or attenuated. Therefore, the fact that a pruned network with the lowest orthogonality scores tends to yield good generalization errors further validates that our signal propagation perspective is indeed effective for pruning at **initialization. Moreover, we test for other** nonlinear activation functions (tanh, leaky-relu, selu), **and found that the orthogonal initialization** consistently outperforms variance scaling methods (see Table 3)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1211,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1212,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1213,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1214,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1215,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1216,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1217,
        askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1218 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Here, we verify that our signal propagation perspective for **pruning neural networks at initialization** is indeed valid, by evaluating further on various modern neural networks and datasets."@en ;
    askg-onto:inSentence "Here, we verify that our signal propagation perspective for **pruning neural networks at initialization** is indeed valid, by evaluating further on various modern neural networks and datasets."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-modern_neural_networks,
        askg-data:Entity-neural_networks,
        askg-data:Entity-pruning_neural_networks_at_initialization,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To this end, we provide orthogonality scores (OS) and generalization errors of the sparse networks obtained by different methods and show that layerwise dynamical isometry with enforced approximate isometry results in the best performance; here, we define OS as 1l Pl k(Cl ⊙Wl) T(Cl ⊙Wl)−I lkF **, which** can be used to indicate how close are the weight matrices in each layer of the pruned network to being orthogonal."@en ;
    askg-onto:inSentence "To this end, we provide orthogonality scores (OS) and generalization errors of the sparse networks obtained by different methods and show that layerwise dynamical isometry with enforced approximate isometry results in the best performance; here, we define OS as 1l Pl k(Cl ⊙Wl) T(Cl ⊙Wl)−I lkF **, which** can be used to indicate how close are the weight matrices in each layer of the pruned network to being orthogonal."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_performance,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-orthogonal,
        askg-data:Entity-orthogonality_scores,
        askg-data:Entity-os,
        askg-data:Entity-weight_matrices .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "All results are the average of 5 runs, and we do not optimize anything specific for a particular case (see Appendix B for experiment settings)."@en ;
    askg-onto:inSentence "All results are the average of 5 runs, and we do not optimize anything specific for a particular case (see Appendix B for experiment settings)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_runs,
        askg-data:Entity-anything_specific_for_a_particular_case,
        askg-data:Entity-experiment_settings,
        askg-data:Entity-results,
        askg-data:Entity-we .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "**The results are presented in Table 2.** The best **pruning results are achieved when the approximate dynamical isometry is enforced on the** pruned sparse network (i.e., LDI-AI), across all tested architectures."@en ;
    askg-onto:inSentence "**The results are presented in Table 2.** The best **pruning results are achieved when the approximate dynamical isometry is enforced on the** pruned sparse network (i.e., LDI-AI), across all tested architectures."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_tested_architectures,
        askg-data:Entity-approximate_dynamical_isometry,
        askg-data:Entity-architectures,
        askg-data:Entity-ldi-ai,
        askg-data:Entity-pruned_sparse_network,
        askg-data:Entity-pruning_results .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Also, the second best **results** are achieved with the orthogonal initialization that satisfies layerwise dynamical isometry (i.e**., LDI).** Looking closely, it is evident that there exists a high correlation between the orthogonality scores and the performance of pruned networks; i.e., the network initialized to have the lowest orthogonality scores achieves the best generalization errors after training."@en ;
    askg-onto:inSentence "Also, the second best **results** are achieved with the orthogonal initialization that satisfies layerwise dynamical isometry (i.e**., LDI).** Looking closely, it is evident that there exists a high correlation between the orthogonality scores and the performance of pruned networks; i.e., the network initialized to have the lowest orthogonality scores achieves the best generalization errors after training."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_generalization_errors,
        askg-data:Entity-best_results,
        askg-data:Entity-lowest_orthogonality_scores,
        askg-data:Entity-network,
        askg-data:Entity-orthogonal_initialization,
        askg-data:Entity-orthogonality_scores,
        askg-data:Entity-performance_of_pruned_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Note that the orthogonality scores being close to 0, by definition, states how faithful a network **will be with regard to letting signals** propagate without being amplified or attenuated."@en ;
    askg-onto:inSentence "Note that the orthogonality scores being close to 0, by definition, states how faithful a network **will be with regard to letting signals** propagate without being amplified or attenuated."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_network,
        askg-data:Entity-network,
        askg-data:Entity-orthogonality_scores,
        askg-data:Entity-signals .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Therefore, the fact that a pruned network with the lowest orthogonality scores tends to yield good generalization errors further validates that our signal propagation perspective is indeed effective for pruning at **initialization."@en ;
    askg-onto:inSentence "Therefore, the fact that a pruned network with the lowest orthogonality scores tends to yield good generalization errors further validates that our signal propagation perspective is indeed effective for pruning at **initialization."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-good_generalization_errors,
        askg-data:Entity-pruned_network,
        askg-data:Entity-pruning_at_initialization,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-12-Paragraph-121-Sentence-1218 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Moreover, we test for other** nonlinear activation functions (tanh, leaky-relu, selu), **and found that the orthogonal initialization** consistently outperforms variance scaling methods (see Table 3)."@en ;
    askg-onto:inSentence "Moreover, we test for other** nonlinear activation functions (tanh, leaky-relu, selu), **and found that the orthogonal initialization** consistently outperforms variance scaling methods (see Table 3)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nonlinear_activation_functions,
        askg-data:Entity-orthogonal_initialization,
        askg-data:Entity-variance_scaling_methods .

askg-data:Paper-54ff6fb7db5b9fad-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "5.2 P**Runing Without Supervision**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-132,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-134 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "So far, we have shown that pruning random networks can be approached from a signal propagation perspective by ensuring faithful connection sensitivity. **Another factor that constitutes connection** sensitivity is the loss term. At a glance, it is not obvious how informative the supervised loss measured on a random network will be for connection sensitivity. In this section, we look into the effect of supervision, by simply replacing the loss computed using ground-truth labels with different unsupervised surrogate losses as follows: replacing the target distribution using ground-truth labels with uniform distribution (Unif.), and using the averaged output prediction of the network (Pred.; softmax/raw). The results for MLP networks are in Table 4. Even though unsupervised pruning results are not as good as the supervised case, the results are still interesting, especially for the uniform case, in that there was no supervision given. We thus **experiment further for the uniform case** on other networks, and obtain the following results: 8.25, 11.69, 11.01, 8.82 errors (%) for VGG16, ResNet32, ResNet56, ResNet110, respectively. Surprisingly, the results are often competitive to that of pruning with supervision (i.e**., compare to LDI results in Table 2). Notably, previous pruning** algorithms assume the existence of supervision a priori. Being the first demonstration, along with the signal propagation perspective, this unsupervised pruning strategy can be useful in scenarios where there are no labels or only weak supervision is available."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-13110,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1312,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1313,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1314,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1315,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1316,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1317,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1318,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1319 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "So far, we have shown that pruning random networks can be approached from a signal propagation perspective by ensuring faithful connection sensitivity."@en ;
    askg-onto:inSentence "So far, we have shown that pruning random networks can be approached from a signal propagation perspective by ensuring faithful connection sensitivity."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful_connection_sensitivity,
        askg-data:Entity-pruning_random_networks,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-13110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Being the first demonstration, along with the signal propagation perspective, this unsupervised pruning strategy can be useful in scenarios where there are no labels or only weak supervision is available."@en ;
    askg-onto:inSentence "Being the first demonstration, along with the signal propagation perspective, this unsupervised pruning strategy can be useful in scenarios where there are no labels or only weak supervision is available."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_demonstration,
        askg-data:Entity-scenarios_with_no_labels,
        askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-unsupervised_pruning_strategy .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Another factor that constitutes connection** sensitivity is the loss term."@en ;
    askg-onto:inSentence "**Another factor that constitutes connection** sensitivity is the loss term."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-loss_term .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "At a glance, it is not obvious how informative the supervised loss measured on a random network will be for connection sensitivity."@en ;
    askg-onto:inSentence "At a glance, it is not obvious how informative the supervised loss measured on a random network will be for connection sensitivity."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-random_network,
        askg-data:Entity-supervised_loss .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In this section, we look into the effect of supervision, by simply replacing the loss computed using ground-truth labels with different unsupervised surrogate losses as follows: replacing the target distribution using ground-truth labels with uniform distribution (Unif.), and using the averaged output prediction of the network (Pred.; softmax/raw)."@en ;
    askg-onto:inSentence "In this section, we look into the effect of supervision, by simply replacing the loss computed using ground-truth labels with different unsupervised surrogate losses as follows: replacing the target distribution using ground-truth labels with uniform distribution (Unif.), and using the averaged output prediction of the network (Pred.; softmax/raw)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_labels,
        askg-data:Entity-network,
        askg-data:Entity-softmaxraw,
        askg-data:Entity-supervision,
        askg-data:Entity-target_distribution,
        askg-data:Entity-uniform_distribution,
        askg-data:Entity-unsupervised_surrogate_losses .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The results for MLP networks are in Table 4."@en ;
    askg-onto:inSentence "The results for MLP networks are in Table 4."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mlp_networks,
        askg-data:Entity-table_4 .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1316 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Even though unsupervised pruning results are not as good as the supervised case, the results are still interesting, especially for the uniform case, in that there was no supervision given."@en ;
    askg-onto:inSentence "Even though unsupervised pruning results are not as good as the supervised case, the results are still interesting, especially for the uniform case, in that there was no supervision given."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-interesting_results,
        askg-data:Entity-unsupervised_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1317 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We thus **experiment further for the uniform case** on other networks, and obtain the following results: 8.25, 11.69, 11.01, 8.82 errors (%) for VGG16, ResNet32, ResNet56, ResNet110, respectively."@en ;
    askg-onto:inSentence "We thus **experiment further for the uniform case** on other networks, and obtain the following results: 8.25, 11.69, 11.01, 8.82 errors (%) for VGG16, ResNet32, ResNet56, ResNet110, respectively."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1101_errors_,
        askg-data:Entity-1169_errors_,
        askg-data:Entity-825_errors_,
        askg-data:Entity-882_errors_,
        askg-data:Entity-resnet110,
        askg-data:Entity-resnet32,
        askg-data:Entity-resnet56,
        askg-data:Entity-vgg16 .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1318 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Surprisingly, the results are often competitive to that of pruning with supervision (i.e**., compare to LDI results in Table 2)."@en ;
    askg-onto:inSentence "Surprisingly, the results are often competitive to that of pruning with supervision (i.e**., compare to LDI results in Table 2)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi_results,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-131-Sentence-1319 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Notably, previous pruning** algorithms assume the existence of supervision a priori."@en ;
    askg-onto:inSentence "Notably, previous pruning** algorithms assume the existence of supervision a priori."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_algorithms,
        askg-data:Entity-the_existence_of_supervision_a_priori .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-132 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "ization, and report gen. errors (average over 10 runs)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-132-Sentence-1321,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-132-Sentence-1322 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-132-Sentence-1321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "ization, and report gen."@en ;
    askg-onto:inSentence "ization, and report gen."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-report_gen .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-132-Sentence-1322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "errors (average over 10 runs)."@en ;
    askg-onto:inSentence "errors (average over 10 runs)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10_runs,
        askg-data:Entity-errors .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Dataset Error **Error** Category prune train&test sup. → unsup. (∆) **rand** Standard MNIST MNIST 2.42 → 2.94 +0.52 **15.56** Transfer F-MNIST MNIST 2.66 → 2.80 +0.14 **18.03** Standard F-MNIST F-MNIST 11.90 → 13.01 +1.11 **24.72** Transfer MNIST F-MNIST 14.17 → 13.39 -0.78 **24.89** To demonstrate further, we also conducted transfer of sparsity **experiments such as** transferring a pruned network from one task to another (MNIST ↔ **Fashion-MNIST).** Table 5 shows that, while pruning results may degrade if sparsity is transferred, or done without supervision, less impact is caused for unsupervised pruning when transferred to a different task (i.e., 0.52 to 0.14 on MNIST, and 1.11 to −0.78 on F- MNIST). This indicates that inductive bias exists in data, affecting transfer and unsupervised pruning, and potentially, that \"universal\" sparse topology might be obtainable if universal data distribution is known (e.g**., extremely large dataset in practice). This may help in situations where different** tasks from unknown data distribution are to be performed (e.g**., continual learning). We also tested** two other unsupervised losses, but none performed as well as **uniform loss (**e.g**., Jacobian norms** kJk1: 5.03, kJk2**: 3.00 vs. Unif.: 2.94), implying that if pruning is to be unsupervised, the uniform** loss would better be used, because other unsupervised losses depend on the input data (thus can suffer from inductive bias). Random pruning degrades significantly at high sparsity for all cases."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1331,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1332,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1333,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1334,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1335,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1336,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1337,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1338 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Dataset Error **Error** Category prune train&test sup."@en ;
    askg-onto:inSentence "Dataset Error **Error** Category prune train&test sup."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset_error,
        askg-data:Entity-error_category,
        askg-data:Entity-prune_traintest .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "→ unsup."@en ;
    askg-onto:inSentence "→ unsup."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-unsup .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(∆) **rand** Standard MNIST MNIST 2.42 → 2.94 +0.52 **15.56** Transfer F-MNIST MNIST 2.66 → 2.80 +0.14 **18.03** Standard F-MNIST F-MNIST 11.90 → 13.01 +1.11 **24.72** Transfer MNIST F-MNIST 14.17 → 13.39 -0.78 **24.89** To demonstrate further, we also conducted transfer of sparsity **experiments such as** transferring a pruned network from one task to another (MNIST ↔ **Fashion-MNIST).** Table 5 shows that, while pruning results may degrade if sparsity is transferred, or done without supervision, less impact is caused for unsupervised pruning when transferred to a different task (i.e., 0.52 to 0.14 on MNIST, and 1.11 to −0.78 on F- MNIST)."@en ;
    askg-onto:inSentence "(∆) **rand** Standard MNIST MNIST 2.42 → 2.94 +0.52 **15.56** Transfer F-MNIST MNIST 2.66 → 2.80 +0.14 **18.03** Standard F-MNIST F-MNIST 11.90 → 13.01 +1.11 **24.72** Transfer MNIST F-MNIST 14.17 → 13.39 -0.78 **24.89** To demonstrate further, we also conducted transfer of sparsity **experiments such as** transferring a pruned network from one task to another (MNIST ↔ **Fashion-MNIST).** Table 5 shows that, while pruning results may degrade if sparsity is transferred, or done without supervision, less impact is caused for unsupervised pruning when transferred to a different task (i.e., 0.52 to 0.14 on MNIST, and 1.11 to −0.78 on F- MNIST)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fashion-mnist,
        askg-data:Entity-mnist,
        askg-data:Entity-pruned_network,
        askg-data:Entity-sparsity,
        askg-data:Entity-sparsity_experiments,
        askg-data:Entity-unsupervised_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1334 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This indicates that inductive bias exists in data, affecting transfer and unsupervised pruning, and potentially, that \"universal\" sparse topology might be obtainable if universal data distribution is known (e.g**., extremely large dataset in practice)."@en ;
    askg-onto:inSentence "This indicates that inductive bias exists in data, affecting transfer and unsupervised pruning, and potentially, that \"universal\" sparse topology might be obtainable if universal data distribution is known (e.g**., extremely large dataset in practice)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-dataset,
        askg-data:Entity-extremely_large,
        askg-data:Entity-inductive_bias,
        askg-data:Entity-transfer,
        askg-data:Entity-universal_data_distribution,
        askg-data:Entity-universal_sparse_topology,
        askg-data:Entity-unsupervised_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1335 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This may help in situations where different** tasks from unknown data distribution are to be performed (e.g**., continual learning)."@en ;
    askg-onto:inSentence "This may help in situations where different** tasks from unknown data distribution are to be performed (e.g**., continual learning)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-continual_learning,
        askg-data:Entity-learning,
        askg-data:Entity-tasks,
        askg-data:Entity-unknown_data_distribution .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1336 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We also tested** two other unsupervised losses, but none performed as well as **uniform loss (**e.g**., Jacobian norms** kJk1: 5.03, kJk2**: 3.00 vs."@en ;
    askg-onto:inSentence "We also tested** two other unsupervised losses, but none performed as well as **uniform loss (**e.g**., Jacobian norms** kJk1: 5.03, kJk2**: 3.00 vs."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-300,
        askg-data:Entity-503,
        askg-data:Entity-jacobian_norms_kjk1,
        askg-data:Entity-jacobian_norms_kjk2,
        askg-data:Entity-uniform_loss,
        askg-data:Entity-unsupervised_losses .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1337 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Unif.: 2.94), implying that if pruning is to be unsupervised, the uniform** loss would better be used, because other unsupervised losses depend on the input data (thus can suffer from inductive bias)."@en ;
    askg-onto:inSentence "Unif.: 2.94), implying that if pruning is to be unsupervised, the uniform** loss would better be used, because other unsupervised losses depend on the input data (thus can suffer from inductive bias)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-uniform_loss,
        askg-data:Entity-unsupervised_loss .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-133-Sentence-1338 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Random pruning degrades significantly at high sparsity for all cases."@en ;
    askg-onto:inSentence "Random pruning degrades significantly at high sparsity for all cases."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-high_sparsity,
        askg-data:Entity-random_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-134 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Table 5: Transfer of sparsity experiment results for LeNet. We prune for κ¯ = 97% at orthogonal initial-"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-134-Sentence-1341,
        askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-134-Sentence-1342 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-134-Sentence-1341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 5: Transfer of sparsity experiment results for LeNet."@en ;
    askg-onto:inSentence "Table 5: Transfer of sparsity experiment results for LeNet."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiment,
        askg-data:Entity-lenet,
        askg-data:Entity-model,
        askg-data:Entity-transfer_of_sparsity_experiment_results .

askg-data:Paper-54ff6fb7db5b9fad-Section-13-Paragraph-134-Sentence-1342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We prune for κ¯ = 97% at orthogonal initial-"@en ;
    askg-onto:inSentence "We prune for κ¯ = 97% at orthogonal initial-"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BA,
        askg-data:Entity-97 .

askg-data:Paper-54ff6fb7db5b9fad-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "5.3 N**Eural Architecture Sculpting**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We have shown that pruning at initialization, even when no supervision is provided, can be effective based on the signal propagation perspective. This begs the question of whether pruning needs to be limited to pre-shaped architectures or not. In other words, **what if pruning is applied to an arbitrarily** bulky network and is treated as *sculpting* **an architecture? In order to find out, we conduct the** following experiments: we take a popular pre-designed architecture (ResNet20 in He et al. (2016)) as a base network, and consider a range of variants that are originally bigger than the base model, but pruned to have the same number of parameters as the base dense network. Specifically, we consider the following equivalents: (1) **the same number of residual blocks, but with larger widths;** (2) a reduced number of residual blocks with larger widths; (3) **a larger residual block and the same** width (see Table 6 in Appendix B for details). The results are **presented in Figure 3.** Overall, the sparse equivalents record lower errors than the dense base model. Notice that some models are extremely sparse (e.g., Equivalent 1 pruned for κ¯ = 98.4%). While all networks have the same number of parameters, discovered sparse equivalents outperform the dense reference network. This result is well aligned with recent findings in Kalchbrenner et al. (2018): large sparse networks can outperform their small dense counterpart, while enjoying increased computational and memory efficiency via a dedicated implementation for sparsity in practice. Also, it seems that pruning wider networks tends to be more effective in producing a better model than pruning deeper ones (e.g**., Equivalent 1 vs. Equivalent 3). We** further note that unlike existing prior works, the sparse networks are discovered by sculpting arbitrarily-designed architecture, without pretraining nor supervision."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1411,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14110,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1412,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1413,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1414,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1415,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1416,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1417,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1418,
        askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1419 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We have shown that pruning at initialization, even when no supervision is provided, can be effective based on the signal propagation perspective."@en ;
    askg-onto:inSentence "We have shown that pruning at initialization, even when no supervision is provided, can be effective based on the signal propagation perspective."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_at_initialization,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "This result is well aligned with recent findings in Kalchbrenner et al."@en ;
    askg-onto:inSentence "This result is well aligned with recent findings in Kalchbrenner et al."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kalchbrenner_et_al,
        askg-data:Entity-recent_findings .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "(2018): large sparse networks can outperform their small dense counterpart, while enjoying increased computational and memory efficiency via a dedicated implementation for sparsity in practice."@en ;
    askg-onto:inSentence "(2018): large sparse networks can outperform their small dense counterpart, while enjoying increased computational and memory efficiency via a dedicated implementation for sparsity in practice."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dedicated_implementation_for_sparsity,
        askg-data:Entity-increased_computational_and_memory_efficiency,
        askg-data:Entity-large_sparse_networks,
        askg-data:Entity-practice,
        askg-data:Entity-small_dense_counterpart .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Also, it seems that pruning wider networks tends to be more effective in producing a better model than pruning deeper ones (e.g**., Equivalent 1 vs."@en ;
    askg-onto:inSentence "Also, it seems that pruning wider networks tends to be more effective in producing a better model than pruning deeper ones (e.g**., Equivalent 1 vs."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_better_model,
        askg-data:Entity-pruning_wider_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Equivalent 3)."@en ;
    askg-onto:inSentence "Equivalent 3)."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-equivalent_3 .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-14114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "We** further note that unlike existing prior works, the sparse networks are discovered by sculpting arbitrarily-designed architecture, without pretraining nor supervision."@en ;
    askg-onto:inSentence "We** further note that unlike existing prior works, the sparse networks are discovered by sculpting arbitrarily-designed architecture, without pretraining nor supervision."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-sculpting_arbitrarily-designed_architecture,
        askg-data:Entity-sparse_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This begs the question of whether pruning needs to be limited to pre-shaped architectures or not."@en ;
    askg-onto:inSentence "This begs the question of whether pruning needs to be limited to pre-shaped architectures or not."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pre-shaped_architectures,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In other words, **what if pruning is applied to an arbitrarily** bulky network and is treated as *sculpting* **an architecture?"@en ;
    askg-onto:inSentence "In other words, **what if pruning is applied to an arbitrarily** bulky network and is treated as *sculpting* **an architecture?"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architecture,
        askg-data:Entity-bulky_network,
        askg-data:Entity-pruning,
        askg-data:Entity-sculpting .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In order to find out, we conduct the** following experiments: we take a popular pre-designed architecture (ResNet20 in He et al."@en ;
    askg-onto:inSentence "In order to find out, we conduct the** following experiments: we take a popular pre-designed architecture (ResNet20 in He et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pre-designed_architecture,
        askg-data:Entity-resnet20 .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2016)) as a base network, and consider a range of variants that are originally bigger than the base model, but pruned to have the same number of parameters as the base dense network."@en ;
    askg-onto:inSentence "(2016)) as a base network, and consider a range of variants that are originally bigger than the base model, but pruned to have the same number of parameters as the base dense network."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-base_dense_network,
        askg-data:Entity-base_model,
        askg-data:Entity-base_network,
        askg-data:Entity-dense_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Specifically, we consider the following equivalents: (1) **the same number of residual blocks, but with larger widths;** (2) a reduced number of residual blocks with larger widths; (3) **a larger residual block and the same** width (see Table 6 in Appendix B for details)."@en ;
    askg-onto:inSentence "Specifically, we consider the following equivalents: (1) **the same number of residual blocks, but with larger widths;** (2) a reduced number of residual blocks with larger widths; (3) **a larger residual block and the same** width (see Table 6 in Appendix B for details)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_larger_residual_block,
        askg-data:Entity-a_reduced_number_of_residual_blocks,
        askg-data:Entity-the_same_number_of_residual_blocks,
        askg-data:Entity-the_same_width .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1417 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The results are **presented in Figure 3.** Overall, the sparse equivalents record lower errors than the dense base model."@en ;
    askg-onto:inSentence "The results are **presented in Figure 3.** Overall, the sparse equivalents record lower errors than the dense base model."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dense_base_model,
        askg-data:Entity-higher_errors,
        askg-data:Entity-lower_errors,
        askg-data:Entity-sparse_equivalents .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1418 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Notice that some models are extremely sparse (e.g., Equivalent 1 pruned for κ¯ = 98.4%)."@en ;
    askg-onto:inSentence "Notice that some models are extremely sparse (e.g., Equivalent 1 pruned for κ¯ = 98.4%)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BA__984,
        askg-data:Entity-equivalent_1 .

askg-data:Paper-54ff6fb7db5b9fad-Section-14-Paragraph-141-Sentence-1419 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "While all networks have the same number of parameters, discovered sparse equivalents outperform the dense reference network."@en ;
    askg-onto:inSentence "While all networks have the same number of parameters, discovered sparse equivalents outperform the dense reference network."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dense_reference_network,
        askg-data:Entity-sparse_equivalents .

askg-data:Paper-54ff6fb7db5b9fad-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "6 D**Iscussion And Future Work**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-151,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "![9_image_0.png](9_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-151-Sentence-1511 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![9_image_0.png](9_image_0.png)"@en ;
    askg-onto:inSentence "![9_image_0.png](9_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-9_image_0png,
        askg-data:Entity-image .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Figure 3: Neural architecture sculpting results on CIFAR-10. We report generalization errors (avg. over 5 **runs). All** networks have the same number of parameters (269k) and trained identically."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1521,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1522,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1523,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1524 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 3: Neural architecture sculpting results on CIFAR-10."@en ;
    askg-onto:inSentence "Figure 3: Neural architecture sculpting results on CIFAR-10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-neural_architecture_sculpting .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We report generalization errors (avg."@en ;
    askg-onto:inSentence "We report generalization errors (avg."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-avg,
        askg-data:Entity-generalization_errors .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "over 5 **runs)."@en ;
    askg-onto:inSentence "over 5 **runs)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiment,
        askg-data:Entity-runs .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-152-Sentence-1524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "All** networks have the same number of parameters (269k) and trained identically."@en ;
    askg-onto:inSentence "All** networks have the same number of parameters (269k) and trained identically."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-269k,
        askg-data:Entity-identically,
        askg-data:Entity-networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "In this work, we have approached the problem of pruning neural networks at initialization from a signal propagation perspective. Based on observing the effect of varying the initialization, we found that initial weights have a critical impact on connection sensitivity measurements and hence pruning results. This led us to conduct theoretical analysis based on dynamical isometry and a mean field theory, and formally characterize a sufficient condition to ensure faithful signal propagation in a given network. Moreover, our analysis on compressed neural networks revealed that signal propagation characteristics of a sparse network highly correlates with its trainability, and also that pruning can break dynamical isometry ensured on a network at **initialization, resulting in degradation** of trainability of the compressed network. To address this, **we introduced a simple, yet effective** data-free method to recover the orthogonality and enhance trainability of the compressed network. Finally, throughout a range of validation and extension experiments, we verified that our signal propagation perspective is effective for understanding, improving, and extending the task of pruning at initialization across various settings. We believe that **our results on the increased trainability of** compressed networks can take us one step towards finding \"winning lottery ticket\" (i.e**., a set of** initial weights that given a sparse topology can quickly reach to a generalization performance that is comparable to the uncompressed network, once trained) suggested in Frankle & Carbin (2019). We point out, however, that there remains several aspects to **consider. While pruning on enforced** isometry produces trainable sparse networks, the two-stage orthogonalization process (i.e**., prune** first and enforce the orthogonality later) can be suboptimal **especially at a high sparsity level. Also,** network weights change during training, which can affect signal propagation characteristics, and therefore, dynamical isometry may not continue to hold over **the course of training. We hypothesize** that a potential key to successful neural network compression is to address the complex interplay between optimization and signal propagation, and it might be immensely beneficial if an optimization naturally takes place in the space of isometry. We believe that our signal propagation perspective provides a means to formulate this as an optimization problem by maximizing the trainability of sparse networks while pruning, and we intend to explore this **direction as a future work.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1531,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-15310,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-15311,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-15312,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1532,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1533,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1534,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1535,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1536,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1537,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1538,
        askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1539 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this work, we have approached the problem of pruning neural networks at initialization from a signal propagation perspective."@en ;
    askg-onto:inSentence "In this work, we have approached the problem of pruning neural networks at initialization from a signal propagation perspective."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-neural_networks,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-15310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Also,** network weights change during training, which can affect signal propagation characteristics, and therefore, dynamical isometry may not continue to hold over **the course of training."@en ;
    askg-onto:inSentence "Also,** network weights change during training, which can affect signal propagation characteristics, and therefore, dynamical isometry may not continue to hold over **the course of training."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-network_weights,
        askg-data:Entity-signal_propagation_characteristics,
        askg-data:Entity-the_course_of_training,
        askg-data:Entity-training .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-15311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "We hypothesize** that a potential key to successful neural network compression is to address the complex interplay between optimization and signal propagation, and it might be immensely beneficial if an optimization naturally takes place in the space of isometry."@en ;
    askg-onto:inSentence "We hypothesize** that a potential key to successful neural network compression is to address the complex interplay between optimization and signal propagation, and it might be immensely beneficial if an optimization naturally takes place in the space of isometry."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-isometry,
        askg-data:Entity-neural_network_compression,
        askg-data:Entity-optimization,
        askg-data:Entity-optimization_and_signal_propagation .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-15312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "We believe that our signal propagation perspective provides a means to formulate this as an optimization problem by maximizing the trainability of sparse networks while pruning, and we intend to explore this **direction as a future work.**"@en ;
    askg-onto:inSentence "We believe that our signal propagation perspective provides a means to formulate this as an optimization problem by maximizing the trainability of sparse networks while pruning, and we intend to explore this **direction as a future work.**"^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_work,
        askg-data:Entity-means_to_formulate_as_an_optimization_problem,
        askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-sparse_networks,
        askg-data:Entity-this_direction,
        askg-data:Entity-trainability .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Based on observing the effect of varying the initialization, we found that initial weights have a critical impact on connection sensitivity measurements and hence pruning results."@en ;
    askg-onto:inSentence "Based on observing the effect of varying the initialization, we found that initial weights have a critical impact on connection sensitivity measurements and hence pruning results."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_weights,
        askg-data:Entity-pruning_results .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This led us to conduct theoretical analysis based on dynamical isometry and a mean field theory, and formally characterize a sufficient condition to ensure faithful signal propagation in a given network."@en ;
    askg-onto:inSentence "This led us to conduct theoretical analysis based on dynamical isometry and a mean field theory, and formally characterize a sufficient condition to ensure faithful signal propagation in a given network."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-faithful_signal_propagation,
        askg-data:Entity-mean_field_theory,
        askg-data:Entity-network,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sufficient_condition,
        askg-data:Entity-theoretical_analysis .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, our analysis on compressed neural networks revealed that signal propagation characteristics of a sparse network highly correlates with its trainability, and also that pruning can break dynamical isometry ensured on a network at **initialization, resulting in degradation** of trainability of the compressed network."@en ;
    askg-onto:inSentence "Moreover, our analysis on compressed neural networks revealed that signal propagation characteristics of a sparse network highly correlates with its trainability, and also that pruning can break dynamical isometry ensured on a network at **initialization, resulting in degradation** of trainability of the compressed network."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compressed_neural_networks,
        askg-data:Entity-degradation,
        askg-data:Entity-dynamical_isometry,
        askg-data:Entity-network_at_initialization,
        askg-data:Entity-pruning,
        askg-data:Entity-signal_propagation_characteristics,
        askg-data:Entity-sparse_network,
        askg-data:Entity-trainability,
        askg-data:Entity-trainability_of_the_compressed_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1535 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To address this, **we introduced a simple, yet effective** data-free method to recover the orthogonality and enhance trainability of the compressed network."@en ;
    askg-onto:inSentence "To address this, **we introduced a simple, yet effective** data-free method to recover the orthogonality and enhance trainability of the compressed network."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compressed_network,
        askg-data:Entity-data-free_method,
        askg-data:Entity-orthogonality,
        askg-data:Entity-trainability .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1536 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Finally, throughout a range of validation and extension experiments, we verified that our signal propagation perspective is effective for understanding, improving, and extending the task of pruning at initialization across various settings."@en ;
    askg-onto:inSentence "Finally, throughout a range of validation and extension experiments, we verified that our signal propagation perspective is effective for understanding, improving, and extending the task of pruning at initialization across various settings."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-task_of_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1537 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We believe that **our results on the increased trainability of** compressed networks can take us one step towards finding \"winning lottery ticket\" (i.e**., a set of** initial weights that given a sparse topology can quickly reach to a generalization performance that is comparable to the uncompressed network, once trained) suggested in Frankle & Carbin (2019)."@en ;
    askg-onto:inSentence "We believe that **our results on the increased trainability of** compressed networks can take us one step towards finding \"winning lottery ticket\" (i.e**., a set of** initial weights that given a sparse topology can quickly reach to a generalization performance that is comparable to the uncompressed network, once trained) suggested in Frankle & Carbin (2019)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-compressed_networks,
        askg-data:Entity-frankle__carbin,
        askg-data:Entity-generalization_performance,
        askg-data:Entity-initial_weights,
        askg-data:Entity-uncompressed_network,
        askg-data:Entity-winning_lottery_ticket .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1538 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We point out, however, that there remains several aspects to **consider."@en ;
    askg-onto:inSentence "We point out, however, that there remains several aspects to **consider."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aspects,
        askg-data:Entity-several .

askg-data:Paper-54ff6fb7db5b9fad-Section-15-Paragraph-153-Sentence-1539 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "While pruning on enforced** isometry produces trainable sparse networks, the two-stage orthogonalization process (i.e**., prune** first and enforce the orthogonality later) can be suboptimal **especially at a high sparsity level."@en ;
    askg-onto:inSentence "While pruning on enforced** isometry produces trainable sparse networks, the two-stage orthogonalization process (i.e**., prune** first and enforce the orthogonality later) can be suboptimal **especially at a high sparsity level."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-high_sparsity_level,
        askg-data:Entity-isometry,
        askg-data:Entity-suboptimal,
        askg-data:Entity-trainable_sparse_networks,
        askg-data:Entity-two-stage_orthogonalization_process .

askg-data:Paper-54ff6fb7db5b9fad-Section-16 a askg-onto:Section ;
    rdfs:label "Section 16"@en ;
    domo:Text "A**Cknowledgments**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-16-Paragraph-161 ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-16-Paragraph-161 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "This work was supported by the ERC grant ERC-2012-AdG 321162-HELIOS, EPSRC grant Seebibyte EP/M013774/1, EPSRC/MURI grant EP/N019474/1 and the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016). We would also like to acknowledge the Royal Academy of Engineering and FiveAI, and thank Richard Hartley, Puneet Dokania and Amartya Sanyal for helpful discussions."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-16-Paragraph-161-Sentence-1611,
        askg-data:Paper-54ff6fb7db5b9fad-Section-16-Paragraph-161-Sentence-1612 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-16-Paragraph-161-Sentence-1611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This work was supported by the ERC grant ERC-2012-AdG 321162-HELIOS, EPSRC grant Seebibyte EP/M013774/1, EPSRC/MURI grant EP/N019474/1 and the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016)."@en ;
    askg-onto:inSentence "This work was supported by the ERC grant ERC-2012-AdG 321162-HELIOS, EPSRC grant Seebibyte EP/M013774/1, EPSRC/MURI grant EP/N019474/1 and the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australian_research_council_centre_of_excellence_for_robotic_vision,
        askg-data:Entity-this_work .

askg-data:Paper-54ff6fb7db5b9fad-Section-16-Paragraph-161-Sentence-1612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We would also like to acknowledge the Royal Academy of Engineering and FiveAI, and thank Richard Hartley, Puneet Dokania and Amartya Sanyal for helpful discussions."@en ;
    askg-onto:inSentence "We would also like to acknowledge the Royal Academy of Engineering and FiveAI, and thank Richard Hartley, Puneet Dokania and Amartya Sanyal for helpful discussions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-amartya_sanyal,
        askg-data:Entity-discussions,
        askg-data:Entity-fiveai,
        askg-data:Entity-puneet_dokania,
        askg-data:Entity-richard_hartley,
        askg-data:Entity-royal_academy_of_engineering .

askg-data:Paper-54ff6fb7db5b9fad-Section-17 a askg-onto:Section ;
    rdfs:label "Section 17"@en ;
    domo:Text "R**Eferences**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174 ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. *ICLR***, 2019.** Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. *AISTATS***, 2010.** Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. *ICLR***, 2016.** Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. *ICCV***, 2015.** Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. *CVPR***, 2016.** Geoffrey E Hinton and Ruslan R Salakhutdinov. Reducing the dimensionality of data with neural networks. *Science***, 2006.** Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande, Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander Dieleman, and Koray Kavukcuoglu. Efficient neural audio synthesis. *ICML***, 2018.** Yann LeCun, Léon Bottou, Genevieve B. Orr, and Klaus-Robert **Müller. Efficient backprop.** Neural Networks: Tricks of the Trade**, 1998.** Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. *Nature***, 2015.** Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. *ICLR***, 2019.** Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difficulty of training recurrent neural networks. 2013."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1711,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17110,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17115,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17116,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17117,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17118,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17119,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1712,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17120,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17121,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17122,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17123,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1713,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1714,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1715,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1716,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1717,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1718,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1719 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Jonathan Frankle and Michael Carbin."@en ;
    askg-onto:inSentence "Jonathan Frankle and Michael Carbin."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jonathan_frankle,
        askg-data:Entity-michael_carbin,
        askg-data:Entity-person .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Deep residual learning for image recognition."@en ;
    askg-onto:inSentence "Deep residual learning for image recognition."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_residual_learning,
        askg-data:Entity-image_recognition .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "*CVPR***, 2016.** Geoffrey E Hinton and Ruslan R Salakhutdinov."@en ;
    askg-onto:inSentence "*CVPR***, 2016.** Geoffrey E Hinton and Ruslan R Salakhutdinov."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr_2016,
        askg-data:Entity-geoffrey_e_hinton,
        askg-data:Entity-ruslan_r_salakhutdinov .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Reducing the dimensionality of data with neural networks."@en ;
    askg-onto:inSentence "Reducing the dimensionality of data with neural networks."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-dimensionality_reduction,
        askg-data:Entity-neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "*Science***, 2006.** Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande, Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander Dieleman, and Koray Kavukcuoglu."@en ;
    askg-onto:inSentence "*Science***, 2006.** Nal Kalchbrenner, Erich Elsen, Karen Simonyan, Seb Noury, Norman Casagrande, Edward Lockhart, Florian Stimberg, Aaron van den Oord, Sander Dieleman, and Koray Kavukcuoglu."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aaron_van_den_oord,
        askg-data:Entity-author,
        askg-data:Entity-edward_lockhart,
        askg-data:Entity-erich_elsen,
        askg-data:Entity-florian_stimberg,
        askg-data:Entity-karen_simonyan,
        askg-data:Entity-koray_kavukcuoglu,
        askg-data:Entity-nal_kalchbrenner,
        askg-data:Entity-norman_casagrande,
        askg-data:Entity-publication,
        askg-data:Entity-sander_dieleman,
        askg-data:Entity-science,
        askg-data:Entity-seb_noury .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Efficient neural audio synthesis."@en ;
    askg-onto:inSentence "Efficient neural audio synthesis."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-neural_audio_synthesis .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "*ICML***, 2018.** Yann LeCun, Léon Bottou, Genevieve B."@en ;
    askg-onto:inSentence "*ICML***, 2018.** Yann LeCun, Léon Bottou, Genevieve B."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-genevieve_b,
        askg-data:Entity-icml,
        askg-data:Entity-l%C3%A9on_bottou,
        askg-data:Entity-publication,
        askg-data:Entity-yann_lecun .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Orr, and Klaus-Robert **Müller."@en ;
    askg-onto:inSentence "Orr, and Klaus-Robert **Müller."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-klaus-robert_m%C3%BCller,
        askg-data:Entity-orr .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17117 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Efficient backprop.** Neural Networks: Tricks of the Trade**, 1998.** Yann LeCun, Yoshua Bengio, and Geoffrey Hinton."@en ;
    askg-onto:inSentence "Efficient backprop.** Neural Networks: Tricks of the Trade**, 1998.** Yann LeCun, Yoshua Bengio, and Geoffrey Hinton."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1998,
        askg-data:Entity-efficient_backprop_neural_networks_tricks_of_the_trade,
        askg-data:Entity-geoffrey_hinton,
        askg-data:Entity-yann_lecun,
        askg-data:Entity-yoshua_bengio .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17118 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Deep learning."@en ;
    askg-onto:inSentence "Deep learning."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-deep_learning .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17119 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "*Nature***, 2015.** Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr."@en ;
    askg-onto:inSentence "*Nature***, 2015.** Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-namhoon_lee,
        askg-data:Entity-nature_2015,
        askg-data:Entity-philip_hs_torr,
        askg-data:Entity-thalaiyasingam_ajanthan .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The lottery ticket hypothesis: Finding sparse, trainable neural networks."@en ;
    askg-onto:inSentence "The lottery ticket hypothesis: Finding sparse, trainable neural networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lottery_ticket_hypothesis,
        askg-data:Entity-model,
        askg-data:Entity-sparse_trainable_neural_networks,
        askg-data:Entity-theory .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17120 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Snip: Single-shot network pruning based on connection sensitivity."@en ;
    askg-onto:inSentence "Snip: Single-shot network pruning based on connection sensitivity."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-single-shot_network_pruning,
        askg-data:Entity-technique .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17121 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "*ICLR***, 2019.** Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio."@en ;
    askg-onto:inSentence "*ICLR***, 2019.** Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-iclr,
        askg-data:Entity-iclr_2019,
        askg-data:Entity-razvan_pascanu,
        askg-data:Entity-tomas_mikolov,
        askg-data:Entity-yoshua_bengio .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17122 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "On the difficulty of training recurrent neural networks."@en ;
    askg-onto:inSentence "On the difficulty of training recurrent neural networks."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-difficulty,
        askg-data:Entity-recurrent_neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-17123 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "2013."@en ;
    askg-onto:inSentence "2013."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2013,
        askg-data:Entity-research .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*ICLR***, 2019.** Xavier Glorot and Yoshua Bengio."@en ;
    askg-onto:inSentence "*ICLR***, 2019.** Xavier Glorot and Yoshua Bengio."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iclr_2019,
        askg-data:Entity-xavier_glorot,
        askg-data:Entity-yoshua_bengio .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Understanding the difficulty of training deep feedforward neural networks."@en ;
    askg-onto:inSentence "Understanding the difficulty of training deep feedforward neural networks."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_feedforward_neural_networks,
        askg-data:Entity-training .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "*AISTATS***, 2010.** Song Han, Huizi Mao, and William J Dally."@en ;
    askg-onto:inSentence "*AISTATS***, 2010.** Song Han, Huizi Mao, and William J Dally."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2010,
        askg-data:Entity-aistats,
        askg-data:Entity-huizi_mao,
        askg-data:Entity-song_han,
        askg-data:Entity-william_j_dally .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1716 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding."@en ;
    askg-onto:inSentence "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compressing_deep_neural_networks,
        askg-data:Entity-deep_compression,
        askg-data:Entity-huffman_coding,
        askg-data:Entity-pruning,
        askg-data:Entity-trained_quantization .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1717 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "*ICLR***, 2016.** Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun."@en ;
    askg-onto:inSentence "*ICLR***, 2016.** Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-iclr,
        askg-data:Entity-jian_sun,
        askg-data:Entity-kaiming_he,
        askg-data:Entity-publication,
        askg-data:Entity-shaoqing_ren,
        askg-data:Entity-xiangyu_zhang .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1718 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification."@en ;
    askg-onto:inSentence "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classification,
        askg-data:Entity-human-level_performance,
        askg-data:Entity-imagenet_classification,
        askg-data:Entity-rectifiers .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-171-Sentence-1719 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "*ICCV***, 2015.** Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun."@en ;
    askg-onto:inSentence "*ICCV***, 2015.** Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iccv,
        askg-data:Entity-iccv_2015,
        askg-data:Entity-jian_sun,
        askg-data:Entity-kaiming_he,
        askg-data:Entity-shaoqing_ren,
        askg-data:Entity-xiangyu_zhang .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Jeffrey Pennington, Samuel Schoenholz, and Surya Ganguli. **Resurrecting the sigmoid in deep** learning through dynamical isometry: theory and practice. *NeurIPS***, 2017.** Jeffrey Pennington, Samuel S Schoenholz, and Surya Ganguli. The emergence of spectral universality in deep networks. *AISTATS***, 2018.** Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, and Surya Ganguli. Exponential expressivity in deep neural networks through transient chaos. *NeurIPS***, 2016.** Russell Reed. Pruning algorithms-a survey. *Neural Networks***, 1993.** Andrew M Saxe, James L McClelland, and Surya Ganguli. Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. *ICLR***, 2014.** Samuel S Schoenholz, Justin Gilmer, Surya Ganguli, and Jascha Sohl-Dickstein. Deep information propagation. *ICLR***, 2017.** Wojciech Tarnowski, Piotr Warchoł, Stanisław Jastrz˛ebski, Jacek Tabor, and Maciej A Nowak. Dynamical isometry is achieved in residual networks in a universal way for any activation function."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1721,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17210,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17211,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17212,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17213,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17214,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1722,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1723,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1724,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1725,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1726,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1727,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1728,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1729 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Jeffrey Pennington, Samuel Schoenholz, and Surya Ganguli."@en ;
    askg-onto:inSentence "Jeffrey Pennington, Samuel Schoenholz, and Surya Ganguli."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jeffrey_pennington,
        askg-data:Entity-person,
        askg-data:Entity-samuel_schoenholz,
        askg-data:Entity-surya_ganguli .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks."@en ;
    askg-onto:inSentence "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_linear_neural_networks,
        askg-data:Entity-learning_in_deep_linear_neural_networks,
        askg-data:Entity-neural_networks,
        askg-data:Entity-nonlinear_dynamics .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17211 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "*ICLR***, 2014.** Samuel S Schoenholz, Justin Gilmer, Surya Ganguli, and Jascha Sohl-Dickstein."@en ;
    askg-onto:inSentence "*ICLR***, 2014.** Samuel S Schoenholz, Justin Gilmer, Surya Ganguli, and Jascha Sohl-Dickstein."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-conference,
        askg-data:Entity-iclr,
        askg-data:Entity-jascha_sohl-dickstein,
        askg-data:Entity-justin_gilmer,
        askg-data:Entity-samuel_s_schoenholz,
        askg-data:Entity-surya_ganguli .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17212 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Deep information propagation."@en ;
    askg-onto:inSentence "Deep information propagation."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-deep_information_propagation .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17213 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "*ICLR***, 2017.** Wojciech Tarnowski, Piotr Warchoł, Stanisław Jastrz˛ebski, Jacek Tabor, and Maciej A Nowak."@en ;
    askg-onto:inSentence "*ICLR***, 2017.** Wojciech Tarnowski, Piotr Warchoł, Stanisław Jastrz˛ebski, Jacek Tabor, and Maciej A Nowak."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-conference,
        askg-data:Entity-iclr,
        askg-data:Entity-jacek_tabor,
        askg-data:Entity-maciej_a_nowak,
        askg-data:Entity-piotr_warcho%C5%82,
        askg-data:Entity-stanis%C5%82aw_jastrz%C4%99bski,
        askg-data:Entity-wojciech_tarnowski .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-17214 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Dynamical isometry is achieved in residual networks in a universal way for any activation function."@en ;
    askg-onto:inSentence "Dynamical isometry is achieved in residual networks in a universal way for any activation function."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_activation_function,
        askg-data:Entity-dynamical_isometry,
        askg-data:Entity-residual_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Resurrecting the sigmoid in deep** learning through dynamical isometry: theory and practice."@en ;
    askg-onto:inSentence "**Resurrecting the sigmoid in deep** learning through dynamical isometry: theory and practice."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-dynamical_isometry,
        askg-data:Entity-function,
        askg-data:Entity-paradigm,
        askg-data:Entity-sigmoid,
        askg-data:Entity-theory .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*NeurIPS***, 2017.** Jeffrey Pennington, Samuel S Schoenholz, and Surya Ganguli."@en ;
    askg-onto:inSentence "*NeurIPS***, 2017.** Jeffrey Pennington, Samuel S Schoenholz, and Surya Ganguli."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-jeffrey_pennington,
        askg-data:Entity-neurips,
        askg-data:Entity-publication,
        askg-data:Entity-samuel_s_schoenholz,
        askg-data:Entity-surya_ganguli .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The emergence of spectral universality in deep networks."@en ;
    askg-onto:inSentence "The emergence of spectral universality in deep networks."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_networks,
        askg-data:Entity-spectral_universality .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1725 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "*AISTATS***, 2018.** Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, and Surya Ganguli."@en ;
    askg-onto:inSentence "*AISTATS***, 2018.** Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, and Surya Ganguli."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aistats_2018,
        askg-data:Entity-ben_poole,
        askg-data:Entity-jascha_sohl-dickstein,
        askg-data:Entity-maithra_raghu,
        askg-data:Entity-subhaneil_lahiri,
        askg-data:Entity-surya_ganguli .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1726 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Exponential expressivity in deep neural networks through transient chaos."@en ;
    askg-onto:inSentence "Exponential expressivity in deep neural networks through transient chaos."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_neural_networks,
        askg-data:Entity-exponential_expressivity,
        askg-data:Entity-transient_chaos .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1727 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "*NeurIPS***, 2016.** Russell Reed."@en ;
    askg-onto:inSentence "*NeurIPS***, 2016.** Russell Reed."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-russell_reed .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1728 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Pruning algorithms-a survey."@en ;
    askg-onto:inSentence "Pruning algorithms-a survey."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_algorithms,
        askg-data:Entity-survey .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-172-Sentence-1729 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "*Neural Networks***, 1993.** Andrew M Saxe, James L McClelland, and Surya Ganguli."@en ;
    askg-onto:inSentence "*Neural Networks***, 1993.** Andrew M Saxe, James L McClelland, and Surya Ganguli."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-andrew_m_saxe,
        askg-data:Entity-james_l_mcclelland,
        askg-data:Entity-neural_networks,
        askg-data:Entity-surya_ganguli .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "AISTATS**, 2019.** Lechao Xiao, Yasaman Bahri, Jascha Sohl-Dickstein, Samuel S Schoenholz, and Jeffrey Pennington. Dynamical isometry and a mean field theory of cnns: How to **train 10,000-layer vanilla** convolutional neural networks. *ICML***, 2018.** Ge Yang and Samuel Schoenholz. Mean field residual networks: **On the edge of chaos.** *NeurIPS*, 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1731,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1732,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1733,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1734 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "AISTATS**, 2019.** Lechao Xiao, Yasaman Bahri, Jascha Sohl-Dickstein, Samuel S Schoenholz, and Jeffrey Pennington."@en ;
    askg-onto:inSentence "AISTATS**, 2019.** Lechao Xiao, Yasaman Bahri, Jascha Sohl-Dickstein, Samuel S Schoenholz, and Jeffrey Pennington."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aistats,
        askg-data:Entity-author,
        askg-data:Entity-jascha_sohl-dickstein,
        askg-data:Entity-jeffrey_pennington,
        askg-data:Entity-lechao_xiao,
        askg-data:Entity-samuel_s_schoenholz,
        askg-data:Entity-yasaman_bahri .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Dynamical isometry and a mean field theory of cnns: How to **train 10,000-layer vanilla** convolutional neural networks."@en ;
    askg-onto:inSentence "Dynamical isometry and a mean field theory of cnns: How to **train 10,000-layer vanilla** convolutional neural networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10000-layer_vanilla_convolutional_neural_networks,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-dynamical_isometry,
        askg-data:Entity-mean_field_theory_of_cnns .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*ICML***, 2018.** Ge Yang and Samuel Schoenholz."@en ;
    askg-onto:inSentence "*ICML***, 2018.** Ge Yang and Samuel Schoenholz."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ge_yang,
        askg-data:Entity-ge_yang_and_samuel_schoenholz,
        askg-data:Entity-icml,
        askg-data:Entity-icml_2018,
        askg-data:Entity-samuel_schoenholz .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-173-Sentence-1734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Mean field residual networks: **On the edge of chaos.** *NeurIPS*, 2017."@en ;
    askg-onto:inSentence "Mean field residual networks: **On the edge of chaos.** *NeurIPS*, 2017."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-concept,
        askg-data:Entity-conference,
        askg-data:Entity-mean_field_residual_networks,
        askg-data:Entity-neurips .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Greg Yang, Jeffrey Pennington, Vinay Rao, Jascha Sohl-Dickstein, and Samuel S Schoenholz. A mean field theory of batch normalization. *ICLR***, 2019.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174-Sentence-1741,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174-Sentence-1742,
        askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174-Sentence-1743 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174-Sentence-1741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Greg Yang, Jeffrey Pennington, Vinay Rao, Jascha Sohl-Dickstein, and Samuel S Schoenholz."@en ;
    askg-onto:inSentence "Greg Yang, Jeffrey Pennington, Vinay Rao, Jascha Sohl-Dickstein, and Samuel S Schoenholz."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-greg_yang,
        askg-data:Entity-jascha_sohl-dickstein,
        askg-data:Entity-jeffrey_pennington,
        askg-data:Entity-person,
        askg-data:Entity-samuel_s_schoenholz,
        askg-data:Entity-vinay_rao .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174-Sentence-1742 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A mean field theory of batch normalization."@en ;
    askg-onto:inSentence "A mean field theory of batch normalization."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-mean_field_theory .

askg-data:Paper-54ff6fb7db5b9fad-Section-17-Paragraph-174-Sentence-1743 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*ICLR***, 2019.**"@en ;
    askg-onto:inSentence "*ICLR***, 2019.**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-iclr,
        askg-data:Entity-publication,
        askg-data:Entity-year .

askg-data:Paper-54ff6fb7db5b9fad-Section-18 a askg-onto:Section ;
    rdfs:label "Section 18"@en ;
    domo:Text "A Gradients In Terms Of J**Acobians**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1810,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1811,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-183,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-184,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-185,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-186,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-189 ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Proposition 1. Let ǫ = **∂L/∂**x K **denote the error signal and** x 0 **denote the input signal. Then,** 1. the gradients satisfy:"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1811,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1812,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1813,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1814 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proposition 1."@en ;
    askg-onto:inSentence "Proposition 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-proposition_1 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let ǫ = **∂L/∂**x K **denote the error signal and** x 0 **denote the input signal."@en ;
    askg-onto:inSentence "Let ǫ = **∂L/∂**x K **denote the error signal and** x 0 **denote the input signal."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C7%AB,
        askg-data:Entity-error_signal,
        askg-data:Entity-input_signal,
        askg-data:Entity-x_0 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Then,** 1."@en ;
    askg-onto:inSentence "Then,** 1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-concept .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-181-Sentence-1814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "the gradients satisfy:"@en ;
    askg-onto:inSentence "the gradients satisfy:"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradients,
        askg-data:Entity-triple .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1810 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "ectorized from is used. Notice, $$\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{W}^{l}}=\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{h}^{l}}\\frac{\\partial\\mathbf{h}^{l}}{\\partial\\mathbf{W}^{l}}=\\mathbf{D}^{l}\\frac{\\partial\\mathbf{h}^{l}}{\\partial\\mathbf{W}^{l}}\\.$$ ynamics for a particular neuron $i$, $$h^{l}_{i}=\\sum_{j}W^{l}_{ij}x^{l-1}_{j}+b^{l}_{i}\\,$$ $$\\partial h^{l}_{i}\\qquad\\quad l-1$$ $$\\frac{\\partial h_{i}^{l}}{\\partial W_{i j}^{l}}=x_{j}^{l-1}\\ .$$ Therefore, using the Kronecker product, we can compactly write:"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1810-Sentence-18101,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1810-Sentence-18102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1810-Sentence-18101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "ectorized from is used."@en ;
    askg-onto:inSentence "ectorized from is used."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-vectorized .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1810-Sentence-18102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Notice, $$\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{W}^{l}}=\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{h}^{l}}\\frac{\\partial\\mathbf{h}^{l}}{\\partial\\mathbf{W}^{l}}=\\mathbf{D}^{l}\\frac{\\partial\\mathbf{h}^{l}}{\\partial\\mathbf{W}^{l}}\\.$$ ynamics for a particular neuron $i$, $$h^{l}_{i}=\\sum_{j}W^{l}_{ij}x^{l-1}_{j}+b^{l}_{i}\\,$$ $$\\partial h^{l}_{i}\\qquad\\quad l-1$$ $$\\frac{\\partial h_{i}^{l}}{\\partial W_{i j}^{l}}=x_{j}^{l-1}\\ .$$ Therefore, using the Kronecker product, we can compactly write:"@en ;
    askg-onto:inSentence "Notice, $$\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{W}^{l}}=\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{h}^{l}}\\frac{\\partial\\mathbf{h}^{l}}{\\partial\\mathbf{W}^{l}}=\\mathbf{D}^{l}\\frac{\\partial\\mathbf{h}^{l}}{\\partial\\mathbf{W}^{l}}\\.$$ ynamics for a particular neuron $i$, $$h^{l}_{i}=\\sum_{j}W^{l}_{ij}x^{l-1}_{j}+b^{l}_{i}\\,$$ $$\\partial h^{l}_{i}\\qquad\\quad l-1$$ $$\\frac{\\partial h_{i}^{l}}{\\partial W_{i j}^{l}}=x_{j}^{l-1}\\ .$$ Therefore, using the Kronecker product, we can compactly write:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hl_i,
        askg-data:Entity-i,
        askg-data:Entity-kronecker_product,
        askg-data:Entity-matrix_operations,
        askg-data:Entity-neuron,
        askg-data:Entity-wl_ij,
        askg-data:Entity-xl-1_j .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1811 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "$$\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{W}^{l}}=(\\mathbf{D}^{l})^{T}\\otimes(\\mathbf{x}^{l-1})^{T}\\ .$$ $$(12)$$ $$(13)$$ $${\\mathrm{write}}.$$ $$(14)$$ $$(15)$$ $$(16)$$ T. **(14)** Now, Equation 11 can be written as:"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1811-Sentence-18111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1811-Sentence-18112 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1811-Sentence-18111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{W}^{l}}=(\\mathbf{D}^{l})^{T}\\otimes(\\mathbf{x}^{l-1})^{T}\\ .$$ $$(12)$$ $$(13)$$ $${\\mathrm{write}}.$$ $$(14)$$ $$(15)$$ $$(16)$$ T."@en ;
    askg-onto:inSentence "$$\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{W}^{l}}=(\\mathbf{D}^{l})^{T}\\otimes(\\mathbf{x}^{l-1})^{T}\\ .$$ $$(12)$$ $$(13)$$ $${\\mathrm{write}}.$$ $$(14)$$ $$(15)$$ $$(16)$$ T."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extdlt%09extotimes%09extxl-1t,
        askg-data:Entity-%0Crac%09extpartial_%09extxl%09extpartial_%09extwl .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1811-Sentence-18112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**(14)** Now, Equation 11 can be written as:"@en ;
    askg-onto:inSentence "**(14)** Now, Equation 11 can be written as:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_mathematical_expression,
        askg-data:Entity-equation_11 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "$\\mathbf{g}_{\\mathbf{w}^{l}}=(\\epsilon\\,\\mathbf{J}^{l,K}\\mathbf{D}^{l})^{T}\\otimes(\\mathbf{x}^{l-1})^{T}$, $\\mathbf{g}_{\\mathbf{w}^{l}}^{T}=\\epsilon\\,\\mathbf{J}^{l,K}\\mathbf{D}^{l}\\otimes\\mathbf{x}^{l-1}$. Here, AT ⊗ BT = (A ⊗ B) Tis used. Moreover, for linear networks Dl = I and x l = h l**for all**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812-Sentence-18121,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812-Sentence-18122,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812-Sentence-18123 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812-Sentence-18121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\mathbf{g}_{\\mathbf{w}^{l}}=(\\epsilon\\,\\mathbf{J}^{l,K}\\mathbf{D}^{l})^{T}\\otimes(\\mathbf{x}^{l-1})^{T}$, $\\mathbf{g}_{\\mathbf{w}^{l}}^{T}=\\epsilon\\,\\mathbf{J}^{l,K}\\mathbf{D}^{l}\\otimes\\mathbf{x}^{l-1}$."@en ;
    askg-onto:inSentence "$\\mathbf{g}_{\\mathbf{w}^{l}}=(\\epsilon\\,\\mathbf{J}^{l,K}\\mathbf{D}^{l})^{T}\\otimes(\\mathbf{x}^{l-1})^{T}$, $\\mathbf{g}_{\\mathbf{w}^{l}}^{T}=\\epsilon\\,\\mathbf{J}^{l,K}\\mathbf{D}^{l}\\otimes\\mathbf{x}^{l-1}$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Crac1%09au%09extjlk%09extdl%09imes%09extxl-1,
        askg-data:Entity-%0Crac1%09au%09extjlk%09extdlt%09imes%09extxl-1t,
        askg-data:Entity-g_wl,
        askg-data:Entity-g_wlt .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812-Sentence-18122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here, AT ⊗ BT = (A ⊗ B) Tis used."@en ;
    askg-onto:inSentence "Here, AT ⊗ BT = (A ⊗ B) Tis used."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a__b_t,
        askg-data:Entity-at__bt .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1812-Sentence-18123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Moreover, for linear networks Dl = I and x l = h l**for all**"@en ;
    askg-onto:inSentence "Moreover, for linear networks Dl = I and x l = h l**for all**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dl__i,
        askg-data:Entity-linear_networks,
        askg-data:Entity-x_l__h_lfor_all .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "l ∈ {1 . . . K}. Therefore, x l−1can be written as: x l−1 = φ(Wl−1φ(Wl−2. . . φ(W1x 0 + b 1). . . + b l−2) + b l−1) , (16) = Wl−1(Wl−2. . .(W1x 0 + b 1). . . + b l−2) + b l−1, =Y l−1 k=1 Wkx 0 + l Y −1 k=2 Wkb 1 + . . . + b l−1, = J 0,l−1x 0 + a , where a **is the constant term that does not depend on** x 0**. Hence, the proof is complete.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18131,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181310,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181311,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181312,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181313,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181314,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181315,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181316,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181317,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181318,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181319,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18132,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181320,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18133,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18134,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18135,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18136,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18137,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18138,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18139 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "l ∈ {1 ."@en ;
    askg-onto:inSentence "l ∈ {1 ."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-l .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-corpus,
        askg-data:Entity-dataset,
        askg-data:Entity-device,
        askg-data:Entity-institution,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-researcher,
        askg-data:Entity-study,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "+ b l−2) + b l−1) , (16) = Wl−1(Wl−2."@en ;
    askg-onto:inSentence "+ b l−2) + b l−1) , (16) = Wl−1(Wl−2."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-wl1,
        askg-data:Entity-wl2 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai_research_group,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-deep_learning,
        askg-data:Entity-healthcare,
        askg-data:Entity-image_recognition,
        askg-data:Entity-machine_learning,
        askg-data:Entity-medical_imaging,
        askg-data:Entity-research_area,
        askg-data:Entity-research_on_ai,
        askg-data:Entity-university_of_california .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text ".(W1x 0 + b 1)."@en ;
    askg-onto:inSentence ".(W1x 0 + b 1)."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0__b_1,
        askg-data:Entity-w1x .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181314 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function,
        askg-data:Entity-knowledge_graph,
        askg-data:Entity-triples_list .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181315 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-device,
        askg-data:Entity-method,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181316 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "+ b l−2) + b l−1, =Y l−1 k=1 Wkx 0 + l Y −1 k=2 Wkb 1 + ."@en ;
    askg-onto:inSentence "+ b l−2) + b l−1, =Y l−1 k=1 Wkx 0 + l Y −1 k=2 Wkb 1 + ."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b_l1,
        askg-data:Entity-b_l2,
        askg-data:Entity-wkb_1,
        askg-data:Entity-wkx_0,
        askg-data:Entity-y,
        askg-data:Entity-y_l1 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181317 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_science,
        askg-data:Entity-concept,
        askg-data:Entity-data_integration,
        askg-data:Entity-knowledge_graph,
        askg-data:Entity-knowledge_graph_building,
        askg-data:Entity-knowledge_representation,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-research,
        askg-data:Entity-science,
        askg-data:Entity-triple_extraction .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181318 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-author,
        askg-data:Entity-concept,
        askg-data:Entity-dataset,
        askg-data:Entity-framework,
        askg-data:Entity-method,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-study,
        askg-data:Entity-tool .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181319 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "+ b l−1, = J 0,l−1x 0 + a , where a **is the constant term that does not depend on** x 0**."@en ;
    askg-onto:inSentence "+ b l−1, = J 0,l−1x 0 + a , where a **is the constant term that does not depend on** x 0**."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-constant_term,
        askg-data:Entity-x_0 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-company,
        askg-data:Entity-device,
        askg-data:Entity-experiment,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-scientist,
        askg-data:Entity-software,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-181320 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Hence, the proof is complete.**"@en ;
    askg-onto:inSentence "Hence, the proof is complete.**"^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complete,
        askg-data:Entity-proof .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-data_analysis,
        askg-data:Entity-experiment,
        askg-data:Entity-machine_learning,
        askg-data:Entity-organization,
        askg-data:Entity-research_area,
        askg-data:Entity-research_initiative,
        askg-data:Entity-researcher .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "K}."@en ;
    askg-onto:inSentence "K}."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-k .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Therefore, x l−1can be written as: x l−1 = φ(Wl−1φ(Wl−2."@en ;
    askg-onto:inSentence "Therefore, x l−1can be written as: x l−1 = φ(Wl−1φ(Wl−2."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86wl1%CF%86wl2,
        askg-data:Entity-x_l1 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18136 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_printing,
        askg-data:Entity-additive_manufacturing,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-automation,
        askg-data:Entity-computer_vision,
        askg-data:Entity-machine_learning,
        askg-data:Entity-manufacturing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-product_development,
        askg-data:Entity-prototyping,
        askg-data:Entity-rapid_prototyping,
        askg-data:Entity-research_area,
        askg-data:Entity-robotics .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18137 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-condition,
        askg-data:Entity-device,
        askg-data:Entity-experiment,
        askg-data:Entity-method,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-study,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18138 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "φ(W1x 0 + b 1)."@en ;
    askg-onto:inSentence "φ(W1x 0 + b 1)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86w1x_0__b_1,
        askg-data:Entity-mathematical_expression .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-1813-Sentence-18139 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-article,
        askg-data:Entity-concept,
        askg-data:Entity-condition,
        askg-data:Entity-data,
        askg-data:Entity-dataset,
        askg-data:Entity-device,
        askg-data:Entity-experiment,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-results,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}{\\bf D}^{l}\\otimes{\\bf x}^{l-1}\\;,$$ this formula can let the state $l$. l−1, (9) where J l,K = ∂x K/∂x lis the Jacobian from layer l to the output and ⊗ **is the Kronecker product.** 2. additionally, for linear networks, i.e., when φ **is the identity:** g"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182-Sentence-1821,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182-Sentence-1822,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182-Sentence-1823 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182-Sentence-1821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}{\\bf D}^{l}\\otimes{\\bf x}^{l-1}\\;,$$ this formula can let the state $l$."@en ;
    askg-onto:inSentence "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}{\\bf D}^{l}\\otimes{\\bf x}^{l-1}\\;,$$ this formula can let the state $l$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f_dl,
        askg-data:Entity-f_g_f_wlt,
        askg-data:Entity-f_jlk,
        askg-data:Entity-f_xl-1,
        askg-data:Entity-state_l .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182-Sentence-1822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "l−1, (9) where J l,K = ∂x K/∂x lis the Jacobian from layer l to the output and ⊗ **is the Kronecker product.** 2."@en ;
    askg-onto:inSentence "l−1, (9) where J l,K = ∂x K/∂x lis the Jacobian from layer l to the output and ⊗ **is the Kronecker product.** 2."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jacobian,
        askg-data:Entity-kronecker_product .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-182-Sentence-1823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "additionally, for linear networks, i.e., when φ **is the identity:** g"@en ;
    askg-onto:inSentence "additionally, for linear networks, i.e., when φ **is the identity:** g"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-identity,
        askg-data:Entity-linear_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-183 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$({\\mathfrak{g}})$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-183-Sentence-1831 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-183-Sentence-1831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$({\\mathfrak{g}})$$"@en ;
    askg-onto:inSentence "$$({\\mathfrak{g}})$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extfrakg,
        askg-data:Entity-a_mathematical_object .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-184 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "0 + a, **(10)**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-184-Sentence-1841 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-184-Sentence-1841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "0 + a, **(10)**"@en ;
    askg-onto:inSentence "0 + a, **(10)**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0,
        askg-data:Entity-10,
        askg-data:Entity-concept .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-185 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\mathbf{\\tau}_{1}^{i}=\\epsilon\\,\\mathbf{J}^{l,K}\\otimes\\left(\\mathbf{J}^{0,l-1}\\mathbf{x}^{0}+\\mathbf{a}\\right)\\ ,$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-185-Sentence-1851 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-185-Sentence-1851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{\\tau}_{1}^{i}=\\epsilon\\,\\mathbf{J}^{l,K}\\otimes\\left(\\mathbf{J}^{0,l-1}\\mathbf{x}^{0}+\\mathbf{a}\\right)\\ ,$$"@en ;
    askg-onto:inSentence "$$\\mathbf{\\tau}_{1}^{i}=\\epsilon\\,\\mathbf{J}^{l,K}\\otimes\\left(\\mathbf{J}^{0,l-1}\\mathbf{x}^{0}+\\mathbf{a}\\right)\\ ,$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%84%E2%82%81%E2%81%B1,
        askg-data:Entity-a,
        askg-data:Entity-j,
        askg-data:Entity-tensor,
        askg-data:Entity-variable,
        askg-data:Entity-x%E2%81%B0 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-186 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "where J 0,l−1 = ∂x l−1/∂x 0is the Jacobian from the input to layer l − 1 and a ∈ R N **is the** constant term that does not depend on x 0."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-186-Sentence-1861 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-186-Sentence-1861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where J 0,l−1 = ∂x l−1/∂x 0is the Jacobian from the input to layer l − 1 and a ∈ R N **is the** constant term that does not depend on x 0."@en ;
    askg-onto:inSentence "where J 0,l−1 = ∂x l−1/∂x 0is the Jacobian from the input to layer l − 1 and a ∈ R N **is the** constant term that does not depend on x 0."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constant_term,
        askg-data:Entity-input,
        askg-data:Entity-jacobian,
        askg-data:Entity-layer_l_-_1,
        askg-data:Entity-x_0 .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Proof. **The proof is based on a simple algebraic manipulation of the chain rule. The gradient of the** loss with respect to the weight matrix Wl**can be written as:**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187-Sentence-1871,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187-Sentence-1872,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187-Sentence-1873 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187-Sentence-1871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof."@en ;
    askg-onto:inSentence "Proof."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-proof .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187-Sentence-1872 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**The proof is based on a simple algebraic manipulation of the chain rule."@en ;
    askg-onto:inSentence "**The proof is based on a simple algebraic manipulation of the chain rule."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algebraic_manipulation,
        askg-data:Entity-chain_rule,
        askg-data:Entity-proof .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-187-Sentence-1873 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The gradient of the** loss with respect to the weight matrix Wl**can be written as:**"@en ;
    askg-onto:inSentence "The gradient of the** loss with respect to the weight matrix Wl**can be written as:**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-loss,
        askg-data:Entity-weight_matrix_wl .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "$${\\bf g_{w}}^{l}=\\frac{\\partial L}{\\partial{\\bf W}^{l}}=\\frac{\\partial L}{\\partial{\\bf x}^{K}}\\frac{\\partial{\\bf x}^{K}}{\\partial{\\bf x}^{l}}\\frac{\\partial{\\bf x}^{l}}{\\partial{\\bf W}^{l}}.\\tag{11}$$ Here, the gradient $\\partial{\\bf y}/\\partial{\\bf x}$ is represented as a matrix of dimension ${\\bf y}$-size $\\times$ x-size. For gradients with respect to matrices, their vectorized from is used. Notice,"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188-Sentence-1881,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188-Sentence-1882,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188-Sentence-1883 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188-Sentence-1881 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\bf g_{w}}^{l}=\\frac{\\partial L}{\\partial{\\bf W}^{l}}=\\frac{\\partial L}{\\partial{\\bf x}^{K}}\\frac{\\partial{\\bf x}^{K}}{\\partial{\\bf x}^{l}}\\frac{\\partial{\\bf x}^{l}}{\\partial{\\bf W}^{l}}.\\tag{11}$$ Here, the gradient $\\partial{\\bf y}/\\partial{\\bf x}$ is represented as a matrix of dimension ${\\bf y}$-size $\\times$ x-size."@en ;
    askg-onto:inSentence "$${\\bf g_{w}}^{l}=\\frac{\\partial L}{\\partial{\\bf W}^{l}}=\\frac{\\partial L}{\\partial{\\bf x}^{K}}\\frac{\\partial{\\bf x}^{K}}{\\partial{\\bf x}^{l}}\\frac{\\partial{\\bf x}^{l}}{\\partial{\\bf W}^{l}}.\\tag{11}$$ Here, the gradient $\\partial{\\bf y}/\\partial{\\bf x}$ is represented as a matrix of dimension ${\\bf y}$-size $\\times$ x-size."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g_wl,
        askg-data:Entity-gradient_yx,
        askg-data:Entity-matrix_of_dimension_y-size__x-size .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188-Sentence-1882 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For gradients with respect to matrices, their vectorized from is used."@en ;
    askg-onto:inSentence "For gradients with respect to matrices, their vectorized from is used."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradients,
        askg-data:Entity-vectorized_form .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-188-Sentence-1883 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Notice,"@en ;
    askg-onto:inSentence "Notice,"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-document,
        askg-data:Entity-notice .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-189 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Considering the feed-forward. Considering the feed-forward dynamics for a particular neuron i,"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-189-Sentence-1891,
        askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-189-Sentence-1892 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-189-Sentence-1891 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Considering the feed-forward."@en ;
    askg-onto:inSentence "Considering the feed-forward."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-feed-forward .

askg-data:Paper-54ff6fb7db5b9fad-Section-18-Paragraph-189-Sentence-1892 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Considering the feed-forward dynamics for a particular neuron i,"@en ;
    askg-onto:inSentence "Considering the feed-forward dynamics for a particular neuron i,"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feed-forward_dynamics,
        askg-data:Entity-neuron_i .

askg-data:Paper-54ff6fb7db5b9fad-Section-19 a askg-onto:Section ;
    rdfs:label "Section 19"@en ;
    domo:Text "B E**Xperiment Settings**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1910,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1912,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1913,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1914,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-192,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-193,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-194,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-196,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-197,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-199 ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Pruning at initialization**. By default, we perform pruning at initialization based on connection** sensitivity scores as in Lee et al. (2019). When computing connection sensitivity, we always use all examples in the training set to prevent stochasticity by **a particular mini-batch. Unless stated** otherwise, we set the default sparsity level to be κ¯ = 90% (i.e., 90**% of the entire parameters in a** network is pruned away). For all tested architectures, pruning for such level of sparsity does not lead to a large accuracy drop. Additionally, we perform either random pruning (at initialization) or a magnitude based pruning (at pretrained) for comparison purposes. Random pruning refers to pruning parameters randomly and globally for a given sparsity level. For the magnitude based pruning, we first train a model and simply prune parameters globally in **a single-shot based on the magnitude** of the pretrained parameters (i.e., keep the large weights while pruning small ones). For initialization methods, we follow either variance scaling initialization schemes (i.e**., VS-L, VS-G, VS-H, as** in LeCun et al. (1998); Glorot & Bengio (2010); He et al. (2015), respectively) or (convolutional) orthogonal initialization schemes (Saxe et al., 2014; Xiao **et al., 2018).** Training and evaluation**. Throughout experiments, we evaluate pruning results on MNIST,** CIFAR-10, and Tiny-ImageNet image classification tasks. For training of the pruned sparse networks, we use SGD with momentum and train up to 80k (for MNIST) or 100**k (for CIFAR-10 and** Tiny-ImageNet) iterations. The initial learning rate is set to be 0.1 and is decayed by 1/10 **at every** 20k (MNIST) or 25k (CIFAR-10 and Tiny-ImageNet). The mini-batch size is set to be 100, 128, 200 **for MNIST, CIFAR-10, Tiny-ImageNet, respectively. We do not optimize anything specific for a** particular case, and follow the standard training procedure. For all experiments, we use 10% of training set for the validation set, which corresponds to 5400, 5000, 9000 **images for MNIST, CIFAR-10,** Tiny-IamgeNet, respectively. We evaluate at every 1**k iteration, and record the lowest test error. All** results are the average of either 10 (for MNIST) or 5 **(for CIFAR-10 and Tiny-ImageNet) runs.** Signal propagation and approximate dynamical isometry**. We use the entire training set when** computing Jacobian singular values of a network. In order to enforce approximate dynamical isometry when specified, given a pruned sparse network, we optimize for the objective in Equation 8 using gradient descent. The learning rate is set to be 0.1 and we perform 10**k gradient update steps** (although it usually reaches to convergence far before). This process is data-free and thus fast; e.g., depending on the size of the network and the number of update steps, it can take less than a few seconds on a modern computer. Neural architecture sculpting**. We provide the model details in Table 6.** Table 6: All models (Equivalents 1,2,3) are initially bigger than the base network (ResNet20), by either being wider or deeper, but pruned to have the same number of parameters as the base network (269k). The widening factor (k) refers to the filter multiplier; e.g**., for the basic filter size of 16,** the widening factor of k=2 will result in 32 filters. The block **size refers to the number of residual** blocks in each block layer; all models have three block layers. More/less number of residual blocks means the network is deeper/shallower. The reported generalization errors are averages over 5 runs. We find that the technique of *architecture sculpting***, pruning randomly initialized neural networks** based on our signal propagation perspective even in the absence of ground-truth supervision, can be used to find models of superior performance under the same parameter budget."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1911,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19110,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19115,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19116,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19117,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19118,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19119,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1912,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19120,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19121,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19122,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19123,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19124,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19125,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19126,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19127,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19128,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19129,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1913,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19130,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19131,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1914,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1915,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1916,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1917,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1918,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1919 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Pruning at initialization**."@en ;
    askg-onto:inSentence "Pruning at initialization**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initialization,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "For initialization methods, we follow either variance scaling initialization schemes (i.e**., VS-L, VS-G, VS-H, as** in LeCun et al."@en ;
    askg-onto:inSentence "For initialization methods, we follow either variance scaling initialization schemes (i.e**., VS-L, VS-G, VS-H, as** in LeCun et al."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initialization_methods,
        askg-data:Entity-lecun_et_al,
        askg-data:Entity-variance_scaling_initialization_schemes .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "(1998); Glorot & Bengio (2010); He et al."@en ;
    askg-onto:inSentence "(1998); Glorot & Bengio (2010); He et al."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1998,
        askg-data:Entity-2010,
        askg-data:Entity-glorot__bengio,
        askg-data:Entity-he_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "(2015), respectively) or (convolutional) orthogonal initialization schemes (Saxe et al., 2014; Xiao **et al., 2018).** Training and evaluation**."@en ;
    askg-onto:inSentence "(2015), respectively) or (convolutional) orthogonal initialization schemes (Saxe et al., 2014; Xiao **et al., 2018).** Training and evaluation**."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation,
        askg-data:Entity-orthogonal_initialization_schemes,
        askg-data:Entity-saxe_et_al,
        askg-data:Entity-xiao_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Throughout experiments, we evaluate pruning results on MNIST,** CIFAR-10, and Tiny-ImageNet image classification tasks."@en ;
    askg-onto:inSentence "Throughout experiments, we evaluate pruning results on MNIST,** CIFAR-10, and Tiny-ImageNet image classification tasks."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-mnist,
        askg-data:Entity-pruning_results,
        askg-data:Entity-tiny-imagenet .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "For training of the pruned sparse networks, we use SGD with momentum and train up to 80k (for MNIST) or 100**k (for CIFAR-10 and** Tiny-ImageNet) iterations."@en ;
    askg-onto:inSentence "For training of the pruned sparse networks, we use SGD with momentum and train up to 80k (for MNIST) or 100**k (for CIFAR-10 and** Tiny-ImageNet) iterations."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-mnist,
        askg-data:Entity-pruned_sparse_networks,
        askg-data:Entity-sgd,
        askg-data:Entity-tiny-imagenet,
        askg-data:Entity-training .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "The initial learning rate is set to be 0.1 and is decayed by 1/10 **at every** 20k (MNIST) or 25k (CIFAR-10 and Tiny-ImageNet)."@en ;
    askg-onto:inSentence "The initial learning rate is set to be 0.1 and is decayed by 1/10 **at every** 20k (MNIST) or 25k (CIFAR-10 and Tiny-ImageNet)."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-01,
        askg-data:Entity-110,
        askg-data:Entity-20k,
        askg-data:Entity-25k,
        askg-data:Entity-cifar-10,
        askg-data:Entity-initial_learning_rate,
        askg-data:Entity-learning_rate,
        askg-data:Entity-mnist,
        askg-data:Entity-tiny-imagenet .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "The mini-batch size is set to be 100, 128, 200 **for MNIST, CIFAR-10, Tiny-ImageNet, respectively."@en ;
    askg-onto:inSentence "The mini-batch size is set to be 100, 128, 200 **for MNIST, CIFAR-10, Tiny-ImageNet, respectively."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-mini-batch_size,
        askg-data:Entity-mnist,
        askg-data:Entity-tiny-imagenet .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19117 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "We do not optimize anything specific for a** particular case, and follow the standard training procedure."@en ;
    askg-onto:inSentence "We do not optimize anything specific for a** particular case, and follow the standard training procedure."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-particular_case,
        askg-data:Entity-standard_training_procedure .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19118 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "For all experiments, we use 10% of training set for the validation set, which corresponds to 5400, 5000, 9000 **images for MNIST, CIFAR-10,** Tiny-IamgeNet, respectively."@en ;
    askg-onto:inSentence "For all experiments, we use 10% of training set for the validation set, which corresponds to 5400, 5000, 9000 **images for MNIST, CIFAR-10,** Tiny-IamgeNet, respectively."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-dataset,
        askg-data:Entity-mnist,
        askg-data:Entity-tiny-iamgenet .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19119 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "We evaluate at every 1**k iteration, and record the lowest test error."@en ;
    askg-onto:inSentence "We evaluate at every 1**k iteration, and record the lowest test error."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1k_iteration,
        askg-data:Entity-lowest_test_error .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "By default, we perform pruning at initialization based on connection** sensitivity scores as in Lee et al."@en ;
    askg-onto:inSentence "By default, we perform pruning at initialization based on connection** sensitivity scores as in Lee et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_scores,
        askg-data:Entity-lee_et_al,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19120 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "All** results are the average of either 10 (for MNIST) or 5 **(for CIFAR-10 and Tiny-ImageNet) runs.** Signal propagation and approximate dynamical isometry**."@en ;
    askg-onto:inSentence "All** results are the average of either 10 (for MNIST) or 5 **(for CIFAR-10 and Tiny-ImageNet) runs.** Signal propagation and approximate dynamical isometry**."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10,
        askg-data:Entity-5,
        askg-data:Entity-approximate_dynamical_isometry,
        askg-data:Entity-cifar-10,
        askg-data:Entity-mnist,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-tiny-imagenet .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19121 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "We use the entire training set when** computing Jacobian singular values of a network."@en ;
    askg-onto:inSentence "We use the entire training set when** computing Jacobian singular values of a network."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jacobian_singular_values,
        askg-data:Entity-network .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19122 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "In order to enforce approximate dynamical isometry when specified, given a pruned sparse network, we optimize for the objective in Equation 8 using gradient descent."@en ;
    askg-onto:inSentence "In order to enforce approximate dynamical isometry when specified, given a pruned sparse network, we optimize for the objective in Equation 8 using gradient descent."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradient_descent,
        askg-data:Entity-objective_in_equation_8,
        askg-data:Entity-optimization,
        askg-data:Entity-pruned_sparse_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19123 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "The learning rate is set to be 0.1 and we perform 10**k gradient update steps** (although it usually reaches to convergence far before)."@en ;
    askg-onto:inSentence "The learning rate is set to be 0.1 and we perform 10**k gradient update steps** (although it usually reaches to convergence far before)."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-01,
        askg-data:Entity-10k,
        askg-data:Entity-gradient_update_steps,
        askg-data:Entity-learning_rate .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19124 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "This process is data-free and thus fast; e.g., depending on the size of the network and the number of update steps, it can take less than a few seconds on a modern computer."@en ;
    askg-onto:inSentence "This process is data-free and thus fast; e.g., depending on the size of the network and the number of update steps, it can take less than a few seconds on a modern computer."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data-free,
        askg-data:Entity-fast,
        askg-data:Entity-less_than_a_few_seconds_on_a_modern_computer,
        askg-data:Entity-network,
        askg-data:Entity-number_of_update_steps,
        askg-data:Entity-process,
        askg-data:Entity-size .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19125 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Neural architecture sculpting**."@en ;
    askg-onto:inSentence "Neural architecture sculpting**."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-neural_architecture_sculpting .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19126 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "We provide the model details in Table 6.** Table 6: All models (Equivalents 1,2,3) are initially bigger than the base network (ResNet20), by either being wider or deeper, but pruned to have the same number of parameters as the base network (269k)."@en ;
    askg-onto:inSentence "We provide the model details in Table 6.** Table 6: All models (Equivalents 1,2,3) are initially bigger than the base network (ResNet20), by either being wider or deeper, but pruned to have the same number of parameters as the base network (269k)."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-269k,
        askg-data:Entity-base_network_resnet20,
        askg-data:Entity-models_equivalents_123,
        askg-data:Entity-resnet20 .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19127 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "The widening factor (k) refers to the filter multiplier; e.g**., for the basic filter size of 16,** the widening factor of k=2 will result in 32 filters."@en ;
    askg-onto:inSentence "The widening factor (k) refers to the filter multiplier; e.g**., for the basic filter size of 16,** the widening factor of k=2 will result in 32 filters."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-16,
        askg-data:Entity-2,
        askg-data:Entity-32_filters,
        askg-data:Entity-basic_filter_size,
        askg-data:Entity-filter_multiplier,
        askg-data:Entity-widening_factor_k .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19128 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "The block **size refers to the number of residual** blocks in each block layer; all models have three block layers."@en ;
    askg-onto:inSentence "The block **size refers to the number of residual** blocks in each block layer; all models have three block layers."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-models,
        askg-data:Entity-number_of_residual_blocks,
        askg-data:Entity-size,
        askg-data:Entity-three_block_layers .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19129 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "More/less number of residual blocks means the network is deeper/shallower."@en ;
    askg-onto:inSentence "More/less number of residual blocks means the network is deeper/shallower."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network_is_deepershallower,
        askg-data:Entity-number_of_residual_blocks .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2019)."@en ;
    askg-onto:inSentence "(2019)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-year .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19130 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "The reported generalization errors are averages over 5 runs."@en ;
    askg-onto:inSentence "The reported generalization errors are averages over 5 runs."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_runs,
        askg-data:Entity-generalization_errors .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-19131 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "We find that the technique of *architecture sculpting***, pruning randomly initialized neural networks** based on our signal propagation perspective even in the absence of ground-truth supervision, can be used to find models of superior performance under the same parameter budget."@en ;
    askg-onto:inSentence "We find that the technique of *architecture sculpting***, pruning randomly initialized neural networks** based on our signal propagation perspective even in the absence of ground-truth supervision, can be used to find models of superior performance under the same parameter budget."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architecture_sculpting,
        askg-data:Entity-models_of_superior_performance,
        askg-data:Entity-pruning_randomly_initialized_neural_networks,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "When computing connection sensitivity, we always use all examples in the training set to prevent stochasticity by **a particular mini-batch."@en ;
    askg-onto:inSentence "When computing connection sensitivity, we always use all examples in the training set to prevent stochasticity by **a particular mini-batch."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-mini-batch,
        askg-data:Entity-stochasticity,
        askg-data:Entity-training_set .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1915 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Unless stated** otherwise, we set the default sparsity level to be κ¯ = 90% (i.e., 90**% of the entire parameters in a** network is pruned away)."@en ;
    askg-onto:inSentence "Unless stated** otherwise, we set the default sparsity level to be κ¯ = 90% (i.e., 90**% of the entire parameters in a** network is pruned away)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BA__90,
        askg-data:Entity-90,
        askg-data:Entity-network,
        askg-data:Entity-parameters,
        askg-data:Entity-sparsity_level .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1916 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "For all tested architectures, pruning for such level of sparsity does not lead to a large accuracy drop."@en ;
    askg-onto:inSentence "For all tested architectures, pruning for such level of sparsity does not lead to a large accuracy drop."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-accuracy_drop,
        askg-data:Entity-architectures,
        askg-data:Entity-pruning,
        askg-data:Entity-sparsity .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1917 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Additionally, we perform either random pruning (at initialization) or a magnitude based pruning (at pretrained) for comparison purposes."@en ;
    askg-onto:inSentence "Additionally, we perform either random pruning (at initialization) or a magnitude based pruning (at pretrained) for comparison purposes."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-magnitude_based_pruning,
        askg-data:Entity-method,
        askg-data:Entity-random_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1918 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Random pruning refers to pruning parameters randomly and globally for a given sparsity level."@en ;
    askg-onto:inSentence "Random pruning refers to pruning parameters randomly and globally for a given sparsity level."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_parameters,
        askg-data:Entity-random_pruning,
        askg-data:Entity-sparsity_level .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-191-Sentence-1919 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "For the magnitude based pruning, we first train a model and simply prune parameters globally in **a single-shot based on the magnitude** of the pretrained parameters (i.e., keep the large weights while pruning small ones)."@en ;
    askg-onto:inSentence "For the magnitude based pruning, we first train a model and simply prune parameters globally in **a single-shot based on the magnitude** of the pretrained parameters (i.e., keep the large weights while pruning small ones)."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-magnitude,
        askg-data:Entity-magnitude_based_pruning,
        askg-data:Entity-model,
        askg-data:Entity-parameters,
        askg-data:Entity-single-shot,
        askg-data:Entity-technique,
        askg-data:Entity-weights .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1910 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "(a) Signal propagation (all statistics; magnitude based pruning)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1910-Sentence-19101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1910-Sentence-19101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) Signal propagation (all statistics; magnitude based pruning)"@en ;
    askg-onto:inSentence "(a) Signal propagation (all statistics; magnitude based pruning)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-magnitude_based_pruning,
        askg-data:Entity-method,
        askg-data:Entity-signal_propagation .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Figure 6: Signal propagation measurments (all signular value statistics) for the magnitude based pruning (Mag) on the 7-layer linear and tanh MLP networks. As **described in the experiment settings** in Appendix B, the magnitude based pruning is performed on a pretrained model. Notice that unlike other cases where pruning is done at initialization (i.e**., using either random or connection sensitivity** based pruning methods), the singular value distribution changes abruptly when pruned (i.e**., note of** the sharp change of singular values from 0 to 10% sparsity). Also, the singular values are not concentrated (note of high standard deviations), which explains rather inferior trainability compared to other methods. We conjecture that naively pruning based on the magnitude of parameters in a single-shot, without pruning gradually or employing some sophisticated tricks such as layerwise thresholding, can lead to a failure of training compressed networks."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19115 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 6: Signal propagation measurments (all signular value statistics) for the magnitude based pruning (Mag) on the 7-layer linear and tanh MLP networks."@en ;
    askg-onto:inSentence "Figure 6: Signal propagation measurments (all signular value statistics) for the magnitude based pruning (Mag) on the 7-layer linear and tanh MLP networks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7-layer_linear_and_tanh_mlp_networks,
        askg-data:Entity-magnitude_based_pruning,
        askg-data:Entity-signal_propagation_measurements .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As **described in the experiment settings** in Appendix B, the magnitude based pruning is performed on a pretrained model."@en ;
    askg-onto:inSentence "As **described in the experiment settings** in Appendix B, the magnitude based pruning is performed on a pretrained model."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_pretrained_model,
        askg-data:Entity-magnitude_based_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Notice that unlike other cases where pruning is done at initialization (i.e**., using either random or connection sensitivity** based pruning methods), the singular value distribution changes abruptly when pruned (i.e**., note of** the sharp change of singular values from 0 to 10% sparsity)."@en ;
    askg-onto:inSentence "Notice that unlike other cases where pruning is done at initialization (i.e**., using either random or connection sensitivity** based pruning methods), the singular value distribution changes abruptly when pruned (i.e**., note of** the sharp change of singular values from 0 to 10% sparsity)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10_sparsity,
        askg-data:Entity-initialization,
        askg-data:Entity-pruning_methods,
        askg-data:Entity-singular_value_distribution,
        askg-data:Entity-singular_values,
        askg-data:Entity-sparsity .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Also, the singular values are not concentrated (note of high standard deviations), which explains rather inferior trainability compared to other methods."@en ;
    askg-onto:inSentence "Also, the singular values are not concentrated (note of high standard deviations), which explains rather inferior trainability compared to other methods."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inferior_trainability,
        askg-data:Entity-not_concentrated,
        askg-data:Entity-singular_values,
        askg-data:Entity-standard_deviations .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1911-Sentence-19115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We conjecture that naively pruning based on the magnitude of parameters in a single-shot, without pruning gradually or employing some sophisticated tricks such as layerwise thresholding, can lead to a failure of training compressed networks."@en ;
    askg-onto:inSentence "We conjecture that naively pruning based on the magnitude of parameters in a single-shot, without pruning gradually or employing some sophisticated tricks such as layerwise thresholding, can lead to a failure of training compressed networks."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-layerwise_thresholding,
        askg-data:Entity-magnitude_of_parameters,
        askg-data:Entity-naively_pruning,
        askg-data:Entity-pruning,
        askg-data:Entity-training_compressed_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1912 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "![14_image_2.png](14_image_2.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1912-Sentence-19121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1912-Sentence-19121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![14_image_2.png](14_image_2.png)"@en ;
    askg-onto:inSentence "![14_image_2.png](14_image_2.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-findings,
        askg-data:Entity-research_concepts,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1913 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "Figure 7: Signal propagation and training behavior for ReLU **and Leaky-ReLU activation functions.** They resemble those of the tanh case as in Figure 2, and hence the conclusion holds about the same."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1913-Sentence-19131 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1913-Sentence-19131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 7: Signal propagation and training behavior for ReLU **and Leaky-ReLU activation functions.** They resemble those of the tanh case as in Figure 2, and hence the conclusion holds about the same."@en ;
    askg-onto:inSentence "Figure 7: Signal propagation and training behavior for ReLU **and Leaky-ReLU activation functions.** They resemble those of the tanh case as in Figure 2, and hence the conclusion holds about the same."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-activation_function,
        askg-data:Entity-leaky-relu_activation_function,
        askg-data:Entity-relu_activation_function,
        askg-data:Entity-relu_and_leaky-relu_activation_functions,
        askg-data:Entity-tanh_case .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1914 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1914-Sentence-19141 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1914-Sentence-19141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:inSentence "![15_image_0.png](15_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai_ethics,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_vision,
        askg-data:Entity-data,
        askg-data:Entity-deep_learning,
        askg-data:Entity-machine_learning,
        askg-data:Entity-machine_learning_algorithm,
        askg-data:Entity-machine_learning_algorithms,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-robotics,
        askg-data:Entity-support_vector_machines .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Figure 8: Training performance (loss and accuracy) by different methods for VGG16 on CIFAR-10. To examine the effect of initialization in isolation on the trainability of sparse neural networks, we remove batch normalization (BN) layers for this experiment, as BN tends to improve training speed as well as generalization performance. As a result, enforcing approximate isometry (LDI-CS-AIF) improves the training speed quite dramatically compared to **the pruned network without isometry** (LDI-CS). We also find that even compared to the non-pruned dense network (LDI-Dense) which is ensured layerwise dynamical isometry, LDI-CS-AIF trains faster in the early training phase. This result is quite promising and more encouraging than the previous case of MLP (see Figures 2 and 7), as it potentially indicates that an underparameterized network (by connection sensitivity pruning) can even outperform an overparameterized network, at least **in the early phase of neural network** training. Furthermore, we add results of using the spectral **norm in enforcing approximate isometry** in Equation 8 (LDI-CS-AIS), and find that it also trains faster than the case of broken isometry (LDI-CS), yet not as much as the case of using the Frobenius norm (LDI-CS-AIF)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19151,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19152,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19153,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19154,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19155,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19156 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 8: Training performance (loss and accuracy) by different methods for VGG16 on CIFAR-10."@en ;
    askg-onto:inSentence "Figure 8: Training performance (loss and accuracy) by different methods for VGG16 on CIFAR-10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-vgg16 .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To examine the effect of initialization in isolation on the trainability of sparse neural networks, we remove batch normalization (BN) layers for this experiment, as BN tends to improve training speed as well as generalization performance."@en ;
    askg-onto:inSentence "To examine the effect of initialization in isolation on the trainability of sparse neural networks, we remove batch normalization (BN) layers for this experiment, as BN tends to improve training speed as well as generalization performance."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization_bn_layers,
        askg-data:Entity-bn,
        askg-data:Entity-generalization_performance,
        askg-data:Entity-initialization,
        askg-data:Entity-this_experiment,
        askg-data:Entity-trainability_of_sparse_neural_networks,
        askg-data:Entity-training_speed .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As a result, enforcing approximate isometry (LDI-CS-AIF) improves the training speed quite dramatically compared to **the pruned network without isometry** (LDI-CS)."@en ;
    askg-onto:inSentence "As a result, enforcing approximate isometry (LDI-CS-AIF) improves the training speed quite dramatically compared to **the pruned network without isometry** (LDI-CS)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-cs,
        askg-data:Entity-ldi-cs-aif,
        askg-data:Entity-the_pruned_network_without_isometry,
        askg-data:Entity-training_speed .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We also find that even compared to the non-pruned dense network (LDI-Dense) which is ensured layerwise dynamical isometry, LDI-CS-AIF trains faster in the early training phase."@en ;
    askg-onto:inSentence "We also find that even compared to the non-pruned dense network (LDI-Dense) which is ensured layerwise dynamical isometry, LDI-CS-AIF trains faster in the early training phase."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-early_training_phase,
        askg-data:Entity-ldi-cs-aif,
        askg-data:Entity-ldi-dense .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19155 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This result is quite promising and more encouraging than the previous case of MLP (see Figures 2 and 7), as it potentially indicates that an underparameterized network (by connection sensitivity pruning) can even outperform an overparameterized network, at least **in the early phase of neural network** training."@en ;
    askg-onto:inSentence "This result is quite promising and more encouraging than the previous case of MLP (see Figures 2 and 7), as it potentially indicates that an underparameterized network (by connection sensitivity pruning) can even outperform an overparameterized network, at least **in the early phase of neural network** training."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_pruning,
        askg-data:Entity-early_phase_of_training,
        askg-data:Entity-mlp,
        askg-data:Entity-neural_network,
        askg-data:Entity-overparameterized_network,
        askg-data:Entity-underparameterized_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-1915-Sentence-19156 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Furthermore, we add results of using the spectral **norm in enforcing approximate isometry** in Equation 8 (LDI-CS-AIS), and find that it also trains faster than the case of broken isometry (LDI-CS), yet not as much as the case of using the Frobenius norm (LDI-CS-AIF)."@en ;
    askg-onto:inSentence "Furthermore, we add results of using the spectral **norm in enforcing approximate isometry** in Equation 8 (LDI-CS-AIS), and find that it also trains faster than the case of broken isometry (LDI-CS), yet not as much as the case of using the Frobenius norm (LDI-CS-AIF)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approximate_isometry,
        askg-data:Entity-frobenius_norm,
        askg-data:Entity-ldi-cs,
        askg-data:Entity-ldi-cs-aif,
        askg-data:Entity-ldi-cs-ais,
        askg-data:Entity-spectral_norm .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-192 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "| Model category | Shape | Widening (k) | Block size | Init. | GT | Sparsity | Error | |------------------|----------------------------|----------------|--------------|---------|------|------------|---------| | Base | ResNet20 (He et al., 2016) | 1 | 3 | VS\\-H | ✓ | 0.0 | 8.046 | | Equivalent 1 | wider | 2 | 3 | LDI | ✗ | 74.8 | 7.618 | | | wider | 4 | 3 | LDI | ✗ | 93.7 | 7.630 | | | wider | 6 | 3 | LDI | ✗ | 97.2 | 7.708 | | | wider | 8 | 3 | LDI | ✗ | 98.4 | 7.836 | | Equivalent 2 | wider & shallower | 2 | 2 | LDI | ✗ | 60.4 | 7.776 | | | wider & shallower | 4 | 2 | LDI | ✗ | 90.1 | 7.876 | | | wider & shallower | 6 | 2 | LDI | ✗ | 95.6 | 7.940 | | Equivalent 3 | deeper | 1 | 5 | LDI | ✗ | 42.0 | 7.912 |"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-192-Sentence-1921,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-192-Sentence-1922 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-192-Sentence-1921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Model category | Shape | Widening (k) | Block size | Init."@en ;
    askg-onto:inSentence "| Model category | Shape | Widening (k) | Block size | Init."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-block_size,
        askg-data:Entity-init,
        askg-data:Entity-model_category,
        askg-data:Entity-shape,
        askg-data:Entity-widening_k .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-192-Sentence-1922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "| GT | Sparsity | Error | |------------------|----------------------------|----------------|--------------|---------|------|------------|---------| | Base | ResNet20 (He et al., 2016) | 1 | 3 | VS\\-H | ✓ | 0.0 | 8.046 | | Equivalent 1 | wider | 2 | 3 | LDI | ✗ | 74.8 | 7.618 | | | wider | 4 | 3 | LDI | ✗ | 93.7 | 7.630 | | | wider | 6 | 3 | LDI | ✗ | 97.2 | 7.708 | | | wider | 8 | 3 | LDI | ✗ | 98.4 | 7.836 | | Equivalent 2 | wider & shallower | 2 | 2 | LDI | ✗ | 60.4 | 7.776 | | | wider & shallower | 4 | 2 | LDI | ✗ | 90.1 | 7.876 | | | wider & shallower | 6 | 2 | LDI | ✗ | 95.6 | 7.940 | | Equivalent 3 | deeper | 1 | 5 | LDI | ✗ | 42.0 | 7.912 |"@en ;
    askg-onto:inSentence "| GT | Sparsity | Error | |------------------|----------------------------|----------------|--------------|---------|------|------------|---------| | Base | ResNet20 (He et al., 2016) | 1 | 3 | VS\\-H | ✓ | 0.0 | 8.046 | | Equivalent 1 | wider | 2 | 3 | LDI | ✗ | 74.8 | 7.618 | | | wider | 4 | 3 | LDI | ✗ | 93.7 | 7.630 | | | wider | 6 | 3 | LDI | ✗ | 97.2 | 7.708 | | | wider | 8 | 3 | LDI | ✗ | 98.4 | 7.836 | | Equivalent 2 | wider & shallower | 2 | 2 | LDI | ✗ | 60.4 | 7.776 | | | wider & shallower | 4 | 2 | LDI | ✗ | 90.1 | 7.876 | | | wider & shallower | 6 | 2 | LDI | ✗ | 95.6 | 7.940 | | Equivalent 3 | deeper | 1 | 5 | LDI | ✗ | 42.0 | 7.912 |"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deeper,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-resnet20_he_et_al_2016,
        askg-data:Entity-wider,
        askg-data:Entity-wider__shallower .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-193 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "C SIGNAL PROPAGATION IN SPARSE NETWORKS: **ADDITIONAL RESULTS**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-193-Sentence-1931 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-193-Sentence-1931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "C SIGNAL PROPAGATION IN SPARSE NETWORKS: **ADDITIONAL RESULTS**"@en ;
    askg-onto:inSentence "C SIGNAL PROPAGATION IN SPARSE NETWORKS: **ADDITIONAL RESULTS**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_results,
        askg-data:Entity-c_signal_propagation_in_sparse_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-194 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-194-Sentence-1941 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-194-Sentence-1941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:inSentence "![13_image_0.png](13_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company_r,
        askg-data:Entity-dataset_1,
        askg-data:Entity-experiment_y,
        askg-data:Entity-method_z,
        askg-data:Entity-organization_a,
        askg-data:Entity-person_x,
        askg-data:Entity-research_group_b,
        askg-data:Entity-result_2,
        askg-data:Entity-study_w,
        askg-data:Entity-tool_q .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "(b) Training behavior (loss and accuracy) Figure 4: Full results for (a) signal propagation (all signular value statistics), and (b) training behavior (including accuracy) for 7-layer linear and tanh MLP networks. We provide results of LDI-Rand, LDI-Rand-AI, VS-CS, LDI-CS, LDI-CS-AI on the linear case for both singular value statistics and training log. We also plot results of LDI-Mag and LDI-Dense on the tanh case for trainability; the training results of non-pruned (LDI-Dense) and magnitude (LDI-Mag) pruning are only reported for the tanh case, because the learning rate had to be lowered for **the linear case (otherwise it explodes),** which makes the comparison not entirely fair. We provide the singular value statistics for the magnitude pruning in Figure 6 to avoid clutter. Also, extended training logs for random and magnitude based pruning are provided separately in Figure 5 to illustrate the difference in convergence speed."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1951,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1952,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1953,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1954,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1955 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(b) Training behavior (loss and accuracy) Figure 4: Full results for (a) signal propagation (all signular value statistics), and (b) training behavior (including accuracy) for 7-layer linear and tanh MLP networks."@en ;
    askg-onto:inSentence "(b) Training behavior (loss and accuracy) Figure 4: Full results for (a) signal propagation (all signular value statistics), and (b) training behavior (including accuracy) for 7-layer linear and tanh MLP networks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7-layer_linear_and_tanh_mlp_networks,
        askg-data:Entity-accuracy,
        askg-data:Entity-loss_and_accuracy,
        askg-data:Entity-training_behavior .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1952 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We provide results of LDI-Rand, LDI-Rand-AI, VS-CS, LDI-CS, LDI-CS-AI on the linear case for both singular value statistics and training log."@en ;
    askg-onto:inSentence "We provide results of LDI-Rand, LDI-Rand-AI, VS-CS, LDI-CS, LDI-CS-AI on the linear case for both singular value statistics and training log."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-cs,
        askg-data:Entity-ldi-cs-ai,
        askg-data:Entity-ldi-rand,
        askg-data:Entity-ldi-rand-ai,
        askg-data:Entity-singular_value_statistics,
        askg-data:Entity-training_log,
        askg-data:Entity-vs-cs .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1953 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We also plot results of LDI-Mag and LDI-Dense on the tanh case for trainability; the training results of non-pruned (LDI-Dense) and magnitude (LDI-Mag) pruning are only reported for the tanh case, because the learning rate had to be lowered for **the linear case (otherwise it explodes),** which makes the comparison not entirely fair."@en ;
    askg-onto:inSentence "We also plot results of LDI-Mag and LDI-Dense on the tanh case for trainability; the training results of non-pruned (LDI-Dense) and magnitude (LDI-Mag) pruning are only reported for the tanh case, because the learning rate had to be lowered for **the linear case (otherwise it explodes),** which makes the comparison not entirely fair."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ldi-dense,
        askg-data:Entity-ldi-mag,
        askg-data:Entity-learning_rate,
        askg-data:Entity-linear_case,
        askg-data:Entity-pruning,
        askg-data:Entity-tanh_case,
        askg-data:Entity-trainability .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1954 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We provide the singular value statistics for the magnitude pruning in Figure 6 to avoid clutter."@en ;
    askg-onto:inSentence "We provide the singular value statistics for the magnitude pruning in Figure 6 to avoid clutter."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-magnitude_pruning,
        askg-data:Entity-singular_value_statistics .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-195-Sentence-1955 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Also, extended training logs for random and magnitude based pruning are provided separately in Figure 5 to illustrate the difference in convergence speed."@en ;
    askg-onto:inSentence "Also, extended training logs for random and magnitude based pruning are provided separately in Figure 5 to illustrate the difference in convergence speed."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-difference_in_convergence_speed,
        askg-data:Entity-figure_5,
        askg-data:Entity-random_and_magnitude_based_pruning,
        askg-data:Entity-training_logs .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-196 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-196-Sentence-1961 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-196-Sentence-1961 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:inSentence "![14_image_0.png](14_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-author,
        askg-data:Entity-cancer_research,
        askg-data:Entity-clinical_trials,
        askg-data:Entity-data_science,
        askg-data:Entity-deep_learning,
        askg-data:Entity-disease,
        askg-data:Entity-healthcare,
        askg-data:Entity-machine_learning,
        askg-data:Entity-pytorch,
        askg-data:Entity-research_area,
        askg-data:Entity-research_paper,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-tensorflow .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-197 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "(a) Training behavior"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-197-Sentence-1971 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-197-Sentence-1971 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) Training behavior"@en ;
    askg-onto:inSentence "(a) Training behavior"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-training_behavior .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Figure 5: Extended training log (i.e**., Loss and Accuracy) for random (Rand) and magnitude (Mag)** pruning. The sparse networks obtained by random or magnitude pruning take a much longer time to train than that obtained by pruning based on connection sensitivity. All methods are pruned at the layerwise orthogonal initialization, and trained the same **way as before.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198-Sentence-1981,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198-Sentence-1982,
        askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198-Sentence-1983 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198-Sentence-1981 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 5: Extended training log (i.e**., Loss and Accuracy) for random (Rand) and magnitude (Mag)** pruning."@en ;
    askg-onto:inSentence "Figure 5: Extended training log (i.e**., Loss and Accuracy) for random (Rand) and magnitude (Mag)** pruning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-loss_and_accuracy,
        askg-data:Entity-magnitude_pruning,
        askg-data:Entity-pruning,
        askg-data:Entity-random_pruning,
        askg-data:Entity-training_log .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198-Sentence-1982 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The sparse networks obtained by random or magnitude pruning take a much longer time to train than that obtained by pruning based on connection sensitivity."@en ;
    askg-onto:inSentence "The sparse networks obtained by random or magnitude pruning take a much longer time to train than that obtained by pruning based on connection sensitivity."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_based_on_connection_sensitivity,
        askg-data:Entity-random_or_magnitude_pruning,
        askg-data:Entity-sparse_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-198-Sentence-1983 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "All methods are pruned at the layerwise orthogonal initialization, and trained the same **way as before.**"@en ;
    askg-onto:inSentence "All methods are pruned at the layerwise orthogonal initialization, and trained the same **way as before.**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-before,
        askg-data:Entity-layerwise_orthogonal_initialization,
        askg-data:Entity-methods .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-199 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "![14_image_1.png](14_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-199-Sentence-1991 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-19-Paragraph-199-Sentence-1991 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![14_image_1.png](14_image_1.png)"@en ;
    askg-onto:inSentence "![14_image_1.png](14_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-14_image_1png,
        askg-data:Entity-image .

askg-data:Paper-54ff6fb7db5b9fad-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "A**Bstract**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Network pruning is a promising avenue for compressing deep neural networks. A typical approach to pruning starts by training a model and then removing redundant parameters while minimizing the impact on what is learned. Alternatively, a recent approach shows that pruning can be done at initialization prior to training, based on a saliency criterion called connection sensitivity. However, it remains unclear exactly why pruning an untrained, randomly initialized neural network is effective. In this work, by noting connection sensitivity as a form of gradient, we formally characterize initialization conditions to ensure reliable connection sensitivity measurements, which in turn yields effective pruning results. Moreover, we analyze the signal propagation properties of the resulting pruned networks and introduce a simple, data-free method to improve their trainability. Our modifications to the existing pruning at initialization method lead **to improved results on** all tested network models for image classification tasks. Furthermore, we empirically study the effect of supervision for pruning and demonstrate that our signal propagation perspective, combined with unsupervised pruning, can be useful in various scenarios where pruning is applied to non-standard **arbitrarily-designed** architectures."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-211,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-212,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-213,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-214,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-215,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-216,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-217,
        askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-218 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Network pruning is a promising avenue for compressing deep neural networks."@en ;
    askg-onto:inSentence "Network pruning is a promising avenue for compressing deep neural networks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network_pruning,
        askg-data:Entity-promising_avenue_for_compressing_deep_neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A typical approach to pruning starts by training a model and then removing redundant parameters while minimizing the impact on what is learned."@en ;
    askg-onto:inSentence "A typical approach to pruning starts by training a model and then removing redundant parameters while minimizing the impact on what is learned."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-impact,
        askg-data:Entity-knowledge_acquisition,
        askg-data:Entity-learning,
        askg-data:Entity-model,
        askg-data:Entity-parameters,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Alternatively, a recent approach shows that pruning can be done at initialization prior to training, based on a saliency criterion called connection sensitivity."@en ;
    askg-onto:inSentence "Alternatively, a recent approach shows that pruning can be done at initialization prior to training, based on a saliency criterion called connection sensitivity."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-initialization,
        askg-data:Entity-pruning,
        askg-data:Entity-saliency_criterion,
        askg-data:Entity-training .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, it remains unclear exactly why pruning an untrained, randomly initialized neural network is effective."@en ;
    askg-onto:inSentence "However, it remains unclear exactly why pruning an untrained, randomly initialized neural network is effective."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-neural_network,
        askg-data:Entity-pruning_an_untrained_randomly_initialized_neural_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In this work, by noting connection sensitivity as a form of gradient, we formally characterize initialization conditions to ensure reliable connection sensitivity measurements, which in turn yields effective pruning results."@en ;
    askg-onto:inSentence "In this work, by noting connection sensitivity as a form of gradient, we formally characterize initialization conditions to ensure reliable connection sensitivity measurements, which in turn yields effective pruning results."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-connection_sensitivity_measurements,
        askg-data:Entity-effective_pruning_results,
        askg-data:Entity-gradient,
        askg-data:Entity-initialization_conditions,
        askg-data:Entity-reliable_connection_sensitivity_measurements .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Moreover, we analyze the signal propagation properties of the resulting pruned networks and introduce a simple, data-free method to improve their trainability."@en ;
    askg-onto:inSentence "Moreover, we analyze the signal propagation properties of the resulting pruned networks and introduce a simple, data-free method to improve their trainability."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data-free_method,
        askg-data:Entity-resulting_pruned_networks,
        askg-data:Entity-signal_propagation_properties,
        askg-data:Entity-trainability .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Our modifications to the existing pruning at initialization method lead **to improved results on** all tested network models for image classification tasks."@en ;
    askg-onto:inSentence "Our modifications to the existing pruning at initialization method lead **to improved results on** all tested network models for image classification tasks."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-modifications,
        askg-data:Entity-network_models_for_image_classification_tasks .

askg-data:Paper-54ff6fb7db5b9fad-Section-2-Paragraph-21-Sentence-218 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Furthermore, we empirically study the effect of supervision for pruning and demonstrate that our signal propagation perspective, combined with unsupervised pruning, can be useful in various scenarios where pruning is applied to non-standard **arbitrarily-designed** architectures."@en ;
    askg-onto:inSentence "Furthermore, we empirically study the effect of supervision for pruning and demonstrate that our signal propagation perspective, combined with unsupervised pruning, can be useful in various scenarios where pruning is applied to non-standard **arbitrarily-designed** architectures."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-standard_arbitrarily-designed_architectures,
        askg-data:Entity-pruning,
        askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-supervision,
        askg-data:Entity-unsupervised_pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "1 I**Ntroduction**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31 ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Deep learning has made great strides in machine learning and **been applied to various fields from** computer vision and natural language processing, to health **care and playing games (LeCun et al.,** 2015). Despite the immense success, however, it remains challenging to deal with the excessive computational and memory requirements of large neural network models. To this end, lightweight models are often preferred, and *network pruning***, a technique to reduce parameters in a network, has** been widely employed to compress deep neural networks (Han et al., 2016). Nonetheless, designing pruning algorithms has been often purely based on ad-hoc intuition lacking rigorous underpinning, partly because pruning was typically carried out after training the model as a post-processing step or interwoven with the training procedure, without adequate tools to analyze. Recently, Lee et al. (2019) have shown that pruning can be done on randomly initialized neural networks in a single-shot prior to training (i.e., *pruning at initialization***). They empirically** showed that as long as the initial random weights are drawn from appropriately scaled Gaussians (e.g**., Glorot & Bengio (2010)), their pruning criterion called connection sensitivity can be used to** prune deep neural networks, often to an extreme level of sparsity while maintaining good accuracy once trained. However, it remains unclear as to why pruning at initialization is effective, how it should be understood theoretically and whether it can be extended further. In this work, we first look into the effect of initialization on pruning, and find that initial weights have critical impact on connection sensitivity, and therefore, **pruning results. Deeper investigation shows** that connection sensitivity is determined by an interplay between gradients and weights. Therefore when the initial weights are not chosen appropriately, the propagation of input signals into layers of 1 these random weights can result in saturating error signals (i.e**., gradients) under backpropagation,** and hence unreliable connection sensitivity, potentially **leading to a catastrophic pruning failure.** This result leads us to develop a signal propagation perspective for pruning at initialization, and to provide a formal characterization of how a network needs to be initialized for reliable connection sensitivity measurements and in turn effective pruning. Precisely, we show that a sufficient condition to ensure faithful1**connection sensitivity is** *layerwise dynamical isometry***, which is defined as all** singular values of the layerwise Jacobians being concentrated around 1. Our signal propagation perspective is inspired by the recent literature on dynamical isometry and mean field theory (Saxe et al., 2014; Poole et al., 2016; Schoenholz et al., 2017; Pennington et al., 2017), in which the general signal propagation in neural networks is studied. We extend this result to understanding and improving pruning at initialization. Moreover, we study signal propagation in the pruned sparse networks and its effect on trainability. We find that pruning neural networks can indeed break dynamical isometry, and hence, hinders signal propagation and degrades the training performance of the resulting sparse network. In order to address this issue, we propose a simple, yet effective data-free method to recover the layerwise orthogonality given the sparse topology, which in turn improves the training performance of the compressed network significantly. Our analysis further reveals that in addition to signal propagation, the choice of pruning method and sparsity level can influence **trainability in sparse neural networks.** Perfect layerwise dynamical isometry cannot always be ensured in the modern networks that have components such as ReLU nonlinearities (Pennington et al., 2017) and/or batch normalization (Yang et al., 2019). Even in such cases, however, our experiments on various modern architectures (including convolutional and residual neural networks) indicate that connection sensitivity computed based on layerwise dynamical isometry is robust and consistently outperforms pruning based on other initialization schemes. This indicates that **the signal propagation perspective is not** only important to theoretically understand pruning at initialization, but also it improves the results of pruning for a range of networks of practical interest. Furthermore, this signal propagation perspective for pruning poses another important question: how informative is the error signal computed on randomly initialized networks, or can we prune neural networks even without supervision? To understand this, we compute connection sensitivity scores with different unsupervised surrogate losses and evaluate the pruning results. Interestingly, our results indicate that we can in fact prune networks in an unsupervised manner to extreme sparsity levels without compromising accuracy, and it often compares competitively to pruning with supervision. Moreover, we test if pruning at initialization can be extended to obtain architectures that yield better performance than standard pre-designed architectures with the same number of parameters. In fact, this process, which we call *neural architecture sculpting***, compares favorably against hand-designed** architectures, taking network pruning one step further towards neural architecture search."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-311,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3110,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3113,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3114,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3115,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3116,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3117,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3118,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3119,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-312,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3120,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3121,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3122,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3123,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3124,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3125,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-313,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-314,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-315,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-316,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-317,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-318,
        askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-319 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Deep learning has made great strides in machine learning and **been applied to various fields from** computer vision and natural language processing, to health **care and playing games (LeCun et al.,** 2015)."@en ;
    askg-onto:inSentence "Deep learning has made great strides in machine learning and **been applied to various fields from** computer vision and natural language processing, to health **care and playing games (LeCun et al.,** 2015)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-computer_vision,
        askg-data:Entity-deep_learning,
        askg-data:Entity-health_care,
        askg-data:Entity-lecun,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-playing_games .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Deeper investigation shows** that connection sensitivity is determined by an interplay between gradients and weights."@en ;
    askg-onto:inSentence "Deeper investigation shows** that connection sensitivity is determined by an interplay between gradients and weights."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_interplay_between_gradients_and_weights,
        askg-data:Entity-connection_sensitivity .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Therefore when the initial weights are not chosen appropriately, the propagation of input signals into layers of 1 these random weights can result in saturating error signals (i.e**., gradients) under backpropagation,** and hence unreliable connection sensitivity, potentially **leading to a catastrophic pruning failure.** This result leads us to develop a signal propagation perspective for pruning at initialization, and to provide a formal characterization of how a network needs to be initialized for reliable connection sensitivity measurements and in turn effective pruning."@en ;
    askg-onto:inSentence "Therefore when the initial weights are not chosen appropriately, the propagation of input signals into layers of 1 these random weights can result in saturating error signals (i.e**., gradients) under backpropagation,** and hence unreliable connection sensitivity, potentially **leading to a catastrophic pruning failure.** This result leads us to develop a signal propagation perspective for pruning at initialization, and to provide a formal characterization of how a network needs to be initialized for reliable connection sensitivity measurements and in turn effective pruning."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backpropagation,
        askg-data:Entity-catastrophic_pruning_failure,
        askg-data:Entity-effective_pruning,
        askg-data:Entity-initialization,
        askg-data:Entity-input_signals,
        askg-data:Entity-layers_of_random_weights,
        askg-data:Entity-network,
        askg-data:Entity-pruning_at_initialization,
        askg-data:Entity-reliable_connection_sensitivity_measurements,
        askg-data:Entity-saturating_error_signals,
        askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-unreliable_connection_sensitivity .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Precisely, we show that a sufficient condition to ensure faithful1**connection sensitivity is** *layerwise dynamical isometry***, which is defined as all** singular values of the layerwise Jacobians being concentrated around 1."@en ;
    askg-onto:inSentence "Precisely, we show that a sufficient condition to ensure faithful1**connection sensitivity is** *layerwise dynamical isometry***, which is defined as all** singular values of the layerwise Jacobians being concentrated around 1."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-layerwise_jacobians,
        askg-data:Entity-singular_values .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Our signal propagation perspective is inspired by the recent literature on dynamical isometry and mean field theory (Saxe et al., 2014; Poole et al., 2016; Schoenholz et al., 2017; Pennington et al., 2017), in which the general signal propagation in neural networks is studied."@en ;
    askg-onto:inSentence "Our signal propagation perspective is inspired by the recent literature on dynamical isometry and mean field theory (Saxe et al., 2014; Poole et al., 2016; Schoenholz et al., 2017; Pennington et al., 2017), in which the general signal propagation in neural networks is studied."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-2016,
        askg-data:Entity-2017,
        askg-data:Entity-dynamical_isometry,
        askg-data:Entity-mean_field_theory,
        askg-data:Entity-neural_networks,
        askg-data:Entity-pennington_et_al,
        askg-data:Entity-poole_et_al,
        askg-data:Entity-recent_literature,
        askg-data:Entity-saxe_et_al,
        askg-data:Entity-schoenholz_et_al,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "We extend this result to understanding and improving pruning at initialization."@en ;
    askg-onto:inSentence "We extend this result to understanding and improving pruning at initialization."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initialization,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Moreover, we study signal propagation in the pruned sparse networks and its effect on trainability."@en ;
    askg-onto:inSentence "Moreover, we study signal propagation in the pruned sparse networks and its effect on trainability."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruned_sparse_networks,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-trainability .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "We find that pruning neural networks can indeed break dynamical isometry, and hence, hinders signal propagation and degrades the training performance of the resulting sparse network."@en ;
    askg-onto:inSentence "We find that pruning neural networks can indeed break dynamical isometry, and hence, hinders signal propagation and degrades the training performance of the resulting sparse network."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-neural_network,
        askg-data:Entity-pruning_neural_networks,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sparse_network,
        askg-data:Entity-training_performance .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3117 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "In order to address this issue, we propose a simple, yet effective data-free method to recover the layerwise orthogonality given the sparse topology, which in turn improves the training performance of the compressed network significantly."@en ;
    askg-onto:inSentence "In order to address this issue, we propose a simple, yet effective data-free method to recover the layerwise orthogonality given the sparse topology, which in turn improves the training performance of the compressed network significantly."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compressed_network,
        askg-data:Entity-data-free_method,
        askg-data:Entity-layerwise_orthogonality,
        askg-data:Entity-sparse_topology,
        askg-data:Entity-training_performance .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3118 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Our analysis further reveals that in addition to signal propagation, the choice of pruning method and sparsity level can influence **trainability in sparse neural networks.** Perfect layerwise dynamical isometry cannot always be ensured in the modern networks that have components such as ReLU nonlinearities (Pennington et al., 2017) and/or batch normalization (Yang et al., 2019)."@en ;
    askg-onto:inSentence "Our analysis further reveals that in addition to signal propagation, the choice of pruning method and sparsity level can influence **trainability in sparse neural networks.** Perfect layerwise dynamical isometry cannot always be ensured in the modern networks that have components such as ReLU nonlinearities (Pennington et al., 2017) and/or batch normalization (Yang et al., 2019)."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-modern_networks,
        askg-data:Entity-pennington_et_al_2017,
        askg-data:Entity-pruning_method,
        askg-data:Entity-relu_nonlinearities,
        askg-data:Entity-signal_propagation,
        askg-data:Entity-sparsity_level,
        askg-data:Entity-trainability_in_sparse_neural_networks,
        askg-data:Entity-yang_et_al_2019 .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3119 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Even in such cases, however, our experiments on various modern architectures (including convolutional and residual neural networks) indicate that connection sensitivity computed based on layerwise dynamical isometry is robust and consistently outperforms pruning based on other initialization schemes."@en ;
    askg-onto:inSentence "Even in such cases, however, our experiments on various modern architectures (including convolutional and residual neural networks) indicate that connection sensitivity computed based on layerwise dynamical isometry is robust and consistently outperforms pruning based on other initialization schemes."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-experiments,
        askg-data:Entity-initialization_schemes,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-modern_architectures,
        askg-data:Entity-pruning,
        askg-data:Entity-pruning_based_on_other_initialization_schemes,
        askg-data:Entity-residual_neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Despite the immense success, however, it remains challenging to deal with the excessive computational and memory requirements of large neural network models."@en ;
    askg-onto:inSentence "Despite the immense success, however, it remains challenging to deal with the excessive computational and memory requirements of large neural network models."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computational_and_memory_requirements,
        askg-data:Entity-large_neural_network_models .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3120 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "This indicates that **the signal propagation perspective is not** only important to theoretically understand pruning at initialization, but also it improves the results of pruning for a range of networks of practical interest."@en ;
    askg-onto:inSentence "This indicates that **the signal propagation perspective is not** only important to theoretically understand pruning at initialization, but also it improves the results of pruning for a range of networks of practical interest."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_range_of_networks,
        askg-data:Entity-pruning,
        askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-the_results_of_pruning,
        askg-data:Entity-theoretically_understand_pruning_at_initialization .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3121 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Furthermore, this signal propagation perspective for pruning poses another important question: how informative is the error signal computed on randomly initialized networks, or can we prune neural networks even without supervision?"@en ;
    askg-onto:inSentence "Furthermore, this signal propagation perspective for pruning poses another important question: how informative is the error signal computed on randomly initialized networks, or can we prune neural networks even without supervision?"^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-error_signal,
        askg-data:Entity-important_question,
        askg-data:Entity-neural_networks,
        askg-data:Entity-randomly_initialized_networks,
        askg-data:Entity-signal_propagation_perspective,
        askg-data:Entity-without_supervision .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3122 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "To understand this, we compute connection sensitivity scores with different unsupervised surrogate losses and evaluate the pruning results."@en ;
    askg-onto:inSentence "To understand this, we compute connection sensitivity scores with different unsupervised surrogate losses and evaluate the pruning results."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_scores,
        askg-data:Entity-pruning_results,
        askg-data:Entity-unsupervised_surrogate_losses .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3123 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Interestingly, our results indicate that we can in fact prune networks in an unsupervised manner to extreme sparsity levels without compromising accuracy, and it often compares competitively to pruning with supervision."@en ;
    askg-onto:inSentence "Interestingly, our results indicate that we can in fact prune networks in an unsupervised manner to extreme sparsity levels without compromising accuracy, and it often compares competitively to pruning with supervision."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-extreme_sparsity_levels,
        askg-data:Entity-networks,
        askg-data:Entity-pruning,
        askg-data:Entity-pruning_with_supervision .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3124 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Moreover, we test if pruning at initialization can be extended to obtain architectures that yield better performance than standard pre-designed architectures with the same number of parameters."@en ;
    askg-onto:inSentence "Moreover, we test if pruning at initialization can be extended to obtain architectures that yield better performance than standard pre-designed architectures with the same number of parameters."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architectures,
        askg-data:Entity-architectures_that_yield_better_performance_than_standard_pre-designed_architectures,
        askg-data:Entity-better_performance_than_standard_pre-designed_architectures,
        askg-data:Entity-parameters,
        askg-data:Entity-pruning_at_initialization,
        askg-data:Entity-standard_pre-designed_architectures .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-3125 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "In fact, this process, which we call *neural architecture sculpting***, compares favorably against hand-designed** architectures, taking network pruning one step further towards neural architecture search."@en ;
    askg-onto:inSentence "In fact, this process, which we call *neural architecture sculpting***, compares favorably against hand-designed** architectures, taking network pruning one step further towards neural architecture search."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hand-designed_architectures,
        askg-data:Entity-network_pruning,
        askg-data:Entity-neural_architecture_sculpting,
        askg-data:Entity-neural_architecture_search .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To this end, lightweight models are often preferred, and *network pruning***, a technique to reduce parameters in a network, has** been widely employed to compress deep neural networks (Han et al., 2016)."@en ;
    askg-onto:inSentence "To this end, lightweight models are often preferred, and *network pruning***, a technique to reduce parameters in a network, has** been widely employed to compress deep neural networks (Han et al., 2016)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-deep_neural_networks,
        askg-data:Entity-han_et_al,
        askg-data:Entity-network_pruning,
        askg-data:Entity-parameters_in_a_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Nonetheless, designing pruning algorithms has been often purely based on ad-hoc intuition lacking rigorous underpinning, partly because pruning was typically carried out after training the model as a post-processing step or interwoven with the training procedure, without adequate tools to analyze."@en ;
    askg-onto:inSentence "Nonetheless, designing pruning algorithms has been often purely based on ad-hoc intuition lacking rigorous underpinning, partly because pruning was typically carried out after training the model as a post-processing step or interwoven with the training procedure, without adequate tools to analyze."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ad-hoc_intuition,
        askg-data:Entity-pruning,
        askg-data:Entity-pruning_algorithms,
        askg-data:Entity-tools,
        askg-data:Entity-training_procedure,
        askg-data:Entity-training_the_model .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Recently, Lee et al."@en ;
    askg-onto:inSentence "Recently, Lee et al."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lee_et_al,
        askg-data:Entity-research .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-316 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "(2019) have shown that pruning can be done on randomly initialized neural networks in a single-shot prior to training (i.e., *pruning at initialization***)."@en ;
    askg-onto:inSentence "(2019) have shown that pruning can be done on randomly initialized neural networks in a single-shot prior to training (i.e., *pruning at initialization***)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-neural_networks,
        askg-data:Entity-pruning,
        askg-data:Entity-pruning_at_initialization,
        askg-data:Entity-randomly_initialized_neural_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-317 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "They empirically** showed that as long as the initial random weights are drawn from appropriately scaled Gaussians (e.g**., Glorot & Bengio (2010)), their pruning criterion called connection sensitivity can be used to** prune deep neural networks, often to an extreme level of sparsity while maintaining good accuracy once trained."@en ;
    askg-onto:inSentence "They empirically** showed that as long as the initial random weights are drawn from appropriately scaled Gaussians (e.g**., Glorot & Bengio (2010)), their pruning criterion called connection sensitivity can be used to** prune deep neural networks, often to an extreme level of sparsity while maintaining good accuracy once trained."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-deep_neural_networks,
        askg-data:Entity-good_accuracy,
        askg-data:Entity-prune_deep_neural_networks,
        askg-data:Entity-pruning_criterion,
        askg-data:Entity-random_weights,
        askg-data:Entity-scaled_gaussians .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-318 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "However, it remains unclear as to why pruning at initialization is effective, how it should be understood theoretically and whether it can be extended further."@en ;
    askg-onto:inSentence "However, it remains unclear as to why pruning at initialization is effective, how it should be understood theoretically and whether it can be extended further."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_at_initialization,
        askg-data:Entity-theoretical_understanding .

askg-data:Paper-54ff6fb7db5b9fad-Section-3-Paragraph-31-Sentence-319 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In this work, we first look into the effect of initialization on pruning, and find that initial weights have critical impact on connection sensitivity, and therefore, **pruning results."@en ;
    askg-onto:inSentence "In this work, we first look into the effect of initialization on pruning, and find that initial weights have critical impact on connection sensitivity, and therefore, **pruning results."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-initial_weights,
        askg-data:Entity-initialization,
        askg-data:Entity-pruning,
        askg-data:Entity-pruning_results .

askg-data:Paper-54ff6fb7db5b9fad-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "2 P**Reliminaries**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-42,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-43,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Pruning at initialization. The principle behind conventional approaches for network **pruning is to** find unnecessary parameters, such that by eliminating them the complexity of the model is reduced while minimizing the impact on what is learned (Reed, 1993). **Naturally, a typical pruning algorithm** starts *after* **convergence to a minimum or training to some degree. This pretraining requirement** has been left unattended until Lee et al. (2019) recently showed that pruning can be performed on untrained networks at initiailzation prior to training. They proposed a method called SNIP **which** relies on a new saliency criterion, namely *connection sensitivity***, defined as follows:**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-413,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-414,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-415,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-416 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Pruning at initialization."@en ;
    askg-onto:inSentence "Pruning at initialization."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initialization,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The principle behind conventional approaches for network **pruning is to** find unnecessary parameters, such that by eliminating them the complexity of the model is reduced while minimizing the impact on what is learned (Reed, 1993)."@en ;
    askg-onto:inSentence "The principle behind conventional approaches for network **pruning is to** find unnecessary parameters, such that by eliminating them the complexity of the model is reduced while minimizing the impact on what is learned (Reed, 1993)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1993,
        askg-data:Entity-author,
        askg-data:Entity-complexity_of_the_model,
        askg-data:Entity-method,
        askg-data:Entity-network_pruning,
        askg-data:Entity-parameters,
        askg-data:Entity-publication,
        askg-data:Entity-reed .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "**Naturally, a typical pruning algorithm** starts *after* **convergence to a minimum or training to some degree."@en ;
    askg-onto:inSentence "**Naturally, a typical pruning algorithm** starts *after* **convergence to a minimum or training to some degree."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence_to_a_minimum,
        askg-data:Entity-pruning_algorithm,
        askg-data:Entity-some_degree .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This pretraining requirement** has been left unattended until Lee et al."@en ;
    askg-onto:inSentence "This pretraining requirement** has been left unattended until Lee et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lee_et_al,
        askg-data:Entity-pretraining_requirement .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2019) recently showed that pruning can be performed on untrained networks at initiailzation prior to training."@en ;
    askg-onto:inSentence "(2019) recently showed that pruning can be performed on untrained networks at initiailzation prior to training."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning,
        askg-data:Entity-training,
        askg-data:Entity-untrained_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-41-Sentence-416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "They proposed a method called SNIP **which** relies on a new saliency criterion, namely *connection sensitivity***, defined as follows:**"@en ;
    askg-onto:inSentence "They proposed a method called SNIP **which** relies on a new saliency criterion, namely *connection sensitivity***, defined as follows:**"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-snip .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$s_{j}({\\bf w};{\\cal D})=\\frac{|g_{j}({\\bf w};{\\cal D})|}{\\sum_{k=1}^{m}|g_{k}({\\bf w};{\\cal D})|}\\;,\\qquad\\mbox{where}\\quad g_{j}({\\bf w};{\\cal D})=\\left.\\frac{\\partial L({\\bf c}\\odot{\\bf w};{\\cal D})}{\\partial c_{j}}\\right|_{{\\bf c}=1}\\;.\\tag{1}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-42-Sentence-421 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$s_{j}({\\bf w};{\\cal D})=\\frac{|g_{j}({\\bf w};{\\cal D})|}{\\sum_{k=1}^{m}|g_{k}({\\bf w};{\\cal D})|}\\;,\\qquad\\mbox{where}\\quad g_{j}({\\bf w};{\\cal D})=\\left.\\frac{\\partial L({\\bf c}\\odot{\\bf w};{\\cal D})}{\\partial c_{j}}\\right|_{{\\bf c}=1}\\;.\\tag{1}$$"@en ;
    askg-onto:inSentence "$$s_{j}({\\bf w};{\\cal D})=\\frac{|g_{j}({\\bf w};{\\cal D})|}{\\sum_{k=1}^{m}|g_{k}({\\bf w};{\\cal D})|}\\;,\\qquad\\mbox{where}\\quad g_{j}({\\bf w};{\\cal D})=\\left.\\frac{\\partial L({\\bf c}\\odot{\\bf w};{\\cal D})}{\\partial c_{j}}\\right|_{{\\bf c}=1}\\;.\\tag{1}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c_j,
        askg-data:Entity-function,
        askg-data:Entity-g_jf_w%0Acal_d,
        askg-data:Entity-lf_c%0Aodotf_w%0Acal_d,
        askg-data:Entity-parameter,
        askg-data:Entity-s_jf_w%0Acal_d,
        askg-data:Entity-score .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-43 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Here, sj **is the saliency of the parameter** j, w ∈ R m is the network parameters, c ∈ {0, 1} m is the auxiliary indicator variables representing the connectivity of network parameters, m **is the total** number of parameters in the network, and D is a given dataset. Also, gj **is the derivative of the** loss L with respect to cj **, which turns out to be an infinitesimal approximation of the change in the**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-43-Sentence-431,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-43-Sentence-432 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-43-Sentence-431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Here, sj **is the saliency of the parameter** j, w ∈ R m is the network parameters, c ∈ {0, 1} m is the auxiliary indicator variables representing the connectivity of network parameters, m **is the total** number of parameters in the network, and D is a given dataset."@en ;
    askg-onto:inSentence "Here, sj **is the saliency of the parameter** j, w ∈ R m is the network parameters, c ∈ {0, 1} m is the auxiliary indicator variables representing the connectivity of network parameters, m **is the total** number of parameters in the network, and D is a given dataset."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-dataset,
        askg-data:Entity-m,
        askg-data:Entity-parameter_j,
        askg-data:Entity-parameters_in_the_network,
        askg-data:Entity-sj .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-43-Sentence-432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Also, gj **is the derivative of the** loss L with respect to cj **, which turns out to be an infinitesimal approximation of the change in the**"@en ;
    askg-onto:inSentence "Also, gj **is the derivative of the** loss L with respect to cj **, which turns out to be an infinitesimal approximation of the change in the**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cj,
        askg-data:Entity-gj,
        askg-data:Entity-loss_l,
        askg-data:Entity-the_change .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "1 The term faithful is used to describe signals propagating in a network isometrically with minimal amplification or attenuation, and borrowed from Saxe et al. (2014), **the first work to introduce dynamical isometry.** loss with respect to removing the parameter j**. Designed to be computed at initialization, pruning is** performed by keeping top-κ (where κ **denotes a desired sparsity level) salient parameters based** on the above sensitivity scores. Dynamical isometry and mean field theory**. The success of training deep neural networks is** due in large part to the initial weights (Hinton & Salakhutdinov, 2006; Glorot & Bengio, 2010; Pascanu et al., 2013). In essence, the principle behind these random weight initializations is to have the mean squared singular value of a network's input-output Jacobian close to 1, so that on average, an error vector will preserve its norm under backpropagation; however, this is not sufficient to prevent amplification or attenuation of an error vector on **worst case. A stronger condition that** having as many singular values as possible near 1 **is called** *dynamical isometry* **(Saxe et al., 2014).** Under this condition, error signals backpropagate isometrically through the network, approximately preserving its norm and all angles between error vectors. Alongside dynamical isometry, mean field theory **is used to develop a theoretical understanding of signal propagation in neural networks with** random parameters (Poole et al., 2016). Precisely, the mean field approximation states that preactivations of wide, untrained neural networks can be captured as a Gaussian distribution. Recent works revealed a maximum depth through which signals can propagate at initialization, and verified that networks are trainable when signals can travel all the way through them (Schoenholz et al., 2017; Yang & Schoenholz, 2017; Xiao et al., 2018)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-441,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-4410,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-442,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-443,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-444,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-445,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-446,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-447,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-448,
        askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-449 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1 The term faithful is used to describe signals propagating in a network isometrically with minimal amplification or attenuation, and borrowed from Saxe et al."@en ;
    askg-onto:inSentence "1 The term faithful is used to describe signals propagating in a network isometrically with minimal amplification or attenuation, and borrowed from Saxe et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful,
        askg-data:Entity-saxe_et_al,
        askg-data:Entity-signals_propagating_in_a_network_isometrically_with_minimal_amplification_or_attenuation .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-4410 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Recent works revealed a maximum depth through which signals can propagate at initialization, and verified that networks are trainable when signals can travel all the way through them (Schoenholz et al., 2017; Yang & Schoenholz, 2017; Xiao et al., 2018)."@en ;
    askg-onto:inSentence "Recent works revealed a maximum depth through which signals can propagate at initialization, and verified that networks are trainable when signals can travel all the way through them (Schoenholz et al., 2017; Yang & Schoenholz, 2017; Xiao et al., 2018)."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-2018,
        askg-data:Entity-maximum_depth,
        askg-data:Entity-networks,
        askg-data:Entity-schoenholz_et_al,
        askg-data:Entity-signals,
        askg-data:Entity-signals_can_travel_through_them,
        askg-data:Entity-xiao_et_al,
        askg-data:Entity-yang__schoenholz .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2014), **the first work to introduce dynamical isometry.** loss with respect to removing the parameter j**."@en ;
    askg-onto:inSentence "(2014), **the first work to introduce dynamical isometry.** loss with respect to removing the parameter j**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-loss .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Designed to be computed at initialization, pruning is** performed by keeping top-κ (where κ **denotes a desired sparsity level) salient parameters based** on the above sensitivity scores."@en ;
    askg-onto:inSentence "Designed to be computed at initialization, pruning is** performed by keeping top-κ (where κ **denotes a desired sparsity level) salient parameters based** on the above sensitivity scores."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_desired_sparsity_level,
        askg-data:Entity-keeping_top-%CE%BA_salient_parameters,
        askg-data:Entity-pruning,
        askg-data:Entity-sensitivity_scores,
        askg-data:Entity-the_above,
        askg-data:Entity-top-%CE%BA .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-444 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Dynamical isometry and mean field theory**."@en ;
    askg-onto:inSentence "Dynamical isometry and mean field theory**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-mean_field_theory .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-445 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The success of training deep neural networks is** due in large part to the initial weights (Hinton & Salakhutdinov, 2006; Glorot & Bengio, 2010; Pascanu et al., 2013)."@en ;
    askg-onto:inSentence "The success of training deep neural networks is** due in large part to the initial weights (Hinton & Salakhutdinov, 2006; Glorot & Bengio, 2010; Pascanu et al., 2013)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2006,
        askg-data:Entity-2010,
        askg-data:Entity-2013,
        askg-data:Entity-deep_neural_networks,
        askg-data:Entity-glorot__bengio,
        askg-data:Entity-hinton__salakhutdinov,
        askg-data:Entity-initial_weights,
        askg-data:Entity-pascanu_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-446 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In essence, the principle behind these random weight initializations is to have the mean squared singular value of a network's input-output Jacobian close to 1, so that on average, an error vector will preserve its norm under backpropagation; however, this is not sufficient to prevent amplification or attenuation of an error vector on **worst case."@en ;
    askg-onto:inSentence "In essence, the principle behind these random weight initializations is to have the mean squared singular value of a network's input-output Jacobian close to 1, so that on average, an error vector will preserve its norm under backpropagation; however, this is not sufficient to prevent amplification or attenuation of an error vector on **worst case."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backpropagation,
        askg-data:Entity-error_vector,
        askg-data:Entity-mean_squared_singular_value_of_a_networks_input-output_jacobian,
        askg-data:Entity-random_weight_initializations,
        askg-data:Entity-worst_case .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-447 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "A stronger condition that** having as many singular values as possible near 1 **is called** *dynamical isometry* **(Saxe et al., 2014).** Under this condition, error signals backpropagate isometrically through the network, approximately preserving its norm and all angles between error vectors."@en ;
    askg-onto:inSentence "A stronger condition that** having as many singular values as possible near 1 **is called** *dynamical isometry* **(Saxe et al., 2014).** Under this condition, error signals backpropagate isometrically through the network, approximately preserving its norm and all angles between error vectors."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-error_signals,
        askg-data:Entity-having_as_many_singular_values_as_possible_near_1,
        askg-data:Entity-isometrically_through_the_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-448 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Alongside dynamical isometry, mean field theory **is used to develop a theoretical understanding of signal propagation in neural networks with** random parameters (Poole et al., 2016)."@en ;
    askg-onto:inSentence "Alongside dynamical isometry, mean field theory **is used to develop a theoretical understanding of signal propagation in neural networks with** random parameters (Poole et al., 2016)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-mean_field_theory,
        askg-data:Entity-signal_propagation_in_neural_networks_with_random_parameters .

askg-data:Paper-54ff6fb7db5b9fad-Section-4-Paragraph-44-Sentence-449 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Precisely, the mean field approximation states that preactivations of wide, untrained neural networks can be captured as a Gaussian distribution."@en ;
    askg-onto:inSentence "Precisely, the mean field approximation states that preactivations of wide, untrained neural networks can be captured as a Gaussian distribution."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gaussian_distribution,
        askg-data:Entity-mean_field_approximation,
        askg-data:Entity-neural_networks,
        askg-data:Entity-preactivations_of_wide_untrained_neural_networks_can_be_captured_as_a_gaussian_distribution .

askg-data:Paper-54ff6fb7db5b9fad-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "3 S**Ignal Propagation Perspective To Pruning Random Networks**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-52,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-53 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Problem setup. Consider a fully-connected, feed-forward neural network **with weight matrices** Wl ∈ R N×N **, biases** b l ∈ R N **, pre-activations** h l ∈ R N **, and post-activations** x l ∈ R N **, for** l ∈ {1 . . . K} up to K **layers. Now, the feed-forward dynamics of a network can be written as,**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-511,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-512,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-513,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-514,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-515,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-516 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Problem setup."@en ;
    askg-onto:inSentence "Problem setup."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-problem_setup .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Consider a fully-connected, feed-forward neural network **with weight matrices** Wl ∈ R N×N **, biases** b l ∈ R N **, pre-activations** h l ∈ R N **, and post-activations** x l ∈ R N **, for** l ∈ {1 ."@en ;
    askg-onto:inSentence "Consider a fully-connected, feed-forward neural network **with weight matrices** Wl ∈ R N×N **, biases** b l ∈ R N **, pre-activations** h l ∈ R N **, and post-activations** x l ∈ R N **, for** l ∈ {1 ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-biases,
        askg-data:Entity-fully-connected_feed-forward_neural_network,
        askg-data:Entity-post-activations,
        askg-data:Entity-pre-activations,
        askg-data:Entity-weight_matrices .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-company,
        askg-data:Entity-concept,
        askg-data:Entity-corpus,
        askg-data:Entity-dataset,
        askg-data:Entity-device,
        askg-data:Entity-institution,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-person,
        askg-data:Entity-research_area,
        askg-data:Entity-scientist,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conditions,
        askg-data:Entity-datasets,
        askg-data:Entity-experiments,
        askg-data:Entity-methods,
        askg-data:Entity-organizations,
        askg-data:Entity-research_concepts,
        askg-data:Entity-research_findings,
        askg-data:Entity-scientists,
        askg-data:Entity-tools .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "K} up to K **layers."@en ;
    askg-onto:inSentence "K} up to K **layers."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-k_layers .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-51-Sentence-516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Now, the feed-forward dynamics of a network can be written as,**"@en ;
    askg-onto:inSentence "Now, the feed-forward dynamics of a network can be written as,**"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feed-forward_dynamics,
        askg-data:Entity-network .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-52 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$${\\bf x}^{l}=\\phi({\\bf h}^{l})\\;,\\qquad{\\bf h}^{l}={\\bf W}^{l}{\\bf x}^{l-1}+{\\bf b}^{l}\\;,$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-52-Sentence-521 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-52-Sentence-521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\bf x}^{l}=\\phi({\\bf h}^{l})\\;,\\qquad{\\bf h}^{l}={\\bf W}^{l}{\\bf x}^{l-1}+{\\bf b}^{l}\\;,$$"@en ;
    askg-onto:inSentence "$${\\bf x}^{l}=\\phi({\\bf h}^{l})\\;,\\qquad{\\bf h}^{l}={\\bf W}^{l}{\\bf x}^{l-1}+{\\bf b}^{l}\\;,$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bl,
        askg-data:Entity-hl,
        askg-data:Entity-wl,
        askg-data:Entity-xl,
        askg-data:Entity-xl-1 .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-53 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "l, (2) where φ : R → R **is an elementwise nonlinearity, and the input is denoted by** x 0**. Given the network** configuration, the parameters are initialized by sampling from a probability distribution, typically a zero mean Gaussian with scaled variance (LeCun et al., 1998; **Glorot & Bengio, 2010).**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-53-Sentence-531,
        askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-53-Sentence-532 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-53-Sentence-531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "l, (2) where φ : R → R **is an elementwise nonlinearity, and the input is denoted by** x 0**."@en ;
    askg-onto:inSentence "l, (2) where φ : R → R **is an elementwise nonlinearity, and the input is denoted by** x 0**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-input,
        askg-data:Entity-r__r,
        askg-data:Entity-x_0 .

askg-data:Paper-54ff6fb7db5b9fad-Section-5-Paragraph-53-Sentence-532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given the network** configuration, the parameters are initialized by sampling from a probability distribution, typically a zero mean Gaussian with scaled variance (LeCun et al., 1998; **Glorot & Bengio, 2010).**"@en ;
    askg-onto:inSentence "Given the network** configuration, the parameters are initialized by sampling from a probability distribution, typically a zero mean Gaussian with scaled variance (LeCun et al., 1998; **Glorot & Bengio, 2010).**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1998,
        askg-data:Entity-2010,
        askg-data:Entity-glorot__bengio,
        askg-data:Entity-lecun_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "3.1 E**Ffect Of Initialization On Pruning**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-62,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "It is observed in Lee et al. (2019) that pruning results tend to improve when initial weights are drawn from a scaled Gaussian, or so-called variance scaling **initialization (LeCun et al., 1998;** Glorot & Bengio, 2010; He et al., 2015). As we wish to better understand the role of these random initial weights in pruning, we will examine the effect of **varying initialization on the pruning** results. In essence, variance scaling schemes introduce normalization factors to adjust the variance σ **of the** weight sampling distribution, which can be summarized as σ → α ψl σ, where ψl**is a layerwise scalar** that depends on an architecture specification such as the number of output neurons in the previous layer (e.g., fan-in), and α is a global scalar throughout the network. Notice in case of a **network** with layers of the same width, the variance can be controlled **by a single scalar** γ = αψ as ψl = ψ for all layers l**. In particular, we take both linear and tanh multilayer perceptron networks (MLP)** of layers K = 7 and width N = 100 on MNIST with σ = 1 **as the default, similar to Saxe et al.** (2014). We initialize these networks with different γ**, compute the connection sensitivity, prune it,** and then visualize layerwise the resulting sparsity patterns c **as well as the corresponding connection** sensitivity used for pruning in Figure 1. It is seen in the sparsity patterns that for the tanh network, **unlike the linear case, more parameters** tend to be pruned in the later layers than the earlier layers. As a result, this limits the learning capability of the subnetwork critically when a high sparsity level is requested; e.g., for κ¯ = 90**%, only a** few parameters in later layers are retained after pruning. This is explained by the connection sensitivity plot. The sensitivity of parameters in the nonlinear **network tends to decrease towards the later** layers, and therefore, choosing the top-κ **parameters globally based on the sensitivity scores results** in a subnetwork in which retained parameters are distributed highly non-uniformly and sparsely towards the end of the network. This result implies that the initial weights have a crucial effect on the connection sensitivity, and from there, the pruning results."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-611,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-6110,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-6111,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-6112,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-612,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-613,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-614,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-615,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-616,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-617,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-618,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-619 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "It is observed in Lee et al."@en ;
    askg-onto:inSentence "It is observed in Lee et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lee_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-6110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "This is explained by the connection sensitivity plot."@en ;
    askg-onto:inSentence "This is explained by the connection sensitivity plot."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_plot .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-6111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "The sensitivity of parameters in the nonlinear **network tends to decrease towards the later** layers, and therefore, choosing the top-κ **parameters globally based on the sensitivity scores results** in a subnetwork in which retained parameters are distributed highly non-uniformly and sparsely towards the end of the network."@en ;
    askg-onto:inSentence "The sensitivity of parameters in the nonlinear **network tends to decrease towards the later** layers, and therefore, choosing the top-κ **parameters globally based on the sensitivity scores results** in a subnetwork in which retained parameters are distributed highly non-uniformly and sparsely towards the end of the network."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-later_layers,
        askg-data:Entity-non-uniformly_and_sparsely,
        askg-data:Entity-parameters,
        askg-data:Entity-sensitivity_scores,
        askg-data:Entity-subnetwork,
        askg-data:Entity-top-%CE%BA_parameters .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-6112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "This result implies that the initial weights have a crucial effect on the connection sensitivity, and from there, the pruning results."@en ;
    askg-onto:inSentence "This result implies that the initial weights have a crucial effect on the connection sensitivity, and from there, the pruning results."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-initial_weights,
        askg-data:Entity-pruning_results .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2019) that pruning results tend to improve when initial weights are drawn from a scaled Gaussian, or so-called variance scaling **initialization (LeCun et al., 1998;** Glorot & Bengio, 2010; He et al., 2015)."@en ;
    askg-onto:inSentence "(2019) that pruning results tend to improve when initial weights are drawn from a scaled Gaussian, or so-called variance scaling **initialization (LeCun et al., 1998;** Glorot & Bengio, 2010; He et al., 2015)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-glorot__bengio_2010,
        askg-data:Entity-he_et_al_2015,
        askg-data:Entity-initial_weights,
        askg-data:Entity-lecun_et_al,
        askg-data:Entity-pruning_results,
        askg-data:Entity-scaled_gaussian,
        askg-data:Entity-variance_scaling_initialization .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As we wish to better understand the role of these random initial weights in pruning, we will examine the effect of **varying initialization on the pruning** results."@en ;
    askg-onto:inSentence "As we wish to better understand the role of these random initial weights in pruning, we will examine the effect of **varying initialization on the pruning** results."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_weights,
        askg-data:Entity-initialization,
        askg-data:Entity-pruning,
        askg-data:Entity-pruning_results .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In essence, variance scaling schemes introduce normalization factors to adjust the variance σ **of the** weight sampling distribution, which can be summarized as σ → α ψl σ, where ψl**is a layerwise scalar** that depends on an architecture specification such as the number of output neurons in the previous layer (e.g., fan-in), and α is a global scalar throughout the network."@en ;
    askg-onto:inSentence "In essence, variance scaling schemes introduce normalization factors to adjust the variance σ **of the** weight sampling distribution, which can be summarized as σ → α ψl σ, where ψl**is a layerwise scalar** that depends on an architecture specification such as the number of output neurons in the previous layer (e.g., fan-in), and α is a global scalar throughout the network."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architecture_specification,
        askg-data:Entity-layerwise_scalar,
        askg-data:Entity-normalization_factors,
        askg-data:Entity-number_of_output_neurons,
        askg-data:Entity-output_neurons,
        askg-data:Entity-previous_layer,
        askg-data:Entity-variance_%CF%83,
        askg-data:Entity-variance_scaling_schemes,
        askg-data:Entity-weight_sampling_distribution .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Notice in case of a **network** with layers of the same width, the variance can be controlled **by a single scalar** γ = αψ as ψl = ψ for all layers l**."@en ;
    askg-onto:inSentence "Notice in case of a **network** with layers of the same width, the variance can be controlled **by a single scalar** γ = αψ as ψl = ψ for all layers l**."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3__%CE%B1%CF%88,
        askg-data:Entity-network,
        askg-data:Entity-scalar,
        askg-data:Entity-variance .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-616 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In particular, we take both linear and tanh multilayer perceptron networks (MLP)** of layers K = 7 and width N = 100 on MNIST with σ = 1 **as the default, similar to Saxe et al.** (2014)."@en ;
    askg-onto:inSentence "In particular, we take both linear and tanh multilayer perceptron networks (MLP)** of layers K = 7 and width N = 100 on MNIST with σ = 1 **as the default, similar to Saxe et al.** (2014)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_study,
        askg-data:Entity-image_classification,
        askg-data:Entity-k,
        askg-data:Entity-mnist,
        askg-data:Entity-multilayer_perceptron_networks_mlp,
        askg-data:Entity-n,
        askg-data:Entity-neural_network,
        askg-data:Entity-saxe_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-617 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We initialize these networks with different γ**, compute the connection sensitivity, prune it,** and then visualize layerwise the resulting sparsity patterns c **as well as the corresponding connection** sensitivity used for pruning in Figure 1."@en ;
    askg-onto:inSentence "We initialize these networks with different γ**, compute the connection sensitivity, prune it,** and then visualize layerwise the resulting sparsity patterns c **as well as the corresponding connection** sensitivity used for pruning in Figure 1."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-different_%CE%B3,
        askg-data:Entity-layerwise,
        askg-data:Entity-networks,
        askg-data:Entity-pruning,
        askg-data:Entity-sparsity_patterns .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-618 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "It is seen in the sparsity patterns that for the tanh network, **unlike the linear case, more parameters** tend to be pruned in the later layers than the earlier layers."@en ;
    askg-onto:inSentence "It is seen in the sparsity patterns that for the tanh network, **unlike the linear case, more parameters** tend to be pruned in the later layers than the earlier layers."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-earlier_layers,
        askg-data:Entity-later_layers,
        askg-data:Entity-linear_case,
        askg-data:Entity-more_parameters,
        askg-data:Entity-tanh_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-61-Sentence-619 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "As a result, this limits the learning capability of the subnetwork critically when a high sparsity level is requested; e.g., for κ¯ = 90**%, only a** few parameters in later layers are retained after pruning."@en ;
    askg-onto:inSentence "As a result, this limits the learning capability of the subnetwork critically when a high sparsity level is requested; e.g., for κ¯ = 90**%, only a** few parameters in later layers are retained after pruning."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BA,
        askg-data:Entity-90,
        askg-data:Entity-later_layers,
        askg-data:Entity-learning_capability,
        askg-data:Entity-parameters,
        askg-data:Entity-pruning,
        askg-data:Entity-retained,
        askg-data:Entity-subnetwork .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![3_image_0.png](3_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-62-Sentence-621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![3_image_0.png](3_image_0.png)"@en ;
    askg-onto:inSentence "![3_image_0.png](3_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-meaningful_entities .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 1: (left) layerwise sparsity patterns c ∈ {0, 1} 100×100 **obtained as a result of pruning for the** sparsity level κ¯ = {10, .., 90}%. Here, black(0)/white(1**) pixels refer to pruned/retained parameters;** (right) connection sensitivities (CS**) measured for the parameters in each layer. All networks are** initialized with γ = 1.0. Unlike the linear case, the sparsity pattern for the tanh network is nonuniform over different layers. When pruning for a high sparsity level (e.g., κ¯ = 90**%), this becomes** critical and leads to poor learning capability as there are only a few parameters left in later layers. This is explained by the connection sensitivity plot which shows that for the nonlinear network parameters in later layers have saturating, lower connection sensitivities than those in earlier layers."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-631,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-632,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-633,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-634,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-635,
        askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-636 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 1: (left) layerwise sparsity patterns c ∈ {0, 1} 100×100 **obtained as a result of pruning for the** sparsity level κ¯ = {10, .., 90}%."@en ;
    askg-onto:inSentence "Figure 1: (left) layerwise sparsity patterns c ∈ {0, 1} 100×100 **obtained as a result of pruning for the** sparsity level κ¯ = {10, .., 90}%."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-layerwise_sparsity_patterns,
        askg-data:Entity-sparsity_level_%CE%BA__10__90 .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here, black(0)/white(1**) pixels refer to pruned/retained parameters;** (right) connection sensitivities (CS**) measured for the parameters in each layer."@en ;
    askg-onto:inSentence "Here, black(0)/white(1**) pixels refer to pruned/retained parameters;** (right) connection sensitivities (CS**) measured for the parameters in each layer."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-black0white1_pixels,
        askg-data:Entity-connection_sensitivities_cs,
        askg-data:Entity-parameters_in_each_layer,
        askg-data:Entity-prunedretained_parameters .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "All networks are** initialized with γ = 1.0."@en ;
    askg-onto:inSentence "All networks are** initialized with γ = 1.0."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3__10,
        askg-data:Entity-all_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Unlike the linear case, the sparsity pattern for the tanh network is nonuniform over different layers."@en ;
    askg-onto:inSentence "Unlike the linear case, the sparsity pattern for the tanh network is nonuniform over different layers."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nonuniform_over_different_layers,
        askg-data:Entity-tanh_network .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-635 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "When pruning for a high sparsity level (e.g., κ¯ = 90**%), this becomes** critical and leads to poor learning capability as there are only a few parameters left in later layers."@en ;
    askg-onto:inSentence "When pruning for a high sparsity level (e.g., κ¯ = 90**%), this becomes** critical and leads to poor learning capability as there are only a few parameters left in later layers."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-poor_learning_capability,
        askg-data:Entity-pruning .

askg-data:Paper-54ff6fb7db5b9fad-Section-6-Paragraph-63-Sentence-636 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This is explained by the connection sensitivity plot which shows that for the nonlinear network parameters in later layers have saturating, lower connection sensitivities than those in earlier layers."@en ;
    askg-onto:inSentence "This is explained by the connection sensitivity plot which shows that for the nonlinear network parameters in later layers have saturating, lower connection sensitivities than those in earlier layers."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_plot,
        askg-data:Entity-earlier_layers,
        askg-data:Entity-later_layers,
        askg-data:Entity-nonlinear_network_parameters,
        askg-data:Entity-saturating_lower_connection_sensitivities .

askg-data:Paper-54ff6fb7db5b9fad-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "3.2 G**Radient Signal In Connection Sensitivity**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-72,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73 ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We posit that the unreliability of connection sensitivity observed in Figure 1 is due to poor signal propagation: an initialization that projects the input signal to be strongly amplified or attenuated in the forward pass will saturate the error signal under backpropagation (i.e**., gradients), and hence will** result in poorly calibrated connection sensitivity scores **across layers, which will eventually lead to** poor pruning results, potentially with complete disconnection of signal paths (e.g**., entire layer).** Precisely, we give the relationship between the connection **sensitivity and the gradients as follows.** From Equation 1, connection sensitivity is a normalized magnitude of gradients with respect to the connectivity parameters c. Here, we use the vectorized notation where w **denotes all learnable** parameters and c **denotes the corresponding connectivity parameters. From chain rule, we can write:**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71-Sentence-711,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71-Sentence-712,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71-Sentence-713 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71-Sentence-711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We posit that the unreliability of connection sensitivity observed in Figure 1 is due to poor signal propagation: an initialization that projects the input signal to be strongly amplified or attenuated in the forward pass will saturate the error signal under backpropagation (i.e**., gradients), and hence will** result in poorly calibrated connection sensitivity scores **across layers, which will eventually lead to** poor pruning results, potentially with complete disconnection of signal paths (e.g**., entire layer).** Precisely, we give the relationship between the connection **sensitivity and the gradients as follows.** From Equation 1, connection sensitivity is a normalized magnitude of gradients with respect to the connectivity parameters c."@en ;
    askg-onto:inSentence "We posit that the unreliability of connection sensitivity observed in Figure 1 is due to poor signal propagation: an initialization that projects the input signal to be strongly amplified or attenuated in the forward pass will saturate the error signal under backpropagation (i.e**., gradients), and hence will** result in poorly calibrated connection sensitivity scores **across layers, which will eventually lead to** poor pruning results, potentially with complete disconnection of signal paths (e.g**., entire layer).** Precisely, we give the relationship between the connection **sensitivity and the gradients as follows.** From Equation 1, connection sensitivity is a normalized magnitude of gradients with respect to the connectivity parameters c."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complete_disconnection_of_signal_paths,
        askg-data:Entity-connection_sensitivity,
        askg-data:Entity-connection_sensitivity_scores,
        askg-data:Entity-connectivity_parameters,
        askg-data:Entity-error_signal,
        askg-data:Entity-gradients,
        askg-data:Entity-initialization,
        askg-data:Entity-input_signal,
        askg-data:Entity-poor_pruning_results,
        askg-data:Entity-poor_signal_propagation,
        askg-data:Entity-strongly_amplified_or_attenuated .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71-Sentence-712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here, we use the vectorized notation where w **denotes all learnable** parameters and c **denotes the corresponding connectivity parameters."@en ;
    askg-onto:inSentence "Here, we use the vectorized notation where w **denotes all learnable** parameters and c **denotes the corresponding connectivity parameters."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_learnable_parameters,
        askg-data:Entity-c,
        askg-data:Entity-the_corresponding_connectivity_parameters,
        askg-data:Entity-w .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-71-Sentence-713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "From chain rule, we can write:**"@en ;
    askg-onto:inSentence "From chain rule, we can write:**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-calculus,
        askg-data:Entity-chain_rule,
        askg-data:Entity-mathematics .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-72 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\left.\\frac{\\partial L(\\mathbf{c}\\odot\\mathbf{w};\\mathcal{D})}{\\partial\\mathbf{c}}\\right|_{\\mathbf{c}=1}=\\left.\\frac{\\partial L(\\mathbf{c}\\odot\\mathbf{w};\\mathcal{D})}{\\partial(\\mathbf{c}\\odot\\mathbf{w})}\\right|_{\\mathbf{c}=1}\\odot\\mathbf{w}=\\frac{\\partial L(\\mathbf{w};\\mathcal{D})}{\\partial\\mathbf{w}}\\odot\\mathbf{w}.\\tag{3}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-72-Sentence-721 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-72-Sentence-721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\left.\\frac{\\partial L(\\mathbf{c}\\odot\\mathbf{w};\\mathcal{D})}{\\partial\\mathbf{c}}\\right|_{\\mathbf{c}=1}=\\left.\\frac{\\partial L(\\mathbf{c}\\odot\\mathbf{w};\\mathcal{D})}{\\partial(\\mathbf{c}\\odot\\mathbf{w})}\\right|_{\\mathbf{c}=1}\\odot\\mathbf{w}=\\frac{\\partial L(\\mathbf{w};\\mathcal{D})}{\\partial\\mathbf{w}}\\odot\\mathbf{w}.\\tag{3}$$"@en ;
    askg-onto:inSentence "$$\\left.\\frac{\\partial L(\\mathbf{c}\\odot\\mathbf{w};\\mathcal{D})}{\\partial\\mathbf{c}}\\right|_{\\mathbf{c}=1}=\\left.\\frac{\\partial L(\\mathbf{c}\\odot\\mathbf{w};\\mathcal{D})}{\\partial(\\mathbf{c}\\odot\\mathbf{w})}\\right|_{\\mathbf{c}=1}\\odot\\mathbf{w}=\\frac{\\partial L(\\mathbf{w};\\mathcal{D})}{\\partial\\mathbf{w}}\\odot\\mathbf{w}.\\tag{3}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c1,
        askg-data:Entity-lcwd,
        askg-data:Entity-lwd,
        askg-data:Entity-w .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Therefore, ∂L/∂c is the gradients ∂L/∂w **amplified (or attenuated) by the corresponding weights** w, i.e., ∂L/∂cj = ∂L/∂wj wj for all j ∈ {1 . . .m}. Considering ∂L/∂cj for a given j**, since** wj **does not depend on any other layers or signal propagation, the only term that depends on signal** propagation in the network is the gradient term ∂L/∂wj**. Hence, a necessary condition to ensure** faithful ∂L/∂c (and connection sensitivity) is that the gradients ∂L/∂w **need to be faithful. In** the following section, we formalize this from a signal propagation perspective, and characterize an initial condition that ensures reliable connection sensitivity measurement."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-731,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-732,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-733,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-734,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-735,
        askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-736 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Therefore, ∂L/∂c is the gradients ∂L/∂w **amplified (or attenuated) by the corresponding weights** w, i.e., ∂L/∂cj = ∂L/∂wj wj for all j ∈ {1 ."@en ;
    askg-onto:inSentence "Therefore, ∂L/∂c is the gradients ∂L/∂w **amplified (or attenuated) by the corresponding weights** w, i.e., ∂L/∂cj = ∂L/∂wj wj for all j ∈ {1 ."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradients_lw,
        askg-data:Entity-lc,
        askg-data:Entity-lcj,
        askg-data:Entity-lwj_wj .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-molecules,
        askg-data:Entity-research_concepts,
        askg-data:Entity-research_methods,
        askg-data:Entity-tools .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text ".m}."@en ;
    askg-onto:inSentence ".m}."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-m,
        askg-data:Entity-unknown .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Considering ∂L/∂cj for a given j**, since** wj **does not depend on any other layers or signal propagation, the only term that depends on signal** propagation in the network is the gradient term ∂L/∂wj**."@en ;
    askg-onto:inSentence "Considering ∂L/∂cj for a given j**, since** wj **does not depend on any other layers or signal propagation, the only term that depends on signal** propagation in the network is the gradient term ∂L/∂wj**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradient_term_lwj,
        askg-data:Entity-lcj,
        askg-data:Entity-signal_propagation .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-735 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Hence, a necessary condition to ensure** faithful ∂L/∂c (and connection sensitivity) is that the gradients ∂L/∂w **need to be faithful."@en ;
    askg-onto:inSentence "Hence, a necessary condition to ensure** faithful ∂L/∂c (and connection sensitivity) is that the gradients ∂L/∂w **need to be faithful."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful_lw,
        askg-data:Entity-lc .

askg-data:Paper-54ff6fb7db5b9fad-Section-7-Paragraph-73-Sentence-736 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In** the following section, we formalize this from a signal propagation perspective, and characterize an initial condition that ensures reliable connection sensitivity measurement."@en ;
    askg-onto:inSentence "In** the following section, we formalize this from a signal propagation perspective, and characterize an initial condition that ensures reliable connection sensitivity measurement."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_measurement,
        askg-data:Entity-initial_condition .

askg-data:Paper-54ff6fb7db5b9fad-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "3.3 L**Ayerwise Dynamical Isometry**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-81,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-83,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-84,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-86,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "3.3.1 GRADIENTS IN TERMS OF J**ACOBIANS** From the feed-forward dynamics of a network in Equation 2, the network's input-output Jacobian corresponding to a given input x 0**can be written, by the chain rule of differentiation, as:**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-81-Sentence-811 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3.3.1 GRADIENTS IN TERMS OF J**ACOBIANS** From the feed-forward dynamics of a network in Equation 2, the network's input-output Jacobian corresponding to a given input x 0**can be written, by the chain rule of differentiation, as:**"@en ;
    askg-onto:inSentence "3.3.1 GRADIENTS IN TERMS OF J**ACOBIANS** From the feed-forward dynamics of a network in Equation 2, the network's input-output Jacobian corresponding to a given input x 0**can be written, by the chain rule of differentiation, as:**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chain_rule_of_differentiation,
        askg-data:Entity-input-output_jacobian,
        askg-data:Entity-network .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbf{J}^{0,K}={\\frac{\\partial\\mathbf{x}^{K}}{\\partial\\mathbf{x}^{0}}}=\\prod_{l=1}^{K}\\mathbf{D}^{l}\\mathbf{W}^{l}\\ ,$$ DlWl, (4) where Dl ∈ R N×N **is a diagonal matrix with entries** Dlij = φ ′ (h li)δij **, with** φ ′ denoting the derivative of nonlinearity φ, and δij = 1[i = j] **is the Kronecker delta. Here, we will use** J k,l **to denote the** Jacobian from layer k to layer l**. Now, we give the relationship between gradients and Jacobians:** Proposition 1. Let ǫ = **∂L/∂**x K **denote the error signal and** x 0 **denote the input signal. Then,**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-821,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-822,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-823,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-824,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-825 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{J}^{0,K}={\\frac{\\partial\\mathbf{x}^{K}}{\\partial\\mathbf{x}^{0}}}=\\prod_{l=1}^{K}\\mathbf{D}^{l}\\mathbf{W}^{l}\\ ,$$ DlWl, (4) where Dl ∈ R N×N **is a diagonal matrix with entries** Dlij = φ ′ (h li)δij **, with** φ ′ denoting the derivative of nonlinearity φ, and δij = 1[i = j] **is the Kronecker delta."@en ;
    askg-onto:inSentence "$$\\mathbf{J}^{0,K}={\\frac{\\partial\\mathbf{x}^{K}}{\\partial\\mathbf{x}^{0}}}=\\prod_{l=1}^{K}\\mathbf{D}^{l}\\mathbf{W}^{l}\\ ,$$ DlWl, (4) where Dl ∈ R N×N **is a diagonal matrix with entries** Dlij = φ ′ (h li)δij **, with** φ ′ denoting the derivative of nonlinearity φ, and δij = 1[i = j] **is the Kronecker delta."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B4ij,
        askg-data:Entity-%CF%86,
        askg-data:Entity-diagonal_matrix,
        askg-data:Entity-dlij,
        askg-data:Entity-kronecker_delta,
        askg-data:Entity-nonlinearity .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here, we will use** J k,l **to denote the** Jacobian from layer k to layer l**."@en ;
    askg-onto:inSentence "Here, we will use** J k,l **to denote the** Jacobian from layer k to layer l**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j_kl,
        askg-data:Entity-jacobian_from_layer_k_to_layer_l .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Now, we give the relationship between gradients and Jacobians:** Proposition 1."@en ;
    askg-onto:inSentence "Now, we give the relationship between gradients and Jacobians:** Proposition 1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradients,
        askg-data:Entity-jacobians .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-824 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Let ǫ = **∂L/∂**x K **denote the error signal and** x 0 **denote the input signal."@en ;
    askg-onto:inSentence "Let ǫ = **∂L/∂**x K **denote the error signal and** x 0 **denote the input signal."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C7%AB,
        askg-data:Entity-error_signal,
        askg-data:Entity-input_signal,
        askg-data:Entity-x_0 .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-82-Sentence-825 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Then,**"@en ;
    askg-onto:inSentence "Then,**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-device,
        askg-data:Entity-method,
        askg-data:Entity-platform,
        askg-data:Entity-research_area,
        askg-data:Entity-technology .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-83 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$(4)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-83-Sentence-831 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-83-Sentence-831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(4)$$"@en ;
    askg-onto:inSentence "$$(4)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4,
        askg-data:Entity-concept .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-84 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "1. the gradients satisfy:"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-84-Sentence-841,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-84-Sentence-842 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-84-Sentence-841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1."@en ;
    askg-onto:inSentence "1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-concept,
        askg-data:Entity-deep_learning,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-triple .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-84-Sentence-842 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "the gradients satisfy:"@en ;
    askg-onto:inSentence "the gradients satisfy:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradients .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}{\\bf D}^{l}\\otimes{\\bf x}^{l-1}\\;,$$ $\\left(6\\right)$. l−1, (5) where J l,K = ∂x K/∂x lis the Jacobian from layer l to the output and ⊗ **is the Kronecker product.** 2. additionally, for linear networks, i.e., when φ **is the identity:**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85-Sentence-851,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85-Sentence-852,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85-Sentence-853 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85-Sentence-851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}{\\bf D}^{l}\\otimes{\\bf x}^{l-1}\\;,$$ $\\left(6\\right)$."@en ;
    askg-onto:inSentence "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}{\\bf D}^{l}\\otimes{\\bf x}^{l-1}\\;,$$ $\\left(6\\right)$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Aepsilon_jlk_dl_%09ensor_xl-1,
        askg-data:Entity-g_wl .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85-Sentence-852 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "l−1, (5) where J l,K = ∂x K/∂x lis the Jacobian from layer l to the output and ⊗ **is the Kronecker product.** 2."@en ;
    askg-onto:inSentence "l−1, (5) where J l,K = ∂x K/∂x lis the Jacobian from layer l to the output and ⊗ **is the Kronecker product.** 2."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jacobian,
        askg-data:Entity-kronecker_product,
        askg-data:Entity-the_jacobian_from_layer_l_to_the_output,
        askg-data:Entity-the_kronecker_product .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-85-Sentence-853 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "additionally, for linear networks, i.e., when φ **is the identity:**"@en ;
    askg-onto:inSentence "additionally, for linear networks, i.e., when φ **is the identity:**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-concept,
        askg-data:Entity-linear_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-86 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}\\otimes\\left({\\bf J}^{0,l-1}{\\bf x}^{0}+{\\bf a}\\right)\\ ,$$ 0 + a, (6) where J 0,l−1 = ∂x l−1/∂x 0is the Jacobian from the input to layer l−1 and a ∈ R N **is a constant** term that does not depend on x 0."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-86-Sentence-861 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-86-Sentence-861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}\\otimes\\left({\\bf J}^{0,l-1}{\\bf x}^{0}+{\\bf a}\\right)\\ ,$$ 0 + a, (6) where J 0,l−1 = ∂x l−1/∂x 0is the Jacobian from the input to layer l−1 and a ∈ R N **is a constant** term that does not depend on x 0."@en ;
    askg-onto:inSentence "$${\\bf g}_{{\\bf w}^{l}}^{T}=\\epsilon\\,{\\bf J}^{l,K}\\otimes\\left({\\bf J}^{0,l-1}{\\bf x}^{0}+{\\bf a}\\right)\\ ,$$ 0 + a, (6) where J 0,l−1 = ∂x l−1/∂x 0is the Jacobian from the input to layer l−1 and a ∈ R N **is a constant** term that does not depend on x 0."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-constant_term,
        askg-data:Entity-jacobian,
        askg-data:Entity-jacobian_from_the_input_to_layer_l1,
        askg-data:Entity-x_0 .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Proof. This can be proved by an algebraic manipulation of the chain rule while using the feedforward dynamics in Equation 2. We provide the full derivation in Appendix A. Notice that the gradient at layer l **constitutes both the backward propagation of the error signal** ǫ up to layer l **and the forward propagation of the input signal** x 0 up to layer l−1**. Moreover, especially in** the linear case, the signal propagation in both directions is governed by the corresponding Jacobians. We believe that this interpretation of gradients is useful as it sheds light on how signal propagation affects the gradients. To this end, we next analyze the conditions on the Jacobians, which would guarantee faithful signal propagation in the network, and consequently, faithful gradients."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-871,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-872,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-873,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-874,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-875,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-876,
        askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-877 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof."@en ;
    askg-onto:inSentence "Proof."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-proof .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-872 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This can be proved by an algebraic manipulation of the chain rule while using the feedforward dynamics in Equation 2."@en ;
    askg-onto:inSentence "This can be proved by an algebraic manipulation of the chain rule while using the feedforward dynamics in Equation 2."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algebraic_manipulation,
        askg-data:Entity-chain_rule,
        askg-data:Entity-equation_2,
        askg-data:Entity-feedforward_dynamics .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-873 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We provide the full derivation in Appendix A."@en ;
    askg-onto:inSentence "We provide the full derivation in Appendix A."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appendix_a,
        askg-data:Entity-full_derivation .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-874 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Notice that the gradient at layer l **constitutes both the backward propagation of the error signal** ǫ up to layer l **and the forward propagation of the input signal** x 0 up to layer l−1**."@en ;
    askg-onto:inSentence "Notice that the gradient at layer l **constitutes both the backward propagation of the error signal** ǫ up to layer l **and the forward propagation of the input signal** x 0 up to layer l−1**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backward_propagation_of_the_error_signal,
        askg-data:Entity-forward_propagation_of_the_input_signal,
        askg-data:Entity-gradient .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-875 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Moreover, especially in** the linear case, the signal propagation in both directions is governed by the corresponding Jacobians."@en ;
    askg-onto:inSentence "Moreover, especially in** the linear case, the signal propagation in both directions is governed by the corresponding Jacobians."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-corresponding_jacobians,
        askg-data:Entity-signal_propagation .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-876 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We believe that this interpretation of gradients is useful as it sheds light on how signal propagation affects the gradients."@en ;
    askg-onto:inSentence "We believe that this interpretation of gradients is useful as it sheds light on how signal propagation affects the gradients."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-how_signal_propagation_affects_the_gradients,
        askg-data:Entity-interpretation_of_gradients .

askg-data:Paper-54ff6fb7db5b9fad-Section-8-Paragraph-87-Sentence-877 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "To this end, we next analyze the conditions on the Jacobians, which would guarantee faithful signal propagation in the network, and consequently, faithful gradients."@en ;
    askg-onto:inSentence "To this end, we next analyze the conditions on the Jacobians, which would guarantee faithful signal propagation in the network, and consequently, faithful gradients."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful_gradients,
        askg-data:Entity-faithful_signal_propagation,
        askg-data:Entity-jacobians .

askg-data:Paper-54ff6fb7db5b9fad-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "3.3.2 E**Nsuring Faithful Gradients**"@en ;
    askg-onto:hasParagraph askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-91,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-95,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-97,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Here, we first consider the layerwise signal propagation which would be useful to derive properties on the initialization to ensure faithful gradients. To this **end, let us consider the layerwise Jacobian:**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-91-Sentence-911,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-91-Sentence-912 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Here, we first consider the layerwise signal propagation which would be useful to derive properties on the initialization to ensure faithful gradients."@en ;
    askg-onto:inSentence "Here, we first consider the layerwise signal propagation which would be useful to derive properties on the initialization to ensure faithful gradients."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deriving_properties_on_the_initialization,
        askg-data:Entity-layerwise_signal_propagation .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-91-Sentence-912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To this **end, let us consider the layerwise Jacobian:**"@en ;
    askg-onto:inSentence "To this **end, let us consider the layerwise Jacobian:**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-layerwise_jacobian .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbf{J}^{l-1,l}={\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{x}^{l-1}}}=\\mathbf{D}^{l}\\mathbf{W}^{l}\\,.$$ = DlWl. (7) Note that it is sufficient to have *layerwise dynamical isometry* **in order to ensure faithful signal** propagation in the network. Definition 1. (*Layerwise dynamical isometry***) Let** J l−1,l = ∂x l ∂xl−1 ∈ R Nl×Nl−1 **be the Jacobian** matrix of layer l**. The network is said to satisfy layerwise dynamical isometry if the singular values** of J l−1,l are concentrated near 1 **for all layers,** i.e., for a given ǫ > 0, the singular value σj **satisfies** |1 − σj | ≤ ǫ **for all** j."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-921,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-922,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-923,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-924,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-925 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{J}^{l-1,l}={\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{x}^{l-1}}}=\\mathbf{D}^{l}\\mathbf{W}^{l}\\,.$$ = DlWl."@en ;
    askg-onto:inSentence "$$\\mathbf{J}^{l-1,l}={\\frac{\\partial\\mathbf{x}^{l}}{\\partial\\mathbf{x}^{l-1}}}=\\mathbf{D}^{l}\\mathbf{W}^{l}\\,.$$ = DlWl."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Crac%0Crac%09extpartial_%09extxl%09extpartial_%09extxl-1,
        askg-data:Entity-dl,
        askg-data:Entity-jl-1l,
        askg-data:Entity-wl .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(7) Note that it is sufficient to have *layerwise dynamical isometry* **in order to ensure faithful signal** propagation in the network."@en ;
    askg-onto:inSentence "(7) Note that it is sufficient to have *layerwise dynamical isometry* **in order to ensure faithful signal** propagation in the network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful_signal_propagation,
        askg-data:Entity-layerwise_dynamical_isometry .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Definition 1."@en ;
    askg-onto:inSentence "Definition 1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-definition_1 .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-924 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(*Layerwise dynamical isometry***) Let** J l−1,l = ∂x l ∂xl−1 ∈ R Nl×Nl−1 **be the Jacobian** matrix of layer l**."@en ;
    askg-onto:inSentence "(*Layerwise dynamical isometry***) Let** J l−1,l = ∂x l ∂xl−1 ∈ R Nl×Nl−1 **be the Jacobian** matrix of layer l**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j_l1l__x_l_xl1__r_nlnl1,
        askg-data:Entity-jacobian_matrix,
        askg-data:Entity-layer_l,
        askg-data:Entity-layerwise_dynamical_isometry .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-92-Sentence-925 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The network is said to satisfy layerwise dynamical isometry if the singular values** of J l−1,l are concentrated near 1 **for all layers,** i.e., for a given ǫ > 0, the singular value σj **satisfies** |1 − σj | ≤ ǫ **for all** j."@en ;
    askg-onto:inSentence "The network is said to satisfy layerwise dynamical isometry if the singular values** of J l−1,l are concentrated near 1 **for all layers,** i.e., for a given ǫ > 0, the singular value σj **satisfies** |1 − σj | ≤ ǫ **for all** j."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-1__%CF%83j___%C7%AB,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-network,
        askg-data:Entity-singular_value_%CF%83j,
        askg-data:Entity-singular_values_of_j_l1l .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "This would guarantee that the signal from layer l to l − 1 (or vice versa) is propagated without amplification or attenuation in any of its dimension. From Proposition 1 and Equation 7, by induction, it is easy to show that if the layerwise signal propagation is **faithful, the error and input signals will** faithfully propagate throughout the network, resulting in **faithful gradients.** For linear networks, J l−1,l = Wl**. Therefore, one can initialize the weight matrix to be** *orthogonal* such that (Wl) TWl = I, where I is the identity matrix of dimension N**. In this case, all singular** values of Wl**are exactly** 1 (i.e**., exact dynamical isometry), and such an initialization guarantees** faithful gradients. While a linear network is of little practical use, we note that it helps to develop theoretical analysis and provides intuition as to why dynamical isometry is a useful measure."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-931,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-932,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-933,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-934,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-935 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This would guarantee that the signal from layer l to l − 1 (or vice versa) is propagated without amplification or attenuation in any of its dimension."@en ;
    askg-onto:inSentence "This would guarantee that the signal from layer l to l − 1 (or vice versa) is propagated without amplification or attenuation in any of its dimension."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-layer_l_to_l__1,
        askg-data:Entity-signal .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "From Proposition 1 and Equation 7, by induction, it is easy to show that if the layerwise signal propagation is **faithful, the error and input signals will** faithfully propagate throughout the network, resulting in **faithful gradients.** For linear networks, J l−1,l = Wl**."@en ;
    askg-onto:inSentence "From Proposition 1 and Equation 7, by induction, it is easy to show that if the layerwise signal propagation is **faithful, the error and input signals will** faithfully propagate throughout the network, resulting in **faithful gradients.** For linear networks, J l−1,l = Wl**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful_gradients,
        askg-data:Entity-layerwise_signal_propagation,
        askg-data:Entity-linear_networks .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-933 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Therefore, one can initialize the weight matrix to be** *orthogonal* such that (Wl) TWl = I, where I is the identity matrix of dimension N**."@en ;
    askg-onto:inSentence "Therefore, one can initialize the weight matrix to be** *orthogonal* such that (Wl) TWl = I, where I is the identity matrix of dimension N**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-i,
        askg-data:Entity-identity_matrix,
        askg-data:Entity-n,
        askg-data:Entity-orthogonal,
        askg-data:Entity-weight_matrix,
        askg-data:Entity-wl_twl .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-934 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In this case, all singular** values of Wl**are exactly** 1 (i.e**., exact dynamical isometry), and such an initialization guarantees** faithful gradients."@en ;
    askg-onto:inSentence "In this case, all singular** values of Wl**are exactly** 1 (i.e**., exact dynamical isometry), and such an initialization guarantees** faithful gradients."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-dynamical_isometry,
        askg-data:Entity-exact_dynamical_isometry,
        askg-data:Entity-faithful_gradients,
        askg-data:Entity-initialization,
        askg-data:Entity-wl .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-93-Sentence-935 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "While a linear network is of little practical use, we note that it helps to develop theoretical analysis and provides intuition as to why dynamical isometry is a useful measure."@en ;
    askg-onto:inSentence "While a linear network is of little practical use, we note that it helps to develop theoretical analysis and provides intuition as to why dynamical isometry is a useful measure."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-linear_network,
        askg-data:Entity-measure,
        askg-data:Entity-of_little_practical_use,
        askg-data:Entity-theoretical_analysis .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "For nonlinear networks, the diagonal matrix Dl **needs to be accounted for as it depends on the** pre-activations h lat layer l**. In this case, it is important to have the pre-activations** h l**fall into the** linear region of the nonlinear function φ**. Precisely, mean-field theory assumes that for large-**N limit, the empirical distribution of the pre-activations h l**converges to a Gaussian with zero mean** and variance q l**, where the variance follows a recursion relation (Poole et al., 2016). Therefore, to** achieve layerwise dynamical isometry, the idea becomes to find a fixed point q ∗ **such that** h l ∼ N (0, q∗) for all l ∈ {1 . . . K}. Such a fixed point makes Dl = D **for all layers, and therefore, the** pre-activations are placed in the linear region of the nonlinearity.2 **Then, given the nonlinearity, one** can find a rescaling such that (DWl) T(DWl**) = (**Wl) TWl/σ2w = I**. The procedure for finding** the rescaling σ 2w **for various nonlinearities are discussed in Pennington et al. (2017; 2018). Also, this** easily extends to convolutional neural networks using the initialization method in Xiao et al. (2018)."@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-941,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-9410,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-9411,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-9412,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-942,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-943,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-944,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-945,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-946,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-947,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-948,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-949 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For nonlinear networks, the diagonal matrix Dl **needs to be accounted for as it depends on the** pre-activations h lat layer l**."@en ;
    askg-onto:inSentence "For nonlinear networks, the diagonal matrix Dl **needs to be accounted for as it depends on the** pre-activations h lat layer l**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-diagonal_matrix_dl,
        askg-data:Entity-pre-activations_h_lat_layer_l .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-9410 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(2017; 2018)."@en ;
    askg-onto:inSentence "(2017; 2018)."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-2018 .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-9411 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Also, this** easily extends to convolutional neural networks using the initialization method in Xiao et al."@en ;
    askg-onto:inSentence "Also, this** easily extends to convolutional neural networks using the initialization method in Xiao et al."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-initialization_method,
        askg-data:Entity-technology,
        askg-data:Entity-xiao_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-9412 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "(2018)."@en ;
    askg-onto:inSentence "(2018)."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-study .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-942 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In this case, it is important to have the pre-activations** h l**fall into the** linear region of the nonlinear function φ**."@en ;
    askg-onto:inSentence "In this case, it is important to have the pre-activations** h l**fall into the** linear region of the nonlinear function φ**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-linear_region_of_the_nonlinear_function_%CF%86,
        askg-data:Entity-pre-activations_h_l .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-943 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Precisely, mean-field theory assumes that for large-**N limit, the empirical distribution of the pre-activations h l**converges to a Gaussian with zero mean** and variance q l**, where the variance follows a recursion relation (Poole et al., 2016)."@en ;
    askg-onto:inSentence "Precisely, mean-field theory assumes that for large-**N limit, the empirical distribution of the pre-activations h l**converges to a Gaussian with zero mean** and variance q l**, where the variance follows a recursion relation (Poole et al., 2016)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-empirical_distribution_of_the_pre-activations,
        askg-data:Entity-mean-field_theory,
        askg-data:Entity-poole_et_al_2016,
        askg-data:Entity-publication,
        askg-data:Entity-recursion_relation,
        askg-data:Entity-variance .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-944 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Therefore, to** achieve layerwise dynamical isometry, the idea becomes to find a fixed point q ∗ **such that** h l ∼ N (0, q∗) for all l ∈ {1 ."@en ;
    askg-onto:inSentence "Therefore, to** achieve layerwise dynamical isometry, the idea becomes to find a fixed point q ∗ **such that** h l ∼ N (0, q∗) for all l ∈ {1 ."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fixed_point_q_,
        askg-data:Entity-h_l,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-n_0_q .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-945 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-text,
        askg-data:Entity-triples_list .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-946 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-article,
        askg-data:Entity-author,
        askg-data:Entity-cell_type,
        askg-data:Entity-company,
        askg-data:Entity-concept,
        askg-data:Entity-condition,
        askg-data:Entity-corpus,
        askg-data:Entity-database,
        askg-data:Entity-dataset,
        askg-data:Entity-device,
        askg-data:Entity-disease,
        askg-data:Entity-domain,
        askg-data:Entity-equipment,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-framework,
        askg-data:Entity-gene,
        askg-data:Entity-head,
        askg-data:Entity-index,
        askg-data:Entity-institution,
        askg-data:Entity-measure,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-molecule,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-paradigm,
        askg-data:Entity-person,
        askg-data:Entity-platform,
        askg-data:Entity-protein,
        askg-data:Entity-publication,
        askg-data:Entity-rate,
        askg-data:Entity-relation,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-result,
        askg-data:Entity-scientist,
        askg-data:Entity-score,
        askg-data:Entity-semantic_types,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-symptom,
        askg-data:Entity-system,
        askg-data:Entity-tail,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-triples,
        askg-data:Entity-university .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-947 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "K}."@en ;
    askg-onto:inSentence "K}."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-mathematical_expressions .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-948 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Such a fixed point makes Dl = D **for all layers, and therefore, the** pre-activations are placed in the linear region of the nonlinearity.2 **Then, given the nonlinearity, one** can find a rescaling such that (DWl) T(DWl**) = (**Wl) TWl/σ2w = I**."@en ;
    askg-onto:inSentence "Such a fixed point makes Dl = D **for all layers, and therefore, the** pre-activations are placed in the linear region of the nonlinearity.2 **Then, given the nonlinearity, one** can find a rescaling such that (DWl) T(DWl**) = (**Wl) TWl/σ2w = I**."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-dl,
        askg-data:Entity-dwl_tdwl,
        askg-data:Entity-linear_region_of_the_nonlinearity,
        askg-data:Entity-pre-activations,
        askg-data:Entity-wl_twl%CF%832w__i .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-94-Sentence-949 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "The procedure for finding** the rescaling σ 2w **for various nonlinearities are discussed in Pennington et al."@en ;
    askg-onto:inSentence "The procedure for finding** the rescaling σ 2w **for various nonlinearities are discussed in Pennington et al."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pennington_et_al,
        askg-data:Entity-the_procedure_for_finding_the_rescaling_%CF%83_2w_for_various_nonlinearities .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-95 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$(7)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-95-Sentence-951 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-95-Sentence-951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(7)$$"@en ;
    askg-onto:inSentence "$$(7)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7,
        askg-data:Entity-integer .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "2 **Dynamical isometry can hold for antisymmetric sigmoidal activation functions (**e.g**., tanh) as shown** in Pennington et al. (2017). A recent work by Tarnowski et al. **(2019) have also shown that dynamical isometry** is achievable irrespective of the activation function in ResNets. Table 1: Jacobian singular values and resulting sparse networks for the 7-layer tanh MLP network considered in section 3.1. SG, CN, and Sparsity refer to Scaled Gaussian, Condition Number (i.e., smax/smin, where smax and smin are the maximum and minimum Jacobian singular values), and a **ratio** of pruned prameters to the total number of parameters, respectively. SG (γ=10−2**) is equivalent to the** variance scaling initialization as in LeCun et al. (1998); Glorot & Bengio (2010). The failure cases correspond to unreliable connection sensitivity resulted **from poorly conditioned initial Jacobians.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-961,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-962,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-963,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-964,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-965,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-966,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-967,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-968,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-969 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-961 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2 **Dynamical isometry can hold for antisymmetric sigmoidal activation functions (**e.g**., tanh) as shown** in Pennington et al."@en ;
    askg-onto:inSentence "2 **Dynamical isometry can hold for antisymmetric sigmoidal activation functions (**e.g**., tanh) as shown** in Pennington et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-antisymmetric_sigmoidal_activation_functions,
        askg-data:Entity-dynamical_isometry,
        askg-data:Entity-pennington_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-962 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2017)."@en ;
    askg-onto:inSentence "(2017)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-research .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-963 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A recent work by Tarnowski et al."@en ;
    askg-onto:inSentence "A recent work by Tarnowski et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-recent_work,
        askg-data:Entity-tarnowski_et_al .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-964 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "**(2019) have also shown that dynamical isometry** is achievable irrespective of the activation function in ResNets."@en ;
    askg-onto:inSentence "**(2019) have also shown that dynamical isometry** is achievable irrespective of the activation function in ResNets."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-activation_function_in_resnets,
        askg-data:Entity-dynamical_isometry .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-965 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Table 1: Jacobian singular values and resulting sparse networks for the 7-layer tanh MLP network considered in section 3.1."@en ;
    askg-onto:inSentence "Table 1: Jacobian singular values and resulting sparse networks for the 7-layer tanh MLP network considered in section 3.1."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7-layer_tanh_mlp_network,
        askg-data:Entity-section_31 .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-966 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "SG, CN, and Sparsity refer to Scaled Gaussian, Condition Number (i.e., smax/smin, where smax and smin are the maximum and minimum Jacobian singular values), and a **ratio** of pruned prameters to the total number of parameters, respectively."@en ;
    askg-onto:inSentence "SG, CN, and Sparsity refer to Scaled Gaussian, Condition Number (i.e., smax/smin, where smax and smin are the maximum and minimum Jacobian singular values), and a **ratio** of pruned prameters to the total number of parameters, respectively."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cn,
        askg-data:Entity-condition_number,
        askg-data:Entity-maximum_and_minimum_jacobian_singular_values,
        askg-data:Entity-pruned_parameters_to_the_total_number_of_parameters,
        askg-data:Entity-ratio,
        askg-data:Entity-scaled_gaussian,
        askg-data:Entity-sg,
        askg-data:Entity-smaxsmin .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-967 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "SG (γ=10−2**) is equivalent to the** variance scaling initialization as in LeCun et al."@en ;
    askg-onto:inSentence "SG (γ=10−2**) is equivalent to the** variance scaling initialization as in LeCun et al."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lecun_et_al,
        askg-data:Entity-sg,
        askg-data:Entity-variance_scaling_initialization .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-968 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "(1998); Glorot & Bengio (2010)."@en ;
    askg-onto:inSentence "(1998); Glorot & Bengio (2010)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2010,
        askg-data:Entity-glorot__bengio .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-96-Sentence-969 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "The failure cases correspond to unreliable connection sensitivity resulted **from poorly conditioned initial Jacobians.**"@en ;
    askg-onto:inSentence "The failure cases correspond to unreliable connection sensitivity resulted **from poorly conditioned initial Jacobians.**"^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_jacobians,
        askg-data:Entity-unreliable_connection_sensitivity .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-97 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "| | | Jacobian singular values | | | | | Sparsity in pruned network (across layers) | | | | | |----------------|----------|----------------------------|----------|------|------|------|----------------------------------------------|------|------|------|-------| | Initialization | Mean | Std | CN | 1 | 2 | 3 | 4 | 5 | 6 | 7 | Error | | SG (γ=10−4 ) | 2.46e−07 | 9.90e−08 | 4.66e+00 | 0.97 | 0.80 | 0.80 | 0.80 | 0.80 | 0.81 | 0.48 | 2.66 | | SG (γ=10−3 ) | 5.74e−04 | 2.45e−04 | 8.54e+00 | 0.97 | 0.80 | 0.80 | 0.80 | 0.80 | 0.81 | 0.48 | 2.67 | | SG (γ=10−2 ) | 4.49e−01 | 2.51e−01 | 5.14e+01 | 0.96 | 0.80 | 0.80 | 0.80 | 0.81 | 0.81 | 0.49 | 2.67 | | SG (γ=10−1 ) | 2.30e+01 | 2.56e+01 | 2.92e+04 | 0.96 | 0.81 | 0.82 | 0.82 | 0.82 | 0.80 | 0.45 | 2.61 | | SG (γ=100 ) | 1.03e+03 | 2.61e+03 | 3.34e+11 | 0.85 | 0.88 | 0.99 | 1.00 | 1.00 | 1.00 | 0.91 | 90.2 | | SG (γ=101 ) | 3.67e+04 | 2.64e+05 | inf | 0.84 | 0.95 | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | 90.2 |"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-97-Sentence-971 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-97-Sentence-971 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | | Jacobian singular values | | | | | Sparsity in pruned network (across layers) | | | | | |----------------|----------|----------------------------|----------|------|------|------|----------------------------------------------|------|------|------|-------| | Initialization | Mean | Std | CN | 1 | 2 | 3 | 4 | 5 | 6 | 7 | Error | | SG (γ=10−4 ) | 2.46e−07 | 9.90e−08 | 4.66e+00 | 0.97 | 0.80 | 0.80 | 0.80 | 0.80 | 0.81 | 0.48 | 2.66 | | SG (γ=10−3 ) | 5.74e−04 | 2.45e−04 | 8.54e+00 | 0.97 | 0.80 | 0.80 | 0.80 | 0.80 | 0.81 | 0.48 | 2.67 | | SG (γ=10−2 ) | 4.49e−01 | 2.51e−01 | 5.14e+01 | 0.96 | 0.80 | 0.80 | 0.80 | 0.81 | 0.81 | 0.49 | 2.67 | | SG (γ=10−1 ) | 2.30e+01 | 2.56e+01 | 2.92e+04 | 0.96 | 0.81 | 0.82 | 0.82 | 0.82 | 0.80 | 0.45 | 2.61 | | SG (γ=100 ) | 1.03e+03 | 2.61e+03 | 3.34e+11 | 0.85 | 0.88 | 0.99 | 1.00 | 1.00 | 1.00 | 0.91 | 90.2 | | SG (γ=101 ) | 3.67e+04 | 2.64e+05 | inf | 0.84 | 0.95 | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | 90.2 |"@en ;
    askg-onto:inSentence "| | | Jacobian singular values | | | | | Sparsity in pruned network (across layers) | | | | | |----------------|----------|----------------------------|----------|------|------|------|----------------------------------------------|------|------|------|-------| | Initialization | Mean | Std | CN | 1 | 2 | 3 | 4 | 5 | 6 | 7 | Error | | SG (γ=10−4 ) | 2.46e−07 | 9.90e−08 | 4.66e+00 | 0.97 | 0.80 | 0.80 | 0.80 | 0.80 | 0.81 | 0.48 | 2.66 | | SG (γ=10−3 ) | 5.74e−04 | 2.45e−04 | 8.54e+00 | 0.97 | 0.80 | 0.80 | 0.80 | 0.80 | 0.81 | 0.48 | 2.67 | | SG (γ=10−2 ) | 4.49e−01 | 2.51e−01 | 5.14e+01 | 0.96 | 0.80 | 0.80 | 0.80 | 0.81 | 0.81 | 0.49 | 2.67 | | SG (γ=10−1 ) | 2.30e+01 | 2.56e+01 | 2.92e+04 | 0.96 | 0.81 | 0.82 | 0.82 | 0.82 | 0.80 | 0.45 | 2.61 | | SG (γ=100 ) | 1.03e+03 | 2.61e+03 | 3.34e+11 | 0.85 | 0.88 | 0.99 | 1.00 | 1.00 | 1.00 | 0.91 | 90.2 | | SG (γ=101 ) | 3.67e+04 | 2.64e+05 | inf | 0.84 | 0.95 | 1.00 | 1.00 | 1.00 | 1.00 | 1.00 | 90.2 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-103e03,
        askg-data:Entity-230e01,
        askg-data:Entity-246e07,
        askg-data:Entity-367e04,
        askg-data:Entity-449e01,
        askg-data:Entity-574e04,
        askg-data:Entity-jacobian_singular_values,
        askg-data:Entity-sg_%CE%B3100,
        askg-data:Entity-sg_%CE%B3101,
        askg-data:Entity-sg_%CE%B3102,
        askg-data:Entity-sg_%CE%B3103,
        askg-data:Entity-sg_%CE%B3104,
        askg-data:Entity-sparsity_in_pruned_network_across_layers .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "We note that dynamical isometry is in fact a weaker condition **than layerwise dynamical isometry.** However, in practice, the initialization suggested in the existing works (Pennington et al., 2017; Xiao et al., 2018), i.e**., orthogonal initialization for weight matrices in each layer with rescaling** based on mean field theory, satisfy layerwise dynamical isometry, even though this term was not mentioned. Now, recall from Section 3.1 that a network is pruned with a global threshold based on connection sensitivity, and from Section 3.2 that the connection sensitivity is the gradients scaled by the weights. This in turn implies that the connection sensitivity scores **across layers are required to be of the same** scale. To this end, we require the gradients to be faithful and the weights to be in the same scale for all the layers. Notice, this condition is trivially satisfied when the layerwise dynamical isometry is ensured, as each layer is initialized identically (i.e**., orthogonal initialization) and the gradients are** guaranteed to be faithful. Finally, we verify the failure of pruning cases presented in Section 3.1 based on the signal propagation perspective. Specifically, we measure the singular **value distribution of the input-output** Jacobian (J 0,K) for the 7**-layer tanh MLP network, and the results are reported in Table 1. Note that** while connection sensitivity based pruning is robust to moderate changes in the Jacobian singular values, it failed catastrophically when the condition number of the Jacobian is very large (> **1e+11**). In fact, these failure cases correspond to the completely disconnected networks, as a consequence of pruning with unreliable connection sensitivity resulted from poorly conditioned initial Jacobians. As we will show subsequently, these findings extend to modern architectures, and layerwise dynamical isometry yields well-conditioned Jacobians and in turn the **best pruning results.**"@en ;
    askg-onto:hasSentence askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-981,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-9810,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-982,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-983,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-984,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-985,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-986,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-987,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-988,
        askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-989 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-981 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We note that dynamical isometry is in fact a weaker condition **than layerwise dynamical isometry.** However, in practice, the initialization suggested in the existing works (Pennington et al., 2017; Xiao et al., 2018), i.e**., orthogonal initialization for weight matrices in each layer with rescaling** based on mean field theory, satisfy layerwise dynamical isometry, even though this term was not mentioned."@en ;
    askg-onto:inSentence "We note that dynamical isometry is in fact a weaker condition **than layerwise dynamical isometry.** However, in practice, the initialization suggested in the existing works (Pennington et al., 2017; Xiao et al., 2018), i.e**., orthogonal initialization for weight matrices in each layer with rescaling** based on mean field theory, satisfy layerwise dynamical isometry, even though this term was not mentioned."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamical_isometry,
        askg-data:Entity-each_layer,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-mean_field_theory,
        askg-data:Entity-orthogonal_initialization,
        askg-data:Entity-weight_matrices .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-9810 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "As we will show subsequently, these findings extend to modern architectures, and layerwise dynamical isometry yields well-conditioned Jacobians and in turn the **best pruning results.**"@en ;
    askg-onto:inSentence "As we will show subsequently, these findings extend to modern architectures, and layerwise dynamical isometry yields well-conditioned Jacobians and in turn the **best pruning results.**"^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_pruning_results,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-well-conditioned_jacobians .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-982 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Now, recall from Section 3.1 that a network is pruned with a global threshold based on connection sensitivity, and from Section 3.2 that the connection sensitivity is the gradients scaled by the weights."@en ;
    askg-onto:inSentence "Now, recall from Section 3.1 that a network is pruned with a global threshold based on connection sensitivity, and from Section 3.2 that the connection sensitivity is the gradients scaled by the weights."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity,
        askg-data:Entity-global_threshold,
        askg-data:Entity-gradients_scaled_by_the_weights,
        askg-data:Entity-network .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-983 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This in turn implies that the connection sensitivity scores **across layers are required to be of the same** scale."@en ;
    askg-onto:inSentence "This in turn implies that the connection sensitivity scores **across layers are required to be of the same** scale."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_scores,
        askg-data:Entity-scale .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-984 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To this end, we require the gradients to be faithful and the weights to be in the same scale for all the layers."@en ;
    askg-onto:inSentence "To this end, we require the gradients to be faithful and the weights to be in the same scale for all the layers."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful,
        askg-data:Entity-gradients,
        askg-data:Entity-layers,
        askg-data:Entity-weights .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-985 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Notice, this condition is trivially satisfied when the layerwise dynamical isometry is ensured, as each layer is initialized identically (i.e**., orthogonal initialization) and the gradients are** guaranteed to be faithful."@en ;
    askg-onto:inSentence "Notice, this condition is trivially satisfied when the layerwise dynamical isometry is ensured, as each layer is initialized identically (i.e**., orthogonal initialization) and the gradients are** guaranteed to be faithful."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faithful,
        askg-data:Entity-gradients,
        askg-data:Entity-layerwise_dynamical_isometry,
        askg-data:Entity-orthogonal_initialization .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-986 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Finally, we verify the failure of pruning cases presented in Section 3.1 based on the signal propagation perspective."@en ;
    askg-onto:inSentence "Finally, we verify the failure of pruning cases presented in Section 3.1 based on the signal propagation perspective."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pruning_cases,
        askg-data:Entity-signal_propagation_perspective .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-987 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Specifically, we measure the singular **value distribution of the input-output** Jacobian (J 0,K) for the 7**-layer tanh MLP network, and the results are reported in Table 1."@en ;
    askg-onto:inSentence "Specifically, we measure the singular **value distribution of the input-output** Jacobian (J 0,K) for the 7**-layer tanh MLP network, and the results are reported in Table 1."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7-layer_tanh_mlp_network,
        askg-data:Entity-jacobian_j_0k,
        askg-data:Entity-neural_network,
        askg-data:Entity-value_distribution .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-988 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Note that** while connection sensitivity based pruning is robust to moderate changes in the Jacobian singular values, it failed catastrophically when the condition number of the Jacobian is very large (> **1e+11**)."@en ;
    askg-onto:inSentence "Note that** while connection sensitivity based pruning is robust to moderate changes in the Jacobian singular values, it failed catastrophically when the condition number of the Jacobian is very large (> **1e+11**)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connection_sensitivity_based_pruning,
        askg-data:Entity-jacobian,
        askg-data:Entity-moderate_changes_in_the_jacobian_singular_values,
        askg-data:Entity-very_large__1e11 .

askg-data:Paper-54ff6fb7db5b9fad-Section-9-Paragraph-98-Sentence-989 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In fact, these failure cases correspond to the completely disconnected networks, as a consequence of pruning with unreliable connection sensitivity resulted from poorly conditioned initial Jacobians."@en ;
    askg-onto:inSentence "In fact, these failure cases correspond to the completely disconnected networks, as a consequence of pruning with unreliable connection sensitivity resulted from poorly conditioned initial Jacobians."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-completely_disconnected_networks,
        askg-data:Entity-failure_cases,
        askg-data:Entity-poorly_conditioned_initial_jacobians,
        askg-data:Entity-pruning,
        askg-data:Entity-unreliable_connection_sensitivity .

askg-data:Entity-%C7%AB rdfs:label "ǫ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BA rdfs:label "κ¯"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0 rdfs:label "0"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-01 rdfs:label "0.1"@en ;
    askg-onto:entityType "Rate"@en,
        "Score"@en .

askg-data:Entity-10 rdfs:label "10"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-10_runs rdfs:label "10 runs"@en ;
    askg-onto:entityType "Experiment"@en,
        "Score"@en .

askg-data:Entity-110 rdfs:label "1/10"@en ;
    askg-onto:entityType "Concept"@en,
        "Rate"@en .

askg-data:Entity-2013 rdfs:label "2013"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-269k rdfs:label "269k"@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-5_runs rdfs:label "5 runs"@en ;
    askg-onto:entityType "Experiment"@en,
        "Score"@en .

askg-data:Entity-7-layer_tanh_mlp_network rdfs:label "7-layer tanh MLP network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-90 rdfs:label "90%"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-aistats rdfs:label "AISTATS"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-algebraic_manipulation rdfs:label "algebraic manipulation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backpropagation rdfs:label "backpropagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_normalization rdfs:label "batch normalization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c rdfs:label "C"@en,
        "c"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compressed_network rdfs:label "compressed network"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-connection_sensitivity_plot rdfs:label "connection sensitivity plot"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-d rdfs:label "D"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-disease rdfs:label "Disease"@en ;
    askg-onto:entityType "Disease"@en .

askg-data:Entity-dl rdfs:label "D^{l}"@en,
        "Dl"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-earlier_layers rdfs:label "earlier layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiment_settings rdfs:label "experiment settings"@en ;
    askg-onto:entityType "Concept"@en,
        "Experiment"@en .

askg-data:Entity-feed-forward_dynamics rdfs:label "feed-forward dynamics"@en ;
    askg-onto:entityType "Concept"@en,
        "Paradigm"@en .

askg-data:Entity-finding rdfs:label "Finding"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-framework rdfs:label "Framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-frobenius_norm rdfs:label "Frobenius norm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalization_performance rdfs:label "generalization performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradient rdfs:label "gradient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradient_descent rdfs:label "gradient descent"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-healthcare rdfs:label "Healthcare"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-i rdfs:label "I"@en,
        "i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iclr_2019 rdfs:label "ICLR 2019"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-icml rdfs:label "ICML"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-identity_matrix rdfs:label "identity matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image rdfs:label "Image"@en,
        "image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_recognition rdfs:label "Image Recognition"@en,
        "image recognition"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-input rdfs:label "input"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-isometry rdfs:label "isometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jacobians rdfs:label "Jacobians"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jian_sun rdfs:label "Jian Sun"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-kaiming_he rdfs:label "Kaiming He"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-knowledge_graph rdfs:label "Knowledge Graph"@en,
        "knowledge graph"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_signal_propagation rdfs:label "layerwise signal propagation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-lc rdfs:label "∂L/∂c"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lcj rdfs:label "∂L/∂cj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi rdfs:label "LDI"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-ldi-cs_rand-ai rdfs:label "LDI-{CS, Rand}-AI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi-rand-ai rdfs:label "LDI-Rand-AI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning rdfs:label "learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_case rdfs:label "linear case"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-loss_and_accuracy rdfs:label "Loss and Accuracy"@en,
        "loss and accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-m rdfs:label ".m}"@en,
        "m"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-measure rdfs:label "Measure"@en,
        "measure"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-methods rdfs:label "methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-modern_neural_networks rdfs:label "modern neural networks"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-n rdfs:label "N"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-namhoon_lee rdfs:label "Namhoon Lee"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-natural_language_processing rdfs:label "Natural Language Processing"@en,
        "natural language processing"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-neurips rdfs:label "NeurIPS"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-number_of_residual_blocks rdfs:label "number of residual blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-orthogonality rdfs:label "orthogonality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pre-activations rdfs:label "pre-activations"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-process rdfs:label "process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruned_network rdfs:label "pruned network"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-pruning_method rdfs:label "pruning method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pruning_methods rdfs:label "pruning methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-reliable_connection_sensitivity_measurements rdfs:label "reliable connection sensitivity measurements"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-resnet110 rdfs:label "ResNet110"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet20 rdfs:label "ResNet20"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet56 rdfs:label "ResNet56"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-robotics rdfs:label "Robotics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-runs rdfs:label "runs"@en ;
    askg-onto:entityType "Concept"@en,
        "Experiment"@en .

askg-data:Entity-samuel_schoenholz rdfs:label "Samuel Schoenholz"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-scaled_gaussian rdfs:label "Scaled Gaussian"@en,
        "scaled Gaussian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-schoenholz_et_al rdfs:label "Schoenholz et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-science rdfs:label "Science"@en,
        "science"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-sensitivity_scores rdfs:label "sensitivity scores"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sg rdfs:label "SG"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shaoqing_ren rdfs:label "Shaoqing Ren"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-signal_propagation_measurements rdfs:label "Signal propagation measurements"@en,
        "signal propagation measurements"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-size rdfs:label "size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparse_equivalents rdfs:label "sparse equivalents"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-step_4 rdfs:label "Step 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subnetwork rdfs:label "subnetwork"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tanh_case rdfs:label "tanh case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tanh_network rdfs:label "tanh network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-thalaiyasingam_ajanthan rdfs:label "Thalaiyasingam Ajanthan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-theoretical_analysis rdfs:label "theoretical analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tool rdfs:label "Tool"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-training_log rdfs:label "training log"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-triple_extraction rdfs:label "Triple extraction"@en,
        "triple extraction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triples_list rdfs:label "Triples_list"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uniform_loss rdfs:label "uniform loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-university rdfs:label "University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unknown rdfs:label "unknown"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_surrogate_losses rdfs:label "unsupervised surrogate losses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variance rdfs:label "variance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vs-g rdfs:label "VS-G"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-vs-h rdfs:label "VS-H"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-vs-l rdfs:label "VS-L"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-w rdfs:label "w"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wrn16 rdfs:label "WRN16"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-xiangyu_zhang rdfs:label "Xiangyu Zhang"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-yann_lecun rdfs:label "Yann LeCun"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-year rdfs:label "Year"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BA__90 rdfs:label "κ¯ = 90%"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-%CF%86 rdfs:label "φ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1998 rdfs:label "(1998)"@en,
        "1998"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2016 rdfs:label "2016"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2018 rdfs:label "2018"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2019 rdfs:label "2019"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-7-layer_linear_and_tanh_mlp_networks rdfs:label "7-layer linear and tanh MLP networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-activation_function rdfs:label "Activation Function"@en,
        "activation function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ai rdfs:label "AI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approximate_isometry rdfs:label "Approximate Isometry"@en,
        "approximate isometry"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-architectures rdfs:label "architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-article rdfs:label "Article"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-avg rdfs:label "avg."@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-best_results rdfs:label "best results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-chain_rule rdfs:label "chain rule"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-company rdfs:label "Company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-computer_vision rdfs:label "Computer Vision"@en,
        "computer vision"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-constant_term rdfs:label "constant term"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolutional_neural_networks rdfs:label "convolutional neural networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-corpus rdfs:label "Corpus"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-dense_network rdfs:label "dense network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-faithful rdfs:label "faithful"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-faithful_gradients rdfs:label "faithful gradients"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-faithful_signal_propagation rdfs:label "faithful signal propagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-function rdfs:label "Function"@en,
        "function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g_wl rdfs:label "g_w^{l}"@en,
        "g_{w^{l}}"@en,
        "g_{w}^{l}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_signal rdfs:label "input signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kronecker_product rdfs:label "Kronecker product"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi-ai rdfs:label "LDI-AI"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-ldi-cs-ai rdfs:label "LDI-CS-AI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi-cs-aif rdfs:label "LDI-CS-AIF"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-learning_rate rdfs:label "learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss rdfs:label "loss"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-magnitude_pruning rdfs:label "magnitude pruning"@en ;
    askg-onto:entityType "Method"@en,
        "Technique"@en .

askg-data:Entity-optimization rdfs:label "optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-orthogonal rdfs:label "orthogonal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-overparameterization rdfs:label "Overparameterization"@en,
        "overparameterization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paradigm rdfs:label "Paradigm"@en,
        "paradigm"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-pennington_et_al rdfs:label "Pennington et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-pruned_sparse_network rdfs:label "pruned sparse network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruned_sparse_networks rdfs:label "pruned sparse networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruning_algorithms rdfs:label "Pruning algorithms"@en,
        "pruning algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-research_concepts rdfs:label "research concepts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-score rdfs:label "Score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-sgd rdfs:label "SGD"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-signal_propagation_characteristics rdfs:label "signal propagation characteristics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-singular_value_statistics rdfs:label "singular value statistics"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-sparsity_level rdfs:label "sparsity level"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-supervision rdfs:label "supervision"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-technique rdfs:label "Technique"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-theory rdfs:label "Theory"@en,
        "theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-tools rdfs:label "tools"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-trainability_of_sparse_neural_networks rdfs:label "trainability of sparse neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_behavior rdfs:label "Training behavior"@en,
        "training behavior"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_performance rdfs:label "training performance"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-training_speed rdfs:label "training speed"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triple rdfs:label "triple"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unreliable_connection_sensitivity rdfs:label "unreliable connection sensitivity"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-variance_scaling_initialization rdfs:label "variance scaling initialization"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-weight_matrices rdfs:label "weight matrices"@en ;
    askg-onto:entityType "Concept"@en,
        "Device"@en,
        "Technology"@en .

askg-data:Entity-weights rdfs:label "weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xiao_et_al rdfs:label "Xiao et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-yoshua_bengio rdfs:label "Yoshua Bengio"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-1 rdfs:label "1"@en,
        "{1"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-a rdfs:label "A"@en,
        "a"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-condition rdfs:label "Condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-conference rdfs:label "Conference"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data rdfs:label "Data"@en,
        "data"@en ;
    askg-onto:entityType "Concept"@en,
        "Corpus"@en .

askg-data:Entity-data-free_method rdfs:label "data-free method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-datasets rdfs:label "datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-deep_neural_networks rdfs:label "deep neural networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-error_signal rdfs:label "error signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiments rdfs:label "experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-glorot__bengio rdfs:label "Glorot & Bengio"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-institution rdfs:label "Institution"@en ;
    askg-onto:entityType "Institution"@en .

askg-data:Entity-jacobian_singular_values rdfs:label "Jacobian singular values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jascha_sohl-dickstein rdfs:label "Jascha Sohl-Dickstein"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-jeffrey_pennington rdfs:label "Jeffrey Pennington"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-k rdfs:label "K"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-later_layers rdfs:label "later layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ldi-cs rdfs:label "LDI-CS"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-ldi-dense rdfs:label "LDI-Dense"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-lecun_et_al rdfs:label "LeCun et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-linear_networks rdfs:label "linear networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_pruning rdfs:label "Network pruning"@en,
        "network pruning"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-neural_architecture_sculpting rdfs:label "Neural architecture sculpting"@en,
        "neural architecture sculpting"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-orthogonality_scores rdfs:label "orthogonality scores"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-platform rdfs:label "Platform"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-proof rdfs:label "Proof"@en,
        "proof"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruned_networks rdfs:label "pruned networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research rdfs:label "Research"@en,
        "research"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en,
        "Research Field"@en .

askg-data:Entity-research_field rdfs:label "Research Field"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_group rdfs:label "Research Group"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-resnet32 rdfs:label "ResNet32"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-results rdfs:label "Results"@en,
        "results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-samuel_s_schoenholz rdfs:label "Samuel S Schoenholz"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-saxe_et_al rdfs:label "Saxe et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-scientist rdfs:label "Scientist"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-signals rdfs:label "signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-software rdfs:label "Software"@en ;
    askg-onto:entityType "Software"@en,
        "Tool"@en .

askg-data:Entity-sparse_topology rdfs:label "sparse topology"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparsity rdfs:label "sparsity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wl rdfs:label "W^l"@en,
        "W^{l}"@en,
        "Wl"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2010 rdfs:label "2010"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2017 rdfs:label "2017"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-approximate_dynamical_isometry rdfs:label "approximate dynamical isometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-connection_sensitivity_scores rdfs:label "connection sensitivity scores"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en,
        "Score"@en .

askg-data:Entity-generalization_errors rdfs:label "generalization errors"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-iclr rdfs:label "ICLR"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-jacobian rdfs:label "Jacobian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lee_et_al rdfs:label "Lee et al."@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-magnitude_based_pruning rdfs:label "magnitude based pruning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-organization rdfs:label "Organization"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-orthogonal_initialization rdfs:label "orthogonal initialization"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-person rdfs:label "Person"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-singular_values rdfs:label "singular values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparse_network rdfs:label "sparse network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-surya_ganguli rdfs:label "Surya Ganguli"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-unsupervised_pruning rdfs:label "unsupervised pruning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en,
        "artificial intelligence"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-mean_field_theory rdfs:label "mean field theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-networks rdfs:label "networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_network rdfs:label "neural network"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-researcher rdfs:label "Researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-tiny-imagenet rdfs:label "Tiny-ImageNet"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-vgg16 rdfs:label "VGG16"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-x_0 rdfs:label "x 0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en,
        "Deep learning"@en,
        "deep learning"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-gradients rdfs:label "gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parameters rdfs:label "parameters"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-pruning_at_initialization rdfs:label "pruning at initialization"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-random_pruning rdfs:label "Random pruning"@en,
        "random pruning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-training rdfs:label "training"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-device rdfs:label "Device"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-experiment rdfs:label "Experiment"@en,
        "experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-initial_weights rdfs:label "initial weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en,
        "machine learning"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-model rdfs:label "Model"@en,
        "model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-pruning_results rdfs:label "pruning results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-sparse_networks rdfs:label "sparse networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-study rdfs:label "Study"@en ;
    askg-onto:entityType "Research Field"@en,
        "Study"@en .

askg-data:Entity-trainability rdfs:label "trainability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-mnist rdfs:label "MNIST"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-cifar-10 rdfs:label "CIFAR-10"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-technology rdfs:label "Technology"@en,
        "technology"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-publication rdfs:label "Publication"@en,
        "publication"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-algorithm rdfs:label "Algorithm"@en,
        "algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-initialization rdfs:label "initialization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layerwise_dynamical_isometry rdfs:label "Layerwise dynamical isometry"@en,
        "layerwise dynamical isometry"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-neural_networks rdfs:label "Neural Networks"@en,
        "neural networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Publication"@en,
        "Technology"@en .

askg-data:Entity-research_area rdfs:label "Research Area"@en ;
    askg-onto:entityType "Research Area"@en,
        "Research Field"@en .

askg-data:Entity-author rdfs:label "Author"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-network rdfs:label "network"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "System"@en .

askg-data:Entity-connection_sensitivity rdfs:label "connection sensitivity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamical_isometry rdfs:label "Dynamical isometry"@en,
        "dynamical isometry"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-signal_propagation_perspective rdfs:label "signal propagation perspective"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal_propagation rdfs:label "Signal propagation"@en,
        "signal propagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-concept rdfs:label "Concept"@en,
        "concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pruning rdfs:label "Pruning"@en,
        "pruning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

