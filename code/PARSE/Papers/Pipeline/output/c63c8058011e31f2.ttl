@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-c63c8058011e31f2 a askg-onto:Paper ;
    rdfs:label "c63c8058011e31f2"@en ;
    dc:title "c63c8058011e31f2"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-c63c8058011e31f2-Section-1,
        askg-data:Paper-c63c8058011e31f2-Section-10,
        askg-data:Paper-c63c8058011e31f2-Section-11,
        askg-data:Paper-c63c8058011e31f2-Section-12,
        askg-data:Paper-c63c8058011e31f2-Section-13,
        askg-data:Paper-c63c8058011e31f2-Section-14,
        askg-data:Paper-c63c8058011e31f2-Section-15,
        askg-data:Paper-c63c8058011e31f2-Section-16,
        askg-data:Paper-c63c8058011e31f2-Section-17,
        askg-data:Paper-c63c8058011e31f2-Section-18,
        askg-data:Paper-c63c8058011e31f2-Section-19,
        askg-data:Paper-c63c8058011e31f2-Section-2,
        askg-data:Paper-c63c8058011e31f2-Section-20,
        askg-data:Paper-c63c8058011e31f2-Section-21,
        askg-data:Paper-c63c8058011e31f2-Section-22,
        askg-data:Paper-c63c8058011e31f2-Section-23,
        askg-data:Paper-c63c8058011e31f2-Section-24,
        askg-data:Paper-c63c8058011e31f2-Section-25,
        askg-data:Paper-c63c8058011e31f2-Section-26,
        askg-data:Paper-c63c8058011e31f2-Section-27,
        askg-data:Paper-c63c8058011e31f2-Section-28,
        askg-data:Paper-c63c8058011e31f2-Section-29,
        askg-data:Paper-c63c8058011e31f2-Section-3,
        askg-data:Paper-c63c8058011e31f2-Section-30,
        askg-data:Paper-c63c8058011e31f2-Section-31,
        askg-data:Paper-c63c8058011e31f2-Section-32,
        askg-data:Paper-c63c8058011e31f2-Section-33,
        askg-data:Paper-c63c8058011e31f2-Section-34,
        askg-data:Paper-c63c8058011e31f2-Section-35,
        askg-data:Paper-c63c8058011e31f2-Section-4,
        askg-data:Paper-c63c8058011e31f2-Section-5,
        askg-data:Paper-c63c8058011e31f2-Section-6,
        askg-data:Paper-c63c8058011e31f2-Section-7,
        askg-data:Paper-c63c8058011e31f2-Section-8,
        askg-data:Paper-c63c8058011e31f2-Section-9 .

askg-data:Entity-%C2%B5s rdfs:label "µs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%C2%B5x rdfs:label "µx"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%C2%B5y rdfs:label "µy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BB_b_%CE%BB_vbz rdfs:label "λ B λ (vB)·z"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BB_vdz rdfs:label "λ (vD)·z"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%81 rdfs:label "ρ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83c rdfs:label "σc"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83x rdfs:label "σx"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83xy_cross-correlation rdfs:label "σxy cross-correlation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83y rdfs:label "σy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%86_ax rdfs:label "Φ_A(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity--1_and_1 rdfs:label "-1 and 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0 rdfs:label "${0}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-01 rdfs:label "[0,1]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1 rdfs:label "[1]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-10 rdfs:label "10"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-10-eta_%0Alambdadx rdfs:label """10^{-eta_{
\\lambda}d(x)}"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-100 rdfs:label "100"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-10000_images rdfs:label "10,000 images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-101 rdfs:label "10−1"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-1037_turbid_underwater_images rdfs:label "1,037 turbid underwater images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-11 rdfs:label "[11]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-11211 rdfs:label "112×11"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-11_convolutional_layer rdfs:label "1×1 convolutional layer"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-1200 rdfs:label "1200"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-12000_synthetic_underwater_images rdfs:label "12,000 synthetic underwater images"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-12_enhanced_results rdfs:label "12 enhanced results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-1449_images rdfs:label "1449 images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-14_convolutional_layers rdfs:label "14 convolutional layers"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-15000_underwater_images rdfs:label "15,000 underwater images"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-17 rdfs:label "17"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-17561769 rdfs:label "1756–1769"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-180180_transmission_map rdfs:label "180×180 transmission map"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-1817_images_with_distortion rdfs:label "1,817 images with distortion"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-1924 rdfs:label "1924"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-200 rdfs:label "200"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-2000_images rdfs:label "2,000 images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-2003 rdfs:label "2003"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2004 rdfs:label "2004"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2006 rdfs:label "2006"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-200_clear_images rdfs:label "200 clear images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-2010 rdfs:label "2010"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2011 rdfs:label "2011"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2012 rdfs:label "2012"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2104 rdfs:label "2×10−4"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-2105_image_patches rdfs:label "2×105 image patches"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-214 rdfs:label "21(4)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-25_layers rdfs:label "25 layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-286286 rdfs:label "286×286"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-29 rdfs:label "29"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-29_different_underwater_ambient_lights rdfs:label "29 different underwater ambient lights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2_loss_functions rdfs:label "2 loss functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-30 rdfs:label "30"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-32 rdfs:label "32"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-3232_feature_matrix rdfs:label "32×32 feature matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3232_image_patches rdfs:label "32×32 image patches"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-34 rdfs:label "34"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-35 rdfs:label "35"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3800_high-quality_air_images rdfs:label "3800 high-quality air images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-3800_underwater_images rdfs:label "3800 underwater images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-39 rdfs:label "39"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3d_structure rdfs:label "3D structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-40 rdfs:label "40"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-42_layers rdfs:label "42 layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-46 rdfs:label "[46]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-4__4 rdfs:label "4 × 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-5103 rdfs:label "5×10−3"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-5105 rdfs:label "5×10−5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-58_60 rdfs:label "[58, 60]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-5_0_3_until_25105 rdfs:label "5× 0 3 until 2.5×105"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-6143_images_without_distortion rdfs:label "6,143 images without distortion"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-64_and_128_feature_maps rdfs:label "64 and 128 feature maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-64_feature_maps rdfs:label "64 feature maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-7000_images rdfs:label "7,000 images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-77_and_33_filter_size rdfs:label "7×7 and 3×3 filter size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-800_pairs_of_images rdfs:label "800 pairs of images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-837 rdfs:label "837"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-890_corresponding_reference_images rdfs:label "890 corresponding reference images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-890_reference_images rdfs:label "890 reference images"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-9 rdfs:label "9"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-90_pairs_of_images rdfs:label "90 pairs of images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-950_real-world_underwater_images rdfs:label "950 real-world underwater images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-950_underwater_images rdfs:label "950 underwater images"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-a_benchmark rdfs:label "a benchmark"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-a_category-level_3d_object_dataset rdfs:label "A category-level 3d object dataset"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_category-level_3d_object_dataset_putting_the_kinect_to_work rdfs:label "A category-level 3d object dataset: Putting the kinect to work"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-a_deep_cnn_method_for_underwater_image_enhancement rdfs:label "A deep cnn method for underwater image enhancement"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-a_fusion_adversarial_underwater_image_enhancement_network rdfs:label "A Fusion Adversarial Underwater Image Enhancement Network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_fusion_adversarial_underwater_image_enhancement_network_with_a_public_test_dataset rdfs:label "A Fusion Adversarial Underwater Image Enhancement Network with a Public Test Dataset"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-a_large_range_of_image_resolution rdfs:label "a large range of image resolution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_new_quantitative_dataset rdfs:label "a new quantitative dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-a_patch-structure_representation_method_for_quality_assessment_of_contrast_changed_images rdfs:label "A patch-structure representation method for quality assessment of contrast changed images"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-a_research_tool_for_long-term_and_continuous_analysis_of_fish_assemblage_in_coral-reefs rdfs:label "A research tool for long-term and continuous analysis of fish assemblage in coral-reefs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_revised_underwater_image_formation_model rdfs:label "A revised underwater image formation model"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-a_simple_fast_and_repeatable_survey_method_for_underwater_visual_3d_benthic_mapping_and_monitoring rdfs:label "A simple, fast, and repeatable survey method for underwater visual 3d benthic mapping and monitoring"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-a_universal_image_quality_index rdfs:label "A universal image quality index"@en ;
    askg-onto:entityType "Index"@en,
        "Publication"@en .

askg-data:Entity-a_visual_representation rdfs:label "a visual representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-accurate_distance rdfs:label "accurate distance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-acosta_a rdfs:label "Acosta, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-adam_a_method_for_stochastic_optimization rdfs:label "Adam: A method for stochastic optimization"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-advancement rdfs:label "advancement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-adversarial_learning rdfs:label "adversarial learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-agaian_s rdfs:label "Agaian, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-agnostic_model rdfs:label "agnostic model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-ahmed_f rdfs:label "Ahmed, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-air rdfs:label "air"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-aitken_a rdfs:label "Aitken, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-akkaynak__treibitz rdfs:label "Akkaynak & Treibitz"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-akkaynak_d rdfs:label "Akkaynak, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-aleotti_j rdfs:label "Aleotti, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-all-in-one_underwater_image_enhancement_using_domain-adversarial_learning rdfs:label "All-in-one underwater image enhancement using domain-adversarial learning"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-all_the_results rdfs:label "all the results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-alternatives rdfs:label "alternatives"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ambient_forwardlooking rdfs:label "ambient_forwardlooking"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-an_underwater_color_image_quality_evaluation_metric rdfs:label "An underwater color image quality evaluation metric"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-an_underwater_image_enhancement_dataset rdfs:label "An underwater image enhancement dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-an_underwater_image_enhancement_dataset_and_beyond rdfs:label "An underwater image enhancement dataset and beyond"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-an_underwater_stereo_vision_system rdfs:label "An underwater stereo vision system"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-an_underwater_stereo_vision_system_from_design_to_deployment_and_dataset_acquisition rdfs:label "An underwater stereo vision system: from design to deployment and dataset acquisition"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-an_unspecified_concept rdfs:label "an unspecified concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-analysis rdfs:label "analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ancuti_co rdfs:label "Ancuti, C.O."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-anwar rdfs:label "Anwar"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-anwar_et_al rdfs:label "Anwar et al."@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-applications_in_practical_scenarios rdfs:label "applications in practical scenarios"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-architectural_differences rdfs:label "architectural differences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arjovsky_m rdfs:label "Arjovsky, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-artifacts rdfs:label "artifacts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-artificial_datasets rdfs:label "artificial datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-artificial_neural_networks rdfs:label "Artificial Neural Networks"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-artificially_produced_datasets rdfs:label "artificially produced datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-arxiv rdfs:label "arXiv"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-arxiv151106434 rdfs:label "arXiv:1511.06434"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv180703528 rdfs:label "arXiv:1807.03528"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv181101343 rdfs:label "arXiv:1811.01343"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv190513342 rdfs:label "arXiv:1905.13342"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv9 rdfs:label "arxiv9"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-arxiv_e-prints rdfs:label "arXiv e-prints"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-arxiv_preprint_arxiv151106434 rdfs:label "arXiv preprint arXiv:1511.06434"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv180104011 rdfs:label "arXiv preprint arXiv:1801.04011"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv180205957 rdfs:label "arXiv preprint arXiv:1802.05957"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv180700734 rdfs:label "arXiv preprint arXiv:1807.00734"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190105495 rdfs:label "arXiv preprint arXiv:1901.05495"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190612021 rdfs:label "arXiv preprint arXiv:1906.12021"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-ask_me_anything_free-form_visual_question_answering_based_on_knowledge_from_external_sources rdfs:label "Ask me anything: Free-form visual question answering based on knowledge from external sources"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-aspects_of_the_current_networks rdfs:label "aspects of the current networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-atmosphere rdfs:label "atmosphere"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-atmospheric_attenuation_coefficient rdfs:label "atmospheric attenuation coefficient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attenuation_coefficient rdfs:label "attenuation coefficient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-aucuti_c rdfs:label "Aucuti, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-australia rdfs:label "Australia"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-australian_national_university rdfs:label "Australian National University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-automatic_evaluation_metrics rdfs:label "automatic evaluation metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-automatic_evaluations rdfs:label "automatic evaluations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-auvs rdfs:label "AUVs"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-available_images rdfs:label "available images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-avidan_s rdfs:label "Avidan, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-b%CE%BB rdfs:label "Bλ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b3do rdfs:label "B3DO"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-b_%CE%BB rdfs:label "B∞ λ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b_lambda rdfs:label "B_lambda"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ba_j rdfs:label "Ba, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-background rdfs:label "background"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-background_light_and_scene_depth rdfs:label "background light and scene depth"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-background_light_network rdfs:label "background light network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backscatter_images rdfs:label "backscatter images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backscattered_light rdfs:label "backscattered light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backward_network rdfs:label "backward network"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-badrinarayanan_v rdfs:label "Badrinarayanan, V."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-barnes_n rdfs:label "Barnes, N."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-barron_jt rdfs:label "Barron, J.T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-basic_building_block rdfs:label "basic building block"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch-mode_learning_method rdfs:label "batch-mode learning method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-batch_normalization_accelerating_deep_network_training_by_reducing_internal_covariate_shift rdfs:label "Batch normalization: Accelerating deep network training by reducing internal covariate shift"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-batch_size rdfs:label "batch size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_size_of_16 rdfs:label "batch size of 16"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-beitrage_zur_physik_der_freien_atmosphare rdfs:label "Beitrage zur Physik der freien Atmosphare"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-bekaert_p rdfs:label "Bekaert, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-benchmark_dataset rdfs:label "benchmark dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-benchmark_results rdfs:label "benchmark results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-berman_d rdfs:label "Berman, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-best_among_the_competitors rdfs:label "best among the competitors"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-best_outcomes rdfs:label "best outcomes"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-bias rdfs:label "bias"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-big_data rdfs:label "Big Data"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-block-based_designs rdfs:label "block-based designs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-block_or_module rdfs:label "block or module"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blocks_architecture rdfs:label "block's architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blue_and_green_ones rdfs:label "blue and green ones"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bluish_images rdfs:label "bluish images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blurry_details rdfs:label "blurry details"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-bo_l rdfs:label "Bo, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-boom_bj rdfs:label "Boom, B.J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-both_the_datasets rdfs:label "both the datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-bottom_image rdfs:label "bottom image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bottou_l rdfs:label "Bottou, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-branches rdfs:label "branches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-brox_t rdfs:label "Brox, T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bryson_m rdfs:label "Bryson, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-c1__%CF%83c__c2__conl__c3__%C2%B5s rdfs:label "C1 × σc + C2 × conl + C3 × µs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c1uicmc2uismc3uiconm rdfs:label "c1×UICM+c2×UISM+c3×UIConM"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-caballero_j rdfs:label "Caballero, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-caffe rdfs:label "Caffe"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-camera_relocalization_in_rgb-d_images rdfs:label "camera relocalization in rgb-d images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-canberra_act_2600 rdfs:label "Canberra ACT 2600"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cao_et_al rdfs:label "Cao et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-cao_k rdfs:label "Cao, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-cao_y rdfs:label "Cao, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-captured_underwater_image rdfs:label "captured underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-caselli_s rdfs:label "Caselli, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-cc-net_and_hr-net rdfs:label "CC-Net and HR-Net"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-challenging_data rdfs:label "challenging data"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-challenging_images rdfs:label "challenging images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-channels rdfs:label "channels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-characteristics rdfs:label "characteristics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-chen_y rdfs:label "Chen, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-chiang_j rdfs:label "Chiang, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-chintala_s rdfs:label "Chintala, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-chou_hm rdfs:label "Chou, H.M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chroma rdfs:label "chroma"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-chroma_contrast_and_saturation_of_cielab rdfs:label "chroma, contrast, and saturation of CIELab"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cid rdfs:label "CID"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cipolla_r rdfs:label "Cipolla, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-classical_methods rdfs:label "classical methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classification rdfs:label "classification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-clear_images rdfs:label "clear images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-clear_latent_image rdfs:label "clear latent image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-clear_physical_meaning rdfs:label "clear physical meaning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-clearest rdfs:label "clearest"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-cnn-based_algorithms rdfs:label "CNN-based algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-cnn_algorithms rdfs:label "CNN algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-cnn_models rdfs:label "CNN models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-cnn_underwater_image_enhancement_model rdfs:label "CNN underwater image enhancement model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-coarse_subnet rdfs:label "coarse subnet"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coastal_water_types rdfs:label "coastal water types"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coefficient rdfs:label "coefficient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coefficient_associated_with_the_direct_signal rdfs:label "coefficient associated with the direct signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coefficient_of_backscatter rdfs:label "coefficient of backscatter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-color-correction_subnet rdfs:label "color-correction subnet"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-color_corrected_image rdfs:label "color corrected image"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-color_corrected_underwater_image rdfs:label "color corrected underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-color_correction rdfs:label "color correction"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-color_deviations rdfs:label "color deviations"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-color_restoration rdfs:label "color restoration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-company rdfs:label "Company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-complexity rdfs:label "complexity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-comprehensive_literature_survey rdfs:label "comprehensive literature survey"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-computed_ones rdfs:label "computed ones"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computer_science rdfs:label "Computer Science"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-computer_vision_and_image_processing_tasks rdfs:label "computer vision and image processing tasks"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-conditional_adversarial_networks rdfs:label "conditional adversarial networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cong_r rdfs:label "Cong, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-conl rdfs:label "conl"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-consistent_filter_size_of_55 rdfs:label "consistent filter size of 5×5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constructed_dataset rdfs:label "constructed dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-consumer_depth_cameras rdfs:label "Consumer depth cameras"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-content_and_structure_of_source_images rdfs:label "content and structure of source images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-contrast_change rdfs:label "contrast change"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-contrast_degradation rdfs:label "contrast degradation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-contrast_measure_uiconm rdfs:label "contrast measure (UIConM)"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-contrasts_cx_y rdfs:label "contrasts c(x, y)"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-conv_layer rdfs:label "Conv layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolutional rdfs:label "convolutional"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolutional_batch_normalization_bn_leaky_relu_lrelu_sequence rdfs:label "convolutional, batch normalization (BN), leaky ReLU (LReLU) sequence"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-convolutional_network_for_biomedical_image_segmentation rdfs:label "Convolutional network for biomedical image segmentation"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-convolutional_neural_networks_cnns rdfs:label "convolutional neural networks (CNNs)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coral_reef_system rdfs:label "coral reef system"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cosman_pc rdfs:label "Cosman, P.C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-courville_ac rdfs:label "Courville, A.C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-criminisi_a rdfs:label "Criminisi, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-cropped_patch_of_6666 rdfs:label "cropped patch of 66×66"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-crowdsourced rdfs:label "crowdsourced"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-csiro rdfs:label "CSIRO"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-cunningham_a rdfs:label "Cunningham, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-current_metrics rdfs:label "current metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-current_models rdfs:label "current models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_networks rdfs:label "current networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_techniques rdfs:label "current techniques"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-cycle-consistent_loss rdfs:label "cycle-consistent loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cyclegan_network rdfs:label "CycleGAN network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-d rdfs:label "D"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dark_background rdfs:label "dark background"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-darrell_t rdfs:label "Darrell, T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-data-driven_technique rdfs:label "data-driven technique"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-data61 rdfs:label "Data61"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-dataset_acquisition rdfs:label "dataset acquisition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dataset_of_images rdfs:label "dataset of images"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-deblurring rdfs:label "deblurring"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-decoder rdfs:label "decoder"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-decoder_portion rdfs:label "decoder portion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deconvolution_layer rdfs:label "deconvolution layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deconvolutional_layer rdfs:label "deconvolutional layer"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-deep_cnn_method_for_enhancement_of_underwater_images rdfs:label "deep CNN method for enhancement of underwater images"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_convolutional_encoder-decoder_architecture_for_image_segmentation rdfs:label "deep convolutional encoder-decoder architecture for image segmentation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_convolutional_generative_adversarial_network rdfs:label "Deep Convolutional Generative Adversarial Network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning-based_underwater_image_enhancement_methods rdfs:label "deep learning-based underwater image enhancement methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_learning_method rdfs:label "deep learning method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_network_for_underwater_image_restoration rdfs:label "deep network for underwater image restoration"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-deep_pixel_to_pixel_network_for_underwater_image_enhancement_and_restoration rdfs:label "Deep pixel to pixel network for underwater image enhancement and restoration"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-deep_residual_learning rdfs:label "Deep residual learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_residual_learning_for_image_recognition rdfs:label "Deep residual learning for image recognition"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-deep_underwater_image_enhancement_networks rdfs:label "deep underwater image enhancement networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_underwater_image_restoration_and_enhancement_algorithms rdfs:label "deep underwater image restoration and enhancement algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-degradation rdfs:label "degradation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degradation_model rdfs:label "degradation model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degradation_of_the_underwater_image rdfs:label "degradation of the underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degrading_effect rdfs:label "degrading effect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dehazing rdfs:label "dehazing"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-deng_j rdfs:label "Deng, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dense_connections rdfs:label "dense connections"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-densegan1 rdfs:label "DenseGAN1"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-densegan_generator rdfs:label "DenseGAN generator"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-densely_residual_laplacian_superresolution rdfs:label "Densely residual laplacian superresolution"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-department_of_computer_science_city_university_of_hong_kong rdfs:label "Department of Computer Science, City University of Hong Kong"@en ;
    askg-onto:entityType "Institution"@en .

askg-data:Entity-depth rdfs:label "depth"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth-guided_networks rdfs:label "depth-guided networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_estimation_and_color_correction_networks rdfs:label "depth estimation and color correction networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_information rdfs:label "depth information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_map_prediction_from_a_single_image_using_a_multi-scale_deep_network rdfs:label "Depth map prediction from a single image using a multi-scale deep network"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-depth_map_super-resolution rdfs:label "depth map super-resolution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_of_network rdfs:label "depth of network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-designs rdfs:label "designs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-details rdfs:label "details"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-developing_more_robust_and_effective_deep_algorithms rdfs:label "developing more robust and effective deep algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dick_a rdfs:label "Dick, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-difference_residual_between_the_degraded_underwater_image_and_its_clean_counterpart rdfs:label "difference (residual) between the degraded underwater image and its clean counterpart"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different rdfs:label "different"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_aspects rdfs:label "different aspects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_branches rdfs:label "different branches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_categories rdfs:label "different categories"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_competitions rdfs:label "different competitions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_dilations rdfs:label "different dilations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_size_of_sliding_windows rdfs:label "different size of sliding windows"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-digital_display rdfs:label "digital display"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-direct_light rdfs:label "direct light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-discriminator_d rdfs:label "discriminator D"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-discriminator_network rdfs:label "discriminator network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-distance_from_the_scene_to_the_camera rdfs:label "distance from the scene to the camera"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distinct_individuals rdfs:label "distinct individuals"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-distinct_inputs_at_separate_branches rdfs:label "distinct inputs at separate branches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distorted_and_original_signal rdfs:label "distorted and original signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distribution rdfs:label "distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distribution_of_generated_images rdfs:label "distribution of generated images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-diverse_datasets rdfs:label "diverse datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-diverse_physical_mathematical_models rdfs:label "diverse physical (mathematical) models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-diverse_scenemain_object_categories rdfs:label "diverse scene/main object categories"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-diverse_underwater_images rdfs:label "diverse underwater images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-document_recognition rdfs:label "document recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dong_j rdfs:label "Dong, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-dong_w rdfs:label "Dong, W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dumoulin_v rdfs:label "Dumoulin, V."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-e rdfs:label "E"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e%CE%BBx_0 rdfs:label "Eλ(x, 0)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e%CE%BBx_dx rdfs:label "Eλ*x, d*(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e_%0Alambdax0 rdfs:label """E_{
\\lambda}(x,0)"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e_%0Alambdaxdx rdfs:label """E_{
\\lambda}(x,d(x))"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e_s%CE%BB_b_%CE%B2 rdfs:label "{E, Sλ, b, β}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_network_element rdfs:label "each network element"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-earlier_defined_evaluation_metrics rdfs:label "earlier defined evaluation metrics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-earth-mover_or_wasserstein-1_distance rdfs:label "Earth-Mover or Wasserstein-1 distance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ecology_and_evolution rdfs:label "Ecology and evolution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-efros_a rdfs:label "Efros, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-efros_aa rdfs:label "Efros, A.A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-eigen_d rdfs:label "Eigen, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-eigen_et_al rdfs:label "Eigen et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-emerging_from_water_underwater_image_color_correction_based_on_weakly_supervised_color_transfer rdfs:label "Emerging from water: Underwater image color correction based on weakly supervised color transfer"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-encoder-decoder_network rdfs:label "encoder-decoder network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-encoder-decoder_structure rdfs:label "encoder-decoder structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-encoder-decoder_unet rdfs:label "encoder-decoder UNET"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-end-to-end_model rdfs:label "end-to-end model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-energy_of_light rdfs:label "energy of light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eng rdfs:label "Eng."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-engineering_and_research rdfs:label "engineering and research"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-enhanced_images rdfs:label "enhanced images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-enhanced_results rdfs:label "enhanced results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-enhanced_underwater_image rdfs:label "enhanced underwater image"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-enhancement rdfs:label "enhancement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-enhancing_underwater_imagery_using_generative_adversarial_networks rdfs:label "Enhancing underwater imagery using generative adversarial networks"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-enhancing_underwater_images_and_videos_by_fusion rdfs:label "Enhancing underwater images and videos by fusion"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-error_measurement rdfs:label "error measurement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-error_signal rdfs:label "error signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-essential_aspects rdfs:label "essential aspects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimations rdfs:label "estimations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-euclidean rdfs:label "Euclidean"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-european_union_seventh_framework_program rdfs:label "European Union Seventh Framework program"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-eustice_rm rdfs:label "Eustice, R.M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-evaluation_and_training rdfs:label "evaluation and training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-event rdfs:label "Event"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-excellent_metrics_in_optimization rdfs:label "excellent metrics in optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-existing_issues rdfs:label "existing issues"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-existing_network_architectures rdfs:label "existing network architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-exp%CE%B2dx rdfs:label "exp(−βd(x))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-exp-%CE%B2_dx rdfs:label "exp(-β d(x))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiments rdfs:label "experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-experts rdfs:label "experts"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fabbri_c rdfs:label "Fabbri, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-failure_cases rdfs:label "failure cases"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-fair_comparison rdfs:label "fair comparison"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-faithful_to_the_original_underwater_image rdfs:label "faithful to the original underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-false_colors rdfs:label "false colors"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-fan_x rdfs:label "Fan, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-far_distances rdfs:label "far distances"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fast_attenuation_of_red_wavelength rdfs:label "fast attenuation of red wavelength"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feature_transformation_units_ftus rdfs:label "feature transformation units (FTUs)"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-features_of_the_underwater_types rdfs:label "features of the underwater types"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-few-shot_learning rdfs:label "few-shot learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-field_of_study rdfs:label "field of study"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_4 rdfs:label "Figure 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_5 rdfs:label "Figure 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-filter_numbers rdfs:label "filter numbers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-filter_sizes_of_11_33_55_and_77 rdfs:label "filter sizes of 1×1, 3×3, 5×5 and 7×7"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-filters rdfs:label "filters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_convolutional_layer rdfs:label "final convolutional layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_loss_computation rdfs:label "final loss computation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_references rdfs:label "final references"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finding rdfs:label "Finding"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-first_two_convolutional_layers rdfs:label "first two convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_two_layers_of_the_generator rdfs:label "first two layers of the generator"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fischer_p rdfs:label "Fischer, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-fish4knowledge rdfs:label "Fish4Knowledge"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-fisher_rb rdfs:label "Fisher, R.B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fitzgibbon_a rdfs:label "Fitzgibbon, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-five_layers rdfs:label "five layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-five_layers_of_spectral_normalization rdfs:label "five layers of spectral normalization"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-fixed_learning_rate_of_00002 rdfs:label "fixed learning rate of 0.0002"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fixed_learning_rate_of_106 rdfs:label "fixed learning rate of 10−6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-follows rdfs:label "follows"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formulation rdfs:label "Formulation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-forward_network rdfs:label "forward network"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-four_metrics rdfs:label "four metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-fox_d rdfs:label "Fox, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-framework rdfs:label "Framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-friedman_a rdfs:label "Friedman, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-fritz_m rdfs:label "Fritz, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-full-reference_image_quality_assessment rdfs:label "full-reference image quality assessment"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-full-size_images rdfs:label "full-size images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fully_connected_layers rdfs:label "fully connected layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fully_connected_ones rdfs:label "fully connected ones"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fully_convolutional rdfs:label "fully convolutional"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-functions rdfs:label "functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fundamental_block_structure rdfs:label "fundamental block structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fusion_generative_adversarial_network rdfs:label "Fusion generative adversarial network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-future rdfs:label "future"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_directions rdfs:label "future directions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_research rdfs:label "future research"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-future_research_areas rdfs:label "future research areas"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-future_study rdfs:label "future study"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g rdfs:label "g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gamma_correction rdfs:label "Gamma Correction"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-gan-based_models rdfs:label "GAN-based models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-gan-based_networks rdfs:label "GAN-based networks"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-gan_loss rdfs:label "GAN loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gao_c rdfs:label "Gao, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-gated_fusion_cnn rdfs:label "gated fusion CNN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-general_idea rdfs:label "general idea"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalization rdfs:label "generalization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalization_capability rdfs:label "generalization capability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalization_of_models rdfs:label "generalization of models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generative_adversarial_nets rdfs:label "Generative adversarial nets"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-generative_adversarial_networks_gans rdfs:label "generative adversarial networks (GANs)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generator_g rdfs:label "generator G"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-generator_network rdfs:label "generator network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-generators rdfs:label "generators"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-girshick_r rdfs:label "Girshick, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-global_atmospheric_light rdfs:label "global atmospheric light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-global_skip_connection rdfs:label "global skip connection"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-global_statistics rdfs:label "global statistics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-glocker_b rdfs:label "Glocker, B."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-good_results rdfs:label "good results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-goodfellow_i rdfs:label "Goodfellow, I."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-google rdfs:label "Google"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-gpt-3 rdfs:label "GPT-3"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-gradient-based_learning_applied_to_document_recognition rdfs:label "Gradient-based learning applied to document recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-gradients_norms rdfs:label "gradients norms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-greenish_tone rdfs:label "greenish tone"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-greenish_underwater_images rdfs:label "greenish underwater images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-greenish_underwater_samples rdfs:label "greenish underwater samples"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-ground-truth_image rdfs:label "ground-truth image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ground_truth_images rdfs:label "ground truth images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-groundtruth_images rdfs:label "groundtruth images"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-gu_s rdfs:label "Gu, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-guided_filter rdfs:label "guided filter"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-gulrajani_i rdfs:label "Gulrajani, I."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-guo_et_al rdfs:label "Guo et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-guo_y rdfs:label "Guo, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-haffner_p rdfs:label "Haffner, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-haze rdfs:label "haze"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-haze-free_latent_image rdfs:label "haze-free latent image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-haze-line_images rdfs:label "Haze-line images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-haze_detection_network rdfs:label "haze detection network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-haze_removal rdfs:label "haze removal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-haze_removal_network rdfs:label "haze removal network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hazeline rdfs:label "Hazeline"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-hazy_image_formation rdfs:label "hazy image formation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-he_j rdfs:label "He, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hierarchical_features_driven_residual_learning rdfs:label "Hierarchical features driven residual learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high-level_vision_tasks rdfs:label "high-level vision tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high_frequencies_loss rdfs:label "high frequencies' loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-higher_psnr rdfs:label "higher PSNR"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-hinton_g rdfs:label "Hinton, G."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hinton_ge rdfs:label "Hinton, G.E."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-histogram_equalization rdfs:label "Histogram Equalization"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-histogram_equalizationbased_methods rdfs:label "histogram equalizationbased methods"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-hoiem_d rdfs:label "Hoiem, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-homogeneous_global_background_light rdfs:label "homogeneous global background light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hou_et_al rdfs:label "Hou et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hou_j rdfs:label "Hou, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hou_m rdfs:label "Hou, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hour rdfs:label "hour"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-httpgroupsinfedacukf4kindexhtml rdfs:label "http://groups.inf.ed.ac.uk/f4k/index.html"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-httpsgithubcomkskindata rdfs:label "https://github.com/kskin/data"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-huang_px rdfs:label "Huang, P.X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-human-visual-systeminspired_underwater_image_quality_measures rdfs:label "Human-visual-systeminspired underwater image quality measures"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-human_inputs rdfs:label "human inputs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-human_perception_of_image_quality rdfs:label "human perception of image quality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-human_subjects rdfs:label "human subjects"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-human_visual_evaluation rdfs:label "human visual evaluation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-human_visual_perception rdfs:label "human visual perception"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-human_visual_system_hvs rdfs:label "human visual system (HVS)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-huszar_f rdfs:label "Huszar, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hvs_model rdfs:label "HVS model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-i_%CE%BBxe%CE%B2_%CE%BBdv rdfs:label "I_λ(x)e^{−β_λ^D(v)}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-i_lambda rdfs:label "I_lambda"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-i_lambda_and_t_lambda rdfs:label "I_lambda and T_lambda"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iccv rdfs:label "ICCV"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-icip rdfs:label "ICIP"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-icml rdfs:label "ICML"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition rdfs:label "IEEE Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-ieee_j rdfs:label "IEEE J."@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-ieee_journal_of_oceanic_engineering rdfs:label "IEEE Journal of Oceanic Engineering"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-ieee_robotics_and_automation_letters rdfs:label "IEEE Robotics and Automation Letters"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-ieee_signal_processing_magazine rdfs:label "IEEE signal processing magazine"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-ieee_transactions_on_image_processing rdfs:label "IEEE Transactions on Image Processing"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-iet_image_processing rdfs:label "IET Image Processing"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-image-to-image_translation_with_conditional_adversarial_networks rdfs:label "Image-to-image translation with conditional adversarial networks"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-image_collection rdfs:label "image collection"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_colorfulness_measure_uicm rdfs:label "image colorfulness measure (UICM)"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-image_denoising rdfs:label "image denoising"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-image_enhancement_and_restoration_problems rdfs:label "image enhancement and restoration problems"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-image_enhancement_methods rdfs:label "image enhancement methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-image_fidelity rdfs:label "image fidelity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_pixel_intensities rdfs:label "image pixel intensities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_processing rdfs:label "image processing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_quality_assessment rdfs:label "image quality assessment"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_quality_assessment_from_error_visibility_to_structural_similarity rdfs:label "Image quality assessment: from error visibility to structural similarity"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-image_quality_of_enhanced_results rdfs:label "image quality of enhanced results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-image_restoration_task rdfs:label "image restoration task"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_restoration_using_very_deep_convolutional_encoder-decoder_networks_with_symmetric_skip_connections rdfs:label "Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-image_super-resolution rdfs:label "image super-resolution"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-images_in_the_uiebd rdfs:label "images in the UIEBD"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-imaging_models rdfs:label "imaging models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-imaging_sensor rdfs:label "imaging sensor"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-importance rdfs:label "importance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improve_the_perceptual_quality_of_the_images rdfs:label "improve the perceptual quality of the images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improved_image rdfs:label "improved image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improved_training_of_wasserstein_gans rdfs:label "Improved training of wasserstein gans"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-improvement rdfs:label "improvement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inauthentic_results rdfs:label "inauthentic results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-inconvenient_to_utilize rdfs:label "inconvenient to utilize"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-increasing_visibility_in_the_underwater_scene rdfs:label "increasing visibility in the underwater scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-indoor_segmentation_and_support_inference_from_rgbd_images rdfs:label "Indoor segmentation and support inference from rgbd images"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-information_retrieval rdfs:label "information retrieval"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_layer rdfs:label "initial layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_three_layers rdfs:label "initial three layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-innovation rdfs:label "Innovation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_features rdfs:label "input features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_images_of_512__512_resolution rdfs:label "input images of 512 × 512 resolution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_patch_size rdfs:label "input patch size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_resolution_of_128__128 rdfs:label "input resolution of 128 × 128"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-internal_flash rdfs:label "internal flash"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-international_community rdfs:label "international community"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-international_conference_on_medical_image_computing_and_computer-assisted_intervention rdfs:label "International Conference on Medical image computing and computer-assisted intervention"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ioffe_s rdfs:label "Ioffe, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-islam_mj rdfs:label "Islam, M.J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-isola_p rdfs:label "Isola, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-issues rdfs:label "issues"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-izadi_s rdfs:label "Izadi, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-janoch_a rdfs:label "Janoch, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-ji_x rdfs:label "Ji, X."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-jia_y rdfs:label "Jia, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-joint_residual_learning rdfs:label "Joint residual learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jolicoeur-martineau_a rdfs:label "Jolicoeur-Martineau, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-journal rdfs:label "Journal"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-k-means_clustering rdfs:label "K-Means Clustering"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-kallasi_f rdfs:label "Kallasi, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-karayev_s rdfs:label "Karayev, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kataoka_t rdfs:label "Kataoka, T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kendall_a rdfs:label "Kendall, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kernel_sizes rdfs:label "kernel sizes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kernel_sizes_and_filter_numbers rdfs:label "kernel sizes and filter numbers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kernels rdfs:label "kernels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-key_components rdfs:label "key components"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kinect rdfs:label "kinect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kinect_dataset rdfs:label "Kinect dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kinect_datasets rdfs:label "Kinect datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kingma_dp rdfs:label "Kingma, D.P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-knowledge_from_external_sources rdfs:label "knowledge from external sources"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kohli_p rdfs:label "Kohli, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-koschmieder_h rdfs:label "Koschmieder, H."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-koyama_m rdfs:label "Koyama, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kwong_s rdfs:label "Kwong, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-l rdfs:label "L"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lack_of_purposely_built_evaluation_metrics rdfs:label "lack of purposely built evaluation metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-lai_k rdfs:label "Lai, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-large-scale_hierarchical_image_database rdfs:label "large-scale hierarchical image database"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-large_training_dataset rdfs:label "large training dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-last_two_layers rdfs:label "last two layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-latent_clear_underwater_image rdfs:label "latent clear underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-latest_development_and_comparison rdfs:label "latest development and comparison"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layer rdfs:label "layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-layers rdfs:label "layers"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-learn_different_features_of_the_same_input_at_different_levels rdfs:label "learn different features of the same input at different levels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_deep_cnn_denoiser_prior_for_image_restoration rdfs:label "Learning deep cnn denoiser prior for image restoration"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-learning_method rdfs:label "learning method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-learning_rate_106 rdfs:label "learning rate 10−6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ledig_c rdfs:label "Ledig, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-less_than_45_layers rdfs:label "less than 45 layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-levy_d rdfs:label "Levy, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-li rdfs:label "Li"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-li_h rdfs:label "Li, H."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-li_k rdfs:label "Li, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-li_lj rdfs:label "Li, L.J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-li_q rdfs:label "Li, Q."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-light rdfs:label "light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-light_field_camera rdfs:label "light field camera"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-light_network rdfs:label "light network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-light_network_and_transmission_map_network rdfs:label "light network and transmission map network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-light_selective_absorption_and_scattering_in_water rdfs:label "light selective absorption and scattering in water"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lima_e rdfs:label "Lima, E."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-limitations_of_synthetic_underwater_image_datasets rdfs:label "limitations of synthetic underwater image datasets"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-limited_datasets rdfs:label "limited datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-limited_quality_degradation_types rdfs:label "limited quality degradation types"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lin_fp rdfs:label "Lin, F.P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lin_w rdfs:label "Lin, W."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-linear_combination rdfs:label "linear combination"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lipschitz rdfs:label "Lipschitz"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-list rdfs:label "list"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-liu_l rdfs:label "Liu, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-liu_r rdfs:label "Liu, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-local_ssim rdfs:label "local SSIM"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-local_structures_sx_y rdfs:label "local structures s(*x, y*)"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-long_way_to_go rdfs:label "long way to go"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-longer_wavelength_than_blue_and_green_ones rdfs:label "longer wavelength than blue and green ones"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_functions rdfs:label "loss functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_of_the_generator rdfs:label "loss of the generator"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-love_it_or_leave_it rdfs:label "Love it or leave it?"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-low-level_visual_tasks rdfs:label "low-level visual tasks"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-low_contrast_and_brightness rdfs:label "low contrast and brightness"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-low_medium_and_high-level_degradation rdfs:label "low, medium and high-level degradation"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-lu_et_al rdfs:label "Lu et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-lu_j_li_n_zhang_s_yu_z_zheng_h_zheng_b rdfs:label "Lu, J., Li, N., Zhang, S., Yu, Z., Zheng, H., Zheng, B."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-luminance rdfs:label "luminance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-luminance_lx_y rdfs:label "luminance l(*x, y*)"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-luo_z rdfs:label "Luo, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lxycdot_cxycdot_sxy rdfs:label "$l(x,y)\\cdot c(x,y)\\cdot s(x,y)$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-m rdfs:label "M"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ma_k rdfs:label "Ma, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-machine_learning_algorithm rdfs:label "Machine Learning algorithm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-madin_j rdfs:label "Madin, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-majority_voting rdfs:label "majority voting"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mao_x rdfs:label "Mao, X."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-maps rdfs:label "maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-marine_autonomous_robotics_for_interventions rdfs:label "Marine Autonomous Robotics for InterventionS"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-marine_ecosystems rdfs:label "marine ecosystems"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-matconvnet rdfs:label "MatConvNet"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-mathematical_expression rdfs:label "mathematical expression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathematical_measure rdfs:label "mathematical measure"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-mathematical_object rdfs:label "Mathematical Object"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathematically_defined_measures rdfs:label "mathematically defined measures"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-max-pooling_index_information rdfs:label "max-pooling index information"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-mcycle-gan rdfs:label "MCycle-GAN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-mean rdfs:label "mean"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean_intensity rdfs:label "mean intensity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean_square_error rdfs:label "Mean Square Error"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean_squared_error rdfs:label "Mean squared error"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean_squared_error_love_it_or_leave_it rdfs:label "Mean squared error: Love it or leave it?"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-measurement_systems rdfs:label "measurement systems"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-medium_attenuation_coefficient rdfs:label "medium attenuation coefficient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-method_for_quality_assessment rdfs:label "method for quality assessment"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-method_performance rdfs:label "method performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-metz_l rdfs:label "Metz, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-michigans_marine_hydrodynamics_laboratory rdfs:label "Michigan's Marine Hydrodynamics Laboratory"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-microsoft_7-scenes rdfs:label "Microsoft 7-scenes"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-milk_of_30_50_and_70_ml rdfs:label "milk of 30, 50, and 70 ml"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-milk_of_30_50_and_70_ml_into_1m3_of_water rdfs:label "milk of 30, 50, and 70 ml into 1m3 of water"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-minimal_work rdfs:label "minimal work"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-miyato_t rdfs:label "Miyato, T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-modern_image_quality_assessment rdfs:label "Modern image quality assessment"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-modular_designs rdfs:label "modular designs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-modular_or_block_designs rdfs:label "Modular or block designs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-monotonous_content rdfs:label "monotonous content"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-most_turbid rdfs:label "most turbid"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-msdb rdfs:label "MSDB"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-msdb_blocks rdfs:label "MSDB blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multi-scale_adversarial_network_for_underwater_image_restoration rdfs:label "Multi-scale adversarial network for underwater image restoration"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-multi-scale_cycle_generative_adversarial_network_mcyclegan rdfs:label "Multi-Scale Cycle Generative Adversarial Network (MCycleGAN)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-multi-scale_deep_network rdfs:label "Multi-scale deep network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multi-scale_fcnn rdfs:label "multi-scale FCNN"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multi-scale_network rdfs:label "multi-scale network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiple_branch_designs rdfs:label "multiple branch designs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiple_generators rdfs:label "multiple generators"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiple_variants rdfs:label "multiple variants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiscale_dense_block_msdb_algorithm rdfs:label "multiscale dense block (MSDB) algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-multiscale_dense_generative_adversarial_network rdfs:label "multiscale dense generative adversarial network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-multiscale_ssim_map rdfs:label "multiscale SSIM map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiscale_structural_similarity_for_image_quality_assessment rdfs:label "Multiscale structural similarity for image quality assessment"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-n rdfs:label "N"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n%CE%BB rdfs:label "Nλ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n_%0Alambdaigdxig rdfs:label """N_{
\\lambda}ig{(}d(x)ig{)}"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nair_v rdfs:label "Nair, V."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-naive rdfs:label "naive"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-natural_language_processing_model rdfs:label "natural language processing model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nature_2015_32 rdfs:label "Nature (2015) 32"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-need_of_the_hour rdfs:label "need of the hour"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_depth rdfs:label "Network Depth"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_models rdfs:label "network models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_specifics rdfs:label "network specifics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_network_classifier rdfs:label "neural network classifier"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-neural_networks rdfs:label "Neural Networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nine_resnet_blocks rdfs:label "nine ResNet blocks"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-nips_2016 rdfs:label "NIPS (2016)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-nlp rdfs:label "NLP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_in_underwater_images rdfs:label "noise in underwater images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_vector rdfs:label "noise vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-parametric_upsampling_layer rdfs:label "non-parametric upsampling layer"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-none rdfs:label "none"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-not_trivial rdfs:label "not trivial"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nui rdfs:label "nui"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number rdfs:label "number"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nyu rdfs:label "NYU"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-nyu_dataset rdfs:label "NYU dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-object_detection rdfs:label "object detection"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_recognition rdfs:label "object recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-objective_functions rdfs:label "objective functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-observed_image rdfs:label "observed image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-observed_underwater_image rdfs:label "observed underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-observing_conditions rdfs:label "observing conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-oceanic rdfs:label "Oceanic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oceans_resources rdfs:label "ocean's resources"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oleari_f rdfs:label "Oleari, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-one_channel rdfs:label "one channel"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-one_discriminator rdfs:label "one discriminator"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-one_generator rdfs:label "one generator"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-one_of_the_signals rdfs:label "one of the signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-open_ocean_water_types rdfs:label "open ocean water types"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-open_research_problem rdfs:label "open research problem"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-optical_properties_of_selective_attenuation_in_water rdfs:label "optical properties of selective attenuation in water"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optics__laser_technology rdfs:label "Optics & Laser Technology"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-optimization rdfs:label "optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-organization_of_deep_networks_based_on_essential_aspects rdfs:label "organization of deep networks based on essential aspects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-original rdfs:label "Original"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-original_800_pairs_of_training_data rdfs:label "original 800 pairs of training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-original_paper rdfs:label "original paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-original_signal rdfs:label "original signal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-original_underwater_image_colors rdfs:label "original underwater image colors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-other_metrics rdfs:label "other metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-others rdfs:label "others"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-output_transmission_map rdfs:label "output transmission map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-over-exposed_the_images rdfs:label "over-exposed the images"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-pacific_rim_conference_on_multimedia rdfs:label "Pacific Rim Conference on Multimedia"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-paired_underwater_images rdfs:label "paired underwater images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-palazzo_s rdfs:label "Palazzo, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-panetta_k rdfs:label "Panetta, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-parameters rdfs:label "parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-park_t rdfs:label "Park, T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-particles_in_the_water rdfs:label "particles in the water"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patch-based_approach rdfs:label "patch-based approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-patch-based_contrast_image_quality_index rdfs:label "patch-based contrast image quality index"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patch-based_contrast_quality_index rdfs:label "Patch-based contrast quality index"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patch_size rdfs:label "patch size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patch_x rdfs:label "patch x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patch_y rdfs:label "patch y"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patches rdfs:label "patches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-peak_signal_to_noise_ratio_psnr rdfs:label "peak signal to noise ratio (PSNR)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-peng_yt rdfs:label "Peng, Y.T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-per-pixel_error rdfs:label "per-pixel error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-percentage_of_the_scene_radiance_reaching_the_camera rdfs:label "percentage of the scene radiance reaching the camera"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-perceptual_quality rdfs:label "perceptual quality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-performance_of_high-level_vision_tasks rdfs:label "performance of high-level vision tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-photo-realistic_single_image_superresolution_using_a_generative_adversarial_network rdfs:label "Photo-realistic single image superresolution using a generative adversarial network"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-physical_model rdfs:label "physical model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pioneering_work_in_deep_learning_direction rdfs:label "pioneering work in deep learning direction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel-wise_dense_learning rdfs:label "pixel-wise dense learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel-wise_loss_functions rdfs:label "pixel-wise loss functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixelto-pixel_p2p_network rdfs:label "pixelto-pixel (P2P) network"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-pizarro_o rdfs:label "Pizarro, O."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-pooling_operation rdfs:label "pooling operation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-porikli_f rdfs:label "Porikli, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-possible_research_directions rdfs:label "possible research directions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-potential_reasons rdfs:label "potential reasons"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pre-trained_network rdfs:label "pre-trained network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-precomputed_real-time_texture_synthesis_with_markovian_generative_adversarial_networks rdfs:label "Precomputed real-time texture synthesis with markovian generative adversarial networks"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-predefined_size rdfs:label "predefined size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-predicted_image rdfs:label "predicted image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prior_or_domain_knowledge rdfs:label "prior or domain knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proceedings_of_the_ieee rdfs:label "Proceedings of the IEEE"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-process rdfs:label "process"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-processing_step rdfs:label "processing step"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proj_benchmark rdfs:label "proj_benchmark"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-promising_results rdfs:label "promising results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-psnr_values rdfs:label "PSNR values"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-public_test_dataset rdfs:label "Public Test Dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-puhrsch_c rdfs:label "Puhrsch, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-pure_water_and_hazy_conditions rdfs:label "pure water and hazy conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-q_ixy_%0A%09ext__q_cxy_%0A%09ext_and__q_sxy rdfs:label """q_{i}(x,y) 
	ext{, } q_{c}(x,y) 
	ext{, and } q_{s}(x,y)"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-qcx_y rdfs:label "qc(x, y)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-qix_y rdfs:label "qi(x, y)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-qix_y__qcx_y__qsx_y rdfs:label "qi(x, y) · qc(x, y) · qs(*x, y*)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-qsx_y rdfs:label "qs(x, y)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-qualitative_and_quantitative_comparison rdfs:label "qualitative and quantitative comparison"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quality rdfs:label "quality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quality_measure rdfs:label "Quality measure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quality_of_the_predicted_images rdfs:label "quality of the predicted images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quantitative_measures rdfs:label "quantitative measures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quantitative_results rdfs:label "Quantitative results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-quantitative_score rdfs:label "quantitative score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-r rdfs:label "r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r_g_and_b_channels rdfs:label "R, G, and B channels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-radford_a rdfs:label "Radford, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-random_forest rdfs:label "Random Forest"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-random_medium_attenuation_coefficient rdfs:label "random medium attenuation coefficient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-randomly rdfs:label "randomly"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-raw_input_image rdfs:label "raw input image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-raw_underwater_images_and_videos rdfs:label "raw underwater images and videos"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ray rdfs:label "ray"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-readers rdfs:label "readers"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-real-world_underwater_image_datasets rdfs:label "real-world underwater image datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-real-world_underwater_image_formation_model rdfs:label "real-world underwater image formation model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-real_and_fake_image_patches rdfs:label "real and fake image patches"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-real_image rdfs:label "real image"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-realistic_feedback rdfs:label "realistic feedback"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-reconstruction_layer rdfs:label "reconstruction layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recovered_style_image rdfs:label "recovered style image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rectified_linear_units rdfs:label "Rectified linear units"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rectified_linear_units_improve_restricted_boltzmann_machines rdfs:label "Rectified linear units improve restricted boltzmann machines"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-red_green_and_blue_channels rdfs:label "red, green, and blue channels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-red_wavelength rdfs:label "red wavelength"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rednet rdfs:label "REDNet"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-refine_subnet rdfs:label "refine subnet"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-refined_subnet rdfs:label "refined subnet"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relationship rdfs:label "relationship"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relativistic_gan_loss rdfs:label "relativistic GAN loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relativistic_loss rdfs:label "relativistic loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reliability rdfs:label "reliability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-remaining_ones rdfs:label "remaining ones"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-ren_w rdfs:label "Ren, W."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-repetition_of_the_same_structure rdfs:label "repetition of the same structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-report rdfs:label "report"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-repository rdfs:label "repository"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-representative_images rdfs:label "representative images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-research rdfs:label "research"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_directions rdfs:label "research directions"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_fellow rdfs:label "research fellow"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-restoration rdfs:label "restoration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-restoring_the_underwater_image rdfs:label "restoring the underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-restricted_boltzmann_machines rdfs:label "restricted boltzmann machines"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-result rdfs:label "Result"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-rgb-d_images rdfs:label "RGB-D images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rgb-d_nyu-v2_dataset rdfs:label "RGB-D NYU-v2 dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-rizzini_dl rdfs:label "Rizzini, D.L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-robustness rdfs:label "robustness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-robustness_and_effectiveness rdfs:label "robustness and effectiveness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ronneberger_o rdfs:label "Ronneberger, O."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-rumi rdfs:label "Rumi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-s rdfs:label "S."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s%CE%BB rdfs:label "Sλ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-saeedanwardata61csiroau rdfs:label "saeed.anwar@data61.csiro.au"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-saenko_k rdfs:label "Saenko, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-same rdfs:label "same"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-same_architecture rdfs:label "same architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sample_underwater_images rdfs:label "sample underwater images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-samples rdfs:label "samples"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sattar_j rdfs:label "Sattar, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-saturation rdfs:label "saturation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scale-invariant_minimum_square_error_mse rdfs:label "scale-invariant minimum square error (MSE)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scaleddown_version_of_underwater_scene_input rdfs:label "scaleddown version of underwater scene input"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scattering_effects rdfs:label "scattering effects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scattering_medium rdfs:label "scattering medium"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scene rdfs:label "scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scene_coordinate_regression_forests rdfs:label "Scene coordinate regression forests"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-scene_coordinate_regression_forests_for_camera_relocalization_in_rgb-d_images rdfs:label "Scene coordinate regression forests for camera relocalization in rgb-d images"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-scene_radiance rdfs:label "scene radiance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scientific_exploration rdfs:label "scientific exploration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scientist rdfs:label "Scientist"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-scope rdfs:label "scope"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-search-and-rescue_tasks rdfs:label "search-and-rescue tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_4 rdfs:label "Section 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_5 rdfs:label "Section 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_6 rdfs:label "Section 6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-segnet_a_deep_convolutional_encoder-decoder_architecture_for_image_segmentation rdfs:label "Segnet: A deep convolutional encoder-decoder architecture for image segmentation"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-selective_attenuation_of_different_wavelengths rdfs:label "selective attenuation of different wavelengths"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_deconvolutional-bn-lrelu rdfs:label "sequence Deconvolutional-BN-LReLU"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-sequences_of_convolutional-bn-lrelu rdfs:label "sequences of convolutional-BN-LReLU"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-seven_additional_versions rdfs:label "seven additional versions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-seven_convolutional_layers rdfs:label "seven convolutional layers"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-seven_deconvolutional_layers rdfs:label "seven deconvolutional layers"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-sgd rdfs:label "SGD"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-sharing_network rdfs:label "sharing network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sharpness_measure_uism rdfs:label "sharpness measure (UISM)"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-sheikh_hr rdfs:label "Sheikh, H.R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-shi_w rdfs:label "Shi, W."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-shore_industry rdfs:label "shore industry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shotton_j rdfs:label "Shotton, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-sigmoid rdfs:label "Sigmoid"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-sigmoid_activation rdfs:label "sigmoid activation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sigmoid_layer rdfs:label "sigmoid layer"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-signal_fidelity rdfs:label "signal fidelity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal_fidelity_measures rdfs:label "signal fidelity measures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal_measure rdfs:label "signal measure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signal_strength rdfs:label "signal strength"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-signs rdfs:label "signs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-silberman_n rdfs:label "Silberman, N."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-similarities rdfs:label "similarities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-similarity_or_distortion rdfs:label "similarity or distortion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simonyan_k rdfs:label "Simonyan, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-simple rdfs:label "simple"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simple_statistics rdfs:label "simple statistics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simple_to_calculate_and_computationally_inexpensive_normally rdfs:label "simple to calculate and computationally inexpensive normally"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simplified_underwater_image_formulation_model rdfs:label "simplified underwater image formulation model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simulated_scenes rdfs:label "simulated scenes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single_image_haze_removal rdfs:label "Single image haze removal"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-single_image_haze_removal_using_dark_channel_prior rdfs:label "Single image haze removal using dark channel prior"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-single_quantity rdfs:label "single quantity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-six_metrics rdfs:label "six metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-skipping_layers rdfs:label "skipping layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smoothing rdfs:label "smoothing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-socher_r rdfs:label "Socher, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-soft_constraint rdfs:label "soft constraint"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-source_code_or_executables rdfs:label "source code or executables"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-source_domain rdfs:label "source domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-sowmya_a rdfs:label "Sowmya, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-spampinato_c rdfs:label "Spampinato, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-specialist_persons rdfs:label "specialist persons"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-specialized_objective_functions rdfs:label "specialized objective functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spectral_normalization_for_generative_adversarial_networks rdfs:label "Spectral normalization for generative adversarial networks"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-ssiai rdfs:label "SSIAI"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-ssim_loss_functions rdfs:label "SSIM loss functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ssim_maps rdfs:label "SSIM maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stacked_conditional_generative_adversarial_networks rdfs:label "stacked conditional generative adversarial networks"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-stacked_generative_adversarial_networks rdfs:label "stacked generative adversarial networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-of-the-art_conventional_methods rdfs:label "state-of-the-art conventional methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-of-the-art_performance rdfs:label "state-of-the-art performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-statistical_analysis rdfs:label "Statistical Analysis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-statues rdfs:label "statues"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stereo rdfs:label "stereo"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stereo_images rdfs:label "stereo images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stereo_imaging rdfs:label "stereo imaging"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-stochastic_optimization rdfs:label "stochastic optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-strength_of_light rdfs:label "strength of light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-strobes rdfs:label "strobes"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-structural_distortion rdfs:label "structural distortion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structural_similarity_ssim_index rdfs:label "Structural SIMilarity (SSIM) index"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-style_transfer rdfs:label "style transfer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subjective_scores_of_image_quality rdfs:label "subjective scores of image quality"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-subnets rdfs:label "subnets"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subnetwork rdfs:label "subnetwork"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subsequent_layers rdfs:label "subsequent layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-such_networks rdfs:label "such networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-summation_of_the_three_products rdfs:label "summation of the three products"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-sun_et_al rdfs:label "Sun et al."@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-sun_j rdfs:label "Sun, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-sun_x rdfs:label "Sun, X."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-super-resolution rdfs:label "super-resolution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-support_vector_machine rdfs:label "Support Vector Machine"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-symmetric_encoder_and_decoder_network rdfs:label "symmetric encoder and decoder network"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-synthesis_lectures_on_image_video_and_multimedia_processing rdfs:label "Synthesis Lectures on Image, Video, and Multimedia Processing"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-synthesized_underwater_images rdfs:label "synthesized underwater images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-synthetic rdfs:label "synthetic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-synthetic_image rdfs:label "synthetic image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-synthetic_images rdfs:label "synthetic images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-synthetic_training_data rdfs:label "synthetic training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-synthetic_type-i_training_data rdfs:label "synthetic type-I training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-synthetic_underwater_image_datasets rdfs:label "synthetic underwater image datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-synthetically rdfs:label "synthetically"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-system rdfs:label "system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-szegedy_c rdfs:label "Szegedy, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-t_%0Alambdax rdfs:label """T_{
\\lambda}(x)"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t_lambda rdfs:label "T_lambda"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_2 rdfs:label "Table 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tanh rdfs:label "TanH"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-technique rdfs:label "technique"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-tejani_a rdfs:label "Tejani, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-ten_types_of_underwater_image_datasets rdfs:label "ten types of underwater image datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-tensorflow rdfs:label "TensorFlow"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-terms rdfs:label "terms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-test_images rdfs:label "test images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-testing_set rdfs:label "testing set"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_air rdfs:label "the air"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_amount_of_radiance rdfs:label "the amount of radiance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_backscattered_light rdfs:label "the backscattered light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_beam_attenuation_coefficient rdfs:label "the beam attenuation coefficient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_beam_scattering_coefficient rdfs:label "the beam scattering coefficient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_coefficient_dependencies rdfs:label "the coefficient dependencies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_direct_transmitted_light rdfs:label "the direct transmitted light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_discriminator rdfs:label "the discriminator"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-the_experimental_quantitative_and_qualitative_results rdfs:label "the experimental quantitative and qualitative results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-the_internet rdfs:label "the internet"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_irradiance rdfs:label "the irradiance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_medium_energy_ratio rdfs:label "the medium energy ratio"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_normalized_residual_energy rdfs:label "the normalized residual energy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_number_of_pixels rdfs:label "the number of pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_original rdfs:label "the original"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_other_generator rdfs:label "the other generator"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-the_pixels_at_i_th_location rdfs:label "the pixels at i th location"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_point_x rdfs:label "the point x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_prediction_of_one_generator rdfs:label "the prediction of one generator"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_range_along_los rdfs:label "the range along LOS"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_ratio_of_residual_energy_to_the_initial_energy_per_unit_of_distance rdfs:label "the ratio of residual energy to the initial energy per unit of distance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_reflectance rdfs:label "the reflectance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_relativistic_discriminator_a_key_element_missing_from_standard_gan rdfs:label "The relativistic discriminator: a key element missing from standard gan"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-the_same_network rdfs:label "the same network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_scene_point_x rdfs:label "the scene point x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_scene_radiance rdfs:label "the scene radiance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_scene_radiance_captured_by_the_camera rdfs:label "the scene radiance captured by the camera"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_sensor_spectral_response rdfs:label "the sensor spectral response"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_thirty-seventh_asilomar_conference_on_signals_systems__computers rdfs:label "The Thirty-Seventh Asilomar Conference on Signals, Systems & Computers"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-the_type_of_water rdfs:label "the type of water"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_underwater_scene rdfs:label "the underwater scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_use_of_artificial_light_in_deep_water rdfs:label "the use of artificial light in deep water"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_veiling_light rdfs:label "the veiling light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_wavelength_of_light rdfs:label "the wavelength of light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theis_l rdfs:label "Theis, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-theorie_der_horizontalen_sichtweite rdfs:label "Theorie der horizontalen sichtweite"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-this_direction rdfs:label "this direction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_model rdfs:label "this model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-this_paper rdfs:label "this paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-three_binary_filters rdfs:label "three binary filters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_channels rdfs:label "three channels"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-three_confidence_maps rdfs:label "three confidence maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_convolutional_layers rdfs:label "three convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_deconvolutional_layers rdfs:label "three deconvolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_densely_connected_building_blocks rdfs:label "three densely connected building blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_densely_connected_convolutional_layers rdfs:label "three densely connected convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_learned_confidence_maps rdfs:label "three learned confidence maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_losses rdfs:label "three losses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_stacked_multi-scale_convolutional_layers rdfs:label "three stacked multi-scale convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_subnetworks rdfs:label "three subnetworks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-thresholded rdfs:label "thresholded"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-to_prevent_the_learned_mappings_from_contradicting_each_other rdfs:label "to prevent the learned mappings from contradicting each other"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-top_image rdfs:label "top image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_and_testing rdfs:label "training and testing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_and_testing_the_algorithms rdfs:label "training and testing the algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_dataset rdfs:label "training dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_datasets rdfs:label "training datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_of_images rdfs:label "training of images"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-transformed_three_inputs rdfs:label "transformed three inputs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transmission_map_network rdfs:label "transmission map network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-transmission_map_network_tm-net rdfs:label "transmission map network (TM-Net)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triple_extraction rdfs:label "triple extraction"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-turbid_and_generated_images rdfs:label "turbid and generated images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-turbid_underwater_image rdfs:label "turbid underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two rdfs:label "two"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_convolutional_layers rdfs:label "two convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_discriminators rdfs:label "two discriminators"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-two_generators rdfs:label "two generators"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-two_metrics rdfs:label "two metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-two_signals rdfs:label "two signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_steps rdfs:label "two steps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_subnetworks rdfs:label "two subnetworks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-u-net rdfs:label "U-net"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-u-net_convolutional_networks_for_biomedical_image_segmentation rdfs:label "U-net: Convolutional networks for biomedical image segmentation"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-u_lambda rdfs:label "U_lambda"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uiebd_underwater_image_enhancement_benchmark_dataset rdfs:label "UIEBD: Underwater Image Enhancement Benchmark Dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-uiq rdfs:label "UIQ"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-underlying_network_architecture rdfs:label "underlying network architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-undersea_intervention rdfs:label "undersea intervention"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-understanding_the_process_of_underwater_image_degradation rdfs:label "understanding the process of underwater image degradation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater rdfs:label "underwater"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-underwater_and_their_reference_images rdfs:label "underwater and their reference images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_archaeology rdfs:label "underwater archaeology"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-underwater_camera_footage rdfs:label "underwater camera footage"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_color_correct rdfs:label "underwater color correct"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_color_image_quality_evaluation rdfs:label "Underwater color image quality evaluation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_datasets rdfs:label "underwater datasets"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_evaluation_metrics rdfs:label "underwater evaluation metrics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_generative_adversarial_network_ugan rdfs:label "Underwater Generative adversarial network (UGAN)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-underwater_image_degradation rdfs:label "underwater image degradation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_dehazing_with_a_light_field_camera rdfs:label "Underwater image dehazing with a light field camera"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-underwater_image_enhancement_algorithms rdfs:label "underwater image enhancement algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-underwater_image_enhancement_by_wavelength_compensation_and_dehazing rdfs:label "Underwater image enhancement by wavelength compensation and dehazing"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-underwater_image_enhancement_dataset rdfs:label "underwater image enhancement dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-underwater_image_enhancement_models rdfs:label "underwater image enhancement models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-underwater_image_enhancement_networks rdfs:label "underwater image enhancement networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_enhancement_system rdfs:label "underwater image enhancement system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-underwater_image_enhancement_tasks rdfs:label "underwater image enhancement tasks"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-underwater_image_enhancement_using_a_multiscale_dense_generative_adversarial_network rdfs:label "Underwater image enhancement using a multiscale dense generative adversarial network"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-underwater_image_enhancement_using_domain_adversarial_learning_uie-dal rdfs:label "Underwater Image Enhancement using Domain Adversarial Learning (UIE-DAL)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_formation_models rdfs:label "underwater image formation models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_properties rdfs:label "underwater image properties"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_quality rdfs:label "underwater image quality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_quality_measure rdfs:label "underwater image quality measure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_restoration_using_deep_networks rdfs:label "Underwater image restoration using deep networks"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-underwater_imagery rdfs:label "underwater imagery"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_images_to_be_regarded_in_unknown_locations rdfs:label "underwater images to be regarded in unknown locations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_light_field_image_dataset rdfs:label "Underwater Light Field Image Dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-underwater_light_field_images rdfs:label "underwater light field images"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-underwater_networks rdfs:label "underwater networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_physical_model_properties rdfs:label "underwater physical model properties"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-underwater_research_progress rdfs:label "underwater research progress"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-underwater_residual_convolutional_neural_network_ur-_cnn rdfs:label "Underwater residual convolutional neural network (UR- CNN)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_scenarios rdfs:label "underwater scenarios"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-underwater_single_image_color_restoration rdfs:label "Underwater single image color restoration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-underwater_single_image_color_restoration_using_hazelines_and_a_new_quantitative_dataset rdfs:label "Underwater single image color restoration using hazelines and a new quantitative dataset"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-underwater_stereo_vision_system5 rdfs:label "underwater stereo vision system5"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-underwater_style rdfs:label "underwater style"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_surveillance rdfs:label "underwater surveillance"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-underwater_type rdfs:label "underwater type"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_videos rdfs:label "underwater videos"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uneven_bright_speck rdfs:label "uneven bright speck"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-university rdfs:label "university"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unknown rdfs:label "unknown"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unpaired_image-to-image_translation_using_cycle-consistent_adversarial_networks rdfs:label "Unpaired image-to-image translation using cycle-consistent adversarial networks"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-unpaired_training_data rdfs:label "unpaired training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-unreliable_results rdfs:label "unreliable results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-unsolved_open_issues rdfs:label "unsolved open issues"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unspecified rdfs:label "unspecified"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unstable_results rdfs:label "unstable results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-unsupervised_feature_learning_for_3d_scene_labeling rdfs:label "Unsupervised feature learning for 3d scene labeling"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-unsupervised_generative_network rdfs:label "unsupervised generative network"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-unsupervised_representation_learning_with_deep_convolutional_generative_adversarial_networks rdfs:label "Unsupervised representation learning with deep convolutional generative adversarial networks"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-uplavikar_p rdfs:label "Uplavikar, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-upsampling rdfs:label "upsampling"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-upsampling_layer rdfs:label "upsampling layer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-user_observation rdfs:label "user observation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uw_rgb-d rdfs:label "UW RGB-D"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-uwcnn-type-i rdfs:label "UWCNN-type-I"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-uwcnn_models rdfs:label "UWCNN models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-uwcnn_type-1 rdfs:label "UWCNN type-1"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwcnn_type-3 rdfs:label "UWCNN type-3"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwcnn_type-5 rdfs:label "UWCNN type-5"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwcnn_type-7 rdfs:label "UWCNN type-7"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwcnn_type-9 rdfs:label "UWCNN type-9"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwcnn_type-i rdfs:label "UWCNN type-I"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwcnn_type-ii rdfs:label "UWCNN type-II"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwcnn_type-iii rdfs:label "UWCNN type-III"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uwe_dataset rdfs:label "UWE Dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-valid_distance_metrics rdfs:label "valid distance metrics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-valuable_information rdfs:label "valuable information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-van_den_hengel_a rdfs:label "van den Hengel, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-variance_of_chroma rdfs:label "variance of chroma"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variant rdfs:label "variant"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-varying_difficulty rdfs:label "varying difficulty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-veiling_light rdfs:label "veiling light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-very_deep_convolutional_networks_for_large-scale_image_recognition rdfs:label "Very deep convolutional networks for large-scale image recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-vgg19_network rdfs:label "VGG19 network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-video_and_fish_analysis_dataset rdfs:label "video and fish analysis dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-visual_comparisons rdfs:label "visual comparisons"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-visual_information rdfs:label "visual information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_perception rdfs:label "visual perception"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_question_answering rdfs:label "visual question answering"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visually_pleasing_results rdfs:label "visually pleasing results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-visually_promising_results rdfs:label "visually promising results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-volume_number rdfs:label "Volume Number"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w rdfs:label "W"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wand_m rdfs:label "Wand, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wang__bovik rdfs:label "Wang & Bovik"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wang_et_al rdfs:label "Wang et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wang_p rdfs:label "Wang, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wang_s rdfs:label "Wang, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wang_w rdfs:label "Wang, W."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wang_y rdfs:label "Wang, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wasserstein_gan_with_gradient_penalty rdfs:label "Wasserstein GAN with gradient penalty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wasserstein_loss rdfs:label "Wasserstein loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-water_type rdfs:label "water type"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-watergan_unsupervised_generative_network_to_enable_real-time_color_correction_of_monocular_underwater_images rdfs:label "Watergan: Unsupervised generative network to enable real-time color correction of monocular underwater images."@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-wavelength rdfs:label "wavelength"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wavelength_dissipation rdfs:label "wavelength dissipation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wavelength_of_the_rgb_channels rdfs:label "wavelength of the RGB channels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wavelengths rdfs:label "wavelengths"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weakly_supervised_color_transfer_method rdfs:label "weakly supervised color transfer method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-weights rdfs:label "weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weights_from_vgg rdfs:label "weights from VGG"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weights_of_convolutional_layers rdfs:label "weights of convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wgan-gp rdfs:label "WGAN-GP"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-white_balance rdfs:label "White Balance"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-williams_sb rdfs:label "Williams, S.B."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-worst_due_to_training_on_the_synthesized_underwater_images rdfs:label "worst due to training on the synthesized underwater images"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-wu_q rdfs:label "Wu, Q."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-wu_z rdfs:label "Wu, Z."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-xi rdfs:label "xi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xu_h rdfs:label "Xu, H."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-xu_r rdfs:label "Xu, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-y rdfs:label "y"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-yang_m rdfs:label "Yang, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-yang_yb rdfs:label "Yang, Y.B."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-ye_x rdfs:label "Ye, X."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-year rdfs:label "Year"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-year_2015 rdfs:label "year 2015"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-yeganeh_h rdfs:label "Yeganeh, H."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-yi rdfs:label "yi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-yin_r rdfs:label "Yin, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-yoshida_y rdfs:label "Yoshida, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-yu_et_al rdfs:label "Yu et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-z rdfs:label "z"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-z_%CF%81_e_s%CE%BB_%CE%B2 rdfs:label "{z, ρ, E, Sλ, β}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-zach_c rdfs:label "Zach, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zero-shot_or_few-shot_learning rdfs:label "zero-shot or few-shot learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-zero-shot_problem rdfs:label "zero-shot problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-zhang_j rdfs:label "Zhang, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhang_k rdfs:label "Zhang, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhang_x rdfs:label "Zhang, X."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhou_t rdfs:label "Zhou, T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhu_jy rdfs:label "Zhu, J.Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhu_y rdfs:label "Zhu, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zisserman_a rdfs:label "Zisserman, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zoom-in rdfs:label "zoom-in"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-zuo_w rdfs:label "Zuo, W."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Paper-c63c8058011e31f2-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "Diving Deeper Into Underwater Image Enhancement: A Survey"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-13,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Saeed Anwar∗· Chongyi Li∗ Received: date / Accepted: date Abstract The powerful representation capacity of deep learning has made it inevitable for the underwater image enhancement community to employ its potential. The exploration of deep underwater image enhancement networks is increasing over time, and hence; a comprehensive survey is the need of the hour. In this paper, our main aim is two-fold, 1): to provide a comprehensive and in-depth survey of the deep learning-based underwater image enhancement, which covers various perspectives ranging from algorithms to open issues, and 2): to conduct a qualitative and quantitative comparison of the deep algorithms on diverse datasets to serve as a benchmark, which has been barely explored before."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11-Sentence-111,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11-Sentence-112,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11-Sentence-113 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Saeed Anwar∗· Chongyi Li∗ Received: date / Accepted: date Abstract The powerful representation capacity of deep learning has made it inevitable for the underwater image enhancement community to employ its potential."@en ;
    askg-onto:inSentence "Saeed Anwar∗· Chongyi Li∗ Received: date / Accepted: date Abstract The powerful representation capacity of deep learning has made it inevitable for the underwater image enhancement community to employ its potential."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-chongyi_li,
        askg-data:Entity-deep_learning,
        askg-data:Entity-saeed_anwar,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11-Sentence-112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The exploration of deep underwater image enhancement networks is increasing over time, and hence; a comprehensive survey is the need of the hour."@en ;
    askg-onto:inSentence "The exploration of deep underwater image enhancement networks is increasing over time, and hence; a comprehensive survey is the need of the hour."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_underwater_image_enhancement_networks,
        askg-data:Entity-hour,
        askg-data:Entity-need_of_the_hour,
        askg-data:Entity-survey .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-11-Sentence-113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In this paper, our main aim is two-fold, 1): to provide a comprehensive and in-depth survey of the deep learning-based underwater image enhancement, which covers various perspectives ranging from algorithms to open issues, and 2): to conduct a qualitative and quantitative comparison of the deep algorithms on diverse datasets to serve as a benchmark, which has been barely explored before."@en ;
    askg-onto:inSentence "In this paper, our main aim is two-fold, 1): to provide a comprehensive and in-depth survey of the deep learning-based underwater image enhancement, which covers various perspectives ranging from algorithms to open issues, and 2): to conduct a qualitative and quantitative comparison of the deep algorithms on diverse datasets to serve as a benchmark, which has been barely explored before."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_benchmark,
        askg-data:Entity-deep_algorithms,
        askg-data:Entity-deep_learning-based_underwater_image_enhancement,
        askg-data:Entity-diverse_datasets,
        askg-data:Entity-method,
        askg-data:Entity-qualitative_and_quantitative_comparison,
        askg-data:Entity-research_area .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "To be specific, we first introduce the underwater image formation models, which are the base of training data synthesis and design of deep networks, and also helpful for understanding the process of underwater image degradation. Then, we review deep underwater image enhancement algorithms, and a glimpse of some of the aspects of the current networks is presented including network architecture, network parameters, training data, loss function, and training configurations. We also summarize the evaluation metrics and underwater image datasets. Following that, a systematically experimental comparison is carried out to analyze the robustness and effectiveness of deep algorithms."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-121,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-122,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-123,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-124 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To be specific, we first introduce the underwater image formation models, which are the base of training data synthesis and design of deep networks, and also helpful for understanding the process of underwater image degradation."@en ;
    askg-onto:inSentence "To be specific, we first introduce the underwater image formation models, which are the base of training data synthesis and design of deep networks, and also helpful for understanding the process of underwater image degradation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-training_data_synthesis,
        askg-data:Entity-underwater_image_degradation,
        askg-data:Entity-underwater_image_formation_models .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Then, we review deep underwater image enhancement algorithms, and a glimpse of some of the aspects of the current networks is presented including network architecture, network parameters, training data, loss function, and training configurations."@en ;
    askg-onto:inSentence "Then, we review deep underwater image enhancement algorithms, and a glimpse of some of the aspects of the current networks is presented including network architecture, network parameters, training data, loss function, and training configurations."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aspects_of_the_current_networks,
        askg-data:Entity-current_networks,
        askg-data:Entity-deep_underwater_image_enhancement_algorithms,
        askg-data:Entity-loss_function,
        askg-data:Entity-network_architecture,
        askg-data:Entity-network_parameters,
        askg-data:Entity-training_configurations,
        askg-data:Entity-training_data .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We also summarize the evaluation metrics and underwater image datasets."@en ;
    askg-onto:inSentence "We also summarize the evaluation metrics and underwater image datasets."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_metrics,
        askg-data:Entity-underwater_image_datasets .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-12-Sentence-124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Following that, a systematically experimental comparison is carried out to analyze the robustness and effectiveness of deep algorithms."@en ;
    askg-onto:inSentence "Following that, a systematically experimental comparison is carried out to analyze the robustness and effectiveness of deep algorithms."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_algorithms,
        askg-data:Entity-robustness_and_effectiveness .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-13 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Australian National University, Canberra ACT 2600, E-mail: saeed.anwar@data61.csiro.au C. Li is a postdoctoral fellow Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong, China E-mail: lichongyi@tju.edu.cn ∗ shows equal contribution."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-13-Sentence-131,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-13-Sentence-132 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-13-Sentence-131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Australian National University, Canberra ACT 2600, E-mail: saeed.anwar@data61.csiro.au C."@en ;
    askg-onto:inSentence "Australian National University, Canberra ACT 2600, E-mail: saeed.anwar@data61.csiro.au C."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australian_national_university,
        askg-data:Entity-canberra_act_2600,
        askg-data:Entity-saeed_anwar,
        askg-data:Entity-saeedanwardata61csiroau .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-13-Sentence-132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Li is a postdoctoral fellow Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong, China E-mail: lichongyi@tju.edu.cn ∗ shows equal contribution."@en ;
    askg-onto:inSentence "Li is a postdoctoral fellow Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong, China E-mail: lichongyi@tju.edu.cn ∗ shows equal contribution."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-department_of_computer_science_city_university_of_hong_kong,
        askg-data:Entity-li .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Meanwhile, we point out the shortcomings of current benchmark datasets and evaluation metrics. Finally, we discuss several unsolved open issues and suggest possible research directions. We hope that all efforts done in this paper might serve as a comprehensive reference for future research and call for the development of deep learning-based underwater image enhancement. Keywords Underwater image enhancement · deep learning · convolutional neural networks (CNNs) · generative adversarial networks (GANs) · underwater datasets · underwater evaluation metrics · survey."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-141,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-142,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-143,
        askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-144 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Meanwhile, we point out the shortcomings of current benchmark datasets and evaluation metrics."@en ;
    askg-onto:inSentence "Meanwhile, we point out the shortcomings of current benchmark datasets and evaluation metrics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-benchmark_datasets,
        askg-data:Entity-evaluation_metrics .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Finally, we discuss several unsolved open issues and suggest possible research directions."@en ;
    askg-onto:inSentence "Finally, we discuss several unsolved open issues and suggest possible research directions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-possible_research_directions,
        askg-data:Entity-unsolved_open_issues .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We hope that all efforts done in this paper might serve as a comprehensive reference for future research and call for the development of deep learning-based underwater image enhancement."@en ;
    askg-onto:inSentence "We hope that all efforts done in this paper might serve as a comprehensive reference for future research and call for the development of deep learning-based underwater image enhancement."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_underwater_image_enhancement,
        askg-data:Entity-future_research,
        askg-data:Entity-image_enhancement,
        askg-data:Entity-paper .

askg-data:Paper-c63c8058011e31f2-Section-1-Paragraph-14-Sentence-144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Keywords Underwater image enhancement · deep learning · convolutional neural networks (CNNs) · generative adversarial networks (GANs) · underwater datasets · underwater evaluation metrics · survey."@en ;
    askg-onto:inSentence "Keywords Underwater image enhancement · deep learning · convolutional neural networks (CNNs) · generative adversarial networks (GANs) · underwater datasets · underwater evaluation metrics · survey."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-concept,
        askg-data:Entity-convolutional_neural_networks_cnns,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning,
        askg-data:Entity-generative_adversarial_networks_gans,
        askg-data:Entity-metric,
        askg-data:Entity-research_area,
        askg-data:Entity-survey,
        askg-data:Entity-technology,
        askg-data:Entity-underwater_datasets,
        askg-data:Entity-underwater_evaluation_metrics,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "3.1.2 Uie-Dal"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101,
        askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102 ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Underwater Image Enhancement using Domain Adversarial Learning (UIE-DAL) [54] aims to learn agnostic model where it can enhance any underwater-type image. The backbone architecture of the UIE-DAL [54] is the famous encoder-decoder UNET [48]. The novelty of this work is the incorporation of a neural network classifier, named nuisance classifier, which classifies the latent vector extracted from the encoder."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101-Sentence-1011,
        askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101-Sentence-1012,
        askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101-Sentence-1013 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101-Sentence-1011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Underwater Image Enhancement using Domain Adversarial Learning (UIE-DAL) [54] aims to learn agnostic model where it can enhance any underwater-type image."@en ;
    askg-onto:inSentence "Underwater Image Enhancement using Domain Adversarial Learning (UIE-DAL) [54] aims to learn agnostic model where it can enhance any underwater-type image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-agnostic_model,
        askg-data:Entity-underwater_image_enhancement_using_domain_adversarial_learning_uie-dal .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101-Sentence-1012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The backbone architecture of the UIE-DAL [54] is the famous encoder-decoder UNET [48]."@en ;
    askg-onto:inSentence "The backbone architecture of the UIE-DAL [54] is the famous encoder-decoder UNET [48]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_unet,
        askg-data:Entity-uie-dal .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-101-Sentence-1013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The novelty of this work is the incorporation of a neural network classifier, named nuisance classifier, which classifies the latent vector extracted from the encoder."@en ;
    askg-onto:inSentence "The novelty of this work is the incorporation of a neural network classifier, named nuisance classifier, which classifies the latent vector extracted from the encoder."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder,
        askg-data:Entity-latent_vector,
        askg-data:Entity-neural_network_classifier,
        askg-data:Entity-nuisance_classifier .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The authors claim the model to be agnostic considering that nuisance classifier is not aware of the underwater type as it receives the latent vector from the encoder, which is agnostic to the features of the underwater types. The UIE-DAL [54] combines three losses i.e. `2, nuisance loss, and adversarial loss. The training is achieved in two steps. First, the only encoder-decoder structure is trained, then a nuisance classier is incorporated in the network."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1021,
        askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1022,
        askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1023,
        askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1024,
        askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1025 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The authors claim the model to be agnostic considering that nuisance classifier is not aware of the underwater type as it receives the latent vector from the encoder, which is agnostic to the features of the underwater types."@en ;
    askg-onto:inSentence "The authors claim the model to be agnostic considering that nuisance classifier is not aware of the underwater type as it receives the latent vector from the encoder, which is agnostic to the features of the underwater types."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder,
        askg-data:Entity-features_of_the_underwater_types,
        askg-data:Entity-latent_vector,
        askg-data:Entity-model,
        askg-data:Entity-nuisance_classifier,
        askg-data:Entity-underwater_type .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The UIE-DAL [54] combines three losses i.e."@en ;
    askg-onto:inSentence "The UIE-DAL [54] combines three losses i.e."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-three_losses,
        askg-data:Entity-uie-dal .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "`2, nuisance loss, and adversarial loss."@en ;
    askg-onto:inSentence "`2, nuisance loss, and adversarial loss."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_loss,
        askg-data:Entity-nuisance_loss .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The training is achieved in two steps."@en ;
    askg-onto:inSentence "The training is achieved in two steps."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-training,
        askg-data:Entity-two_steps .

askg-data:Paper-c63c8058011e31f2-Section-10-Paragraph-102-Sentence-1025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "First, the only encoder-decoder structure is trained, then a nuisance classier is incorporated in the network."@en ;
    askg-onto:inSentence "First, the only encoder-decoder structure is trained, then a nuisance classier is incorporated in the network."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_structure,
        askg-data:Entity-nuisance_classifier,
        askg-data:Entity-the_network .

askg-data:Paper-c63c8058011e31f2-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "3.1.3 Ugan"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Recently, Underwater Generative adversarial network (UGAN) [12] is proposed to improve the underwater image quality. For discriminator, UGAN chose WGAN- GP (Wasserstein GAN with gradient penalty) [14] to enforces the soft constraint on the output concerning its input via the Lipschitz on the gradients norms instead of clipping the gradients in some range. The discriminator is fully convolutional and is similar to [46] except batch normalization [22] is not applied to the weights of convolutional layers. Furthermore, the discriminator outputs 32×32 feature matrix similar to PatchGAN [36]. The generator is motivated by CycleGAN [66], comparable to the encoder-decoder network of UNET [48]. The encoder of UGAN [12] is composed of convolutional layers having filter sizes of 4 × 4 with a stride of two followed by batch normalization [22] and leaky ReLU (slope of 0.2). Similarly, the decoder portion consists of deconvolutional layers followed by ReLU [42] only except the last layer where TanH is used to restrict distribution between -1 and 1."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1112,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1113,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1114,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1115,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1116,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1117 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Recently, Underwater Generative adversarial network (UGAN) [12] is proposed to improve the underwater image quality."@en ;
    askg-onto:inSentence "Recently, Underwater Generative adversarial network (UGAN) [12] is proposed to improve the underwater image quality."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-underwater_generative_adversarial_network_ugan,
        askg-data:Entity-underwater_image_quality .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For discriminator, UGAN chose WGAN- GP (Wasserstein GAN with gradient penalty) [14] to enforces the soft constraint on the output concerning its input via the Lipschitz on the gradients norms instead of clipping the gradients in some range."@en ;
    askg-onto:inSentence "For discriminator, UGAN chose WGAN- GP (Wasserstein GAN with gradient penalty) [14] to enforces the soft constraint on the output concerning its input via the Lipschitz on the gradients norms instead of clipping the gradients in some range."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradients_norms,
        askg-data:Entity-input,
        askg-data:Entity-lipschitz,
        askg-data:Entity-output,
        askg-data:Entity-soft_constraint,
        askg-data:Entity-ugan,
        askg-data:Entity-wasserstein_gan_with_gradient_penalty,
        askg-data:Entity-wgan-gp .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The discriminator is fully convolutional and is similar to [46] except batch normalization [22] is not applied to the weights of convolutional layers."@en ;
    askg-onto:inSentence "The discriminator is fully convolutional and is similar to [46] except batch normalization [22] is not applied to the weights of convolutional layers."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-46,
        askg-data:Entity-batch_normalization,
        askg-data:Entity-discriminator,
        askg-data:Entity-fully_convolutional,
        askg-data:Entity-weights_of_convolutional_layers .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Furthermore, the discriminator outputs 32×32 feature matrix similar to PatchGAN [36]."@en ;
    askg-onto:inSentence "Furthermore, the discriminator outputs 32×32 feature matrix similar to PatchGAN [36]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3232_feature_matrix,
        askg-data:Entity-discriminator,
        askg-data:Entity-patchgan .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The generator is motivated by CycleGAN [66], comparable to the encoder-decoder network of UNET [48]."@en ;
    askg-onto:inSentence "The generator is motivated by CycleGAN [66], comparable to the encoder-decoder network of UNET [48]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cyclegan,
        askg-data:Entity-unet .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The encoder of UGAN [12] is composed of convolutional layers having filter sizes of 4 × 4 with a stride of two followed by batch normalization [22] and leaky ReLU (slope of 0.2)."@en ;
    askg-onto:inSentence "The encoder of UGAN [12] is composed of convolutional layers having filter sizes of 4 × 4 with a stride of two followed by batch normalization [22] and leaky ReLU (slope of 0.2)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-02,
        askg-data:Entity-4__4,
        askg-data:Entity-batch_normalization,
        askg-data:Entity-convolutional_layers,
        askg-data:Entity-leaky_relu,
        askg-data:Entity-two,
        askg-data:Entity-ugan .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-111-Sentence-1117 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Similarly, the decoder portion consists of deconvolutional layers followed by ReLU [42] only except the last layer where TanH is used to restrict distribution between -1 and 1."@en ;
    askg-onto:inSentence "Similarly, the decoder portion consists of deconvolutional layers followed by ReLU [42] only except the last layer where TanH is used to restrict distribution between -1 and 1."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decoder_portion,
        askg-data:Entity-deconvolutional_layers,
        askg-data:Entity-distribution,
        askg-data:Entity-last_layer,
        askg-data:Entity-relu,
        askg-data:Entity-tanh .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The evaluation and training are achieved on the subsets of ImageNet [10]. Moreover, two types of underwater images are collected *i.e.* one set of 6,143 images without distortion and another set of 1,817 images with distortion. The Adam [28] is used as optimizer with a fixed learning rate of 10−4for 100 epochs. The input to the network is 256×256×3, while loss is a linear combination of `1 and Earth-Mover or Wasserstein-1 distance."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1121,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1122,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1123,
        askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1124 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The evaluation and training are achieved on the subsets of ImageNet [10]."@en ;
    askg-onto:inSentence "The evaluation and training are achieved on the subsets of ImageNet [10]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_and_training,
        askg-data:Entity-imagenet .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Moreover, two types of underwater images are collected *i.e.* one set of 6,143 images without distortion and another set of 1,817 images with distortion."@en ;
    askg-onto:inSentence "Moreover, two types of underwater images are collected *i.e.* one set of 6,143 images without distortion and another set of 1,817 images with distortion."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1817_images_with_distortion,
        askg-data:Entity-6143_images_without_distortion,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The Adam [28] is used as optimizer with a fixed learning rate of 10−4for 100 epochs."@en ;
    askg-onto:inSentence "The Adam [28] is used as optimizer with a fixed learning rate of 10−4for 100 epochs."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-100,
        askg-data:Entity-104,
        askg-data:Entity-adam,
        askg-data:Entity-epochs,
        askg-data:Entity-learning_rate,
        askg-data:Entity-optimizer .

askg-data:Paper-c63c8058011e31f2-Section-11-Paragraph-112-Sentence-1124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The input to the network is 256×256×3, while loss is a linear combination of `1 and Earth-Mover or Wasserstein-1 distance."@en ;
    askg-onto:inSentence "The input to the network is 256×256×3, while loss is a linear combination of `1 and Earth-Mover or Wasserstein-1 distance."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2562563,
        askg-data:Entity-earth-mover_or_wasserstein-1_distance,
        askg-data:Entity-input,
        askg-data:Entity-loss .

askg-data:Paper-c63c8058011e31f2-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "3.2 Modular Designs"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121 ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Modular or block designs employ the repetition of the same structure, commonly known as a \"block\" or a\"module\", to learn the features. These designs are very successful in computer vision and machine learning tasks. We provide the example of modular or block-based designs for underwater networks below."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121-Sentence-1211,
        askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121-Sentence-1212,
        askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121-Sentence-1213 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121-Sentence-1211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Modular or block designs employ the repetition of the same structure, commonly known as a \"block\" or a\"module\", to learn the features."@en ;
    askg-onto:inSentence "Modular or block designs employ the repetition of the same structure, commonly known as a \"block\" or a\"module\", to learn the features."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-block_or_module,
        askg-data:Entity-features,
        askg-data:Entity-modular_or_block_designs,
        askg-data:Entity-repetition_of_the_same_structure,
        askg-data:Entity-structure .

askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121-Sentence-1212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These designs are very successful in computer vision and machine learning tasks."@en ;
    askg-onto:inSentence "These designs are very successful in computer vision and machine learning tasks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision,
        askg-data:Entity-designs,
        askg-data:Entity-machine_learning .

askg-data:Paper-c63c8058011e31f2-Section-12-Paragraph-121-Sentence-1213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We provide the example of modular or block-based designs for underwater networks below."@en ;
    askg-onto:inSentence "We provide the example of modular or block-based designs for underwater networks below."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-block-based_designs,
        askg-data:Entity-modular_designs,
        askg-data:Entity-underwater_networks .

askg-data:Paper-c63c8058011e31f2-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "3.2.1 Uwcnn"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-132,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-133,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-135 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To deal with the low contrast and distorted color of the degraded underwater images, Anwar *et al.* [3] proposed a CNN underwater image enhancement model, called UWCNN. The UWCNN is an end-to-end model trained by the synthetic underwater image datasets, which includes three densely connected building blocks. Furthermore, each basic building block consists of three densely connected convolutional layers. After the three chained building blocks, a convolutional layer is used to learn the difference (residual) between the degraded underwater image and its clean counterpart."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1312,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1313,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1314 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To deal with the low contrast and distorted color of the degraded underwater images, Anwar *et al.* [3] proposed a CNN underwater image enhancement model, called UWCNN."@en ;
    askg-onto:inSentence "To deal with the low contrast and distorted color of the degraded underwater images, Anwar *et al.* [3] proposed a CNN underwater image enhancement model, called UWCNN."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anwar_et_al,
        askg-data:Entity-cnn_underwater_image_enhancement_model,
        askg-data:Entity-uwcnn .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The UWCNN is an end-to-end model trained by the synthetic underwater image datasets, which includes three densely connected building blocks."@en ;
    askg-onto:inSentence "The UWCNN is an end-to-end model trained by the synthetic underwater image datasets, which includes three densely connected building blocks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-end-to-end_model,
        askg-data:Entity-synthetic_underwater_image_datasets,
        askg-data:Entity-three_densely_connected_building_blocks,
        askg-data:Entity-uwcnn .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, each basic building block consists of three densely connected convolutional layers."@en ;
    askg-onto:inSentence "Furthermore, each basic building block consists of three densely connected convolutional layers."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-basic_building_block,
        askg-data:Entity-three_densely_connected_convolutional_layers .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-131-Sentence-1314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "After the three chained building blocks, a convolutional layer is used to learn the difference (residual) between the degraded underwater image and its clean counterpart."@en ;
    askg-onto:inSentence "After the three chained building blocks, a convolutional layer is used to learn the difference (residual) between the degraded underwater image and its clean counterpart."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_layer,
        askg-data:Entity-difference_residual_between_the_degraded_underwater_image_and_its_clean_counterpart .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-132 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![4_image_0.png](4_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-132-Sentence-1321 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-132-Sentence-1321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![4_image_0.png](4_image_0.png)"@en ;
    askg-onto:inSentence "![4_image_0.png](4_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-unknown_concept .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-133 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Fig. 1 Categorization of Deep Underwater Networks: The organization of deep networks based on their essential aspects."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-133-Sentence-1331,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-133-Sentence-1332 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-133-Sentence-1331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-unknown_concept .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-133-Sentence-1332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "1 Categorization of Deep Underwater Networks: The organization of deep networks based on their essential aspects."@en ;
    askg-onto:inSentence "1 Categorization of Deep Underwater Networks: The organization of deep networks based on their essential aspects."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_underwater_networks,
        askg-data:Entity-organization_of_deep_networks_based_on_essential_aspects .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "To train the UWCNN [3] model, the authors use the attenuation coefficients of different water types to synthesize various underwater image datasets according to the underwater image formation model resulting in ten types of underwater image datasets which are synthesized by using the RGB-D NYU-v2 dataset [50]. These underwater image datasets simulate the open ocean water types and coastal water types ranging from the clearest to the most turbid. Finally, the authors train ten UWCNN models for the ten types of underwater images. The parameters of the UWCNN model are learned by joint optimizing the `2 and SSIM loss functions. In the entire UWCNN, the kernel sizes and filter numbers are fixed, *i.e.*, 3×3 and 16, respectively."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1341,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1342,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1343,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1344,
        askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1345 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To train the UWCNN [3] model, the authors use the attenuation coefficients of different water types to synthesize various underwater image datasets according to the underwater image formation model resulting in ten types of underwater image datasets which are synthesized by using the RGB-D NYU-v2 dataset [50]."@en ;
    askg-onto:inSentence "To train the UWCNN [3] model, the authors use the attenuation coefficients of different water types to synthesize various underwater image datasets according to the underwater image formation model resulting in ten types of underwater image datasets which are synthesized by using the RGB-D NYU-v2 dataset [50]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attenuation_coefficients,
        askg-data:Entity-rgb-d_nyu-v2_dataset,
        askg-data:Entity-ten_types_of_underwater_image_datasets,
        askg-data:Entity-underwater_image_datasets,
        askg-data:Entity-underwater_image_formation_model,
        askg-data:Entity-uwcnn_model .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These underwater image datasets simulate the open ocean water types and coastal water types ranging from the clearest to the most turbid."@en ;
    askg-onto:inSentence "These underwater image datasets simulate the open ocean water types and coastal water types ranging from the clearest to the most turbid."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-clearest,
        askg-data:Entity-coastal_water_types,
        askg-data:Entity-most_turbid,
        askg-data:Entity-open_ocean_water_types,
        askg-data:Entity-underwater_image_datasets .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Finally, the authors train ten UWCNN models for the ten types of underwater images."@en ;
    askg-onto:inSentence "Finally, the authors train ten UWCNN models for the ten types of underwater images."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-underwater_images,
        askg-data:Entity-uwcnn_models .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1344 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The parameters of the UWCNN model are learned by joint optimizing the `2 and SSIM loss functions."@en ;
    askg-onto:inSentence "The parameters of the UWCNN model are learned by joint optimizing the `2 and SSIM loss functions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2_loss_functions,
        askg-data:Entity-ssim_loss_functions,
        askg-data:Entity-uwcnn_model .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-134-Sentence-1345 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In the entire UWCNN, the kernel sizes and filter numbers are fixed, *i.e.*, 3×3 and 16, respectively."@en ;
    askg-onto:inSentence "In the entire UWCNN, the kernel sizes and filter numbers are fixed, *i.e.*, 3×3 and 16, respectively."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-16,
        askg-data:Entity-33,
        askg-data:Entity-filter_numbers,
        askg-data:Entity-kernel_sizes,
        askg-data:Entity-kernel_sizes_and_filter_numbers,
        askg-data:Entity-uwcnn .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-135 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "The learning rate is set to 2×10−4 and ADAM [28] is used for optimization in TensorFlow framework."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-135-Sentence-1351 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-13-Paragraph-135-Sentence-1351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The learning rate is set to 2×10−4 and ADAM [28] is used for optimization in TensorFlow framework."@en ;
    askg-onto:inSentence "The learning rate is set to 2×10−4 and ADAM [28] is used for optimization in TensorFlow framework."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2104,
        askg-data:Entity-adam,
        askg-data:Entity-learning_rate,
        askg-data:Entity-tensorflow_framework .

askg-data:Paper-c63c8058011e31f2-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "3.2.2 Densegan"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-141,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To enhance the underwater images, Guo *et al.* [16] introduced a multiscale dense block (MSDB) algorithm, namely, DenseGAN1 which employs the use of dense connections, residual learning, and multi-scale network for underwater image enhancement."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-141-Sentence-1411 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To enhance the underwater images, Guo *et al.* [16] introduced a multiscale dense block (MSDB) algorithm, namely, DenseGAN1 which employs the use of dense connections, residual learning, and multi-scale network for underwater image enhancement."@en ;
    askg-onto:inSentence "To enhance the underwater images, Guo *et al.* [16] introduced a multiscale dense block (MSDB) algorithm, namely, DenseGAN1 which employs the use of dense connections, residual learning, and multi-scale network for underwater image enhancement."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dense_connections,
        askg-data:Entity-densegan1,
        askg-data:Entity-guo_et_al,
        askg-data:Entity-multi-scale_network,
        askg-data:Entity-multiscale_dense_block_msdb_algorithm,
        askg-data:Entity-residual_learning,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The generator at the start is composed of two convolutional, batch normalization (BN), leaky ReLU (LReLU) sequence then two MSDB blocks followed by sequence Deconvolutional-BN-LReLU, while at the end there is a deconvolutional layer and a TanH layer. The network architecture of the DenseGAN generator and MSDB are shown in Figure 2. In each MSDB block, the input features are passed through two different branches, where each branch has kernels with different dilations. The features from each branch are concatenated half-way through the MSDB block and fed again into the respective branches. At the end of the MSDB block, the features are concatenated again and passed through a 1×1 convolutional layer. The discriminator network is similar to PatchGAN [36]; however, it is composed of five layers of spectral normalization [41]. Except for the first and last layer, the discriminator is composed of sequences of convolutional-BN-LReLU."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1421,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1422,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1423,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1424,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1425,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1426,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1427 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The generator at the start is composed of two convolutional, batch normalization (BN), leaky ReLU (LReLU) sequence then two MSDB blocks followed by sequence Deconvolutional-BN-LReLU, while at the end there is a deconvolutional layer and a TanH layer."@en ;
    askg-onto:inSentence "The generator at the start is composed of two convolutional, batch normalization (BN), leaky ReLU (LReLU) sequence then two MSDB blocks followed by sequence Deconvolutional-BN-LReLU, while at the end there is a deconvolutional layer and a TanH layer."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_batch_normalization_bn_leaky_relu_lrelu_sequence,
        askg-data:Entity-deconvolutional_layer,
        askg-data:Entity-generator,
        askg-data:Entity-msdb_blocks,
        askg-data:Entity-sequence_deconvolutional-bn-lrelu,
        askg-data:Entity-tanh_layer .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The network architecture of the DenseGAN generator and MSDB are shown in Figure 2."@en ;
    askg-onto:inSentence "The network architecture of the DenseGAN generator and MSDB are shown in Figure 2."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-densegan_generator,
        askg-data:Entity-msdb,
        askg-data:Entity-network_architecture .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In each MSDB block, the input features are passed through two different branches, where each branch has kernels with different dilations."@en ;
    askg-onto:inSentence "In each MSDB block, the input features are passed through two different branches, where each branch has kernels with different dilations."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-branches,
        askg-data:Entity-different_dilations,
        askg-data:Entity-input_features,
        askg-data:Entity-kernels,
        askg-data:Entity-msdb_block .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The features from each branch are concatenated half-way through the MSDB block and fed again into the respective branches."@en ;
    askg-onto:inSentence "The features from each branch are concatenated half-way through the MSDB block and fed again into the respective branches."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-features,
        askg-data:Entity-msdb_block .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "At the end of the MSDB block, the features are concatenated again and passed through a 1×1 convolutional layer."@en ;
    askg-onto:inSentence "At the end of the MSDB block, the features are concatenated again and passed through a 1×1 convolutional layer."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11_convolutional_layer,
        askg-data:Entity-features,
        askg-data:Entity-msdb_block .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The discriminator network is similar to PatchGAN [36]; however, it is composed of five layers of spectral normalization [41]."@en ;
    askg-onto:inSentence "The discriminator network is similar to PatchGAN [36]; however, it is composed of five layers of spectral normalization [41]."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discriminator_network,
        askg-data:Entity-five_layers_of_spectral_normalization,
        askg-data:Entity-patchgan .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-142-Sentence-1427 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Except for the first and last layer, the discriminator is composed of sequences of convolutional-BN-LReLU."@en ;
    askg-onto:inSentence "Except for the first and last layer, the discriminator is composed of sequences of convolutional-BN-LReLU."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discriminator,
        askg-data:Entity-sequences_of_convolutional-bn-lrelu .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The first two layers of the generator have 7×7 and 3×3 filter size with 64 and 128 feature maps respectively. The last deconvolution layer outputs the same number of channels as the input. The TanH layer keeps the distribution between -1 and 1. Moreover, the slope of the leaky ReLU is fixed at 0.2, and the network is trained via TensorFlow framework using a learning rate of 10−3 with patch size of 256×256×3. The ADAM [28] is used for optimization, and batch size is set to 32. The losses employed are GAN loss, `1, and gradient loss."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1431,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1432,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1433,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1434,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1435,
        askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1436 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The first two layers of the generator have 7×7 and 3×3 filter size with 64 and 128 feature maps respectively."@en ;
    askg-onto:inSentence "The first two layers of the generator have 7×7 and 3×3 filter size with 64 and 128 feature maps respectively."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-64_and_128_feature_maps,
        askg-data:Entity-77_and_33_filter_size,
        askg-data:Entity-first_two_layers_of_the_generator .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The last deconvolution layer outputs the same number of channels as the input."@en ;
    askg-onto:inSentence "The last deconvolution layer outputs the same number of channels as the input."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deconvolution_layer,
        askg-data:Entity-number_of_channels .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The TanH layer keeps the distribution between -1 and 1."@en ;
    askg-onto:inSentence "The TanH layer keeps the distribution between -1 and 1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity--1_and_1,
        askg-data:Entity-tanh_layer .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, the slope of the leaky ReLU is fixed at 0.2, and the network is trained via TensorFlow framework using a learning rate of 10−3 with patch size of 256×256×3."@en ;
    askg-onto:inSentence "Moreover, the slope of the leaky ReLU is fixed at 0.2, and the network is trained via TensorFlow framework using a learning rate of 10−3 with patch size of 256×256×3."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-02,
        askg-data:Entity-103,
        askg-data:Entity-2562563,
        askg-data:Entity-leaky_relu,
        askg-data:Entity-network,
        askg-data:Entity-tensorflow_framework .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1435 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The ADAM [28] is used for optimization, and batch size is set to 32."@en ;
    askg-onto:inSentence "The ADAM [28] is used for optimization, and batch size is set to 32."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-32,
        askg-data:Entity-adam,
        askg-data:Entity-batch_size,
        askg-data:Entity-optimization .

askg-data:Paper-c63c8058011e31f2-Section-14-Paragraph-143-Sentence-1436 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The losses employed are GAN loss, `1, and gradient loss."@en ;
    askg-onto:inSentence "The losses employed are GAN loss, `1, and gradient loss."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gan_loss,
        askg-data:Entity-gradient_loss,
        askg-data:Entity-losses .

askg-data:Paper-c63c8058011e31f2-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "3.3 Multi-Branch Designs"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-15-Paragraph-151 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The multiple branch designs aim to either learn different features of the same input at different levels or exploit distinct inputs at separate branches. Following are the examples of such networks."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-15-Paragraph-151-Sentence-1511,
        askg-data:Paper-c63c8058011e31f2-Section-15-Paragraph-151-Sentence-1512 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The multiple branch designs aim to either learn different features of the same input at different levels or exploit distinct inputs at separate branches."@en ;
    askg-onto:inSentence "The multiple branch designs aim to either learn different features of the same input at different levels or exploit distinct inputs at separate branches."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-distinct_inputs_at_separate_branches,
        askg-data:Entity-learn_different_features_of_the_same_input_at_different_levels,
        askg-data:Entity-multiple_branch_designs .

askg-data:Paper-c63c8058011e31f2-Section-15-Paragraph-151-Sentence-1512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Following are the examples of such networks."@en ;
    askg-onto:inSentence "Following are the examples of such networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-networks,
        askg-data:Entity-such_networks .

askg-data:Paper-c63c8058011e31f2-Section-16 a askg-onto:Section ;
    rdfs:label "Section 16"@en ;
    domo:Text "3.3.1 Uie-Net"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-163,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-164,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-165,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-168,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169 ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Wang *et al.* [56] presented a deep CNN method for enhancement of underwater images, namely, UIE-Net, which is composed of three subnetworks. The first subnet called sharing network (termed as S-Net) is composed of convolutional layers only. S-Net extracts fea-"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161-Sentence-1611,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161-Sentence-1612,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161-Sentence-1613 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161-Sentence-1611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Wang *et al.* [56] presented a deep CNN method for enhancement of underwater images, namely, UIE-Net, which is composed of three subnetworks."@en ;
    askg-onto:inSentence "Wang *et al.* [56] presented a deep CNN method for enhancement of underwater images, namely, UIE-Net, which is composed of three subnetworks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_cnn_method_for_enhancement_of_underwater_images,
        askg-data:Entity-three_subnetworks,
        askg-data:Entity-uie-net,
        askg-data:Entity-wang_et_al .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161-Sentence-1612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The first subnet called sharing network (termed as S-Net) is composed of convolutional layers only."@en ;
    askg-onto:inSentence "The first subnet called sharing network (termed as S-Net) is composed of convolutional layers only."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_layers,
        askg-data:Entity-s-net,
        askg-data:Entity-sharing_network .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-161-Sentence-1613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "S-Net extracts fea-"@en ;
    askg-onto:inSentence "S-Net extracts fea-"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-features,
        askg-data:Entity-s-net .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "1 The authors' term the model as UWGAN; however, Li *et al.* [34] proposed a model with the same name earlier. To avoid confusion, we call it DenseGAN due to its dense connections. 6 Saeed Anwar∗, Chongyi Li∗"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162-Sentence-1621,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162-Sentence-1622,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162-Sentence-1623 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162-Sentence-1621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1 The authors' term the model as UWGAN; however, Li *et al.* [34] proposed a model with the same name earlier."@en ;
    askg-onto:inSentence "1 The authors' term the model as UWGAN; however, Li *et al.* [34] proposed a model with the same name earlier."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-li_et_al,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162-Sentence-1622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To avoid confusion, we call it DenseGAN due to its dense connections."@en ;
    askg-onto:inSentence "To avoid confusion, we call it DenseGAN due to its dense connections."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-densegan .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-162-Sentence-1623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "6 Saeed Anwar∗, Chongyi Li∗"@en ;
    askg-onto:inSentence "6 Saeed Anwar∗, Chongyi Li∗"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-chongyi_li,
        askg-data:Entity-saeed_anwar .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-163 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![5_image_0.png](5_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-163-Sentence-1631 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-163-Sentence-1631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![5_image_0.png](5_image_0.png)"@en ;
    askg-onto:inSentence "![5_image_0.png](5_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-framework,
        askg-data:Entity-institution,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-researcher,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-tool .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-164 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Fig. 2 Network architectures: A glimpse of network architectures used for underwater image enhancement using CNNs"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-164-Sentence-1641,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-164-Sentence-1642 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-164-Sentence-1641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-unknown_concept .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-164-Sentence-1642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "2 Network architectures: A glimpse of network architectures used for underwater image enhancement using CNNs"@en ;
    askg-onto:inSentence "2 Network architectures: A glimpse of network architectures used for underwater image enhancement using CNNs"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnns,
        askg-data:Entity-network_architectures,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-165 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "and GANs. Best viewed with zoom-in on a digital display."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-165-Sentence-1651,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-165-Sentence-1652 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-165-Sentence-1651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and GANs."@en ;
    askg-onto:inSentence "and GANs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-gans .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-165-Sentence-1652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Best viewed with zoom-in on a digital display."@en ;
    askg-onto:inSentence "Best viewed with zoom-in on a digital display."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-digital_display,
        askg-data:Entity-zoom-in .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "tures from the input image which is then forwarded to the other two subnets (i.e. the branches of the network: the color correction network (CC-Net) and the haze removal network (HR-Net).) CC-Net and HR-Net output color corrected image, and transmission map, respectively. Both CC-Net and HR-Net have the same network structure consisting of four convolutional layers, followed by sigmoid activation. The only difference between CC-Net and HR-Net is the number of output channels *i.e.* three channels and one channel, respectively."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1661,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1662,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1663,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1664 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "tures from the input image which is then forwarded to the other two subnets (i.e."@en ;
    askg-onto:inSentence "tures from the input image which is then forwarded to the other two subnets (i.e."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_image,
        askg-data:Entity-subnets .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1662 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "the branches of the network: the color correction network (CC-Net) and the haze removal network (HR-Net).) CC-Net and HR-Net output color corrected image, and transmission map, respectively."@en ;
    askg-onto:inSentence "the branches of the network: the color correction network (CC-Net) and the haze removal network (HR-Net).) CC-Net and HR-Net output color corrected image, and transmission map, respectively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cc-net,
        askg-data:Entity-color_corrected_image,
        askg-data:Entity-color_correction_network,
        askg-data:Entity-haze_removal_network,
        askg-data:Entity-hr-net,
        askg-data:Entity-transmission_map .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1663 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Both CC-Net and HR-Net have the same network structure consisting of four convolutional layers, followed by sigmoid activation."@en ;
    askg-onto:inSentence "Both CC-Net and HR-Net have the same network structure consisting of four convolutional layers, followed by sigmoid activation."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cc-net,
        askg-data:Entity-four_convolutional_layers,
        askg-data:Entity-hr-net,
        askg-data:Entity-sigmoid_activation .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-166-Sentence-1664 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The only difference between CC-Net and HR-Net is the number of output channels *i.e.* three channels and one channel, respectively."@en ;
    askg-onto:inSentence "The only difference between CC-Net and HR-Net is the number of output channels *i.e.* three channels and one channel, respectively."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cc-net,
        askg-data:Entity-hr-net,
        askg-data:Entity-one_channel,
        askg-data:Entity-three_channels .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "The S-Net has two convolutional layers and a consistent filter size of 5×5, while the CC-Net and HR- Net have four convolutional layers with filter sizes of 1×*1, 3*×3, 5×5 and 7×7 to capture contextual information. Figure 2 shows the underlying network architecture of the UIE-Net. The inputs to the network are 32×32 image patches in the procedure of training, and the network is trained on 2×105image patches synthesized from 200 clear images collected from the internet."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167-Sentence-1671,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167-Sentence-1672,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167-Sentence-1673 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167-Sentence-1671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The S-Net has two convolutional layers and a consistent filter size of 5×5, while the CC-Net and HR- Net have four convolutional layers with filter sizes of 1×*1, 3*×3, 5×5 and 7×7 to capture contextual information."@en ;
    askg-onto:inSentence "The S-Net has two convolutional layers and a consistent filter size of 5×5, while the CC-Net and HR- Net have four convolutional layers with filter sizes of 1×*1, 3*×3, 5×5 and 7×7 to capture contextual information."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cc-net,
        askg-data:Entity-cc-net_and_hr-net,
        askg-data:Entity-consistent_filter_size_of_55,
        askg-data:Entity-filter_sizes_of_11_33_55_and_77,
        askg-data:Entity-four_convolutional_layers,
        askg-data:Entity-hr-net,
        askg-data:Entity-s-net,
        askg-data:Entity-two_convolutional_layers .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167-Sentence-1672 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Figure 2 shows the underlying network architecture of the UIE-Net."@en ;
    askg-onto:inSentence "Figure 2 shows the underlying network architecture of the UIE-Net."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-uie-net,
        askg-data:Entity-underlying_network_architecture .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-167-Sentence-1673 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The inputs to the network are 32×32 image patches in the procedure of training, and the network is trained on 2×105image patches synthesized from 200 clear images collected from the internet."@en ;
    askg-onto:inSentence "The inputs to the network are 32×32 image patches in the procedure of training, and the network is trained on 2×105image patches synthesized from 200 clear images collected from the internet."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-200_clear_images,
        askg-data:Entity-2105_image_patches,
        askg-data:Entity-3232_image_patches,
        askg-data:Entity-network,
        askg-data:Entity-the_internet,
        askg-data:Entity-the_network .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-168 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "The initial learning rate is fixed at 5×10−3, which is decreased by half after 5× 0 3 until 2.5×105."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-168-Sentence-1681 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-168-Sentence-1681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The initial learning rate is fixed at 5×10−3, which is decreased by half after 5× 0 3 until 2.5×105."@en ;
    askg-onto:inSentence "The initial learning rate is fixed at 5×10−3, which is decreased by half after 5× 0 3 until 2.5×105."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5103,
        askg-data:Entity-5_0_3_until_25105,
        askg-data:Entity-learning_rate .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "The loss employed for learning is `2. Moreover, the authors perform smoothing on the input patches to obtain desirable results. As the last step, the guided image filtering [18] is applied on the transmission map to remove artifacts if any. It is also to be noted here that UIE-Net is one of the pioneering work in deep learning direction."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1691,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1692,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1693,
        askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1694 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The loss employed for learning is `2."@en ;
    askg-onto:inSentence "The loss employed for learning is `2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning,
        askg-data:Entity-loss .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1692 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Moreover, the authors perform smoothing on the input patches to obtain desirable results."@en ;
    askg-onto:inSentence "Moreover, the authors perform smoothing on the input patches to obtain desirable results."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-authors,
        askg-data:Entity-smoothing .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1693 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As the last step, the guided image filtering [18] is applied on the transmission map to remove artifacts if any."@en ;
    askg-onto:inSentence "As the last step, the guided image filtering [18] is applied on the transmission map to remove artifacts if any."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guided_image_filtering,
        askg-data:Entity-transmission_map .

askg-data:Paper-c63c8058011e31f2-Section-16-Paragraph-169-Sentence-1694 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "It is also to be noted here that UIE-Net is one of the pioneering work in deep learning direction."@en ;
    askg-onto:inSentence "It is also to be noted here that UIE-Net is one of the pioneering work in deep learning direction."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pioneering_work_in_deep_learning_direction,
        askg-data:Entity-uie-net .

askg-data:Paper-c63c8058011e31f2-Section-17 a askg-onto:Section ;
    rdfs:label "Section 17"@en ;
    domo:Text "3.3.2 Duienet"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-171,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173 ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-171 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "More recently, Li *et al.* [35] constructed a real-world underwater image enhancement dataset, including 950 underwater images, 890 of which have the corresponding reference images. These potential reference images are produced by 12 image enhancement methods, and the final references are selected by 50 volunteers via majority voting."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-171-Sentence-1711,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-171-Sentence-1712 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-171-Sentence-1711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "More recently, Li *et al.* [35] constructed a real-world underwater image enhancement dataset, including 950 underwater images, 890 of which have the corresponding reference images."@en ;
    askg-onto:inSentence "More recently, Li *et al.* [35] constructed a real-world underwater image enhancement dataset, including 950 underwater images, 890 of which have the corresponding reference images."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-890_reference_images,
        askg-data:Entity-950_underwater_images,
        askg-data:Entity-li_et_al,
        askg-data:Entity-underwater_image_enhancement_dataset .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-171-Sentence-1712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These potential reference images are produced by 12 image enhancement methods, and the final references are selected by 50 volunteers via majority voting."@en ;
    askg-onto:inSentence "These potential reference images are produced by 12 image enhancement methods, and the final references are selected by 50 volunteers via majority voting."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_references,
        askg-data:Entity-image_enhancement_methods,
        askg-data:Entity-majority_voting,
        askg-data:Entity-reference_images,
        askg-data:Entity-volunteers .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Inspired by fusion-based underwater image enhancement method [4], Li *et al.* [35] proposed a gated fusion CNN trained by the constructed dataset for underwater image enhancement, called DUIENet. First, three input versions are generated by sequentially applying White Balance, Histogram Equalization, and Gamma Correction algorithms to the raw input image. Then, the DUIENet learns three confidence maps, which determine the most important features remaining in the final result. The DUIENet is a multi-scale FCNN, which consists of 14 convolutional layers followed ReLU except for the last layer (followed by Sigmoid). To reduce the color casts and artifacts introduced by the three pre-processing algorithms, three feature transformation units (FTUs) are used in the DUIENet [35]. The FTU includes three stacked multi-scale convolutional layers. The input of each FTU is the corresponding preprocessed underwater image, and its output is the transformed image. At last, the transformed three inputs are multiplied by the three learned confidence maps, and then the summation of the three products is the enhanced underwater image."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1721,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1722,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1723,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1724,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1725,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1726,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1727,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1728 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Inspired by fusion-based underwater image enhancement method [4], Li *et al.* [35] proposed a gated fusion CNN trained by the constructed dataset for underwater image enhancement, called DUIENet."@en ;
    askg-onto:inSentence "Inspired by fusion-based underwater image enhancement method [4], Li *et al.* [35] proposed a gated fusion CNN trained by the constructed dataset for underwater image enhancement, called DUIENet."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constructed_dataset,
        askg-data:Entity-duienet,
        askg-data:Entity-gated_fusion_cnn,
        askg-data:Entity-li_et_al,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "First, three input versions are generated by sequentially applying White Balance, Histogram Equalization, and Gamma Correction algorithms to the raw input image."@en ;
    askg-onto:inSentence "First, three input versions are generated by sequentially applying White Balance, Histogram Equalization, and Gamma Correction algorithms to the raw input image."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gamma_correction,
        askg-data:Entity-histogram_equalization,
        askg-data:Entity-raw_input_image,
        askg-data:Entity-white_balance .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Then, the DUIENet learns three confidence maps, which determine the most important features remaining in the final result."@en ;
    askg-onto:inSentence "Then, the DUIENet learns three confidence maps, which determine the most important features remaining in the final result."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-duienet,
        askg-data:Entity-three_confidence_maps .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The DUIENet is a multi-scale FCNN, which consists of 14 convolutional layers followed ReLU except for the last layer (followed by Sigmoid)."@en ;
    askg-onto:inSentence "The DUIENet is a multi-scale FCNN, which consists of 14 convolutional layers followed ReLU except for the last layer (followed by Sigmoid)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-14_convolutional_layers,
        askg-data:Entity-duienet,
        askg-data:Entity-last_layer,
        askg-data:Entity-multi-scale_fcnn,
        askg-data:Entity-relu,
        askg-data:Entity-sigmoid .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1725 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To reduce the color casts and artifacts introduced by the three pre-processing algorithms, three feature transformation units (FTUs) are used in the DUIENet [35]."@en ;
    askg-onto:inSentence "To reduce the color casts and artifacts introduced by the three pre-processing algorithms, three feature transformation units (FTUs) are used in the DUIENet [35]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-duienet,
        askg-data:Entity-feature_transformation_units_ftus .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1726 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The FTU includes three stacked multi-scale convolutional layers."@en ;
    askg-onto:inSentence "The FTU includes three stacked multi-scale convolutional layers."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ftu,
        askg-data:Entity-three_stacked_multi-scale_convolutional_layers .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1727 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The input of each FTU is the corresponding preprocessed underwater image, and its output is the transformed image."@en ;
    askg-onto:inSentence "The input of each FTU is the corresponding preprocessed underwater image, and its output is the transformed image."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ftu .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-172-Sentence-1728 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "At last, the transformed three inputs are multiplied by the three learned confidence maps, and then the summation of the three products is the enhanced underwater image."@en ;
    askg-onto:inSentence "At last, the transformed three inputs are multiplied by the three learned confidence maps, and then the summation of the three products is the enhanced underwater image."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-enhanced_underwater_image,
        askg-data:Entity-summation_of_the_three_products,
        askg-data:Entity-three_learned_confidence_maps,
        askg-data:Entity-transformed_three_inputs .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "With the constructed dataset, the authors selected 800 pairs of images randomly to generate the training set. These images are resized to 112×11 and data augmentation is used to obtain seven additional versions of the original 800 pairs of training data. The rest 90 pairs of images are treated as the testing set. To reduce the artifacts induced by pixel-wise loss functions, the authors minimize the perceptual loss (layer relu5 4 of the pre-trained VGG19 network [51])."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1731,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1732,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1733,
        askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1734 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "With the constructed dataset, the authors selected 800 pairs of images randomly to generate the training set."@en ;
    askg-onto:inSentence "With the constructed dataset, the authors selected 800 pairs of images randomly to generate the training set."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-800_pairs_of_images,
        askg-data:Entity-authors .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These images are resized to 112×11 and data augmentation is used to obtain seven additional versions of the original 800 pairs of training data."@en ;
    askg-onto:inSentence "These images are resized to 112×11 and data augmentation is used to obtain seven additional versions of the original 800 pairs of training data."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11211,
        askg-data:Entity-data_augmentation,
        askg-data:Entity-images,
        askg-data:Entity-original_800_pairs_of_training_data,
        askg-data:Entity-seven_additional_versions,
        askg-data:Entity-training_data .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The rest 90 pairs of images are treated as the testing set."@en ;
    askg-onto:inSentence "The rest 90 pairs of images are treated as the testing set."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-90_pairs_of_images,
        askg-data:Entity-testing_set .

askg-data:Paper-c63c8058011e31f2-Section-17-Paragraph-173-Sentence-1734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To reduce the artifacts induced by pixel-wise loss functions, the authors minimize the perceptual loss (layer relu5 4 of the pre-trained VGG19 network [51])."@en ;
    askg-onto:inSentence "To reduce the artifacts induced by pixel-wise loss functions, the authors minimize the perceptual loss (layer relu5 4 of the pre-trained VGG19 network [51])."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-perceptual_loss,
        askg-data:Entity-pixel-wise_loss_functions,
        askg-data:Entity-pre-trained_network,
        askg-data:Entity-vgg19_network .

askg-data:Paper-c63c8058011e31f2-Section-18 a askg-onto:Section ;
    rdfs:label "Section 18"@en ;
    domo:Text "3.3.3 Fgan"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-183 ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Fusion generative adversarial network, abbreviated as FGAN [37], takes multiple inputs and passes them through different branches in the same network. In the end, the features are summed before the loss of the generator. The architecture of FGAN [37] is similar to DenseGAN with slight modifications in the block's architecture. The generator with the fundamental block structure is shown in Figure 2. The discriminator is composed of five convolutional layers employing spectral normalization [41]. The discriminator is similar to PatchGAN [36]."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1811,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1812,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1813,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1814,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1815,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1816 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fusion generative adversarial network, abbreviated as FGAN [37], takes multiple inputs and passes them through different branches in the same network."@en ;
    askg-onto:inSentence "Fusion generative adversarial network, abbreviated as FGAN [37], takes multiple inputs and passes them through different branches in the same network."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_branches,
        askg-data:Entity-fgan,
        askg-data:Entity-fusion_generative_adversarial_network,
        askg-data:Entity-inputs,
        askg-data:Entity-the_same_network .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the end, the features are summed before the loss of the generator."@en ;
    askg-onto:inSentence "In the end, the features are summed before the loss of the generator."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-features,
        askg-data:Entity-loss_of_the_generator .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The architecture of FGAN [37] is similar to DenseGAN with slight modifications in the block's architecture."@en ;
    askg-onto:inSentence "The architecture of FGAN [37] is similar to DenseGAN with slight modifications in the block's architecture."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blocks_architecture,
        askg-data:Entity-densegan,
        askg-data:Entity-fgan .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The generator with the fundamental block structure is shown in Figure 2."@en ;
    askg-onto:inSentence "The generator with the fundamental block structure is shown in Figure 2."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fundamental_block_structure,
        askg-data:Entity-generator .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The discriminator is composed of five convolutional layers employing spectral normalization [41]."@en ;
    askg-onto:inSentence "The discriminator is composed of five convolutional layers employing spectral normalization [41]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discriminator,
        askg-data:Entity-five_convolutional_layers,
        askg-data:Entity-spectral_normalization .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-181-Sentence-1816 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The discriminator is similar to PatchGAN [36]."@en ;
    askg-onto:inSentence "The discriminator is similar to PatchGAN [36]."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discriminator,
        askg-data:Entity-patchgan .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "A batch-mode learning method with a batch size of 16 is applied. The RGB images of size 256×256 are used as inputs. Further, the learning rate is set to 10−3."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182-Sentence-1821,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182-Sentence-1822,
        askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182-Sentence-1823 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182-Sentence-1821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A batch-mode learning method with a batch size of 16 is applied."@en ;
    askg-onto:inSentence "A batch-mode learning method with a batch size of 16 is applied."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch-mode_learning_method,
        askg-data:Entity-batch_size_of_16 .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182-Sentence-1822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The RGB images of size 256×256 are used as inputs."@en ;
    askg-onto:inSentence "The RGB images of size 256×256 are used as inputs."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inputs,
        askg-data:Entity-rgb_images .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-182-Sentence-1823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Further, the learning rate is set to 10−3."@en ;
    askg-onto:inSentence "Further, the learning rate is set to 10−3."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-103,
        askg-data:Entity-learning_rate .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-183 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The loss function is a combination of relativistic GAN loss [27], adversarial loss, and `2 loss."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-183-Sentence-1831 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-18-Paragraph-183-Sentence-1831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The loss function is a combination of relativistic GAN loss [27], adversarial loss, and `2 loss."@en ;
    askg-onto:inSentence "The loss function is a combination of relativistic GAN loss [27], adversarial loss, and `2 loss."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2_loss,
        askg-data:Entity-adversarial_loss,
        askg-data:Entity-loss_function,
        askg-data:Entity-relativistic_gan_loss .

askg-data:Paper-c63c8058011e31f2-Section-19 a askg-onto:Section ;
    rdfs:label "Section 19"@en ;
    domo:Text "3.4 Depth-Guided Networks"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191 ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Depth map or transmission map plays a vital role in restoring the underwater image, which is related to the degradation induced by scattering. Therefore, it is a natural choice to predict the depth map or transmission map of the underwater image to improve the performance of enhancement and restoration. We list the depth-guided networks next."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191-Sentence-1911,
        askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191-Sentence-1912,
        askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191-Sentence-1913 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191-Sentence-1911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Depth map or transmission map plays a vital role in restoring the underwater image, which is related to the degradation induced by scattering."@en ;
    askg-onto:inSentence "Depth map or transmission map plays a vital role in restoring the underwater image, which is related to the degradation induced by scattering."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-degradation,
        askg-data:Entity-depth_map,
        askg-data:Entity-restoring_the_underwater_image,
        askg-data:Entity-scattering .

askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191-Sentence-1912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Therefore, it is a natural choice to predict the depth map or transmission map of the underwater image to improve the performance of enhancement and restoration."@en ;
    askg-onto:inSentence "Therefore, it is a natural choice to predict the depth map or transmission map of the underwater image to improve the performance of enhancement and restoration."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_map,
        askg-data:Entity-enhancement,
        askg-data:Entity-performance,
        askg-data:Entity-restoration,
        askg-data:Entity-transmission_map,
        askg-data:Entity-underwater_image .

askg-data:Paper-c63c8058011e31f2-Section-19-Paragraph-191-Sentence-1913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We list the depth-guided networks next."@en ;
    askg-onto:inSentence "We list the depth-guided networks next."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth-guided_networks .

askg-data:Paper-c63c8058011e31f2-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "1 Introduction"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-22,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "'Sit, be still, and listen.' Rumi Nowadays, developing, exploring, and protecting the ocean's resources have become the strategy center in the international community. Clear underwater images and videos can provide valuable information of the underwater world, which are essential for numerous engineering and research tasks such as underwater archaeology, underwater surveillance, *etc.* However, the raw underwater images and videos usually suffer from the effects of quality degradation, especially the impact of backscatter in far distances. The issues of quality degradation are mainly introduced by light selective absorption and scattering in water as well as the use of artificial light in deep water. The degraded underwater images have low contrast and brightness, color deviations, blurry details, and uneven bright speck, which limit their applications in practical scenarios. As an indispensable processing step, underwater image enhancement methods"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-211,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-212,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-213,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-214,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-215 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "'Sit, be still, and listen.' Rumi Nowadays, developing, exploring, and protecting the ocean's resources have become the strategy center in the international community."@en ;
    askg-onto:inSentence "'Sit, be still, and listen.' Rumi Nowadays, developing, exploring, and protecting the ocean's resources have become the strategy center in the international community."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-international_community,
        askg-data:Entity-oceans_resources,
        askg-data:Entity-rumi .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Clear underwater images and videos can provide valuable information of the underwater world, which are essential for numerous engineering and research tasks such as underwater archaeology, underwater surveillance, *etc.* However, the raw underwater images and videos usually suffer from the effects of quality degradation, especially the impact of backscatter in far distances."@en ;
    askg-onto:inSentence "Clear underwater images and videos can provide valuable information of the underwater world, which are essential for numerous engineering and research tasks such as underwater archaeology, underwater surveillance, *etc.* However, the raw underwater images and videos usually suffer from the effects of quality degradation, especially the impact of backscatter in far distances."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backscatter,
        askg-data:Entity-engineering_and_research,
        askg-data:Entity-quality_degradation,
        askg-data:Entity-raw_underwater_images_and_videos,
        askg-data:Entity-underwater_archaeology,
        askg-data:Entity-underwater_images,
        askg-data:Entity-underwater_images_and_videos,
        askg-data:Entity-underwater_surveillance,
        askg-data:Entity-underwater_videos,
        askg-data:Entity-valuable_information .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The issues of quality degradation are mainly introduced by light selective absorption and scattering in water as well as the use of artificial light in deep water."@en ;
    askg-onto:inSentence "The issues of quality degradation are mainly introduced by light selective absorption and scattering in water as well as the use of artificial light in deep water."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-light_selective_absorption_and_scattering_in_water,
        askg-data:Entity-quality_degradation,
        askg-data:Entity-the_use_of_artificial_light_in_deep_water .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The degraded underwater images have low contrast and brightness, color deviations, blurry details, and uneven bright speck, which limit their applications in practical scenarios."@en ;
    askg-onto:inSentence "The degraded underwater images have low contrast and brightness, color deviations, blurry details, and uneven bright speck, which limit their applications in practical scenarios."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-applications_in_practical_scenarios,
        askg-data:Entity-blurry_details,
        askg-data:Entity-color_deviations,
        askg-data:Entity-low_contrast_and_brightness,
        askg-data:Entity-underwater_images,
        askg-data:Entity-uneven_bright_speck .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-21-Sentence-215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "As an indispensable processing step, underwater image enhancement methods"@en ;
    askg-onto:inSentence "As an indispensable processing step, underwater image enhancement methods"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-processing_step,
        askg-data:Entity-underwater_image_enhancement_methods .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-22 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "S. Anwar is a research fellow Data61, CSIRO, ACT 2601, AU ranging from the conventional techniques (*e.g.*, physical model-based methods, and histogram equalizationbased methods) to the data-driven techniques (e.g., convolutional neural networks, and generative adversarial networks) have been attracting increasing attention."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-22-Sentence-221,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-22-Sentence-222 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-22-Sentence-221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "S."@en ;
    askg-onto:inSentence "S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-s .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-22-Sentence-222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Anwar is a research fellow Data61, CSIRO, ACT 2601, AU ranging from the conventional techniques (*e.g.*, physical model-based methods, and histogram equalizationbased methods) to the data-driven techniques (e.g., convolutional neural networks, and generative adversarial networks) have been attracting increasing attention."@en ;
    askg-onto:inSentence "Anwar is a research fellow Data61, CSIRO, ACT 2601, AU ranging from the conventional techniques (*e.g.*, physical model-based methods, and histogram equalizationbased methods) to the data-driven techniques (e.g., convolutional neural networks, and generative adversarial networks) have been attracting increasing attention."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anwar,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-csiro,
        askg-data:Entity-data-driven_technique,
        askg-data:Entity-data61,
        askg-data:Entity-generative_adversarial_networks,
        askg-data:Entity-histogram_equalizationbased_methods,
        askg-data:Entity-physical_model-based_methods,
        askg-data:Entity-research_fellow,
        askg-data:Entity-technique .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The past few decades have seen the rapid development of deep learning techniques, which have been extensively applied in various computer vision and image processing tasks [31]. Deep learning has significantly improved the performance of high-level vision tasks such as object detection [47] and object recognition [19]. Moreover, the low-level vision tasks, such as image superresolution [15] and image denoising [65], also benefit from the advantages of deep networks and deliver stateof-the-art performance. Unfortunately, we are unable to observe the appealing performance of deep learningbased underwater image enhancement, although lots of researchers have attempted to utilize the deep learning techniques to the underwater image enhancement."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-231,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-232,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-233,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-234 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The past few decades have seen the rapid development of deep learning techniques, which have been extensively applied in various computer vision and image processing tasks [31]."@en ;
    askg-onto:inSentence "The past few decades have seen the rapid development of deep learning techniques, which have been extensively applied in various computer vision and image processing tasks [31]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision_and_image_processing_tasks,
        askg-data:Entity-deep_learning_techniques .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Deep learning has significantly improved the performance of high-level vision tasks such as object detection [47] and object recognition [19]."@en ;
    askg-onto:inSentence "Deep learning has significantly improved the performance of high-level vision tasks such as object detection [47] and object recognition [19]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-high-level_vision_tasks,
        askg-data:Entity-object_detection,
        askg-data:Entity-object_recognition,
        askg-data:Entity-performance_of_high-level_vision_tasks .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Moreover, the low-level vision tasks, such as image superresolution [15] and image denoising [65], also benefit from the advantages of deep networks and deliver stateof-the-art performance."@en ;
    askg-onto:inSentence "Moreover, the low-level vision tasks, such as image superresolution [15] and image denoising [65], also benefit from the advantages of deep networks and deliver stateof-the-art performance."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_networks,
        askg-data:Entity-image_denoising,
        askg-data:Entity-image_superresolution,
        askg-data:Entity-state-of-the-art_performance .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-23-Sentence-234 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Unfortunately, we are unable to observe the appealing performance of deep learningbased underwater image enhancement, although lots of researchers have attempted to utilize the deep learning techniques to the underwater image enhancement."@en ;
    askg-onto:inSentence "Unfortunately, we are unable to observe the appealing performance of deep learningbased underwater image enhancement, although lots of researchers have attempted to utilize the deep learning techniques to the underwater image enhancement."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_underwater_image_enhancement,
        askg-data:Entity-deep_learning_techniques,
        askg-data:Entity-researchers,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "In this paper, we mainly focus on deep learning method, which enhance and restore underwater images. Through this exposition, we provide the latest development and comparison of current deep underwater image restoration and enhancement algorithms. Furthermore, we summarize the existing issues, analyze the potential reasons, and suggest future research directions. The main contributions of this paper are two-fold: - We summarize the deep learning-based underwater image enhancement algorithms, including network architectures, network parameters, training data, loss function, and training configurations. It provides, to the best of our knowledge, the first comprehensive and in-depth survey for deep learning-based underwater image enhancement, which is helpful for developing more robust and effective deep algorithms."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-241,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-242,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-243,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-244,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-245 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this paper, we mainly focus on deep learning method, which enhance and restore underwater images."@en ;
    askg-onto:inSentence "In this paper, we mainly focus on deep learning method, which enhance and restore underwater images."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_method,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Through this exposition, we provide the latest development and comparison of current deep underwater image restoration and enhancement algorithms."@en ;
    askg-onto:inSentence "Through this exposition, we provide the latest development and comparison of current deep underwater image restoration and enhancement algorithms."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_underwater_image_restoration_and_enhancement_algorithms,
        askg-data:Entity-latest_development_and_comparison .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-243 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, we summarize the existing issues, analyze the potential reasons, and suggest future research directions."@en ;
    askg-onto:inSentence "Furthermore, we summarize the existing issues, analyze the potential reasons, and suggest future research directions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-existing_issues,
        askg-data:Entity-future,
        askg-data:Entity-issues,
        askg-data:Entity-potential_reasons,
        askg-data:Entity-reasons,
        askg-data:Entity-research_directions .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-244 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The main contributions of this paper are two-fold: - We summarize the deep learning-based underwater image enhancement algorithms, including network architectures, network parameters, training data, loss function, and training configurations."@en ;
    askg-onto:inSentence "The main contributions of this paper are two-fold: - We summarize the deep learning-based underwater image enhancement algorithms, including network architectures, network parameters, training data, loss function, and training configurations."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_underwater_image_enhancement_algorithms,
        askg-data:Entity-loss_function,
        askg-data:Entity-network_architectures,
        askg-data:Entity-network_parameters,
        askg-data:Entity-training_configurations,
        askg-data:Entity-training_data .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-24-Sentence-245 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "It provides, to the best of our knowledge, the first comprehensive and in-depth survey for deep learning-based underwater image enhancement, which is helpful for developing more robust and effective deep algorithms."@en ;
    askg-onto:inSentence "It provides, to the best of our knowledge, the first comprehensive and in-depth survey for deep learning-based underwater image enhancement, which is helpful for developing more robust and effective deep algorithms."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_underwater_image_enhancement,
        askg-data:Entity-developing_more_robust_and_effective_deep_algorithms,
        askg-data:Entity-survey .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "- We conduct the systematic experiments on diverse datasets to qualitatively and quantitatively compare the deep learning-based underwater image enhancement algorithms. Our evaluation and analysis demonstrate the performance of current deep algorithms, point out their limitations, and indicates the bias of existing benchmark datasets and evaluation metrics. As a consequence, we give potential insights for future research directions in this field of study. The rest of the paper is organized as follows. Section 2 introduces the background of underwater image enhancement and restoration, mainly focusing on the imaging models. Section 3 presents the existing deep learning-based underwater image enhancement algorithms and insights into the network. Section 4 gives the experimental quantitative and qualitative results and analysis, evaluation metrics, and datasets. Section 5 suggests future research directions, and Section 6 concludes this paper."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-251,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-252,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-253,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-254,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-255,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-256,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-257,
        askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-258 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- We conduct the systematic experiments on diverse datasets to qualitatively and quantitatively compare the deep learning-based underwater image enhancement algorithms."@en ;
    askg-onto:inSentence "- We conduct the systematic experiments on diverse datasets to qualitatively and quantitatively compare the deep learning-based underwater image enhancement algorithms."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-deep_learning-based_underwater_image_enhancement_algorithms,
        askg-data:Entity-experiments .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Our evaluation and analysis demonstrate the performance of current deep algorithms, point out their limitations, and indicates the bias of existing benchmark datasets and evaluation metrics."@en ;
    askg-onto:inSentence "Our evaluation and analysis demonstrate the performance of current deep algorithms, point out their limitations, and indicates the bias of existing benchmark datasets and evaluation metrics."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-benchmark_datasets,
        askg-data:Entity-bias,
        askg-data:Entity-deep_algorithms,
        askg-data:Entity-evaluation_metrics,
        askg-data:Entity-performance .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-253 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As a consequence, we give potential insights for future research directions in this field of study."@en ;
    askg-onto:inSentence "As a consequence, we give potential insights for future research directions in this field of study."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-field_of_study,
        askg-data:Entity-future_research_directions .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-254 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The rest of the paper is organized as follows."@en ;
    askg-onto:inSentence "The rest of the paper is organized as follows."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-follows,
        askg-data:Entity-paper .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-255 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Section 2 introduces the background of underwater image enhancement and restoration, mainly focusing on the imaging models."@en ;
    askg-onto:inSentence "Section 2 introduces the background of underwater image enhancement and restoration, mainly focusing on the imaging models."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-background,
        askg-data:Entity-imaging_models,
        askg-data:Entity-underwater_image_enhancement,
        askg-data:Entity-underwater_image_restoration .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-256 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Section 3 presents the existing deep learning-based underwater image enhancement algorithms and insights into the network."@en ;
    askg-onto:inSentence "Section 3 presents the existing deep learning-based underwater image enhancement algorithms and insights into the network."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_underwater_image_enhancement_algorithms,
        askg-data:Entity-existing_algorithms,
        askg-data:Entity-network .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-257 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Section 4 gives the experimental quantitative and qualitative results and analysis, evaluation metrics, and datasets."@en ;
    askg-onto:inSentence "Section 4 gives the experimental quantitative and qualitative results and analysis, evaluation metrics, and datasets."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-datasets,
        askg-data:Entity-evaluation_metrics,
        askg-data:Entity-section_4,
        askg-data:Entity-the_experimental_quantitative_and_qualitative_results .

askg-data:Paper-c63c8058011e31f2-Section-2-Paragraph-25-Sentence-258 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Section 5 suggests future research directions, and Section 6 concludes this paper."@en ;
    askg-onto:inSentence "Section 5 suggests future research directions, and Section 6 concludes this paper."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_research_directions,
        askg-data:Entity-section_5,
        askg-data:Entity-section_6,
        askg-data:Entity-this_paper .

askg-data:Paper-c63c8058011e31f2-Section-20 a askg-onto:Section ;
    rdfs:label "Section 20"@en ;
    domo:Text "3.4.1 Urcnn"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202 ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Underwater residual convolutional neural network (UR- CNN) [21] is proposed by Hou *et al.*, which aims to learn the transmission map. The URCNN, in the first, uses a convolutional layer followed by ReLU to extract features. The batch normalization and ReLU succeed the second Conv layer. This pattern is repeated until the reconstruction layer, where only the convolutional layer is employed to output the transmission map. A global skip connection is used to enforce residual learning. The output transmission map is used to refine the input image."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2011,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2012,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2013,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2014,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2015,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2016 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Underwater residual convolutional neural network (UR- CNN) [21] is proposed by Hou *et al.*, which aims to learn the transmission map."@en ;
    askg-onto:inSentence "Underwater residual convolutional neural network (UR- CNN) [21] is proposed by Hou *et al.*, which aims to learn the transmission map."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hou_et_al,
        askg-data:Entity-underwater_residual_convolutional_neural_network_ur-_cnn .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The URCNN, in the first, uses a convolutional layer followed by ReLU to extract features."@en ;
    askg-onto:inSentence "The URCNN, in the first, uses a convolutional layer followed by ReLU to extract features."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_layer,
        askg-data:Entity-features,
        askg-data:Entity-relu,
        askg-data:Entity-urcnn .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The batch normalization and ReLU succeed the second Conv layer."@en ;
    askg-onto:inSentence "The batch normalization and ReLU succeed the second Conv layer."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-conv_layer,
        askg-data:Entity-relu .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This pattern is repeated until the reconstruction layer, where only the convolutional layer is employed to output the transmission map."@en ;
    askg-onto:inSentence "This pattern is repeated until the reconstruction layer, where only the convolutional layer is employed to output the transmission map."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_layer,
        askg-data:Entity-reconstruction_layer,
        askg-data:Entity-transmission_map .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2015 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "A global skip connection is used to enforce residual learning."@en ;
    askg-onto:inSentence "A global skip connection is used to enforce residual learning."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-global_skip_connection,
        askg-data:Entity-residual_learning .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-201-Sentence-2016 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The output transmission map is used to refine the input image."@en ;
    askg-onto:inSentence "The output transmission map is used to refine the input image."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_image,
        askg-data:Entity-output_transmission_map .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The network architecture of the URCNN is a modified version of VGG [51] and the input to the network is 180×180 transmission map instead of the original image. The underwater images are generated from randomly selected 1000 NYU dataset [50] images. Furthermore, using random medium attenuation coefficient and background light, a total of 1800 images are generated for training and 200 images for testing. The initial learning rate is selected to be 10−1 and reduced to 10−4 for 60 epochs. The depth of the network is 25 layers with each layer having 64 feature maps and a filter size of 3×3. Similar to [56], the loss used for learning is `2."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2021,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2022,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2023,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2024,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2025,
        askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2026 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The network architecture of the URCNN is a modified version of VGG [51] and the input to the network is 180×180 transmission map instead of the original image."@en ;
    askg-onto:inSentence "The network architecture of the URCNN is a modified version of VGG [51] and the input to the network is 180×180 transmission map instead of the original image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-180180_transmission_map,
        askg-data:Entity-input,
        askg-data:Entity-urcnn,
        askg-data:Entity-vgg .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The underwater images are generated from randomly selected 1000 NYU dataset [50] images."@en ;
    askg-onto:inSentence "The underwater images are generated from randomly selected 1000 NYU dataset [50] images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nyu_dataset,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, using random medium attenuation coefficient and background light, a total of 1800 images are generated for training and 200 images for testing."@en ;
    askg-onto:inSentence "Furthermore, using random medium attenuation coefficient and background light, a total of 1800 images are generated for training and 200 images for testing."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-background_light,
        askg-data:Entity-images,
        askg-data:Entity-random_medium_attenuation_coefficient,
        askg-data:Entity-testing,
        askg-data:Entity-training,
        askg-data:Entity-training_of_images .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The initial learning rate is selected to be 10−1 and reduced to 10−4 for 60 epochs."@en ;
    askg-onto:inSentence "The initial learning rate is selected to be 10−1 and reduced to 10−4 for 60 epochs."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-101,
        askg-data:Entity-104,
        askg-data:Entity-60,
        askg-data:Entity-epochs,
        askg-data:Entity-learning_rate .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The depth of the network is 25 layers with each layer having 64 feature maps and a filter size of 3×3."@en ;
    askg-onto:inSentence "The depth of the network is 25 layers with each layer having 64 feature maps and a filter size of 3×3."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-25_layers,
        askg-data:Entity-33,
        askg-data:Entity-64_feature_maps,
        askg-data:Entity-layer,
        askg-data:Entity-network .

askg-data:Paper-c63c8058011e31f2-Section-20-Paragraph-202-Sentence-2026 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Similar to [56], the loss used for learning is `2."@en ;
    askg-onto:inSentence "Similar to [56], the loss used for learning is `2."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2,
        askg-data:Entity-loss .

askg-data:Paper-c63c8058011e31f2-Section-21 a askg-onto:Section ;
    rdfs:label "Section 21"@en ;
    domo:Text "3.4.2 Uir-Net"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216 ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Cao *et al.* [8] lately developed a deep network for underwater image restoration inspired by classical methods where the transmission map and the background light are estimated and computed independently. Consequently, two different network architectures were proposed *i.e.* the light network (BL-Net) and the transmission map network (TM-Net) while collectively, the network is called UIR-Net [8]. The background light network (BL-Net) is simple and consists of five layers. The initial three layers are convolutional with BN and pooling. The last two layers are fully connected ones."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2111,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2112,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2113,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2114,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2115 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Cao *et al.* [8] lately developed a deep network for underwater image restoration inspired by classical methods where the transmission map and the background light are estimated and computed independently."@en ;
    askg-onto:inSentence "Cao *et al.* [8] lately developed a deep network for underwater image restoration inspired by classical methods where the transmission map and the background light are estimated and computed independently."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-background_light,
        askg-data:Entity-cao_et_al,
        askg-data:Entity-classical_methods,
        askg-data:Entity-deep_network_for_underwater_image_restoration,
        askg-data:Entity-transmission_map .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Consequently, two different network architectures were proposed *i.e.* the light network (BL-Net) and the transmission map network (TM-Net) while collectively, the network is called UIR-Net [8]."@en ;
    askg-onto:inSentence "Consequently, two different network architectures were proposed *i.e.* the light network (BL-Net) and the transmission map network (TM-Net) while collectively, the network is called UIR-Net [8]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-light_network,
        askg-data:Entity-light_network_and_transmission_map_network,
        askg-data:Entity-transmission_map_network,
        askg-data:Entity-uir-net .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The background light network (BL-Net) is simple and consists of five layers."@en ;
    askg-onto:inSentence "The background light network (BL-Net) is simple and consists of five layers."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-background_light_network,
        askg-data:Entity-bl-net,
        askg-data:Entity-five_layers .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The initial three layers are convolutional with BN and pooling."@en ;
    askg-onto:inSentence "The initial three layers are convolutional with BN and pooling."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bn,
        askg-data:Entity-convolutional,
        askg-data:Entity-initial_three_layers,
        askg-data:Entity-pooling .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-211-Sentence-2115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The last two layers are fully connected ones."@en ;
    askg-onto:inSentence "The last two layers are fully connected ones."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fully_connected_ones,
        askg-data:Entity-last_two_layers .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The output of this BL-Net is thresholded to constrain it, in the range of [0,1]. The transmission map network (TM-Net) is more complicated and is based on [11], consisting of two subnets, *i.e.*, coarse-global subnet, and refine subnet. The coarse subnet is made of five convolutional layers, with the first two convolutional layers having pooling and batch normalization. The last layers of the coarse-global subnet are fully connected ones. The refined subnet has three convolutional layers and an upsampling layer which lies before the final convolutional layer. The output of this network is the depth map. Using depth maps, the transmission maps are computed. As a last preprocessing step, the guided filter [18] is applied to refine the maps further."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2121,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2122,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2123,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2124,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2125,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2126,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2127,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2128 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The output of this BL-Net is thresholded to constrain it, in the range of [0,1]."@en ;
    askg-onto:inSentence "The output of this BL-Net is thresholded to constrain it, in the range of [0,1]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bl-net,
        askg-data:Entity-thresholded .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The transmission map network (TM-Net) is more complicated and is based on [11], consisting of two subnets, *i.e.*, coarse-global subnet, and refine subnet."@en ;
    askg-onto:inSentence "The transmission map network (TM-Net) is more complicated and is based on [11], consisting of two subnets, *i.e.*, coarse-global subnet, and refine subnet."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coarse-global_subnet,
        askg-data:Entity-refine_subnet,
        askg-data:Entity-transmission_map_network_tm-net .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The coarse subnet is made of five convolutional layers, with the first two convolutional layers having pooling and batch normalization."@en ;
    askg-onto:inSentence "The coarse subnet is made of five convolutional layers, with the first two convolutional layers having pooling and batch normalization."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-coarse_subnet,
        askg-data:Entity-first_two_convolutional_layers,
        askg-data:Entity-five_convolutional_layers,
        askg-data:Entity-pooling .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The last layers of the coarse-global subnet are fully connected ones."@en ;
    askg-onto:inSentence "The last layers of the coarse-global subnet are fully connected ones."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coarse-global_subnet,
        askg-data:Entity-fully_connected_layers .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The refined subnet has three convolutional layers and an upsampling layer which lies before the final convolutional layer."@en ;
    askg-onto:inSentence "The refined subnet has three convolutional layers and an upsampling layer which lies before the final convolutional layer."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_layers,
        askg-data:Entity-final_convolutional_layer,
        askg-data:Entity-refined_subnet,
        askg-data:Entity-upsampling_layer .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2126 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The output of this network is the depth map."@en ;
    askg-onto:inSentence "The output of this network is the depth map."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_map,
        askg-data:Entity-network .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2127 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Using depth maps, the transmission maps are computed."@en ;
    askg-onto:inSentence "Using depth maps, the transmission maps are computed."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_maps,
        askg-data:Entity-transmission_maps .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-212-Sentence-2128 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "As a last preprocessing step, the guided filter [18] is applied to refine the maps further."@en ;
    askg-onto:inSentence "As a last preprocessing step, the guided filter [18] is applied to refine the maps further."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guided_filter,
        askg-data:Entity-maps .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The loss for the BL-Net is Euclidean while for the TM-Net is a scale-invariant minimum square error (MSE) adopted from Eigen *et al.* [11]. Similar to [56], UIR- Net [8] use NYU-v2 dataset [50] to generate 12,000 synthetic underwater images using a total of 29 different underwater ambient lights. The BL-Net is initialized randomly, while TM-Net utilizes the weights from VGG [51]."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213-Sentence-2131,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213-Sentence-2132,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213-Sentence-2133 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213-Sentence-2131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The loss for the BL-Net is Euclidean while for the TM-Net is a scale-invariant minimum square error (MSE) adopted from Eigen *et al.* [11]."@en ;
    askg-onto:inSentence "The loss for the BL-Net is Euclidean while for the TM-Net is a scale-invariant minimum square error (MSE) adopted from Eigen *et al.* [11]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11,
        askg-data:Entity-bl-net,
        askg-data:Entity-eigen_et_al,
        askg-data:Entity-euclidean,
        askg-data:Entity-scale-invariant_minimum_square_error_mse,
        askg-data:Entity-tm-net .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213-Sentence-2132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Similar to [56], UIR- Net [8] use NYU-v2 dataset [50] to generate 12,000 synthetic underwater images using a total of 29 different underwater ambient lights."@en ;
    askg-onto:inSentence "Similar to [56], UIR- Net [8] use NYU-v2 dataset [50] to generate 12,000 synthetic underwater images using a total of 29 different underwater ambient lights."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-12000_synthetic_underwater_images,
        askg-data:Entity-29_different_underwater_ambient_lights,
        askg-data:Entity-nyu-v2_dataset,
        askg-data:Entity-uir-net .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-213-Sentence-2133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The BL-Net is initialized randomly, while TM-Net utilizes the weights from VGG [51]."@en ;
    askg-onto:inSentence "The BL-Net is initialized randomly, while TM-Net utilizes the weights from VGG [51]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bl-net,
        askg-data:Entity-randomly,
        askg-data:Entity-tm-net,
        askg-data:Entity-vgg,
        askg-data:Entity-weights,
        askg-data:Entity-weights_from_vgg .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "3.4.3 WaterGAN WaterGAN [38] as the name indicates, is a generative adversarial network, which manipulates RGB-D images to simulate underwater images for color correction. The authors present a two-part solution where the first part in the pipeline is the WaterGAN [38], and the second part is the image restoration network, composed of a depth estimation network and a color correction network. The WaterGAN has two systems: a generator G and discriminator D. The generator is a noise vector, which is projected, reshaped and passed through several convolutional and deconvolutional layers which output a synthetic image. The discriminator distinguishes between real image (from another dataset) and synthetic (generated by generator). The generator aims to create images which the discriminator classify as real."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2141,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2142,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2143,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2144,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2145,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2146 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3.4.3 WaterGAN WaterGAN [38] as the name indicates, is a generative adversarial network, which manipulates RGB-D images to simulate underwater images for color correction."@en ;
    askg-onto:inSentence "3.4.3 WaterGAN WaterGAN [38] as the name indicates, is a generative adversarial network, which manipulates RGB-D images to simulate underwater images for color correction."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-color_correction,
        askg-data:Entity-generative_adversarial_network,
        askg-data:Entity-rgb-d_images,
        askg-data:Entity-underwater_images,
        askg-data:Entity-watergan .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The authors present a two-part solution where the first part in the pipeline is the WaterGAN [38], and the second part is the image restoration network, composed of a depth estimation network and a color correction network."@en ;
    askg-onto:inSentence "The authors present a two-part solution where the first part in the pipeline is the WaterGAN [38], and the second part is the image restoration network, composed of a depth estimation network and a color correction network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-color_correction_network,
        askg-data:Entity-depth_estimation_network,
        askg-data:Entity-image_restoration_network,
        askg-data:Entity-tool,
        askg-data:Entity-watergan .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The WaterGAN has two systems: a generator G and discriminator D."@en ;
    askg-onto:inSentence "The WaterGAN has two systems: a generator G and discriminator D."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discriminator_d,
        askg-data:Entity-generator_g,
        askg-data:Entity-watergan .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The generator is a noise vector, which is projected, reshaped and passed through several convolutional and deconvolutional layers which output a synthetic image."@en ;
    askg-onto:inSentence "The generator is a noise vector, which is projected, reshaped and passed through several convolutional and deconvolutional layers which output a synthetic image."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generator,
        askg-data:Entity-layers,
        askg-data:Entity-noise_vector,
        askg-data:Entity-synthetic_image .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2145 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The discriminator distinguishes between real image (from another dataset) and synthetic (generated by generator)."@en ;
    askg-onto:inSentence "The discriminator distinguishes between real image (from another dataset) and synthetic (generated by generator)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discriminator,
        askg-data:Entity-generator,
        askg-data:Entity-real_image,
        askg-data:Entity-synthetic .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-214-Sentence-2146 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The generator aims to create images which the discriminator classify as real."@en ;
    askg-onto:inSentence "The generator aims to create images which the discriminator classify as real."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discriminator,
        askg-data:Entity-generator,
        askg-data:Entity-images,
        askg-data:Entity-real .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "The underwater images generated by [38] are passed through an image restoration network. The network is inspired by an encoder-decoder architecture, particularly, pixel-wise dense learning, and SegNet [5]. The SegNet uses a non-parametric upsampling layer which benefits from the max-pooling index information in the encoder. Furthermore, the authors incorporate the skipping layers in the encoder-decoder architecture to compensate for the high frequencies' loss due to pooling operation."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2151,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2152,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2153,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2154 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The underwater images generated by [38] are passed through an image restoration network."@en ;
    askg-onto:inSentence "The underwater images generated by [38] are passed through an image restoration network."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_restoration_network,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The network is inspired by an encoder-decoder architecture, particularly, pixel-wise dense learning, and SegNet [5]."@en ;
    askg-onto:inSentence "The network is inspired by an encoder-decoder architecture, particularly, pixel-wise dense learning, and SegNet [5]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_architecture,
        askg-data:Entity-network,
        askg-data:Entity-pixel-wise_dense_learning,
        askg-data:Entity-segnet .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The SegNet uses a non-parametric upsampling layer which benefits from the max-pooling index information in the encoder."@en ;
    askg-onto:inSentence "The SegNet uses a non-parametric upsampling layer which benefits from the max-pooling index information in the encoder."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-max-pooling_index_information,
        askg-data:Entity-non-parametric_upsampling_layer,
        askg-data:Entity-segnet .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-215-Sentence-2154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Furthermore, the authors incorporate the skipping layers in the encoder-decoder architecture to compensate for the high frequencies' loss due to pooling operation."@en ;
    askg-onto:inSentence "Furthermore, the authors incorporate the skipping layers in the encoder-decoder architecture to compensate for the high frequencies' loss due to pooling operation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-authors,
        askg-data:Entity-encoder-decoder_architecture,
        askg-data:Entity-high_frequencies_loss,
        askg-data:Entity-pooling_operation,
        askg-data:Entity-skipping_layers .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "The authors collect 7,000 images from Michigan's Marine Hydrodynamics Laboratory. Another 6,500 images are collected from Port Royal, Jamaica. Similarly, 6,083 images are gathered from the coral reef system, Australia [45]. Besides, four Kinect datasets *i.e.* the B3DO [24], the UW RGB-D [30], the NYU [50] and the Microsoft 7-scenes [49], are utilized to form 15,000 underwater images via WaterGAN, out of which 12,000 are used for training and 3,000 for testing. The depth estimation network is trained separately at a fixed learning rate of 10−6 while the color correction network is initially trained with an input resolution of 128 × 128 having learning rate 10−6. After that, the authors refined the color correction network with input images of 512 × 512 resolution, reducing the base learning rate to 10−7. The `2 loss is utilized for depth estimation and color correction networks, and further, as a postprocessing step, the images are normalized *i.e.* [0,1]."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2161,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2162,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2163,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2164,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2165,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2166,
        askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2167 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The authors collect 7,000 images from Michigan's Marine Hydrodynamics Laboratory."@en ;
    askg-onto:inSentence "The authors collect 7,000 images from Michigan's Marine Hydrodynamics Laboratory."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7000_images,
        askg-data:Entity-michigans_marine_hydrodynamics_laboratory .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Another 6,500 images are collected from Port Royal, Jamaica."@en ;
    askg-onto:inSentence "Another 6,500 images are collected from Port Royal, Jamaica."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-images .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2163 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Similarly, 6,083 images are gathered from the coral reef system, Australia [45]."@en ;
    askg-onto:inSentence "Similarly, 6,083 images are gathered from the coral reef system, Australia [45]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australia,
        askg-data:Entity-coral_reef_system,
        askg-data:Entity-images .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2164 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Besides, four Kinect datasets *i.e.* the B3DO [24], the UW RGB-D [30], the NYU [50] and the Microsoft 7-scenes [49], are utilized to form 15,000 underwater images via WaterGAN, out of which 12,000 are used for training and 3,000 for testing."@en ;
    askg-onto:inSentence "Besides, four Kinect datasets *i.e.* the B3DO [24], the UW RGB-D [30], the NYU [50] and the Microsoft 7-scenes [49], are utilized to form 15,000 underwater images via WaterGAN, out of which 12,000 are used for training and 3,000 for testing."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-15000_underwater_images,
        askg-data:Entity-b3do,
        askg-data:Entity-kinect_dataset,
        askg-data:Entity-kinect_datasets,
        askg-data:Entity-microsoft_7-scenes,
        askg-data:Entity-nyu,
        askg-data:Entity-testing,
        askg-data:Entity-training,
        askg-data:Entity-underwater_images,
        askg-data:Entity-uw_rgb-d,
        askg-data:Entity-watergan .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2165 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The depth estimation network is trained separately at a fixed learning rate of 10−6 while the color correction network is initially trained with an input resolution of 128 × 128 having learning rate 10−6."@en ;
    askg-onto:inSentence "The depth estimation network is trained separately at a fixed learning rate of 10−6 while the color correction network is initially trained with an input resolution of 128 × 128 having learning rate 10−6."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-color_correction_network,
        askg-data:Entity-depth_estimation_network,
        askg-data:Entity-fixed_learning_rate_of_106,
        askg-data:Entity-input_resolution_of_128__128,
        askg-data:Entity-learning_rate_106 .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2166 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "After that, the authors refined the color correction network with input images of 512 × 512 resolution, reducing the base learning rate to 10−7."@en ;
    askg-onto:inSentence "After that, the authors refined the color correction network with input images of 512 × 512 resolution, reducing the base learning rate to 10−7."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-107,
        askg-data:Entity-authors,
        askg-data:Entity-color_correction_network,
        askg-data:Entity-input_images_of_512__512_resolution,
        askg-data:Entity-learning_rate .

askg-data:Paper-c63c8058011e31f2-Section-21-Paragraph-216-Sentence-2167 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The `2 loss is utilized for depth estimation and color correction networks, and further, as a postprocessing step, the images are normalized *i.e.* [0,1]."@en ;
    askg-onto:inSentence "The `2 loss is utilized for depth estimation and color correction networks, and further, as a postprocessing step, the images are normalized *i.e.* [0,1]."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-01,
        askg-data:Entity-2_loss,
        askg-data:Entity-depth_estimation_and_color_correction_networks,
        askg-data:Entity-images .

askg-data:Paper-c63c8058011e31f2-Section-22 a askg-onto:Section ;
    rdfs:label "Section 22"@en ;
    domo:Text "3.5 Dual Generator Gans"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221 ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The dual generator GANs algorithms for underwater image enhancement employ multiple generators to predict the improved image. Currently, the trend is to use two generators with one discriminator or two generators with two discriminators; either the aim is to share the features between the generators or use the prediction of one generator as an input to the other generator. Examples of the dual generator GANs are the following."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221-Sentence-2211,
        askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221-Sentence-2212,
        askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221-Sentence-2213 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221-Sentence-2211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The dual generator GANs algorithms for underwater image enhancement employ multiple generators to predict the improved image."@en ;
    askg-onto:inSentence "The dual generator GANs algorithms for underwater image enhancement employ multiple generators to predict the improved image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dual_generator_gans,
        askg-data:Entity-generators,
        askg-data:Entity-improved_image,
        askg-data:Entity-multiple_generators .

askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221-Sentence-2212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Currently, the trend is to use two generators with one discriminator or two generators with two discriminators; either the aim is to share the features between the generators or use the prediction of one generator as an input to the other generator."@en ;
    askg-onto:inSentence "Currently, the trend is to use two generators with one discriminator or two generators with two discriminators; either the aim is to share the features between the generators or use the prediction of one generator as an input to the other generator."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-one_discriminator,
        askg-data:Entity-one_generator,
        askg-data:Entity-the_other_generator,
        askg-data:Entity-the_prediction_of_one_generator,
        askg-data:Entity-two_discriminators,
        askg-data:Entity-two_generators .

askg-data:Paper-c63c8058011e31f2-Section-22-Paragraph-221-Sentence-2213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Examples of the dual generator GANs are the following."@en ;
    askg-onto:inSentence "Examples of the dual generator GANs are the following."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dual_generator_gans,
        askg-data:Entity-gans .

askg-data:Paper-c63c8058011e31f2-Section-23 a askg-onto:Section ;
    rdfs:label "Section 23"@en ;
    domo:Text "3.5.1 Uwgan"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232 ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Based on the GANs [13], Li *et al.* [34] proposed a weakly supervised color transfer method for underwater image color correction, called UWGAN. The UWGAN model relaxes the need for paired underwater images for training and allows the underwater images to be regarded in unknown locations, which benefits from adversarial learning. Following the CycleGAN [66], the UWGAN model adopts a cycle structure which includes a forward network and a backward network to learn the mapping functions between a source domain (i.e., underwater) and a target domain (*i.e.*, air). The purpose of such a cycle structure is to capture the unique characteristics of one image collection and figure out how these characteristics could be translated into the other image collection."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2311,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2312,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2313,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2314 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Based on the GANs [13], Li *et al.* [34] proposed a weakly supervised color transfer method for underwater image color correction, called UWGAN."@en ;
    askg-onto:inSentence "Based on the GANs [13], Li *et al.* [34] proposed a weakly supervised color transfer method for underwater image color correction, called UWGAN."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-li_et_al,
        askg-data:Entity-uwgan,
        askg-data:Entity-weakly_supervised_color_transfer_method .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The UWGAN model relaxes the need for paired underwater images for training and allows the underwater images to be regarded in unknown locations, which benefits from adversarial learning."@en ;
    askg-onto:inSentence "The UWGAN model relaxes the need for paired underwater images for training and allows the underwater images to be regarded in unknown locations, which benefits from adversarial learning."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_learning,
        askg-data:Entity-paired_underwater_images,
        askg-data:Entity-underwater_images_to_be_regarded_in_unknown_locations,
        askg-data:Entity-uwgan_model .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Following the CycleGAN [66], the UWGAN model adopts a cycle structure which includes a forward network and a backward network to learn the mapping functions between a source domain (i.e., underwater) and a target domain (*i.e.*, air)."@en ;
    askg-onto:inSentence "Following the CycleGAN [66], the UWGAN model adopts a cycle structure which includes a forward network and a backward network to learn the mapping functions between a source domain (i.e., underwater) and a target domain (*i.e.*, air)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-air,
        askg-data:Entity-backward_network,
        askg-data:Entity-cycle_structure,
        askg-data:Entity-forward_network,
        askg-data:Entity-source_domain,
        askg-data:Entity-target_domain,
        askg-data:Entity-underwater,
        askg-data:Entity-uwgan_model .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-231-Sentence-2314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The purpose of such a cycle structure is to capture the unique characteristics of one image collection and figure out how these characteristics could be translated into the other image collection."@en ;
    askg-onto:inSentence "The purpose of such a cycle structure is to capture the unique characteristics of one image collection and figure out how these characteristics could be translated into the other image collection."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-characteristics,
        askg-data:Entity-cycle_structure,
        askg-data:Entity-image_collection .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The generators used in the UWGAN [34] have the same architecture as [25]. For the discriminators, the UWGAN uses 70×70 PatchGANs [36]. To train the network, 3800 underwater images and 3800 high-quality air images are collected and are resized to 256×256. The final loss function is the linear combination of three-loss functions, including adversarial loss, cycle consistency loss, and SSIM loss. The adversarial loss is to match the distribution of generated images with that of the target domain. The cycle consistency loss is to prevent the learned mappings from contradicting each other. The SSIM loss is to preserve the content and structure of source images."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2321,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2322,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2323,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2324,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2325,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2326,
        askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2327 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The generators used in the UWGAN [34] have the same architecture as [25]."@en ;
    askg-onto:inSentence "The generators used in the UWGAN [34] have the same architecture as [25]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-same_architecture,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For the discriminators, the UWGAN uses 70×70 PatchGANs [36]."@en ;
    askg-onto:inSentence "For the discriminators, the UWGAN uses 70×70 PatchGANs [36]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7070_patchgans,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To train the network, 3800 underwater images and 3800 high-quality air images are collected and are resized to 256×256."@en ;
    askg-onto:inSentence "To train the network, 3800 underwater images and 3800 high-quality air images are collected and are resized to 256×256."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-256256,
        askg-data:Entity-3800_high-quality_air_images,
        askg-data:Entity-3800_underwater_images,
        askg-data:Entity-network .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The final loss function is the linear combination of three-loss functions, including adversarial loss, cycle consistency loss, and SSIM loss."@en ;
    askg-onto:inSentence "The final loss function is the linear combination of three-loss functions, including adversarial loss, cycle consistency loss, and SSIM loss."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_loss,
        askg-data:Entity-cycle_consistency_loss,
        askg-data:Entity-linear_combination,
        askg-data:Entity-loss_function,
        askg-data:Entity-ssim_loss .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2325 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The adversarial loss is to match the distribution of generated images with that of the target domain."@en ;
    askg-onto:inSentence "The adversarial loss is to match the distribution of generated images with that of the target domain."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_loss,
        askg-data:Entity-distribution_of_generated_images,
        askg-data:Entity-target_domain .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2326 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The cycle consistency loss is to prevent the learned mappings from contradicting each other."@en ;
    askg-onto:inSentence "The cycle consistency loss is to prevent the learned mappings from contradicting each other."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cycle_consistency_loss,
        askg-data:Entity-to_prevent_the_learned_mappings_from_contradicting_each_other .

askg-data:Paper-c63c8058011e31f2-Section-23-Paragraph-232-Sentence-2327 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The SSIM loss is to preserve the content and structure of source images."@en ;
    askg-onto:inSentence "The SSIM loss is to preserve the content and structure of source images."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-content_and_structure_of_source_images,
        askg-data:Entity-ssim_loss .

askg-data:Paper-c63c8058011e31f2-Section-24 a askg-onto:Section ;
    rdfs:label "Section 24"@en ;
    domo:Text "3.5.2 Mcyclegan"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243 ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To restore underwater images, Lu *et al.* [39] proposed a Multi-Scale Cycle Generative Adversarial Network (MCycleGAN), which is a variant of the CycleGAN network [66]. The authors incorporate the multiscale SSIM loss into the CycleGAN [66] to improve the image restoration task. The aim is to transfer the underwater style to the recovered style image."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241-Sentence-2411,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241-Sentence-2412,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241-Sentence-2413 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241-Sentence-2411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To restore underwater images, Lu *et al.* [39] proposed a Multi-Scale Cycle Generative Adversarial Network (MCycleGAN), which is a variant of the CycleGAN network [66]."@en ;
    askg-onto:inSentence "To restore underwater images, Lu *et al.* [39] proposed a Multi-Scale Cycle Generative Adversarial Network (MCycleGAN), which is a variant of the CycleGAN network [66]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cyclegan_network,
        askg-data:Entity-lu_et_al,
        askg-data:Entity-multi-scale_cycle_generative_adversarial_network_mcyclegan .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241-Sentence-2412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The authors incorporate the multiscale SSIM loss into the CycleGAN [66] to improve the image restoration task."@en ;
    askg-onto:inSentence "The authors incorporate the multiscale SSIM loss into the CycleGAN [66] to improve the image restoration task."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cyclegan,
        askg-data:Entity-image_restoration_task,
        askg-data:Entity-multiscale_ssim_loss .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-241-Sentence-2413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The aim is to transfer the underwater style to the recovered style image."@en ;
    askg-onto:inSentence "The aim is to transfer the underwater style to the recovered style image."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-recovered_style_image,
        askg-data:Entity-underwater_style .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "As a first step, the dark channel prior (DCP) [17] is used to obtain the transmission map of a turbid underwater image. Additionally, the transmission maps provide depth information in the form of three binary filters. The turbid underwater images are forwarded through the generator network. The turbid and generated clear underwater images are split into R, G, and B channels. The channels are then subjected to different size of sliding windows to compute the SSIM loss between the turbid and generated images. Furthermore, the SSIM maps are multiplied with corresponding filters and added together, which results in the multiscale SSIM map for final loss computation. As a final step, both the real-world underwater image and the computed ones are passed through the discriminator."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2421,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2422,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2423,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2424,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2425,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2426,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2427 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As a first step, the dark channel prior (DCP) [17] is used to obtain the transmission map of a turbid underwater image."@en ;
    askg-onto:inSentence "As a first step, the dark channel prior (DCP) [17] is used to obtain the transmission map of a turbid underwater image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dark_channel_prior,
        askg-data:Entity-transmission_map,
        askg-data:Entity-turbid_underwater_image .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Additionally, the transmission maps provide depth information in the form of three binary filters."@en ;
    askg-onto:inSentence "Additionally, the transmission maps provide depth information in the form of three binary filters."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_information,
        askg-data:Entity-three_binary_filters,
        askg-data:Entity-transmission_maps .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The turbid underwater images are forwarded through the generator network."@en ;
    askg-onto:inSentence "The turbid underwater images are forwarded through the generator network."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generator_network,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The turbid and generated clear underwater images are split into R, G, and B channels."@en ;
    askg-onto:inSentence "The turbid and generated clear underwater images are split into R, G, and B channels."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-r_g_and_b_channels,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The channels are then subjected to different size of sliding windows to compute the SSIM loss between the turbid and generated images."@en ;
    askg-onto:inSentence "The channels are then subjected to different size of sliding windows to compute the SSIM loss between the turbid and generated images."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-channels,
        askg-data:Entity-different_size_of_sliding_windows,
        askg-data:Entity-ssim_loss,
        askg-data:Entity-turbid_and_generated_images .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Furthermore, the SSIM maps are multiplied with corresponding filters and added together, which results in the multiscale SSIM map for final loss computation."@en ;
    askg-onto:inSentence "Furthermore, the SSIM maps are multiplied with corresponding filters and added together, which results in the multiscale SSIM map for final loss computation."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-filters,
        askg-data:Entity-final_loss_computation,
        askg-data:Entity-multiscale_ssim_map,
        askg-data:Entity-ssim_maps .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-242-Sentence-2427 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "As a final step, both the real-world underwater image and the computed ones are passed through the discriminator."@en ;
    askg-onto:inSentence "As a final step, both the real-world underwater image and the computed ones are passed through the discriminator."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computed_ones,
        askg-data:Entity-the_discriminator,
        askg-data:Entity-underwater_image .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "CycleGAN [66] inspired the generator and discriminator of MCycleGAN [39]. More specifically, the generator is adapted from image superresolution by Johnson *et al.* [26] which consists of nine ResNet blocks with training images of size 256×256 while the discriminator is based on 70×70 PatchGANs [23, 33] to differentiate between real and fake image patches. The loss function is a union of the adversarial loss, the cycle-consistent loss, and the multiscale SSIM loss. The dataset is composed of 1,037 turbid underwater images collected from ImageNet [10] and Jiao Zhou Bay, out of which 837 are retained as a training dataset, and the rest 200 are reserved for testing. ADAM [28] is used as an optimizer adopting a fixed learning rate of 0.0002 until convergence."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2431,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2432,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2433,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2434,
        askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2435 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "CycleGAN [66] inspired the generator and discriminator of MCycleGAN [39]."@en ;
    askg-onto:inSentence "CycleGAN [66] inspired the generator and discriminator of MCycleGAN [39]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cyclegan,
        askg-data:Entity-mcyclegan .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "More specifically, the generator is adapted from image superresolution by Johnson *et al.* [26] which consists of nine ResNet blocks with training images of size 256×256 while the discriminator is based on 70×70 PatchGANs [23, 33] to differentiate between real and fake image patches."@en ;
    askg-onto:inSentence "More specifically, the generator is adapted from image superresolution by Johnson *et al.* [26] which consists of nine ResNet blocks with training images of size 256×256 while the discriminator is based on 70×70 PatchGANs [23, 33] to differentiate between real and fake image patches."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-256256,
        askg-data:Entity-7070_patchgans,
        askg-data:Entity-discriminator,
        askg-data:Entity-generator,
        askg-data:Entity-image_superresolution,
        askg-data:Entity-nine_resnet_blocks,
        askg-data:Entity-real_and_fake_image_patches,
        askg-data:Entity-training_images .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The loss function is a union of the adversarial loss, the cycle-consistent loss, and the multiscale SSIM loss."@en ;
    askg-onto:inSentence "The loss function is a union of the adversarial loss, the cycle-consistent loss, and the multiscale SSIM loss."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_loss,
        askg-data:Entity-cycle-consistent_loss,
        askg-data:Entity-loss_function,
        askg-data:Entity-multiscale_ssim_loss .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The dataset is composed of 1,037 turbid underwater images collected from ImageNet [10] and Jiao Zhou Bay, out of which 837 are retained as a training dataset, and the rest 200 are reserved for testing."@en ;
    askg-onto:inSentence "The dataset is composed of 1,037 turbid underwater images collected from ImageNet [10] and Jiao Zhou Bay, out of which 837 are retained as a training dataset, and the rest 200 are reserved for testing."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1037_turbid_underwater_images,
        askg-data:Entity-200,
        askg-data:Entity-837,
        askg-data:Entity-dataset,
        askg-data:Entity-imagenet,
        askg-data:Entity-testing,
        askg-data:Entity-training_dataset .

askg-data:Paper-c63c8058011e31f2-Section-24-Paragraph-243-Sentence-2435 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "ADAM [28] is used as an optimizer adopting a fixed learning rate of 0.0002 until convergence."@en ;
    askg-onto:inSentence "ADAM [28] is used as an optimizer adopting a fixed learning rate of 0.0002 until convergence."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-fixed_learning_rate_of_00002,
        askg-data:Entity-optimizer .

askg-data:Paper-c63c8058011e31f2-Section-25 a askg-onto:Section ;
    rdfs:label "Section 25"@en ;
    domo:Text "3.5.3 Uie-Sgan"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252 ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Yu *et al.* [64] proposed an underwater image enhancement system using stacked conditional generative adversarial networks, abbreviated as UIE-sGAN. The proposed network architecture consists of two subnetworks i.e. haze detection subnetwork and color correction subnetwork. Each subnetwork has a generator and discriminator, and the color correction subnetwork is stacked on the haze detection subnetwork. For the haze detection subnet, the generator is similar to UNET [48] consisting of seven convolutional layers and seven deconvolutional layers, both followed by BN and leaky ReLU except the first convolutional layer where only leaky ReLU is employed and the last deconvolutional layer where TanH nonlinear function is realized. While the discriminator is made of four convolutional layers where the initial layer has leaky ReLU purely, and the subsequent ones have batch normalization and leaky ReLU followed by a sigmoid layer. The output of the haze detection network is a haze mask. The structure of haze detection subnet and the color-correction subnet is identical except that color-correction subnet takes the haze mask and RGB images as input and outputs a color corrected underwater image."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2511,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2512,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2513,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2514,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2515,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2516,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2517,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2518 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Yu *et al.* [64] proposed an underwater image enhancement system using stacked conditional generative adversarial networks, abbreviated as UIE-sGAN."@en ;
    askg-onto:inSentence "Yu *et al.* [64] proposed an underwater image enhancement system using stacked conditional generative adversarial networks, abbreviated as UIE-sGAN."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-stacked_conditional_generative_adversarial_networks,
        askg-data:Entity-uie-sgan,
        askg-data:Entity-underwater_image_enhancement_system,
        askg-data:Entity-yu_et_al .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The proposed network architecture consists of two subnetworks i.e."@en ;
    askg-onto:inSentence "The proposed network architecture consists of two subnetworks i.e."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network_architecture,
        askg-data:Entity-two_subnetworks .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "haze detection subnetwork and color correction subnetwork."@en ;
    askg-onto:inSentence "haze detection subnetwork and color correction subnetwork."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-color_correction_subnetwork,
        askg-data:Entity-haze_detection_subnetwork .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Each subnetwork has a generator and discriminator, and the color correction subnetwork is stacked on the haze detection subnetwork."@en ;
    askg-onto:inSentence "Each subnetwork has a generator and discriminator, and the color correction subnetwork is stacked on the haze detection subnetwork."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-color_correction_subnetwork,
        askg-data:Entity-discriminator,
        askg-data:Entity-generator,
        askg-data:Entity-haze_detection_subnetwork,
        askg-data:Entity-subnetwork .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For the haze detection subnet, the generator is similar to UNET [48] consisting of seven convolutional layers and seven deconvolutional layers, both followed by BN and leaky ReLU except the first convolutional layer where only leaky ReLU is employed and the last deconvolutional layer where TanH nonlinear function is realized."@en ;
    askg-onto:inSentence "For the haze detection subnet, the generator is similar to UNET [48] consisting of seven convolutional layers and seven deconvolutional layers, both followed by BN and leaky ReLU except the first convolutional layer where only leaky ReLU is employed and the last deconvolutional layer where TanH nonlinear function is realized."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bn,
        askg-data:Entity-concept,
        askg-data:Entity-convolutional_layers,
        askg-data:Entity-deconvolutional_layers,
        askg-data:Entity-generator,
        askg-data:Entity-haze_detection_subnet,
        askg-data:Entity-leaky_relu,
        askg-data:Entity-seven_convolutional_layers,
        askg-data:Entity-seven_deconvolutional_layers,
        askg-data:Entity-unet .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "While the discriminator is made of four convolutional layers where the initial layer has leaky ReLU purely, and the subsequent ones have batch normalization and leaky ReLU followed by a sigmoid layer."@en ;
    askg-onto:inSentence "While the discriminator is made of four convolutional layers where the initial layer has leaky ReLU purely, and the subsequent ones have batch normalization and leaky ReLU followed by a sigmoid layer."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-discriminator,
        askg-data:Entity-four_convolutional_layers,
        askg-data:Entity-initial_layer,
        askg-data:Entity-leaky_relu,
        askg-data:Entity-sigmoid_layer,
        askg-data:Entity-subsequent_layers .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2517 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The output of the haze detection network is a haze mask."@en ;
    askg-onto:inSentence "The output of the haze detection network is a haze mask."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-haze_detection_network,
        askg-data:Entity-haze_mask .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-251-Sentence-2518 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "The structure of haze detection subnet and the color-correction subnet is identical except that color-correction subnet takes the haze mask and RGB images as input and outputs a color corrected underwater image."@en ;
    askg-onto:inSentence "The structure of haze detection subnet and the color-correction subnet is identical except that color-correction subnet takes the haze mask and RGB images as input and outputs a color corrected underwater image."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-color-correction_subnet,
        askg-data:Entity-color_corrected_underwater_image,
        askg-data:Entity-haze_detection_subnet,
        askg-data:Entity-haze_mask,
        askg-data:Entity-rgb_images .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The UIE-sGAN [64] has three losses *i.e.* the adversarial loss for each network and a consistency loss. The training is accomplished by using WaterGAN [38] to generate underwater images from NYU-v2 dataset [50]. Out of 1449 images, 1200 are held for training while the network is evaluated on the remaining ones. The images are resized to 286×286 and then cropped to 256×256 and further applying data augmentation. The network is optimized using ADAM by fixing the learning rate as 5×10−5."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2521,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2522,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2523,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2524,
        askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2525 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The UIE-sGAN [64] has three losses *i.e.* the adversarial loss for each network and a consistency loss."@en ;
    askg-onto:inSentence "The UIE-sGAN [64] has three losses *i.e.* the adversarial loss for each network and a consistency loss."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_loss,
        askg-data:Entity-consistency_loss,
        askg-data:Entity-uie-sgan .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The training is accomplished by using WaterGAN [38] to generate underwater images from NYU-v2 dataset [50]."@en ;
    askg-onto:inSentence "The training is accomplished by using WaterGAN [38] to generate underwater images from NYU-v2 dataset [50]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-nyu-v2_dataset,
        askg-data:Entity-underwater_images,
        askg-data:Entity-watergan .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Out of 1449 images, 1200 are held for training while the network is evaluated on the remaining ones."@en ;
    askg-onto:inSentence "Out of 1449 images, 1200 are held for training while the network is evaluated on the remaining ones."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1200,
        askg-data:Entity-1449_images,
        askg-data:Entity-network,
        askg-data:Entity-remaining_ones .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The images are resized to 286×286 and then cropped to 256×256 and further applying data augmentation."@en ;
    askg-onto:inSentence "The images are resized to 286×286 and then cropped to 256×256 and further applying data augmentation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-256256,
        askg-data:Entity-286286,
        askg-data:Entity-data_augmentation,
        askg-data:Entity-images .

askg-data:Paper-c63c8058011e31f2-Section-25-Paragraph-252-Sentence-2525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The network is optimized using ADAM by fixing the learning rate as 5×10−5."@en ;
    askg-onto:inSentence "The network is optimized using ADAM by fixing the learning rate as 5×10−5."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5105,
        askg-data:Entity-adam,
        askg-data:Entity-learning_rate,
        askg-data:Entity-network .

askg-data:Paper-c63c8058011e31f2-Section-26 a askg-onto:Section ;
    rdfs:label "Section 26"@en ;
    domo:Text "3.6 Network Specifics"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-261,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-263,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-266,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-267,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-268 ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-261 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "After reviewing current deep learning-based underwater image enhancement algorithms, we emphasize the different aspects of the above-mentioned deep models. First, we summarize the network specifics of different models in Table 1 and then further analyze network loss, depth, parameters, and input patch size."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-261-Sentence-2611,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-261-Sentence-2612 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-261-Sentence-2611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "After reviewing current deep learning-based underwater image enhancement algorithms, we emphasize the different aspects of the above-mentioned deep models."@en ;
    askg-onto:inSentence "After reviewing current deep learning-based underwater image enhancement algorithms, we emphasize the different aspects of the above-mentioned deep models."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_underwater_image_enhancement_algorithms,
        askg-data:Entity-different_aspects .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-261-Sentence-2612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "First, we summarize the network specifics of different models in Table 1 and then further analyze network loss, depth, parameters, and input patch size."@en ;
    askg-onto:inSentence "First, we summarize the network specifics of different models in Table 1 and then further analyze network loss, depth, parameters, and input patch size."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth,
        askg-data:Entity-input_patch_size,
        askg-data:Entity-models,
        askg-data:Entity-network_loss,
        askg-data:Entity-network_specifics,
        askg-data:Entity-parameters .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Network Loss Network loss plays an integral part in learning the task underhand. Here, we discuss the losses employed in deep underwater image enhancement. The most popular type of loss functions are to minimize the per-pixel error between the ground-truth image and the predicted image, commonly known as `1 and `2. For example, the UIE-Net [56], UIR-Net [8], P2P Net [53], and URCNN [21] only use `2 to optimize their networks."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2621,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2622,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2623,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2624 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Network Loss Network loss plays an integral part in learning the task underhand."@en ;
    askg-onto:inSentence "Network Loss Network loss plays an integral part in learning the task underhand."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning,
        askg-data:Entity-network_loss .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here, we discuss the losses employed in deep underwater image enhancement."@en ;
    askg-onto:inSentence "Here, we discuss the losses employed in deep underwater image enhancement."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_underwater_image_enhancement,
        askg-data:Entity-losses .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The most popular type of loss functions are to minimize the per-pixel error between the ground-truth image and the predicted image, commonly known as `1 and `2."@en ;
    askg-onto:inSentence "The most popular type of loss functions are to minimize the per-pixel error between the ground-truth image and the predicted image, commonly known as `1 and `2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_image,
        askg-data:Entity-loss_functions,
        askg-data:Entity-per-pixel_error,
        askg-data:Entity-predicted_image .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-262-Sentence-2624 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For example, the UIE-Net [56], UIR-Net [8], P2P Net [53], and URCNN [21] only use `2 to optimize their networks."@en ;
    askg-onto:inSentence "For example, the UIE-Net [56], UIR-Net [8], P2P Net [53], and URCNN [21] only use `2 to optimize their networks."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2,
        askg-data:Entity-model,
        askg-data:Entity-networks,
        askg-data:Entity-p2p_net,
        askg-data:Entity-uie-net,
        askg-data:Entity-uir-net,
        askg-data:Entity-urcnn .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-263 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Usually, other losses such as SSIM, gradient *etc.*, are combined with the ones mentioned earlier to improve the performance of the networks, *e.g.* UWCNN [3]. On the other hand, GANs rely on adversarial loss and perceptual loss to enhance the perceptual quality of the enhanced images, such as DenseGAN [16], UWGAN [34], etc."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-263-Sentence-2631,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-263-Sentence-2632 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-263-Sentence-2631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Usually, other losses such as SSIM, gradient *etc.*, are combined with the ones mentioned earlier to improve the performance of the networks, *e.g.* UWCNN [3]."@en ;
    askg-onto:inSentence "Usually, other losses such as SSIM, gradient *etc.*, are combined with the ones mentioned earlier to improve the performance of the networks, *e.g.* UWCNN [3]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ssim,
        askg-data:Entity-uwcnn .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-263-Sentence-2632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "On the other hand, GANs rely on adversarial loss and perceptual loss to enhance the perceptual quality of the enhanced images, such as DenseGAN [16], UWGAN [34], etc."@en ;
    askg-onto:inSentence "On the other hand, GANs rely on adversarial loss and perceptual loss to enhance the perceptual quality of the enhanced images, such as DenseGAN [16], UWGAN [34], etc."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_loss,
        askg-data:Entity-densegan,
        askg-data:Entity-gans,
        askg-data:Entity-perceptual_loss,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Network Depth and Paramters The network depth and the number of parameters are related. The deeper the network, the more the number of parameters. Unlike other image classification [20] and enhancement tasks [2] where the network depth has exponentially increased and even consists of hundreds of convolutional layers, the underwater image enhancement networks are still very shallow composed of less than 45 layers (deepest network is the WaterGAN [38] with 42 layers); hence comprised of very less number of parameters2."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264-Sentence-2641,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264-Sentence-2642,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264-Sentence-2643 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264-Sentence-2641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Network Depth and Paramters The network depth and the number of parameters are related."@en ;
    askg-onto:inSentence "Network Depth and Paramters The network depth and the number of parameters are related."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network_depth,
        askg-data:Entity-number_of_parameters .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264-Sentence-2642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The deeper the network, the more the number of parameters."@en ;
    askg-onto:inSentence "The deeper the network, the more the number of parameters."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network,
        askg-data:Entity-number_of_parameters .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-264-Sentence-2643 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Unlike other image classification [20] and enhancement tasks [2] where the network depth has exponentially increased and even consists of hundreds of convolutional layers, the underwater image enhancement networks are still very shallow composed of less than 45 layers (deepest network is the WaterGAN [38] with 42 layers); hence comprised of very less number of parameters2."@en ;
    askg-onto:inSentence "Unlike other image classification [20] and enhancement tasks [2] where the network depth has exponentially increased and even consists of hundreds of convolutional layers, the underwater image enhancement networks are still very shallow composed of less than 45 layers (deepest network is the WaterGAN [38] with 42 layers); hence comprised of very less number of parameters2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-42_layers,
        askg-data:Entity-less_than_45_layers,
        askg-data:Entity-underwater_image_enhancement_networks,
        askg-data:Entity-watergan .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Input Patch Size Contrary to low-level vision tasks, most of the underwater image enhancement algorithms operate on full-size images. The reason may be to incorporate the wavelength dissipation of red, green, and blue channels. Furthermore, some algorithms reduce the image to predefined size, which requires upsampling"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265-Sentence-2651,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265-Sentence-2652,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265-Sentence-2653 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265-Sentence-2651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Input Patch Size Contrary to low-level vision tasks, most of the underwater image enhancement algorithms operate on full-size images."@en ;
    askg-onto:inSentence "Input Patch Size Contrary to low-level vision tasks, most of the underwater image enhancement algorithms operate on full-size images."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-full-size_images,
        askg-data:Entity-underwater_image_enhancement_algorithms .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265-Sentence-2652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The reason may be to incorporate the wavelength dissipation of red, green, and blue channels."@en ;
    askg-onto:inSentence "The reason may be to incorporate the wavelength dissipation of red, green, and blue channels."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-red_green_and_blue_channels,
        askg-data:Entity-wavelength_dissipation .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-265-Sentence-2653 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, some algorithms reduce the image to predefined size, which requires upsampling"@en ;
    askg-onto:inSentence "Furthermore, some algorithms reduce the image to predefined size, which requires upsampling"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-image,
        askg-data:Entity-predefined_size,
        askg-data:Entity-upsampling .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-266 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![9_image_0.png](9_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-266-Sentence-2661 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-266-Sentence-2661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![9_image_0.png](9_image_0.png)"@en ;
    askg-onto:inSentence "![9_image_0.png](9_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-author,
        askg-data:Entity-experiment,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-research,
        askg-data:Entity-researchers,
        askg-data:Entity-results,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-267 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Fig. 3 Representative images: Three sample images from Haze-line [6], ULFID [52], and UIEBD [35] datasets to show the diversity of the underwater images."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-267-Sentence-2671,
        askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-267-Sentence-2672 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-267-Sentence-2671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_visual_representation,
        askg-data:Entity-fig .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-267-Sentence-2672 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "3 Representative images: Three sample images from Haze-line [6], ULFID [52], and UIEBD [35] datasets to show the diversity of the underwater images."@en ;
    askg-onto:inSentence "3 Representative images: Three sample images from Haze-line [6], ULFID [52], and UIEBD [35] datasets to show the diversity of the underwater images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-haze-line,
        askg-data:Entity-uiebd,
        askg-data:Entity-ulfid,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-268 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "as a post-processing step, such as MCycleGAN [39], DenseGAN [16], and UWGAN [34]."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-268-Sentence-2681 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-26-Paragraph-268-Sentence-2681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "as a post-processing step, such as MCycleGAN [39], DenseGAN [16], and UWGAN [34]."@en ;
    askg-onto:inSentence "as a post-processing step, such as MCycleGAN [39], DenseGAN [16], and UWGAN [34]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-densegan,
        askg-data:Entity-mcyclegan,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-27 a askg-onto:Section ;
    rdfs:label "Section 27"@en ;
    domo:Text "4 Experimental Settings"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-271,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2710,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-272,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-273,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-274,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-275,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-276,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-277,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-279 ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-271 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "4.1 Real-world Underwater Image Datasets Due to the limitations of synthetic underwater image datasets (*e.g.*, inaccurate formation models, hard assumptions, insufficient images, specific scenes, *etc.*), we mainly introduce the real-world underwater image datasets in this section."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-271-Sentence-2711 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-271-Sentence-2711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4.1 Real-world Underwater Image Datasets Due to the limitations of synthetic underwater image datasets (*e.g.*, inaccurate formation models, hard assumptions, insufficient images, specific scenes, *etc.*), we mainly introduce the real-world underwater image datasets in this section."@en ;
    askg-onto:inSentence "4.1 Real-world Underwater Image Datasets Due to the limitations of synthetic underwater image datasets (*e.g.*, inaccurate formation models, hard assumptions, insufficient images, specific scenes, *etc.*), we mainly introduce the real-world underwater image datasets in this section."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-limitations_of_synthetic_underwater_image_datasets,
        askg-data:Entity-real-world_underwater_image_datasets .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2710 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "- Haze-line Dataset [6] collected a dataset of images taken in different locations with varying water properties, showing color charts in the scenes (about 33GB in size). Moreover, the 3D structure of the scene was calculated based on stereo imaging6."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2710-Sentence-27101,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2710-Sentence-27102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2710-Sentence-27101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Haze-line Dataset [6] collected a dataset of images taken in different locations with varying water properties, showing color charts in the scenes (about 33GB in size)."@en ;
    askg-onto:inSentence "- Haze-line Dataset [6] collected a dataset of images taken in different locations with varying water properties, showing color charts in the scenes (about 33GB in size)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset_of_images,
        askg-data:Entity-haze-line_dataset .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2710-Sentence-27102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Moreover, the 3D structure of the scene was calculated based on stereo imaging6."@en ;
    askg-onto:inSentence "Moreover, the 3D structure of the scene was calculated based on stereo imaging6."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_structure,
        askg-data:Entity-stereo_imaging .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "- UIEBD: Underwater Image Enhancement Benchmark Dataset [35] includes 950 real-world underwater images, 890 of which have the corresponding reference images where each reference image is selected from 12 enhanced results. The rest 60 underwater images which cannot obtain satisfactory references are treated as challenging data. The UIEBD [35] contains a large range of image resolution and spans diverse scene/main object categories.7."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711-Sentence-27111,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711-Sentence-27112,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711-Sentence-27113 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711-Sentence-27111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- UIEBD: Underwater Image Enhancement Benchmark Dataset [35] includes 950 real-world underwater images, 890 of which have the corresponding reference images where each reference image is selected from 12 enhanced results."@en ;
    askg-onto:inSentence "- UIEBD: Underwater Image Enhancement Benchmark Dataset [35] includes 950 real-world underwater images, 890 of which have the corresponding reference images where each reference image is selected from 12 enhanced results."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-12_enhanced_results,
        askg-data:Entity-890_corresponding_reference_images,
        askg-data:Entity-950_real-world_underwater_images,
        askg-data:Entity-uiebd_underwater_image_enhancement_benchmark_dataset .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711-Sentence-27112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The rest 60 underwater images which cannot obtain satisfactory references are treated as challenging data."@en ;
    askg-onto:inSentence "The rest 60 underwater images which cannot obtain satisfactory references are treated as challenging data."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-challenging_data,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2711-Sentence-27113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The UIEBD [35] contains a large range of image resolution and spans diverse scene/main object categories.7."@en ;
    askg-onto:inSentence "The UIEBD [35] contains a large range of image resolution and spans diverse scene/main object categories.7."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_large_range_of_image_resolution,
        askg-data:Entity-diverse_scenemain_object_categories,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "The existing real-world underwater image datasets usually have monotonous content and limited quality degradation types. Moreover, these datasets did not provide the corresponding ground truth images because it is impractical to simultaneously obtain the degraded underwater image and the ground-truth of the same scene. The UIEBD [35] provides the corresponding reference images which can be considered for full-reference image quality assessment. We conduct experimental quantitative and visual comparisons on this dataset. Besides, to validate the generalization of current deep algorithms, we also present the visual results of different methods on another two datasets i.e., Haze-line dataset [6] and ULFID [52]. Some representative samples of these three datasets are given in Figure 3."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27121,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27122,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27123,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27124,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27125,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27126 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The existing real-world underwater image datasets usually have monotonous content and limited quality degradation types."@en ;
    askg-onto:inSentence "The existing real-world underwater image datasets usually have monotonous content and limited quality degradation types."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-limited_quality_degradation_types,
        askg-data:Entity-monotonous_content,
        askg-data:Entity-underwater_image_datasets .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Moreover, these datasets did not provide the corresponding ground truth images because it is impractical to simultaneously obtain the degraded underwater image and the ground-truth of the same scene."@en ;
    askg-onto:inSentence "Moreover, these datasets did not provide the corresponding ground truth images because it is impractical to simultaneously obtain the degraded underwater image and the ground-truth of the same scene."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-ground_truth_images .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The UIEBD [35] provides the corresponding reference images which can be considered for full-reference image quality assessment."@en ;
    askg-onto:inSentence "The UIEBD [35] provides the corresponding reference images which can be considered for full-reference image quality assessment."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-full-reference_image_quality_assessment,
        askg-data:Entity-reference_images,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We conduct experimental quantitative and visual comparisons on this dataset."@en ;
    askg-onto:inSentence "We conduct experimental quantitative and visual comparisons on this dataset."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-this_dataset .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Besides, to validate the generalization of current deep algorithms, we also present the visual results of different methods on another two datasets i.e., Haze-line dataset [6] and ULFID [52]."@en ;
    askg-onto:inSentence "Besides, to validate the generalization of current deep algorithms, we also present the visual results of different methods on another two datasets i.e., Haze-line dataset [6] and ULFID [52]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_algorithms,
        askg-data:Entity-different_methods,
        askg-data:Entity-generalization,
        askg-data:Entity-haze-line_dataset,
        askg-data:Entity-ulfid,
        askg-data:Entity-visual_results .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-2712-Sentence-27126 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Some representative samples of these three datasets are given in Figure 3."@en ;
    askg-onto:inSentence "Some representative samples of these three datasets are given in Figure 3."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-samples .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-272 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "- Fish4Knowledge [7] is funded by the European Union Seventh Framework program for the study of marine ecosystems, which provides a video and fish analysis dataset (about 200 Tb in size)3."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-272-Sentence-2721 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-272-Sentence-2721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Fish4Knowledge [7] is funded by the European Union Seventh Framework program for the study of marine ecosystems, which provides a video and fish analysis dataset (about 200 Tb in size)3."@en ;
    askg-onto:inSentence "- Fish4Knowledge [7] is funded by the European Union Seventh Framework program for the study of marine ecosystems, which provides a video and fish analysis dataset (about 200 Tb in size)3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-european_union_seventh_framework_program,
        askg-data:Entity-fish4knowledge,
        askg-data:Entity-marine_ecosystems,
        askg-data:Entity-video_and_fish_analysis_dataset .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-273 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "- ULFID: Underwater Light Field Image Dataset [52] contains several underwater light field images in pure water and hazy conditions, as well as images taken in the air for reference4."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-273-Sentence-2731 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-273-Sentence-2731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- ULFID: Underwater Light Field Image Dataset [52] contains several underwater light field images in pure water and hazy conditions, as well as images taken in the air for reference4."@en ;
    askg-onto:inSentence "- ULFID: Underwater Light Field Image Dataset [52] contains several underwater light field images in pure water and hazy conditions, as well as images taken in the air for reference4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pure_water_and_hazy_conditions,
        askg-data:Entity-the_air,
        askg-data:Entity-ulfid,
        askg-data:Entity-underwater_light_field_image_dataset,
        askg-data:Entity-underwater_light_field_images .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-274 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "- MARIS: Marine Autonomous Robotics for InterventionS [43] is to advance the development of coop-"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-274-Sentence-2741 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-274-Sentence-2741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- MARIS: Marine Autonomous Robotics for InterventionS [43] is to advance the development of coop-"@en ;
    askg-onto:inSentence "- MARIS: Marine Autonomous Robotics for InterventionS [43] is to advance the development of coop-"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-marine_autonomous_robotics_for_interventions,
        askg-data:Entity-maris .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-275 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "2 As most of the network models are not publicly available, a fair comparison to determine exact number of parameters is not possible."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-275-Sentence-2751 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-275-Sentence-2751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2 As most of the network models are not publicly available, a fair comparison to determine exact number of parameters is not possible."@en ;
    askg-onto:inSentence "2 As most of the network models are not publicly available, a fair comparison to determine exact number of parameters is not possible."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fair_comparison,
        askg-data:Entity-network_models,
        askg-data:Entity-number_of_parameters .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-276 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "erating AUVs for undersea intervention in the off3 http://groups.inf.ed.ac.uk/f4k/index.html 4 https://github.com/kskin/data"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-276-Sentence-2761 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-276-Sentence-2761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "erating AUVs for undersea intervention in the off3 http://groups.inf.ed.ac.uk/f4k/index.html 4 https://github.com/kskin/data"@en ;
    askg-onto:inSentence "erating AUVs for undersea intervention in the off3 http://groups.inf.ed.ac.uk/f4k/index.html 4 https://github.com/kskin/data"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-auvs,
        askg-data:Entity-httpgroupsinfedacukf4kindexhtml,
        askg-data:Entity-httpsgithubcomkskindata,
        askg-data:Entity-repository,
        askg-data:Entity-undersea_intervention,
        askg-data:Entity-website .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-277 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "| | | | | | | Network Parameters | | | | |----------------|---------|---------|----------|----------|--------|----------------------|-------------|------------|----------------| | | Patch | Network | Feature | Variable | | Residual | Skip | | | | Methods | Size | Depth | maps | Kernels | Blocks | learning | connections | Framework | Loss | | UIE\\-Net [56] | 32×32 | 7 | 16\\-20 | D | | | | \\- | `2 | | UIR\\-Net [8] | 224×224 | 8 | 96\\-384 | D | | | | \\- | `2 | | P2P Net [53] | 66×66 | 6 | 96\\-384 | D | | D | D | Caffe | `2 | | UIE\\-sGAN [64] | 256×256 | 16 | 64\\-512 | | | D | D | TensorFlow | `gan,`c | | WaterGAN [38] | 512×512 | 42 | 128\\-512 | | | D | D | Caffe | `2 | | UGAN [12] | 256×256 | 9 | 64\\-512 | D | | D | D | TensorFlow | `1,`W | | UWCNN [3] | 310×230 | 10 | 32 | | D | D | D | TensorFlow | `2,`SSIM | | URCNN [21] | 180×180 | 25 | 64 | | | D | D | MatConvNet | `2 | | UWGAN [34] | 256×256 | 18 | 64\\-256 | D | D | | | TensorFlow | `gan,`c,`SSIM | | DUIENet [35] | 112×112 | 8 | 32\\-128 | D | | | | TensorFlow | `perceptual | | MCycleGAN [39] | 256×256 | 24 | 64\\-128 | D | D | D | D | TensorFlow | `gan,`c,`MSSIM | | DenseGAN [16] | 256×256 | 10 | 64\\-512 | D | D | D | D | TensorFlow | `2,`gan,`g | | FGAN [37] | 256×256 | 8 | 64\\-256 | D | D | D | D | TensorFlow | `2,`gan,`r | | UIE\\-DAL [54] | 256×256 | 27 | 64\\-512 | | | D | D | \\- | `2,`gan,`nui |"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-277-Sentence-2771 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-277-Sentence-2771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | | | | | | Network Parameters | | | | |----------------|---------|---------|----------|----------|--------|----------------------|-------------|------------|----------------| | | Patch | Network | Feature | Variable | | Residual | Skip | | | | Methods | Size | Depth | maps | Kernels | Blocks | learning | connections | Framework | Loss | | UIE\\-Net [56] | 32×32 | 7 | 16\\-20 | D | | | | \\- | `2 | | UIR\\-Net [8] | 224×224 | 8 | 96\\-384 | D | | | | \\- | `2 | | P2P Net [53] | 66×66 | 6 | 96\\-384 | D | | D | D | Caffe | `2 | | UIE\\-sGAN [64] | 256×256 | 16 | 64\\-512 | | | D | D | TensorFlow | `gan,`c | | WaterGAN [38] | 512×512 | 42 | 128\\-512 | | | D | D | Caffe | `2 | | UGAN [12] | 256×256 | 9 | 64\\-512 | D | | D | D | TensorFlow | `1,`W | | UWCNN [3] | 310×230 | 10 | 32 | | D | D | D | TensorFlow | `2,`SSIM | | URCNN [21] | 180×180 | 25 | 64 | | | D | D | MatConvNet | `2 | | UWGAN [34] | 256×256 | 18 | 64\\-256 | D | D | | | TensorFlow | `gan,`c,`SSIM | | DUIENet [35] | 112×112 | 8 | 32\\-128 | D | | | | TensorFlow | `perceptual | | MCycleGAN [39] | 256×256 | 24 | 64\\-128 | D | D | D | D | TensorFlow | `gan,`c,`MSSIM | | DenseGAN [16] | 256×256 | 10 | 64\\-512 | D | D | D | D | TensorFlow | `2,`gan,`g | | FGAN [37] | 256×256 | 8 | 64\\-256 | D | D | D | D | TensorFlow | `2,`gan,`r | | UIE\\-DAL [54] | 256×256 | 27 | 64\\-512 | | | D | D | \\- | `2,`gan,`nui |"@en ;
    askg-onto:inSentence "| | | | | | | Network Parameters | | | | |----------------|---------|---------|----------|----------|--------|----------------------|-------------|------------|----------------| | | Patch | Network | Feature | Variable | | Residual | Skip | | | | Methods | Size | Depth | maps | Kernels | Blocks | learning | connections | Framework | Loss | | UIE\\-Net [56] | 32×32 | 7 | 16\\-20 | D | | | | \\- | `2 | | UIR\\-Net [8] | 224×224 | 8 | 96\\-384 | D | | | | \\- | `2 | | P2P Net [53] | 66×66 | 6 | 96\\-384 | D | | D | D | Caffe | `2 | | UIE\\-sGAN [64] | 256×256 | 16 | 64\\-512 | | | D | D | TensorFlow | `gan,`c | | WaterGAN [38] | 512×512 | 42 | 128\\-512 | | | D | D | Caffe | `2 | | UGAN [12] | 256×256 | 9 | 64\\-512 | D | | D | D | TensorFlow | `1,`W | | UWCNN [3] | 310×230 | 10 | 32 | | D | D | D | TensorFlow | `2,`SSIM | | URCNN [21] | 180×180 | 25 | 64 | | | D | D | MatConvNet | `2 | | UWGAN [34] | 256×256 | 18 | 64\\-256 | D | D | | | TensorFlow | `gan,`c,`SSIM | | DUIENet [35] | 112×112 | 8 | 32\\-128 | D | | | | TensorFlow | `perceptual | | MCycleGAN [39] | 256×256 | 24 | 64\\-128 | D | D | D | D | TensorFlow | `gan,`c,`MSSIM | | DenseGAN [16] | 256×256 | 10 | 64\\-512 | D | D | D | D | TensorFlow | `2,`gan,`g | | FGAN [37] | 256×256 | 8 | 64\\-256 | D | D | D | D | TensorFlow | `2,`gan,`r | | UIE\\-DAL [54] | 256×256 | 27 | 64\\-512 | | | D | D | \\- | `2,`gan,`nui |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-caffe,
        askg-data:Entity-densegan,
        askg-data:Entity-duienet,
        askg-data:Entity-fgan,
        askg-data:Entity-matconvnet,
        askg-data:Entity-mcyclegan,
        askg-data:Entity-model,
        askg-data:Entity-p2p_net,
        askg-data:Entity-platform,
        askg-data:Entity-tensorflow,
        askg-data:Entity-ugan,
        askg-data:Entity-uie-dal,
        askg-data:Entity-uie-net,
        askg-data:Entity-uie-sgan,
        askg-data:Entity-uir-net,
        askg-data:Entity-urcnn,
        askg-data:Entity-uwcnn,
        askg-data:Entity-uwgan,
        askg-data:Entity-watergan .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Table 1 Network Specifics: Essential parameters of underwater image enhancement and restoration networks. The losses i.e., `gan, `c, `W , `nui, `r and `g represents adversarial, consistency, Wasserstein, nuisance, relativistic and gradient losses, respectively. The \"-\" means information is not available."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278-Sentence-2781,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278-Sentence-2782,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278-Sentence-2783 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278-Sentence-2781 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 1 Network Specifics: Essential parameters of underwater image enhancement and restoration networks."@en ;
    askg-onto:inSentence "Table 1 Network Specifics: Essential parameters of underwater image enhancement and restoration networks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network,
        askg-data:Entity-underwater_image_enhancement,
        askg-data:Entity-underwater_image_restoration .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278-Sentence-2782 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The losses i.e., `gan, `c, `W , `nui, `r and `g represents adversarial, consistency, Wasserstein, nuisance, relativistic and gradient losses, respectively."@en ;
    askg-onto:inSentence "The losses i.e., `gan, `c, `W , `nui, `r and `g represents adversarial, consistency, Wasserstein, nuisance, relativistic and gradient losses, respectively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_loss,
        askg-data:Entity-c,
        askg-data:Entity-consistency_loss,
        askg-data:Entity-g,
        askg-data:Entity-gan,
        askg-data:Entity-gradient_loss,
        askg-data:Entity-nui,
        askg-data:Entity-nuisance_loss,
        askg-data:Entity-r,
        askg-data:Entity-relativistic_loss,
        askg-data:Entity-w,
        askg-data:Entity-wasserstein_loss .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-278-Sentence-2783 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The \"-\" means information is not available."@en ;
    askg-onto:inSentence "The \"-\" means information is not available."^^xsd:string ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-279 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "shore industry, in search-and-rescue tasks, and in various flavors of scientific exploration. This project provides several underwater images and videos captured by underwater stereo vision system5."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-279-Sentence-2791,
        askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-279-Sentence-2792 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-279-Sentence-2791 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "shore industry, in search-and-rescue tasks, and in various flavors of scientific exploration."@en ;
    askg-onto:inSentence "shore industry, in search-and-rescue tasks, and in various flavors of scientific exploration."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientific_exploration,
        askg-data:Entity-search-and-rescue_tasks,
        askg-data:Entity-shore_industry .

askg-data:Paper-c63c8058011e31f2-Section-27-Paragraph-279-Sentence-2792 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This project provides several underwater images and videos captured by underwater stereo vision system5."@en ;
    askg-onto:inSentence "This project provides several underwater images and videos captured by underwater stereo vision system5."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-underwater_images_and_videos,
        askg-data:Entity-underwater_stereo_vision_system5 .

askg-data:Paper-c63c8058011e31f2-Section-28 a askg-onto:Section ;
    rdfs:label "Section 28"@en ;
    domo:Text "4.2 Evaluation Metrics"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281 ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Evaluations performed for underwater image enhancement can be broadly categorized into automatic evaluation metrics and human visual system (HVS). The automatic evaluations are performed using six metrics, out of these, four are also most widely used in image enhancement and restoration problems *i.e.* PSNR, MSE, and SSIM [61], and PCQI [55] while the other two are specific for underwater image enhancement *i.e.* UCIQE [63] and UIQM [44]. Next, to make the article inclusive, we describe all the evaluation metrics and then detail their limitations and reliability. Moreover, we also provide the report which details the human visual evaluation and its importance."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2811,
        askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2812,
        askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2813,
        askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2814 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Evaluations performed for underwater image enhancement can be broadly categorized into automatic evaluation metrics and human visual system (HVS)."@en ;
    askg-onto:inSentence "Evaluations performed for underwater image enhancement can be broadly categorized into automatic evaluation metrics and human visual system (HVS)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_evaluation_metrics,
        askg-data:Entity-human_visual_system_hvs,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The automatic evaluations are performed using six metrics, out of these, four are also most widely used in image enhancement and restoration problems *i.e.* PSNR, MSE, and SSIM [61], and PCQI [55] while the other two are specific for underwater image enhancement *i.e.* UCIQE [63] and UIQM [44]."@en ;
    askg-onto:inSentence "The automatic evaluations are performed using six metrics, out of these, four are also most widely used in image enhancement and restoration problems *i.e.* PSNR, MSE, and SSIM [61], and PCQI [55] while the other two are specific for underwater image enhancement *i.e.* UCIQE [63] and UIQM [44]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_evaluations,
        askg-data:Entity-four_metrics,
        askg-data:Entity-image_enhancement_and_restoration_problems,
        askg-data:Entity-mse,
        askg-data:Entity-pcqi,
        askg-data:Entity-psnr,
        askg-data:Entity-six_metrics,
        askg-data:Entity-ssim,
        askg-data:Entity-two_metrics,
        askg-data:Entity-uciqe,
        askg-data:Entity-uiqm,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Next, to make the article inclusive, we describe all the evaluation metrics and then detail their limitations and reliability."@en ;
    askg-onto:inSentence "Next, to make the article inclusive, we describe all the evaluation metrics and then detail their limitations and reliability."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_metrics,
        askg-data:Entity-limitations,
        askg-data:Entity-reliability .

askg-data:Paper-c63c8058011e31f2-Section-28-Paragraph-281-Sentence-2814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, we also provide the report which details the human visual evaluation and its importance."@en ;
    askg-onto:inSentence "Moreover, we also provide the report which details the human visual evaluation and its importance."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-human_visual_evaluation,
        askg-data:Entity-importance,
        askg-data:Entity-report .

askg-data:Paper-c63c8058011e31f2-Section-29 a askg-onto:Section ;
    rdfs:label "Section 29"@en ;
    domo:Text "4.2.1 Automatic Evaluation Metrics"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2912,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2913,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2916,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2917,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-292,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-293,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-295,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-299 ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "- MSE and PSNR: We begin our discussion with Mean Square Error (MSE) as the signal measure. The MSE aims to provide a quantitative score that represents the similarity or distortion between the two signals. Usually, one of the signals is the original"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291-Sentence-2911,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291-Sentence-2912,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291-Sentence-2913 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291-Sentence-2911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- MSE and PSNR: We begin our discussion with Mean Square Error (MSE) as the signal measure."@en ;
    askg-onto:inSentence "- MSE and PSNR: We begin our discussion with Mean Square Error (MSE) as the signal measure."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mean_square_error,
        askg-data:Entity-mse,
        askg-data:Entity-psnr,
        askg-data:Entity-signal_measure .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291-Sentence-2912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The MSE aims to provide a quantitative score that represents the similarity or distortion between the two signals."@en ;
    askg-onto:inSentence "The MSE aims to provide a quantitative score that represents the similarity or distortion between the two signals."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mse,
        askg-data:Entity-quantitative_score,
        askg-data:Entity-similarity_or_distortion .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-291-Sentence-2913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Usually, one of the signals is the original"@en ;
    askg-onto:inSentence "Usually, one of the signals is the original"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-one_of_the_signals,
        askg-data:Entity-the_original .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "- PCQI: Patch-based contrast quality index (PCQI) [55] relies on patch-based approach as contrary to relying on global statistics. The PCQI depends on three independent quantities of an image patch *i.e.* mean, signal strength and structure. Mathematically, a patch-based contrast image quality index (PCQI) is given by:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910-Sentence-29101,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910-Sentence-29102,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910-Sentence-29103 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910-Sentence-29101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- PCQI: Patch-based contrast quality index (PCQI) [55] relies on patch-based approach as contrary to relying on global statistics."@en ;
    askg-onto:inSentence "- PCQI: Patch-based contrast quality index (PCQI) [55] relies on patch-based approach as contrary to relying on global statistics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-global_statistics,
        askg-data:Entity-patch-based_approach,
        askg-data:Entity-patch-based_contrast_quality_index,
        askg-data:Entity-pcqi .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910-Sentence-29102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The PCQI depends on three independent quantities of an image patch *i.e.* mean, signal strength and structure."@en ;
    askg-onto:inSentence "The PCQI depends on three independent quantities of an image patch *i.e.* mean, signal strength and structure."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mean,
        askg-data:Entity-pcqi,
        askg-data:Entity-signal_strength,
        askg-data:Entity-structure .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2910-Sentence-29103 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Mathematically, a patch-based contrast image quality index (PCQI) is given by:"@en ;
    askg-onto:inSentence "Mathematically, a patch-based contrast image quality index (PCQI) is given by:"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_quality_index,
        askg-data:Entity-patch-based_contrast_image_quality_index,
        askg-data:Entity-pcqi .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "$$\\mathrm{PCQI}=q_{i}(x,y)\\cdot q_{c}(x,y)\\cdot q_{s}(x,y),$$ $\\left(9\\right)$. PCQI = qi(x, y) · qc(x, y) · qs(*x, y*), (9) $\\left(7\\right)$. where qi(*x, y*) is to compare mean intensity, qc(*x, y*) is to determine the structural distortion and qs(*x, y*) is the contrast change. PCQI is mathematically expensive as compared to other metrics. Next, we discuss quantitative measures, which are more specific to underwater image enhancement."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29111,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29112,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29113,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29114,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29115 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathrm{PCQI}=q_{i}(x,y)\\cdot q_{c}(x,y)\\cdot q_{s}(x,y),$$ $\\left(9\\right)$."@en ;
    askg-onto:inSentence "$$\\mathrm{PCQI}=q_{i}(x,y)\\cdot q_{c}(x,y)\\cdot q_{s}(x,y),$$ $\\left(9\\right)$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pcqi,
        askg-data:Entity-q_ixy_%0A%09ext__q_cxy_%0A%09ext_and__q_sxy .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "PCQI = qi(x, y) · qc(x, y) · qs(*x, y*), (9) $\\left(7\\right)$."@en ;
    askg-onto:inSentence "PCQI = qi(x, y) · qc(x, y) · qs(*x, y*), (9) $\\left(7\\right)$."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pcqi,
        askg-data:Entity-qix_y__qcx_y__qsx_y .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "where qi(*x, y*) is to compare mean intensity, qc(*x, y*) is to determine the structural distortion and qs(*x, y*) is the contrast change."@en ;
    askg-onto:inSentence "where qi(*x, y*) is to compare mean intensity, qc(*x, y*) is to determine the structural distortion and qs(*x, y*) is the contrast change."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-contrast_change,
        askg-data:Entity-mean_intensity,
        askg-data:Entity-qcx_y,
        askg-data:Entity-qix_y,
        askg-data:Entity-qsx_y,
        askg-data:Entity-structural_distortion .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "PCQI is mathematically expensive as compared to other metrics."@en ;
    askg-onto:inSentence "PCQI is mathematically expensive as compared to other metrics."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-other_metrics,
        askg-data:Entity-pcqi .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2911-Sentence-29115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Next, we discuss quantitative measures, which are more specific to underwater image enhancement."@en ;
    askg-onto:inSentence "Next, we discuss quantitative measures, which are more specific to underwater image enhancement."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-quantitative_measures,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2912 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "- UCIQE: Underwater color image quality evaluation abbreviated as UCIQE [63], is based chroma, contrast, and saturation of CIELab and is defined as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2912-Sentence-29121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2912-Sentence-29121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- UCIQE: Underwater color image quality evaluation abbreviated as UCIQE [63], is based chroma, contrast, and saturation of CIELab and is defined as:"@en ;
    askg-onto:inSentence "- UCIQE: Underwater color image quality evaluation abbreviated as UCIQE [63], is based chroma, contrast, and saturation of CIELab and is defined as:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chroma_contrast_and_saturation_of_cielab,
        askg-data:Entity-uciqe,
        askg-data:Entity-underwater_color_image_quality_evaluation .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2913 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "$$\\operatorname{CID}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2913-Sentence-29131 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2913-Sentence-29131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\operatorname{CID}$$"@en ;
    askg-onto:inSentence "$$\\operatorname{CID}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cid,
        askg-data:Entity-concept .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "$\\therefore$ C. $\\left(10\\right)$. UCIQE = C1 × σc + C2 × conl + C3 × µs, (10) where σc, conl and µs are the standard deviation of chroma, the contrast of luminance, and the mean of saturation. It is to be noted here that for underwater images, human perception has a good correlation with the variance of chroma."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29141,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29142,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29143,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29144 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\therefore$ C."@en ;
    askg-onto:inSentence "$\\therefore$ C."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "$\\left(10\\right)$."@en ;
    askg-onto:inSentence "$\\left(10\\right)$."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10,
        askg-data:Entity-number .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "UCIQE = C1 × σc + C2 × conl + C3 × µs, (10) where σc, conl and µs are the standard deviation of chroma, the contrast of luminance, and the mean of saturation."@en ;
    askg-onto:inSentence "UCIQE = C1 × σc + C2 × conl + C3 × µs, (10) where σc, conl and µs are the standard deviation of chroma, the contrast of luminance, and the mean of saturation."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C2%B5s,
        askg-data:Entity-%CF%83c,
        askg-data:Entity-c1__%CF%83c__c2__conl__c3__%C2%B5s,
        askg-data:Entity-chroma,
        askg-data:Entity-conl,
        askg-data:Entity-luminance,
        askg-data:Entity-saturation,
        askg-data:Entity-uciqe .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2914-Sentence-29144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "It is to be noted here that for underwater images, human perception has a good correlation with the variance of chroma."@en ;
    askg-onto:inSentence "It is to be noted here that for underwater images, human perception has a good correlation with the variance of chroma."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-human_perception,
        askg-data:Entity-variance_of_chroma .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "- UIQM: UIQM [44] stands for underwater image quality measure and is different from earlier defined evaluation metrics. The UIQ employs the HVS model only, and does not require a reference image; hence, a better candidate for evaluation of underwater images. UIQM is dependent on three attribute measures the underwater images, which are 1) image colorfulness measure (UICM), 2) sharpness measure (UISM), and 3) contrast measure (UIConM). Following is the formulation of UIQM:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29151,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29152,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29153,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29154 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- UIQM: UIQM [44] stands for underwater image quality measure and is different from earlier defined evaluation metrics."@en ;
    askg-onto:inSentence "- UIQM: UIQM [44] stands for underwater image quality measure and is different from earlier defined evaluation metrics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-earlier_defined_evaluation_metrics,
        askg-data:Entity-uiqm,
        askg-data:Entity-underwater_image_quality_measure .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The UIQ employs the HVS model only, and does not require a reference image; hence, a better candidate for evaluation of underwater images."@en ;
    askg-onto:inSentence "The UIQ employs the HVS model only, and does not require a reference image; hence, a better candidate for evaluation of underwater images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hvs_model,
        askg-data:Entity-uiq,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "UIQM is dependent on three attribute measures the underwater images, which are 1) image colorfulness measure (UICM), 2) sharpness measure (UISM), and 3) contrast measure (UIConM)."@en ;
    askg-onto:inSentence "UIQM is dependent on three attribute measures the underwater images, which are 1) image colorfulness measure (UICM), 2) sharpness measure (UISM), and 3) contrast measure (UIConM)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-contrast_measure_uiconm,
        askg-data:Entity-image_colorfulness_measure_uicm,
        askg-data:Entity-sharpness_measure_uism,
        askg-data:Entity-uiqm .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2915-Sentence-29154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Following is the formulation of UIQM:"@en ;
    askg-onto:inSentence "Following is the formulation of UIQM:"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulation,
        askg-data:Entity-uiqm .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2916 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "$$\\mathrm{M},\\ ($$"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2916-Sentence-29161 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2916-Sentence-29161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathrm{M},\\ ($$"@en ;
    askg-onto:inSentence "$$\\mathrm{M},\\ ($$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-m .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2917 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "UIQM = c1×UICM+c2×UISM+c3×UIConM, (11) where c1, c2 and c3 are the parameters which are application dependent, *e.g.*, more weight should be given to c1 for underwater color correct while c2 for increasing visibility in the underwater scene."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2917-Sentence-29171 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-2917-Sentence-29171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "UIQM = c1×UICM+c2×UISM+c3×UIConM, (11) where c1, c2 and c3 are the parameters which are application dependent, *e.g.*, more weight should be given to c1 for underwater color correct while c2 for increasing visibility in the underwater scene."@en ;
    askg-onto:inSentence "UIQM = c1×UICM+c2×UISM+c3×UIConM, (11) where c1, c2 and c3 are the parameters which are application dependent, *e.g.*, more weight should be given to c1 for underwater color correct while c2 for increasing visibility in the underwater scene."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c1,
        askg-data:Entity-c1uicmc2uismc3uiconm,
        askg-data:Entity-c2,
        askg-data:Entity-c3,
        askg-data:Entity-increasing_visibility_in_the_underwater_scene,
        askg-data:Entity-uiqm,
        askg-data:Entity-underwater_color_correct .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-292 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "5 http://rimlab.ce.unipr.it/Maris.html 6 http://csms.haifa.ac.il/profiles/tTreibitz/ datasets/ambient_forwardlooking/index.html 7 https://li-chongyi.github.io/proj_benchmark.html signal, and the other one is recovered from some distortion or contamination. Mathematically, the MSE between the two signals can be expressed as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-292-Sentence-2921,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-292-Sentence-2922 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-292-Sentence-2921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "5 http://rimlab.ce.unipr.it/Maris.html 6 http://csms.haifa.ac.il/profiles/tTreibitz/ datasets/ambient_forwardlooking/index.html 7 https://li-chongyi.github.io/proj_benchmark.html signal, and the other one is recovered from some distortion or contamination."@en ;
    askg-onto:inSentence "5 http://rimlab.ce.unipr.it/Maris.html 6 http://csms.haifa.ac.il/profiles/tTreibitz/ datasets/ambient_forwardlooking/index.html 7 https://li-chongyi.github.io/proj_benchmark.html signal, and the other one is recovered from some distortion or contamination."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ambient_forwardlooking,
        askg-data:Entity-dataset,
        askg-data:Entity-maris,
        askg-data:Entity-proj_benchmark,
        askg-data:Entity-website .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-292-Sentence-2922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Mathematically, the MSE between the two signals can be expressed as:"@en ;
    askg-onto:inSentence "Mathematically, the MSE between the two signals can be expressed as:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mse,
        askg-data:Entity-signals .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-293 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$\\mathrm{MSE}={\\frac{1}{N}}\\sum_{i=1}^{N}(x_{i}-y_{i})^{2},$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-293-Sentence-2931 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-293-Sentence-2931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathrm{MSE}={\\frac{1}{N}}\\sum_{i=1}^{N}(x_{i}-y_{i})^{2},$$"@en ;
    askg-onto:inSentence "$$\\mathrm{MSE}={\\frac{1}{N}}\\sum_{i=1}^{N}(x_{i}-y_{i})^{2},$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mse .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "where x and y are two signals, in this case, images and xi and yi are the pixels at i th location. Similarly, N are the number of pixels. Furthermore, in the image processing literature, peak signal to noise ratio (PSNR) measure is computed from MSE as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294-Sentence-2941,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294-Sentence-2942,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294-Sentence-2943 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294-Sentence-2941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where x and y are two signals, in this case, images and xi and yi are the pixels at i th location."@en ;
    askg-onto:inSentence "where x and y are two signals, in this case, images and xi and yi are the pixels at i th location."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-images,
        askg-data:Entity-signals,
        askg-data:Entity-the_pixels_at_i_th_location,
        askg-data:Entity-two_signals,
        askg-data:Entity-x,
        askg-data:Entity-xi,
        askg-data:Entity-yi .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294-Sentence-2942 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Similarly, N are the number of pixels."@en ;
    askg-onto:inSentence "Similarly, N are the number of pixels."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n,
        askg-data:Entity-the_number_of_pixels .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-294-Sentence-2943 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, in the image processing literature, peak signal to noise ratio (PSNR) measure is computed from MSE as:"@en ;
    askg-onto:inSentence "Furthermore, in the image processing literature, peak signal to noise ratio (PSNR) measure is computed from MSE as:"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mse,
        askg-data:Entity-peak_signal_to_noise_ratio_psnr .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-295 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\mathrm{PSNR}=10\\log_{10}{\\frac{L^{2}}{\\mathrm{MSE}}}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-295-Sentence-2951 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-295-Sentence-2951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathrm{PSNR}=10\\log_{10}{\\frac{L^{2}}{\\mathrm{MSE}}}$$"@en ;
    askg-onto:inSentence "$$\\mathrm{PSNR}=10\\log_{10}{\\frac{L^{2}}{\\mathrm{MSE}}}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mse,
        askg-data:Entity-psnr .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "where L is the dynamic range of image pixel intensities (*i.e.*, 255 for image). The usage of MSE and PSNR has many attractive features *e.g.* 1) it is simple, 2) all norms are valid distance metrics, 3) it has a clear physical meaning, and 4) these are excellent metrics in the context of optimization. The mentioned measures assume that the signal fidelity is independent of the relationship between 1) the original signal, 2) the distorted and original signal, and 3) the signs of the error signal. Unfortunately, none of them even roughly holds in the context of measuring the visual perception of image fidelity [59]. In the next section, we discuss alternatives to these measures."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2961,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2962,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2963,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2964,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2965 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2961 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where L is the dynamic range of image pixel intensities (*i.e.*, 255 for image)."@en ;
    askg-onto:inSentence "where L is the dynamic range of image pixel intensities (*i.e.*, 255 for image)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_pixel_intensities,
        askg-data:Entity-l .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2962 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The usage of MSE and PSNR has many attractive features *e.g.* 1) it is simple, 2) all norms are valid distance metrics, 3) it has a clear physical meaning, and 4) these are excellent metrics in the context of optimization."@en ;
    askg-onto:inSentence "The usage of MSE and PSNR has many attractive features *e.g.* 1) it is simple, 2) all norms are valid distance metrics, 3) it has a clear physical meaning, and 4) these are excellent metrics in the context of optimization."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-clear_physical_meaning,
        askg-data:Entity-excellent_metrics_in_optimization,
        askg-data:Entity-metric,
        askg-data:Entity-mse,
        askg-data:Entity-psnr,
        askg-data:Entity-simple,
        askg-data:Entity-valid_distance_metrics .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2963 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The mentioned measures assume that the signal fidelity is independent of the relationship between 1) the original signal, 2) the distorted and original signal, and 3) the signs of the error signal."@en ;
    askg-onto:inSentence "The mentioned measures assume that the signal fidelity is independent of the relationship between 1) the original signal, 2) the distorted and original signal, and 3) the signs of the error signal."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-distorted_and_original_signal,
        askg-data:Entity-error_signal,
        askg-data:Entity-original_signal,
        askg-data:Entity-relationship,
        askg-data:Entity-signal_fidelity,
        askg-data:Entity-signs .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2964 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Unfortunately, none of them even roughly holds in the context of measuring the visual perception of image fidelity [59]."@en ;
    askg-onto:inSentence "Unfortunately, none of them even roughly holds in the context of measuring the visual perception of image fidelity [59]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_fidelity,
        askg-data:Entity-visual_perception .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-296-Sentence-2965 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In the next section, we discuss alternatives to these measures."@en ;
    askg-onto:inSentence "In the next section, we discuss alternatives to these measures."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alternatives,
        askg-data:Entity-measures .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "- SSIM: Another commonly used measure is the Structural SIMilarity (SSIM) index. The main ideas of SSIM were presented by Wang & Bovik [57] and formulated in [58, 60]. Let us consider that x and y are the patches taken from the two different images but locations to be compared against each other. Then SSIM takes three measures into account, which are the similarity of the patch 1) luminance l(*x, y*), 2) contrasts c(x, y), and 3) the local structures s(*x, y*). As pointed out in [60], these similarities are expressed and computed using simple statistics and are combined to produce local SSIM as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2971,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2972,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2973,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2974,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2975 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2971 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- SSIM: Another commonly used measure is the Structural SIMilarity (SSIM) index."@en ;
    askg-onto:inSentence "- SSIM: Another commonly used measure is the Structural SIMilarity (SSIM) index."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ssim,
        askg-data:Entity-structural_similarity_ssim_index .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2972 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The main ideas of SSIM were presented by Wang & Bovik [57] and formulated in [58, 60]."@en ;
    askg-onto:inSentence "The main ideas of SSIM were presented by Wang & Bovik [57] and formulated in [58, 60]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-58_60,
        askg-data:Entity-ssim,
        askg-data:Entity-wang__bovik .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2973 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Let us consider that x and y are the patches taken from the two different images but locations to be compared against each other."@en ;
    askg-onto:inSentence "Let us consider that x and y are the patches taken from the two different images but locations to be compared against each other."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-x,
        askg-data:Entity-y .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2974 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Then SSIM takes three measures into account, which are the similarity of the patch 1) luminance l(*x, y*), 2) contrasts c(x, y), and 3) the local structures s(*x, y*)."@en ;
    askg-onto:inSentence "Then SSIM takes three measures into account, which are the similarity of the patch 1) luminance l(*x, y*), 2) contrasts c(x, y), and 3) the local structures s(*x, y*)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-contrasts_cx_y,
        askg-data:Entity-local_structures_sx_y,
        askg-data:Entity-luminance_lx_y,
        askg-data:Entity-ssim .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-297-Sentence-2975 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "As pointed out in [60], these similarities are expressed and computed using simple statistics and are combined to produce local SSIM as:"@en ;
    askg-onto:inSentence "As pointed out in [60], these similarities are expressed and computed using simple statistics and are combined to produce local SSIM as:"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-local_ssim,
        askg-data:Entity-similarities,
        askg-data:Entity-simple_statistics .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "SSIM = $l(x,y)\\cdot c(x,y)\\cdot s(x,y)$, $$\\left(\\frac{2\\mu_{x}\\mu_{y}+C_{1}}{\\mu_{x}^{2}+\\mu_{y}^{2}+C_{1}}\\right)\\left(\\frac{2\\sigma_{x}\\sigma_{y}+C_{2}}{\\sigma_{x}^{2}+\\sigma_{y}^{2}+C_{2}}\\right)\\left(\\frac{\\sigma_{xy}+C_{3}}{\\sigma_{x}+\\sigma_{y}+C_{3}}\\right)\\tag{8}$$ = where µx and µy are means while σx and σy are standard deviations of the patches x and y, respectively. Similarly, σxy cross-correlation of the patches after removing their means. The constants C1, C2 and C3 stabilize the terms to avoid near-zero divisions."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298-Sentence-2981,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298-Sentence-2982,
        askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298-Sentence-2983 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298-Sentence-2981 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "SSIM = $l(x,y)\\cdot c(x,y)\\cdot s(x,y)$, $$\\left(\\frac{2\\mu_{x}\\mu_{y}+C_{1}}{\\mu_{x}^{2}+\\mu_{y}^{2}+C_{1}}\\right)\\left(\\frac{2\\sigma_{x}\\sigma_{y}+C_{2}}{\\sigma_{x}^{2}+\\sigma_{y}^{2}+C_{2}}\\right)\\left(\\frac{\\sigma_{xy}+C_{3}}{\\sigma_{x}+\\sigma_{y}+C_{3}}\\right)\\tag{8}$$ = where µx and µy are means while σx and σy are standard deviations of the patches x and y, respectively."@en ;
    askg-onto:inSentence "SSIM = $l(x,y)\\cdot c(x,y)\\cdot s(x,y)$, $$\\left(\\frac{2\\mu_{x}\\mu_{y}+C_{1}}{\\mu_{x}^{2}+\\mu_{y}^{2}+C_{1}}\\right)\\left(\\frac{2\\sigma_{x}\\sigma_{y}+C_{2}}{\\sigma_{x}^{2}+\\sigma_{y}^{2}+C_{2}}\\right)\\left(\\frac{\\sigma_{xy}+C_{3}}{\\sigma_{x}+\\sigma_{y}+C_{3}}\\right)\\tag{8}$$ = where µx and µy are means while σx and σy are standard deviations of the patches x and y, respectively."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C2%B5x,
        askg-data:Entity-%C2%B5y,
        askg-data:Entity-%CF%83x,
        askg-data:Entity-%CF%83y,
        askg-data:Entity-lxycdot_cxycdot_sxy,
        askg-data:Entity-patch_x,
        askg-data:Entity-patch_y,
        askg-data:Entity-ssim .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298-Sentence-2982 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Similarly, σxy cross-correlation of the patches after removing their means."@en ;
    askg-onto:inSentence "Similarly, σxy cross-correlation of the patches after removing their means."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%83xy_cross-correlation,
        askg-data:Entity-concept,
        askg-data:Entity-patches .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-298-Sentence-2983 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The constants C1, C2 and C3 stabilize the terms to avoid near-zero divisions."@en ;
    askg-onto:inSentence "The constants C1, C2 and C3 stabilize the terms to avoid near-zero divisions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c1,
        askg-data:Entity-c2,
        askg-data:Entity-c3,
        askg-data:Entity-terms .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-299 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$$({\\hat{0}})$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-299-Sentence-2991 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-29-Paragraph-299-Sentence-2991 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$({\\hat{0}})$$"@en ;
    askg-onto:inSentence "$$({\\hat{0}})$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0,
        askg-data:Entity-mathematical_object .

askg-data:Paper-c63c8058011e31f2-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "2 Background"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-3-Paragraph-31 ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-3-Paragraph-31 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this section, we mainly introduce the commonly-used physical models for underwater image enhancement, including atmospheric scattering model, simplified underwater image formation model, and revised underwater image formation model. These models are the base of training data synthesis and design of deep networks and also helpful for understanding the process of underwater image degradation."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-3-Paragraph-31-Sentence-311,
        askg-data:Paper-c63c8058011e31f2-Section-3-Paragraph-31-Sentence-312 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-3-Paragraph-31-Sentence-311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this section, we mainly introduce the commonly-used physical models for underwater image enhancement, including atmospheric scattering model, simplified underwater image formation model, and revised underwater image formation model."@en ;
    askg-onto:inSentence "In this section, we mainly introduce the commonly-used physical models for underwater image enhancement, including atmospheric scattering model, simplified underwater image formation model, and revised underwater image formation model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-physical_model,
        askg-data:Entity-revised_underwater_image_formation_model,
        askg-data:Entity-simplified_underwater_image_formation_model .

askg-data:Paper-c63c8058011e31f2-Section-3-Paragraph-31-Sentence-312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These models are the base of training data synthesis and design of deep networks and also helpful for understanding the process of underwater image degradation."@en ;
    askg-onto:inSentence "These models are the base of training data synthesis and design of deep networks and also helpful for understanding the process of underwater image degradation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_networks,
        askg-data:Entity-models,
        askg-data:Entity-training_data_synthesis,
        askg-data:Entity-understanding_the_process_of_underwater_image_degradation .

askg-data:Paper-c63c8058011e31f2-Section-30 a askg-onto:Section ;
    rdfs:label "Section 30"@en ;
    domo:Text "4.2.2 Human Visual System"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-301,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-302,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-303,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-305,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306 ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-301 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Due to the lack of real ground-truth data, human subjects are used to evaluate the quality of the predicted images to an attempt to incorporate the perceptual"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-301-Sentence-3011 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-301-Sentence-3011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Due to the lack of real ground-truth data, human subjects are used to evaluate the quality of the predicted images to an attempt to incorporate the perceptual"@en ;
    askg-onto:inSentence "Due to the lack of real ground-truth data, human subjects are used to evaluate the quality of the predicted images to an attempt to incorporate the perceptual"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-human_subjects,
        askg-data:Entity-quality_of_the_predicted_images .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-302 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "| | | | | UWE Dataset | | | |---------------------|--------|---------|--------|---------------|---------|--------| | Method | PSNR ↑ | MSE ↓ | SSIM ↑ | PCQI ↑ | UCIQE ↑ | UIQM ↑ | | Original | 17.36 | 1768.90 | 0.6168 | 1.1118 | 0.5196 | 1.1571 | | MCycleGAN [39] | 18.33 | 1132.21 | 0.6138 | 0.4521 | 0.5196 | 1.1471 | | URCNN [21] | 15.94 | 2195.89 | 0.5972 | 1.0936 | 0.5196 | 1.5332 | | UWGAN [34] | 16.06 | 1853.70 | 0.2945 | 0.6000 | 0.5921 | 1.1099 | | DUIENet [35] | 19.29 | 1012.20 | 0.8093 | 0.9844 | 0.5720 | 1.2963 | | DenseGAN [16] | 17.56 | 1363.60 | 0.4239 | 0.6697 | 0.6291 | 1.0952 | | UWCNN type\\-1 [3] | 13.03 | 3930.80 | 0.4795 | 1.0310 | 0.4876 | 1.1319 | | UWCNN type\\-3 [3] | 13.58 | 3297.40 | 0.5482 | 1.0146 | 0.4771 | 1.1035 | | UWCNN type\\-5 [3] | 13.29 | 3427.20 | 0.5102 | 0.9223 | 0.4303 | 1.0122 | | UWCNN type\\-7 [3] | 13.30 | 3372.60 | 0.4287 | 0.8693 | 0.4533 | 1.0385 | | UWCNN type\\-9 [3] | 10.58 | 6164.80 | 0.2598 | 0.4958 | 0.3636 | 0.7775 | | UWCNN type\\-I [3] | 15.00 | 2345.00 | 0.5306 | 1.0890 | 0.4954 | 1.1294 | | UWCNN type\\-II [3] | 13.46 | 3654.10 | 0.4509 | 1.0631 | 0.4766 | 1.1048 | | UWCNN type\\-III [3] | 14.24 | 2920.20 | 0.4945 | 1.0486 | 0.4739 | 1.0333 |"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-302-Sentence-3021 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-302-Sentence-3021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | | | | UWE Dataset | | | |---------------------|--------|---------|--------|---------------|---------|--------| | Method | PSNR ↑ | MSE ↓ | SSIM ↑ | PCQI ↑ | UCIQE ↑ | UIQM ↑ | | Original | 17.36 | 1768.90 | 0.6168 | 1.1118 | 0.5196 | 1.1571 | | MCycleGAN [39] | 18.33 | 1132.21 | 0.6138 | 0.4521 | 0.5196 | 1.1471 | | URCNN [21] | 15.94 | 2195.89 | 0.5972 | 1.0936 | 0.5196 | 1.5332 | | UWGAN [34] | 16.06 | 1853.70 | 0.2945 | 0.6000 | 0.5921 | 1.1099 | | DUIENet [35] | 19.29 | 1012.20 | 0.8093 | 0.9844 | 0.5720 | 1.2963 | | DenseGAN [16] | 17.56 | 1363.60 | 0.4239 | 0.6697 | 0.6291 | 1.0952 | | UWCNN type\\-1 [3] | 13.03 | 3930.80 | 0.4795 | 1.0310 | 0.4876 | 1.1319 | | UWCNN type\\-3 [3] | 13.58 | 3297.40 | 0.5482 | 1.0146 | 0.4771 | 1.1035 | | UWCNN type\\-5 [3] | 13.29 | 3427.20 | 0.5102 | 0.9223 | 0.4303 | 1.0122 | | UWCNN type\\-7 [3] | 13.30 | 3372.60 | 0.4287 | 0.8693 | 0.4533 | 1.0385 | | UWCNN type\\-9 [3] | 10.58 | 6164.80 | 0.2598 | 0.4958 | 0.3636 | 0.7775 | | UWCNN type\\-I [3] | 15.00 | 2345.00 | 0.5306 | 1.0890 | 0.4954 | 1.1294 | | UWCNN type\\-II [3] | 13.46 | 3654.10 | 0.4509 | 1.0631 | 0.4766 | 1.1048 | | UWCNN type\\-III [3] | 14.24 | 2920.20 | 0.4945 | 1.0486 | 0.4739 | 1.0333 |"@en ;
    askg-onto:inSentence "| | | | | UWE Dataset | | | |---------------------|--------|---------|--------|---------------|---------|--------| | Method | PSNR ↑ | MSE ↓ | SSIM ↑ | PCQI ↑ | UCIQE ↑ | UIQM ↑ | | Original | 17.36 | 1768.90 | 0.6168 | 1.1118 | 0.5196 | 1.1571 | | MCycleGAN [39] | 18.33 | 1132.21 | 0.6138 | 0.4521 | 0.5196 | 1.1471 | | URCNN [21] | 15.94 | 2195.89 | 0.5972 | 1.0936 | 0.5196 | 1.5332 | | UWGAN [34] | 16.06 | 1853.70 | 0.2945 | 0.6000 | 0.5921 | 1.1099 | | DUIENet [35] | 19.29 | 1012.20 | 0.8093 | 0.9844 | 0.5720 | 1.2963 | | DenseGAN [16] | 17.56 | 1363.60 | 0.4239 | 0.6697 | 0.6291 | 1.0952 | | UWCNN type\\-1 [3] | 13.03 | 3930.80 | 0.4795 | 1.0310 | 0.4876 | 1.1319 | | UWCNN type\\-3 [3] | 13.58 | 3297.40 | 0.5482 | 1.0146 | 0.4771 | 1.1035 | | UWCNN type\\-5 [3] | 13.29 | 3427.20 | 0.5102 | 0.9223 | 0.4303 | 1.0122 | | UWCNN type\\-7 [3] | 13.30 | 3372.60 | 0.4287 | 0.8693 | 0.4533 | 1.0385 | | UWCNN type\\-9 [3] | 10.58 | 6164.80 | 0.2598 | 0.4958 | 0.3636 | 0.7775 | | UWCNN type\\-I [3] | 15.00 | 2345.00 | 0.5306 | 1.0890 | 0.4954 | 1.1294 | | UWCNN type\\-II [3] | 13.46 | 3654.10 | 0.4509 | 1.0631 | 0.4766 | 1.1048 | | UWCNN type\\-III [3] | 14.24 | 2920.20 | 0.4945 | 1.0486 | 0.4739 | 1.0333 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-densegan,
        askg-data:Entity-duienet,
        askg-data:Entity-mcyclegan,
        askg-data:Entity-original,
        askg-data:Entity-urcnn,
        askg-data:Entity-uwcnn_type-1,
        askg-data:Entity-uwcnn_type-3,
        askg-data:Entity-uwcnn_type-5,
        askg-data:Entity-uwcnn_type-7,
        askg-data:Entity-uwcnn_type-9,
        askg-data:Entity-uwcnn_type-i,
        askg-data:Entity-uwcnn_type-ii,
        askg-data:Entity-uwcnn_type-iii,
        askg-data:Entity-uwe_dataset,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-303 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Table 2 Quantitative results: The best results are highlighted with red color while the blue color represents the second best."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-303-Sentence-3031 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-303-Sentence-3031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 2 Quantitative results: The best results are highlighted with red color while the blue color represents the second best."@en ;
    askg-onto:inSentence "Table 2 Quantitative results: The best results are highlighted with red color while the blue color represents the second best."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-quantitative_results .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "measures. These human inputs may either be crowdsourced or specialist persons in different competitions. However, none of these methods have shown any significant advantage over the mathematical measure. In other words, mathematically defined measures are still attractive due to the following reasons."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3041,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3042,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3043,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3044 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "measures."@en ;
    askg-onto:inSentence "measures."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-measures,
        askg-data:Entity-metrics .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3042 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These human inputs may either be crowdsourced or specialist persons in different competitions."@en ;
    askg-onto:inSentence "These human inputs may either be crowdsourced or specialist persons in different competitions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-crowdsourced,
        askg-data:Entity-different_competitions,
        askg-data:Entity-human_inputs,
        askg-data:Entity-specialist_persons .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3043 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, none of these methods have shown any significant advantage over the mathematical measure."@en ;
    askg-onto:inSentence "However, none of these methods have shown any significant advantage over the mathematical measure."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mathematical_measure,
        askg-data:Entity-methods .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-304-Sentence-3044 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In other words, mathematically defined measures are still attractive due to the following reasons."@en ;
    askg-onto:inSentence "In other words, mathematically defined measures are still attractive due to the following reasons."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mathematically_defined_measures,
        askg-data:Entity-reasons .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-305 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "- They are simple to calculate and computationally inexpensive normally."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-305-Sentence-3051 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-305-Sentence-3051 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- They are simple to calculate and computationally inexpensive normally."@en ;
    askg-onto:inSentence "- They are simple to calculate and computationally inexpensive normally."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-simple_to_calculate_and_computationally_inexpensive_normally,
        askg-data:Entity-they .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "- They are independent of distinct individuals and observing conditions. Furthermore, it is thought that viewing conditions play an influential role in human perception of image quality. However, if there are multiple viewing conditions, a method dependent on viewing conditions may produce different estimations that may be inconvenient to utilize. Moreover, it may also be specific to the user observation, and it then becomes the responsibility of each to compute the viewing conditions and provide the output to the measurement systems. On the other hand, a method independent of viewing conditions computes a single quantity that provides a general idea about the image quality. Besides, the experience of volunteers significantly affects human visual perception. The volunteers who understand what the degrading effects of attenuation and backscatter are, and what it looks like when either is improperly corrected can provide more reliable subjective scores of image quality."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3061,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3062,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3063,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3064,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3065,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3066,
        askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3067 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3061 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- They are independent of distinct individuals and observing conditions."@en ;
    askg-onto:inSentence "- They are independent of distinct individuals and observing conditions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-distinct_individuals,
        askg-data:Entity-observing_conditions,
        askg-data:Entity-they .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3062 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Furthermore, it is thought that viewing conditions play an influential role in human perception of image quality."@en ;
    askg-onto:inSentence "Furthermore, it is thought that viewing conditions play an influential role in human perception of image quality."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-human_perception_of_image_quality,
        askg-data:Entity-viewing_conditions .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3063 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, if there are multiple viewing conditions, a method dependent on viewing conditions may produce different estimations that may be inconvenient to utilize."@en ;
    askg-onto:inSentence "However, if there are multiple viewing conditions, a method dependent on viewing conditions may produce different estimations that may be inconvenient to utilize."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-estimations,
        askg-data:Entity-inconvenient_to_utilize,
        askg-data:Entity-method,
        askg-data:Entity-viewing_conditions .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3064 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, it may also be specific to the user observation, and it then becomes the responsibility of each to compute the viewing conditions and provide the output to the measurement systems."@en ;
    askg-onto:inSentence "Moreover, it may also be specific to the user observation, and it then becomes the responsibility of each to compute the viewing conditions and provide the output to the measurement systems."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-measurement_systems,
        askg-data:Entity-output,
        askg-data:Entity-user_observation,
        askg-data:Entity-viewing_conditions .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3065 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "On the other hand, a method independent of viewing conditions computes a single quantity that provides a general idea about the image quality."@en ;
    askg-onto:inSentence "On the other hand, a method independent of viewing conditions computes a single quantity that provides a general idea about the image quality."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-general_idea,
        askg-data:Entity-image_quality,
        askg-data:Entity-method,
        askg-data:Entity-single_quantity,
        askg-data:Entity-viewing_conditions .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3066 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Besides, the experience of volunteers significantly affects human visual perception."@en ;
    askg-onto:inSentence "Besides, the experience of volunteers significantly affects human visual perception."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-human_visual_perception,
        askg-data:Entity-volunteers .

askg-data:Paper-c63c8058011e31f2-Section-30-Paragraph-306-Sentence-3067 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The volunteers who understand what the degrading effects of attenuation and backscatter are, and what it looks like when either is improperly corrected can provide more reliable subjective scores of image quality."@en ;
    askg-onto:inSentence "The volunteers who understand what the degrading effects of attenuation and backscatter are, and what it looks like when either is improperly corrected can provide more reliable subjective scores of image quality."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attenuation,
        askg-data:Entity-backscatter,
        askg-data:Entity-degrading_effect,
        askg-data:Entity-subjective_scores_of_image_quality,
        askg-data:Entity-volunteers .

askg-data:Paper-c63c8058011e31f2-Section-31 a askg-onto:Section ;
    rdfs:label "Section 31"@en ;
    domo:Text "4.3 Benchmark Results"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-313,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-314,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315 ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The benchmark results for each technique8 on UIEBD [35] dataset are reported in Table 2. The quantitative experiments are conducted on UIEBD [35] because it is, to the best of our knowledge, the only one dataset which provides the corresponding reference images for image quality assessment. The results by using reference images can provide realistic feedback on the quality of enhanced results to some extent. Moreover, in case of multiple variants of the same algorithm, all the results are reported. We encourage the readers to consult the original paper for a detailed analysis of each variant of the same model."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3111,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3112,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3113,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3114,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3115 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The benchmark results for each technique8 on UIEBD [35] dataset are reported in Table 2."@en ;
    askg-onto:inSentence "The benchmark results for each technique8 on UIEBD [35] dataset are reported in Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-benchmark_results,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The quantitative experiments are conducted on UIEBD [35] because it is, to the best of our knowledge, the only one dataset which provides the corresponding reference images for image quality assessment."@en ;
    askg-onto:inSentence "The quantitative experiments are conducted on UIEBD [35] because it is, to the best of our knowledge, the only one dataset which provides the corresponding reference images for image quality assessment."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_quality_assessment,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The results by using reference images can provide realistic feedback on the quality of enhanced results to some extent."@en ;
    askg-onto:inSentence "The results by using reference images can provide realistic feedback on the quality of enhanced results to some extent."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-enhanced_results,
        askg-data:Entity-quality,
        askg-data:Entity-realistic_feedback,
        askg-data:Entity-reference_images .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, in case of multiple variants of the same algorithm, all the results are reported."@en ;
    askg-onto:inSentence "Moreover, in case of multiple variants of the same algorithm, all the results are reported."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-all_the_results,
        askg-data:Entity-multiple_variants,
        askg-data:Entity-results .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-311-Sentence-3115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We encourage the readers to consult the original paper for a detailed analysis of each variant of the same model."@en ;
    askg-onto:inSentence "We encourage the readers to consult the original paper for a detailed analysis of each variant of the same model."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-original_paper,
        askg-data:Entity-readers .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The results are presented via the metrics mentioned earlier. It is to be noted here that the PSNR, SSIM, PCQI, UCIQE, and UIQM, the higher, the better while the MSE, the lower, the better. Also, to be fair amidst all the methods under consideration, we resize the output of the network where the predicted image is a scaleddown version of the underwater scene input. From Table 2, DUIENet [35] results are the best among the competitors while the UWCNN [3] performs worst due to training on the synthesized underwater images which are different from the images in the UIEBD [35]. However, it is challenging to state the superiority of one method against the others due to many factors involved, for example, the number of parameters, the depth of network, training images, patch size, number of channels and loss function, *etc.* To compare fairly, most of these determinants should be kept consistent. To further validate the performance of different deep algorithms, we conduct qualitative comparisons on diverse underwater images from different datasets in the next section."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3121,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3122,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3123,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3124,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3125,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3126 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The results are presented via the metrics mentioned earlier."@en ;
    askg-onto:inSentence "The results are presented via the metrics mentioned earlier."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-metrics,
        askg-data:Entity-results .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It is to be noted here that the PSNR, SSIM, PCQI, UCIQE, and UIQM, the higher, the better while the MSE, the lower, the better."@en ;
    askg-onto:inSentence "It is to be noted here that the PSNR, SSIM, PCQI, UCIQE, and UIQM, the higher, the better while the MSE, the lower, the better."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-error_measurement,
        askg-data:Entity-image_quality,
        askg-data:Entity-mse,
        askg-data:Entity-pcqi,
        askg-data:Entity-psnr,
        askg-data:Entity-ssim,
        askg-data:Entity-uciqe,
        askg-data:Entity-uiqm .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Also, to be fair amidst all the methods under consideration, we resize the output of the network where the predicted image is a scaleddown version of the underwater scene input."@en ;
    askg-onto:inSentence "Also, to be fair amidst all the methods under consideration, we resize the output of the network where the predicted image is a scaleddown version of the underwater scene input."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-network,
        askg-data:Entity-output,
        askg-data:Entity-scaleddown_version_of_underwater_scene_input .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "From Table 2, DUIENet [35] results are the best among the competitors while the UWCNN [3] performs worst due to training on the synthesized underwater images which are different from the images in the UIEBD [35]."@en ;
    askg-onto:inSentence "From Table 2, DUIENet [35] results are the best among the competitors while the UWCNN [3] performs worst due to training on the synthesized underwater images which are different from the images in the UIEBD [35]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_among_the_competitors,
        askg-data:Entity-duienet,
        askg-data:Entity-images,
        askg-data:Entity-images_in_the_uiebd,
        askg-data:Entity-synthesized_underwater_images,
        askg-data:Entity-uiebd,
        askg-data:Entity-uwcnn,
        askg-data:Entity-worst_due_to_training_on_the_synthesized_underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "However, it is challenging to state the superiority of one method against the others due to many factors involved, for example, the number of parameters, the depth of network, training images, patch size, number of channels and loss function, *etc.* To compare fairly, most of these determinants should be kept consistent."@en ;
    askg-onto:inSentence "However, it is challenging to state the superiority of one method against the others due to many factors involved, for example, the number of parameters, the depth of network, training images, patch size, number of channels and loss function, *etc.* To compare fairly, most of these determinants should be kept consistent."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_of_network,
        askg-data:Entity-loss_function,
        askg-data:Entity-method,
        askg-data:Entity-method_performance,
        askg-data:Entity-number_of_channels,
        askg-data:Entity-number_of_parameters,
        askg-data:Entity-others,
        askg-data:Entity-patch_size,
        askg-data:Entity-training_images .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-312-Sentence-3126 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "To further validate the performance of different deep algorithms, we conduct qualitative comparisons on diverse underwater images from different datasets in the next section."@en ;
    askg-onto:inSentence "To further validate the performance of different deep algorithms, we conduct qualitative comparisons on diverse underwater images from different datasets in the next section."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-deep_algorithms,
        askg-data:Entity-diverse_underwater_images,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-313 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "8 The results are reported for the methods having the source code or executables available or the respected authors agreed to provide the results on the dataset."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-313-Sentence-3131 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-313-Sentence-3131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "8 The results are reported for the methods having the source code or executables available or the respected authors agreed to provide the results on the dataset."@en ;
    askg-onto:inSentence "8 The results are reported for the methods having the source code or executables available or the respected authors agreed to provide the results on the dataset."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-authors,
        askg-data:Entity-dataset,
        askg-data:Entity-methods,
        askg-data:Entity-results,
        askg-data:Entity-source_code_or_executables .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-314 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-314-Sentence-3141 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-314-Sentence-3141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:inSentence "![13_image_0.png](13_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-artificial_neural_networks,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-data_analysis,
        askg-data:Entity-data_science,
        askg-data:Entity-deep_learning,
        askg-data:Entity-k-means_clustering,
        askg-data:Entity-machine_learning,
        askg-data:Entity-machine_learning_algorithm,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-random_forest,
        askg-data:Entity-statistical_analysis,
        askg-data:Entity-support_vector_machine .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Fig. 4 Visual comparison of greenish images: Comparisons of different methods on the greenish underwater samples from UIEBD [35]. Here, UWCNN-type-I represents the model trained by synthetic type-I training data."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315-Sentence-3151,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315-Sentence-3152,
        askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315-Sentence-3153 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315-Sentence-3151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-unknown .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315-Sentence-3152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "4 Visual comparison of greenish images: Comparisons of different methods on the greenish underwater samples from UIEBD [35]."@en ;
    askg-onto:inSentence "4 Visual comparison of greenish images: Comparisons of different methods on the greenish underwater samples from UIEBD [35]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_methods,
        askg-data:Entity-greenish_underwater_samples,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-31-Paragraph-315-Sentence-3153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Here, UWCNN-type-I represents the model trained by synthetic type-I training data."@en ;
    askg-onto:inSentence "Here, UWCNN-type-I represents the model trained by synthetic type-I training data."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-synthetic_type-i_training_data,
        askg-data:Entity-uwcnn-type-i .

askg-data:Paper-c63c8058011e31f2-Section-32 a askg-onto:Section ;
    rdfs:label "Section 32"@en ;
    domo:Text "4.4 Qualitative Comparisons"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-321,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-324,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-325,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-326,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-328,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-329 ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-321 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We present the visual results on UIEBD [35], Hazeline [6] and ULFID [52] in Figures 4-8. The groundtruth images for Haze-line [6] and ULFID [52] are not available; hence, we furnish the visual results only for both the datasets."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-321-Sentence-3211,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-321-Sentence-3212 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-321-Sentence-3211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We present the visual results on UIEBD [35], Hazeline [6] and ULFID [52] in Figures 4-8."@en ;
    askg-onto:inSentence "We present the visual results on UIEBD [35], Hazeline [6] and ULFID [52] in Figures 4-8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figures_4-8,
        askg-data:Entity-hazeline,
        askg-data:Entity-uiebd,
        askg-data:Entity-ulfid .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-321-Sentence-3212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The groundtruth images for Haze-line [6] and ULFID [52] are not available; hence, we furnish the visual results only for both the datasets."@en ;
    askg-onto:inSentence "The groundtruth images for Haze-line [6] and ULFID [52] are not available; hence, we furnish the visual results only for both the datasets."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-both_the_datasets,
        askg-data:Entity-groundtruth_images,
        askg-data:Entity-haze-line,
        askg-data:Entity-ulfid,
        askg-data:Entity-visual_results .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Fig. 6 The low and high backscatter images: The challenging images to remove the backscatter. The images are selected from UIEBD [35] dataset. The top image shows the low backscatter, while the bottom image illustrates the high backscatter."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32101,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32102,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32103,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32104 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_unspecified_concept,
        askg-data:Entity-fig .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "6 The low and high backscatter images: The challenging images to remove the backscatter."@en ;
    askg-onto:inSentence "6 The low and high backscatter images: The challenging images to remove the backscatter."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backscatter_images,
        askg-data:Entity-challenging_images .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32103 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The images are selected from UIEBD [35] dataset."@en ;
    askg-onto:inSentence "The images are selected from UIEBD [35] dataset."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-images,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3210-Sentence-32104 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The top image shows the low backscatter, while the bottom image illustrates the high backscatter."@en ;
    askg-onto:inSentence "The top image shows the low backscatter, while the bottom image illustrates the high backscatter."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom_image,
        askg-data:Entity-high_backscatter,
        askg-data:Entity-low_backscatter,
        askg-data:Entity-top_image .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "computing the evaluation metrics. The images in this dataset are challenging since most of the images have bluish tone and high backscatter. UWGAN [34] and DenseGAN [16] provide visually promising results, but both have created false colors, and this is also the case with DUIENet [35] and MCycle- GAN [39] networks. It is obvious that all deep algorithms fall behind the performance of a conventional method [6] which mismatches the progress of deep learning in other low-level visual tasks."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32111,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32112,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32113,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32114 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "computing the evaluation metrics."@en ;
    askg-onto:inSentence "computing the evaluation metrics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_metrics .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The images in this dataset are challenging since most of the images have bluish tone and high backscatter."@en ;
    askg-onto:inSentence "The images in this dataset are challenging since most of the images have bluish tone and high backscatter."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-images .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "UWGAN [34] and DenseGAN [16] provide visually promising results, but both have created false colors, and this is also the case with DUIENet [35] and MCycle- GAN [39] networks."@en ;
    askg-onto:inSentence "UWGAN [34] and DenseGAN [16] provide visually promising results, but both have created false colors, and this is also the case with DUIENet [35] and MCycle- GAN [39] networks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-densegan,
        askg-data:Entity-duienet,
        askg-data:Entity-false_colors,
        askg-data:Entity-mcycle-gan,
        askg-data:Entity-uwgan,
        askg-data:Entity-visually_promising_results .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3211-Sentence-32114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "It is obvious that all deep algorithms fall behind the performance of a conventional method [6] which mismatches the progress of deep learning in other low-level visual tasks."@en ;
    askg-onto:inSentence "It is obvious that all deep algorithms fall behind the performance of a conventional method [6] which mismatches the progress of deep learning in other low-level visual tasks."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conventional_method,
        askg-data:Entity-deep_algorithms,
        askg-data:Entity-deep_learning,
        askg-data:Entity-low-level_visual_tasks .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "- ULFID [52] images: As the last example, we show the images with severe degradations from ULFID [52] in Figure 8. The ground-truth images for this dataset are not feasible to evaluate the models; hence, we only present the visual results. Although the deep algorithms can remove the greenish tone from the images; however, all of them fail to furnish clear images and even amplify the noise. This dataset is an excellent example that the underwater image enhancement still requires concerted efforts to progress, and the noise in underwater images should be paid more attention in the future study."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32121,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32122,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32123,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32124 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- ULFID [52] images: As the last example, we show the images with severe degradations from ULFID [52] in Figure 8."@en ;
    askg-onto:inSentence "- ULFID [52] images: As the last example, we show the images with severe degradations from ULFID [52] in Figure 8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-images,
        askg-data:Entity-ulfid .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The ground-truth images for this dataset are not feasible to evaluate the models; hence, we only present the visual results."@en ;
    askg-onto:inSentence "The ground-truth images for this dataset are not feasible to evaluate the models; hence, we only present the visual results."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_images,
        askg-data:Entity-models .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Although the deep algorithms can remove the greenish tone from the images; however, all of them fail to furnish clear images and even amplify the noise."@en ;
    askg-onto:inSentence "Although the deep algorithms can remove the greenish tone from the images; however, all of them fail to furnish clear images and even amplify the noise."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-clear_images,
        askg-data:Entity-deep_algorithms,
        askg-data:Entity-greenish_tone,
        askg-data:Entity-noise .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-3212-Sentence-32124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This dataset is an excellent example that the underwater image enhancement still requires concerted efforts to progress, and the noise in underwater images should be paid more attention in the future study."@en ;
    askg-onto:inSentence "This dataset is an excellent example that the underwater image enhancement still requires concerted efforts to progress, and the noise in underwater images should be paid more attention in the future study."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-future_study,
        askg-data:Entity-noise,
        askg-data:Entity-noise_in_underwater_images,
        askg-data:Entity-underwater_image_enhancement,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "- Greenish tone images: In Figure 4, we present the visual comparisons of greenish underwater images from UIEBD [35] for the state-of-the-art CNN- based and GAN-based methods. The GAN-based models aim to improve the perceptual quality, while CNN models are more focused on the PSNR values of the enhanced images. One can notice that the outputs of GAN methods are generally different in the tone as compared to CNN methods, as the later is more faithful to the original underwater image colors. This also contributes to the higher PSNR for the CNN methods compared to GAN methods, as shown in Table 2. It is to be noted that in Figure 4, we only show one of the variants in case of the same algorithm for the limited space."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3221,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3222,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3223,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3224,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3225 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Greenish tone images: In Figure 4, we present the visual comparisons of greenish underwater images from UIEBD [35] for the state-of-the-art CNN- based and GAN-based methods."@en ;
    askg-onto:inSentence "- Greenish tone images: In Figure 4, we present the visual comparisons of greenish underwater images from UIEBD [35] for the state-of-the-art CNN- based and GAN-based methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn-based_methods,
        askg-data:Entity-gan-based_methods,
        askg-data:Entity-greenish_underwater_images,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The GAN-based models aim to improve the perceptual quality, while CNN models are more focused on the PSNR values of the enhanced images."@en ;
    askg-onto:inSentence "The GAN-based models aim to improve the perceptual quality, while CNN models are more focused on the PSNR values of the enhanced images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn_models,
        askg-data:Entity-enhanced_images,
        askg-data:Entity-gan-based_models,
        askg-data:Entity-perceptual_quality,
        askg-data:Entity-psnr_values .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "One can notice that the outputs of GAN methods are generally different in the tone as compared to CNN methods, as the later is more faithful to the original underwater image colors."@en ;
    askg-onto:inSentence "One can notice that the outputs of GAN methods are generally different in the tone as compared to CNN methods, as the later is more faithful to the original underwater image colors."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn_methods,
        askg-data:Entity-gan_methods,
        askg-data:Entity-original_underwater_image_colors .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This also contributes to the higher PSNR for the CNN methods compared to GAN methods, as shown in Table 2."@en ;
    askg-onto:inSentence "This also contributes to the higher PSNR for the CNN methods compared to GAN methods, as shown in Table 2."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn_methods,
        askg-data:Entity-gan_methods,
        askg-data:Entity-higher_psnr .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-322-Sentence-3225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "It is to be noted that in Figure 4, we only show one of the variants in case of the same algorithm for the limited space."@en ;
    askg-onto:inSentence "It is to be noted that in Figure 4, we only show one of the variants in case of the same algorithm for the limited space."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-figure_4,
        askg-data:Entity-same,
        askg-data:Entity-variant .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "- Bluish tone images: Figure 5 shows the visual comparisons on two bluish images from UIEBD [35] consisting of a ray and statues. The bluish tone is ubiquitous in underwater images and difficult to be completely removed by current algorithms. DUIENet [35] and UWCNN [3] render the best outcomes; however, the results still have a bluish tone, especially"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323-Sentence-3231,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323-Sentence-3232,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323-Sentence-3233 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323-Sentence-3231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Bluish tone images: Figure 5 shows the visual comparisons on two bluish images from UIEBD [35] consisting of a ray and statues."@en ;
    askg-onto:inSentence "- Bluish tone images: Figure 5 shows the visual comparisons on two bluish images from UIEBD [35] consisting of a ray and statues."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bluish_images,
        askg-data:Entity-figure_5,
        askg-data:Entity-ray,
        askg-data:Entity-statues,
        askg-data:Entity-uiebd,
        askg-data:Entity-visual_comparisons .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323-Sentence-3232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The bluish tone is ubiquitous in underwater images and difficult to be completely removed by current algorithms."@en ;
    askg-onto:inSentence "The bluish tone is ubiquitous in underwater images and difficult to be completely removed by current algorithms."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bluish_tone,
        askg-data:Entity-current_algorithms .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-323-Sentence-3233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "DUIENet [35] and UWCNN [3] render the best outcomes; however, the results still have a bluish tone, especially"@en ;
    askg-onto:inSentence "DUIENet [35] and UWCNN [3] render the best outcomes; however, the results still have a bluish tone, especially"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_outcomes,
        askg-data:Entity-duienet,
        askg-data:Entity-uwcnn .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-324 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-324-Sentence-3241 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-324-Sentence-3241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:inSentence "![14_image_0.png](14_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-big_data,
        askg-data:Entity-data_analysis,
        askg-data:Entity-data_science,
        askg-data:Entity-innovation,
        askg-data:Entity-machine_learning,
        askg-data:Entity-research_area,
        askg-data:Entity-technology .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-325 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Fig. 5 Qualitative comparisons on bluish images: The results of various CNN-based and GAN-based methods on the sample underwater images from UIEBD [35]."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-325-Sentence-3251,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-325-Sentence-3252 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-325-Sentence-3251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-325-Sentence-3252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "5 Qualitative comparisons on bluish images: The results of various CNN-based and GAN-based methods on the sample underwater images from UIEBD [35]."@en ;
    askg-onto:inSentence "5 Qualitative comparisons on bluish images: The results of various CNN-based and GAN-based methods on the sample underwater images from UIEBD [35]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn-based_methods,
        askg-data:Entity-gan-based_methods,
        askg-data:Entity-sample_underwater_images,
        askg-data:Entity-uiebd .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-326 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "in far distances (more severe backscatter). By contrast, the UWGAN [34] and DenseGAN [16] introduces obvious artificial colors mainly inducing by the shortcomings of their unpaired training data."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-326-Sentence-3261,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-326-Sentence-3262 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-326-Sentence-3261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "in far distances (more severe backscatter)."@en ;
    askg-onto:inSentence "in far distances (more severe backscatter)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backscatter,
        askg-data:Entity-far_distances .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-326-Sentence-3262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "By contrast, the UWGAN [34] and DenseGAN [16] introduces obvious artificial colors mainly inducing by the shortcomings of their unpaired training data."@en ;
    askg-onto:inSentence "By contrast, the UWGAN [34] and DenseGAN [16] introduces obvious artificial colors mainly inducing by the shortcomings of their unpaired training data."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_colors,
        askg-data:Entity-densegan,
        askg-data:Entity-gan,
        askg-data:Entity-unpaired_training_data,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "- Low and high backscatter images: Backscatter is a challenging problem faced during the underwater imaginary. The leading causes of backscattering are the strobes or the internal flash, which lights up the particles in the water present between the subject and the camera lens. This phenomenon can also be observed behind the subject, lighting up the open water. With a dark background, backscattering is more natural to recognize. Here, we present two images in Figure 6 on low and high backscatter from [35]. The first image in Figure 6 is an example of low backscatter, while the bottom one is of high backscatter. We can visually observe that the URCNN [21] has over-exposed the images while the UWGAN [34] created some artificial colors. In addition, the low backscatter is relatively easier to be removed than the high backscatter. For the high backscatter image, none of the methods can produce visually pleasing results and current methods even introduce annoying artifacts and color casts. It should also be regarded here that UWCNN [3] can produce good results if the model matches the type of water."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3271,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-32710,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3272,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3273,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3274,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3275,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3276,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3277,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3278,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3279 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Low and high backscatter images: Backscatter is a challenging problem faced during the underwater imaginary."@en ;
    askg-onto:inSentence "- Low and high backscatter images: Backscatter is a challenging problem faced during the underwater imaginary."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backscatter,
        askg-data:Entity-underwater_imagery .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-32710 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "It should also be regarded here that UWCNN [3] can produce good results if the model matches the type of water."@en ;
    askg-onto:inSentence "It should also be regarded here that UWCNN [3] can produce good results if the model matches the type of water."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-good_results,
        askg-data:Entity-the_type_of_water,
        askg-data:Entity-uwcnn .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3272 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The leading causes of backscattering are the strobes or the internal flash, which lights up the particles in the water present between the subject and the camera lens."@en ;
    askg-onto:inSentence "The leading causes of backscattering are the strobes or the internal flash, which lights up the particles in the water present between the subject and the camera lens."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backscattering,
        askg-data:Entity-internal_flash,
        askg-data:Entity-particles_in_the_water,
        askg-data:Entity-strobes .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3273 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This phenomenon can also be observed behind the subject, lighting up the open water."@en ;
    askg-onto:inSentence "This phenomenon can also be observed behind the subject, lighting up the open water."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-open_water,
        askg-data:Entity-phenomenon .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3274 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "With a dark background, backscattering is more natural to recognize."@en ;
    askg-onto:inSentence "With a dark background, backscattering is more natural to recognize."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backscattering,
        askg-data:Entity-dark_background .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3275 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Here, we present two images in Figure 6 on low and high backscatter from [35]."@en ;
    askg-onto:inSentence "Here, we present two images in Figure 6 on low and high backscatter from [35]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_6,
        askg-data:Entity-high_backscatter,
        askg-data:Entity-images,
        askg-data:Entity-low_backscatter .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3276 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The first image in Figure 6 is an example of low backscatter, while the bottom one is of high backscatter."@en ;
    askg-onto:inSentence "The first image in Figure 6 is an example of low backscatter, while the bottom one is of high backscatter."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_6,
        askg-data:Entity-high_backscatter,
        askg-data:Entity-low_backscatter .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3277 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We can visually observe that the URCNN [21] has over-exposed the images while the UWGAN [34] created some artificial colors."@en ;
    askg-onto:inSentence "We can visually observe that the URCNN [21] has over-exposed the images while the UWGAN [34] created some artificial colors."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_colors,
        askg-data:Entity-over-exposed_the_images,
        askg-data:Entity-urcnn,
        askg-data:Entity-uwgan .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3278 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In addition, the low backscatter is relatively easier to be removed than the high backscatter."@en ;
    askg-onto:inSentence "In addition, the low backscatter is relatively easier to be removed than the high backscatter."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-high_backscatter,
        askg-data:Entity-low_backscatter .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-327-Sentence-3279 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "For the high backscatter image, none of the methods can produce visually pleasing results and current methods even introduce annoying artifacts and color casts."@en ;
    askg-onto:inSentence "For the high backscatter image, none of the methods can produce visually pleasing results and current methods even introduce annoying artifacts and color casts."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artifacts,
        askg-data:Entity-color_casts,
        askg-data:Entity-methods,
        askg-data:Entity-visually_pleasing_results .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-328 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "- Haze-line [6] images: The visual comparisons for underwater images from Haze-line dataset [6] is provided in Figure 7. This dataset only provides the depth maps reconstructed from the stereo images; however, no ground-truth images are available for"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-328-Sentence-3281,
        askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-328-Sentence-3282 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-328-Sentence-3281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Haze-line [6] images: The visual comparisons for underwater images from Haze-line dataset [6] is provided in Figure 7."@en ;
    askg-onto:inSentence "- Haze-line [6] images: The visual comparisons for underwater images from Haze-line dataset [6] is provided in Figure 7."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-haze-line_dataset,
        askg-data:Entity-haze-line_images .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-328-Sentence-3282 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This dataset only provides the depth maps reconstructed from the stereo images; however, no ground-truth images are available for"@en ;
    askg-onto:inSentence "This dataset only provides the depth maps reconstructed from the stereo images; however, no ground-truth images are available for"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-depth_maps,
        askg-data:Entity-ground-truth_images,
        askg-data:Entity-stereo_images .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-329 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-329-Sentence-3291 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-32-Paragraph-329-Sentence-3291 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:inSentence "![15_image_0.png](15_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_science,
        askg-data:Entity-experiment,
        askg-data:Entity-institution,
        askg-data:Entity-journal,
        askg-data:Entity-machine_learning,
        askg-data:Entity-metric,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-research_area,
        askg-data:Entity-researcher,
        askg-data:Entity-result,
        askg-data:Entity-study .

askg-data:Paper-c63c8058011e31f2-Section-33 a askg-onto:Section ;
    rdfs:label "Section 33"@en ;
    domo:Text "5 Future And Emerging Directions"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3310,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3311,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3312,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-332,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-335,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-338,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-339 ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Underwater image enhancement is a classical research area and has improved a lot in recent years, mainly due to the rapid development of deep learning techniques. The performance is still lacking in many aspects when compared to other image enhancement techniques like image super-resolution, deblurring, and dehazing. There is ample room to advancement the underwater image enhancement direction. Here, in the following paragraphs, we present the list of some of the potential future directions."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3311,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3312,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3313,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3314 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Underwater image enhancement is a classical research area and has improved a lot in recent years, mainly due to the rapid development of deep learning techniques."@en ;
    askg-onto:inSentence "Underwater image enhancement is a classical research area and has improved a lot in recent years, mainly due to the rapid development of deep learning techniques."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_techniques,
        askg-data:Entity-research_area,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The performance is still lacking in many aspects when compared to other image enhancement techniques like image super-resolution, deblurring, and dehazing."@en ;
    askg-onto:inSentence "The performance is still lacking in many aspects when compared to other image enhancement techniques like image super-resolution, deblurring, and dehazing."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deblurring,
        askg-data:Entity-dehazing,
        askg-data:Entity-image_enhancement_techniques,
        askg-data:Entity-image_super-resolution .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "There is ample room to advancement the underwater image enhancement direction."@en ;
    askg-onto:inSentence "There is ample room to advancement the underwater image enhancement direction."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advancement,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-331-Sentence-3314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Here, in the following paragraphs, we present the list of some of the potential future directions."@en ;
    askg-onto:inSentence "Here, in the following paragraphs, we present the list of some of the potential future directions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_directions,
        askg-data:Entity-list .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3310 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Fig. 8 Images from ULFID [52]: A challenging dataset where all the methods fail to provide clean results."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3310-Sentence-33101,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3310-Sentence-33102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3310-Sentence-33101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-unspecified .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3310-Sentence-33102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "8 Images from ULFID [52]: A challenging dataset where all the methods fail to provide clean results."@en ;
    askg-onto:inSentence "8 Images from ULFID [52]: A challenging dataset where all the methods fail to provide clean results."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-methods,
        askg-data:Entity-ulfid .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3311 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "This has shown an increase in the performance in areas like visual question answering and would likely help to improve underwater image enhancement."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3311-Sentence-33111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3311-Sentence-33111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This has shown an increase in the performance in areas like visual question answering and would likely help to improve underwater image enhancement."@en ;
    askg-onto:inSentence "This has shown an increase in the performance in areas like visual question answering and would likely help to improve underwater image enhancement."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-underwater_image_enhancement,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3312 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "- Unsupervised learning: Due to the lack of dataset, which has underwater images and their ground-truth images, many methods generate synthetic data to train their models. Although these models exhibit promising results for synthetic underwater scenes; however, they fail on real-world underwater images."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3312-Sentence-33121,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3312-Sentence-33122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3312-Sentence-33121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Unsupervised learning: Due to the lack of dataset, which has underwater images and their ground-truth images, many methods generate synthetic data to train their models."@en ;
    askg-onto:inSentence "- Unsupervised learning: Due to the lack of dataset, which has underwater images and their ground-truth images, many methods generate synthetic data to train their models."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-ground-truth_images,
        askg-data:Entity-learning_method,
        askg-data:Entity-methods,
        askg-data:Entity-synthetic_data,
        askg-data:Entity-underwater_images,
        askg-data:Entity-unsupervised_learning .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3312-Sentence-33122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Although these models exhibit promising results for synthetic underwater scenes; however, they fail on real-world underwater images."@en ;
    askg-onto:inSentence "Although these models exhibit promising results for synthetic underwater scenes; however, they fail on real-world underwater images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-models,
        askg-data:Entity-promising_results,
        askg-data:Entity-real-world_underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "To deal with the lack of data, a possible research direction could be unsupervised learning, also known as zero-shot or few-shot learning. This capability may lead to promising results, but the zero-shot problem itself is not trivial. A more realistic scenario would be to employ the present limited datasets, few-shot learning, where the network learns from a few available images. The development of unsupervised learning is an open research problem."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33131,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33132,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33133,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33134 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To deal with the lack of data, a possible research direction could be unsupervised learning, also known as zero-shot or few-shot learning."@en ;
    askg-onto:inSentence "To deal with the lack of data, a possible research direction could be unsupervised learning, also known as zero-shot or few-shot learning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-unsupervised_learning,
        askg-data:Entity-zero-shot_or_few-shot_learning .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This capability may lead to promising results, but the zero-shot problem itself is not trivial."@en ;
    askg-onto:inSentence "This capability may lead to promising results, but the zero-shot problem itself is not trivial."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-not_trivial,
        askg-data:Entity-zero-shot_problem .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A more realistic scenario would be to employ the present limited datasets, few-shot learning, where the network learns from a few available images."@en ;
    askg-onto:inSentence "A more realistic scenario would be to employ the present limited datasets, few-shot learning, where the network learns from a few available images."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-available_images,
        askg-data:Entity-few-shot_learning,
        askg-data:Entity-limited_datasets,
        askg-data:Entity-network .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3313-Sentence-33134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The development of unsupervised learning is an open research problem."@en ;
    askg-onto:inSentence "The development of unsupervised learning is an open research problem."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-open_research_problem,
        askg-data:Entity-unsupervised_learning .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "- Real vs. Synthetic: Existing algorithms use diverse physical (mathematical) models to generate underwater images. The distribution of the generated underwater scenes may not be conferred to the real-world scenes; therefore, the models trained on artificially produced datasets lack generalization capability. A more thorough and exhaustive effort is required to generate artificial datasets, and one solution may be to use GAN-based networks to transfer style from underwater images to the simulated scenes. Even though minimal work [38] has been done in this direction, still there is a lot of scope of improvement."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33141,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33142,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33143,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33144,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33145 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Real vs."@en ;
    askg-onto:inSentence "- Real vs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-real .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Synthetic: Existing algorithms use diverse physical (mathematical) models to generate underwater images."@en ;
    askg-onto:inSentence "Synthetic: Existing algorithms use diverse physical (mathematical) models to generate underwater images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-diverse_physical_mathematical_models,
        askg-data:Entity-existing_algorithms,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The distribution of the generated underwater scenes may not be conferred to the real-world scenes; therefore, the models trained on artificially produced datasets lack generalization capability."@en ;
    askg-onto:inSentence "The distribution of the generated underwater scenes may not be conferred to the real-world scenes; therefore, the models trained on artificially produced datasets lack generalization capability."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificially_produced_datasets,
        askg-data:Entity-generalization_capability,
        askg-data:Entity-models .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "A more thorough and exhaustive effort is required to generate artificial datasets, and one solution may be to use GAN-based networks to transfer style from underwater images to the simulated scenes."@en ;
    askg-onto:inSentence "A more thorough and exhaustive effort is required to generate artificial datasets, and one solution may be to use GAN-based networks to transfer style from underwater images to the simulated scenes."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_datasets,
        askg-data:Entity-gan-based_networks,
        askg-data:Entity-simulated_scenes,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-3314-Sentence-33145 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Even though minimal work [38] has been done in this direction, still there is a lot of scope of improvement."@en ;
    askg-onto:inSentence "Even though minimal work [38] has been done in this direction, still there is a lot of scope of improvement."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-improvement,
        askg-data:Entity-minimal_work,
        askg-data:Entity-scope,
        askg-data:Entity-this_direction .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-332 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![16_image_0.png](16_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-332-Sentence-3321 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-332-Sentence-3321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![16_image_0.png](16_image_0.png)"@en ;
    askg-onto:inSentence "![16_image_0.png](16_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_vision,
        askg-data:Entity-image_recognition,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-research_area .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Fig. 7 Visual comparisons on Haze-line [6]: The Haze-line dataset provides an accurate distance based on the stereo. To be fair to the authors of Haze-line [6], we have also included the results of the best performer (*i.e.*, Haze-line [6], a conventional method) on this dataset."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333-Sentence-3331,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333-Sentence-3332,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333-Sentence-3333 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333-Sentence-3331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fig."@en ;
    askg-onto:inSentence "Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-visual_information .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333-Sentence-3332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "7 Visual comparisons on Haze-line [6]: The Haze-line dataset provides an accurate distance based on the stereo."@en ;
    askg-onto:inSentence "7 Visual comparisons on Haze-line [6]: The Haze-line dataset provides an accurate distance based on the stereo."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-accurate_distance,
        askg-data:Entity-haze-line,
        askg-data:Entity-haze-line_dataset,
        askg-data:Entity-stereo .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-333-Sentence-3333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To be fair to the authors of Haze-line [6], we have also included the results of the best performer (*i.e.*, Haze-line [6], a conventional method) on this dataset."@en ;
    askg-onto:inSentence "To be fair to the authors of Haze-line [6], we have also included the results of the best performer (*i.e.*, Haze-line [6], a conventional method) on this dataset."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conventional_method,
        askg-data:Entity-haze-line,
        askg-data:Entity-this_dataset .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "- Datasets: Underwater image enhancement methods usually employ synthetic images for training due to lack of representative real-world underwater images and its corresponding ground-truth images. Although there are limited datasets available, which have underwater and their reference images; however, these datasets consist of a finite number of images and are typically used as test images rather than training the models. A true effort in this direction may improve the performance of underwater image enhancement models and also provide realistic feedback on the image quality of enhanced results by different methods."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334-Sentence-3341,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334-Sentence-3342,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334-Sentence-3343 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334-Sentence-3341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Datasets: Underwater image enhancement methods usually employ synthetic images for training due to lack of representative real-world underwater images and its corresponding ground-truth images."@en ;
    askg-onto:inSentence "- Datasets: Underwater image enhancement methods usually employ synthetic images for training due to lack of representative real-world underwater images and its corresponding ground-truth images."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_images,
        askg-data:Entity-real-world_underwater_images,
        askg-data:Entity-representative_images,
        askg-data:Entity-synthetic_images,
        askg-data:Entity-training,
        askg-data:Entity-underwater_image_enhancement_methods .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334-Sentence-3342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Although there are limited datasets available, which have underwater and their reference images; however, these datasets consist of a finite number of images and are typically used as test images rather than training the models."@en ;
    askg-onto:inSentence "Although there are limited datasets available, which have underwater and their reference images; however, these datasets consist of a finite number of images and are typically used as test images rather than training the models."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-test_images,
        askg-data:Entity-underwater_and_their_reference_images .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-334-Sentence-3343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A true effort in this direction may improve the performance of underwater image enhancement models and also provide realistic feedback on the image quality of enhanced results by different methods."@en ;
    askg-onto:inSentence "A true effort in this direction may improve the performance of underwater image enhancement models and also provide realistic feedback on the image quality of enhanced results by different methods."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_methods,
        askg-data:Entity-image_quality_of_enhanced_results,
        askg-data:Entity-performance,
        askg-data:Entity-underwater_image_enhancement_models .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-335 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "- Objective functions and evaluation metrics: Current algorithms predominantly employ objective functions common to image enhancement techniques."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-335-Sentence-3351 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-335-Sentence-3351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Objective functions and evaluation metrics: Current algorithms predominantly employ objective functions common to image enhancement techniques."@en ;
    askg-onto:inSentence "- Objective functions and evaluation metrics: Current algorithms predominantly employ objective functions common to image enhancement techniques."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_algorithms,
        askg-data:Entity-evaluation_metrics,
        askg-data:Entity-image_enhancement_techniques,
        askg-data:Entity-objective_functions .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Although these functions produce some favorable results; however, none of them incorporate the underwater physical model properties. Likewise, the available evaluation metrics to underwater images are limited and have failure cases, which keeps the field of underwater image enhancement at a standstill. For example, the visual results shown in Figures 4-8 do not match the quantitative results in Table 2. Therefore, more specialized objective functions and evaluation metrics are required to advance the underwater image enhancement research."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3361,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3362,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3363,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3364 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Although these functions produce some favorable results; however, none of them incorporate the underwater physical model properties."@en ;
    askg-onto:inSentence "Although these functions produce some favorable results; however, none of them incorporate the underwater physical model properties."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-functions,
        askg-data:Entity-none,
        askg-data:Entity-results,
        askg-data:Entity-underwater_physical_model_properties .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Likewise, the available evaluation metrics to underwater images are limited and have failure cases, which keeps the field of underwater image enhancement at a standstill."@en ;
    askg-onto:inSentence "Likewise, the available evaluation metrics to underwater images are limited and have failure cases, which keeps the field of underwater image enhancement at a standstill."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_metrics,
        askg-data:Entity-failure_cases,
        askg-data:Entity-underwater_image_enhancement,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3363 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For example, the visual results shown in Figures 4-8 do not match the quantitative results in Table 2."@en ;
    askg-onto:inSentence "For example, the visual results shown in Figures 4-8 do not match the quantitative results in Table 2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figures_4-8,
        askg-data:Entity-table_2 .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-336-Sentence-3364 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Therefore, more specialized objective functions and evaluation metrics are required to advance the underwater image enhancement research."@en ;
    askg-onto:inSentence "Therefore, more specialized objective functions and evaluation metrics are required to advance the underwater image enhancement research."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_metrics,
        askg-data:Entity-specialized_objective_functions,
        askg-data:Entity-underwater_image_enhancement_research .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "- Prior knowledge: The human perception of the scene depends on the extensive domain or prior knowledge. When experts describe the image quality, they don't solely rely on the content of the visuals; instead, they also use their domain knowledge. An exciting venue to explore is to augment the current techniques with prior or domain knowledge [62]."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337-Sentence-3371,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337-Sentence-3372,
        askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337-Sentence-3373 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337-Sentence-3371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "- Prior knowledge: The human perception of the scene depends on the extensive domain or prior knowledge."@en ;
    askg-onto:inSentence "- Prior knowledge: The human perception of the scene depends on the extensive domain or prior knowledge."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain_knowledge,
        askg-data:Entity-human_perception .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337-Sentence-3372 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "When experts describe the image quality, they don't solely rely on the content of the visuals; instead, they also use their domain knowledge."@en ;
    askg-onto:inSentence "When experts describe the image quality, they don't solely rely on the content of the visuals; instead, they also use their domain knowledge."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain_knowledge,
        askg-data:Entity-experts,
        askg-data:Entity-image_quality .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-337-Sentence-3373 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "An exciting venue to explore is to augment the current techniques with prior or domain knowledge [62]."@en ;
    askg-onto:inSentence "An exciting venue to explore is to augment the current techniques with prior or domain knowledge [62]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_techniques,
        askg-data:Entity-prior_or_domain_knowledge .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-338 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "18 Saeed Anwar∗, Chongyi Li∗"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-338-Sentence-3381 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-338-Sentence-3381 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "18 Saeed Anwar∗, Chongyi Li∗"@en ;
    askg-onto:inSentence "18 Saeed Anwar∗, Chongyi Li∗"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-chongyi_li,
        askg-data:Entity-saeed_anwar .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-339 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "![17_image_0.png](17_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-339-Sentence-3391 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-33-Paragraph-339-Sentence-3391 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![17_image_0.png](17_image_0.png)"@en ;
    askg-onto:inSentence "![17_image_0.png](17_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_area .

askg-data:Paper-c63c8058011e31f2-Section-34 a askg-onto:Section ;
    rdfs:label "Section 34"@en ;
    domo:Text "6 Conclusion"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343 ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We presented the first comprehensive literature survey on CNNs and GANs for underwater image enhancement. To the best of our knowledge, we have included all the deep learning-based methods, which deal with underwater image enhancement, including those which are available on arxiv9. Moreover, we provided and reviewed the datasets, which can be used for training and testing the algorithms. We also discussed the details of the evaluation metrics with their limitations. Using all the metrics, we compared the performance on the benchmark dataset. We also presented the visual comparisons to illustrate the varying difficulty and the robustness of the algorithms. As a final step, we reviewed the limitations and provided future research areas to advance the underwater image enhancement."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3411,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3412,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3413,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3414,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3415,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3416,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3417 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We presented the first comprehensive literature survey on CNNs and GANs for underwater image enhancement."@en ;
    askg-onto:inSentence "We presented the first comprehensive literature survey on CNNs and GANs for underwater image enhancement."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnns,
        askg-data:Entity-comprehensive_literature_survey,
        askg-data:Entity-gans,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To the best of our knowledge, we have included all the deep learning-based methods, which deal with underwater image enhancement, including those which are available on arxiv9."@en ;
    askg-onto:inSentence "To the best of our knowledge, we have included all the deep learning-based methods, which deal with underwater image enhancement, including those which are available on arxiv9."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv9,
        askg-data:Entity-deep_learning-based_methods,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Moreover, we provided and reviewed the datasets, which can be used for training and testing the algorithms."@en ;
    askg-onto:inSentence "Moreover, we provided and reviewed the datasets, which can be used for training and testing the algorithms."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-datasets,
        askg-data:Entity-training_and_testing,
        askg-data:Entity-training_and_testing_the_algorithms .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We also discussed the details of the evaluation metrics with their limitations."@en ;
    askg-onto:inSentence "We also discussed the details of the evaluation metrics with their limitations."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_metrics,
        askg-data:Entity-limitations .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Using all the metrics, we compared the performance on the benchmark dataset."@en ;
    askg-onto:inSentence "Using all the metrics, we compared the performance on the benchmark dataset."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-benchmark_dataset,
        askg-data:Entity-performance .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We also presented the visual comparisons to illustrate the varying difficulty and the robustness of the algorithms."@en ;
    askg-onto:inSentence "We also presented the visual comparisons to illustrate the varying difficulty and the robustness of the algorithms."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-robustness,
        askg-data:Entity-varying_difficulty .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-341-Sentence-3417 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "As a final step, we reviewed the limitations and provided future research areas to advance the underwater image enhancement."@en ;
    askg-onto:inSentence "As a final step, we reviewed the limitations and provided future research areas to advance the underwater image enhancement."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_research_areas,
        askg-data:Entity-limitations,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The deep learning-based underwater image enhancement methods still follow the development of deep learning ranging from CNNs to GANs. Most of the current models are the modifications of existing network architectures such as encoder-decoder network and CycleGAN. The significant difference is the training data (*i.e.*, underwater images). Besides, there is no network architecture or loss function well-designed for underwater image enhancement tasks, which results in the unstable and visually unpleasing results. In most cases, the deep learning-based methods fall behind state-ofthe-art conventional methods. More importantly, almost all models use synthetic data for networks' training. The synthetic training data limit the generalization of models. Thus, the development of deep learningbased underwater image enhancement has a long way to go."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3421,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3422,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3423,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3424,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3425,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3426,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3427,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3428 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The deep learning-based underwater image enhancement methods still follow the development of deep learning ranging from CNNs to GANs."@en ;
    askg-onto:inSentence "The deep learning-based underwater image enhancement methods still follow the development of deep learning ranging from CNNs to GANs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnns,
        askg-data:Entity-deep_learning,
        askg-data:Entity-deep_learning-based_underwater_image_enhancement_methods,
        askg-data:Entity-gans .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Most of the current models are the modifications of existing network architectures such as encoder-decoder network and CycleGAN."@en ;
    askg-onto:inSentence "Most of the current models are the modifications of existing network architectures such as encoder-decoder network and CycleGAN."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_models,
        askg-data:Entity-cyclegan,
        askg-data:Entity-encoder-decoder_network,
        askg-data:Entity-existing_network_architectures .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The significant difference is the training data (*i.e.*, underwater images)."@en ;
    askg-onto:inSentence "The significant difference is the training data (*i.e.*, underwater images)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-training_data,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Besides, there is no network architecture or loss function well-designed for underwater image enhancement tasks, which results in the unstable and visually unpleasing results."@en ;
    askg-onto:inSentence "Besides, there is no network architecture or loss function well-designed for underwater image enhancement tasks, which results in the unstable and visually unpleasing results."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-loss_function,
        askg-data:Entity-network_architecture,
        askg-data:Entity-underwater_image_enhancement_tasks .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In most cases, the deep learning-based methods fall behind state-ofthe-art conventional methods."@en ;
    askg-onto:inSentence "In most cases, the deep learning-based methods fall behind state-ofthe-art conventional methods."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_methods,
        askg-data:Entity-state-of-the-art_conventional_methods .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "More importantly, almost all models use synthetic data for networks' training."@en ;
    askg-onto:inSentence "More importantly, almost all models use synthetic data for networks' training."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-models,
        askg-data:Entity-networks,
        askg-data:Entity-synthetic_data .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3427 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The synthetic training data limit the generalization of models."@en ;
    askg-onto:inSentence "The synthetic training data limit the generalization of models."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalization_of_models,
        askg-data:Entity-synthetic_training_data .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-342-Sentence-3428 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Thus, the development of deep learningbased underwater image enhancement has a long way to go."@en ;
    askg-onto:inSentence "Thus, the development of deep learningbased underwater image enhancement has a long way to go."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning-based_underwater_image_enhancement,
        askg-data:Entity-long_way_to_go .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "According to our survey, the underwater research progress is hindered by the lack of purposely built evaluation metrics and large training dataset. The current metrics are taken from the image enhancement while the training datasets are synthetically generated. One approach to develop evaluation metrics is to incorporate underwater image properties. Similarly, more realistic datasets can be created using the GANs."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3431,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3432,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3433,
        askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3434 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "According to our survey, the underwater research progress is hindered by the lack of purposely built evaluation metrics and large training dataset."@en ;
    askg-onto:inSentence "According to our survey, the underwater research progress is hindered by the lack of purposely built evaluation metrics and large training dataset."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lack_of_purposely_built_evaluation_metrics,
        askg-data:Entity-large_training_dataset,
        askg-data:Entity-underwater_research_progress .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The current metrics are taken from the image enhancement while the training datasets are synthetically generated."@en ;
    askg-onto:inSentence "The current metrics are taken from the image enhancement while the training datasets are synthetically generated."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_metrics,
        askg-data:Entity-image_enhancement,
        askg-data:Entity-synthetically,
        askg-data:Entity-training_datasets .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "One approach to develop evaluation metrics is to incorporate underwater image properties."@en ;
    askg-onto:inSentence "One approach to develop evaluation metrics is to incorporate underwater image properties."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_metrics,
        askg-data:Entity-underwater_image_properties .

askg-data:Paper-c63c8058011e31f2-Section-34-Paragraph-343-Sentence-3434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Similarly, more realistic datasets can be created using the GANs."@en ;
    askg-onto:inSentence "Similarly, more realistic datasets can be created using the GANs."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-gans .

askg-data:Paper-c63c8058011e31f2-Section-35 a askg-onto:Section ;
    rdfs:label "Section 35"@en ;
    domo:Text "References"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-356,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357 ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "1. Akkaynak, D., Treibitz, T.: A revised underwater image formation model. In: CVPR (2018) 2. Anwar, S., Barnes, N.: Densely residual laplacian superresolution. arXiv preprint arXiv:1906.12021 (2019) 3. Anwar, S., Li, C., Porikli, F.: Deep underwater image enhancement. arXiv preprint arXiv:1807.03528 (2018) 4. Aucuti, C., Ancuti, C.O., Bekaert, P.: Enhancing underwater images and videos by fusion. In: CVPR (2012) 5. Badrinarayanan, V., Kendall, A., Cipolla, R.: Segnet: A deep convolutional encoder-decoder architecture for image segmentation. TPAMI (2017) 6. Berman, D., Levy, D., Avidan, S., Treibitz, T.: Underwater single image color restoration using hazelines and a new quantitative dataset. arXiv preprint arXiv:1811.01343 (2018) 7. Boom, B.J., He, J., Palazzo, S., Huang, P.X., Chou, H.M., Lin, F.P., Spampinato, C., Fisher, R.B.: A research tool for long-term and continuous analysis of fish assemblage in coral-reefs using underwater camera footage. In: Ecological Informatics (2014) 8. Cao, K., Peng, Y.T., Cosman, P.C.: Underwater image restoration using deep networks to estimate background light and scene depth. In: SSIAI (2018) 9. Chiang, J., Chen, Y.: Underwater image enhancement by wavelength compensation and dehazing. IEEE Transactions on Image Processing 21(4), 1756–1769 (2012) 10. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: CVPR (2009) 11. Eigen, D., Puhrsch, C., Fergus, R.: Depth map prediction from a single image using a multi-scale deep network. In: NIPS (2014) 12. Fabbri, C., Islam, M.J., Sattar, J.: Enhancing underwater imagery using generative adversarial networks. arXiv preprint arXiv:1801.04011 (2018) 13. Goodfellow, I.: Generative adversarial nets. In: NIPS (2014) 14. Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C.: Improved training of wasserstein gans. In: NIPS (2017) 15. Guo, C., Li, C., Guo, J., etal: Hierarchical features driven residual learning for depth map super-resolution. TIP (2018)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3511,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35110,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35111,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35112,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35113,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35114,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35115,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35116,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35117,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35118,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35119,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3512,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35120,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35121,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35122,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35123,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35124,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35125,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35126,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35127,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35128,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35129,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3513,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35130,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35131,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3514,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3515,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3516,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3517,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3518,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3519 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1."@en ;
    askg-onto:inSentence "1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-company,
        askg-data:Entity-deep_learning,
        askg-data:Entity-google,
        askg-data:Entity-gpt-3,
        askg-data:Entity-information_retrieval,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing_model,
        askg-data:Entity-nlp,
        askg-data:Entity-triple_extraction .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Badrinarayanan, V., Kendall, A., Cipolla, R.: Segnet: A deep convolutional encoder-decoder architecture for image segmentation."@en ;
    askg-onto:inSentence "Badrinarayanan, V., Kendall, A., Cipolla, R.: Segnet: A deep convolutional encoder-decoder architecture for image segmentation."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-badrinarayanan_v,
        askg-data:Entity-cipolla_r,
        askg-data:Entity-deep_convolutional_encoder-decoder_architecture_for_image_segmentation,
        askg-data:Entity-kendall_a,
        askg-data:Entity-segnet,
        askg-data:Entity-segnet_a_deep_convolutional_encoder-decoder_architecture_for_image_segmentation .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "TPAMI (2017) 6."@en ;
    askg-onto:inSentence "TPAMI (2017) 6."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-tpami .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Berman, D., Levy, D., Avidan, S., Treibitz, T.: Underwater single image color restoration using hazelines and a new quantitative dataset."@en ;
    askg-onto:inSentence "Berman, D., Levy, D., Avidan, S., Treibitz, T.: Underwater single image color restoration using hazelines and a new quantitative dataset."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_new_quantitative_dataset,
        askg-data:Entity-avidan_s,
        askg-data:Entity-berman_d,
        askg-data:Entity-color_restoration,
        askg-data:Entity-dataset,
        askg-data:Entity-levy_d,
        askg-data:Entity-treibitz_t,
        askg-data:Entity-underwater_single_image_color_restoration,
        askg-data:Entity-underwater_single_image_color_restoration_using_hazelines_and_a_new_quantitative_dataset .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "arXiv preprint arXiv:1811.01343 (2018) 7."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1811.01343 (2018) 7."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-arxiv181101343,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Boom, B.J., He, J., Palazzo, S., Huang, P.X., Chou, H.M., Lin, F.P., Spampinato, C., Fisher, R.B.: A research tool for long-term and continuous analysis of fish assemblage in coral-reefs using underwater camera footage."@en ;
    askg-onto:inSentence "Boom, B.J., He, J., Palazzo, S., Huang, P.X., Chou, H.M., Lin, F.P., Spampinato, C., Fisher, R.B.: A research tool for long-term and continuous analysis of fish assemblage in coral-reefs using underwater camera footage."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_research_tool_for_long-term_and_continuous_analysis_of_fish_assemblage_in_coral-reefs,
        askg-data:Entity-author,
        askg-data:Entity-boom_bj,
        askg-data:Entity-chou_hm,
        askg-data:Entity-dataset,
        askg-data:Entity-fisher_rb,
        askg-data:Entity-he_j,
        askg-data:Entity-huang_px,
        askg-data:Entity-lin_fp,
        askg-data:Entity-palazzo_s,
        askg-data:Entity-spampinato_c,
        askg-data:Entity-tool,
        askg-data:Entity-underwater_camera_footage .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "In: Ecological Informatics (2014) 8."@en ;
    askg-onto:inSentence "In: Ecological Informatics (2014) 8."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Cao, K., Peng, Y.T., Cosman, P.C.: Underwater image restoration using deep networks to estimate background light and scene depth."@en ;
    askg-onto:inSentence "Cao, K., Peng, Y.T., Cosman, P.C.: Underwater image restoration using deep networks to estimate background light and scene depth."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-background_light_and_scene_depth,
        askg-data:Entity-cao_k,
        askg-data:Entity-cosman_pc,
        askg-data:Entity-peng_yt,
        askg-data:Entity-underwater_image_restoration_using_deep_networks .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35117 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "In: SSIAI (2018) 9."@en ;
    askg-onto:inSentence "In: SSIAI (2018) 9."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-ssiai .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35118 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Chiang, J., Chen, Y.: Underwater image enhancement by wavelength compensation and dehazing."@en ;
    askg-onto:inSentence "Chiang, J., Chen, Y.: Underwater image enhancement by wavelength compensation and dehazing."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chen_y,
        askg-data:Entity-chiang_j,
        askg-data:Entity-method,
        askg-data:Entity-underwater_image_enhancement_by_wavelength_compensation_and_dehazing .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35119 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "IEEE Transactions on Image Processing 21(4), 1756–1769 (2012) 10."@en ;
    askg-onto:inSentence "IEEE Transactions on Image Processing 21(4), 1756–1769 (2012) 10."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-17561769,
        askg-data:Entity-2012,
        askg-data:Entity-214,
        askg-data:Entity-ieee_transactions_on_image_processing,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Akkaynak, D., Treibitz, T.: A revised underwater image formation model."@en ;
    askg-onto:inSentence "Akkaynak, D., Treibitz, T.: A revised underwater image formation model."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_revised_underwater_image_formation_model,
        askg-data:Entity-akkaynak_d,
        askg-data:Entity-model,
        askg-data:Entity-treibitz_t .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35120 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database."@en ;
    askg-onto:inSentence "Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-deng_j,
        askg-data:Entity-dong_w,
        askg-data:Entity-fei-fei_l,
        askg-data:Entity-imagenet,
        askg-data:Entity-large-scale_hierarchical_image_database,
        askg-data:Entity-li_k,
        askg-data:Entity-li_lj,
        askg-data:Entity-socher_r .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35121 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "In: CVPR (2009) 11."@en ;
    askg-onto:inSentence "In: CVPR (2009) 11."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2009,
        askg-data:Entity-cvpr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35122 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Eigen, D., Puhrsch, C., Fergus, R.: Depth map prediction from a single image using a multi-scale deep network."@en ;
    askg-onto:inSentence "Eigen, D., Puhrsch, C., Fergus, R.: Depth map prediction from a single image using a multi-scale deep network."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_map_prediction_from_a_single_image_using_a_multi-scale_deep_network,
        askg-data:Entity-eigen_d,
        askg-data:Entity-fergus_r,
        askg-data:Entity-multi-scale_deep_network,
        askg-data:Entity-puhrsch_c .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35123 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "In: NIPS (2014) 12."@en ;
    askg-onto:inSentence "In: NIPS (2014) 12."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-nips .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35124 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Fabbri, C., Islam, M.J., Sattar, J.: Enhancing underwater imagery using generative adversarial networks."@en ;
    askg-onto:inSentence "Fabbri, C., Islam, M.J., Sattar, J.: Enhancing underwater imagery using generative adversarial networks."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-enhancing_underwater_imagery_using_generative_adversarial_networks,
        askg-data:Entity-fabbri_c,
        askg-data:Entity-generative_adversarial_networks,
        askg-data:Entity-islam_mj,
        askg-data:Entity-sattar_j .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35125 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "arXiv preprint arXiv:1801.04011 (2018) 13."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1801.04011 (2018) 13."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv180104011,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35126 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Goodfellow, I.: Generative adversarial nets."@en ;
    askg-onto:inSentence "Goodfellow, I.: Generative adversarial nets."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generative_adversarial_nets,
        askg-data:Entity-goodfellow_i .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35127 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "In: NIPS (2014) 14."@en ;
    askg-onto:inSentence "In: NIPS (2014) 14."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-nips .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35128 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C.: Improved training of wasserstein gans."@en ;
    askg-onto:inSentence "Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C.: Improved training of wasserstein gans."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ahmed_f,
        askg-data:Entity-arjovsky_m,
        askg-data:Entity-courville_ac,
        askg-data:Entity-dumoulin_v,
        askg-data:Entity-gulrajani_i,
        askg-data:Entity-improved_training_of_wasserstein_gans,
        askg-data:Entity-research_area .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35129 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "In: NIPS (2017) 15."@en ;
    askg-onto:inSentence "In: NIPS (2017) 15."^^xsd:string ;
    askg-onto:index "29"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In: CVPR (2018) 2."@en ;
    askg-onto:inSentence "In: CVPR (2018) 2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-cvpr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35130 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "Guo, C., Li, C., Guo, J., etal: Hierarchical features driven residual learning for depth map super-resolution."@en ;
    askg-onto:inSentence "Guo, C., Li, C., Guo, J., etal: Hierarchical features driven residual learning for depth map super-resolution."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-depth_map_super-resolution,
        askg-data:Entity-guo_c,
        askg-data:Entity-guo_j,
        askg-data:Entity-hierarchical_features_driven_residual_learning,
        askg-data:Entity-li_c,
        askg-data:Entity-method,
        askg-data:Entity-research_area .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-35131 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "TIP (2018)"@en ;
    askg-onto:inSentence "TIP (2018)"^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-tip .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Anwar, S., Barnes, N.: Densely residual laplacian superresolution."@en ;
    askg-onto:inSentence "Anwar, S., Barnes, N.: Densely residual laplacian superresolution."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anwar_s,
        askg-data:Entity-barnes_n,
        askg-data:Entity-concept,
        askg-data:Entity-densely_residual_laplacian_superresolution .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "arXiv preprint arXiv:1906.12021 (2019) 3."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1906.12021 (2019) 3."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv190612021,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Anwar, S., Li, C., Porikli, F.: Deep underwater image enhancement."@en ;
    askg-onto:inSentence "Anwar, S., Li, C., Porikli, F.: Deep underwater image enhancement."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anwar_s,
        askg-data:Entity-deep_underwater_image_enhancement,
        askg-data:Entity-li_c,
        askg-data:Entity-porikli_f,
        askg-data:Entity-research_area .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3517 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "arXiv preprint arXiv:1807.03528 (2018) 4."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1807.03528 (2018) 4."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-arxiv180703528,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3518 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Aucuti, C., Ancuti, C.O., Bekaert, P.: Enhancing underwater images and videos by fusion."@en ;
    askg-onto:inSentence "Aucuti, C., Ancuti, C.O., Bekaert, P.: Enhancing underwater images and videos by fusion."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ancuti_co,
        askg-data:Entity-aucuti_c,
        askg-data:Entity-bekaert_p,
        askg-data:Entity-enhancing_underwater_images_and_videos_by_fusion .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-351-Sentence-3519 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In: CVPR (2012) 5."@en ;
    askg-onto:inSentence "In: CVPR (2012) 5."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "9 at the time of submission 16. Guo, Y., Li, H., Zhuang, P.: Underwater image enhancement using a multiscale dense generative adversarial network. IEEE J. Oceanic. Eng. (2019) 17. He, K., Sun, J., Tang, X.: Single image haze removal using dark channel prior. TPAMI (2011) 18. He, K., Sun, J., Tang, X.: Guided image filtering. TPAMI (2013) 19. He, K., Zhang, X., Ren, S., etal: Deep residual learniing for image recognition. In: CVPR (2016) 20. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR, pp. 770–778 (2016) 21. Hou, M., Liu, R., Fan, X., Luo, Z.: Joint residual learning for underwater image enhancement. In: ICIP (2018) 22. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) 23. Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-toimage translation with conditional adversarial networks. In: CVPR (2017) 24. Janoch, A., Karayev, S., Jia, Y., Barron, J.T., Fritz, M., Saenko, K., Darrell, T.: A category-level 3d object dataset: Putting the kinect to work. In: Consumer depth cameras for computer vision (2013) 25. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution. In: ECCV (2016) 26. Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution. In: ECCV (2016) 27. Jolicoeur-Martineau, A.: The relativistic discriminator: a key element missing from standard gan. arXiv preprint arXiv:1807.00734 (2018) 28. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. ICLR (2014) 29. Koschmieder, H.: Theorie der horizontalen sichtweite."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3521,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35210,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35211,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35212,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35213,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35214,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35215,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35216,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35217,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35218,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35219,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3522,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35220,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35221,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35222,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35223,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35224,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35225,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35226,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35227,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35228,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35229,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3523,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35230,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35231,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3524,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3525,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3526,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3527,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3528,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3529 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "9 at the time of submission 16."@en ;
    askg-onto:inSentence "9 at the time of submission 16."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-16,
        askg-data:Entity-9 .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "TPAMI (2013) 19."@en ;
    askg-onto:inSentence "TPAMI (2013) 19."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication,
        askg-data:Entity-tpami .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35211 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "He, K., Zhang, X., Ren, S., etal: Deep residual learniing for image recognition."@en ;
    askg-onto:inSentence "He, K., Zhang, X., Ren, S., etal: Deep residual learniing for image recognition."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_residual_learning_for_image_recognition,
        askg-data:Entity-he_k,
        askg-data:Entity-image_recognition .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35212 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "In: CVPR (2016) 20."@en ;
    askg-onto:inSentence "In: CVPR (2016) 20."^^xsd:string ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35213 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition."@en ;
    askg-onto:inSentence "He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-deep_residual_learning,
        askg-data:Entity-he_k,
        askg-data:Entity-image_recognition,
        askg-data:Entity-method,
        askg-data:Entity-ren_s,
        askg-data:Entity-research_area,
        askg-data:Entity-sun_j,
        askg-data:Entity-zhang_x .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35214 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "In: CVPR, pp."@en ;
    askg-onto:inSentence "In: CVPR, pp."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-cvpr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35215 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "770–778 (2016) 21."@en ;
    askg-onto:inSentence "770–778 (2016) 21."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-article .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35216 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Hou, M., Liu, R., Fan, X., Luo, Z.: Joint residual learning for underwater image enhancement."@en ;
    askg-onto:inSentence "Hou, M., Liu, R., Fan, X., Luo, Z.: Joint residual learning for underwater image enhancement."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-fan_x,
        askg-data:Entity-hou_m,
        askg-data:Entity-joint_residual_learning,
        askg-data:Entity-liu_r,
        askg-data:Entity-luo_z,
        askg-data:Entity-method,
        askg-data:Entity-research_area,
        askg-data:Entity-underwater_image_enhancement .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35217 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "In: ICIP (2018) 22."@en ;
    askg-onto:inSentence "In: ICIP (2018) 22."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-icip .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35218 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) 23."@en ;
    askg-onto:inSentence "Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) 23."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization_accelerating_deep_network_training_by_reducing_internal_covariate_shift,
        askg-data:Entity-ioffe_s,
        askg-data:Entity-szegedy_c .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35219 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-toimage translation with conditional adversarial networks."@en ;
    askg-onto:inSentence "Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A.: Image-toimage translation with conditional adversarial networks."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conditional_adversarial_networks,
        askg-data:Entity-efros_aa,
        askg-data:Entity-image-to-image_translation_with_conditional_adversarial_networks,
        askg-data:Entity-isola_p,
        askg-data:Entity-zhou_t,
        askg-data:Entity-zhu_jy .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Guo, Y., Li, H., Zhuang, P.: Underwater image enhancement using a multiscale dense generative adversarial network."@en ;
    askg-onto:inSentence "Guo, Y., Li, H., Zhuang, P.: Underwater image enhancement using a multiscale dense generative adversarial network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guo_y,
        askg-data:Entity-image_enhancement,
        askg-data:Entity-multiscale_dense_generative_adversarial_network,
        askg-data:Entity-underwater_image_enhancement_using_a_multiscale_dense_generative_adversarial_network .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35220 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "In: CVPR (2017) 24."@en ;
    askg-onto:inSentence "In: CVPR (2017) 24."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-cvpr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35221 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Janoch, A., Karayev, S., Jia, Y., Barron, J.T., Fritz, M., Saenko, K., Darrell, T.: A category-level 3d object dataset: Putting the kinect to work."@en ;
    askg-onto:inSentence "Janoch, A., Karayev, S., Jia, Y., Barron, J.T., Fritz, M., Saenko, K., Darrell, T.: A category-level 3d object dataset: Putting the kinect to work."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_category-level_3d_object_dataset,
        askg-data:Entity-a_category-level_3d_object_dataset_putting_the_kinect_to_work,
        askg-data:Entity-barron_jt,
        askg-data:Entity-darrell_t,
        askg-data:Entity-dataset,
        askg-data:Entity-device,
        askg-data:Entity-fritz_m,
        askg-data:Entity-janoch_a,
        askg-data:Entity-jia_y,
        askg-data:Entity-karayev_s,
        askg-data:Entity-kinect,
        askg-data:Entity-saenko_k .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35222 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "In: Consumer depth cameras for computer vision (2013) 25."@en ;
    askg-onto:inSentence "In: Consumer depth cameras for computer vision (2013) 25."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision,
        askg-data:Entity-consumer_depth_cameras,
        askg-data:Entity-technology .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35223 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution."@en ;
    askg-onto:inSentence "Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alahi_a,
        askg-data:Entity-fei-fei_l,
        askg-data:Entity-johnson_j,
        askg-data:Entity-perceptual_losses_for_real-time_style_transfer_and_super-resolution,
        askg-data:Entity-style_transfer,
        askg-data:Entity-super-resolution .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35224 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "In: ECCV (2016) 26."@en ;
    askg-onto:inSentence "In: ECCV (2016) 26."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-eccv .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35225 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution."@en ;
    askg-onto:inSentence "Johnson, J., Alahi, A., Fei-Fei, L.: Perceptual losses for real-time style transfer and super-resolution."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alahi_a,
        askg-data:Entity-computer_vision,
        askg-data:Entity-fei-fei_l,
        askg-data:Entity-johnson_j,
        askg-data:Entity-perceptual_losses_for_real-time_style_transfer_and_super-resolution .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35226 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "In: ECCV (2016) 27."@en ;
    askg-onto:inSentence "In: ECCV (2016) 27."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eccv,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35227 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Jolicoeur-Martineau, A.: The relativistic discriminator: a key element missing from standard gan."@en ;
    askg-onto:inSentence "Jolicoeur-Martineau, A.: The relativistic discriminator: a key element missing from standard gan."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jolicoeur-martineau_a,
        askg-data:Entity-the_relativistic_discriminator_a_key_element_missing_from_standard_gan .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35228 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "arXiv preprint arXiv:1807.00734 (2018) 28."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1807.00734 (2018) 28."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv180700734,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35229 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization."@en ;
    askg-onto:inSentence "Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-adam_a_method_for_stochastic_optimization,
        askg-data:Entity-ba_j,
        askg-data:Entity-kingma_dp,
        askg-data:Entity-stochastic_optimization .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "IEEE J."@en ;
    askg-onto:inSentence "IEEE J."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_j,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35230 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "ICLR (2014) 29."@en ;
    askg-onto:inSentence "ICLR (2014) 29."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-29,
        askg-data:Entity-conference,
        askg-data:Entity-iclr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-35231 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "Koschmieder, H.: Theorie der horizontalen sichtweite."@en ;
    askg-onto:inSentence "Koschmieder, H.: Theorie der horizontalen sichtweite."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-koschmieder_h,
        askg-data:Entity-theorie_der_horizontalen_sichtweite .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Oceanic."@en ;
    askg-onto:inSentence "Oceanic."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-oceanic .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Eng."@en ;
    askg-onto:inSentence "Eng."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-eng .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3526 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "(2019) 17."@en ;
    askg-onto:inSentence "(2019) 17."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-17,
        askg-data:Entity-2019 .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3527 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "He, K., Sun, J., Tang, X.: Single image haze removal using dark channel prior."@en ;
    askg-onto:inSentence "He, K., Sun, J., Tang, X.: Single image haze removal using dark channel prior."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dark_channel_prior,
        askg-data:Entity-haze_removal,
        askg-data:Entity-he_k,
        askg-data:Entity-single_image_haze_removal,
        askg-data:Entity-single_image_haze_removal_using_dark_channel_prior .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3528 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "TPAMI (2011) 18."@en ;
    askg-onto:inSentence "TPAMI (2011) 18."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2011,
        askg-data:Entity-tpami .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-352-Sentence-3529 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "He, K., Sun, J., Tang, X.: Guided image filtering."@en ;
    askg-onto:inSentence "He, K., Sun, J., Tang, X.: Guided image filtering."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guided_image_filtering,
        askg-data:Entity-he_k,
        askg-data:Entity-image_processing .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Beitrage zur Physik der freien Atmosphare (1924) 30. Lai, K., Bo, L., Fox, D.: Unsupervised feature learning for 3d scene labeling. In: ICRA (2014) 31. LeCun, Y., Bengio, Y., Hinton, G.: Nature (2015) 32. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradientbased learning applied to document recognition. Proceedings of the IEEE (1998) 33. Ledig, C., Wang, Z., Shi, W., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., et al.: Photo-realistic single image superresolution using a generative adversarial network. In: CVPR (2017) 34. Li, C., Guo, C., Guo, J.: Emerging from water: Underwater image color correction based on weakly supervised color transfer. IEEE Signal Processing Letters (2018) 35. Li, C., Guo, C., Ren, W., Cong, R., Hou, J., Kwong, S.: An underwater image enhancement dataset and beyond."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3531,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-35310,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-35311,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3532,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3533,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3534,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3535,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3536,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3537,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3538,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3539 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Beitrage zur Physik der freien Atmosphare (1924) 30."@en ;
    askg-onto:inSentence "Beitrage zur Physik der freien Atmosphare (1924) 30."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1924,
        askg-data:Entity-30,
        askg-data:Entity-beitrage_zur_physik_der_freien_atmosphare,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-35310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "IEEE Signal Processing Letters (2018) 35."@en ;
    askg-onto:inSentence "IEEE Signal Processing Letters (2018) 35."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-35,
        askg-data:Entity-ieee_signal_processing_letters,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-35311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Li, C., Guo, C., Ren, W., Cong, R., Hou, J., Kwong, S.: An underwater image enhancement dataset and beyond."@en ;
    askg-onto:inSentence "Li, C., Guo, C., Ren, W., Cong, R., Hou, J., Kwong, S.: An underwater image enhancement dataset and beyond."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_underwater_image_enhancement_dataset,
        askg-data:Entity-an_underwater_image_enhancement_dataset_and_beyond,
        askg-data:Entity-cong_r,
        askg-data:Entity-guo_c,
        askg-data:Entity-hou_j,
        askg-data:Entity-image_enhancement,
        askg-data:Entity-kwong_s,
        askg-data:Entity-li_c,
        askg-data:Entity-ren_w .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Lai, K., Bo, L., Fox, D.: Unsupervised feature learning for 3d scene labeling."@en ;
    askg-onto:inSentence "Lai, K., Bo, L., Fox, D.: Unsupervised feature learning for 3d scene labeling."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bo_l,
        askg-data:Entity-fox_d,
        askg-data:Entity-lai_k,
        askg-data:Entity-study,
        askg-data:Entity-unsupervised_feature_learning_for_3d_scene_labeling .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In: ICRA (2014) 31."@en ;
    askg-onto:inSentence "In: ICRA (2014) 31."^^xsd:string ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "LeCun, Y., Bengio, Y., Hinton, G.: Nature (2015) 32."@en ;
    askg-onto:inSentence "LeCun, Y., Bengio, Y., Hinton, G.: Nature (2015) 32."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bengio_y,
        askg-data:Entity-hinton_g,
        askg-data:Entity-lecun_y,
        askg-data:Entity-nature_2015_32 .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3535 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradientbased learning applied to document recognition."@en ;
    askg-onto:inSentence "LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradientbased learning applied to document recognition."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bengio_y,
        askg-data:Entity-bottou_l,
        askg-data:Entity-document_recognition,
        askg-data:Entity-gradient-based_learning_applied_to_document_recognition,
        askg-data:Entity-haffner_p,
        askg-data:Entity-lecun_y .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3536 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Proceedings of the IEEE (1998) 33."@en ;
    askg-onto:inSentence "Proceedings of the IEEE (1998) 33."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings_of_the_ieee,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3537 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Ledig, C., Wang, Z., Shi, W., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., et al.: Photo-realistic single image superresolution using a generative adversarial network."@en ;
    askg-onto:inSentence "Ledig, C., Wang, Z., Shi, W., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., et al.: Photo-realistic single image superresolution using a generative adversarial network."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-acosta_a,
        askg-data:Entity-aitken_a,
        askg-data:Entity-caballero_j,
        askg-data:Entity-cunningham_a,
        askg-data:Entity-generative_adversarial_network,
        askg-data:Entity-huszar_f,
        askg-data:Entity-ledig_c,
        askg-data:Entity-photo-realistic_single_image_superresolution_using_a_generative_adversarial_network,
        askg-data:Entity-shi_w,
        askg-data:Entity-tejani_a,
        askg-data:Entity-theis_l,
        askg-data:Entity-wang_z .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3538 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In: CVPR (2017) 34."@en ;
    askg-onto:inSentence "In: CVPR (2017) 34."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-34,
        askg-data:Entity-cvpr,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-353-Sentence-3539 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Li, C., Guo, C., Guo, J.: Emerging from water: Underwater image color correction based on weakly supervised color transfer."@en ;
    askg-onto:inSentence "Li, C., Guo, C., Guo, J.: Emerging from water: Underwater image color correction based on weakly supervised color transfer."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-emerging_from_water_underwater_image_color_correction_based_on_weakly_supervised_color_transfer,
        askg-data:Entity-guo_c,
        askg-data:Entity-guo_j,
        askg-data:Entity-li_c,
        askg-data:Entity-research_area .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "arXiv preprint arXiv:1901.05495 (2019) 36. Li, C., Wand, M.: Precomputed real-time texture synthesis with markovian generative adversarial networks. In: ECCV (2016) 37. Li, H., Li, J., Wang, W.: A Fusion Adversarial Underwater Image Enhancement Network with a Public Test Dataset. arXiv e-prints arXiv:1906.06819 (2019) 38. Li, J., Skinner, K.A., Eustice, R.M., Johnson-Roberson, M.: Watergan: Unsupervised generative network to enable real-time color correction of monocular underwater images. IEEE Robotics and Automation Letters (2018) 39. Lu, J., Li, N., Zhang, S., Yu, Z., Zheng, H., Zheng, B.: Multi-scale adversarial network for underwater image restoration. Optics & Laser Technology (2019) 40. Mao, X., Shen, C., Yang, Y.B.: Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections. In: NIPS (2016) 41. Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y.: Spectral normalization for generative adversarial networks. arXiv preprint arXiv:1802.05957 (2018) 42. Nair, V., Hinton, G.E.: Rectified linear units improve restricted boltzmann machines. In: ICML (2010) 43. Oleari, F., Kallasi, F., Rizzini, D.L., Aleotti, J., Caselli, S.: An underwater stereo vision system: from design to deployment and dataset acquistion. In: OCEANS (2015) 44. Panetta, K., Gao, C., Agaian, S.: Human-visual-systeminspired underwater image quality measures. IEEE Journal of Oceanic Engineering (2015) 45. Pizarro, O., Friedman, A., Bryson, M., Williams, S.B., Madin, J.: A simple, fast, and repeatable survey method for underwater visual 3d benthic mapping and monitoring. Ecology and evolution (2017) 46. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 (2015) 47. Ren, S., He, K., Girshick, R., etal: Guided image filtering."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3541,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35410,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35411,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35412,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35413,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35414,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35415,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35416,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35417,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35418,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35419,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3542,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35420,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35421,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35422,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35423,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35424,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3543,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3544,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3545,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3546,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3547,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3548,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3549 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "arXiv preprint arXiv:1901.05495 (2019) 36."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1901.05495 (2019) 36."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv190105495,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35410 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Mao, X., Shen, C., Yang, Y.B.: Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections."@en ;
    askg-onto:inSentence "Mao, X., Shen, C., Yang, Y.B.: Image restoration using very deep convolutional encoder-decoder networks with symmetric skip connections."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_restoration_using_very_deep_convolutional_encoder-decoder_networks_with_symmetric_skip_connections,
        askg-data:Entity-mao_x,
        askg-data:Entity-method,
        askg-data:Entity-shen_c,
        askg-data:Entity-yang_yb .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35411 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "In: NIPS (2016) 41."@en ;
    askg-onto:inSentence "In: NIPS (2016) 41."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-nips,
        askg-data:Entity-nips_2016,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35412 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y.: Spectral normalization for generative adversarial networks."@en ;
    askg-onto:inSentence "Miyato, T., Kataoka, T., Koyama, M., Yoshida, Y.: Spectral normalization for generative adversarial networks."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generative_adversarial_networks,
        askg-data:Entity-kataoka_t,
        askg-data:Entity-koyama_m,
        askg-data:Entity-miyato_t,
        askg-data:Entity-spectral_normalization,
        askg-data:Entity-spectral_normalization_for_generative_adversarial_networks,
        askg-data:Entity-yoshida_y .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35413 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "arXiv preprint arXiv:1802.05957 (2018) 42."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1802.05957 (2018) 42."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv180205957,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35414 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Nair, V., Hinton, G.E.: Rectified linear units improve restricted boltzmann machines."@en ;
    askg-onto:inSentence "Nair, V., Hinton, G.E.: Rectified linear units improve restricted boltzmann machines."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hinton_ge,
        askg-data:Entity-nair_v,
        askg-data:Entity-rectified_linear_units,
        askg-data:Entity-rectified_linear_units_improve_restricted_boltzmann_machines,
        askg-data:Entity-restricted_boltzmann_machines .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35415 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "In: ICML (2010) 43."@en ;
    askg-onto:inSentence "In: ICML (2010) 43."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2010,
        askg-data:Entity-icml,
        askg-data:Entity-machine_learning .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35416 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Oleari, F., Kallasi, F., Rizzini, D.L., Aleotti, J., Caselli, S.: An underwater stereo vision system: from design to deployment and dataset acquistion."@en ;
    askg-onto:inSentence "Oleari, F., Kallasi, F., Rizzini, D.L., Aleotti, J., Caselli, S.: An underwater stereo vision system: from design to deployment and dataset acquistion."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aleotti_j,
        askg-data:Entity-an_underwater_stereo_vision_system,
        askg-data:Entity-an_underwater_stereo_vision_system_from_design_to_deployment_and_dataset_acquisition,
        askg-data:Entity-caselli_s,
        askg-data:Entity-dataset_acquisition,
        askg-data:Entity-kallasi_f,
        askg-data:Entity-oleari_f,
        askg-data:Entity-process,
        askg-data:Entity-rizzini_dl,
        askg-data:Entity-system .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35417 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "In: OCEANS (2015) 44."@en ;
    askg-onto:inSentence "In: OCEANS (2015) 44."^^xsd:string ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35418 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Panetta, K., Gao, C., Agaian, S.: Human-visual-systeminspired underwater image quality measures."@en ;
    askg-onto:inSentence "Panetta, K., Gao, C., Agaian, S.: Human-visual-systeminspired underwater image quality measures."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-agaian_s,
        askg-data:Entity-gao_c,
        askg-data:Entity-human-visual-systeminspired_underwater_image_quality_measures,
        askg-data:Entity-panetta_k,
        askg-data:Entity-quality_measure .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35419 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "IEEE Journal of Oceanic Engineering (2015) 45."@en ;
    askg-onto:inSentence "IEEE Journal of Oceanic Engineering (2015) 45."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-ieee_journal_of_oceanic_engineering,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3542 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Li, C., Wand, M.: Precomputed real-time texture synthesis with markovian generative adversarial networks."@en ;
    askg-onto:inSentence "Li, C., Wand, M.: Precomputed real-time texture synthesis with markovian generative adversarial networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-li_c,
        askg-data:Entity-precomputed_real-time_texture_synthesis_with_markovian_generative_adversarial_networks,
        askg-data:Entity-wand_m .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35420 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Pizarro, O., Friedman, A., Bryson, M., Williams, S.B., Madin, J.: A simple, fast, and repeatable survey method for underwater visual 3d benthic mapping and monitoring."@en ;
    askg-onto:inSentence "Pizarro, O., Friedman, A., Bryson, M., Williams, S.B., Madin, J.: A simple, fast, and repeatable survey method for underwater visual 3d benthic mapping and monitoring."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_simple_fast_and_repeatable_survey_method_for_underwater_visual_3d_benthic_mapping_and_monitoring,
        askg-data:Entity-bryson_m,
        askg-data:Entity-friedman_a,
        askg-data:Entity-madin_j,
        askg-data:Entity-pizarro_o,
        askg-data:Entity-williams_sb .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35421 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Ecology and evolution (2017) 46."@en ;
    askg-onto:inSentence "Ecology and evolution (2017) 46."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ecology_and_evolution,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35422 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks."@en ;
    askg-onto:inSentence "Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chintala_s,
        askg-data:Entity-deep_convolutional_generative_adversarial_network,
        askg-data:Entity-metz_l,
        askg-data:Entity-radford_a,
        askg-data:Entity-unsupervised_representation_learning_with_deep_convolutional_generative_adversarial_networks .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35423 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "arXiv preprint arXiv:1511.06434 (2015) 47."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1511.06434 (2015) 47."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv151106434,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-arxiv_preprint_arxiv151106434,
        askg-data:Entity-publication,
        askg-data:Entity-year_2015 .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-35424 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Ren, S., He, K., Girshick, R., etal: Guided image filtering."@en ;
    askg-onto:inSentence "Ren, S., He, K., Girshick, R., etal: Guided image filtering."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-girshick_r,
        askg-data:Entity-guided_image_filtering,
        askg-data:Entity-he_k,
        askg-data:Entity-ren_s .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3543 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In: ECCV (2016) 37."@en ;
    askg-onto:inSentence "In: ECCV (2016) 37."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-eccv,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3544 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Li, H., Li, J., Wang, W.: A Fusion Adversarial Underwater Image Enhancement Network with a Public Test Dataset."@en ;
    askg-onto:inSentence "Li, H., Li, J., Wang, W.: A Fusion Adversarial Underwater Image Enhancement Network with a Public Test Dataset."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_fusion_adversarial_underwater_image_enhancement_network,
        askg-data:Entity-a_fusion_adversarial_underwater_image_enhancement_network_with_a_public_test_dataset,
        askg-data:Entity-li_h,
        askg-data:Entity-li_j,
        askg-data:Entity-public_test_dataset,
        askg-data:Entity-wang_w .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3545 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "arXiv e-prints arXiv:1906.06819 (2019) 38."@en ;
    askg-onto:inSentence "arXiv e-prints arXiv:1906.06819 (2019) 38."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-article,
        askg-data:Entity-arxiv_e-prints,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3546 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Li, J., Skinner, K.A., Eustice, R.M., Johnson-Roberson, M.: Watergan: Unsupervised generative network to enable real-time color correction of monocular underwater images."@en ;
    askg-onto:inSentence "Li, J., Skinner, K.A., Eustice, R.M., Johnson-Roberson, M.: Watergan: Unsupervised generative network to enable real-time color correction of monocular underwater images."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eustice_rm,
        askg-data:Entity-johnson-roberson_m,
        askg-data:Entity-li_j,
        askg-data:Entity-skinner_ka,
        askg-data:Entity-unsupervised_generative_network,
        askg-data:Entity-watergan,
        askg-data:Entity-watergan_unsupervised_generative_network_to_enable_real-time_color_correction_of_monocular_underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3547 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "IEEE Robotics and Automation Letters (2018) 39."@en ;
    askg-onto:inSentence "IEEE Robotics and Automation Letters (2018) 39."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-39,
        askg-data:Entity-ieee_robotics_and_automation_letters,
        askg-data:Entity-publication,
        askg-data:Entity-volume_number,
        askg-data:Entity-year .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3548 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Lu, J., Li, N., Zhang, S., Yu, Z., Zheng, H., Zheng, B.: Multi-scale adversarial network for underwater image restoration."@en ;
    askg-onto:inSentence "Lu, J., Li, N., Zhang, S., Yu, Z., Zheng, H., Zheng, B.: Multi-scale adversarial network for underwater image restoration."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lu_j_li_n_zhang_s_yu_z_zheng_h_zheng_b,
        askg-data:Entity-multi-scale_adversarial_network_for_underwater_image_restoration .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-354-Sentence-3549 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Optics & Laser Technology (2019) 40."@en ;
    askg-onto:inSentence "Optics & Laser Technology (2019) 40."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-40,
        askg-data:Entity-optics__laser_technology,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "TPAMI (2017) 48. Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: International Conference on Medical image computing and computer-assisted intervention (2015) 49. Shotton, J., Glocker, B., Zach, C., Izadi, S., Criminisi, A., Fitzgibbon, A.: Scene coordinate regression forests for camera relocalization in rgb-d images. In: CVPR (2013) 50. Silberman, N., Hoiem, D., Kohli, P., Fergus, R.: Indoor segmentation and support inference from rgbd images. In: ECCV (2012) 51. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. ICLR (2014) 52. Skinner, K.A., Johnson-Roberson, M.: Underwater image dehazing with a light field camera. In: CVPRW (2017) 53. Sun, X., Liu, L., Li, Q., Dong, J., Lima, E., Yin, R.: Deep pixel to pixel network for underwater image enhancement and restoration. IET Image Processing (2018) 54. Uplavikar, P., Wu, Z., Wang, Z.: All-in-one underwater image enhancement using domain-adversarial learning. arXiv preprint arXiv:1905.13342 (2019) 55. Wang, S., Ma, K., Yeganeh, H., Wang, Z., Lin, W.: A patch-structure representation method for quality assessment of contrast changed images. IEEE Signal Processing Letters (2015) 56. Wang, Y., Zhang, J., Cao, Y., Wang, Z.: A deep cnn method for underwater image enhancement. In: ICIP (2017) 57. Wang, Z., Bovik, A.C.: A universal image quality index."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3551,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35510,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35511,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35512,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35513,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35514,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35515,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35516,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35517,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35518,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35519,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3552,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35520,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3553,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3554,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3555,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3556,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3557,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3558,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3559 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "TPAMI (2017) 48."@en ;
    askg-onto:inSentence "TPAMI (2017) 48."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-tpami .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35510 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Skinner, K.A., Johnson-Roberson, M.: Underwater image dehazing with a light field camera."@en ;
    askg-onto:inSentence "Skinner, K.A., Johnson-Roberson, M.: Underwater image dehazing with a light field camera."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision,
        askg-data:Entity-device,
        askg-data:Entity-johnson-roberson_m,
        askg-data:Entity-light_field_camera,
        askg-data:Entity-skinner_ka,
        askg-data:Entity-underwater_image_dehazing_with_a_light_field_camera .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35511 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "In: CVPRW (2017) 53."@en ;
    askg-onto:inSentence "In: CVPRW (2017) 53."^^xsd:string ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35512 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Sun, X., Liu, L., Li, Q., Dong, J., Lima, E., Yin, R.: Deep pixel to pixel network for underwater image enhancement and restoration."@en ;
    askg-onto:inSentence "Sun, X., Liu, L., Li, Q., Dong, J., Lima, E., Yin, R.: Deep pixel to pixel network for underwater image enhancement and restoration."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_pixel_to_pixel_network_for_underwater_image_enhancement_and_restoration,
        askg-data:Entity-dong_j,
        askg-data:Entity-li_q,
        askg-data:Entity-lima_e,
        askg-data:Entity-liu_l,
        askg-data:Entity-method,
        askg-data:Entity-sun_x,
        askg-data:Entity-yin_r .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35513 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "IET Image Processing (2018) 54."@en ;
    askg-onto:inSentence "IET Image Processing (2018) 54."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iet_image_processing,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35514 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Uplavikar, P., Wu, Z., Wang, Z.: All-in-one underwater image enhancement using domain-adversarial learning."@en ;
    askg-onto:inSentence "Uplavikar, P., Wu, Z., Wang, Z.: All-in-one underwater image enhancement using domain-adversarial learning."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all-in-one_underwater_image_enhancement_using_domain-adversarial_learning,
        askg-data:Entity-concept,
        askg-data:Entity-uplavikar_p,
        askg-data:Entity-wang_z,
        askg-data:Entity-wu_z .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35515 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "arXiv preprint arXiv:1905.13342 (2019) 55."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1905.13342 (2019) 55."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-arxiv,
        askg-data:Entity-arxiv190513342,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-platform,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35516 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Wang, S., Ma, K., Yeganeh, H., Wang, Z., Lin, W.: A patch-structure representation method for quality assessment of contrast changed images."@en ;
    askg-onto:inSentence "Wang, S., Ma, K., Yeganeh, H., Wang, Z., Lin, W.: A patch-structure representation method for quality assessment of contrast changed images."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_patch-structure_representation_method_for_quality_assessment_of_contrast_changed_images,
        askg-data:Entity-lin_w,
        askg-data:Entity-ma_k,
        askg-data:Entity-method_for_quality_assessment,
        askg-data:Entity-wang_s,
        askg-data:Entity-wang_z,
        askg-data:Entity-yeganeh_h .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35517 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "IEEE Signal Processing Letters (2015) 56."@en ;
    askg-onto:inSentence "IEEE Signal Processing Letters (2015) 56."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-ieee_signal_processing_letters,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35518 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Wang, Y., Zhang, J., Cao, Y., Wang, Z.: A deep cnn method for underwater image enhancement."@en ;
    askg-onto:inSentence "Wang, Y., Zhang, J., Cao, Y., Wang, Z.: A deep cnn method for underwater image enhancement."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_deep_cnn_method_for_underwater_image_enhancement,
        askg-data:Entity-cao_y,
        askg-data:Entity-method,
        askg-data:Entity-wang_y,
        askg-data:Entity-wang_z,
        askg-data:Entity-zhang_j .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35519 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "In: ICIP (2017) 57."@en ;
    askg-onto:inSentence "In: ICIP (2017) 57."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation."@en ;
    askg-onto:inSentence "Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brox_t,
        askg-data:Entity-convolutional_network_for_biomedical_image_segmentation,
        askg-data:Entity-fischer_p,
        askg-data:Entity-ronneberger_o,
        askg-data:Entity-u-net,
        askg-data:Entity-u-net_convolutional_networks_for_biomedical_image_segmentation .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-35520 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Wang, Z., Bovik, A.C.: A universal image quality index."@en ;
    askg-onto:inSentence "Wang, Z., Bovik, A.C.: A universal image quality index."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_universal_image_quality_index,
        askg-data:Entity-bovik_ac,
        askg-data:Entity-image_quality,
        askg-data:Entity-image_quality_index,
        askg-data:Entity-wang_z .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3553 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In: International Conference on Medical image computing and computer-assisted intervention (2015) 49."@en ;
    askg-onto:inSentence "In: International Conference on Medical image computing and computer-assisted intervention (2015) 49."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-event,
        askg-data:Entity-international_conference_on_medical_image_computing_and_computer-assisted_intervention .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3554 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Shotton, J., Glocker, B., Zach, C., Izadi, S., Criminisi, A., Fitzgibbon, A.: Scene coordinate regression forests for camera relocalization in rgb-d images."@en ;
    askg-onto:inSentence "Shotton, J., Glocker, B., Zach, C., Izadi, S., Criminisi, A., Fitzgibbon, A.: Scene coordinate regression forests for camera relocalization in rgb-d images."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-camera_relocalization_in_rgb-d_images,
        askg-data:Entity-criminisi_a,
        askg-data:Entity-fitzgibbon_a,
        askg-data:Entity-glocker_b,
        askg-data:Entity-izadi_s,
        askg-data:Entity-scene_coordinate_regression_forests,
        askg-data:Entity-scene_coordinate_regression_forests_for_camera_relocalization_in_rgb-d_images,
        askg-data:Entity-shotton_j,
        askg-data:Entity-zach_c .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3555 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In: CVPR (2013) 50."@en ;
    askg-onto:inSentence "In: CVPR (2013) 50."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3556 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Silberman, N., Hoiem, D., Kohli, P., Fergus, R.: Indoor segmentation and support inference from rgbd images."@en ;
    askg-onto:inSentence "Silberman, N., Hoiem, D., Kohli, P., Fergus, R.: Indoor segmentation and support inference from rgbd images."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fergus_r,
        askg-data:Entity-hoiem_d,
        askg-data:Entity-indoor_segmentation_and_support_inference_from_rgbd_images,
        askg-data:Entity-kohli_p,
        askg-data:Entity-silberman_n,
        askg-data:Entity-study .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3557 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In: ECCV (2012) 51."@en ;
    askg-onto:inSentence "In: ECCV (2012) 51."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eccv,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3558 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition."@en ;
    askg-onto:inSentence "Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_area,
        askg-data:Entity-simonyan_k,
        askg-data:Entity-very_deep_convolutional_networks_for_large-scale_image_recognition,
        askg-data:Entity-zisserman_a .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-355-Sentence-3559 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "ICLR (2014) 52."@en ;
    askg-onto:inSentence "ICLR (2014) 52."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-conference,
        askg-data:Entity-iclr .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-356 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "IEEE signal processing letters (2002) 58. Wang, Z., Bovik, A.C.: Modern image quality assessment."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-356-Sentence-3561,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-356-Sentence-3562 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-356-Sentence-3561 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "IEEE signal processing letters (2002) 58."@en ;
    askg-onto:inSentence "IEEE signal processing letters (2002) 58."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_signal_processing_letters,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-356-Sentence-3562 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Wang, Z., Bovik, A.C.: Modern image quality assessment."@en ;
    askg-onto:inSentence "Wang, Z., Bovik, A.C.: Modern image quality assessment."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bovik_ac,
        askg-data:Entity-modern_image_quality_assessment,
        askg-data:Entity-wang_z .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Synthesis Lectures on Image, Video, and Multimedia Processing (2006) 59. Wang, Z., Bovik, A.C.: Mean squared error: Love it or leave it? a new look at signal fidelity measures. IEEE signal processing magazine (2009) 60. Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., et al.: Image quality assessment: from error visibility to structural similarity. TIP (2004) 61. Wang, Z., Simoncelli, E.P., Bovik, A.C.: Multiscale structural similarity for image quality assessment. In: The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003 (2003) 62. Wu, Q., Wang, P., Shen, C., Dick, A., van den Hengel, A.: Ask me anything: Free-form visual question answering based on knowledge from external sources. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4622–4630 (2016) 63. Yang, M., Sowmya, A.: An underwater color image quality evaluation metric. TIP (2015) 64. Ye, X., Xu, H., Ji, X., Xu, R.: Underwater image enhancement using stacked generative adversarial networks. In: Pacific Rim Conference on Multimedia (2018) 65. Zhang, K., Zuo, W., Gu, S.: Learning deep cnn denoiser prior for image restoration. In: CVPR (2017) 66. Zhu, Y., Park, T., Efros, A.: Unpaired image-to-image translation using cycle-consistent adversarial networks. In: ICCV (2017)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3571,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35710,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35711,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35712,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35713,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35714,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35715,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35716,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35717,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35718,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35719,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3572,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3573,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3574,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3575,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3576,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3577,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3578,
        askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3579 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3571 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Synthesis Lectures on Image, Video, and Multimedia Processing (2006) 59."@en ;
    askg-onto:inSentence "Synthesis Lectures on Image, Video, and Multimedia Processing (2006) 59."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2006,
        askg-data:Entity-publication,
        askg-data:Entity-synthesis_lectures_on_image_video_and_multimedia_processing .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35710 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp."@en ;
    askg-onto:inSentence "In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35711 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "4622–4630 (2016) 63."@en ;
    askg-onto:inSentence "4622–4630 (2016) 63."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-article .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35712 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Yang, M., Sowmya, A.: An underwater color image quality evaluation metric."@en ;
    askg-onto:inSentence "Yang, M., Sowmya, A.: An underwater color image quality evaluation metric."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_underwater_color_image_quality_evaluation_metric,
        askg-data:Entity-metric,
        askg-data:Entity-sowmya_a,
        askg-data:Entity-yang_m .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35713 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "TIP (2015) 64."@en ;
    askg-onto:inSentence "TIP (2015) 64."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-tip .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35714 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Ye, X., Xu, H., Ji, X., Xu, R.: Underwater image enhancement using stacked generative adversarial networks."@en ;
    askg-onto:inSentence "Ye, X., Xu, H., Ji, X., Xu, R.: Underwater image enhancement using stacked generative adversarial networks."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-ji_x,
        askg-data:Entity-method,
        askg-data:Entity-stacked_generative_adversarial_networks,
        askg-data:Entity-study,
        askg-data:Entity-underwater_image_enhancement,
        askg-data:Entity-xu_h,
        askg-data:Entity-xu_r,
        askg-data:Entity-ye_x .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35715 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "In: Pacific Rim Conference on Multimedia (2018) 65."@en ;
    askg-onto:inSentence "In: Pacific Rim Conference on Multimedia (2018) 65."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pacific_rim_conference_on_multimedia,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35716 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Zhang, K., Zuo, W., Gu, S.: Learning deep cnn denoiser prior for image restoration."@en ;
    askg-onto:inSentence "Zhang, K., Zuo, W., Gu, S.: Learning deep cnn denoiser prior for image restoration."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gu_s,
        askg-data:Entity-learning_deep_cnn_denoiser_prior_for_image_restoration,
        askg-data:Entity-method,
        askg-data:Entity-zhang_k,
        askg-data:Entity-zuo_w .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35717 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "In: CVPR (2017) 66."@en ;
    askg-onto:inSentence "In: CVPR (2017) 66."^^xsd:string ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35718 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Zhu, Y., Park, T., Efros, A.: Unpaired image-to-image translation using cycle-consistent adversarial networks."@en ;
    askg-onto:inSentence "Zhu, Y., Park, T., Efros, A.: Unpaired image-to-image translation using cycle-consistent adversarial networks."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-efros_a,
        askg-data:Entity-park_t,
        askg-data:Entity-unpaired_image-to-image_translation_using_cycle-consistent_adversarial_networks,
        askg-data:Entity-zhu_y .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-35719 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "In: ICCV (2017)"@en ;
    askg-onto:inSentence "In: ICCV (2017)"^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iccv .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3572 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Wang, Z., Bovik, A.C.: Mean squared error: Love it or leave it?"@en ;
    askg-onto:inSentence "Wang, Z., Bovik, A.C.: Mean squared error: Love it or leave it?"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bovik_ac,
        askg-data:Entity-love_it_or_leave_it,
        askg-data:Entity-mean_squared_error,
        askg-data:Entity-mean_squared_error_love_it_or_leave_it,
        askg-data:Entity-wang_z .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3573 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "a new look at signal fidelity measures."@en ;
    askg-onto:inSentence "a new look at signal fidelity measures."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-signal_fidelity_measures .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3574 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "IEEE signal processing magazine (2009) 60."@en ;
    askg-onto:inSentence "IEEE signal processing magazine (2009) 60."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2009,
        askg-data:Entity-60,
        askg-data:Entity-ieee_signal_processing_magazine,
        askg-data:Entity-publication .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3575 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., et al.: Image quality assessment: from error visibility to structural similarity."@en ;
    askg-onto:inSentence "Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., et al.: Image quality assessment: from error visibility to structural similarity."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bovik_ac,
        askg-data:Entity-image_quality_assessment_from_error_visibility_to_structural_similarity,
        askg-data:Entity-sheikh_hr,
        askg-data:Entity-simoncelli_ep,
        askg-data:Entity-wang_z .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3576 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "TIP (2004) 61."@en ;
    askg-onto:inSentence "TIP (2004) 61."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2004,
        askg-data:Entity-tip .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3577 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Wang, Z., Simoncelli, E.P., Bovik, A.C.: Multiscale structural similarity for image quality assessment."@en ;
    askg-onto:inSentence "Wang, Z., Simoncelli, E.P., Bovik, A.C.: Multiscale structural similarity for image quality assessment."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bovik_ac,
        askg-data:Entity-concept,
        askg-data:Entity-multiscale_structural_similarity_for_image_quality_assessment,
        askg-data:Entity-simoncelli_ep,
        askg-data:Entity-wang_z .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3578 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In: The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003 (2003) 62."@en ;
    askg-onto:inSentence "In: The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003 (2003) 62."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2003,
        askg-data:Entity-conference,
        askg-data:Entity-the_thirty-seventh_asilomar_conference_on_signals_systems__computers .

askg-data:Paper-c63c8058011e31f2-Section-35-Paragraph-357-Sentence-3579 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Wu, Q., Wang, P., Shen, C., Dick, A., van den Hengel, A.: Ask me anything: Free-form visual question answering based on knowledge from external sources."@en ;
    askg-onto:inSentence "Wu, Q., Wang, P., Shen, C., Dick, A., van den Hengel, A.: Ask me anything: Free-form visual question answering based on knowledge from external sources."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ask_me_anything_free-form_visual_question_answering_based_on_knowledge_from_external_sources,
        askg-data:Entity-dick_a,
        askg-data:Entity-knowledge_from_external_sources,
        askg-data:Entity-shen_c,
        askg-data:Entity-van_den_hengel_a,
        askg-data:Entity-wang_p,
        askg-data:Entity-wu_q .

askg-data:Paper-c63c8058011e31f2-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "2.1 Atmospheric Scattering Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-42,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-43,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "For an image captured in a scattering medium, only a part of the reflected light from the scene reaches the imaging sensor due to the absorption and scattering effects, typically for hazy image formation. Since underwater images usually have a hazy appearance (similar to the hazy image), the atmospheric scattering model [29] is traditionally used to describe the degradation of the underwater image. The atmospheric scattering model [29] can be characterized as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41-Sentence-413 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For an image captured in a scattering medium, only a part of the reflected light from the scene reaches the imaging sensor due to the absorption and scattering effects, typically for hazy image formation."@en ;
    askg-onto:inSentence "For an image captured in a scattering medium, only a part of the reflected light from the scene reaches the imaging sensor due to the absorption and scattering effects, typically for hazy image formation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-absorption,
        askg-data:Entity-hazy_image_formation,
        askg-data:Entity-image,
        askg-data:Entity-imaging_sensor,
        askg-data:Entity-light,
        askg-data:Entity-scattering_effects,
        askg-data:Entity-scattering_medium,
        askg-data:Entity-scene .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Since underwater images usually have a hazy appearance (similar to the hazy image), the atmospheric scattering model [29] is traditionally used to describe the degradation of the underwater image."@en ;
    askg-onto:inSentence "Since underwater images usually have a hazy appearance (similar to the hazy image), the atmospheric scattering model [29] is traditionally used to describe the degradation of the underwater image."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-degradation_of_the_underwater_image .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The atmospheric scattering model [29] can be characterized as:"@en ;
    askg-onto:inSentence "The atmospheric scattering model [29] can be characterized as:"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbf{U}(x)=\\mathbf{I}(x)T(x)+B(1-T(x)),$$ $\\left(1\\right)$."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-42-Sentence-421 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{U}(x)=\\mathbf{I}(x)T(x)+B(1-T(x)),$$ $\\left(1\\right)$."@en ;
    askg-onto:inSentence "$$\\mathbf{U}(x)=\\mathbf{I}(x)T(x)+B(1-T(x)),$$ $\\left(1\\right)$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-ix,
        askg-data:Entity-tx,
        askg-data:Entity-ux .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-43 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "U(x) = I(x)T(x) + B(1 − T(x)), (1) where x denotes the pixel coordinates, U(x) is the observed image, I(x) is the haze-free latent image, B is the global atmospheric light which indicates the intensity of ambient light, and T(x) ∈ [0, 1] is the transmission which represents the percentage of the scene radiance reaching the camera. When the haze is homogenous, T(x) can be further expressed in an exponential decay term as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-43-Sentence-431,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-43-Sentence-432 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-43-Sentence-431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "U(x) = I(x)T(x) + B(1 − T(x)), (1) where x denotes the pixel coordinates, U(x) is the observed image, I(x) is the haze-free latent image, B is the global atmospheric light which indicates the intensity of ambient light, and T(x) ∈ [0, 1] is the transmission which represents the percentage of the scene radiance reaching the camera."@en ;
    askg-onto:inSentence "U(x) = I(x)T(x) + B(1 − T(x)), (1) where x denotes the pixel coordinates, U(x) is the observed image, I(x) is the haze-free latent image, B is the global atmospheric light which indicates the intensity of ambient light, and T(x) ∈ [0, 1] is the transmission which represents the percentage of the scene radiance reaching the camera."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-global_atmospheric_light,
        askg-data:Entity-haze-free_latent_image,
        askg-data:Entity-ix,
        askg-data:Entity-observed_image,
        askg-data:Entity-percentage_of_the_scene_radiance_reaching_the_camera,
        askg-data:Entity-tx,
        askg-data:Entity-ux .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-43-Sentence-432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "When the haze is homogenous, T(x) can be further expressed in an exponential decay term as:"@en ;
    askg-onto:inSentence "When the haze is homogenous, T(x) can be further expressed in an exponential decay term as:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-haze,
        askg-data:Entity-tx .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$T(x)=\\exp(-\\beta d(x)),$$ $\\left(2\\right)$. T(x) = exp(−βd(x)), (2) where β is the atmospheric attenuation coefficient and d(x) is the distance from the scene to the camera. In this atmospheric scattering model, the scattering is nonselective, and attenuation is independent of wavelengths."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44-Sentence-441,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44-Sentence-442,
        askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44-Sentence-443 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44-Sentence-441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$T(x)=\\exp(-\\beta d(x)),$$ $\\left(2\\right)$."@en ;
    askg-onto:inSentence "$$T(x)=\\exp(-\\beta d(x)),$$ $\\left(2\\right)$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B2,
        askg-data:Entity-dx,
        askg-data:Entity-exp-%CE%B2_dx,
        askg-data:Entity-tx,
        askg-data:Entity-x .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44-Sentence-442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "T(x) = exp(−βd(x)), (2) where β is the atmospheric attenuation coefficient and d(x) is the distance from the scene to the camera."@en ;
    askg-onto:inSentence "T(x) = exp(−βd(x)), (2) where β is the atmospheric attenuation coefficient and d(x) is the distance from the scene to the camera."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B2,
        askg-data:Entity-atmospheric_attenuation_coefficient,
        askg-data:Entity-distance_from_the_scene_to_the_camera,
        askg-data:Entity-dx,
        askg-data:Entity-exp%CE%B2dx,
        askg-data:Entity-tx .

askg-data:Paper-c63c8058011e31f2-Section-4-Paragraph-44-Sentence-443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In this atmospheric scattering model, the scattering is nonselective, and attenuation is independent of wavelengths."@en ;
    askg-onto:inSentence "In this atmospheric scattering model, the scattering is nonselective, and attenuation is independent of wavelengths."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-attenuation,
        askg-data:Entity-model,
        askg-data:Entity-scattering,
        askg-data:Entity-wavelengths .

askg-data:Paper-c63c8058011e31f2-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "2.2 Simplified Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-52,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-54,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In fact, there is a significant difference between atmospheric scattering model and real-world underwater image formation model. The real-world underwater imaging is far more complicated due to the optical properties of selective attenuation in water. Thus, in the early stage, most physical model-based methods followed a simplified underwater image formulation model provided by [9]. We denote the captured underwater image by Uλ(x), the clear latent image (also known as scene radiance) as Iλ(x), and the homogeneous global background light as Bλ, then the degradation model is given as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-511,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-512,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-513,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-514 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In fact, there is a significant difference between atmospheric scattering model and real-world underwater image formation model."@en ;
    askg-onto:inSentence "In fact, there is a significant difference between atmospheric scattering model and real-world underwater image formation model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-real-world_underwater_image_formation_model .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The real-world underwater imaging is far more complicated due to the optical properties of selective attenuation in water."@en ;
    askg-onto:inSentence "The real-world underwater imaging is far more complicated due to the optical properties of selective attenuation in water."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optical_properties_of_selective_attenuation_in_water,
        askg-data:Entity-underwater_imaging .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Thus, in the early stage, most physical model-based methods followed a simplified underwater image formulation model provided by [9]."@en ;
    askg-onto:inSentence "Thus, in the early stage, most physical model-based methods followed a simplified underwater image formulation model provided by [9]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-physical_model-based_methods,
        askg-data:Entity-simplified_underwater_image_formulation_model .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-51-Sentence-514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We denote the captured underwater image by Uλ(x), the clear latent image (also known as scene radiance) as Iλ(x), and the homogeneous global background light as Bλ, then the degradation model is given as:"@en ;
    askg-onto:inSentence "We denote the captured underwater image by Uλ(x), the clear latent image (also known as scene radiance) as Iλ(x), and the homogeneous global background light as Bλ, then the degradation model is given as:"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b%CE%BB,
        askg-data:Entity-captured_underwater_image,
        askg-data:Entity-clear_latent_image,
        askg-data:Entity-degradation_model,
        askg-data:Entity-homogeneous_global_background_light,
        askg-data:Entity-i%CE%BBx,
        askg-data:Entity-mathematical_expression,
        askg-data:Entity-scene_radiance,
        askg-data:Entity-u%CE%BBx .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-52 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbf{U}_{\\lambda}(x)=\\mathbf{I}_{\\lambda}(x)\\cdot T_{\\lambda}(x)+B_{\\lambda}\\cdot{\\big(}1-T_{\\lambda}(x){\\big)},$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-52-Sentence-521 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-52-Sentence-521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{U}_{\\lambda}(x)=\\mathbf{I}_{\\lambda}(x)\\cdot T_{\\lambda}(x)+B_{\\lambda}\\cdot{\\big(}1-T_{\\lambda}(x){\\big)},$$"@en ;
    askg-onto:inSentence "$$\\mathbf{U}_{\\lambda}(x)=\\mathbf{I}_{\\lambda}(x)\\cdot T_{\\lambda}(x)+B_{\\lambda}\\cdot{\\big(}1-T_{\\lambda}(x){\\big)},$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b_lambda,
        askg-data:Entity-i_lambda,
        askg-data:Entity-i_lambda_and_t_lambda,
        askg-data:Entity-t_lambda,
        askg-data:Entity-u_lambda .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "where λ presents the wavelength of the RGB channels, and x is a point in the underwater scene. Similarly, Tλ(x) is the medium energy ratio, which is the percentage of the scene radiance captured by the camera (the amount of radiance reflected from the point x). This phenomenon causes contrast degradation, and color casts. To be precise, Tλ(x) is a function of λ and the distance d(x) to the camera from the scene point x, expressed as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-531,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-532,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-533,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-534 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where λ presents the wavelength of the RGB channels, and x is a point in the underwater scene."@en ;
    askg-onto:inSentence "where λ presents the wavelength of the RGB channels, and x is a point in the underwater scene."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB,
        askg-data:Entity-the_underwater_scene,
        askg-data:Entity-wavelength_of_the_rgb_channels,
        askg-data:Entity-x .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Similarly, Tλ(x) is the medium energy ratio, which is the percentage of the scene radiance captured by the camera (the amount of radiance reflected from the point x)."@en ;
    askg-onto:inSentence "Similarly, Tλ(x) is the medium energy ratio, which is the percentage of the scene radiance captured by the camera (the amount of radiance reflected from the point x)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-t%CE%BBx,
        askg-data:Entity-the_amount_of_radiance,
        askg-data:Entity-the_camera,
        askg-data:Entity-the_medium_energy_ratio,
        askg-data:Entity-the_point_x,
        askg-data:Entity-the_scene_radiance,
        askg-data:Entity-the_scene_radiance_captured_by_the_camera .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This phenomenon causes contrast degradation, and color casts."@en ;
    askg-onto:inSentence "This phenomenon causes contrast degradation, and color casts."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-color_casts,
        askg-data:Entity-contrast_degradation,
        askg-data:Entity-phenomenon .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-53-Sentence-534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To be precise, Tλ(x) is a function of λ and the distance d(x) to the camera from the scene point x, expressed as:"@en ;
    askg-onto:inSentence "To be precise, Tλ(x) is a function of λ and the distance d(x) to the camera from the scene point x, expressed as:"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB,
        askg-data:Entity-dx,
        askg-data:Entity-t%CE%BBx,
        askg-data:Entity-the_camera,
        askg-data:Entity-the_scene_point_x .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-54 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$T_{\\lambda}(x)=10^{-\\beta_{\\lambda}d(x)}=\\frac{E_{\\lambda}\\big{(}x,d(x)\\big{)}}{E_{\\lambda}(x,0)}=N_{\\lambda}\\big{(}d(x)\\big{)},\\tag{4}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-54-Sentence-541 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-54-Sentence-541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$T_{\\lambda}(x)=10^{-\\beta_{\\lambda}d(x)}=\\frac{E_{\\lambda}\\big{(}x,d(x)\\big{)}}{E_{\\lambda}(x,0)}=N_{\\lambda}\\big{(}d(x)\\big{)},\\tag{4}$$"@en ;
    askg-onto:inSentence "$$T_{\\lambda}(x)=10^{-\\beta_{\\lambda}d(x)}=\\frac{E_{\\lambda}\\big{(}x,d(x)\\big{)}}{E_{\\lambda}(x,0)}=N_{\\lambda}\\big{(}d(x)\\big{)},\\tag{4}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10-eta_%0Alambdadx,
        askg-data:Entity-dx,
        askg-data:Entity-e_%0Alambdax0,
        askg-data:Entity-e_%0Alambdaxdx,
        askg-data:Entity-n_%0Alambdaigdxig,
        askg-data:Entity-t_%0Alambdax,
        askg-data:Entity-x .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "where βλ is the medium attenuation coefficient, which is dependent on the wavelength. Furthermore, Eλ(x, 0) is the energy of light from the submerged scene before it passes through the transmission medium from a distance d(x) while Eλ*x, d*(x)is the strength of light after absorption by the transmission medium. Moreover, Nλ is the normalized residual energy which is the ratio of residual energy to the initial energy per unit of distance and is dependent on the wavelength of light. For example, the bluish tone of the most underwater images is due to the fast attenuation of the red wavelength in open water as it possesses a longer wavelength than blue and green ones."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-551,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-552,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-553,
        askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-554 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where βλ is the medium attenuation coefficient, which is dependent on the wavelength."@en ;
    askg-onto:inSentence "where βλ is the medium attenuation coefficient, which is dependent on the wavelength."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B2%CE%BB,
        askg-data:Entity-medium_attenuation_coefficient,
        askg-data:Entity-wavelength .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Furthermore, Eλ(x, 0) is the energy of light from the submerged scene before it passes through the transmission medium from a distance d(x) while Eλ*x, d*(x)is the strength of light after absorption by the transmission medium."@en ;
    askg-onto:inSentence "Furthermore, Eλ(x, 0) is the energy of light from the submerged scene before it passes through the transmission medium from a distance d(x) while Eλ*x, d*(x)is the strength of light after absorption by the transmission medium."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e%CE%BBx_0,
        askg-data:Entity-e%CE%BBx_dx,
        askg-data:Entity-energy_of_light,
        askg-data:Entity-strength_of_light .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-553 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Moreover, Nλ is the normalized residual energy which is the ratio of residual energy to the initial energy per unit of distance and is dependent on the wavelength of light."@en ;
    askg-onto:inSentence "Moreover, Nλ is the normalized residual energy which is the ratio of residual energy to the initial energy per unit of distance and is dependent on the wavelength of light."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n%CE%BB,
        askg-data:Entity-the_normalized_residual_energy,
        askg-data:Entity-the_ratio_of_residual_energy_to_the_initial_energy_per_unit_of_distance,
        askg-data:Entity-the_wavelength_of_light .

askg-data:Paper-c63c8058011e31f2-Section-5-Paragraph-55-Sentence-554 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For example, the bluish tone of the most underwater images is due to the fast attenuation of the red wavelength in open water as it possesses a longer wavelength than blue and green ones."@en ;
    askg-onto:inSentence "For example, the bluish tone of the most underwater images is due to the fast attenuation of the red wavelength in open water as it possesses a longer wavelength than blue and green ones."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blue_and_green_ones,
        askg-data:Entity-bluish_tone,
        askg-data:Entity-fast_attenuation_of_red_wavelength,
        askg-data:Entity-longer_wavelength_than_blue_and_green_ones,
        askg-data:Entity-open_water,
        askg-data:Entity-red_wavelength .

askg-data:Paper-c63c8058011e31f2-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "2.3 Revised Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-62,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-63,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Recent research found that the commonly-used atmospheric scattering model and simplified underwater image formation model ignored some key components in the process of real-world underwater imaging [1]. Specifically, the attenuation coefficient for backscatter strongly depends on the veiling light. Moreover, unlike the absorption in the atmosphere, the absorption in water should not be neglected. Most importantly, the attenuation coefficients for the direct signal and the scattering signal are different."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-611,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-612,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-613,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-614 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Recent research found that the commonly-used atmospheric scattering model and simplified underwater image formation model ignored some key components in the process of real-world underwater imaging [1]."@en ;
    askg-onto:inSentence "Recent research found that the commonly-used atmospheric scattering model and simplified underwater image formation model ignored some key components in the process of real-world underwater imaging [1]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-key_components,
        askg-data:Entity-underwater_image_formation_model,
        askg-data:Entity-underwater_imaging .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Specifically, the attenuation coefficient for backscatter strongly depends on the veiling light."@en ;
    askg-onto:inSentence "Specifically, the attenuation coefficient for backscatter strongly depends on the veiling light."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attenuation_coefficient,
        askg-data:Entity-veiling_light .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Moreover, unlike the absorption in the atmosphere, the absorption in water should not be neglected."@en ;
    askg-onto:inSentence "Moreover, unlike the absorption in the atmosphere, the absorption in water should not be neglected."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-absorption,
        askg-data:Entity-atmosphere,
        askg-data:Entity-water .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-61-Sentence-614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Most importantly, the attenuation coefficients for the direct signal and the scattering signal are different."@en ;
    askg-onto:inSentence "Most importantly, the attenuation coefficients for the direct signal and the scattering signal are different."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attenuation_coefficients,
        askg-data:Entity-different .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Based on the findings mentioned above, Akkaynak & Treibitz [1] proposed a revised underwater image formation model which can be expressed as:"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-62-Sentence-621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Based on the findings mentioned above, Akkaynak & Treibitz [1] proposed a revised underwater image formation model which can be expressed as:"@en ;
    askg-onto:inSentence "Based on the findings mentioned above, Akkaynak & Treibitz [1] proposed a revised underwater image formation model which can be expressed as:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-akkaynak__treibitz,
        askg-data:Entity-underwater_image_formation_model .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "λ (vD)·z + B $\\infty\\!\\left(1-e^{-\\beta}\\right)$ λ B λ (vB)·z, (5)"@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-63-Sentence-631 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "λ (vD)·z + B $\\infty\\!\\left(1-e^{-\\beta}\\right)$ λ B λ (vB)·z, (5)"@en ;
    askg-onto:inSentence "λ (vD)·z + B $\\infty\\!\\left(1-e^{-\\beta}\\right)$ λ B λ (vB)·z, (5)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB_b_%CE%BB_vbz,
        askg-data:Entity-%CE%BB_vdz,
        askg-data:Entity-b,
        askg-data:Entity-concept .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$\\mathbf{\\Phi}_{\\mathrm{{A}}}(x)=\\mathbf{I}_{\\lambda}(x)e^{-\\beta_{\\lambda}^{D}(\\mathbf{v})}$$ $\\left(3\\right)$. where B∞ λis the veiling light, βλ is the beam attenuation coefficient, D is the direct transmitted light, B is the backscattered light, the vectors vd(x) and vb(x) represent the coefficient dependencies. To be more specific, vd(x)={z, ρ, E, Sλ, β} and vb(x)={E, Sλ, b, β }, where z is the range along LOS, ρ is the reflectance, E is the irradiance, Sλ is the sensor spectral response, and b is the beam scattering coefficient. Similar to the simplified model, Uλ(x) is the observed underwater image, Iλ(x) is the latent clear underwater image. More details can be found in [1]. Moreover, the coefficient associated with the backscatter varies with the sensor, ambient illumination, and water type. Generally, the coefficient of backscatter is different from the coefficient associated with the direct signal."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-641,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-642,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-643,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-644,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-645,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-646,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-647 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{\\Phi}_{\\mathrm{{A}}}(x)=\\mathbf{I}_{\\lambda}(x)e^{-\\beta_{\\lambda}^{D}(\\mathbf{v})}$$ $\\left(3\\right)$."@en ;
    askg-onto:inSentence "$$\\mathbf{\\Phi}_{\\mathrm{{A}}}(x)=\\mathbf{I}_{\\lambda}(x)e^{-\\beta_{\\lambda}^{D}(\\mathbf{v})}$$ $\\left(3\\right)$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86_ax,
        askg-data:Entity-i_%CE%BBxe%CE%B2_%CE%BBdv .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "where B∞ λis the veiling light, βλ is the beam attenuation coefficient, D is the direct transmitted light, B is the backscattered light, the vectors vd(x) and vb(x) represent the coefficient dependencies."@en ;
    askg-onto:inSentence "where B∞ λis the veiling light, βλ is the beam attenuation coefficient, D is the direct transmitted light, B is the backscattered light, the vectors vd(x) and vb(x) represent the coefficient dependencies."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B2%CE%BB,
        askg-data:Entity-b,
        askg-data:Entity-b_%CE%BB,
        askg-data:Entity-d,
        askg-data:Entity-the_backscattered_light,
        askg-data:Entity-the_beam_attenuation_coefficient,
        askg-data:Entity-the_coefficient_dependencies,
        askg-data:Entity-the_direct_transmitted_light,
        askg-data:Entity-the_veiling_light,
        askg-data:Entity-vbx,
        askg-data:Entity-vdx .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-643 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To be more specific, vd(x)={z, ρ, E, Sλ, β} and vb(x)={E, Sλ, b, β }, where z is the range along LOS, ρ is the reflectance, E is the irradiance, Sλ is the sensor spectral response, and b is the beam scattering coefficient."@en ;
    askg-onto:inSentence "To be more specific, vd(x)={z, ρ, E, Sλ, β} and vb(x)={E, Sλ, b, β }, where z is the range along LOS, ρ is the reflectance, E is the irradiance, Sλ is the sensor spectral response, and b is the beam scattering coefficient."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%81,
        askg-data:Entity-b,
        askg-data:Entity-e,
        askg-data:Entity-e_s%CE%BB_b_%CE%B2,
        askg-data:Entity-s%CE%BB,
        askg-data:Entity-the_beam_scattering_coefficient,
        askg-data:Entity-the_irradiance,
        askg-data:Entity-the_range_along_los,
        askg-data:Entity-the_reflectance,
        askg-data:Entity-the_sensor_spectral_response,
        askg-data:Entity-vbx,
        askg-data:Entity-vdx,
        askg-data:Entity-z,
        askg-data:Entity-z_%CF%81_e_s%CE%BB_%CE%B2 .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-644 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Similar to the simplified model, Uλ(x) is the observed underwater image, Iλ(x) is the latent clear underwater image."@en ;
    askg-onto:inSentence "Similar to the simplified model, Uλ(x) is the observed underwater image, Iλ(x) is the latent clear underwater image."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-i%CE%BBx,
        askg-data:Entity-latent_clear_underwater_image,
        askg-data:Entity-observed_underwater_image,
        askg-data:Entity-u%CE%BBx .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-645 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "More details can be found in [1]."@en ;
    askg-onto:inSentence "More details can be found in [1]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-details .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-646 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Moreover, the coefficient associated with the backscatter varies with the sensor, ambient illumination, and water type."@en ;
    askg-onto:inSentence "Moreover, the coefficient associated with the backscatter varies with the sensor, ambient illumination, and water type."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ambient_illumination,
        askg-data:Entity-coefficient,
        askg-data:Entity-sensor,
        askg-data:Entity-water_type .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-64-Sentence-647 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Generally, the coefficient of backscatter is different from the coefficient associated with the direct signal."@en ;
    askg-onto:inSentence "Generally, the coefficient of backscatter is different from the coefficient associated with the direct signal."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coefficient_associated_with_the_direct_signal,
        askg-data:Entity-coefficient_of_backscatter .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "In summary, the atmospheric scattering model is suitable for underwater scenarios only in some cases, such as shallow water with low backscatter. Compared to the atmospheric scattering model, the simplified underwater image formation model takes the selective attenuation of different wavelengths into consideration, which extends the generalization of this model. However, the simplified underwater image formation model assumes the attenuation coefficients are only properties of the water, which is inaccurate because the attenuation coefficients vary with the sensor, ambient illumination, *etc.* Besides, the simplified model ignores the fact that the backscattered light has a different attenuation coefficient from the direct light. Thus, a physically accurate model (i.e., revised underwater image formation model) is proposed, which further completes the model of underwater image formation. Nevertheless, such an accurate model has barely received much attention due to its complexity. Most of the deep learning-based underwater image enhancement algorithms still follow the atmospheric scattering model or simplified underwater image formation model to synthesize their training data and design their network architectures. Inaccurate models tend to happen in unreliable, unstable, and inauthentic results of deep algorithms."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-651,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-652,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-653,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-654,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-655,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-656,
        askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-657 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In summary, the atmospheric scattering model is suitable for underwater scenarios only in some cases, such as shallow water with low backscatter."@en ;
    askg-onto:inSentence "In summary, the atmospheric scattering model is suitable for underwater scenarios only in some cases, such as shallow water with low backscatter."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-underwater_scenarios .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Compared to the atmospheric scattering model, the simplified underwater image formation model takes the selective attenuation of different wavelengths into consideration, which extends the generalization of this model."@en ;
    askg-onto:inSentence "Compared to the atmospheric scattering model, the simplified underwater image formation model takes the selective attenuation of different wavelengths into consideration, which extends the generalization of this model."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-selective_attenuation_of_different_wavelengths,
        askg-data:Entity-this_model,
        askg-data:Entity-underwater_image_formation_model .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-653 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, the simplified underwater image formation model assumes the attenuation coefficients are only properties of the water, which is inaccurate because the attenuation coefficients vary with the sensor, ambient illumination, *etc.* Besides, the simplified model ignores the fact that the backscattered light has a different attenuation coefficient from the direct light."@en ;
    askg-onto:inSentence "However, the simplified underwater image formation model assumes the attenuation coefficients are only properties of the water, which is inaccurate because the attenuation coefficients vary with the sensor, ambient illumination, *etc.* Besides, the simplified model ignores the fact that the backscattered light has a different attenuation coefficient from the direct light."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ambient_illumination,
        askg-data:Entity-attenuation_coefficients,
        askg-data:Entity-backscattered_light,
        askg-data:Entity-direct_light,
        askg-data:Entity-sensor,
        askg-data:Entity-underwater_image_formation_model,
        askg-data:Entity-water .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-654 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Thus, a physically accurate model (i.e., revised underwater image formation model) is proposed, which further completes the model of underwater image formation."@en ;
    askg-onto:inSentence "Thus, a physically accurate model (i.e., revised underwater image formation model) is proposed, which further completes the model of underwater image formation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-revised_underwater_image_formation_model,
        askg-data:Entity-underwater_image_formation_model .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-655 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Nevertheless, such an accurate model has barely received much attention due to its complexity."@en ;
    askg-onto:inSentence "Nevertheless, such an accurate model has barely received much attention due to its complexity."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complexity,
        askg-data:Entity-model .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-656 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Most of the deep learning-based underwater image enhancement algorithms still follow the atmospheric scattering model or simplified underwater image formation model to synthesize their training data and design their network architectures."@en ;
    askg-onto:inSentence "Most of the deep learning-based underwater image enhancement algorithms still follow the atmospheric scattering model or simplified underwater image formation model to synthesize their training data and design their network architectures."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atmospheric_scattering_model,
        askg-data:Entity-deep_learning-based_underwater_image_enhancement_algorithms,
        askg-data:Entity-network_architectures,
        askg-data:Entity-simplified_underwater_image_formation_model,
        askg-data:Entity-training_data .

askg-data:Paper-c63c8058011e31f2-Section-6-Paragraph-65-Sentence-657 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Inaccurate models tend to happen in unreliable, unstable, and inauthentic results of deep algorithms."@en ;
    askg-onto:inSentence "Inaccurate models tend to happen in unreliable, unstable, and inauthentic results of deep algorithms."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_algorithms,
        askg-data:Entity-inauthentic_results,
        askg-data:Entity-models,
        askg-data:Entity-results,
        askg-data:Entity-unreliable_results,
        askg-data:Entity-unstable_results .

askg-data:Paper-c63c8058011e31f2-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "3 Deep Underwater Image Enhancement Algorithms"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71 ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Deep underwater image enhancement algorithms can ideally be divided into two main categories *i.e.*, CNN- based and GAN-based algorithms. The goal of the CNN algorithms is to be faithful to the original underwater image while the GAN-based algorithms aim to improve the perceptual quality of the images. However, this classification is very naive; therefore, we categorize the networks based on their architectural differences. In Figure 1, the categorization of deep underwater networks is presented, and in the following sections, we list and provide details for each method into different categories based on essential aspects."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-711,
        askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-712,
        askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-713,
        askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-714 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Deep underwater image enhancement algorithms can ideally be divided into two main categories *i.e.*, CNN- based and GAN-based algorithms."@en ;
    askg-onto:inSentence "Deep underwater image enhancement algorithms can ideally be divided into two main categories *i.e.*, CNN- based and GAN-based algorithms."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn-based_algorithms,
        askg-data:Entity-deep_underwater_image_enhancement_algorithms,
        askg-data:Entity-gan-based_algorithms .

askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The goal of the CNN algorithms is to be faithful to the original underwater image while the GAN-based algorithms aim to improve the perceptual quality of the images."@en ;
    askg-onto:inSentence "The goal of the CNN algorithms is to be faithful to the original underwater image while the GAN-based algorithms aim to improve the perceptual quality of the images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn_algorithms,
        askg-data:Entity-faithful_to_the_original_underwater_image,
        askg-data:Entity-gan-based_algorithms,
        askg-data:Entity-improve_the_perceptual_quality_of_the_images .

askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, this classification is very naive; therefore, we categorize the networks based on their architectural differences."@en ;
    askg-onto:inSentence "However, this classification is very naive; therefore, we categorize the networks based on their architectural differences."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architectural_differences,
        askg-data:Entity-classification,
        askg-data:Entity-naive,
        askg-data:Entity-networks .

askg-data:Paper-c63c8058011e31f2-Section-7-Paragraph-71-Sentence-714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Figure 1, the categorization of deep underwater networks is presented, and in the following sections, we list and provide details for each method into different categories based on essential aspects."@en ;
    askg-onto:inSentence "In Figure 1, the categorization of deep underwater networks is presented, and in the following sections, we list and provide details for each method into different categories based on essential aspects."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_underwater_networks,
        askg-data:Entity-different_categories,
        askg-data:Entity-essential_aspects,
        askg-data:Entity-methods .

askg-data:Paper-c63c8058011e31f2-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "3.1 Encoder-Decoder Models"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-8-Paragraph-81 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The following models benefit from the famous encoderdecoder architecture to advance the underwater image enhancement research."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-8-Paragraph-81-Sentence-811 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The following models benefit from the famous encoderdecoder architecture to advance the underwater image enhancement research."@en ;
    askg-onto:inSentence "The following models benefit from the famous encoderdecoder architecture to advance the underwater image enhancement research."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_architecture,
        askg-data:Entity-models,
        askg-data:Entity-underwater_image_enhancement_research .

askg-data:Paper-c63c8058011e31f2-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "3.1.1 P2P Network"@en ;
    askg-onto:hasParagraph askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-91,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Recently, Sun *et al.* [53] suggested the use of pixelto-pixel (P2P) network to enhance underwater images."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-91-Sentence-911 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Recently, Sun *et al.* [53] suggested the use of pixelto-pixel (P2P) network to enhance underwater images."@en ;
    askg-onto:inSentence "Recently, Sun *et al.* [53] suggested the use of pixelto-pixel (P2P) network to enhance underwater images."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pixelto-pixel_p2p_network,
        askg-data:Entity-sun_et_al,
        askg-data:Entity-underwater_images .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The proposed model is a \"symmetric\" encoder and decoder network similar to REDNet [40]. The encoder part is composed of three convolutional layers, while the decoder is made from three deconvolutional layers. ReLU follows each network element except the last one."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92-Sentence-921,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92-Sentence-922,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92-Sentence-923 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92-Sentence-921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The proposed model is a \"symmetric\" encoder and decoder network similar to REDNet [40]."@en ;
    askg-onto:inSentence "The proposed model is a \"symmetric\" encoder and decoder network similar to REDNet [40]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-rednet,
        askg-data:Entity-symmetric_encoder_and_decoder_network .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92-Sentence-922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The encoder part is composed of three convolutional layers, while the decoder is made from three deconvolutional layers."@en ;
    askg-onto:inSentence "The encoder part is composed of three convolutional layers, while the decoder is made from three deconvolutional layers."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decoder,
        askg-data:Entity-encoder,
        askg-data:Entity-three_convolutional_layers,
        askg-data:Entity-three_deconvolutional_layers .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-92-Sentence-923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "ReLU follows each network element except the last one."@en ;
    askg-onto:inSentence "ReLU follows each network element except the last one."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-each_network_element,
        askg-data:Entity-relu .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "This model is trained on 3359 images collected from the real-world environment. To simulate the underwater images, the authors pour milk of 30, 50, and 70 ml into 1m3 of water to produce low, medium and high-level degradation, respectively. Finally, out of these, 10,000 images are selected for training and another 2,000 images for testing. Moreover, the input to the network is a cropped patch of 66×66. The loss function is `2 minimized via SGD [32] with an initial learning rate of 10−7."@en ;
    askg-onto:hasSentence askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-931,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-932,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-933,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-934,
        askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-935 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This model is trained on 3359 images collected from the real-world environment."@en ;
    askg-onto:inSentence "This model is trained on 3359 images collected from the real-world environment."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-images,
        askg-data:Entity-model .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To simulate the underwater images, the authors pour milk of 30, 50, and 70 ml into 1m3 of water to produce low, medium and high-level degradation, respectively."@en ;
    askg-onto:inSentence "To simulate the underwater images, the authors pour milk of 30, 50, and 70 ml into 1m3 of water to produce low, medium and high-level degradation, respectively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-authors,
        askg-data:Entity-low_medium_and_high-level_degradation,
        askg-data:Entity-milk_of_30_50_and_70_ml,
        askg-data:Entity-milk_of_30_50_and_70_ml_into_1m3_of_water .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-933 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Finally, out of these, 10,000 images are selected for training and another 2,000 images for testing."@en ;
    askg-onto:inSentence "Finally, out of these, 10,000 images are selected for training and another 2,000 images for testing."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10000_images,
        askg-data:Entity-2000_images,
        askg-data:Entity-testing,
        askg-data:Entity-training .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-934 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, the input to the network is a cropped patch of 66×66."@en ;
    askg-onto:inSentence "Moreover, the input to the network is a cropped patch of 66×66."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cropped_patch_of_6666,
        askg-data:Entity-input .

askg-data:Paper-c63c8058011e31f2-Section-9-Paragraph-93-Sentence-935 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The loss function is `2 minimized via SGD [32] with an initial learning rate of 10−7."@en ;
    askg-onto:inSentence "The loss function is `2 minimized via SGD [32] with an initial learning rate of 10−7."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-107,
        askg-data:Entity-loss_function,
        askg-data:Entity-sgd .

askg-data:Entity-%CE%B2 rdfs:label "β"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B2%CE%BB rdfs:label "βλ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BB rdfs:label "λ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-02 rdfs:label "0.2"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-103 rdfs:label "10−3"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-104 rdfs:label "10−4"@en ;
    askg-onto:entityType "Metric"@en,
        "Rate"@en .

askg-data:Entity-107 rdfs:label "10−7"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-16 rdfs:label "16"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2 rdfs:label "2"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-2009 rdfs:label "2009"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2562563 rdfs:label "256×256×3"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-2_loss rdfs:label "2 loss"@en,
        "`2 loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-33 rdfs:label "3×3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-60 rdfs:label "60"@en ;
    askg-onto:entityType "Concept"@en,
        "Measure"@en .

askg-data:Entity-7070_patchgans rdfs:label "70×70 PatchGANs"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-absorption rdfs:label "absorption"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-alahi_a rdfs:label "Alahi, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-ambient_illumination rdfs:label "ambient illumination"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-anwar_s rdfs:label "Anwar, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-artificial_colors rdfs:label "artificial colors"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-attenuation rdfs:label "attenuation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-background_light rdfs:label "background light"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-backscattering rdfs:label "backscattering"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-benchmark_datasets rdfs:label "benchmark datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-bengio_y rdfs:label "Bengio, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bluish_tone rdfs:label "bluish tone"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bn rdfs:label "BN"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-c rdfs:label "C."@en,
        "c"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c1 rdfs:label "C1"@en,
        "c1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c2 rdfs:label "C2"@en,
        "c2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c3 rdfs:label "C3"@en,
        "c3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cnn-based_methods rdfs:label "CNN-based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-cnn_methods rdfs:label "CNN methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-coarse-global_subnet rdfs:label "coarse-global subnet"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-color_casts rdfs:label "color casts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-color_correction_subnetwork rdfs:label "color correction subnetwork"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-consistency_loss rdfs:label "consistency loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-conventional_method rdfs:label "conventional method"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-convolutional_neural_networks rdfs:label "Convolutional Neural Networks"@en,
        "convolutional neural networks"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-current_algorithms rdfs:label "Current algorithms"@en,
        "current algorithms"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-cycle_consistency_loss rdfs:label "cycle consistency loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cycle_structure rdfs:label "cycle structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dark_channel_prior rdfs:label "dark channel prior"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_analysis rdfs:label "Data Analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_augmentation rdfs:label "data augmentation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-data_science rdfs:label "Data Science"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-deconvolutional_layers rdfs:label "deconvolutional layers"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-deep_learning-based_methods rdfs:label "deep learning-based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_networks rdfs:label "deep networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-deep_underwater_image_enhancement rdfs:label "Deep underwater image enhancement"@en,
        "deep underwater image enhancement"@en ;
    askg-onto:entityType "Article"@en,
        "Method"@en .

askg-data:Entity-deep_underwater_image_enhancement_algorithms rdfs:label "Deep underwater image enhancement algorithms"@en,
        "deep underwater image enhancement algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-deep_underwater_networks rdfs:label "Deep Underwater Networks"@en,
        "deep underwater networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_estimation_network rdfs:label "depth estimation network"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-depth_maps rdfs:label "depth maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-device rdfs:label "Device"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-domain_knowledge rdfs:label "domain knowledge"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-dual_generator_gans rdfs:label "dual generator GANs"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-epochs rdfs:label "epochs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-existing_algorithms rdfs:label "Existing algorithms"@en,
        "existing algorithms"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-fergus_r rdfs:label "Fergus, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-figure_6 rdfs:label "Figure 6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figures_4-8 rdfs:label "Figures 4-8"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-five_convolutional_layers rdfs:label "five convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ftu rdfs:label "FTU"@en ;
    askg-onto:entityType "Concept"@en,
        "Device"@en .

askg-data:Entity-future_research_directions rdfs:label "future research directions"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-gan rdfs:label "GAN"@en,
        "gan"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gan-based_algorithms rdfs:label "GAN-based algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-gan-based_methods rdfs:label "GAN-based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-gan_methods rdfs:label "GAN methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-generative_adversarial_network rdfs:label "generative adversarial network"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-gradient_loss rdfs:label "gradient loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-guo_j rdfs:label "Guo, J."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-haze_detection_subnet rdfs:label "haze detection subnet"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-haze_detection_subnetwork rdfs:label "haze detection subnetwork"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-haze_mask rdfs:label "haze mask"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-human_perception rdfs:label "human perception"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-i%CE%BBx rdfs:label "Iλ(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iclr rdfs:label "ICLR"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-image_enhancement_techniques rdfs:label "image enhancement techniques"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-image_quality_index rdfs:label "image quality index"@en ;
    askg-onto:entityType "Concept"@en,
        "Index"@en .

askg-data:Entity-image_restoration_network rdfs:label "image restoration network"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-image_superresolution rdfs:label "image superresolution"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-input_image rdfs:label "input image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inputs rdfs:label "inputs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-institution rdfs:label "Institution"@en ;
    askg-onto:entityType "Institution"@en,
        "Organization"@en .

askg-data:Entity-ix rdfs:label "I(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-johnson-roberson_m rdfs:label "Johnson-Roberson, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-johnson_j rdfs:label "Johnson, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-last_layer rdfs:label "last layer"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-latent_vector rdfs:label "latent vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning rdfs:label "learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lecun_y rdfs:label "LeCun, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-li_j rdfs:label "Li, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-losses rdfs:label "losses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maris rdfs:label "MARIS"@en,
        "Maris"@en ;
    askg-onto:entityType "Person"@en,
        "Platform"@en .

askg-data:Entity-measures rdfs:label "measures"@en ;
    askg-onto:entityType "Concept"@en,
        "Measure"@en .

askg-data:Entity-metrics rdfs:label "metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-multiscale_ssim_loss rdfs:label "multiscale SSIM loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-natural_language_processing rdfs:label "Natural Language Processing"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-network_loss rdfs:label "Network loss"@en,
        "network loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_parameters rdfs:label "network parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise rdfs:label "noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nuisance_loss rdfs:label "nuisance loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_channels rdfs:label "number of channels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nyu-v2_dataset rdfs:label "NYU-v2 dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-open_water rdfs:label "open water"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-optimizer rdfs:label "optimizer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-organization rdfs:label "Organization"@en,
        "organization"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-p2p_net rdfs:label "P2P Net"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-paper rdfs:label "paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-perceptual_loss rdfs:label "perceptual loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-perceptual_losses_for_real-time_style_transfer_and_super-resolution rdfs:label "Perceptual losses for real-time style transfer and super-resolution"@en ;
    askg-onto:entityType "Article"@en,
        "Publication"@en .

askg-data:Entity-phenomenon rdfs:label "phenomenon"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-physical_model-based_methods rdfs:label "physical model-based methods"@en ;
    askg-onto:entityType "Method"@en,
        "Technique"@en .

askg-data:Entity-platform rdfs:label "Platform"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-pooling rdfs:label "pooling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quality_degradation rdfs:label "quality degradation"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-real rdfs:label "Real"@en,
        "real"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-real-world_underwater_images rdfs:label "real-world underwater images"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-reasons rdfs:label "reasons"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ren_s rdfs:label "Ren, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-researcher rdfs:label "Researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-researchers rdfs:label "researchers"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-residual_learning rdfs:label "residual learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-revised_underwater_image_formation_model rdfs:label "revised underwater image formation model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-rgb_images rdfs:label "RGB images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scattering rdfs:label "scattering"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sensor rdfs:label "sensor"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-shen_c rdfs:label "Shen, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-signals rdfs:label "signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simoncelli_ep rdfs:label "Simoncelli, E.P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-simplified_underwater_image_formation_model rdfs:label "simplified underwater image formation model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-skinner_ka rdfs:label "Skinner, K.A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-spectral_normalization rdfs:label "Spectral normalization"@en,
        "spectral normalization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structure rdfs:label "structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-synthetic_data rdfs:label "synthetic data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-t%CE%BBx rdfs:label "Tλ(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tanh_layer rdfs:label "TanH layer"@en ;
    askg-onto:entityType "Concept"@en,
        "Device"@en .

askg-data:Entity-target_domain rdfs:label "target domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-tensorflow_framework rdfs:label "TensorFlow framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-the_camera rdfs:label "the camera"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-the_network rdfs:label "the network"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-they rdfs:label "They"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_dataset rdfs:label "this dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-tm-net rdfs:label "TM-Net"@en ;
    askg-onto:entityType "Model"@en,
        "Technology"@en .

askg-data:Entity-training_configurations rdfs:label "training configurations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_data_synthesis rdfs:label "training data synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_images rdfs:label "training images"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-transmission_maps rdfs:label "transmission maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-treibitz_t rdfs:label "Treibitz, T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-u%CE%BBx rdfs:label "Uλ(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image rdfs:label "underwater image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_image_enhancement_methods rdfs:label "Underwater image enhancement methods"@en,
        "underwater image enhancement methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-underwater_image_enhancement_research rdfs:label "underwater image enhancement research"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-underwater_image_restoration rdfs:label "underwater image restoration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underwater_images_and_videos rdfs:label "underwater images and videos"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-underwater_imaging rdfs:label "underwater imaging"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unet rdfs:label "UNET"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Model"@en .

askg-data:Entity-uwcnn_model rdfs:label "UWCNN model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-uwgan_model rdfs:label "UWGAN model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-ux rdfs:label "U(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vbx rdfs:label "vb(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vdx rdfs:label "vd(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vgg rdfs:label "VGG"@en ;
    askg-onto:entityType "Model"@en,
        "Technology"@en .

askg-data:Entity-visual_results rdfs:label "visual results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-water rdfs:label "water"@en ;
    askg-onto:entityType "Condition"@en,
        "Molecule"@en .

askg-data:Entity-website rdfs:label "Website"@en,
        "website"@en ;
    askg-onto:entityType "Concept"@en,
        "Platform"@en .

askg-data:Entity-2019 rdfs:label "2019"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-256256 rdfs:label "256×256"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-algorithms rdfs:label "algorithms"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-attenuation_coefficients rdfs:label "attenuation coefficients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-chongyi_li rdfs:label "Chongyi Li"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cnns rdfs:label "CNNs"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-convolutional_layer rdfs:label "convolutional layer"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-deep_learning_techniques rdfs:label "deep learning techniques"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-depth_map rdfs:label "Depth map"@en,
        "depth map"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-different_methods rdfs:label "different methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-encoder rdfs:label "encoder"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-encoder-decoder_architecture rdfs:label "encoder-decoder architecture"@en ;
    askg-onto:entityType "Concept"@en,
        "Framework"@en,
        "Paradigm"@en .

askg-data:Entity-experiment rdfs:label "Experiment"@en,
        "experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-fei-fei_l rdfs:label "Fei-Fei, L."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-fgan rdfs:label "FGAN"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-four_convolutional_layers rdfs:label "four convolutional layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generative_adversarial_networks rdfs:label "generative adversarial networks"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Technology"@en .

askg-data:Entity-guided_image_filtering rdfs:label "Guided image filtering"@en,
        "guided image filtering"@en ;
    askg-onto:entityType "Method"@en,
        "Publication"@en .

askg-data:Entity-guo_c rdfs:label "Guo, C."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-ieee_signal_processing_letters rdfs:label "IEEE Signal Processing Letters"@en,
        "IEEE signal processing letters"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-image_recognition rdfs:label "Image Recognition"@en,
        "image recognition"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-imagenet rdfs:label "ImageNet"@en,
        "Imagenet"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-limitations rdfs:label "limitations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss rdfs:label "loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-msdb_block rdfs:label "MSDB block"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_architectures rdfs:label "Network architectures"@en,
        "network architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nips rdfs:label "NIPS"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-nuisance_classifier rdfs:label "nuisance classifier"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-output rdfs:label "output"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-patchgan rdfs:label "PatchGAN"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-reference_images rdfs:label "reference images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s-net rdfs:label "S-Net"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-segnet rdfs:label "SegNet"@en,
        "Segnet"@en ;
    askg-onto:entityType "Model"@en,
        "Technology"@en .

askg-data:Entity-ssim_loss rdfs:label "SSIM loss"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-survey rdfs:label "survey"@en ;
    askg-onto:entityType "Concept"@en,
        "Study"@en .

askg-data:Entity-tip rdfs:label "TIP"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-tool rdfs:label "Tool"@en,
        "tool"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-ugan rdfs:label "UGAN"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Model"@en .

askg-data:Entity-uie-dal rdfs:label "UIE-DAL"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-uie-sgan rdfs:label "UIE-sGAN"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-unknown_concept rdfs:label "unknown concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unsupervised_learning rdfs:label "Unsupervised learning"@en,
        "unsupervised learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-volunteers rdfs:label "volunteers"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-2014 rdfs:label "2014"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2015 rdfs:label "2015"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2016 rdfs:label "2016"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2017 rdfs:label "2017"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-arxiv_preprint rdfs:label "arXiv preprint"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-backscatter rdfs:label "Backscatter"@en,
        "backscatter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bl-net rdfs:label "BL-Net"@en ;
    askg-onto:entityType "Model"@en,
        "Technology"@en .

askg-data:Entity-cc-net rdfs:label "CC-Net"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "System"@en,
        "Technology"@en .

askg-data:Entity-color_correction_network rdfs:label "color correction network"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en,
        "Technique"@en .

askg-data:Entity-convolutional_layers rdfs:label "convolutional layers"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en,
        "Technology"@en .

askg-data:Entity-cyclegan rdfs:label "CycleGAN"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Model"@en .

askg-data:Entity-dx rdfs:label "d(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eccv rdfs:label "ECCV"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-ground-truth_images rdfs:label "ground-truth images"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-haze-line rdfs:label "Haze-line"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Method"@en .

askg-data:Entity-haze-line_dataset rdfs:label "Haze-line Dataset"@en,
        "Haze-line dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-high_backscatter rdfs:label "high backscatter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hr-net rdfs:label "HR-Net"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "System"@en,
        "Technology"@en .

askg-data:Entity-image rdfs:label "image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_enhancement rdfs:label "image enhancement"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-image_quality rdfs:label "image quality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input rdfs:label "input"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-leaky_relu rdfs:label "leaky ReLU"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-li_et_al rdfs:label "Li *et al.*"@en,
        "Li et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-low_backscatter rdfs:label "low backscatter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mcyclegan rdfs:label "MCycleGAN"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-metric rdfs:label "Metric"@en,
        "metric"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-network_architecture rdfs:label "network architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-networks rdfs:label "networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_parameters rdfs:label "number of parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-performance rdfs:label "performance"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-saeed_anwar rdfs:label "Saeed Anwar"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-technology rdfs:label "Technology"@en,
        "technology"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-testing rdfs:label "testing"@en ;
    askg-onto:entityType "Concept"@en,
        "Experiment"@en,
        "Method"@en .

askg-data:Entity-tpami rdfs:label "TPAMI"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-uciqe rdfs:label "UCIQE"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-uir-net rdfs:label "UIR-Net"@en ;
    askg-onto:entityType "Model"@en,
        "Technology"@en .

askg-data:Entity-underwater_image_datasets rdfs:label "underwater image datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-viewing_conditions rdfs:label "viewing conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b rdfs:label "B"@en,
        "b"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_normalization rdfs:label "batch normalization"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-bovik_ac rdfs:label "Bovik, A.C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-computer_vision rdfs:label "Computer Vision"@en,
        "computer vision"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Research Field"@en .

askg-data:Entity-conference rdfs:label "Conference"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning-based_underwater_image_enhancement rdfs:label "deep learning-based underwater image enhancement"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-deep_learning-based_underwater_image_enhancement_algorithms rdfs:label "deep learning-based underwater image enhancement algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-he_k rdfs:label "He, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-li_c rdfs:label "Li, C."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-psnr rdfs:label "PSNR"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-relu rdfs:label "ReLU"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Technique"@en,
        "Technology"@en .

askg-data:Entity-training rdfs:label "training"@en ;
    askg-onto:entityType "Concept"@en,
        "Experiment"@en,
        "Method"@en .

askg-data:Entity-training_data rdfs:label "training data"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-tx rdfs:label "T(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uie-net rdfs:label "UIE-Net"@en ;
    askg-onto:entityType "Model"@en,
        "Technology"@en .

askg-data:Entity-x rdfs:label "x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2018 rdfs:label "2018"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-adam rdfs:label "ADAM"@en,
        "Adam"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-authors rdfs:label "authors"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-features rdfs:label "features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gans rdfs:label "GANs"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-methods rdfs:label "methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-results rdfs:label "results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-study rdfs:label "Study"@en,
        "study"@en ;
    askg-onto:entityType "Research Area"@en,
        "Study"@en .

askg-data:Entity-transmission_map rdfs:label "transmission map"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-uiqm rdfs:label "UIQM"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-underwater_image_formation_model rdfs:label "underwater image formation model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-urcnn rdfs:label "URCNN"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en .

askg-data:Entity-article rdfs:label "Article"@en,
        "article"@en ;
    askg-onto:entityType "Article"@en,
        "Publication"@en .

askg-data:Entity-cvpr rdfs:label "CVPR"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en,
        "Deep learning"@en,
        "deep learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fig rdfs:label "Fig"@en,
        "Fig."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate rdfs:label "learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en,
        "machine learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-ssim rdfs:label "SSIM"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-ulfid rdfs:label "ULFID"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-adversarial_loss rdfs:label "adversarial loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-datasets rdfs:label "datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-deep_algorithms rdfs:label "deep algorithms"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-densegan rdfs:label "DenseGAN"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-generator rdfs:label "generator"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Device"@en .

askg-data:Entity-loss_function rdfs:label "loss function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-models rdfs:label "models"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-pcqi rdfs:label "PCQI"@en ;
    askg-onto:entityType "Concept"@en,
        "Index"@en,
        "Metric"@en .

askg-data:Entity-uwcnn rdfs:label "UWCNN"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Model"@en .

askg-data:Entity-watergan rdfs:label "WaterGAN"@en,
        "Watergan"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en,
        "Tool"@en .

askg-data:Entity-atmospheric_scattering_model rdfs:label "atmospheric scattering model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-duienet rdfs:label "DUIENet"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-mse rdfs:label "MSE"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-wang_z rdfs:label "Wang, Z."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-algorithm rdfs:label "Algorithm"@en,
        "algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-discriminator rdfs:label "discriminator"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Device"@en,
        "Technology"@en .

askg-data:Entity-model rdfs:label "Model"@en,
        "model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-author rdfs:label "Author"@en,
        "author"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en .

askg-data:Entity-evaluation_metrics rdfs:label "evaluation metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-uwgan rdfs:label "UWGAN"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-uiebd rdfs:label "UIEBD"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Organization"@en,
        "Platform"@en .

askg-data:Entity-network rdfs:label "network"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "System"@en,
        "Technology"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Concept"@en,
        "Corpus"@en,
        "Dataset"@en .

askg-data:Entity-images rdfs:label "images"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-concept rdfs:label "Concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-research_area rdfs:label "Research Area"@en,
        "research area"@en ;
    askg-onto:entityType "Domain"@en,
        "Research Area"@en .

askg-data:Entity-underwater_image_enhancement rdfs:label "Underwater image enhancement"@en,
        "underwater image enhancement"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Research Area"@en .

askg-data:Entity-underwater_images rdfs:label "underwater images"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Result"@en .

askg-data:Entity-publication rdfs:label "Publication"@en ;
    askg-onto:entityType "Article"@en,
        "Concept"@en,
        "Publication"@en .

