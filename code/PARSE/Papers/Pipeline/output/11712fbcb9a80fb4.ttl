@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-11712fbcb9a80fb4 a askg-onto:Paper ;
    rdfs:label "11712fbcb9a80fb4"@en ;
    dc:title "11712fbcb9a80fb4"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-11712fbcb9a80fb4-Section-1,
        askg-data:Paper-11712fbcb9a80fb4-Section-10,
        askg-data:Paper-11712fbcb9a80fb4-Section-11,
        askg-data:Paper-11712fbcb9a80fb4-Section-12,
        askg-data:Paper-11712fbcb9a80fb4-Section-13,
        askg-data:Paper-11712fbcb9a80fb4-Section-14,
        askg-data:Paper-11712fbcb9a80fb4-Section-15,
        askg-data:Paper-11712fbcb9a80fb4-Section-16,
        askg-data:Paper-11712fbcb9a80fb4-Section-17,
        askg-data:Paper-11712fbcb9a80fb4-Section-18,
        askg-data:Paper-11712fbcb9a80fb4-Section-19,
        askg-data:Paper-11712fbcb9a80fb4-Section-2,
        askg-data:Paper-11712fbcb9a80fb4-Section-20,
        askg-data:Paper-11712fbcb9a80fb4-Section-21,
        askg-data:Paper-11712fbcb9a80fb4-Section-22,
        askg-data:Paper-11712fbcb9a80fb4-Section-23,
        askg-data:Paper-11712fbcb9a80fb4-Section-24,
        askg-data:Paper-11712fbcb9a80fb4-Section-25,
        askg-data:Paper-11712fbcb9a80fb4-Section-26,
        askg-data:Paper-11712fbcb9a80fb4-Section-3,
        askg-data:Paper-11712fbcb9a80fb4-Section-4,
        askg-data:Paper-11712fbcb9a80fb4-Section-5,
        askg-data:Paper-11712fbcb9a80fb4-Section-6,
        askg-data:Paper-11712fbcb9a80fb4-Section-7,
        askg-data:Paper-11712fbcb9a80fb4-Section-8,
        askg-data:Paper-11712fbcb9a80fb4-Section-9 .

askg-data:Entity-%09extbfg rdfs:label "	extbf{g}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extbfy rdfs:label "	extbf{y}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extk%09ext%09ext_%09extv_i%09ext%09ext_%09ext%CE%B1_it rdfs:label "	ext{K}	ext{,}	ext{ }	ext{v}_{i}	ext{,}	ext{ }	ext{α}_{i,t}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extsigmaw%09extprime%09extbfx%09extbfb%09extprime rdfs:label "	extsigma(W^{	extprime}	extbf{x}+	extbf{b}^{	extprime})"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-%09extv_t rdfs:label "${	ext{v}}_{t}$"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-%09ilde%09extbfy rdfs:label "	ilde{	extbf{y}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09ilde%09extbfy__%09extcirc__%09extbfg rdfs:label "	ilde{	extbf{y}} \\, 	extcirc \\, 	extbf{g}"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-%0Aabla_%09hetal_r%09heta rdfs:label """
abla_{	heta}L_{R}(	heta)"""@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%0Aprod_t1tpy_tmid_y_1t-1 rdfs:label """
\\prod_{t=1}^{T}p(y_{t}\\mid y_{1:t-1})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%80t rdfs:label "Πt"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-02 rdfs:label "0.2"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-09 rdfs:label "0.9"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-1 rdfs:label "1"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-100 rdfs:label "100"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-1000 rdfs:label "1,000"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-10010_words rdfs:label "10,010 words"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-108k_images rdfs:label "108K images"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-10_32 rdfs:label "10 [32]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-10_51 rdfs:label "10 [51]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-11 rdfs:label "1×1"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-113287 rdfs:label "113,287"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-1218_hours rdfs:label "12–18 hours"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-123 rdfs:label "123"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-14 rdfs:label "14%"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-1600_object_classes rdfs:label "1,600 object classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-161 rdfs:label "161"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-17m_visual_question_answers rdfs:label "1.7M visual question answers"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-194 rdfs:label "194"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-1994 rdfs:label "1994"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-1_2_29 rdfs:label "1, 2 [29]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_3_4_6_7 rdfs:label "1, 2, 3, 4, 6, 7"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_3_7_28 rdfs:label "1, 2, 3, 7 [28]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_46 rdfs:label "1, 2 [46]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_52 rdfs:label "1, 2 [52]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_8_12 rdfs:label "1, 2, 8 [12]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2000 rdfs:label "2,000"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2002 rdfs:label "2002"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2014 rdfs:label "2014"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2017_vqa_challenge2 rdfs:label "2017 VQA Challenge2"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-2048 rdfs:label "2048"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-256 rdfs:label "25.6"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-264 rdfs:label "26.4"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-27 rdfs:label "27"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-270 rdfs:label "27.0"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-276 rdfs:label "27.6"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2_43 rdfs:label "2 [43]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2_5_17 rdfs:label "2, 5 [17]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2_5_21 rdfs:label "2, 5 [21]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-300_dimension_word_embeddings rdfs:label "300 dimension word embeddings"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-30_ensembled_models rdfs:label "30 ensembled models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-30_models rdfs:label "30 models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-30_of_the_available_data rdfs:label "30% of the available data"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-313_597 rdfs:label "31.3 59.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-315582018601862_2007 rdfs:label "315(5820):1860–1862, 2007"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-33 rdfs:label "[33]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-33201215 rdfs:label "3(3):201–215"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-336_637 rdfs:label "33.6 63.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-34 rdfs:label "[34]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-347 rdfs:label "34.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-352_645 rdfs:label "35.2 64.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-354 rdfs:label "35.4"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-355 rdfs:label "35.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-356_652 rdfs:label "35.6 65.2"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-359 rdfs:label "35.9"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-362 rdfs:label "36.2"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-365 rdfs:label "36.5"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-367 rdfs:label "36.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-369_685 rdfs:label "36.9 68.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-37 rdfs:label "[37]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-377 rdfs:label "37.7"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-380k rdfs:label "380K"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-3_10 rdfs:label "3 [10]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-3_5_10_22 rdfs:label "3, 5, 10 [22]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-3_7_14 rdfs:label "3, 7 [14]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-400_attribute_classes rdfs:label "400 attribute classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-414_705 rdfs:label "41.4 70.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-428 rdfs:label "42.8"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-444_744 rdfs:label "44.4 74.4"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-468 rdfs:label "46.8"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-470_759 rdfs:label "47.0 75.9"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-476_765 rdfs:label "47.6 76.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-485k_questions rdfs:label "485K questions"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-491_794 rdfs:label "49.1 79.4"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-495 rdfs:label "49.5"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-4_45 rdfs:label "4 [45]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-4_6_44 rdfs:label "4, 6 [44]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-4_ensembled_models rdfs:label "4 ensembled models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-5 rdfs:label "[5]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-500 rdfs:label "500"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-512 rdfs:label "512"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-515 rdfs:label "51.5"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-550_812 rdfs:label "55.0 81.2"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-558 rdfs:label "55.8"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-563 rdfs:label "56.3"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-579 rdfs:label "57.9"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-584_845 rdfs:label "58.4 84.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-591 rdfs:label "59.1"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-594 rdfs:label "59.4"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5_10_39 rdfs:label "5, 10 [39]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-5_38 rdfs:label "5 [38]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-5_40 rdfs:label "5 [40]"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-5_6_24_s rdfs:label "5, 6 [24] S."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-5_8 rdfs:label "5 [8]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-5k rdfs:label "5K"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-619_860 rdfs:label "61.9 86.0"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-627_867 rdfs:label "62.7 86.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-632 rdfs:label "63.2"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-641_888 rdfs:label "64.1 88.8"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-6_20 rdfs:label "6 [20]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-6_23_t rdfs:label "6 [23] T."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-6_30 rdfs:label "6 [30]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-6_9 rdfs:label "6 [9]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-703_overall_accuracy rdfs:label "70.3% overall accuracy"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-720_900 rdfs:label "72.0 90.0"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-748_920 rdfs:label "74.8 92.0"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-754 rdfs:label "75.4"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-760 rdfs:label "76.0"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-766 rdfs:label "76.6"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-77 rdfs:label "7×7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-776 rdfs:label "77.6"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-781_937 rdfs:label "78.1 93.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-787_937 rdfs:label "78.7 93.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-7_15 rdfs:label "7 [15]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-7_25 rdfs:label "7 [25]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-7_50 rdfs:label "7 [50]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-801146_2001 rdfs:label "80(1):1–46, 2001"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-802_952 rdfs:label "80.2 95.2"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-803 rdfs:label "80.3"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-83-4229256 rdfs:label "8(3-4):229–256"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-8_41 rdfs:label "8 [41]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-8_42 rdfs:label "8 [42]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-8_times rdfs:label "8 times"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-a_learned_parameter_vector rdfs:label "a learned parameter vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_name rdfs:label "a name"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_prominent_figure_in_ai rdfs:label "a prominent figure in AI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_prominent_figure_in_linguistics rdfs:label "a prominent figure in linguistics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_score_function rdfs:label "a score function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_single_epoch rdfs:label "a single epoch"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-a_single_initialization rdfs:label "a single initialization"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-abstract_classes rdfs:label "abstract classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-acl rdfs:label "ACL"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-acl_workshop rdfs:label "ACL Workshop"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-adaptive rdfs:label "Adaptive"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-adaptive_attention rdfs:label "Adaptive attention"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-additional_output_layer rdfs:label "additional output layer"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-additional_questions_and_answers_from_visual_genome rdfs:label "additional questions and answers from Visual Genome"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-agrawal_j rdfs:label "Agrawal, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-all_other_leaderboard_entries rdfs:label "all other leaderboard entries"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-all_test_server_submissions rdfs:label "all test server submissions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-an_adaptive_learning_rate_method rdfs:label "an adaptive learning rate method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-an_article rdfs:label "an article"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-an_otherwise_salient_image_patch rdfs:label "an otherwise salient image patch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anchor_boxes rdfs:label "anchor boxes"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-anderson_b rdfs:label "Anderson, B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-anderson_x rdfs:label "Anderson, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-anguelov_d rdfs:label "Anguelov, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-annotations rdfs:label "annotations"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-answer_quality rdfs:label "answer quality"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-answers rdfs:label "answers"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-antol_a rdfs:label "Antol, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-any_target_language rdfs:label "Any Target Language"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-areas_of_attention_captioning_model rdfs:label "Areas of Attention captioning model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-arxiv rdfs:label "arXiv"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-arxiv12125701 rdfs:label "arXiv:1212.5701"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv150400325 rdfs:label "arXiv:1504.00325"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv150606272 rdfs:label "arXiv:1506.06272"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv160608390 rdfs:label "arXiv:1606.08390"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv161208083 rdfs:label "arXiv:1612.08083"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv170403162 rdfs:label "arXiv:1704.03162"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv_preprint_arxiv150500387v1 rdfs:label "arXiv preprint arXiv:1505.00387v1"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv151202325 rdfs:label "arXiv preprint arXiv:1512.02325"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv160207332 rdfs:label "arXiv preprint arXiv:1602.07332"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv160305027 rdfs:label "arXiv preprint arXiv:1603.05027"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv161105546 rdfs:label "arXiv preprint arXiv:1611.05546"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-athena rdfs:label "Athena"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-attend_to_spatial_image_features rdfs:label "attend to spatial image features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attended_feature_vector rdfs:label "attended feature vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attended_image_feature rdfs:label "attended image feature"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attended_image_feature_v%CB%86 rdfs:label "attended image feature vˆ"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-attended_image_region rdfs:label "attended image region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attention-based_deep_neural_networks rdfs:label "attention-based deep neural networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-attention_candidates rdfs:label "attention candidates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attention_distribution rdfs:label "attention distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attention_in_visual_search rdfs:label "attention in visual search"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attention_layer rdfs:label "attention layer"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-attention_maps rdfs:label "attention maps"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-attention_models rdfs:label "attention models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-attention_output rdfs:label "attention output"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-attention_to_be_calculated_at_the_level_of_objects_and_other_salient_image_regions rdfs:label "attention to be calculated at the level of objects and other salient image regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attentive_mechanism rdfs:label "attentive mechanism"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attribute_class rdfs:label "attribute class"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attribute_predictor rdfs:label "attribute predictor"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-attributes rdfs:label "attributes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-auli rdfs:label "Auli"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-australian_national_university rdfs:label "Australian National University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-australian_research_council_centre_of_excellence_for_robotic_vision rdfs:label "Australian Research Council Centre of Excellence for Robotic Vision"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-australian_research_councils_discovery_projects_funding_scheme rdfs:label "Australian Research Councils Discovery Projects funding scheme"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-automatic_evaluation_metrics rdfs:label "automatic evaluation metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-automatic_evaluation_of_machine_translation rdfs:label "automatic evaluation of machine translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ba_r rdfs:label "Ba, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-baseline_model rdfs:label "baseline model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-baseline_score rdfs:label "baseline score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-batch_size_of_100 rdfs:label "batch size of 100"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-bathroom rdfs:label "bathroom"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batra_c rdfs:label "Batra, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-beam_search rdfs:label "beam search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-beam_search_decoding rdfs:label "beam search decoding"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-beam_size rdfs:label "beam size"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-belongie_j rdfs:label "Belongie, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bernstein_a rdfs:label "Bernstein, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-best_reported_results rdfs:label "best reported results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-better_performance rdfs:label "better performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-bidirectional_attention rdfs:label "bidirectional attention"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bioengineering_methods rdfs:label "Bioengineering methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bottom-up rdfs:label "'bottom-up'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bottom-up_and_topdown_attention rdfs:label "bottom-up and topdown attention"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bottom-up_at rdfs:label "bottom-up at"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bottom-up_attention_features rdfs:label "bottom-up attention features"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bottom-up_control rdfs:label "bottom-up control"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bottom-up_signals rdfs:label "bottom-up signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bougares_h rdfs:label "Bougares, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bounding_box rdfs:label "bounding box"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bounding_box_refinement rdfs:label "bounding box refinement"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bounding_box_refinements rdfs:label "bounding box refinements"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bounding_boxes rdfs:label "bounding boxes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-box_proposals rdfs:label "box proposals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-buildings rdfs:label "buildings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-buschman rdfs:label "Buschman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-calculations_at_the_level_of_objects_and_other_salient_image_regions rdfs:label "calculations at the level of objects and other salient image regions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-candidate_attention_region rdfs:label "candidate attention region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-capabilities rdfs:label "capabilities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-caption_output rdfs:label "caption output"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-caption_quality rdfs:label "caption quality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-caption_samples rdfs:label "caption samples"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-captioning_models rdfs:label "captioning models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-captioning_of_a_compositionally_novel_scene rdfs:label "captioning of a compositionally novel scene"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-celestial_body rdfs:label "celestial body"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cell_type rdfs:label "Cell Type"@en ;
    askg-onto:entityType "Cell Type"@en .

askg-data:Entity-chen_t-y rdfs:label "Chen, T.-Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chen_y rdfs:label "Chen, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cho_a rdfs:label "Cho, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cho_b rdfs:label "Cho, B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chris_buehler rdfs:label "Chris Buehler"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cider__spice__bleu-4 rdfs:label "CIDEr / SPICE / BLEU-4"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-class-specific_bounding_box_refinements rdfs:label "class-specific bounding box refinements"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-class_detection_confidence_threshold rdfs:label "class detection confidence threshold"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-class_detection_probability rdfs:label "class detection probability"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-classes rdfs:label "classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classification_on_imagenet rdfs:label "classification on ImageNet"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-classifier rdfs:label "classifier"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-closely-cropped_details rdfs:label "closely-cropped details"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cnn_features rdfs:label "CNN features"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-cnn_output rdfs:label "CNN output"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coarse_and_fine_levels_of_detail rdfs:label "coarse and fine levels of detail"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coco rdfs:label "COCO"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-code_models_and_pre-computed_image_features rdfs:label "Code, models and pre-computed image features"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-cognition rdfs:label "Cognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-cognitive_psychology rdfs:label "Cognitive Psychology"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cohen rdfs:label "Cohen"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-combined_bottom-up_and_top-down_visual_attention_mechanism rdfs:label "combined bottom-up and top-down visual attention mechanism"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-combined_bottom-up_and_topdown rdfs:label "combined bottom-up and topdown"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-combined_bottom-up_and_topdown_attention_mechanism rdfs:label "combined bottom-up and topdown attention mechanism"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-company rdfs:label "Company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-complexity_of_the_image rdfs:label "complexity of the image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computer_vision rdfs:label "computer vision"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-computer_vision_and_natural_language_processing rdfs:label "computer vision and natural language processing"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-condition rdfs:label "Condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-conditional_distribution rdfs:label "conditional distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-conference_on_empirical_methods_for_natural_language_processing_emnlp rdfs:label "Conference on Empirical Methods for Natural Language Processing (EMNLP)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-connectionist_reinforcement_learning rdfs:label "connectionist reinforcement learning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-consensus-based_image_description_evaluation rdfs:label "Consensus-based image description evaluation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-considered rdfs:label "considered"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constraint rdfs:label "constraint"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-control_of_goal-directed_and_stimulus-driven_attention rdfs:label "Control of goal-directed and stimulus-driven attention"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convex_combination rdfs:label "convex combination"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-convolutional_layers rdfs:label "convolutional layers"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-convolutional_neural_net rdfs:label "convolutional neural net"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-corbetta rdfs:label "Corbetta"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-corpus rdfs:label "Corpus"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-correct_answer rdfs:label "correct answer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-correct_answers_in_the_training_set rdfs:label "correct answers in the training set"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-courville_r rdfs:label "Courville, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cross-domain_knowledge rdfs:label "cross-domain knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cross-entropy_trained_model rdfs:label "cross-entropy trained model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-cross_entropy_loss rdfs:label "cross entropy loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-cui_f rdfs:label "Cui, F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-currency rdfs:label "Currency"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_model rdfs:label "current model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-current_task rdfs:label "current task"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-d-lstmn-i rdfs:label "d-LSTM+n-I"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-damien_teney rdfs:label "Damien Teney"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dark rdfs:label "dark"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_analysis rdfs:label "Data Analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_augmentation rdfs:label "data augmentation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-data_collection_and_evaluation_server rdfs:label "Data collection and evaluation server"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-datasets rdfs:label "datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-dauphin_a rdfs:label "Dauphin, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-deep_neural_network rdfs:label "deep neural network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_neural_network_architectures rdfs:label "deep neural network architectures"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_residual_learning rdfs:label "Deep residual learning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep_residual_networks rdfs:label "deep residual networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_visual-semantic_alignments rdfs:label "Deep visual-semantic alignments"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deeper_image_understanding rdfs:label "deeper image understanding"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-deeper_lstm rdfs:label "Deeper lstm"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deeplab rdfs:label "DeepLab"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-deeplab_v3 rdfs:label "DeepLab v3+"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deng rdfs:label "Deng"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-deng_h rdfs:label "Deng, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-denkowski rdfs:label "Denkowski"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-details rdfs:label "details"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-disease rdfs:label "Disease"@en ;
    askg-onto:entityType "Disease"@en .

askg-data:Entity-divvala_r rdfs:label "Divvala, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dog rdfs:label "dog"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dogs_head_and_feet rdfs:label "dog's head and feet"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain rdfs:label "Domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-donahue_l rdfs:label "Donahue, L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-downstream_tasks rdfs:label "downstream tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-driver rdfs:label "Driver"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-each_image rdfs:label "each image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_question_type rdfs:label "each question type"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eacl_2014_workshop_on_statistical_machine_translation rdfs:label "EACL 2014 Workshop on Statistical Machine Translation"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-early_stopping rdfs:label "early stopping"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-edges rdfs:label "edges"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-egly_j rdfs:label "Egly, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-elqursh rdfs:label "Elqursh"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-encoding_of_the_previously_generated_word rdfs:label "encoding of the previously generated word"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-engineering rdfs:label "Engineering"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-entity rdfs:label "Entity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-environment rdfs:label "environment"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_4 rdfs:label "Equation 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_5 rdfs:label "Equation 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-erhan_c rdfs:label "Erhan, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-examples_of_model_output rdfs:label "examples of model output"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-existing_partial_output_sequence rdfs:label "existing partial output sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-extensive_cleaning_and_filtering_of_the_training_data rdfs:label "extensive cleaning and filtering of the training data"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-extract_a_small_feature_map rdfs:label "extract a small feature map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f-f rdfs:label "F.-F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-failure_case rdfs:label "failure case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-failure_cases rdfs:label "failure cases"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-fan_m rdfs:label "Fan, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-farhadi rdfs:label "Farhadi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-faster rdfs:label "faster"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-feature-integration_theory rdfs:label "feature-integration theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-feature_binding_problem rdfs:label "feature binding problem"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-feature_maps rdfs:label "feature maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feature_vectors rdfs:label "feature vectors"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-feature_weightings rdfs:label "feature weightings"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-features_and_objects rdfs:label "features and objects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-features_v rdfs:label "features V"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fernando_m rdfs:label "Fernando, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-figure_10 rdfs:label "Figure 10"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_3 rdfs:label "Figure 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_4 rdfs:label "Figure 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_5 rdfs:label "Figure 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_6 rdfs:label "Figure 6"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-figure_8 rdfs:label "Figure 8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_9 rdfs:label "Figure 9"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figures_8_and_9 rdfs:label "Figures 8 and 9"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-final_layers rdfs:label "final layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_layers_of_the_cnn rdfs:label "final layers of the CNN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-findings rdfs:label "findings"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-fine-grained_analysis rdfs:label "fine-grained analysis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-fine-grained_visual_processing rdfs:label "fine-grained visual processing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-fine_details_or_large_image_regions rdfs:label "fine details or large image regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_lstm_layer rdfs:label "first LSTM layer"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-fixed rdfs:label "fixed"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-fixed_set_of_candidate_answers rdfs:label "fixed set of candidate answers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fixed_size_spatial_representation rdfs:label "fixed size spatial representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-freely_annotated_strings rdfs:label "freely annotated strings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fu rdfs:label "Fu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fu_r rdfs:label "Fu, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fukui_d rdfs:label "Fukui, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-full_model rdfs:label "full model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-function rdfs:label "Function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-function_fa__x__r_m__y__r_n rdfs:label "function fa : x ∈ R m → y ∈ R n"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_testing rdfs:label "future testing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-game_controllers rdfs:label "game controllers"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-gao_l rdfs:label "Gao, L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gated_convolutional_networks rdfs:label "gated convolutional networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-gated_hyperbolic_tangent_activations rdfs:label "gated hyperbolic tangent activations"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-gated_recurrent_unit rdfs:label "gated recurrent unit"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-gated_tanh_layers rdfs:label "gated tanh layers"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-gelade rdfs:label "Gelade"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gene rdfs:label "Gene"@en ;
    askg-onto:entityType "Gene"@en .

askg-data:Entity-generated_captions rdfs:label "generated captions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-generated_word rdfs:label "generated word"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generic rdfs:label "generic"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-gevers rdfs:label "Gevers"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-global_vectors_for_word_representation rdfs:label "Global Vectors for Word Representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-glove rdfs:label "GloVe"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-goel rdfs:label "Goel"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-google rdfs:label "Google"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-gould rdfs:label "Gould"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-goyal_t rdfs:label "Goyal, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-grangier rdfs:label "Grangier"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-grass rdfs:label "grass"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gray_numbers rdfs:label "Gray numbers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-greedily-decoded_caption rdfs:label "greedily-decoded caption"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-greedy_non-maximum rdfs:label "greedy non-maximum"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-green_players_mouthguard rdfs:label "green player's mouthguard"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-greff rdfs:label "Greff"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-groth_j rdfs:label "Groth, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-groth_m rdfs:label "Groth, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-grounded_question_answering rdfs:label "grounded question answering"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-group_of_people rdfs:label "group of people"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-guadarrama rdfs:label "Guadarrama"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-guadarrama_m rdfs:label "Guadarrama, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gulcehre_f rdfs:label "Gulcehre, F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gupta_p rdfs:label "Gupta, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-guy rdfs:label "guy"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hadamard_product rdfs:label "Hadamard product"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-hao_fang_r rdfs:label "Hao Fang, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hard_attention_mechanism rdfs:label "'hard' attention mechanism"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hata_j rdfs:label "Hata, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hays_p rdfs:label "Hays, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hdu-usyd-uncc rdfs:label "HDU-USYD-UNCC"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-he rdfs:label "He"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-he_j rdfs:label "He, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-he_r rdfs:label "He, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hendricks_s rdfs:label "Hendricks, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hidden_state_q rdfs:label "hidden state q"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hidden_states_of_dimension_512 rdfs:label "hidden states of dimension 512"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-hierarchical_question-image_co-attention rdfs:label "Hierarchical question-image co-attention"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high_quality_outputs rdfs:label "high quality outputs"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-high_scoring_caption rdfs:label "high scoring caption"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-highest_log-probability rdfs:label "highest log-probability"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-highest_ranking_other_entries rdfs:label "highest ranking other entries"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-hochreiter rdfs:label "Hochreiter"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ht rdfs:label "ht"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-huang_a rdfs:label "Huang, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-icml rdfs:label "ICML"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-identity_mappings rdfs:label "Identity mappings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iilows rdfs:label "IIlows"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-image_bounding_box_features rdfs:label "image bounding box features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_caption rdfs:label "image caption"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_caption_generation rdfs:label "image caption generation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_captioning_experiments rdfs:label "image captioning experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-image_captioning_results rdfs:label "image captioning results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-image_classification rdfs:label "Image classification"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-image_content rdfs:label "image content"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_descriptions rdfs:label "image descriptions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_feature rdfs:label "image feature"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_feature_vectors rdfs:label "image feature vectors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_features_v rdfs:label "image features V"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_features_vi rdfs:label "image features vi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_question_answering rdfs:label "image question answering"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_recognition rdfs:label "image recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_segmentation_model rdfs:label "Image segmentation model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-image_segmentation_tasks rdfs:label "Image segmentation tasks"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-image_understanding rdfs:label "image understanding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improved_performance rdfs:label "improved performance"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-individual rdfs:label "individual"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-individual_pixels rdfs:label "individual pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-informal_term_for_man rdfs:label "informal term for man"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-information rdfs:label "information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_experiments rdfs:label "initial experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-input_features rdfs:label "input features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_regions rdfs:label "input regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_vector rdfs:label "input vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_word rdfs:label "input word"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_word_embedding rdfs:label "input word embedding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-institution rdfs:label "Institution"@en ;
    askg-onto:entityType "Institution"@en .

askg-data:Entity-intensive_to_train rdfs:label "intensive to train"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-intermediate_activation_y rdfs:label "intermediate activation y˜"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-intermediate_level rdfs:label "intermediate level"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-interpretability rdfs:label "interpretability"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-intersection-over-union_iou_threshold rdfs:label "intersection-over-union (IoU) threshold"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-iou_threshold rdfs:label "IoU threshold"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iou_threshold_of_03 rdfs:label "IoU threshold of 0.3"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-iou_threshold_of_07 rdfs:label "IoU threshold of 0.7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-iterations rdfs:label "iterations"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-jabri_a rdfs:label "Jabri, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jaderberg_k rdfs:label "Jaderberg, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jd_ai_research rdfs:label "JD AI Research"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-jin_et_al rdfs:label "Jin et al."@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-jin_k rdfs:label "Jin, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-johnson rdfs:label "Johnson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-johnson_k rdfs:label "Johnson, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-joint_embedding rdfs:label "joint embedding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-joint_multimodal_embedding rdfs:label "joint multimodal embedding"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-joulin rdfs:label "Joulin"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-journal_of_experimental_psychology_general rdfs:label "Journal of Experimental Psychology: General"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-journal_of_experimental_psychology_human_perception_and_performance rdfs:label "Journal of Experimental Psychology: Human Perception and Performance"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-jumping rdfs:label "jumping"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kalantidis_l-j rdfs:label "Kalantidis, L.-J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-karpathy_a rdfs:label "Karpathy, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-karpathy_splits rdfs:label "Karpathy splits"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kavukcuoglu rdfs:label "Kavukcuoglu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kazemi rdfs:label "Kazemi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-khosla_m rdfs:label "Khosla, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-khot_d rdfs:label "Khot, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kiros_k rdfs:label "Kiros, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-krause_s rdfs:label "Krause, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kravitz_s rdfs:label "Kravitz, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-krishna_y rdfs:label "Krishna, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-l_r rdfs:label "L_{R}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l_r%09heta rdfs:label "L_{R}(	heta)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_xe rdfs:label "L_{XE}"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-language rdfs:label "Language"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-language_model rdfs:label "language model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-language_modeling rdfs:label "Language modeling"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-language_specific_translation_evaluation rdfs:label "Language Specific Translation Evaluation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-large_number_of_possible_configurations rdfs:label "large number of possible configurations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-large_regions rdfs:label "large regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-large_scale_visual_recognition_challenge rdfs:label "large scale visual recognition challenge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-larger_knowledge rdfs:label "larger knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lavie rdfs:label "Lavie"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-laying rdfs:label "laying"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learned_embedding_of_the_ground-truth_object_class rdfs:label "learned embedding of the ground-truth object class"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learned_parameters rdfs:label "learned parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learned_word_embedding rdfs:label "learned word embedding"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-learning_rate_of_001 rdfs:label "learning rate of 0.01"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-learning_rate_schedule rdfs:label "learning rate schedule"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-legs rdfs:label "legs"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-lei_zhang rdfs:label "Lei Zhang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-li rdfs:label "Li"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-li_d rdfs:label "Li, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-li_z rdfs:label "Li, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-limited_reading_and_counting rdfs:label "limited reading and counting"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-lin rdfs:label "Lin"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lin_d rdfs:label "Lin, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lin_m rdfs:label "Lin, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-list_of_components rdfs:label "list of components"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-liu_d rdfs:label "Liu, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-liu_z rdfs:label "Liu, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-long-term_recurrent_convolutional_networks rdfs:label "Long-term recurrent convolutional networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-long_short-term_memory rdfs:label "Long short-term memory"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-loss rdfs:label "loss"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-lstm-a3 rdfs:label "LSTM-A3"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-lstm_input_vector rdfs:label "LSTM input vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lu_c rdfs:label "Lu, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lu_j rdfs:label "Lu, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lu_m rdfs:label "Lu, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lu_x rdfs:label "Lu, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lucas_c rdfs:label "Lucas, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ma_z rdfs:label "Ma, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mach_learn rdfs:label "Mach. Learn."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-macquarie_university rdfs:label "Macquarie University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-maire_s rdfs:label "Maire, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-male_individual rdfs:label "male individual"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-manning rdfs:label "Manning"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-many_overlapping_regions rdfs:label "many overlapping regions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-marcheret_y rdfs:label "Marcheret, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mark_johnson rdfs:label "Mark Johnson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mask_r-cnn rdfs:label "Mask R-CNN"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-maximum rdfs:label "maximum"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-maximum_number_of_spatial_regions rdfs:label "maximum number of spatial regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maximum_of_14_words rdfs:label "maximum of 14 words"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-may_1992 rdfs:label "May 1992"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-mcb rdfs:label "MCB"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-mean-pooled_convolutional rdfs:label "mean-pooled convolutional"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mean-pooled_image_feature_v_1k_pi_vi rdfs:label "mean-pooled image feature v¯ =1k Pi vi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mean_pooled_convolutional_feature_vi rdfs:label "mean pooled convolutional feature vi"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mean_pooling rdfs:label "mean pooling"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-measure rdfs:label "Measure"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-mei rdfs:label "Mei"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-memory_cells rdfs:label "memory cells"@en ;
    askg-onto:entityType "Cell Type"@en .

askg-data:Entity-meteor rdfs:label "METEOR"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-meteor_universal rdfs:label "Meteor Universal"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-methods rdfs:label "Methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-microsoft rdfs:label "Microsoft"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-microsoft_coco rdfs:label "Microsoft COCO"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-microsoft_coco_captions rdfs:label "Microsoft COCO captions"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-microsoft_research rdfs:label "Microsoft Research"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-middle_image rdfs:label "middle image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-miller rdfs:label "Miller"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-minimize rdfs:label "minimize"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mitchell_d rdfs:label "Mitchell, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-model_vocabulary rdfs:label "model vocabulary"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-molecule rdfs:label "Molecule"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-momentum_parameter rdfs:label "momentum parameter"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mroueh_j rdfs:label "Mroueh, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mscoco_2014_captions_dataset rdfs:label "MSCOCO 2014 captions dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mscoco_2014_training_and_validation_set rdfs:label "MSCOCO 2014 training and validation set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mscoco_captions_dataset rdfs:label "MSCOCO captions dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mscoco_evaluation_server rdfs:label "MSCOCO evaluation server"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-mscoco_images rdfs:label "MSCOCO images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mscoco_test_server_submission rdfs:label "MSCOCO test server submission"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-multi-class_loss_component rdfs:label "multi-class loss component"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multi-headed_attention rdfs:label "multi-headed attention"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multi-label_classifier rdfs:label "multi-label classifier"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-multi-task_loss_function rdfs:label "multi-task loss function"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multimodal_compact_bilinear_pooling rdfs:label "Multimodal compact bilinear pooling"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multiple_glimpses_of_salient_image_regions rdfs:label "multiple glimpses of salient image regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiple_scales_and_aspect_ratios rdfs:label "multiple scales and aspect ratios"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-murphy rdfs:label "Murphy"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-n rdfs:label "N"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-natural_language_processing rdfs:label "natural language processing"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-natural_way rdfs:label "natural way"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nature_reviews rdfs:label "Nature Reviews"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-negative_expected_score rdfs:label "negative expected score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-network rdfs:label "network"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-neural_computation rdfs:label "Neural Computation"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-neural_image_caption_generation rdfs:label "Neural image caption generation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-neuroscience rdfs:label "Neuroscience"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-night_sky rdfs:label "night sky"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-linear_transformations rdfs:label "non-linear transformations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-maximum_suppression rdfs:label "non-maximum suppression"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-nonvisual_or_task-specific_context rdfs:label "nonvisual or task-specific context"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normal_and_parietal_lesion_subjects rdfs:label "normal and parietal lesion subjects"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-normalized_attention_weight rdfs:label "normalized attention weight"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-normalized_attention_weight_%CE%B1it rdfs:label "normalized attention weight αi,t"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-normalized_cnn rdfs:label "Normalized cnn"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-not_finetuned rdfs:label "not finetuned"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-novel_stimuli rdfs:label "novel stimuli"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_regions_per_image rdfs:label "number of regions per image"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-numerous_previous_models rdfs:label "numerous previous models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-nvidia_k40_gpu rdfs:label "Nvidia K40 GPU"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-nvidia_m40_gpus rdfs:label "Nvidia M40 GPUs"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-nvidia_titan_x_gpus rdfs:label "Nvidia Titan X GPUs"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-o rdfs:label "O."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-object_and_attribute_annotations rdfs:label "object and attribute annotations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_and_attribute_data rdfs:label "object and attribute data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-object_classes rdfs:label "object classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_detection_and_segmentation rdfs:label "Object detection and segmentation"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-object_detection_datasets rdfs:label "object detection datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-object_proposals rdfs:label "object proposals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_recognition rdfs:label "object recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-objectness_score rdfs:label "objectness score"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-objects_and_attention rdfs:label "Objects and attention"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-objects_attributes_and_relationships rdfs:label "objects, attributes and relationships"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-one-hot_encoding rdfs:label "one-hot encoding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_number_of_image_regions rdfs:label "optimal number of image regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization_and_decoding rdfs:label "optimization and decoding"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-our_full_model rdfs:label "our full model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-our_results rdfs:label "our results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-our_submission rdfs:label "our submission"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-our_work rdfs:label "our work"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-ours_resnet rdfs:label "Ours: ResNet"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-output_of_layers_of_convolutional_neural_net rdfs:label "output of layers of convolutional neural net"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-output_of_one_or_more_layers_of_a_cnn rdfs:label "output of one or more layers of a CNN"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-output_of_our_bottom-up_attention_model rdfs:label "output of our bottom-up attention model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-output_of_the_attention_lstm rdfs:label "output of the attention LSTM"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-output_q_of_the_gru rdfs:label "output q of the GRU"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-output_responses_y rdfs:label "output responses y"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-output_set rdfs:label "output set"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-output_vector rdfs:label "output vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-output_vocabulary_size_of_3129 rdfs:label "output vocabulary size of 3,129"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-outputs rdfs:label "outputs"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-overlapping_classes rdfs:label "overlapping classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p_%09hetay_1ts rdfs:label "p_{	heta}(y_{1:T}^{s})"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-p_theta rdfs:label "p_{\\theta}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-package_for_automatic_evaluation_of_summaries rdfs:label "package for automatic evaluation of summaries"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pan_y rdfs:label "Pan, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-papineni_s rdfs:label "Papineni, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-parameters_a rdfs:label "parameters a"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-park_d rdfs:label "Park, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pascal_voc rdfs:label "PASCAL VOC"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-pascal_voc_2012 rdfs:label "Pascal VOC 2012"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-pedersoli_t rdfs:label "Pedersoli, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pennington_r rdfs:label "Pennington, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-perceptual_grouping rdfs:label "Perceptual grouping"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-performance rdfs:label "performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-perona_d rdfs:label "Perona, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-peter_anderson rdfs:label "Peter Anderson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pg-bcmr rdfs:label "PG-BCMR"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-playing rdfs:label "playing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policy rdfs:label "policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policy_gradient_optimization_of_spider rdfs:label "policy gradient optimization of spider"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-poor_detection_performance rdfs:label "poor detection performance"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-poor_quality_caption rdfs:label "poor quality caption"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-posterior_parietal_cortex rdfs:label "posterior parietal cortex"@en ;
    askg-onto:entityType "Cell Type"@en .

askg-data:Entity-prefrontal_cortex rdfs:label "prefrontal cortex"@en ;
    askg-onto:entityType "Cell Type"@en .

askg-data:Entity-preprocessing rdfs:label "preprocessing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pretrained_bottom-up_attention_features rdfs:label "pretrained bottom-up attention features"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-pretrained_cnn_features rdfs:label "pretrained CNN features"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-pretrained_glove_vectors rdfs:label "pretrained GloVe vectors"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-previous_output_of_the_language_lstm rdfs:label "previous output of the language LSTM"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-previous_work rdfs:label "previous work"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-previous_works rdfs:label "previous works"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-previously_published_baseline_results rdfs:label "previously published baseline results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-previously_published_results rdfs:label "previously published results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-previously_published_work rdfs:label "previously published work"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-probability rdfs:label "probability"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-product_of_conditional_distributions rdfs:label "product of conditional distributions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-project_website rdfs:label "project website"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-propagation rdfs:label "propagation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposed_model rdfs:label "proposed model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-protein rdfs:label "Protein"@en ;
    askg-onto:entityType "Protein"@en .

askg-data:Entity-protein_structure rdfs:label "Protein Structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-py_1t rdfs:label "p(y_{1:T})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-py_ty_1t-1 rdfs:label "p(y_{t}|y_{1:t-1})"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-q_and_v rdfs:label "q and v"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-qiu rdfs:label "Qiu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-question rdfs:label "question"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-question-guided_spatial_attention rdfs:label "question-guided spatial attention"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-question_and_the_image rdfs:label "question and the image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-question_text rdfs:label "question text"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-questions_and_answers rdfs:label "questions and answers"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-r%09exthaty_1t rdfs:label "r(	ext{hat}(y_{1:T}))"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-rafal rdfs:label "Rafal"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ramanan_p rdfs:label "Ramanan, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-random_initialization rdfs:label "random initialization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-recent_models rdfs:label "recent models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-recent_progress rdfs:label "recent progress"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-redmon_s rdfs:label "Redmon, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-reed_c-_y rdfs:label "Reed, C.- Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-region rdfs:label "region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-region-based_attention rdfs:label "region-based attention"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-region_cropping rdfs:label "region cropping"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-region_i rdfs:label "region i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-region_of_interest_roi_pooling rdfs:label "region of interest (RoI) pooling"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-region_proposal_network rdfs:label "Region Proposal Network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-region_proposal_networks rdfs:label "region proposal networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-region_proposals rdfs:label "region proposals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regions_of_the_image_that_are_salient rdfs:label "regions of the image that are salient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regression_of_scores rdfs:label "regression of scores"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reinforce_algorithms rdfs:label "REINFORCE algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-related_objects rdfs:label "related objects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relations_between_objects rdfs:label "relations between objects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ren_k rdfs:label "Ren, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rennie_e rdfs:label "Rennie, E."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-representation_of_a_partially-completed_caption rdfs:label "representation of a partially-completed caption"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-representation_of_the_question rdfs:label "representation of the question"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-research_concepts rdfs:label "Research concepts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_field rdfs:label "Research Field"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_work rdfs:label "research work"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-resize rdfs:label "resize"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-resnet-200 rdfs:label "ResNet-200"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet101_encoding rdfs:label "ResNet101 encoding"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet_11 rdfs:label "ResNet (1×1)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet_1414 rdfs:label "ResNet (14×14)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet_77 rdfs:label "ResNet (7×7)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet__r-cnn_model rdfs:label "ResNet / R-CNN model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet_baselines rdfs:label "ResNet baselines"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet_cnn rdfs:label "ResNet CNN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-result rdfs:label "Result"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-resulting_1 rdfs:label "resulting 1"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-results rdfs:label "results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-review_net rdfs:label "Review Net"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-review_networks rdfs:label "Review networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rnn_encoder-decoder rdfs:label "RNN encoder-decoder"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-rohrbach rdfs:label "Rohrbach"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rohrbach_s rdfs:label "Rohrbach, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rohrbach_t rdfs:label "Rohrbach, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ross rdfs:label "Ross"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rouge rdfs:label "Rouge"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-rouge-l rdfs:label "ROUGE-L"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-roukos_t rdfs:label "Roukos, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rpn rdfs:label "RPN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-russakovsky_j rdfs:label "Russakovsky, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ry_1t rdfs:label "r(y_{1:T})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ry_1ts rdfs:label "r(y_{1:T}^{s})"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-salakhutdinov rdfs:label "Salakhutdinov"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-salakhutdinov_r rdfs:label "Salakhutdinov, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-salient rdfs:label "salient"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-salient_region_of_the_image rdfs:label "salient region of the image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-salient_stimuli rdfs:label "salient stimuli"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-satheesh_s rdfs:label "Satheesh, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-scene_factorization rdfs:label "scene factorization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-scene_graphs rdfs:label "scene graphs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-schmid rdfs:label "Schmid"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-scholl rdfs:label "Scholl"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-schwenk rdfs:label "Schwenk"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-science rdfs:label "Science"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-scientific_method rdfs:label "Scientific Method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scores rdfs:label "scores"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-scst_approach rdfs:label "SCST approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-scst_results rdfs:label "SCST results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-scstatt2in rdfs:label "SCST:Att2in"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-second_lstm_layer rdfs:label "second LSTM layer"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-second_stage rdfs:label "second stage"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_31 rdfs:label "Section 3.1"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-semantic_propositional_image_caption_evaluation rdfs:label "Semantic propositional image caption evaluation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_of_words rdfs:label "sequence of words"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_k_image_features rdfs:label "set of k image features"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-sha rdfs:label "Sha"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-shamma_m rdfs:label "Shamma, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-sheeps_legs rdfs:label "sheep's legs"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-show_ask_attend_and_answer rdfs:label "Show, ask, attend, and answer"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-shulman rdfs:label "Shulman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-sigmoid_activation_function rdfs:label "sigmoid activation function"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-significant_gains rdfs:label "significant gains"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-significant_improvement rdfs:label "significant improvement"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-significant_improvements rdfs:label "significant improvements"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-simonyan_a rdfs:label "Simonyan, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-simple_one-pass_attention_mechanisms rdfs:label "simple one-pass attention mechanisms"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-single-model rdfs:label "Single-model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-single_model rdfs:label "single model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-single_shot_multibox_detector rdfs:label "Single shot multibox detector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single_time_step rdfs:label "single time step"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single_word rdfs:label "single word"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sky rdfs:label "sky"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-small_network rdfs:label "small network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smeulders rdfs:label "Smeulders"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-smola rdfs:label "Smola"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-soft_top-down_attention_mechanism rdfs:label "soft top-down attention mechanism"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-softmax_distribution rdfs:label "softmax distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-softmax_distribution_over_each_attribute_class_plus_a_no_attributes_class rdfs:label "softmax distribution over each attribute class plus a 'no attributes' class"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-softmaxw_p%09extbfh_t2%09extbfb_p rdfs:label "softmax(W_{p}	extbf{h}_{t}^{2}+	extbf{b}_{p})"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-space_of_captions rdfs:label "space of captions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spatial_location rdfs:label "spatial location"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spatial_output_layer_of_a_cnn rdfs:label "spatial output layer of a CNN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-spatial_regions rdfs:label "spatial regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spatial_relationships rdfs:label "spatial relationships"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spatially_co-located rdfs:label "spatially co-located"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spice_f-scores rdfs:label "SPICE F-scores"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-splits rdfs:label "splits"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-srivastava_k rdfs:label "Srivastava, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ssd rdfs:label "SSD"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-stacked_attention rdfs:label "stacked attention"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-stacked_attention_networks rdfs:label "Stacked attention networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-standard_cross-entropy_loss rdfs:label "standard cross-entropy loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-standard_implementation rdfs:label "standard implementation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-of-the-art_results rdfs:label "state-of-the-art results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-statistical_gradient-following_algorithms rdfs:label "statistical gradient-following algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-statistical_machine_translation rdfs:label "statistical machine translation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-stephen_gould rdfs:label "Stephen Gould"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-stovetop rdfs:label "stovetop"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-study_3 rdfs:label "Study 3"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-su_j rdfs:label "Su, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-summers-stay_d rdfs:label "Summers-Stay, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-suppression rdfs:label "suppression"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-system rdfs:label "System"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-szegedy_s rdfs:label "Szegedy, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-table_5 rdfs:label "Table 5"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-tanhw%09extbfx%09extbfb rdfs:label "tanh(W	extbf{x}+	extbf{b})"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-task rdfs:label "Task"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-task-specific_context rdfs:label "task-specific context"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tasks_involving_visual_and_linguistic_understanding rdfs:label "tasks involving visual and linguistic understanding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-teney rdfs:label "Teney"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-teney_p rdfs:label "Teney, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-test_server_submissions rdfs:label "test server submissions"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-test_split rdfs:label "test split"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-testing_images rdfs:label "testing images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-text_pre-processing rdfs:label "text pre-processing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-the_best_of_four_random_initializations rdfs:label "the best of four random initializations"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_dimensions_of_the_vector_representations rdfs:label "the dimensions of the vector representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_question_and_the_image rdfs:label "the question and the image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_resulting_attention_weights rdfs:label "the resulting attention weights"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-the_score_function rdfs:label "the score function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_set rdfs:label "the set"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_state_of_the_art rdfs:label "the state of the art"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_trade-off_between_coarse_and_fine_levels_of_detail rdfs:label "the trade-off between coarse and fine levels of detail"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_word_together rdfs:label "the word 'together'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-they rdfs:label "they"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-three_bi-linear_pairwise_interactions rdfs:label "three bi-linear pairwise interactions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tips_and_tricks_for_visual_question_answering rdfs:label "Tips and tricks for visual question answering"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-tissue_engineering rdfs:label "Tissue Engineering"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-tokenization rdfs:label "tokenization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-top-down rdfs:label "'top-down'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-top-down_approaches rdfs:label "top-down approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-top-down_attention_component rdfs:label "top-down attention component"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-top-down_attention_mechanism rdfs:label "top-down attention mechanism"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-top-down_control rdfs:label "Top-down control"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-top-down_signals rdfs:label "top-down signals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-top-down_variety rdfs:label "top-down variety"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-top-down_visual_attention_mechanisms rdfs:label "Top-down visual attention mechanisms"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-top-down_visual_attention_model rdfs:label "top-down visual attention model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-top_36_features rdfs:label "top 36 features"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-trade-off_between_coarse_and_fine_levels_of_detail rdfs:label "trade-off between coarse and fine levels of detail"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-traditional_relu_or_tanh_layers rdfs:label "traditional ReLU or tanh layers"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-training_and_validation_sets rdfs:label "training and validation sets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_data rdfs:label "training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_images rdfs:label "training images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_iterations rdfs:label "training iterations"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_output rdfs:label "training output"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_process rdfs:label "training process"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_regimes rdfs:label "training regimes"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_set rdfs:label "training set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-tree rdfs:label "tree"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trees rdfs:label "trees"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_lstm_layers rdfs:label "two LSTM layers"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-two_men rdfs:label "Two men"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-two_papers rdfs:label "two papers"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-two_tasks rdfs:label "two tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uijlings_k rdfs:label "Uijlings, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-unexpected_stimuli rdfs:label "unexpected stimuli"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unified_real-time_object_detection rdfs:label "Unified, real-time object detection"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-uniform_grid_of_equally_sized_and_shaped_neural_receptive_fields rdfs:label "uniform grid of equally sized and shaped neural receptive fields"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-university_of_adelaide rdfs:label "University of Adelaide"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-university_of_california_berkeley rdfs:label "University of California, Berkeley"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-university_of_california_san_diego rdfs:label "University of California, San Diego"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-university_of_california_san_francisco rdfs:label "University of California, San Francisco"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unknown_concept rdfs:label "unknown concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unnormalized_attention_weight_ai rdfs:label "unnormalized attention weight ai"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-unpublished_test_server_submissions rdfs:label "unpublished test server submissions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-up-down_attention rdfs:label "Up-Down Attention"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-up-down_captioning_model rdfs:label "Up-Down captioning model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-up-down_vqa_model rdfs:label "Up-Down VQA model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-upmc-lip6 rdfs:label "UPMC-LIP6"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-urban_areas rdfs:label "urban areas"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validation rdfs:label "validation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validation_images rdfs:label "validation images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-van_de_sande_t rdfs:label "Van De Sande, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-van_der_maaten rdfs:label "van der Maaten"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-van_merrienboer_c rdfs:label "van Merrienboer, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-variable rdfs:label "Variable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vector_g rdfs:label "vector g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vedantam_c rdfs:label "Vedantam, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-vedantam_s rdfs:label "Vedantam, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-vegetation rdfs:label "vegetation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-venugopalan_k rdfs:label "Venugopalan, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-verbeek rdfs:label "Verbeek"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-video_game rdfs:label "video game"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-visual7w rdfs:label "Visual7w"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-visual_genome_dataset rdfs:label "Visual Genome dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-visual_genome_images rdfs:label "Visual Genome images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-visual_genome_question_and_answer_pairs rdfs:label "Visual Genome question and answer pairs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-visual_grounding rdfs:label "Visual grounding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_question_answering_baselines rdfs:label "visual question answering baselines"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_question_answering_examples rdfs:label "visual question answering examples"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_representations rdfs:label "visual representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_search rdfs:label "visual search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-visual_sentinel rdfs:label "visual sentinel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visualqa rdfs:label "VisualQA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vocabulary rdfs:label "vocabulary"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vqa_20_test-standard_evaluation_server rdfs:label "VQA 2.0 test-standard evaluation server"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-vqa_approach rdfs:label "VQA approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-vqa_attention rdfs:label "VQA attention"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vqa_experiments rdfs:label "VQA experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-vqa_lstm_cnn rdfs:label "VQA_LSTM_CNN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-vqa_metric rdfs:label "VQA metric"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-vqa_models rdfs:label "VQA models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-vqa_test_server rdfs:label "VQA test server"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-vqa_v20 rdfs:label "VQA v2.0"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-vqa_v20_dataset rdfs:label "VQA v2.0 dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-vqa_v20_test-standard_server rdfs:label "VQA v2.0 test-standard server"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-vqa_v20_training_data rdfs:label "VQA v2.0 training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-w_w0_b_b0 rdfs:label "{W, W0*, b, b*0}"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-ward rdfs:label "Ward"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-weighted_average_of_image_features rdfs:label "weighted average of image features"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-williams rdfs:label "Williams"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-word_embedding rdfs:label "word embedding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-word_embedding_matrix rdfs:label "word embedding matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-word_standing rdfs:label "word 'standing'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-worse_performance rdfs:label "worse performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-wt rdfs:label "wT"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-wu_r rdfs:label "Wu, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-x rdfs:label "X"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_t1 rdfs:label "x_t^1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xiaodong_he rdfs:label "Xiaodong He"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xiong_d rdfs:label "Xiong, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xt rdfs:label "xt"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xu rdfs:label "Xu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xu_j rdfs:label "Xu, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-y_1t rdfs:label "y_{1:T}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-y_1ts rdfs:label "y_{1:T}^{s}"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-yang_a rdfs:label "Yang, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yang_d rdfs:label "Yang, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yang_x rdfs:label "Yang, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yang_y rdfs:label "Yang, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yao_y rdfs:label "Yao, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ye_s rdfs:label "Ye, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yellow_elements rdfs:label "Yellow elements"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-you_only_look_once rdfs:label "You only look once"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-yuan_y rdfs:label "Yuan, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zeiler rdfs:label "Zeiler"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zemel rdfs:label "Zemel"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zero rdfs:label "zero"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-zero-shot_visual_question_answering rdfs:label "Zero-shot visual question answering"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-zhang rdfs:label "Zhang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhu rdfs:label "Zhu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhu_n rdfs:label "Zhu, N."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zisserman rdfs:label "Zisserman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Paper-11712fbcb9a80fb4-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "Bottom-Up And Top-Down Attention For Image Captioning And Visual Question Answering"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-1-Paragraph-11 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Peter Anderson1∗ Xiaodong He2 Chris Buehler3 Damien Teney4 Mark Johnson5 Stephen Gould1 Lei Zhang3 1Australian National University 2JD AI Research 3Microsoft Research 4University of Adelaide 5Macquarie University 1firstname.lastname@anu.edu.au, 2xiaodong.he@jd.com, 3{chris.buehler,leizhang}@microsoft.com 4damien.teney@adelaide.edu.au, 5mark.johnson@mq.edu.au"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-1-Paragraph-11-Sentence-111 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Peter Anderson1∗ Xiaodong He2 Chris Buehler3 Damien Teney4 Mark Johnson5 Stephen Gould1 Lei Zhang3 1Australian National University 2JD AI Research 3Microsoft Research 4University of Adelaide 5Macquarie University 1firstname.lastname@anu.edu.au, 2xiaodong.he@jd.com, 3{chris.buehler,leizhang}@microsoft.com 4damien.teney@adelaide.edu.au, 5mark.johnson@mq.edu.au"@en ;
    askg-onto:inSentence "Peter Anderson1∗ Xiaodong He2 Chris Buehler3 Damien Teney4 Mark Johnson5 Stephen Gould1 Lei Zhang3 1Australian National University 2JD AI Research 3Microsoft Research 4University of Adelaide 5Macquarie University 1firstname.lastname@anu.edu.au, 2xiaodong.he@jd.com, 3{chris.buehler,leizhang}@microsoft.com 4damien.teney@adelaide.edu.au, 5mark.johnson@mq.edu.au"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australian_national_university,
        askg-data:Entity-chris_buehler,
        askg-data:Entity-damien_teney,
        askg-data:Entity-jd_ai_research,
        askg-data:Entity-lei_zhang,
        askg-data:Entity-macquarie_university,
        askg-data:Entity-mark_johnson,
        askg-data:Entity-microsoft_research,
        askg-data:Entity-peter_anderson,
        askg-data:Entity-stephen_gould,
        askg-data:Entity-university_of_adelaide,
        askg-data:Entity-xiaodong_he .

askg-data:Paper-11712fbcb9a80fb4-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "3.2.3 Objective"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-101,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1010,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1011,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-102,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-103,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-104,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-105,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-106,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-107,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109 ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-101 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "$$\\begin{array}{c}{{(3)}}\\\\ {{(4)}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-101-Sentence-1011 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-101-Sentence-1011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{c}{{(3)}}\\\\ {{(4)}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{c}{{(3)}}\\\\ {{(4)}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3,
        askg-data:Entity-4 .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1010 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Question $\\frac{14}{}$. $${\\mathrm{Image~features}}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1010-Sentence-10101,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1010-Sentence-10102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1010-Sentence-10101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Question $\\frac{14}{}$."@en ;
    askg-onto:inSentence "Question $\\frac{14}{}$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1010-Sentence-10102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "$${\\mathrm{Image~features}}$$"@en ;
    askg-onto:inSentence "$${\\mathrm{Image~features}}$$"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-image_features .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1011 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "![4_image_0.png](4_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1011-Sentence-10111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1011-Sentence-10111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![4_image_0.png](4_image_0.png)"@en ;
    askg-onto:inSentence "![4_image_0.png](4_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning,
        askg-data:Entity-imagenet,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-pytorch,
        askg-data:Entity-software,
        askg-data:Entity-tensorflow,
        askg-data:Entity-university_of_california .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "Figure 4. Overview of the proposed VQA model. A deep neural network implements a joint embedding of the question and image features {v1*, ...,* vk} . These features can be defined as the spatial output of a CNN, or following our approach, generated using bottom-up attention. Output is generated by a multi-label classifier operating over a fixed set of candidate answers. Gray numbers indicate the dimensions of the vector representations between layers. Yellow elements use learned parameters."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10121,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10122,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10123,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10124,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10125,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10126,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10127 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 4."@en ;
    askg-onto:inSentence "Figure 4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_4 .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Overview of the proposed VQA model."@en ;
    askg-onto:inSentence "Overview of the proposed VQA model."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A deep neural network implements a joint embedding of the question and image features {v1*, ...,* vk} ."@en ;
    askg-onto:inSentence "A deep neural network implements a joint embedding of the question and image features {v1*, ...,* vk} ."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_neural_network,
        askg-data:Entity-image_features,
        askg-data:Entity-joint_embedding,
        askg-data:Entity-question .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These features can be defined as the spatial output of a CNN, or following our approach, generated using bottom-up attention."@en ;
    askg-onto:inSentence "These features can be defined as the spatial output of a CNN, or following our approach, generated using bottom-up attention."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-cnn,
        askg-data:Entity-features,
        askg-data:Entity-spatial_output .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Output is generated by a multi-label classifier operating over a fixed set of candidate answers."@en ;
    askg-onto:inSentence "Output is generated by a multi-label classifier operating over a fixed set of candidate answers."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fixed_set_of_candidate_answers,
        askg-data:Entity-multi-label_classifier .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10126 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Gray numbers indicate the dimensions of the vector representations between layers."@en ;
    askg-onto:inSentence "Gray numbers indicate the dimensions of the vector representations between layers."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gray_numbers,
        askg-data:Entity-the_dimensions_of_the_vector_representations .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1012-Sentence-10127 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Yellow elements use learned parameters."@en ;
    askg-onto:inSentence "Yellow elements use learned parameters."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learned_parameters,
        askg-data:Entity-yellow_elements .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "highest log-probability of the set. In contrast, we observe that very few unrestricted caption samples score higher than the greedily-decoded caption. Using this approach, we complete CIDEr optimization in a single epoch."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013-Sentence-10131,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013-Sentence-10132,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013-Sentence-10133 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013-Sentence-10131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "highest log-probability of the set."@en ;
    askg-onto:inSentence "highest log-probability of the set."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-highest_log-probability,
        askg-data:Entity-the_set .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013-Sentence-10132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In contrast, we observe that very few unrestricted caption samples score higher than the greedily-decoded caption."@en ;
    askg-onto:inSentence "In contrast, we observe that very few unrestricted caption samples score higher than the greedily-decoded caption."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-caption_samples,
        askg-data:Entity-greedily-decoded_caption .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-1013-Sentence-10133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Using this approach, we complete CIDEr optimization in a single epoch."@en ;
    askg-onto:inSentence "Using this approach, we complete CIDEr optimization in a single epoch."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_single_epoch,
        askg-data:Entity-cider_optimization .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-102 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Given a target ground truth sequence y ∗ 1:Tand a captioning model with parameters θ, we minimize the following cross entropy loss:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-102-Sentence-1021 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-102-Sentence-1021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Given a target ground truth sequence y ∗ 1:Tand a captioning model with parameters θ, we minimize the following cross entropy loss:"@en ;
    askg-onto:inSentence "Given a target ground truth sequence y ∗ 1:Tand a captioning model with parameters θ, we minimize the following cross entropy loss:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_model,
        askg-data:Entity-cross_entropy_loss .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-103 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$L_{XE}(\\theta)=-\\sum_{t=1}^{T}\\log(p_{\\theta}(y_{t}^{*}\\mid y_{1:t-1}^{*}))\\tag{9}$$ $$({\\boldsymbol{S}})$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-103-Sentence-1031 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-103-Sentence-1031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{XE}(\\theta)=-\\sum_{t=1}^{T}\\log(p_{\\theta}(y_{t}^{*}\\mid y_{1:t-1}^{*}))\\tag{9}$$ $$({\\boldsymbol{S}})$$"@en ;
    askg-onto:inSentence "$$L_{XE}(\\theta)=-\\sum_{t=1}^{T}\\log(p_{\\theta}(y_{t}^{*}\\mid y_{1:t-1}^{*}))\\tag{9}$$ $$({\\boldsymbol{S}})$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l_xe,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-104 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "For fair comparison with recent work [34] we also report results optimized for CIDEr [43]. Initializing from the cross-entropy trained model, we seek to minimize the negative expected score:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-104-Sentence-1041,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-104-Sentence-1042 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-104-Sentence-1041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For fair comparison with recent work [34] we also report results optimized for CIDEr [43]."@en ;
    askg-onto:inSentence "For fair comparison with recent work [34] we also report results optimized for CIDEr [43]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cider,
        askg-data:Entity-results .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-104-Sentence-1042 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Initializing from the cross-entropy trained model, we seek to minimize the negative expected score:"@en ;
    askg-onto:inSentence "Initializing from the cross-entropy trained model, we seek to minimize the negative expected score:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cross-entropy_trained_model,
        askg-data:Entity-minimize,
        askg-data:Entity-model,
        askg-data:Entity-negative_expected_score .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-105 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$L_{R}(\\theta)=-\\mathbb{E}_{y_{1:T}\\sim p_{\\theta}}\\left[r(y_{1:T})\\right]\\tag{10}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-105-Sentence-1051 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-105-Sentence-1051 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$L_{R}(\\theta)=-\\mathbb{E}_{y_{1:T}\\sim p_{\\theta}}\\left[r(y_{1:T})\\right]\\tag{10}$$"@en ;
    askg-onto:inSentence "$$L_{R}(\\theta)=-\\mathbb{E}_{y_{1:T}\\sim p_{\\theta}}\\left[r(y_{1:T})\\right]\\tag{10}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function,
        askg-data:Entity-l_r,
        askg-data:Entity-model,
        askg-data:Entity-p_theta,
        askg-data:Entity-ry_1t,
        askg-data:Entity-variable,
        askg-data:Entity-y_1t .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-106 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "where r is the score function (e.g., CIDEr). Following the approach described as Self-Critical Sequence Training [34] (SCST), the gradient of this loss can be approximated:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-106-Sentence-1061,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-106-Sentence-1062 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-106-Sentence-1061 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where r is the score function (e.g., CIDEr)."@en ;
    askg-onto:inSentence "where r is the score function (e.g., CIDEr)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_score_function,
        askg-data:Entity-cider,
        askg-data:Entity-r,
        askg-data:Entity-the_score_function .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-106-Sentence-1062 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Following the approach described as Self-Critical Sequence Training [34] (SCST), the gradient of this loss can be approximated:"@en ;
    askg-onto:inSentence "Following the approach described as Self-Critical Sequence Training [34] (SCST), the gradient of this loss can be approximated:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradient,
        askg-data:Entity-loss,
        askg-data:Entity-scst,
        askg-data:Entity-self-critical_sequence_training .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-107 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$\\nabla_{\\theta}L_{R}(\\theta)\\approx-(r(y_{1:T}^{s})-r(\\hat{y}_{1:T}))\\nabla_{\\theta}\\log p_{\\theta}(y_{1:T}^{s})\\tag{11}$$ $$(6)$$ $$(7)^{\\frac{1}{2}}$$ $$({\\boldsymbol{\\delta}})$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-107-Sentence-1071 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-107-Sentence-1071 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\nabla_{\\theta}L_{R}(\\theta)\\approx-(r(y_{1:T}^{s})-r(\\hat{y}_{1:T}))\\nabla_{\\theta}\\log p_{\\theta}(y_{1:T}^{s})\\tag{11}$$ $$(6)$$ $$(7)^{\\frac{1}{2}}$$ $$({\\boldsymbol{\\delta}})$$"@en ;
    askg-onto:inSentence "$$\\nabla_{\\theta}L_{R}(\\theta)\\approx-(r(y_{1:T}^{s})-r(\\hat{y}_{1:T}))\\nabla_{\\theta}\\log p_{\\theta}(y_{1:T}^{s})\\tag{11}$$ $$(6)$$ $$(7)^{\\frac{1}{2}}$$ $$({\\boldsymbol{\\delta}})$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Aabla_%09hetal_r%09heta,
        askg-data:Entity-l_r%09heta,
        askg-data:Entity-p_%09hetay_1ts,
        askg-data:Entity-r%09exthaty_1t,
        askg-data:Entity-ry_1ts,
        askg-data:Entity-y_1ts .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "where y s 1:Tis a sampled caption and r(ˆy1:T ) defines the baseline score obtained by greedily decoding the current model. SCST (like other REINFORCE [44] algorithms) explores the space of captions by sampling from the policy during training. This gradient tends to increase the probability of sampled captions that score higher than the score from the current model."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108-Sentence-1081,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108-Sentence-1082,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108-Sentence-1083 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108-Sentence-1081 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where y s 1:Tis a sampled caption and r(ˆy1:T ) defines the baseline score obtained by greedily decoding the current model."@en ;
    askg-onto:inSentence "where y s 1:Tis a sampled caption and r(ˆy1:T ) defines the baseline score obtained by greedily decoding the current model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baseline_score,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108-Sentence-1082 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "SCST (like other REINFORCE [44] algorithms) explores the space of captions by sampling from the policy during training."@en ;
    askg-onto:inSentence "SCST (like other REINFORCE [44] algorithms) explores the space of captions by sampling from the policy during training."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-policy,
        askg-data:Entity-reinforce_algorithms,
        askg-data:Entity-scst,
        askg-data:Entity-space_of_captions,
        askg-data:Entity-training .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-108-Sentence-1083 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This gradient tends to increase the probability of sampled captions that score higher than the score from the current model."@en ;
    askg-onto:inSentence "This gradient tends to increase the probability of sampled captions that score higher than the score from the current model."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captions,
        askg-data:Entity-current_model,
        askg-data:Entity-gradient,
        askg-data:Entity-probability .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "In our experiments, we follow SCST but we speed up the training process by restricting the sampling distribution. Using beam search decoding, we sample only from those captions in the decoded beam. Empirically, we have observed when decoding using beam search that the resulting beam typically contains at least one very high scoring caption - although frequently this caption does not have the"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109-Sentence-1091,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109-Sentence-1092,
        askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109-Sentence-1093 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109-Sentence-1091 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In our experiments, we follow SCST but we speed up the training process by restricting the sampling distribution."@en ;
    askg-onto:inSentence "In our experiments, we follow SCST but we speed up the training process by restricting the sampling distribution."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scst,
        askg-data:Entity-training_process .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109-Sentence-1092 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Using beam search decoding, we sample only from those captions in the decoded beam."@en ;
    askg-onto:inSentence "Using beam search decoding, we sample only from those captions in the decoded beam."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-beam_search_decoding,
        askg-data:Entity-captions .

askg-data:Paper-11712fbcb9a80fb4-Section-10-Paragraph-109-Sentence-1093 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Empirically, we have observed when decoding using beam search that the resulting beam typically contains at least one very high scoring caption - although frequently this caption does not have the"@en ;
    askg-onto:inSentence "Empirically, we have observed when decoding using beam search that the resulting beam typically contains at least one very high scoring caption - although frequently this caption does not have the"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-beam_search,
        askg-data:Entity-high_scoring_caption .

askg-data:Paper-11712fbcb9a80fb4-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "3.3. Vqa Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1110,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-113,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-114,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-115,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-116,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-117,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-119 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Given a set of spatial image features V , our proposed VQA model also uses a 'soft' top-down attention mechanism to weight each feature, using the question representation as context. As illustrated in Figure 4, the proposed model implements the well-known joint multimodal embedding of the question and the image, followed by a prediction of regression of scores over a set of candidate answers. This approach has been the basis of numerous previous models [16, 20, 39]. However, as with our captioning model, implementation decisions are important to ensure that this relatively simple model delivers high performance."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1112,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1113,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1114 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Given a set of spatial image features V , our proposed VQA model also uses a 'soft' top-down attention mechanism to weight each feature, using the question representation as context."@en ;
    askg-onto:inSentence "Given a set of spatial image features V , our proposed VQA model also uses a 'soft' top-down attention mechanism to weight each feature, using the question representation as context."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-top-down_attention_mechanism,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As illustrated in Figure 4, the proposed model implements the well-known joint multimodal embedding of the question and the image, followed by a prediction of regression of scores over a set of candidate answers."@en ;
    askg-onto:inSentence "As illustrated in Figure 4, the proposed model implements the well-known joint multimodal embedding of the question and the image, followed by a prediction of regression of scores over a set of candidate answers."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-joint_multimodal_embedding,
        askg-data:Entity-model,
        askg-data:Entity-proposed_model,
        askg-data:Entity-question_and_the_image,
        askg-data:Entity-regression_of_scores,
        askg-data:Entity-set_of_candidate_answers .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This approach has been the basis of numerous previous models [16, 20, 39]."@en ;
    askg-onto:inSentence "This approach has been the basis of numerous previous models [16, 20, 39]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-numerous_previous_models,
        askg-data:Entity-this_approach .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-111-Sentence-1114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, as with our captioning model, implementation decisions are important to ensure that this relatively simple model delivers high performance."@en ;
    askg-onto:inSentence "However, as with our captioning model, implementation decisions are important to ensure that this relatively simple model delivers high performance."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_model,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1110 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Where h is a joint representation of the question and the image, and Wo ∈ R |Σ|×M are learned weights."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1110-Sentence-11101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1110-Sentence-11101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Where h is a joint representation of the question and the image, and Wo ∈ R |Σ|×M are learned weights."@en ;
    askg-onto:inSentence "Where h is a joint representation of the question and the image, and Wo ∈ R |Σ|×M are learned weights."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h,
        askg-data:Entity-the_question_and_the_image .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Due to space constraints, some important aspects of our VQA approach are not detailed here. For full specifics of the VQA model including a detailed exploration of architectures and hyperparameters, refer to Teney et al. [38]."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111-Sentence-11111,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111-Sentence-11112,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111-Sentence-11113 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111-Sentence-11111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Due to space constraints, some important aspects of our VQA approach are not detailed here."@en ;
    askg-onto:inSentence "Due to space constraints, some important aspects of our VQA approach are not detailed here."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-vqa_approach .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111-Sentence-11112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For full specifics of the VQA model including a detailed exploration of architectures and hyperparameters, refer to Teney et al."@en ;
    askg-onto:inSentence "For full specifics of the VQA model including a detailed exploration of architectures and hyperparameters, refer to Teney et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-teney_et_al,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-1111-Sentence-11113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "[38]."@en ;
    askg-onto:inSentence "[38]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-organization,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The learned non-linear transformations within the network are implemented with gated hyperbolic tangent activations [7]. These are a special case of highway networks [37] that have shown a strong empirical advantage over traditional ReLU or tanh layers. Each of our 'gated tanh' layers implements a function fa : x ∈ R m → y ∈ R n with parameters a = {W, W0*, b, b*0} defined as follows:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112-Sentence-1121,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112-Sentence-1122,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112-Sentence-1123 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112-Sentence-1121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The learned non-linear transformations within the network are implemented with gated hyperbolic tangent activations [7]."@en ;
    askg-onto:inSentence "The learned non-linear transformations within the network are implemented with gated hyperbolic tangent activations [7]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gated_hyperbolic_tangent_activations,
        askg-data:Entity-non-linear_transformations .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112-Sentence-1122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These are a special case of highway networks [37] that have shown a strong empirical advantage over traditional ReLU or tanh layers."@en ;
    askg-onto:inSentence "These are a special case of highway networks [37] that have shown a strong empirical advantage over traditional ReLU or tanh layers."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-highway_networks,
        askg-data:Entity-traditional_relu_or_tanh_layers .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-112-Sentence-1123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Each of our 'gated tanh' layers implements a function fa : x ∈ R m → y ∈ R n with parameters a = {W, W0*, b, b*0} defined as follows:"@en ;
    askg-onto:inSentence "Each of our 'gated tanh' layers implements a function fa : x ∈ R m → y ∈ R n with parameters a = {W, W0*, b, b*0} defined as follows:"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function_fa__x__r_m__y__r_n,
        askg-data:Entity-gated_tanh_layers,
        askg-data:Entity-parameters_a,
        askg-data:Entity-w_w0_b_b0 .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-113 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$\\begin{array}{l}{{\\tilde{\\mathbf{y}}=\\operatorname{tanh}\\left(W\\mathbf{x}+\\mathbf{b}\\right)}}\\\\ {{\\mathbf{g}=\\sigma(W^{\\prime}\\mathbf{x}+\\mathbf{b}^{\\prime})}}\\\\ {{\\mathbf{y}=\\tilde{\\mathbf{y}}\\,\\circ\\,\\mathbf{g}}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-113-Sentence-1131 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-113-Sentence-1131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{{\\tilde{\\mathbf{y}}=\\operatorname{tanh}\\left(W\\mathbf{x}+\\mathbf{b}\\right)}}\\\\ {{\\mathbf{g}=\\sigma(W^{\\prime}\\mathbf{x}+\\mathbf{b}^{\\prime})}}\\\\ {{\\mathbf{y}=\\tilde{\\mathbf{y}}\\,\\circ\\,\\mathbf{g}}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{{\\tilde{\\mathbf{y}}=\\operatorname{tanh}\\left(W\\mathbf{x}+\\mathbf{b}\\right)}}\\\\ {{\\mathbf{g}=\\sigma(W^{\\prime}\\mathbf{x}+\\mathbf{b}^{\\prime})}}\\\\ {{\\mathbf{y}=\\tilde{\\mathbf{y}}\\,\\circ\\,\\mathbf{g}}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extbfg,
        askg-data:Entity-%09extbfy,
        askg-data:Entity-%09extsigmaw%09extprime%09extbfx%09extbfb%09extprime,
        askg-data:Entity-%09ilde%09extbfy,
        askg-data:Entity-%09ilde%09extbfy__%09extcirc__%09extbfg,
        askg-data:Entity-tanhw%09extbfx%09extbfb .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-114 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "where σ is the sigmoid activation function, *W, W*0 ∈ R n×m are learned weights, b, b 0 ∈ R n are learned biases, and ◦ is the Hadamard (element-wise) product. The vector g acts multiplicatively as a gate on the intermediate activation y˜."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-114-Sentence-1141,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-114-Sentence-1142 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-114-Sentence-1141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where σ is the sigmoid activation function, *W, W*0 ∈ R n×m are learned weights, b, b 0 ∈ R n are learned biases, and ◦ is the Hadamard (element-wise) product."@en ;
    askg-onto:inSentence "where σ is the sigmoid activation function, *W, W*0 ∈ R n×m are learned weights, b, b 0 ∈ R n are learned biases, and ◦ is the Hadamard (element-wise) product."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%83,
        askg-data:Entity-hadamard_product,
        askg-data:Entity-learned_biases,
        askg-data:Entity-learned_weights,
        askg-data:Entity-sigmoid_activation_function .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-114-Sentence-1142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The vector g acts multiplicatively as a gate on the intermediate activation y˜."@en ;
    askg-onto:inSentence "The vector g acts multiplicatively as a gate on the intermediate activation y˜."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-intermediate_activation_y,
        askg-data:Entity-vector_g .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-115 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Our proposed approach first encodes each question as the hidden state q of a gated recurrent unit [5] (GRU), with each input word represented using a learned word embedding."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-115-Sentence-1151 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-115-Sentence-1151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our proposed approach first encodes each question as the hidden state q of a gated recurrent unit [5] (GRU), with each input word represented using a learned word embedding."@en ;
    askg-onto:inSentence "Our proposed approach first encodes each question as the hidden state q of a gated recurrent unit [5] (GRU), with each input word represented using a learned word embedding."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gated_recurrent_unit,
        askg-data:Entity-hidden_state_q,
        askg-data:Entity-input_word,
        askg-data:Entity-learned_word_embedding .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-116 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Similar to Equation 3, given the output q of the GRU, we generate an unnormalized attention weight ai for each of the k image features vi as follows:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-116-Sentence-1161 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-116-Sentence-1161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Similar to Equation 3, given the output q of the GRU, we generate an unnormalized attention weight ai for each of the k image features vi as follows:"@en ;
    askg-onto:inSentence "Similar to Equation 3, given the output q of the GRU, we generate an unnormalized attention weight ai for each of the k image features vi as follows:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_features_vi,
        askg-data:Entity-output_q_of_the_gru,
        askg-data:Entity-unnormalized_attention_weight_ai .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-117 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$\\mathrm{IIlows}.$$ $$a_{i}=\\mathbf{w}_{a}^{T}f_{a}([\\mathbf{v}_{i},\\mathbf{q}])$$ $$(15)^{\\frac{1}{2}}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-117-Sentence-1171 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-117-Sentence-1171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathrm{IIlows}.$$ $$a_{i}=\\mathbf{w}_{a}^{T}f_{a}([\\mathbf{v}_{i},\\mathbf{q}])$$ $$(15)^{\\frac{1}{2}}$$"@en ;
    askg-onto:inSentence "$$\\mathrm{IIlows}.$$ $$a_{i}=\\mathbf{w}_{a}^{T}f_{a}([\\mathbf{v}_{i},\\mathbf{q}])$$ $$(15)^{\\frac{1}{2}}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iilows,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "where wTais a learned parameter vector. Equation 4 and Equation 5 (neglecting subscripts t) are used to calculate the normalized attention weight and the attended image feature vˆ. The distribution over possible output responses y is given by:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118-Sentence-1181,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118-Sentence-1182,
        askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118-Sentence-1183 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118-Sentence-1181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where wTais a learned parameter vector."@en ;
    askg-onto:inSentence "where wTais a learned parameter vector."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_learned_parameter_vector,
        askg-data:Entity-wt .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118-Sentence-1182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Equation 4 and Equation 5 (neglecting subscripts t) are used to calculate the normalized attention weight and the attended image feature vˆ."@en ;
    askg-onto:inSentence "Equation 4 and Equation 5 (neglecting subscripts t) are used to calculate the normalized attention weight and the attended image feature vˆ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attended_image_feature_v%CB%86,
        askg-data:Entity-equation_4,
        askg-data:Entity-equation_5,
        askg-data:Entity-normalized_attention_weight .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-118-Sentence-1183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The distribution over possible output responses y is given by:"@en ;
    askg-onto:inSentence "The distribution over possible output responses y is given by:"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-distribution,
        askg-data:Entity-output_responses_y .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-119 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$$\\begin{array}{c}{{\\mathbf{h}=f_{q}(\\mathbf{q})\\,\\circ\\,f_{v}({\\hat{\\mathbf{v}}})}}\\\\ {{p(y)=\\sigma(W_{o}\\,f_{o}(\\mathbf{h}))}}\\end{array}$$ $$\\begin{array}{l}{(16)}\\\\ {(17)}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-119-Sentence-1191 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-11-Paragraph-119-Sentence-1191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{c}{{\\mathbf{h}=f_{q}(\\mathbf{q})\\,\\circ\\,f_{v}({\\hat{\\mathbf{v}}})}}\\\\ {{p(y)=\\sigma(W_{o}\\,f_{o}(\\mathbf{h}))}}\\end{array}$$ $$\\begin{array}{l}{(16)}\\\\ {(17)}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{c}{{\\mathbf{h}=f_{q}(\\mathbf{q})\\,\\circ\\,f_{v}({\\hat{\\mathbf{v}}})}}\\\\ {{p(y)=\\sigma(W_{o}\\,f_{o}(\\mathbf{h}))}}\\end{array}$$ $$\\begin{array}{l}{(16)}\\\\ {(17)}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h,
        askg-data:Entity-q_and_v .

askg-data:Paper-11712fbcb9a80fb4-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "4. Evaluation 4.1. Datasets"@en ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "4.1.1 Visual Genome Dataset"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-131,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-133,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-134,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-138 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "$$\\begin{array}{l}{(12)}\\\\ {(13)}\\end{array}$$ $\\left(14\\right)^{2}$ We use the Visual Genome [21] dataset to pretrain our bottom-up attention model, and for data augmentation when training our VQA model. The dataset contains 108K images densely annotated with scene graphs containing objects, attributes and relationships, as well as 1.7M visual question answers."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-131-Sentence-1312 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{(12)}\\\\ {(13)}\\end{array}$$ $\\left(14\\right)^{2}$ We use the Visual Genome [21] dataset to pretrain our bottom-up attention model, and for data augmentation when training our VQA model."@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{(12)}\\\\ {(13)}\\end{array}$$ $\\left(14\\right)^{2}$ We use the Visual Genome [21] dataset to pretrain our bottom-up attention model, and for data augmentation when training our VQA model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention_model,
        askg-data:Entity-data_augmentation,
        askg-data:Entity-visual_genome,
        askg-data:Entity-visual_genome_dataset,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The dataset contains 108K images densely annotated with scene graphs containing objects, attributes and relationships, as well as 1.7M visual question answers."@en ;
    askg-onto:inSentence "The dataset contains 108K images densely annotated with scene graphs containing objects, attributes and relationships, as well as 1.7M visual question answers."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-108k_images,
        askg-data:Entity-17m_visual_question_answers,
        askg-data:Entity-dataset,
        askg-data:Entity-objects_attributes_and_relationships,
        askg-data:Entity-scene_graphs .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For pretraining the bottom-up attention model, we use only the object and attribute data. We reserve 5K images for validation, and 5K images for future testing, treating the remaining 98K images as training data. As approximately 51K Visual Genome images are also found in the MSCOCO captions dataset [23], we are careful to avoid contamination of our MSCOCO validation and test sets. We ensure that any images found in both datasets are contained in the same split in both datasets."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1321,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1322,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1323,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1324 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For pretraining the bottom-up attention model, we use only the object and attribute data."@en ;
    askg-onto:inSentence "For pretraining the bottom-up attention model, we use only the object and attribute data."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention_model,
        askg-data:Entity-object_and_attribute_data .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We reserve 5K images for validation, and 5K images for future testing, treating the remaining 98K images as training data."@en ;
    askg-onto:inSentence "We reserve 5K images for validation, and 5K images for future testing, treating the remaining 98K images as training data."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_testing,
        askg-data:Entity-images,
        askg-data:Entity-training_data,
        askg-data:Entity-validation .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As approximately 51K Visual Genome images are also found in the MSCOCO captions dataset [23], we are careful to avoid contamination of our MSCOCO validation and test sets."@en ;
    askg-onto:inSentence "As approximately 51K Visual Genome images are also found in the MSCOCO captions dataset [23], we are careful to avoid contamination of our MSCOCO validation and test sets."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mscoco_captions_dataset,
        askg-data:Entity-visual_genome_images .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-132-Sentence-1324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We ensure that any images found in both datasets are contained in the same split in both datasets."@en ;
    askg-onto:inSentence "We ensure that any images found in both datasets are contained in the same split in both datasets."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-images .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-133 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "| | Cross\\-Entropy Loss | | | | | | | | CIDEr Optimization | | | | |----------------------|---------------------------------------------|------|------|------|-------|------|------|------|---------------------------------------------|------|-------|------| | | BLEU\\-1 BLEU\\-4 METEOR ROUGE\\-L CIDEr SPICE | | | | | | | | BLEU\\-1 BLEU\\-4 METEOR ROUGE\\-L CIDEr SPICE | | | | | SCST:Att2in [34] | \\- | 31.3 | 26.0 | 54.3 | 101.3 | \\- | \\- | 33.3 | 26.3 | 55.3 | 111.4 | \\- | | SCST:Att2all [34] | \\- | 30.0 | 25.9 | 53.4 | 99.4 | \\- | \\- | 34.2 | 26.7 | 55.7 | 114.0 | \\- | | Ours: ResNet | 74.5 | 33.4 | 26.1 | 54.4 | 105.4 | 19.2 | 76.6 | 34.0 | 26.5 | 54.9 | 111.1 | 20.2 | | Ours: Up\\-Down | 77.2 | 36.2 | 27.0 | 56.4 | 113.5 | 20.3 | 79.8 | 36.3 | 27.7 | 56.9 | 120.1 | 21.4 | | Relative Improvement | 4% | 8% | 3% | 4% | 8% | 6% | 4% | 7% | 5% | 4% | 8% | 6% |"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-133-Sentence-1331 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-133-Sentence-1331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | Cross\\-Entropy Loss | | | | | | | | CIDEr Optimization | | | | |----------------------|---------------------------------------------|------|------|------|-------|------|------|------|---------------------------------------------|------|-------|------| | | BLEU\\-1 BLEU\\-4 METEOR ROUGE\\-L CIDEr SPICE | | | | | | | | BLEU\\-1 BLEU\\-4 METEOR ROUGE\\-L CIDEr SPICE | | | | | SCST:Att2in [34] | \\- | 31.3 | 26.0 | 54.3 | 101.3 | \\- | \\- | 33.3 | 26.3 | 55.3 | 111.4 | \\- | | SCST:Att2all [34] | \\- | 30.0 | 25.9 | 53.4 | 99.4 | \\- | \\- | 34.2 | 26.7 | 55.7 | 114.0 | \\- | | Ours: ResNet | 74.5 | 33.4 | 26.1 | 54.4 | 105.4 | 19.2 | 76.6 | 34.0 | 26.5 | 54.9 | 111.1 | 20.2 | | Ours: Up\\-Down | 77.2 | 36.2 | 27.0 | 56.4 | 113.5 | 20.3 | 79.8 | 36.3 | 27.7 | 56.9 | 120.1 | 21.4 | | Relative Improvement | 4% | 8% | 3% | 4% | 8% | 6% | 4% | 7% | 5% | 4% | 8% | 6% |"@en ;
    askg-onto:inSentence "| | Cross\\-Entropy Loss | | | | | | | | CIDEr Optimization | | | | |----------------------|---------------------------------------------|------|------|------|-------|------|------|------|---------------------------------------------|------|-------|------| | | BLEU\\-1 BLEU\\-4 METEOR ROUGE\\-L CIDEr SPICE | | | | | | | | BLEU\\-1 BLEU\\-4 METEOR ROUGE\\-L CIDEr SPICE | | | | | SCST:Att2in [34] | \\- | 31.3 | 26.0 | 54.3 | 101.3 | \\- | \\- | 33.3 | 26.3 | 55.3 | 111.4 | \\- | | SCST:Att2all [34] | \\- | 30.0 | 25.9 | 53.4 | 99.4 | \\- | \\- | 34.2 | 26.7 | 55.7 | 114.0 | \\- | | Ours: ResNet | 74.5 | 33.4 | 26.1 | 54.4 | 105.4 | 19.2 | 76.6 | 34.0 | 26.5 | 54.9 | 111.1 | 20.2 | | Ours: Up\\-Down | 77.2 | 36.2 | 27.0 | 56.4 | 113.5 | 20.3 | 79.8 | 36.3 | 27.7 | 56.9 | 120.1 | 21.4 | | Relative Improvement | 4% | 8% | 3% | 4% | 8% | 6% | 4% | 7% | 5% | 4% | 8% | 6% |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-ours_resnet,
        askg-data:Entity-ours_up-down,
        askg-data:Entity-relative_improvement,
        askg-data:Entity-scstatt2all,
        askg-data:Entity-scstatt2in .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-134 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "| | Cross\\-Entropy Loss | | | | | | | CIDEr Optimization | | | | | | | |----------------|-----------------------------------------------------|------|-----|-----|------|-----|-----|-----------------------------------------------------|------|------|-----|------|------|-----| | | SPICE Objects Attributes Relations Color Count Size | | | | | | | SPICE Objects Attributes Relations Color Count Size | | | | | | | | Ours: ResNet | 19.2 | 35.4 | 8.6 | 5.3 | 12.2 | 4.1 | 3.9 | 20.2 | 37.0 | 9.2 | 6.1 | 10.6 | 12.0 | 4.3 | | Ours: Up\\-Down | 20.3 | 37.1 | 9.2 | 5.8 | 12.7 | 6.5 | 4.5 | 21.4 | 39.1 | 10.0 | 6.5 | 11.4 | 18.4 | 3.2 |"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-134-Sentence-1341 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-134-Sentence-1341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | Cross\\-Entropy Loss | | | | | | | CIDEr Optimization | | | | | | | |----------------|-----------------------------------------------------|------|-----|-----|------|-----|-----|-----------------------------------------------------|------|------|-----|------|------|-----| | | SPICE Objects Attributes Relations Color Count Size | | | | | | | SPICE Objects Attributes Relations Color Count Size | | | | | | | | Ours: ResNet | 19.2 | 35.4 | 8.6 | 5.3 | 12.2 | 4.1 | 3.9 | 20.2 | 37.0 | 9.2 | 6.1 | 10.6 | 12.0 | 4.3 | | Ours: Up\\-Down | 20.3 | 37.1 | 9.2 | 5.8 | 12.7 | 6.5 | 4.5 | 21.4 | 39.1 | 10.0 | 6.5 | 11.4 | 18.4 | 3.2 |"@en ;
    askg-onto:inSentence "| | Cross\\-Entropy Loss | | | | | | | CIDEr Optimization | | | | | | | |----------------|-----------------------------------------------------|------|-----|-----|------|-----|-----|-----------------------------------------------------|------|------|-----|------|------|-----| | | SPICE Objects Attributes Relations Color Count Size | | | | | | | SPICE Objects Attributes Relations Color Count Size | | | | | | | | Ours: ResNet | 19.2 | 35.4 | 8.6 | 5.3 | 12.2 | 4.1 | 3.9 | 20.2 | 37.0 | 9.2 | 6.1 | 10.6 | 12.0 | 4.3 | | Ours: Up\\-Down | 20.3 | 37.1 | 9.2 | 5.8 | 12.7 | 6.5 | 4.5 | 21.4 | 39.1 | 10.0 | 6.5 | 11.4 | 18.4 | 3.2 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-resnet,
        askg-data:Entity-spice,
        askg-data:Entity-up-down .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Table 1. Single-model image captioning performance on the MSCOCO Karpathy test split. Our baseline ResNet model obtains similar results to SCST [34], the existing state-of-the-art on this test set. Illustrating the contribution of bottom-up attention, our Up-Down model achieves significant (3–8%) relative gains across all metrics regardless of whether cross-entropy loss or CIDEr optimization is used."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1351,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1352,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1353,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1354 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 1."@en ;
    askg-onto:inSentence "Table 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-triples .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Single-model image captioning performance on the MSCOCO Karpathy test split."@en ;
    askg-onto:inSentence "Single-model image captioning performance on the MSCOCO Karpathy test split."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-karpathy_test_split,
        askg-data:Entity-mscoco,
        askg-data:Entity-mscoco_karpathy_test_split .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1353 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our baseline ResNet model obtains similar results to SCST [34], the existing state-of-the-art on this test set."@en ;
    askg-onto:inSentence "Our baseline ResNet model obtains similar results to SCST [34], the existing state-of-the-art on this test set."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-resnet_model,
        askg-data:Entity-scst,
        askg-data:Entity-state-of-the-art .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-135-Sentence-1354 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Illustrating the contribution of bottom-up attention, our Up-Down model achieves significant (3–8%) relative gains across all metrics regardless of whether cross-entropy loss or CIDEr optimization is used."@en ;
    askg-onto:inSentence "Illustrating the contribution of bottom-up attention, our Up-Down model achieves significant (3–8%) relative gains across all metrics regardless of whether cross-entropy loss or CIDEr optimization is used."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cider_optimization,
        askg-data:Entity-cross-entropy_loss,
        askg-data:Entity-significant_gains,
        askg-data:Entity-up-down_model .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Table 2. Breakdown of SPICE F-scores over various subcategories on the MSCOCO Karpathy test split. Our Up-Down model outperforms the ResNet baseline at identifying objects, as well as detecting object attributes and the relations between objects."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136-Sentence-1361,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136-Sentence-1362,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136-Sentence-1363 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136-Sentence-1361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 2."@en ;
    askg-onto:inSentence "Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-research_concepts,
        askg-data:Entity-technology .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136-Sentence-1362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Breakdown of SPICE F-scores over various subcategories on the MSCOCO Karpathy test split."@en ;
    askg-onto:inSentence "Breakdown of SPICE F-scores over various subcategories on the MSCOCO Karpathy test split."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mscoco_karpathy_test_split,
        askg-data:Entity-spice_f-scores .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-136-Sentence-1363 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our Up-Down model outperforms the ResNet baseline at identifying objects, as well as detecting object attributes and the relations between objects."@en ;
    askg-onto:inSentence "Our Up-Down model outperforms the ResNet baseline at identifying objects, as well as detecting object attributes and the relations between objects."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-object_attributes,
        askg-data:Entity-objects,
        askg-data:Entity-relations_between_objects,
        askg-data:Entity-resnet_baseline,
        askg-data:Entity-up-down_model .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "As the object and attribute annotations consist of freely annotated strings, rather than classes, we perform extensive cleaning and filtering of the training data. Starting from 2,000 object classes and 500 attribute classes, we manually remove abstract classes that exhibit poor detection performance in initial experiments. Our final training set contains 1,600 object classes and 400 attribute classes. Note that we do not merge or remove overlapping classes (e.g. 'person', 'man', 'guy'), classes with both singular and plural versions (e.g. 'tree', 'trees') and classes that are difficult to precisely localize (e.g. 'sky', 'grass', 'buildings')."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1371,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1372,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1373,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1374,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1375,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1376,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1377 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As the object and attribute annotations consist of freely annotated strings, rather than classes, we perform extensive cleaning and filtering of the training data."@en ;
    askg-onto:inSentence "As the object and attribute annotations consist of freely annotated strings, rather than classes, we perform extensive cleaning and filtering of the training data."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-extensive_cleaning_and_filtering_of_the_training_data,
        askg-data:Entity-freely_annotated_strings,
        askg-data:Entity-object_and_attribute_annotations,
        askg-data:Entity-we .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1372 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Starting from 2,000 object classes and 500 attribute classes, we manually remove abstract classes that exhibit poor detection performance in initial experiments."@en ;
    askg-onto:inSentence "Starting from 2,000 object classes and 500 attribute classes, we manually remove abstract classes that exhibit poor detection performance in initial experiments."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2000,
        askg-data:Entity-500,
        askg-data:Entity-abstract_classes,
        askg-data:Entity-attribute_classes,
        askg-data:Entity-initial_experiments,
        askg-data:Entity-object_classes,
        askg-data:Entity-poor_detection_performance .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1373 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our final training set contains 1,600 object classes and 400 attribute classes."@en ;
    askg-onto:inSentence "Our final training set contains 1,600 object classes and 400 attribute classes."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1600_object_classes,
        askg-data:Entity-400_attribute_classes,
        askg-data:Entity-training_set .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1374 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Note that we do not merge or remove overlapping classes (e.g."@en ;
    askg-onto:inSentence "Note that we do not merge or remove overlapping classes (e.g."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classes,
        askg-data:Entity-overlapping_classes .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1375 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "'person', 'man', 'guy'), classes with both singular and plural versions (e.g."@en ;
    askg-onto:inSentence "'person', 'man', 'guy'), classes with both singular and plural versions (e.g."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guy,
        askg-data:Entity-individual,
        askg-data:Entity-informal_term_for_man,
        askg-data:Entity-male_individual,
        askg-data:Entity-man,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1376 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "'tree', 'trees') and classes that are difficult to precisely localize (e.g."@en ;
    askg-onto:inSentence "'tree', 'trees') and classes that are difficult to precisely localize (e.g."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-tree,
        askg-data:Entity-trees .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-137-Sentence-1377 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "'sky', 'grass', 'buildings')."@en ;
    askg-onto:inSentence "'sky', 'grass', 'buildings')."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-buildings,
        askg-data:Entity-environment,
        askg-data:Entity-grass,
        askg-data:Entity-sky,
        askg-data:Entity-urban_areas,
        askg-data:Entity-vegetation .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-138 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "When training the VQA model, we augment the VQA v2.0 training data with Visual Genome question and answer pairs provided the correct answer is present in model's answer vocabulary. This represents about 30% of the available data, or 485K questions."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-138-Sentence-1381,
        askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-138-Sentence-1382 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-138-Sentence-1381 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "When training the VQA model, we augment the VQA v2.0 training data with Visual Genome question and answer pairs provided the correct answer is present in model's answer vocabulary."@en ;
    askg-onto:inSentence "When training the VQA model, we augment the VQA v2.0 training data with Visual Genome question and answer pairs provided the correct answer is present in model's answer vocabulary."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-correct_answer,
        askg-data:Entity-visual_genome_question_and_answer_pairs,
        askg-data:Entity-vqa_model,
        askg-data:Entity-vqa_v20_training_data .

askg-data:Paper-11712fbcb9a80fb4-Section-13-Paragraph-138-Sentence-1382 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This represents about 30% of the available data, or 485K questions."@en ;
    askg-onto:inSentence "This represents about 30% of the available data, or 485K questions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30_of_the_available_data,
        askg-data:Entity-485k_questions,
        askg-data:Entity-data,
        askg-data:Entity-questions .

askg-data:Paper-11712fbcb9a80fb4-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "4.1.2 Microsoft Coco Dataset"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141,
        askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-142 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To evaluate our proposed captioning model, we use the MSCOCO 2014 captions dataset [23]. For validation of model hyperparameters and offline testing, we use the 'Karpathy' splits [19] that have been used extensively for reporting results in prior work. This split contains 113,287 training images with five captions each, and 5K images respectively for validation and testing. Our MSCOCO test server submission is trained on the entire MSCOCO 2014 training and validation set (123K images)."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1411,
        askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1412,
        askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1413,
        askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1414 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To evaluate our proposed captioning model, we use the MSCOCO 2014 captions dataset [23]."@en ;
    askg-onto:inSentence "To evaluate our proposed captioning model, we use the MSCOCO 2014 captions dataset [23]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_model,
        askg-data:Entity-mscoco_2014_captions_dataset .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For validation of model hyperparameters and offline testing, we use the 'Karpathy' splits [19] that have been used extensively for reporting results in prior work."@en ;
    askg-onto:inSentence "For validation of model hyperparameters and offline testing, we use the 'Karpathy' splits [19] that have been used extensively for reporting results in prior work."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-karpathy,
        askg-data:Entity-splits .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This split contains 113,287 training images with five captions each, and 5K images respectively for validation and testing."@en ;
    askg-onto:inSentence "This split contains 113,287 training images with five captions each, and 5K images respectively for validation and testing."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-113287,
        askg-data:Entity-5k,
        askg-data:Entity-testing_images,
        askg-data:Entity-training_images,
        askg-data:Entity-validation_images .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-141-Sentence-1414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our MSCOCO test server submission is trained on the entire MSCOCO 2014 training and validation set (123K images)."@en ;
    askg-onto:inSentence "Our MSCOCO test server submission is trained on the entire MSCOCO 2014 training and validation set (123K images)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mscoco_2014_training_and_validation_set,
        askg-data:Entity-mscoco_test_server_submission .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-142 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We follow standard practice and perform only minimal text pre-processing, converting all sentences to lower case, tokenizing on white space, and filtering words that do not occur at least five times, resulting in a model vocabulary of 10,010 words. To evaluate caption quality, we use the standard automatic evaluation metrics, namely SPICE [1], CIDEr [43], METEOR [8], ROUGE-L [22] and BLEU [29]."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-142-Sentence-1421,
        askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-142-Sentence-1422 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-142-Sentence-1421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We follow standard practice and perform only minimal text pre-processing, converting all sentences to lower case, tokenizing on white space, and filtering words that do not occur at least five times, resulting in a model vocabulary of 10,010 words."@en ;
    askg-onto:inSentence "We follow standard practice and perform only minimal text pre-processing, converting all sentences to lower case, tokenizing on white space, and filtering words that do not occur at least five times, resulting in a model vocabulary of 10,010 words."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10010_words,
        askg-data:Entity-method,
        askg-data:Entity-model_vocabulary,
        askg-data:Entity-text_pre-processing .

askg-data:Paper-11712fbcb9a80fb4-Section-14-Paragraph-142-Sentence-1422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To evaluate caption quality, we use the standard automatic evaluation metrics, namely SPICE [1], CIDEr [43], METEOR [8], ROUGE-L [22] and BLEU [29]."@en ;
    askg-onto:inSentence "To evaluate caption quality, we use the standard automatic evaluation metrics, namely SPICE [1], CIDEr [43], METEOR [8], ROUGE-L [22] and BLEU [29]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_evaluation_metrics,
        askg-data:Entity-bleu,
        askg-data:Entity-caption_quality,
        askg-data:Entity-cider,
        askg-data:Entity-meteor,
        askg-data:Entity-rouge-l,
        askg-data:Entity-spice .

askg-data:Paper-11712fbcb9a80fb4-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "4.1.3 Vqa V2.0 Dataset"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-151,
        askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To evaluate our proposed VQA model, we use the recently introduced VQA v2.0 dataset [12], which attempts to minimize the effectiveness of learning dataset priors by balancing the answers to each question. The dataset, which was used as the basis of the 2017 VQA Challenge2, contains 1.1M questions with 11.1M answers relating to MSCOCO images."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-151-Sentence-1511,
        askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-151-Sentence-1512 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To evaluate our proposed VQA model, we use the recently introduced VQA v2.0 dataset [12], which attempts to minimize the effectiveness of learning dataset priors by balancing the answers to each question."@en ;
    askg-onto:inSentence "To evaluate our proposed VQA model, we use the recently introduced VQA v2.0 dataset [12], which attempts to minimize the effectiveness of learning dataset priors by balancing the answers to each question."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-vqa_model,
        askg-data:Entity-vqa_v20_dataset .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-151-Sentence-1512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The dataset, which was used as the basis of the 2017 VQA Challenge2, contains 1.1M questions with 11.1M answers relating to MSCOCO images."@en ;
    askg-onto:inSentence "The dataset, which was used as the basis of the 2017 VQA Challenge2, contains 1.1M questions with 11.1M answers relating to MSCOCO images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017_vqa_challenge2,
        askg-data:Entity-answers,
        askg-data:Entity-dataset,
        askg-data:Entity-mscoco_images,
        askg-data:Entity-questions .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We perform standard question text preprocessing and tokenization. Questions are trimmed to a maximum of 14 words for computational efficiency. The set of candidate answers is restricted to correct answers in the training set that appear more than 8 times, resulting in an output vocabulary size of 3,129. Our VQA test server submissions are trained on the training and validation sets plus additional questions and answers from Visual Genome. To evaluate answer quality, we report accuracies using the standard VQA metric [2], which takes into account the occasional disagreement between annotators for the ground truth answers."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1521,
        askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1522,
        askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1523,
        askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1524,
        askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1525 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We perform standard question text preprocessing and tokenization."@en ;
    askg-onto:inSentence "We perform standard question text preprocessing and tokenization."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-preprocessing,
        askg-data:Entity-question_text,
        askg-data:Entity-tokenization .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Questions are trimmed to a maximum of 14 words for computational efficiency."@en ;
    askg-onto:inSentence "Questions are trimmed to a maximum of 14 words for computational efficiency."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-maximum_of_14_words,
        askg-data:Entity-questions .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The set of candidate answers is restricted to correct answers in the training set that appear more than 8 times, resulting in an output vocabulary size of 3,129."@en ;
    askg-onto:inSentence "The set of candidate answers is restricted to correct answers in the training set that appear more than 8 times, resulting in an output vocabulary size of 3,129."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8_times,
        askg-data:Entity-correct_answers_in_the_training_set,
        askg-data:Entity-output_vocabulary_size_of_3129,
        askg-data:Entity-set_of_candidate_answers .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our VQA test server submissions are trained on the training and validation sets plus additional questions and answers from Visual Genome."@en ;
    askg-onto:inSentence "Our VQA test server submissions are trained on the training and validation sets plus additional questions and answers from Visual Genome."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_questions_and_answers_from_visual_genome,
        askg-data:Entity-questions_and_answers,
        askg-data:Entity-training_and_validation_sets,
        askg-data:Entity-visual_genome,
        askg-data:Entity-vqa_test_server .

askg-data:Paper-11712fbcb9a80fb4-Section-15-Paragraph-152-Sentence-1525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To evaluate answer quality, we report accuracies using the standard VQA metric [2], which takes into account the occasional disagreement between annotators for the ground truth answers."@en ;
    askg-onto:inSentence "To evaluate answer quality, we report accuracies using the standard VQA metric [2], which takes into account the occasional disagreement between annotators for the ground truth answers."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-answer_quality,
        askg-data:Entity-vqa_metric .

askg-data:Paper-11712fbcb9a80fb4-Section-16 a askg-onto:Section ;
    rdfs:label "Section 16"@en ;
    domo:Text "4.2. Resnet Baseline"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-161,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-162,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-163,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-165,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-166,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-168,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169 ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-161 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To quantify the impact of bottom-up attention, in both our captioning and VQA experiments we evaluate our full"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-161-Sentence-1611 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-161-Sentence-1611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To quantify the impact of bottom-up attention, in both our captioning and VQA experiments we evaluate our full"@en ;
    askg-onto:inSentence "To quantify the impact of bottom-up attention, in both our captioning and VQA experiments we evaluate our full"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-captioning,
        askg-data:Entity-vqa_experiments .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-162 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "2http://www.visualqa.org/challenge.html"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-162-Sentence-1621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-162-Sentence-1621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2http://www.visualqa.org/challenge.html"@en ;
    askg-onto:inSentence "2http://www.visualqa.org/challenge.html"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-platform,
        askg-data:Entity-visualqa .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-163 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "| | BLEU\\-1 | | BLEU\\-2 | | BLEU\\-3 | | BLEU\\-4 | | | METEOR | | ROUGE\\-L | CIDEr | | | SPICE | |-----------------------------|-----------|-----|-----------|-----|-----------|-----|-----------|-----|------|----------|------|------------|-------------|------|------|---------| | | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | | Review Net [48] | 72.0 90.0 | | 55.0 81.2 | | 41.4 70.5 | | 31.3 59.7 | | 25.6 | 34.7 | 53.3 | 68.6 | 96.5 | 96.9 | 18.5 | 64.9 | | Adaptive [27] | 74.8 92.0 | | 58.4 84.5 | | 44.4 74.4 | | 33.6 63.7 | | 26.4 | 35.9 | 55.0 | 70.5 | 104.2 105.9 | | 19.7 | 67.3 | | PG\\-BCMR [24] | 75.4 | \\- | 59.1 | \\- | 44.5 | \\- | 33.2 | \\- | 25.7 | \\- | 55 | \\- | 101.3 | \\- | \\- | \\- | | SCST:Att2all [34] 78.1 93.7 | | | 61.9 86.0 | | 47.0 75.9 | | 35.2 64.5 | | 27.0 | 35.5 | 56.3 | 70.7 | 114.7 116.7 | | 20.7 | 68.9 | | [49] LSTM\\-A3 | 78.7 93.7 | | 62.7 86.7 | | 47.6 76.5 | | 35.6 65.2 | | 27 | 35.4 | 56.4 | 70.5 | 116 | 118 | \\- | \\- | | Ours: Up\\-Down | 80.2 95.2 | | 64.1 88.8 | | 49.1 79.4 | | 36.9 68.5 | | 27.6 | 36.7 | 57.1 | 72.4 | 117.9 120.5 | | 21.5 | 71.5 |"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-163-Sentence-1631 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-163-Sentence-1631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | BLEU\\-1 | | BLEU\\-2 | | BLEU\\-3 | | BLEU\\-4 | | | METEOR | | ROUGE\\-L | CIDEr | | | SPICE | |-----------------------------|-----------|-----|-----------|-----|-----------|-----|-----------|-----|------|----------|------|------------|-------------|------|------|---------| | | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | | Review Net [48] | 72.0 90.0 | | 55.0 81.2 | | 41.4 70.5 | | 31.3 59.7 | | 25.6 | 34.7 | 53.3 | 68.6 | 96.5 | 96.9 | 18.5 | 64.9 | | Adaptive [27] | 74.8 92.0 | | 58.4 84.5 | | 44.4 74.4 | | 33.6 63.7 | | 26.4 | 35.9 | 55.0 | 70.5 | 104.2 105.9 | | 19.7 | 67.3 | | PG\\-BCMR [24] | 75.4 | \\- | 59.1 | \\- | 44.5 | \\- | 33.2 | \\- | 25.7 | \\- | 55 | \\- | 101.3 | \\- | \\- | \\- | | SCST:Att2all [34] 78.1 93.7 | | | 61.9 86.0 | | 47.0 75.9 | | 35.2 64.5 | | 27.0 | 35.5 | 56.3 | 70.7 | 114.7 116.7 | | 20.7 | 68.9 | | [49] LSTM\\-A3 | 78.7 93.7 | | 62.7 86.7 | | 47.6 76.5 | | 35.6 65.2 | | 27 | 35.4 | 56.4 | 70.5 | 116 | 118 | \\- | \\- | | Ours: Up\\-Down | 80.2 95.2 | | 64.1 88.8 | | 49.1 79.4 | | 36.9 68.5 | | 27.6 | 36.7 | 57.1 | 72.4 | 117.9 120.5 | | 21.5 | 71.5 |"@en ;
    askg-onto:inSentence "| | BLEU\\-1 | | BLEU\\-2 | | BLEU\\-3 | | BLEU\\-4 | | | METEOR | | ROUGE\\-L | CIDEr | | | SPICE | |-----------------------------|-----------|-----|-----------|-----|-----------|-----|-----------|-----|------|----------|------|------------|-------------|------|------|---------| | | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | c5 | c40 | | Review Net [48] | 72.0 90.0 | | 55.0 81.2 | | 41.4 70.5 | | 31.3 59.7 | | 25.6 | 34.7 | 53.3 | 68.6 | 96.5 | 96.9 | 18.5 | 64.9 | | Adaptive [27] | 74.8 92.0 | | 58.4 84.5 | | 44.4 74.4 | | 33.6 63.7 | | 26.4 | 35.9 | 55.0 | 70.5 | 104.2 105.9 | | 19.7 | 67.3 | | PG\\-BCMR [24] | 75.4 | \\- | 59.1 | \\- | 44.5 | \\- | 33.2 | \\- | 25.7 | \\- | 55 | \\- | 101.3 | \\- | \\- | \\- | | SCST:Att2all [34] 78.1 93.7 | | | 61.9 86.0 | | 47.0 75.9 | | 35.2 64.5 | | 27.0 | 35.5 | 56.3 | 70.7 | 114.7 116.7 | | 20.7 | 68.9 | | [49] LSTM\\-A3 | 78.7 93.7 | | 62.7 86.7 | | 47.6 76.5 | | 35.6 65.2 | | 27 | 35.4 | 56.4 | 70.5 | 116 | 118 | \\- | \\- | | Ours: Up\\-Down | 80.2 95.2 | | 64.1 88.8 | | 49.1 79.4 | | 36.9 68.5 | | 27.6 | 36.7 | 57.1 | 72.4 | 117.9 120.5 | | 21.5 | 71.5 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-256,
        askg-data:Entity-264,
        askg-data:Entity-27,
        askg-data:Entity-270,
        askg-data:Entity-276,
        askg-data:Entity-313_597,
        askg-data:Entity-336_637,
        askg-data:Entity-347,
        askg-data:Entity-352_645,
        askg-data:Entity-354,
        askg-data:Entity-355,
        askg-data:Entity-356_652,
        askg-data:Entity-359,
        askg-data:Entity-367,
        askg-data:Entity-369_685,
        askg-data:Entity-414_705,
        askg-data:Entity-444_744,
        askg-data:Entity-470_759,
        askg-data:Entity-476_765,
        askg-data:Entity-491_794,
        askg-data:Entity-550_812,
        askg-data:Entity-584_845,
        askg-data:Entity-591,
        askg-data:Entity-619_860,
        askg-data:Entity-627_867,
        askg-data:Entity-641_888,
        askg-data:Entity-720_900,
        askg-data:Entity-748_920,
        askg-data:Entity-754,
        askg-data:Entity-781_937,
        askg-data:Entity-787_937,
        askg-data:Entity-802_952,
        askg-data:Entity-adaptive,
        askg-data:Entity-lstm-a3,
        askg-data:Entity-ours_up-down,
        askg-data:Entity-pg-bcmr,
        askg-data:Entity-review_net,
        askg-data:Entity-scstatt2all .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Table 3. Highest ranking published image captioning results on the online MSCOCO test server. Our submission, an ensemble of 4"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164-Sentence-1641,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164-Sentence-1642,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164-Sentence-1643 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164-Sentence-1641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 3."@en ;
    askg-onto:inSentence "Table 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_3,
        askg-data:Entity-triples .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164-Sentence-1642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Highest ranking published image captioning results on the online MSCOCO test server."@en ;
    askg-onto:inSentence "Highest ranking published image captioning results on the online MSCOCO test server."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning_results,
        askg-data:Entity-mscoco .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-164-Sentence-1643 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our submission, an ensemble of 4"@en ;
    askg-onto:inSentence "Our submission, an ensemble of 4"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4,
        askg-data:Entity-submission .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-165 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![6_image_0.png](6_image_0.png) models optimized for CIDEr with different initializations, outperforms previously published work on all reported metrics. At the time of submission (18 July 2017), we also outperformed all unpublished test server submissions."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-165-Sentence-1651,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-165-Sentence-1652 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-165-Sentence-1651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_0.png](6_image_0.png) models optimized for CIDEr with different initializations, outperforms previously published work on all reported metrics."@en ;
    askg-onto:inSentence "![6_image_0.png](6_image_0.png) models optimized for CIDEr with different initializations, outperforms previously published work on all reported metrics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cider,
        askg-data:Entity-models,
        askg-data:Entity-previously_published_work .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-165-Sentence-1652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "At the time of submission (18 July 2017), we also outperformed all unpublished test server submissions."@en ;
    askg-onto:inSentence "At the time of submission (18 July 2017), we also outperformed all unpublished test server submissions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_test_server_submissions,
        askg-data:Entity-unpublished_test_server_submissions .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-166 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Two men playing frisbee in a dark field."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-166-Sentence-1661 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-166-Sentence-1661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Two men playing frisbee in a dark field."@en ;
    askg-onto:inSentence "Two men playing frisbee in a dark field."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-frisbee,
        askg-data:Entity-two_men .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Figure 5. Example of a generated caption showing attended image regions. For each generated word, we visualize the attention weights on individual pixels, outlining the region with the maximum attention weight in red. Avoiding the conventional trade-off between coarse and fine levels of detail, our model focuses on both closely-cropped details, such as the frisbee and the green player's mouthguard when generating the word 'playing', as well as large regions, such as the night sky when generating the word 'dark'."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1671,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1672,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1673,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1674 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 5."@en ;
    askg-onto:inSentence "Figure 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_5 .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1672 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Example of a generated caption showing attended image regions."@en ;
    askg-onto:inSentence "Example of a generated caption showing attended image regions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-caption,
        askg-data:Entity-image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1673 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For each generated word, we visualize the attention weights on individual pixels, outlining the region with the maximum attention weight in red."@en ;
    askg-onto:inSentence "For each generated word, we visualize the attention weights on individual pixels, outlining the region with the maximum attention weight in red."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_weights,
        askg-data:Entity-individual_pixels,
        askg-data:Entity-maximum_attention_weight,
        askg-data:Entity-region .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-167-Sentence-1674 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Avoiding the conventional trade-off between coarse and fine levels of detail, our model focuses on both closely-cropped details, such as the frisbee and the green player's mouthguard when generating the word 'playing', as well as large regions, such as the night sky when generating the word 'dark'."@en ;
    askg-onto:inSentence "Avoiding the conventional trade-off between coarse and fine levels of detail, our model focuses on both closely-cropped details, such as the frisbee and the green player's mouthguard when generating the word 'playing', as well as large regions, such as the night sky when generating the word 'dark'."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-closely-cropped_details,
        askg-data:Entity-coarse_and_fine_levels_of_detail,
        askg-data:Entity-dark,
        askg-data:Entity-frisbee,
        askg-data:Entity-green_players_mouthguard,
        askg-data:Entity-large_regions,
        askg-data:Entity-model,
        askg-data:Entity-night_sky,
        askg-data:Entity-playing .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-168 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "model (*Up-Down*) against prior work as well as an ablated baseline. In each case, the baseline (*ResNet*), uses a ResNet [13] CNN pretrained on ImageNet [35] to encode each image in place of the bottom-up attention mechanism."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-168-Sentence-1681,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-168-Sentence-1682 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-168-Sentence-1681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "model (*Up-Down*) against prior work as well as an ablated baseline."@en ;
    askg-onto:inSentence "model (*Up-Down*) against prior work as well as an ablated baseline."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-up-down .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-168-Sentence-1682 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In each case, the baseline (*ResNet*), uses a ResNet [13] CNN pretrained on ImageNet [35] to encode each image in place of the bottom-up attention mechanism."@en ;
    askg-onto:inSentence "In each case, the baseline (*ResNet*), uses a ResNet [13] CNN pretrained on ImageNet [35] to encode each image in place of the bottom-up attention mechanism."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-each_image,
        askg-data:Entity-imagenet,
        askg-data:Entity-resnet,
        askg-data:Entity-resnet_cnn .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "In image captioning experiments, similarly to previous work [34] we encode the full-sized input image with the final convolutional layer of Resnet-101, and use bilinear interpolation to resize the output to a fixed size spatial representation of 10×10. This is equivalent to the maximum number of spatial regions used in our full model. In VQA experiments, we encode the resized input image with ResNet-200 [14]. In separate experiments we use evaluate the effect of varying the size of the spatial output from its original size of 14×14, to 7×7 (using bilinear interpolation) and 1×1 (i.e., mean pooling without attention)."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1691,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1692,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1693,
        askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1694 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In image captioning experiments, similarly to previous work [34] we encode the full-sized input image with the final convolutional layer of Resnet-101, and use bilinear interpolation to resize the output to a fixed size spatial representation of 10×10."@en ;
    askg-onto:inSentence "In image captioning experiments, similarly to previous work [34] we encode the full-sized input image with the final convolutional layer of Resnet-101, and use bilinear interpolation to resize the output to a fixed size spatial representation of 10×10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bilinear_interpolation,
        askg-data:Entity-fixed_size_spatial_representation,
        askg-data:Entity-image_captioning_experiments,
        askg-data:Entity-previous_work,
        askg-data:Entity-resize,
        askg-data:Entity-resnet-101 .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1692 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This is equivalent to the maximum number of spatial regions used in our full model."@en ;
    askg-onto:inSentence "This is equivalent to the maximum number of spatial regions used in our full model."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-maximum_number_of_spatial_regions,
        askg-data:Entity-our_full_model .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1693 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In VQA experiments, we encode the resized input image with ResNet-200 [14]."@en ;
    askg-onto:inSentence "In VQA experiments, we encode the resized input image with ResNet-200 [14]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-resnet-200 .

askg-data:Paper-11712fbcb9a80fb4-Section-16-Paragraph-169-Sentence-1694 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In separate experiments we use evaluate the effect of varying the size of the spatial output from its original size of 14×14, to 7×7 (using bilinear interpolation) and 1×1 (i.e., mean pooling without attention)."@en ;
    askg-onto:inSentence "In separate experiments we use evaluate the effect of varying the size of the spatial output from its original size of 14×14, to 7×7 (using bilinear interpolation) and 1×1 (i.e., mean pooling without attention)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11,
        askg-data:Entity-1414,
        askg-data:Entity-77,
        askg-data:Entity-attention,
        askg-data:Entity-bilinear_interpolation,
        askg-data:Entity-mean_pooling,
        askg-data:Entity-spatial_output .

askg-data:Paper-11712fbcb9a80fb4-Section-17 a askg-onto:Section ;
    rdfs:label "Section 17"@en ;
    domo:Text "4.3. Image Captioning Results"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-173,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-174,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-177,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-178 ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Table 1 we report the performance of our full model and the ResNet baseline in comparison to the existing stateof-the-art Self-critical Sequence Training [34] (SCST) approach on the test portion of the Karpathy splits. For fair comparison, results are reported for models trained with both standard cross-entropy loss, and models optimized for CIDEr score. Note that the SCST approach uses ResNet101 encoding of full images, similar to our ResNet baseline. All results are reported for a single model with no fine-tuning of the input ResNet / R-CNN model. However, the SCST results are selected from the best of four random initializations, while our results are outcomes from a single initialization."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1711,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1712,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1713,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1714,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1715 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Table 1 we report the performance of our full model and the ResNet baseline in comparison to the existing stateof-the-art Self-critical Sequence Training [34] (SCST) approach on the test portion of the Karpathy splits."@en ;
    askg-onto:inSentence "In Table 1 we report the performance of our full model and the ResNet baseline in comparison to the existing stateof-the-art Self-critical Sequence Training [34] (SCST) approach on the test portion of the Karpathy splits."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-full_model,
        askg-data:Entity-karpathy_splits,
        askg-data:Entity-resnet_baseline,
        askg-data:Entity-self-critical_sequence_training .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For fair comparison, results are reported for models trained with both standard cross-entropy loss, and models optimized for CIDEr score."@en ;
    askg-onto:inSentence "For fair comparison, results are reported for models trained with both standard cross-entropy loss, and models optimized for CIDEr score."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cider_score,
        askg-data:Entity-models,
        askg-data:Entity-standard_cross-entropy_loss .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Note that the SCST approach uses ResNet101 encoding of full images, similar to our ResNet baseline."@en ;
    askg-onto:inSentence "Note that the SCST approach uses ResNet101 encoding of full images, similar to our ResNet baseline."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-resnet101_encoding,
        askg-data:Entity-resnet_baseline,
        askg-data:Entity-scst_approach .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "All results are reported for a single model with no fine-tuning of the input ResNet / R-CNN model."@en ;
    askg-onto:inSentence "All results are reported for a single model with no fine-tuning of the input ResNet / R-CNN model."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-resnet__r-cnn_model .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-171-Sentence-1715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "However, the SCST results are selected from the best of four random initializations, while our results are outcomes from a single initialization."@en ;
    askg-onto:inSentence "However, the SCST results are selected from the best of four random initializations, while our results are outcomes from a single initialization."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_single_initialization,
        askg-data:Entity-our_results,
        askg-data:Entity-scst_results,
        askg-data:Entity-the_best_of_four_random_initializations .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Relative to the SCST models, our ResNet baseline obtains slightly better performance under cross-entropy loss, and slightly worse performance when optimized for CIDEr score. After incorporating bottom-up attention, our full Up-Down model shows significant improvements across all metrics regardless of whether cross-entropy loss or CIDEr optimization is used. Using just a single model, we obtain the best reported results for the Karpathy test split. As illustrated in Table 2, the contribution from bottom-up attention is broadly based, illustrated by improved performance in"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1721,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1722,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1723,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1724 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Relative to the SCST models, our ResNet baseline obtains slightly better performance under cross-entropy loss, and slightly worse performance when optimized for CIDEr score."@en ;
    askg-onto:inSentence "Relative to the SCST models, our ResNet baseline obtains slightly better performance under cross-entropy loss, and slightly worse performance when optimized for CIDEr score."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-better_performance,
        askg-data:Entity-cider_score,
        askg-data:Entity-performance,
        askg-data:Entity-resnet_baseline,
        askg-data:Entity-worse_performance .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "After incorporating bottom-up attention, our full Up-Down model shows significant improvements across all metrics regardless of whether cross-entropy loss or CIDEr optimization is used."@en ;
    askg-onto:inSentence "After incorporating bottom-up attention, our full Up-Down model shows significant improvements across all metrics regardless of whether cross-entropy loss or CIDEr optimization is used."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cider_optimization,
        askg-data:Entity-cross-entropy_loss,
        askg-data:Entity-significant_improvements,
        askg-data:Entity-up-down_model .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Using just a single model, we obtain the best reported results for the Karpathy test split."@en ;
    askg-onto:inSentence "Using just a single model, we obtain the best reported results for the Karpathy test split."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_reported_results,
        askg-data:Entity-karpathy_test_split,
        askg-data:Entity-single_model,
        askg-data:Entity-test_split .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-172-Sentence-1724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As illustrated in Table 2, the contribution from bottom-up attention is broadly based, illustrated by improved performance in"@en ;
    askg-onto:inSentence "As illustrated in Table 2, the contribution from bottom-up attention is broadly based, illustrated by improved performance in"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-improved_performance .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-173 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "| | Yes/No | Number | Other | Overall | |----------------------|----------|----------|---------|-----------| | Ours: ResNet (1×1) | 76.0 | 36.5 | 46.8 | 56.3 | | Ours: ResNet (14×14) | 76.6 | 36.2 | 49.5 | 57.9 | | Ours: ResNet (7×7) | 77.6 | 37.7 | 51.5 | 59.4 | | Ours: Up\\-Down | 80.3 | 42.8 | 55.8 | 63.2 | | Relative Improvement | 3% | 14% | 8% | 6% |"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-173-Sentence-1731 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-173-Sentence-1731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | Yes/No | Number | Other | Overall | |----------------------|----------|----------|---------|-----------| | Ours: ResNet (1×1) | 76.0 | 36.5 | 46.8 | 56.3 | | Ours: ResNet (14×14) | 76.6 | 36.2 | 49.5 | 57.9 | | Ours: ResNet (7×7) | 77.6 | 37.7 | 51.5 | 59.4 | | Ours: Up\\-Down | 80.3 | 42.8 | 55.8 | 63.2 | | Relative Improvement | 3% | 14% | 8% | 6% |"@en ;
    askg-onto:inSentence "| | Yes/No | Number | Other | Overall | |----------------------|----------|----------|---------|-----------| | Ours: ResNet (1×1) | 76.0 | 36.5 | 46.8 | 56.3 | | Ours: ResNet (14×14) | 76.6 | 36.2 | 49.5 | 57.9 | | Ours: ResNet (7×7) | 77.6 | 37.7 | 51.5 | 59.4 | | Ours: Up\\-Down | 80.3 | 42.8 | 55.8 | 63.2 | | Relative Improvement | 3% | 14% | 8% | 6% |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-14,
        askg-data:Entity-3,
        askg-data:Entity-362,
        askg-data:Entity-365,
        askg-data:Entity-377,
        askg-data:Entity-428,
        askg-data:Entity-468,
        askg-data:Entity-495,
        askg-data:Entity-515,
        askg-data:Entity-558,
        askg-data:Entity-563,
        askg-data:Entity-579,
        askg-data:Entity-594,
        askg-data:Entity-6,
        askg-data:Entity-632,
        askg-data:Entity-760,
        askg-data:Entity-766,
        askg-data:Entity-776,
        askg-data:Entity-8,
        askg-data:Entity-803,
        askg-data:Entity-relative_improvement,
        askg-data:Entity-resnet_11,
        askg-data:Entity-resnet_1414,
        askg-data:Entity-resnet_77,
        askg-data:Entity-up-down .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-174 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "| | Yes/No | Number | Other | Overall | |-----------------------|----------|----------|---------|-----------| | Prior [12] | 61.20 | 0.36 | 1.17 | 25.98 | | Language\\-only [12] | 67.01 | 31.55 | 27.37 | 44.26 | | d\\-LSTM+n\\-I [26, 12] | 73.46 | 35.18 | 41.83 | 54.22 | | MCB [11, 12] | 78.82 | 38.28 | 53.36 | 62.27 | | UPMC\\-LIP6 | 82.07 | 41.06 | 57.12 | 65.71 | | Athena | 82.50 | 44.19 | 59.97 | 67.59 | | HDU\\-USYD\\-UNCC | 84.50 | 45.39 | 59.01 | 68.09 | | Ours: Up\\-Down | 86.60 | 48.64 | 61.15 | 70.34 |"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-174-Sentence-1741 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-174-Sentence-1741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | Yes/No | Number | Other | Overall | |-----------------------|----------|----------|---------|-----------| | Prior [12] | 61.20 | 0.36 | 1.17 | 25.98 | | Language\\-only [12] | 67.01 | 31.55 | 27.37 | 44.26 | | d\\-LSTM+n\\-I [26, 12] | 73.46 | 35.18 | 41.83 | 54.22 | | MCB [11, 12] | 78.82 | 38.28 | 53.36 | 62.27 | | UPMC\\-LIP6 | 82.07 | 41.06 | 57.12 | 65.71 | | Athena | 82.50 | 44.19 | 59.97 | 67.59 | | HDU\\-USYD\\-UNCC | 84.50 | 45.39 | 59.01 | 68.09 | | Ours: Up\\-Down | 86.60 | 48.64 | 61.15 | 70.34 |"@en ;
    askg-onto:inSentence "| | Yes/No | Number | Other | Overall | |-----------------------|----------|----------|---------|-----------| | Prior [12] | 61.20 | 0.36 | 1.17 | 25.98 | | Language\\-only [12] | 67.01 | 31.55 | 27.37 | 44.26 | | d\\-LSTM+n\\-I [26, 12] | 73.46 | 35.18 | 41.83 | 54.22 | | MCB [11, 12] | 78.82 | 38.28 | 53.36 | 62.27 | | UPMC\\-LIP6 | 82.07 | 41.06 | 57.12 | 65.71 | | Athena | 82.50 | 44.19 | 59.97 | 67.59 | | HDU\\-USYD\\-UNCC | 84.50 | 45.39 | 59.01 | 68.09 | | Ours: Up\\-Down | 86.60 | 48.64 | 61.15 | 70.34 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-athena,
        askg-data:Entity-d-lstmn-i,
        askg-data:Entity-hdu-usyd-uncc,
        askg-data:Entity-mcb,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-ours_up-down,
        askg-data:Entity-upmc-lip6 .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Table 4. Single-model performance on the VQA v2.0 validation set. The use of bottom-up attention in the Up-Down model provides a significant improvement over the best ResNet baseline across all question types, even though the ResNet baselines use almost twice as many convolutional layers."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175-Sentence-1751,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175-Sentence-1752,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175-Sentence-1753 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175-Sentence-1751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 4."@en ;
    askg-onto:inSentence "Table 4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-findings .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175-Sentence-1752 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Single-model performance on the VQA v2.0 validation set."@en ;
    askg-onto:inSentence "Single-model performance on the VQA v2.0 validation set."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-single-model,
        askg-data:Entity-vqa_v20_validation_set .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-175-Sentence-1753 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The use of bottom-up attention in the Up-Down model provides a significant improvement over the best ResNet baseline across all question types, even though the ResNet baselines use almost twice as many convolutional layers."@en ;
    askg-onto:inSentence "The use of bottom-up attention in the Up-Down model provides a significant improvement over the best ResNet baseline across all question types, even though the ResNet baselines use almost twice as many convolutional layers."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_layers,
        askg-data:Entity-resnet_baseline,
        askg-data:Entity-significant_improvement,
        askg-data:Entity-up-down_model .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Table 5. VQA v2.0 test-standard server accuracy as at 8 August 2017, ranking our submission against published and unpublished work for each question type. Our approach, an ensemble of 30 models, outperforms all other leaderboard entries."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176-Sentence-1761,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176-Sentence-1762,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176-Sentence-1763 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176-Sentence-1761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 5."@en ;
    askg-onto:inSentence "Table 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_5,
        askg-data:Entity-triples .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176-Sentence-1762 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "VQA v2.0 test-standard server accuracy as at 8 August 2017, ranking our submission against published and unpublished work for each question type."@en ;
    askg-onto:inSentence "VQA v2.0 test-standard server accuracy as at 8 August 2017, ranking our submission against published and unpublished work for each question type."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-each_question_type,
        askg-data:Entity-our_submission,
        askg-data:Entity-published_and_unpublished_work,
        askg-data:Entity-vqa_v20 .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-176-Sentence-1763 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our approach, an ensemble of 30 models, outperforms all other leaderboard entries."@en ;
    askg-onto:inSentence "Our approach, an ensemble of 30 models, outperforms all other leaderboard entries."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30_models,
        askg-data:Entity-all_other_leaderboard_entries,
        askg-data:Entity-our_approach .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-177 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "terms of identifying objects, object attributes and also the relationships between objects."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-177-Sentence-1771 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-177-Sentence-1771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "terms of identifying objects, object attributes and also the relationships between objects."@en ;
    askg-onto:inSentence "terms of identifying objects, object attributes and also the relationships between objects."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-object_attributes,
        askg-data:Entity-objects .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-178 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Table 3 reports the performance of 4 ensembled models trained with CIDEr optimization on the official MSCOCO evaluation server, along with the highest ranking previously published results. At the time of submission (18 July 2017), we outperform all other test server submissions on all reported evaluation metrics."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-178-Sentence-1781,
        askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-178-Sentence-1782 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-178-Sentence-1781 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 3 reports the performance of 4 ensembled models trained with CIDEr optimization on the official MSCOCO evaluation server, along with the highest ranking previously published results."@en ;
    askg-onto:inSentence "Table 3 reports the performance of 4 ensembled models trained with CIDEr optimization on the official MSCOCO evaluation server, along with the highest ranking previously published results."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4_ensembled_models,
        askg-data:Entity-cider_optimization,
        askg-data:Entity-mscoco_evaluation_server,
        askg-data:Entity-previously_published_results,
        askg-data:Entity-table_3 .

askg-data:Paper-11712fbcb9a80fb4-Section-17-Paragraph-178-Sentence-1782 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "At the time of submission (18 July 2017), we outperform all other test server submissions on all reported evaluation metrics."@en ;
    askg-onto:inSentence "At the time of submission (18 July 2017), we outperform all other test server submissions on all reported evaluation metrics."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_other_test_server_submissions,
        askg-data:Entity-we .

askg-data:Paper-11712fbcb9a80fb4-Section-18 a askg-onto:Section ;
    rdfs:label "Section 18"@en ;
    domo:Text "4.4. Vqa Results"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-182,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-183,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184 ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Table 4 we report the single model performance of our full Up-Down VQA model relative to several ResNet baselines on the VQA v2.0 validation set. The addition of bottom-up attention provides a significant improvement over the best ResNet baseline across all question types, even though the ResNet baseline uses approximately twice as many convolutional layers. Table 5 reports the performance of 30 ensembled models on the official VQA 2.0 test-standard evaluation server, along with the previously published baseline results and the highest ranking other entries. At the time of submission (8 August 2017), we outperform all other test server submissions. Our submission also achieved first place in the 2017 VQA Challenge."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1811,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1812,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1813,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1814,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1815 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Table 4 we report the single model performance of our full Up-Down VQA model relative to several ResNet baselines on the VQA v2.0 validation set."@en ;
    askg-onto:inSentence "In Table 4 we report the single model performance of our full Up-Down VQA model relative to several ResNet baselines on the VQA v2.0 validation set."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-resnet_baselines,
        askg-data:Entity-up-down_vqa_model,
        askg-data:Entity-vqa_v20_validation_set .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The addition of bottom-up attention provides a significant improvement over the best ResNet baseline across all question types, even though the ResNet baseline uses approximately twice as many convolutional layers."@en ;
    askg-onto:inSentence "The addition of bottom-up attention provides a significant improvement over the best ResNet baseline across all question types, even though the ResNet baseline uses approximately twice as many convolutional layers."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-resnet_baseline .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Table 5 reports the performance of 30 ensembled models on the official VQA 2.0 test-standard evaluation server, along with the previously published baseline results and the highest ranking other entries."@en ;
    askg-onto:inSentence "Table 5 reports the performance of 30 ensembled models on the official VQA 2.0 test-standard evaluation server, along with the previously published baseline results and the highest ranking other entries."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30_ensembled_models,
        askg-data:Entity-highest_ranking_other_entries,
        askg-data:Entity-previously_published_baseline_results,
        askg-data:Entity-vqa_20_test-standard_evaluation_server .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "At the time of submission (8 August 2017), we outperform all other test server submissions."@en ;
    askg-onto:inSentence "At the time of submission (8 August 2017), we outperform all other test server submissions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_other_test_server_submissions,
        askg-data:Entity-test_server_submissions .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-181-Sentence-1815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Our submission also achieved first place in the 2017 VQA Challenge."@en ;
    askg-onto:inSentence "Our submission also achieved first place in the 2017 VQA Challenge."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_place_in_the_2017_vqa_challenge,
        askg-data:Entity-submission .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-182 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Question: What room are they in? Answer: kitchen"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-182-Sentence-1821,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-182-Sentence-1822 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-182-Sentence-1821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Question: What room are they in?"@en ;
    askg-onto:inSentence "Question: What room are they in?"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-room,
        askg-data:Entity-they .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-182-Sentence-1822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Answer: kitchen"@en ;
    askg-onto:inSentence "Answer: kitchen"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitchen,
        askg-data:Entity-room .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-183 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-183-Sentence-1831 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-183-Sentence-1831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:inSentence "![7_image_0.png](7_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-paper,
        askg-data:Entity-platform,
        askg-data:Entity-rate,
        askg-data:Entity-research_group,
        askg-data:Entity-study,
        askg-data:Entity-system,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Figure 6. VQA example illustrating attention output. Given the question 'What room are they in?', the model focuses on the stovetop, generating the answer 'kitchen'."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184-Sentence-1841,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184-Sentence-1842,
        askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184-Sentence-1843 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184-Sentence-1841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 6."@en ;
    askg-onto:inSentence "Figure 6."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_6 .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184-Sentence-1842 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "VQA example illustrating attention output."@en ;
    askg-onto:inSentence "VQA example illustrating attention output."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_output,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-18-Paragraph-184-Sentence-1843 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Given the question 'What room are they in?', the model focuses on the stovetop, generating the answer 'kitchen'."@en ;
    askg-onto:inSentence "Given the question 'What room are they in?', the model focuses on the stovetop, generating the answer 'kitchen'."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitchen,
        askg-data:Entity-model,
        askg-data:Entity-stovetop .

askg-data:Paper-11712fbcb9a80fb4-Section-19 a askg-onto:Section ;
    rdfs:label "Section 19"@en ;
    domo:Text "4.5. Qualitative Analysis"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191,
        askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192 ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To help qualitatively evaluate our attention methodology, in Figure 5 we visualize the attended image regions for different words generated by our Up-Down captioning model. As indicated by this example, our approach is equally capable of focusing on fine details or large image regions. This capability arises because the attention candidates in our model consist of many overlapping regions with varying scales and aspect ratios - each aligned to an object, several related objects, or an otherwise salient image patch."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191-Sentence-1911,
        askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191-Sentence-1912,
        askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191-Sentence-1913 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191-Sentence-1911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To help qualitatively evaluate our attention methodology, in Figure 5 we visualize the attended image regions for different words generated by our Up-Down captioning model."@en ;
    askg-onto:inSentence "To help qualitatively evaluate our attention methodology, in Figure 5 we visualize the attended image regions for different words generated by our Up-Down captioning model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attended_image_regions,
        askg-data:Entity-up-down_captioning_model .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191-Sentence-1912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As indicated by this example, our approach is equally capable of focusing on fine details or large image regions."@en ;
    askg-onto:inSentence "As indicated by this example, our approach is equally capable of focusing on fine details or large image regions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fine_details_or_large_image_regions,
        askg-data:Entity-our_approach .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-191-Sentence-1913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This capability arises because the attention candidates in our model consist of many overlapping regions with varying scales and aspect ratios - each aligned to an object, several related objects, or an otherwise salient image patch."@en ;
    askg-onto:inSentence "This capability arises because the attention candidates in our model consist of many overlapping regions with varying scales and aspect ratios - each aligned to an object, several related objects, or an otherwise salient image patch."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_otherwise_salient_image_patch,
        askg-data:Entity-attention_candidates,
        askg-data:Entity-many_overlapping_regions,
        askg-data:Entity-regions .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Unlike conventional approaches, when a candidate attention region corresponds to an object, or several related objects, all the visual concepts associated with those objects appear to be spatially co-located - and are processed together. In other words, our approach is able to consider all of the information pertaining to an object at once. This is also a natural way for attention to be implemented. In the human visual system, the problem of integrating the separate features of objects in the correct combinations is known as the feature binding problem, and experiments suggest that attention plays a central role in the solution [41, 40]. We include an example of VQA attention in Figure 6."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1921,
        askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1922,
        askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1923,
        askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1924,
        askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1925 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Unlike conventional approaches, when a candidate attention region corresponds to an object, or several related objects, all the visual concepts associated with those objects appear to be spatially co-located - and are processed together."@en ;
    askg-onto:inSentence "Unlike conventional approaches, when a candidate attention region corresponds to an object, or several related objects, all the visual concepts associated with those objects appear to be spatially co-located - and are processed together."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-candidate_attention_region,
        askg-data:Entity-object,
        askg-data:Entity-objects,
        askg-data:Entity-related_objects,
        askg-data:Entity-spatially_co-located,
        askg-data:Entity-visual_concepts .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In other words, our approach is able to consider all of the information pertaining to an object at once."@en ;
    askg-onto:inSentence "In other words, our approach is able to consider all of the information pertaining to an object at once."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-information .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This is also a natural way for attention to be implemented."@en ;
    askg-onto:inSentence "This is also a natural way for attention to be implemented."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-natural_way .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1924 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In the human visual system, the problem of integrating the separate features of objects in the correct combinations is known as the feature binding problem, and experiments suggest that attention plays a central role in the solution [41, 40]."@en ;
    askg-onto:inSentence "In the human visual system, the problem of integrating the separate features of objects in the correct combinations is known as the feature binding problem, and experiments suggest that attention plays a central role in the solution [41, 40]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-feature_binding_problem,
        askg-data:Entity-human_visual_system .

askg-data:Paper-11712fbcb9a80fb4-Section-19-Paragraph-192-Sentence-1925 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We include an example of VQA attention in Figure 6."@en ;
    askg-onto:inSentence "We include an example of VQA attention in Figure 6."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-vqa_attention .

askg-data:Paper-11712fbcb9a80fb4-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "Abstract"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-21,
        askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "![0_Image_0.Png](0_Image_0.Png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-21-Sentence-211 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![0_Image_0.Png](0_Image_0.Png)"@en ;
    askg-onto:inSentence "![0_Image_0.Png](0_Image_0.Png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-city,
        askg-data:Entity-database,
        askg-data:Entity-dataset,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning. In this work, we propose a combined bottom-up and topdown attention mechanism that enables attention to be calculated at the level of objects and other salient image regions. This is the natural basis for attention to be considered. Within our approach, the bottom-up mechanism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while the top-down mechanism determines feature weightings. Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively. Demonstrating the broad applicability of the method, applying the same approach to VQA we obtain first place in the 2017 VQA Challenge."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-221,
        askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-222,
        askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-223,
        askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-224,
        askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-225,
        askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-226 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning."@en ;
    askg-onto:inSentence "Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deeper_image_understanding,
        askg-data:Entity-fine-grained_analysis,
        askg-data:Entity-image_captioning,
        askg-data:Entity-multiple_steps_of_reasoning,
        askg-data:Entity-top-down_visual_attention_mechanisms,
        askg-data:Entity-visual_question_answering_vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In this work, we propose a combined bottom-up and topdown attention mechanism that enables attention to be calculated at the level of objects and other salient image regions."@en ;
    askg-onto:inSentence "In this work, we propose a combined bottom-up and topdown attention mechanism that enables attention to be calculated at the level of objects and other salient image regions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_to_be_calculated_at_the_level_of_objects_and_other_salient_image_regions,
        askg-data:Entity-combined_bottom-up_and_topdown_attention_mechanism .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This is the natural basis for attention to be considered."@en ;
    askg-onto:inSentence "This is the natural basis for attention to be considered."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-considered .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Within our approach, the bottom-up mechanism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while the top-down mechanism determines feature weightings."@en ;
    askg-onto:inSentence "Within our approach, the bottom-up mechanism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while the top-down mechanism determines feature weightings."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_mechanism,
        askg-data:Entity-faster_r-cnn,
        askg-data:Entity-feature_weightings,
        askg-data:Entity-top-down_mechanism .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively."@en ;
    askg-onto:inSentence "Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1179_215_and_369,
        askg-data:Entity-cider__spice__bleu-4,
        askg-data:Entity-cider__spice__bleu-4_scores,
        askg-data:Entity-image_captioning,
        askg-data:Entity-mscoco_test_server,
        askg-data:Entity-new_state-of-the-art,
        askg-data:Entity-scores .

askg-data:Paper-11712fbcb9a80fb4-Section-2-Paragraph-22-Sentence-226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Demonstrating the broad applicability of the method, applying the same approach to VQA we obtain first place in the 2017 VQA Challenge."@en ;
    askg-onto:inSentence "Demonstrating the broad applicability of the method, applying the same approach to VQA we obtain first place in the 2017 VQA Challenge."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_place_in_the_2017_vqa_challenge,
        askg-data:Entity-method,
        askg-data:Entity-vqa,
        askg-data:Entity-we .

askg-data:Paper-11712fbcb9a80fb4-Section-20 a askg-onto:Section ;
    rdfs:label "Section 20"@en ;
    domo:Text "5. Conclusion"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201,
        askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-202 ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We present a novel combined bottom-up and top-down visual attention mechanism. Our approach enables attention to be calculated more naturally at the level of objects and other salient regions. Applying this approach to image captioning and visual question answering, we achieve state-of-the-art results in both tasks, while improving the interpretability of the resulting attention weights."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201-Sentence-2011,
        askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201-Sentence-2012,
        askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201-Sentence-2013 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201-Sentence-2011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We present a novel combined bottom-up and top-down visual attention mechanism."@en ;
    askg-onto:inSentence "We present a novel combined bottom-up and top-down visual attention mechanism."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-combined_bottom-up_and_top-down_visual_attention_mechanism,
        askg-data:Entity-visual_attention_mechanism .

askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201-Sentence-2012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Our approach enables attention to be calculated more naturally at the level of objects and other salient regions."@en ;
    askg-onto:inSentence "Our approach enables attention to be calculated more naturally at the level of objects and other salient regions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-attention .

askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-201-Sentence-2013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Applying this approach to image captioning and visual question answering, we achieve state-of-the-art results in both tasks, while improving the interpretability of the resulting attention weights."@en ;
    askg-onto:inSentence "Applying this approach to image captioning and visual question answering, we achieve state-of-the-art results in both tasks, while improving the interpretability of the resulting attention weights."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-interpretability,
        askg-data:Entity-state-of-the-art_results,
        askg-data:Entity-the_resulting_attention_weights,
        askg-data:Entity-this_approach,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-202 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "At a high level, our work more closely unifies tasks involving visual and linguistic understanding with recent progress in object detection. While this suggests several directions for future research, the immediate benefits of our approach may be captured by simply replacing pretrained CNN features with pretrained bottom-up attention features."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-202-Sentence-2021,
        askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-202-Sentence-2022 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-202-Sentence-2021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "At a high level, our work more closely unifies tasks involving visual and linguistic understanding with recent progress in object detection."@en ;
    askg-onto:inSentence "At a high level, our work more closely unifies tasks involving visual and linguistic understanding with recent progress in object detection."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-object_detection,
        askg-data:Entity-our_work,
        askg-data:Entity-recent_progress,
        askg-data:Entity-tasks_involving_visual_and_linguistic_understanding .

askg-data:Paper-11712fbcb9a80fb4-Section-20-Paragraph-202-Sentence-2022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While this suggests several directions for future research, the immediate benefits of our approach may be captured by simply replacing pretrained CNN features with pretrained bottom-up attention features."@en ;
    askg-onto:inSentence "While this suggests several directions for future research, the immediate benefits of our approach may be captured by simply replacing pretrained CNN features with pretrained bottom-up attention features."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pretrained_bottom-up_attention_features,
        askg-data:Entity-pretrained_cnn_features .

askg-data:Paper-11712fbcb9a80fb4-Section-21 a askg-onto:Section ;
    rdfs:label "Section 21"@en ;
    domo:Text "Acknowledgements"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-21-Paragraph-211 ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-21-Paragraph-211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "This research is partially supported by an Australian Government Research Training Program (RTP) Scholarship, by the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016), by a Google award through the Natural Language Understanding Focused Program, and under the Australian Research Councils Discovery Projects funding scheme (project number DP160102156)."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-21-Paragraph-211-Sentence-2111 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-21-Paragraph-211-Sentence-2111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This research is partially supported by an Australian Government Research Training Program (RTP) Scholarship, by the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016), by a Google award through the Natural Language Understanding Focused Program, and under the Australian Research Councils Discovery Projects funding scheme (project number DP160102156)."@en ;
    askg-onto:inSentence "This research is partially supported by an Australian Government Research Training Program (RTP) Scholarship, by the Australian Research Council Centre of Excellence for Robotic Vision (project number CE140100016), by a Google award through the Natural Language Understanding Focused Program, and under the Australian Research Councils Discovery Projects funding scheme (project number DP160102156)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australian_research_council_centre_of_excellence_for_robotic_vision,
        askg-data:Entity-australian_research_councils_discovery_projects_funding_scheme,
        askg-data:Entity-google,
        askg-data:Entity-research .

askg-data:Paper-11712fbcb9a80fb4-Section-22 a askg-onto:Section ;
    rdfs:label "Section 22"@en ;
    domo:Text "References"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228 ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "[1] P. Anderson, B. Fernando, M. Johnson, and S. Gould."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2211,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2212,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2213,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2214,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2215 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[1] P."@en ;
    askg-onto:inSentence "[1] P."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Anderson, B."@en ;
    askg-onto:inSentence "Anderson, B."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anderson_b,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Fernando, M."@en ;
    askg-onto:inSentence "Fernando, M."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_scientist,
        askg-data:Entity-fernando_m .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Johnson, and S."@en ;
    askg-onto:inSentence "Johnson, and S."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-johnson,
        askg-data:Entity-person,
        askg-data:Entity-s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-221-Sentence-2215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Gould."@en ;
    askg-onto:inSentence "Gould."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gould,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "SPICE: Semantic propositional image caption evaluation. In ECCV, 2016. 6 [2] S. Antol, A. Agrawal, J. Lu, M. Mitchell, D. Batra, C. L."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2221,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2222,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2223,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2224,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2225,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2226,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2227,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2228,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2229 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "SPICE: Semantic propositional image caption evaluation."@en ;
    askg-onto:inSentence "SPICE: Semantic propositional image caption evaluation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-semantic_propositional_image_caption_evaluation,
        askg-data:Entity-spice .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In ECCV, 2016."@en ;
    askg-onto:inSentence "In ECCV, 2016."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-eccv,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "6 [2] S."@en ;
    askg-onto:inSentence "6 [2] S."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Antol, A."@en ;
    askg-onto:inSentence "Antol, A."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-antol_a,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Agrawal, J."@en ;
    askg-onto:inSentence "Agrawal, J."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-agrawal_j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Lu, M."@en ;
    askg-onto:inSentence "Lu, M."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lu_m,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2227 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Mitchell, D."@en ;
    askg-onto:inSentence "Mitchell, D."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mitchell_d,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2228 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Batra, C."@en ;
    askg-onto:inSentence "Batra, C."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batra_c,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-222-Sentence-2229 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Zitnick, and D. Parikh. VQA: Visual Question Answering. In ICCV, 2015. 6 [3] T. J. Buschman and E. K. Miller. Top-down versus bottomup control of attention in the prefrontal and posterior parietal cortices. *Science*, 315(5820):1860–1862, 2007. 1 [4] X. Chen, T.-Y. L. Hao Fang, R. Vedantam, S. Gupta, P. Dollar, and C. L. Zitnick. Microsoft COCO captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325, 2015. 1 [5] K. Cho, B. van Merrienboer, C. Gulcehre, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In *EMNLP*, 2014. 5 [6] M. Corbetta and G. L. Shulman. Control of goal-directed and stimulus-driven attention in the brain. *Nature Reviews* Neuroscience, 3(3):201–215, 2002. 1 [7] Y. N. Dauphin, A. Fan, M. Auli, and D. Grangier. Language modeling with gated convolutional networks. arXiv preprint arXiv:1612.08083, 2016. 5 [8] M. Denkowski and A. Lavie. Meteor Universal: Language Specific Translation Evaluation for Any Target Language. In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation, 2014. 6 [9] J. Donahue, L. A. Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell. Long-term recurrent convolutional networks for visual recognition and description. In *CVPR*, 2015. 3 [10] R. Egly, J. Driver, and R. D. Rafal. Shifting visual attention between objects and locations: evidence from normal and parietal lesion subjects. Journal of Experimental Psychology: General, 123(2):161, 1994. 2 [11] A. Fukui, D. H. Park, D. Yang, A. Rohrbach, T. Darrell, and M. Rohrbach. Multimodal compact bilinear pooling for visual question answering and visual grounding. In *EMNLP*, 2016. 1, 2, 8 [12] Y. Goyal, T. Khot, D. Summers-Stay, D. Batra, and D. Parikh. Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering. In CVPR, 2017. 1, 6, 8 [13] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016. 3, 7 [14] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. *arXiv preprint arXiv:1603.05027*, 2016. 7 [15] S. Hochreiter and J. Schmidhuber. Long short-term memory."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2231,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22310,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223100,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223101,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223102,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223103,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223104,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22311,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22312,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22313,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22314,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22315,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22316,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22317,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22318,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22319,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2232,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22320,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22321,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22322,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22323,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22324,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22325,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22326,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22327,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22328,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22329,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2233,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22330,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22331,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22332,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22333,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22334,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22335,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22336,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22337,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22338,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22339,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2234,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22340,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22341,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22342,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22343,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22344,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22345,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22346,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22347,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22348,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22349,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2235,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22350,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22351,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22352,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22353,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22354,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22355,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22356,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22357,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22358,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22359,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2236,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22360,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22361,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22362,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22363,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22364,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22365,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22366,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22367,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22368,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22369,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2237,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22370,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22371,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22372,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22373,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22374,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22375,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22376,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22377,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22378,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22379,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2238,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22380,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22381,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22382,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22383,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22384,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22385,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22386,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22387,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22388,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22389,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2239,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22390,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22391,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22392,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22393,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22394,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22395,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22396,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22397,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22398,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22399 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zitnick, and D."@en ;
    askg-onto:inSentence "Zitnick, and D."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-person,
        askg-data:Entity-zitnick .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Top-down versus bottomup control of attention in the prefrontal and posterior parietal cortices."@en ;
    askg-onto:inSentence "Top-down versus bottomup control of attention in the prefrontal and posterior parietal cortices."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-bottom-up_control,
        askg-data:Entity-posterior_parietal_cortex,
        askg-data:Entity-prefrontal_cortex,
        askg-data:Entity-top-down_control .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223100 a askg-onto:Sentence ;
    rdfs:label "Sentence 100"@en ;
    domo:Text "*arXiv preprint arXiv:1603.05027*, 2016."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1603.05027*, 2016."^^xsd:string ;
    askg-onto:index "100"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv160305027,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223101 a askg-onto:Sentence ;
    rdfs:label "Sentence 101"@en ;
    domo:Text "7 [15] S."@en ;
    askg-onto:inSentence "7 [15] S."^^xsd:string ;
    askg-onto:index "101"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7_15,
        askg-data:Entity-s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223102 a askg-onto:Sentence ;
    rdfs:label "Sentence 102"@en ;
    domo:Text "Hochreiter and J."@en ;
    askg-onto:inSentence "Hochreiter and J."^^xsd:string ;
    askg-onto:index "102"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hochreiter,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223103 a askg-onto:Sentence ;
    rdfs:label "Sentence 103"@en ;
    domo:Text "Schmidhuber."@en ;
    askg-onto:inSentence "Schmidhuber."^^xsd:string ;
    askg-onto:index "103"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_scientist,
        askg-data:Entity-schmidhuber .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-223104 a askg-onto:Sentence ;
    rdfs:label "Sentence 104"@en ;
    domo:Text "Long short-term memory."@en ;
    askg-onto:inSentence "Long short-term memory."^^xsd:string ;
    askg-onto:index "104"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-long_short-term_memory,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "*Science*, 315(5820):1860–1862, 2007."@en ;
    askg-onto:inSentence "*Science*, 315(5820):1860–1862, 2007."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-315582018601862_2007,
        askg-data:Entity-science .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "1 [4] X."@en ;
    askg-onto:inSentence "1 [4] X."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_area,
        askg-data:Entity-x .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Chen, T.-Y."@en ;
    askg-onto:inSentence "Chen, T.-Y."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chen_t-y,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22314 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l,
        askg-data:Entity-unknown_concept .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22315 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Hao Fang, R."@en ;
    askg-onto:inSentence "Hao Fang, R."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hao_fang_r,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22316 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Vedantam, S."@en ;
    askg-onto:inSentence "Vedantam, S."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-vedantam_s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22317 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Gupta, P."@en ;
    askg-onto:inSentence "Gupta, P."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gupta_p,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22318 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Dollar, and C."@en ;
    askg-onto:inSentence "Dollar, and C."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-dollar,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22319 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Parikh."@en ;
    askg-onto:inSentence "Parikh."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-parikh,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22320 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Zitnick."@en ;
    askg-onto:inSentence "Zitnick."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-zitnick .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22321 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Microsoft COCO captions: Data collection and evaluation server."@en ;
    askg-onto:inSentence "Microsoft COCO captions: Data collection and evaluation server."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_collection_and_evaluation_server,
        askg-data:Entity-microsoft_coco_captions .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22322 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "arXiv preprint arXiv:1504.00325, 2015."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1504.00325, 2015."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-arxiv150400325,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication,
        askg-data:Entity-year .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22323 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "1 [5] K."@en ;
    askg-onto:inSentence "1 [5] K."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5,
        askg-data:Entity-k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22324 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Cho, B."@en ;
    askg-onto:inSentence "Cho, B."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cho_b,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22325 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "van Merrienboer, C."@en ;
    askg-onto:inSentence "van Merrienboer, C."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-van_merrienboer_c .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22326 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Gulcehre, F."@en ;
    askg-onto:inSentence "Gulcehre, F."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gulcehre_f,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22327 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Bougares, H."@en ;
    askg-onto:inSentence "Bougares, H."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bougares_h,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22328 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "Schwenk, and Y."@en ;
    askg-onto:inSentence "Schwenk, and Y."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-schwenk,
        askg-data:Entity-y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22329 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Bengio."@en ;
    askg-onto:inSentence "Bengio."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bengio,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "VQA: Visual Question Answering."@en ;
    askg-onto:inSentence "VQA: Visual Question Answering."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-visual_question_answering,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22330 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "Learning phrase representations using RNN encoder-decoder for statistical machine translation."@en ;
    askg-onto:inSentence "Learning phrase representations using RNN encoder-decoder for statistical machine translation."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rnn_encoder-decoder,
        askg-data:Entity-statistical_machine_translation .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22331 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "In *EMNLP*, 2014."@en ;
    askg-onto:inSentence "In *EMNLP*, 2014."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-emnlp,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22332 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "5 [6] M."@en ;
    askg-onto:inSentence "5 [6] M."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-m,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22333 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "Corbetta and G."@en ;
    askg-onto:inSentence "Corbetta and G."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-corbetta,
        askg-data:Entity-g,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22334 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22335 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Shulman."@en ;
    askg-onto:inSentence "Shulman."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-shulman .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22336 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "Control of goal-directed and stimulus-driven attention in the brain."@en ;
    askg-onto:inSentence "Control of goal-directed and stimulus-driven attention in the brain."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control_of_goal-directed_and_stimulus-driven_attention .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22337 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "*Nature Reviews* Neuroscience, 3(3):201–215, 2002."@en ;
    askg-onto:inSentence "*Nature Reviews* Neuroscience, 3(3):201–215, 2002."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-33201215,
        askg-data:Entity-nature_reviews,
        askg-data:Entity-neuroscience,
        askg-data:Entity-publication,
        askg-data:Entity-research_area .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22338 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "1 [7] Y."@en ;
    askg-onto:inSentence "1 [7] Y."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7,
        askg-data:Entity-y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22339 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "N."@en ;
    askg-onto:inSentence "N."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2234 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In ICCV, 2015."@en ;
    askg-onto:inSentence "In ICCV, 2015."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-iccv .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22340 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "Dauphin, A."@en ;
    askg-onto:inSentence "Dauphin, A."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dauphin_a,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22341 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Fan, M."@en ;
    askg-onto:inSentence "Fan, M."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fan_m,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22342 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "Auli, and D."@en ;
    askg-onto:inSentence "Auli, and D."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-auli,
        askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22343 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "Grangier."@en ;
    askg-onto:inSentence "Grangier."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-grangier,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22344 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "Language modeling with gated convolutional networks."@en ;
    askg-onto:inSentence "Language modeling with gated convolutional networks."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gated_convolutional_networks,
        askg-data:Entity-language_modeling .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22345 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "arXiv preprint arXiv:1612.08083, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1612.08083, 2016."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-arxiv161208083,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication,
        askg-data:Entity-year .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22346 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "5 [8] M."@en ;
    askg-onto:inSentence "5 [8] M."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_8,
        askg-data:Entity-m .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22347 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "Denkowski and A."@en ;
    askg-onto:inSentence "Denkowski and A."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-denkowski,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22348 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "Lavie."@en ;
    askg-onto:inSentence "Lavie."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lavie,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22349 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "Meteor Universal: Language Specific Translation Evaluation for Any Target Language."@en ;
    askg-onto:inSentence "Meteor Universal: Language Specific Translation Evaluation for Any Target Language."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_target_language,
        askg-data:Entity-language,
        askg-data:Entity-language_specific_translation_evaluation,
        askg-data:Entity-meteor_universal,
        askg-data:Entity-method,
        askg-data:Entity-platform .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2235 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "6 [3] T."@en ;
    askg-onto:inSentence "6 [3] T."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6,
        askg-data:Entity-t .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22350 a askg-onto:Sentence ;
    rdfs:label "Sentence 50"@en ;
    domo:Text "In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation, 2014."@en ;
    askg-onto:inSentence "In Proceedings of the EACL 2014 Workshop on Statistical Machine Translation, 2014."^^xsd:string ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eacl_2014_workshop_on_statistical_machine_translation,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22351 a askg-onto:Sentence ;
    rdfs:label "Sentence 51"@en ;
    domo:Text "6 [9] J."@en ;
    askg-onto:inSentence "6 [9] J."^^xsd:string ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6_9,
        askg-data:Entity-j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22352 a askg-onto:Sentence ;
    rdfs:label "Sentence 52"@en ;
    domo:Text "Donahue, L."@en ;
    askg-onto:inSentence "Donahue, L."^^xsd:string ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-donahue_l,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22353 a askg-onto:Sentence ;
    rdfs:label "Sentence 53"@en ;
    domo:Text "A."@en ;
    askg-onto:inSentence "A."^^xsd:string ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-framework,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22354 a askg-onto:Sentence ;
    rdfs:label "Sentence 54"@en ;
    domo:Text "Hendricks, S."@en ;
    askg-onto:inSentence "Hendricks, S."^^xsd:string ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hendricks_s,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22355 a askg-onto:Sentence ;
    rdfs:label "Sentence 55"@en ;
    domo:Text "Guadarrama, M."@en ;
    askg-onto:inSentence "Guadarrama, M."^^xsd:string ;
    askg-onto:index "55"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guadarrama_m,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22356 a askg-onto:Sentence ;
    rdfs:label "Sentence 56"@en ;
    domo:Text "Rohrbach, S."@en ;
    askg-onto:inSentence "Rohrbach, S."^^xsd:string ;
    askg-onto:index "56"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rohrbach_s,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22357 a askg-onto:Sentence ;
    rdfs:label "Sentence 57"@en ;
    domo:Text "Venugopalan, K."@en ;
    askg-onto:inSentence "Venugopalan, K."^^xsd:string ;
    askg-onto:index "57"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-venugopalan_k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22358 a askg-onto:Sentence ;
    rdfs:label "Sentence 58"@en ;
    domo:Text "Saenko, and T."@en ;
    askg-onto:inSentence "Saenko, and T."^^xsd:string ;
    askg-onto:index "58"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-saenko,
        askg-data:Entity-t .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22359 a askg-onto:Sentence ;
    rdfs:label "Sentence 59"@en ;
    domo:Text "Darrell."@en ;
    askg-onto:inSentence "Darrell."^^xsd:string ;
    askg-onto:index "59"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-darrell,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2236 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "J."@en ;
    askg-onto:inSentence "J."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22360 a askg-onto:Sentence ;
    rdfs:label "Sentence 60"@en ;
    domo:Text "Long-term recurrent convolutional networks for visual recognition and description."@en ;
    askg-onto:inSentence "Long-term recurrent convolutional networks for visual recognition and description."^^xsd:string ;
    askg-onto:index "60"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-long-term_recurrent_convolutional_networks,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22361 a askg-onto:Sentence ;
    rdfs:label "Sentence 61"@en ;
    domo:Text "In *CVPR*, 2015."@en ;
    askg-onto:inSentence "In *CVPR*, 2015."^^xsd:string ;
    askg-onto:index "61"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22362 a askg-onto:Sentence ;
    rdfs:label "Sentence 62"@en ;
    domo:Text "3 [10] R."@en ;
    askg-onto:inSentence "3 [10] R."^^xsd:string ;
    askg-onto:index "62"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_10,
        askg-data:Entity-r .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22363 a askg-onto:Sentence ;
    rdfs:label "Sentence 63"@en ;
    domo:Text "Egly, J."@en ;
    askg-onto:inSentence "Egly, J."^^xsd:string ;
    askg-onto:index "63"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-egly_j,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22364 a askg-onto:Sentence ;
    rdfs:label "Sentence 64"@en ;
    domo:Text "Driver, and R."@en ;
    askg-onto:inSentence "Driver, and R."^^xsd:string ;
    askg-onto:index "64"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-driver,
        askg-data:Entity-person,
        askg-data:Entity-r,
        askg-data:Entity-software .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22365 a askg-onto:Sentence ;
    rdfs:label "Sentence 65"@en ;
    domo:Text "D."@en ;
    askg-onto:inSentence "D."^^xsd:string ;
    askg-onto:index "65"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22366 a askg-onto:Sentence ;
    rdfs:label "Sentence 66"@en ;
    domo:Text "Rafal."@en ;
    askg-onto:inSentence "Rafal."^^xsd:string ;
    askg-onto:index "66"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-rafal .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22367 a askg-onto:Sentence ;
    rdfs:label "Sentence 67"@en ;
    domo:Text "Shifting visual attention between objects and locations: evidence from normal and parietal lesion subjects."@en ;
    askg-onto:inSentence "Shifting visual attention between objects and locations: evidence from normal and parietal lesion subjects."^^xsd:string ;
    askg-onto:index "67"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-normal_and_parietal_lesion_subjects,
        askg-data:Entity-visual_attention .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22368 a askg-onto:Sentence ;
    rdfs:label "Sentence 68"@en ;
    domo:Text "Journal of Experimental Psychology: General, 123(2):161, 1994."@en ;
    askg-onto:inSentence "Journal of Experimental Psychology: General, 123(2):161, 1994."^^xsd:string ;
    askg-onto:index "68"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-123,
        askg-data:Entity-161,
        askg-data:Entity-1994,
        askg-data:Entity-2,
        askg-data:Entity-journal_of_experimental_psychology_general,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22369 a askg-onto:Sentence ;
    rdfs:label "Sentence 69"@en ;
    domo:Text "2 [11] A."@en ;
    askg-onto:inSentence "2 [11] A."^^xsd:string ;
    askg-onto:index "69"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2237 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Buschman and E."@en ;
    askg-onto:inSentence "Buschman and E."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-buschman,
        askg-data:Entity-e,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22370 a askg-onto:Sentence ;
    rdfs:label "Sentence 70"@en ;
    domo:Text "Fukui, D."@en ;
    askg-onto:inSentence "Fukui, D."^^xsd:string ;
    askg-onto:index "70"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fukui_d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22371 a askg-onto:Sentence ;
    rdfs:label "Sentence 71"@en ;
    domo:Text "H."@en ;
    askg-onto:inSentence "H."^^xsd:string ;
    askg-onto:index "71"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22372 a askg-onto:Sentence ;
    rdfs:label "Sentence 72"@en ;
    domo:Text "Park, D."@en ;
    askg-onto:inSentence "Park, D."^^xsd:string ;
    askg-onto:index "72"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-park_d,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22373 a askg-onto:Sentence ;
    rdfs:label "Sentence 73"@en ;
    domo:Text "Yang, A."@en ;
    askg-onto:inSentence "Yang, A."^^xsd:string ;
    askg-onto:index "73"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-yang_a .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22374 a askg-onto:Sentence ;
    rdfs:label "Sentence 74"@en ;
    domo:Text "Rohrbach, T."@en ;
    askg-onto:inSentence "Rohrbach, T."^^xsd:string ;
    askg-onto:index "74"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rohrbach_t,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22375 a askg-onto:Sentence ;
    rdfs:label "Sentence 75"@en ;
    domo:Text "Darrell, and M."@en ;
    askg-onto:inSentence "Darrell, and M."^^xsd:string ;
    askg-onto:index "75"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-darrell,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22376 a askg-onto:Sentence ;
    rdfs:label "Sentence 76"@en ;
    domo:Text "Rohrbach."@en ;
    askg-onto:inSentence "Rohrbach."^^xsd:string ;
    askg-onto:index "76"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rohrbach,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22377 a askg-onto:Sentence ;
    rdfs:label "Sentence 77"@en ;
    domo:Text "Multimodal compact bilinear pooling for visual question answering and visual grounding."@en ;
    askg-onto:inSentence "Multimodal compact bilinear pooling for visual question answering and visual grounding."^^xsd:string ;
    askg-onto:index "77"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-multimodal_compact_bilinear_pooling,
        askg-data:Entity-visual_grounding,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22378 a askg-onto:Sentence ;
    rdfs:label "Sentence 78"@en ;
    domo:Text "In *EMNLP*, 2016."@en ;
    askg-onto:inSentence "In *EMNLP*, 2016."^^xsd:string ;
    askg-onto:index "78"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-emnlp .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22379 a askg-onto:Sentence ;
    rdfs:label "Sentence 79"@en ;
    domo:Text "1, 2, 8 [12] Y."@en ;
    askg-onto:inSentence "1, 2, 8 [12] Y."^^xsd:string ;
    askg-onto:index "79"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_8_12,
        askg-data:Entity-y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2238 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "K."@en ;
    askg-onto:inSentence "K."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22380 a askg-onto:Sentence ;
    rdfs:label "Sentence 80"@en ;
    domo:Text "Goyal, T."@en ;
    askg-onto:inSentence "Goyal, T."^^xsd:string ;
    askg-onto:index "80"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goyal_t,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22381 a askg-onto:Sentence ;
    rdfs:label "Sentence 81"@en ;
    domo:Text "Khot, D."@en ;
    askg-onto:inSentence "Khot, D."^^xsd:string ;
    askg-onto:index "81"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-khot_d,
        askg-data:Entity-na .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22382 a askg-onto:Sentence ;
    rdfs:label "Sentence 82"@en ;
    domo:Text "Summers-Stay, D."@en ;
    askg-onto:inSentence "Summers-Stay, D."^^xsd:string ;
    askg-onto:index "82"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-summers-stay_d .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22383 a askg-onto:Sentence ;
    rdfs:label "Sentence 83"@en ;
    domo:Text "Batra, and D."@en ;
    askg-onto:inSentence "Batra, and D."^^xsd:string ;
    askg-onto:index "83"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batra,
        askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22384 a askg-onto:Sentence ;
    rdfs:label "Sentence 84"@en ;
    domo:Text "Parikh."@en ;
    askg-onto:inSentence "Parikh."^^xsd:string ;
    askg-onto:index "84"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-parikh,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22385 a askg-onto:Sentence ;
    rdfs:label "Sentence 85"@en ;
    domo:Text "Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering."@en ;
    askg-onto:inSentence "Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering."^^xsd:string ;
    askg-onto:index "85"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_understanding,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22386 a askg-onto:Sentence ;
    rdfs:label "Sentence 86"@en ;
    domo:Text "In CVPR, 2017."@en ;
    askg-onto:inSentence "In CVPR, 2017."^^xsd:string ;
    askg-onto:index "86"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22387 a askg-onto:Sentence ;
    rdfs:label "Sentence 87"@en ;
    domo:Text "1, 6, 8 [13] K."@en ;
    askg-onto:inSentence "1, 6, 8 [13] K."^^xsd:string ;
    askg-onto:index "87"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-unknown .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22388 a askg-onto:Sentence ;
    rdfs:label "Sentence 88"@en ;
    domo:Text "He, X."@en ;
    askg-onto:inSentence "He, X."^^xsd:string ;
    askg-onto:index "88"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-he_x,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22389 a askg-onto:Sentence ;
    rdfs:label "Sentence 89"@en ;
    domo:Text "Zhang, S."@en ;
    askg-onto:inSentence "Zhang, S."^^xsd:string ;
    askg-onto:index "89"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhang_s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-2239 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Miller."@en ;
    askg-onto:inSentence "Miller."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-miller,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22390 a askg-onto:Sentence ;
    rdfs:label "Sentence 90"@en ;
    domo:Text "Ren, and J."@en ;
    askg-onto:inSentence "Ren, and J."^^xsd:string ;
    askg-onto:index "90"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-ren .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22391 a askg-onto:Sentence ;
    rdfs:label "Sentence 91"@en ;
    domo:Text "Sun."@en ;
    askg-onto:inSentence "Sun."^^xsd:string ;
    askg-onto:index "91"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-star,
        askg-data:Entity-sun .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22392 a askg-onto:Sentence ;
    rdfs:label "Sentence 92"@en ;
    domo:Text "Deep residual learning for image recognition."@en ;
    askg-onto:inSentence "Deep residual learning for image recognition."^^xsd:string ;
    askg-onto:index "92"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-deep_residual_learning,
        askg-data:Entity-image_recognition,
        askg-data:Entity-method .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22393 a askg-onto:Sentence ;
    rdfs:label "Sentence 93"@en ;
    domo:Text "In CVPR, 2016."@en ;
    askg-onto:inSentence "In CVPR, 2016."^^xsd:string ;
    askg-onto:index "93"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-cvpr .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22394 a askg-onto:Sentence ;
    rdfs:label "Sentence 94"@en ;
    domo:Text "3, 7 [14] K."@en ;
    askg-onto:inSentence "3, 7 [14] K."^^xsd:string ;
    askg-onto:index "94"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_7_14,
        askg-data:Entity-k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22395 a askg-onto:Sentence ;
    rdfs:label "Sentence 95"@en ;
    domo:Text "He, X."@en ;
    askg-onto:inSentence "He, X."^^xsd:string ;
    askg-onto:index "95"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-he_x .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22396 a askg-onto:Sentence ;
    rdfs:label "Sentence 96"@en ;
    domo:Text "Zhang, S."@en ;
    askg-onto:inSentence "Zhang, S."^^xsd:string ;
    askg-onto:index "96"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhang_s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22397 a askg-onto:Sentence ;
    rdfs:label "Sentence 97"@en ;
    domo:Text "Ren, and J."@en ;
    askg-onto:inSentence "Ren, and J."^^xsd:string ;
    askg-onto:index "97"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-ren .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22398 a askg-onto:Sentence ;
    rdfs:label "Sentence 98"@en ;
    domo:Text "Sun."@en ;
    askg-onto:inSentence "Sun."^^xsd:string ;
    askg-onto:index "98"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-star,
        askg-data:Entity-sun .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-223-Sentence-22399 a askg-onto:Sentence ;
    rdfs:label "Sentence 99"@en ;
    domo:Text "Identity mappings in deep residual networks."@en ;
    askg-onto:inSentence "Identity mappings in deep residual networks."^^xsd:string ;
    askg-onto:index "99"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_residual_networks,
        askg-data:Entity-identity_mappings .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Neural Computation, 1997. 3 [16] A. Jabri, A. Joulin, and L. van der Maaten. Revisiting visual question answering baselines. arXiv preprint arXiv:1606.08390, 2016. 2, 5 [17] M. Jaderberg, K. Simonyan, A. Zisserman, and K. Kavukcuoglu. Spatial transformer networks. In NIPS, 2015. 2 [18] J. Jin, K. Fu, R. Cui, F. Sha, and C. Zhang. Aligning where to see and what to tell: image caption with regionbased attention and scene factorization. arXiv preprint arXiv:1506.06272, 2015. 2 [19] A. Karpathy and F.-F. Li. Deep visual-semantic alignments for generating image descriptions. In *CVPR*, 2015. 6 [20] V. Kazemi and A. Elqursh. Show, ask, attend, and answer: A strong baseline for visual question answering. *arXiv preprint* arXiv:1704.03162, 2017. 2, 5 [21] R. Krishna, Y. Zhu, O. Groth, J. Johnson, K. Hata, J. Kravitz, S. Chen, Y. Kalantidis, L.-J. Li, D. A. Shamma, M. Bernstein, and L. Fei-Fei. Visual genome: Connecting language and vision using crowdsourced dense image annotations. arXiv preprint arXiv:1602.07332, 2016. 3, 5, 10 [22] C. Lin. Rouge: a package for automatic evaluation of summaries. In *ACL Workshop*, 2004. 6 [23] T. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollar, and C. L. Zitnick. Microsoft COCO: Common objects in context. In *ECCV*, 2014. 5, 6 [24] S. Liu, Z. Zhu, N. Ye, S. Guadarrama, and K. Murphy. Improved image captioning via policy gradient optimization of spider. In *ICCV*, 2017. 7 [25] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.- Y. Fu, and A. C. Berg. SSD: Single shot multibox detector. arXiv preprint arXiv:1512.02325, 2015. 2 [26] J. Lu, X. Lin, D. Batra, and D. Parikh. Deeper lstm and normalized cnn visual question answering model. https://github.com/VT-vision-lab/ VQA_LSTM_CNN, 2015. 8 [27] J. Lu, C. Xiong, D. Parikh, and R. Socher. Knowing when to look: Adaptive attention via a visual sentinel for image captioning. In *CVPR*, 2017. 1, 2, 3, 7 [28] J. Lu, J. Yang, D. Batra, and D. Parikh. Hierarchical question-image co-attention for visual question answering. In *NIPS*, 2016. 1, 2 [29] K. Papineni, S. Roukos, T. Ward, and W. Zhu. Bleu: a method for automatic evaluation of machine translation. In ACL, 2002. 6 [30] M. Pedersoli, T. Lucas, C. Schmid, and J. Verbeek. Areas of attention for image captioning. In *ICCV*, 2017. 2 [31] J. Pennington, R. Socher, and C. D. Manning. GloVe: Global Vectors for Word Representation. In Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP), 2014. 10 [32] J. Redmon, S. K. Divvala, R. B. Girshick, and A. Farhadi."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2241,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22410,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224100,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224101,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224102,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224103,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224104,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224105,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224106,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224107,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224108,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224109,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22411,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224110,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224111,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224112,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224113,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224114,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224115,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224116,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224117,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224118,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224119,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22412,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224120,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224121,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224122,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224123,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224124,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224125,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224126,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224127,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224128,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224129,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22413,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224130,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224131,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224132,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22414,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22415,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22416,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22417,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22418,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22419,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2242,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22420,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22421,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22422,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22423,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22424,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22425,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22426,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22427,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22428,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22429,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2243,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22430,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22431,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22432,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22433,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22434,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22435,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22436,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22437,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22438,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22439,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2244,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22440,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22441,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22442,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22443,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22444,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22445,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22446,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22447,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22448,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22449,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2245,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22450,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22451,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22452,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22453,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22454,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22455,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22456,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22457,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22458,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22459,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2246,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22460,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22461,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22462,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22463,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22464,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22465,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22466,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22467,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22468,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22469,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2247,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22470,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22471,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22472,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22473,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22474,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22475,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22476,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22477,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22478,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22479,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2248,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22480,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22481,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22482,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22483,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22484,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22485,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22486,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22487,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22488,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22489,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2249,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22490,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22491,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22492,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22493,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22494,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22495,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22496,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22497,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22498,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22499 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Neural Computation, 1997."@en ;
    askg-onto:inSentence "Neural Computation, 1997."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-neural_computation,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22410 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Simonyan, A."@en ;
    askg-onto:inSentence "Simonyan, A."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-simonyan_a .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224100 a askg-onto:Sentence ;
    rdfs:label "Sentence 100"@en ;
    domo:Text "Yang, D."@en ;
    askg-onto:inSentence "Yang, D."^^xsd:string ;
    askg-onto:index "100"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-yang_d .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224101 a askg-onto:Sentence ;
    rdfs:label "Sentence 101"@en ;
    domo:Text "Batra, and D."@en ;
    askg-onto:inSentence "Batra, and D."^^xsd:string ;
    askg-onto:index "101"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batra,
        askg-data:Entity-d .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224102 a askg-onto:Sentence ;
    rdfs:label "Sentence 102"@en ;
    domo:Text "Parikh."@en ;
    askg-onto:inSentence "Parikh."^^xsd:string ;
    askg-onto:index "102"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-parikh,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224103 a askg-onto:Sentence ;
    rdfs:label "Sentence 103"@en ;
    domo:Text "Hierarchical question-image co-attention for visual question answering."@en ;
    askg-onto:inSentence "Hierarchical question-image co-attention for visual question answering."^^xsd:string ;
    askg-onto:index "103"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hierarchical_question-image_co-attention,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224104 a askg-onto:Sentence ;
    rdfs:label "Sentence 104"@en ;
    domo:Text "In *NIPS*, 2016."@en ;
    askg-onto:inSentence "In *NIPS*, 2016."^^xsd:string ;
    askg-onto:index "104"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nips,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224105 a askg-onto:Sentence ;
    rdfs:label "Sentence 105"@en ;
    domo:Text "1, 2 [29] K."@en ;
    askg-onto:inSentence "1, 2 [29] K."^^xsd:string ;
    askg-onto:index "105"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_29,
        askg-data:Entity-k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224106 a askg-onto:Sentence ;
    rdfs:label "Sentence 106"@en ;
    domo:Text "Papineni, S."@en ;
    askg-onto:inSentence "Papineni, S."^^xsd:string ;
    askg-onto:index "106"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-papineni_s,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224107 a askg-onto:Sentence ;
    rdfs:label "Sentence 107"@en ;
    domo:Text "Roukos, T."@en ;
    askg-onto:inSentence "Roukos, T."^^xsd:string ;
    askg-onto:index "107"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-roukos_t .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224108 a askg-onto:Sentence ;
    rdfs:label "Sentence 108"@en ;
    domo:Text "Ward, and W."@en ;
    askg-onto:inSentence "Ward, and W."^^xsd:string ;
    askg-onto:index "108"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-w,
        askg-data:Entity-ward .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224109 a askg-onto:Sentence ;
    rdfs:label "Sentence 109"@en ;
    domo:Text "Zhu."@en ;
    askg-onto:inSentence "Zhu."^^xsd:string ;
    askg-onto:index "109"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhu .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22411 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Zisserman, and K."@en ;
    askg-onto:inSentence "Zisserman, and K."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-zisserman .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224110 a askg-onto:Sentence ;
    rdfs:label "Sentence 110"@en ;
    domo:Text "Bleu: a method for automatic evaluation of machine translation."@en ;
    askg-onto:inSentence "Bleu: a method for automatic evaluation of machine translation."^^xsd:string ;
    askg-onto:index "110"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_evaluation_of_machine_translation,
        askg-data:Entity-bleu .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224111 a askg-onto:Sentence ;
    rdfs:label "Sentence 111"@en ;
    domo:Text "In ACL, 2002."@en ;
    askg-onto:inSentence "In ACL, 2002."^^xsd:string ;
    askg-onto:index "111"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002,
        askg-data:Entity-acl .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224112 a askg-onto:Sentence ;
    rdfs:label "Sentence 112"@en ;
    domo:Text "6 [30] M."@en ;
    askg-onto:inSentence "6 [30] M."^^xsd:string ;
    askg-onto:index "112"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6_30,
        askg-data:Entity-m .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224113 a askg-onto:Sentence ;
    rdfs:label "Sentence 113"@en ;
    domo:Text "Pedersoli, T."@en ;
    askg-onto:inSentence "Pedersoli, T."^^xsd:string ;
    askg-onto:index "113"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pedersoli_t,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224114 a askg-onto:Sentence ;
    rdfs:label "Sentence 114"@en ;
    domo:Text "Lucas, C."@en ;
    askg-onto:inSentence "Lucas, C."^^xsd:string ;
    askg-onto:index "114"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lucas_c,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224115 a askg-onto:Sentence ;
    rdfs:label "Sentence 115"@en ;
    domo:Text "Schmid, and J."@en ;
    askg-onto:inSentence "Schmid, and J."^^xsd:string ;
    askg-onto:index "115"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-schmid .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224116 a askg-onto:Sentence ;
    rdfs:label "Sentence 116"@en ;
    domo:Text "Verbeek."@en ;
    askg-onto:inSentence "Verbeek."^^xsd:string ;
    askg-onto:index "116"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-verbeek .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224117 a askg-onto:Sentence ;
    rdfs:label "Sentence 117"@en ;
    domo:Text "Areas of attention for image captioning."@en ;
    askg-onto:inSentence "Areas of attention for image captioning."^^xsd:string ;
    askg-onto:index "117"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-research .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224118 a askg-onto:Sentence ;
    rdfs:label "Sentence 118"@en ;
    domo:Text "In *ICCV*, 2017."@en ;
    askg-onto:inSentence "In *ICCV*, 2017."^^xsd:string ;
    askg-onto:index "118"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iccv .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224119 a askg-onto:Sentence ;
    rdfs:label "Sentence 119"@en ;
    domo:Text "2 [31] J."@en ;
    askg-onto:inSentence "2 [31] J."^^xsd:string ;
    askg-onto:index "119"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22412 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Kavukcuoglu."@en ;
    askg-onto:inSentence "Kavukcuoglu."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kavukcuoglu,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224120 a askg-onto:Sentence ;
    rdfs:label "Sentence 120"@en ;
    domo:Text "Pennington, R."@en ;
    askg-onto:inSentence "Pennington, R."^^xsd:string ;
    askg-onto:index "120"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pennington_r,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224121 a askg-onto:Sentence ;
    rdfs:label "Sentence 121"@en ;
    domo:Text "Socher, and C."@en ;
    askg-onto:inSentence "Socher, and C."^^xsd:string ;
    askg-onto:index "121"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-person,
        askg-data:Entity-socher .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224122 a askg-onto:Sentence ;
    rdfs:label "Sentence 122"@en ;
    domo:Text "D."@en ;
    askg-onto:inSentence "D."^^xsd:string ;
    askg-onto:index "122"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224123 a askg-onto:Sentence ;
    rdfs:label "Sentence 123"@en ;
    domo:Text "Manning."@en ;
    askg-onto:inSentence "Manning."^^xsd:string ;
    askg-onto:index "123"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_prominent_figure_in_linguistics,
        askg-data:Entity-manning .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224124 a askg-onto:Sentence ;
    rdfs:label "Sentence 124"@en ;
    domo:Text "GloVe: Global Vectors for Word Representation."@en ;
    askg-onto:inSentence "GloVe: Global Vectors for Word Representation."^^xsd:string ;
    askg-onto:index "124"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-global_vectors_for_word_representation,
        askg-data:Entity-glove .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224125 a askg-onto:Sentence ;
    rdfs:label "Sentence 125"@en ;
    domo:Text "In Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP), 2014."@en ;
    askg-onto:inSentence "In Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP), 2014."^^xsd:string ;
    askg-onto:index "125"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-conference_on_empirical_methods_for_natural_language_processing_emnlp,
        askg-data:Entity-emnlp,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224126 a askg-onto:Sentence ;
    rdfs:label "Sentence 126"@en ;
    domo:Text "10 [32] J."@en ;
    askg-onto:inSentence "10 [32] J."^^xsd:string ;
    askg-onto:index "126"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10_32,
        askg-data:Entity-j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224127 a askg-onto:Sentence ;
    rdfs:label "Sentence 127"@en ;
    domo:Text "Redmon, S."@en ;
    askg-onto:inSentence "Redmon, S."^^xsd:string ;
    askg-onto:index "127"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-redmon_s,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224128 a askg-onto:Sentence ;
    rdfs:label "Sentence 128"@en ;
    domo:Text "K."@en ;
    askg-onto:inSentence "K."^^xsd:string ;
    askg-onto:index "128"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224129 a askg-onto:Sentence ;
    rdfs:label "Sentence 129"@en ;
    domo:Text "Divvala, R."@en ;
    askg-onto:inSentence "Divvala, R."^^xsd:string ;
    askg-onto:index "129"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-divvala_r,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22413 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Spatial transformer networks."@en ;
    askg-onto:inSentence "Spatial transformer networks."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-spatial_transformer_networks .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224130 a askg-onto:Sentence ;
    rdfs:label "Sentence 130"@en ;
    domo:Text "B."@en ;
    askg-onto:inSentence "B."^^xsd:string ;
    askg-onto:index "130"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224131 a askg-onto:Sentence ;
    rdfs:label "Sentence 131"@en ;
    domo:Text "Girshick, and A."@en ;
    askg-onto:inSentence "Girshick, and A."^^xsd:string ;
    askg-onto:index "131"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-girshick,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-224132 a askg-onto:Sentence ;
    rdfs:label "Sentence 132"@en ;
    domo:Text "Farhadi."@en ;
    askg-onto:inSentence "Farhadi."^^xsd:string ;
    askg-onto:index "132"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-farhadi,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22414 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "In NIPS, 2015."@en ;
    askg-onto:inSentence "In NIPS, 2015."^^xsd:string ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22415 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "2 [18] J."@en ;
    askg-onto:inSentence "2 [18] J."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2,
        askg-data:Entity-j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22416 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Jin, K."@en ;
    askg-onto:inSentence "Jin, K."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jin_k,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22417 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Fu, R."@en ;
    askg-onto:inSentence "Fu, R."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fu_r,
        askg-data:Entity-na .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22418 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Cui, F."@en ;
    askg-onto:inSentence "Cui, F."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cui_f,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22419 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Sha, and C."@en ;
    askg-onto:inSentence "Sha, and C."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-sha .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "3 [16] A."@en ;
    askg-onto:inSentence "3 [16] A."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-study_3 .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22420 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Zhang."@en ;
    askg-onto:inSentence "Zhang."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhang .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22421 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Aligning where to see and what to tell: image caption with regionbased attention and scene factorization."@en ;
    askg-onto:inSentence "Aligning where to see and what to tell: image caption with regionbased attention and scene factorization."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_caption,
        askg-data:Entity-region-based_attention,
        askg-data:Entity-scene_factorization .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22422 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "arXiv preprint arXiv:1506.06272, 2015."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1506.06272, 2015."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv150606272,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22423 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "2 [19] A."@en ;
    askg-onto:inSentence "2 [19] A."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22424 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Karpathy and F.-F."@en ;
    askg-onto:inSentence "Karpathy and F.-F."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f-f,
        askg-data:Entity-karpathy,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22425 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Li."@en ;
    askg-onto:inSentence "Li."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-li,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22426 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Deep visual-semantic alignments for generating image descriptions."@en ;
    askg-onto:inSentence "Deep visual-semantic alignments for generating image descriptions."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_visual-semantic_alignments,
        askg-data:Entity-image_descriptions .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22427 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "In *CVPR*, 2015."@en ;
    askg-onto:inSentence "In *CVPR*, 2015."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22428 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "6 [20] V."@en ;
    askg-onto:inSentence "6 [20] V."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6_20,
        askg-data:Entity-v .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22429 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Kazemi and A."@en ;
    askg-onto:inSentence "Kazemi and A."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-kazemi,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2243 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Jabri, A."@en ;
    askg-onto:inSentence "Jabri, A."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jabri_a,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22430 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "Elqursh."@en ;
    askg-onto:inSentence "Elqursh."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_name,
        askg-data:Entity-elqursh .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22431 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "Show, ask, attend, and answer: A strong baseline for visual question answering."@en ;
    askg-onto:inSentence "Show, ask, attend, and answer: A strong baseline for visual question answering."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-show_ask_attend_and_answer,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22432 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "*arXiv preprint* arXiv:1704.03162, 2017."@en ;
    askg-onto:inSentence "*arXiv preprint* arXiv:1704.03162, 2017."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-article,
        askg-data:Entity-arxiv170403162,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22433 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "2, 5 [21] R."@en ;
    askg-onto:inSentence "2, 5 [21] R."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2_5_21,
        askg-data:Entity-r .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22434 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "Krishna, Y."@en ;
    askg-onto:inSentence "Krishna, Y."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-krishna_y,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22435 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Zhu, O."@en ;
    askg-onto:inSentence "Zhu, O."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhu_o .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22436 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "Groth, J."@en ;
    askg-onto:inSentence "Groth, J."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-groth_j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22437 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "Johnson, K."@en ;
    askg-onto:inSentence "Johnson, K."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-johnson_k,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22438 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "Hata, J."@en ;
    askg-onto:inSentence "Hata, J."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-hata_j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22439 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "Kravitz, S."@en ;
    askg-onto:inSentence "Kravitz, S."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kravitz_s,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2244 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Joulin, and L."@en ;
    askg-onto:inSentence "Joulin, and L."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-joulin,
        askg-data:Entity-l,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22440 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "Chen, Y."@en ;
    askg-onto:inSentence "Chen, Y."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chen_y,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22441 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Kalantidis, L.-J."@en ;
    askg-onto:inSentence "Kalantidis, L.-J."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kalantidis_l-j,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22442 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "Li, D."@en ;
    askg-onto:inSentence "Li, D."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-li_d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22443 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "A."@en ;
    askg-onto:inSentence "A."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-article,
        askg-data:Entity-cell_type,
        askg-data:Entity-concept,
        askg-data:Entity-condition,
        askg-data:Entity-corpus,
        askg-data:Entity-database,
        askg-data:Entity-dataset,
        askg-data:Entity-disease,
        askg-data:Entity-domain,
        askg-data:Entity-equipment,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-framework,
        askg-data:Entity-gene,
        askg-data:Entity-measure,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-molecule,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-person,
        askg-data:Entity-platform,
        askg-data:Entity-publication,
        askg-data:Entity-rate,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-research_group,
        askg-data:Entity-result,
        askg-data:Entity-scientist,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22444 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "Shamma, M."@en ;
    askg-onto:inSentence "Shamma, M."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-shamma_m .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22445 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "Bernstein, and L."@en ;
    askg-onto:inSentence "Bernstein, and L."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bernstein,
        askg-data:Entity-l .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22446 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "Fei-Fei."@en ;
    askg-onto:inSentence "Fei-Fei."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fei-fei,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22447 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "Visual genome: Connecting language and vision using crowdsourced dense image annotations."@en ;
    askg-onto:inSentence "Visual genome: Connecting language and vision using crowdsourced dense image annotations."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-platform,
        askg-data:Entity-visual_genome .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22448 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "arXiv preprint arXiv:1602.07332, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1602.07332, 2016."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv160207332,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22449 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "3, 5, 10 [22] C."@en ;
    askg-onto:inSentence "3, 5, 10 [22] C."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_5_10_22,
        askg-data:Entity-c .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2245 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "van der Maaten."@en ;
    askg-onto:inSentence "van der Maaten."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-van_der_maaten .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22450 a askg-onto:Sentence ;
    rdfs:label "Sentence 50"@en ;
    domo:Text "Lin."@en ;
    askg-onto:inSentence "Lin."^^xsd:string ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lin,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22451 a askg-onto:Sentence ;
    rdfs:label "Sentence 51"@en ;
    domo:Text "Rouge: a package for automatic evaluation of summaries."@en ;
    askg-onto:inSentence "Rouge: a package for automatic evaluation of summaries."^^xsd:string ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-package_for_automatic_evaluation_of_summaries,
        askg-data:Entity-rouge .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22452 a askg-onto:Sentence ;
    rdfs:label "Sentence 52"@en ;
    domo:Text "In *ACL Workshop*, 2004."@en ;
    askg-onto:inSentence "In *ACL Workshop*, 2004."^^xsd:string ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-acl_workshop,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22453 a askg-onto:Sentence ;
    rdfs:label "Sentence 53"@en ;
    domo:Text "6 [23] T."@en ;
    askg-onto:inSentence "6 [23] T."^^xsd:string ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6_23_t,
        askg-data:Entity-t .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22454 a askg-onto:Sentence ;
    rdfs:label "Sentence 54"@en ;
    domo:Text "Lin, M."@en ;
    askg-onto:inSentence "Lin, M."^^xsd:string ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lin_m,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22455 a askg-onto:Sentence ;
    rdfs:label "Sentence 55"@en ;
    domo:Text "Maire, S."@en ;
    askg-onto:inSentence "Maire, S."^^xsd:string ;
    askg-onto:index "55"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-maire_s,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22456 a askg-onto:Sentence ;
    rdfs:label "Sentence 56"@en ;
    domo:Text "Belongie, J."@en ;
    askg-onto:inSentence "Belongie, J."^^xsd:string ;
    askg-onto:index "56"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-belongie_j,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22457 a askg-onto:Sentence ;
    rdfs:label "Sentence 57"@en ;
    domo:Text "Hays, P."@en ;
    askg-onto:inSentence "Hays, P."^^xsd:string ;
    askg-onto:index "57"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hays_p,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22458 a askg-onto:Sentence ;
    rdfs:label "Sentence 58"@en ;
    domo:Text "Perona, D."@en ;
    askg-onto:inSentence "Perona, D."^^xsd:string ;
    askg-onto:index "58"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-perona_d,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22459 a askg-onto:Sentence ;
    rdfs:label "Sentence 59"@en ;
    domo:Text "Ramanan, P."@en ;
    askg-onto:inSentence "Ramanan, P."^^xsd:string ;
    askg-onto:index "59"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ramanan_p,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2246 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Revisiting visual question answering baselines."@en ;
    askg-onto:inSentence "Revisiting visual question answering baselines."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-visual_question_answering_baselines .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22460 a askg-onto:Sentence ;
    rdfs:label "Sentence 60"@en ;
    domo:Text "Dollar, and C."@en ;
    askg-onto:inSentence "Dollar, and C."^^xsd:string ;
    askg-onto:index "60"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-dollar,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22461 a askg-onto:Sentence ;
    rdfs:label "Sentence 61"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "61"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l,
        askg-data:Entity-unknown .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22462 a askg-onto:Sentence ;
    rdfs:label "Sentence 62"@en ;
    domo:Text "Zitnick."@en ;
    askg-onto:inSentence "Zitnick."^^xsd:string ;
    askg-onto:index "62"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-zitnick .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22463 a askg-onto:Sentence ;
    rdfs:label "Sentence 63"@en ;
    domo:Text "Microsoft COCO: Common objects in context."@en ;
    askg-onto:inSentence "Microsoft COCO: Common objects in context."^^xsd:string ;
    askg-onto:index "63"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-microsoft_coco .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22464 a askg-onto:Sentence ;
    rdfs:label "Sentence 64"@en ;
    domo:Text "In *ECCV*, 2014."@en ;
    askg-onto:inSentence "In *ECCV*, 2014."^^xsd:string ;
    askg-onto:index "64"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eccv .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22465 a askg-onto:Sentence ;
    rdfs:label "Sentence 65"@en ;
    domo:Text "5, 6 [24] S."@en ;
    askg-onto:inSentence "5, 6 [24] S."^^xsd:string ;
    askg-onto:index "65"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_6_24_s,
        askg-data:Entity-s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22466 a askg-onto:Sentence ;
    rdfs:label "Sentence 66"@en ;
    domo:Text "Liu, Z."@en ;
    askg-onto:inSentence "Liu, Z."^^xsd:string ;
    askg-onto:index "66"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-liu_z,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22467 a askg-onto:Sentence ;
    rdfs:label "Sentence 67"@en ;
    domo:Text "Zhu, N."@en ;
    askg-onto:inSentence "Zhu, N."^^xsd:string ;
    askg-onto:index "67"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhu_n .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22468 a askg-onto:Sentence ;
    rdfs:label "Sentence 68"@en ;
    domo:Text "Ye, S."@en ;
    askg-onto:inSentence "Ye, S."^^xsd:string ;
    askg-onto:index "68"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication,
        askg-data:Entity-ye_s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22469 a askg-onto:Sentence ;
    rdfs:label "Sentence 69"@en ;
    domo:Text "Guadarrama, and K."@en ;
    askg-onto:inSentence "Guadarrama, and K."^^xsd:string ;
    askg-onto:index "69"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guadarrama,
        askg-data:Entity-k,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2247 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "arXiv preprint arXiv:1606.08390, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1606.08390, 2016."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-arxiv160608390,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22470 a askg-onto:Sentence ;
    rdfs:label "Sentence 70"@en ;
    domo:Text "Murphy."@en ;
    askg-onto:inSentence "Murphy."^^xsd:string ;
    askg-onto:index "70"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-murphy,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22471 a askg-onto:Sentence ;
    rdfs:label "Sentence 71"@en ;
    domo:Text "Improved image captioning via policy gradient optimization of spider."@en ;
    askg-onto:inSentence "Improved image captioning via policy gradient optimization of spider."^^xsd:string ;
    askg-onto:index "71"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-policy_gradient_optimization_of_spider .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22472 a askg-onto:Sentence ;
    rdfs:label "Sentence 72"@en ;
    domo:Text "In *ICCV*, 2017."@en ;
    askg-onto:inSentence "In *ICCV*, 2017."^^xsd:string ;
    askg-onto:index "72"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22473 a askg-onto:Sentence ;
    rdfs:label "Sentence 73"@en ;
    domo:Text "7 [25] W."@en ;
    askg-onto:inSentence "7 [25] W."^^xsd:string ;
    askg-onto:index "73"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7_25,
        askg-data:Entity-w .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22474 a askg-onto:Sentence ;
    rdfs:label "Sentence 74"@en ;
    domo:Text "Liu, D."@en ;
    askg-onto:inSentence "Liu, D."^^xsd:string ;
    askg-onto:index "74"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-liu_d,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22475 a askg-onto:Sentence ;
    rdfs:label "Sentence 75"@en ;
    domo:Text "Anguelov, D."@en ;
    askg-onto:inSentence "Anguelov, D."^^xsd:string ;
    askg-onto:index "75"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anguelov_d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22476 a askg-onto:Sentence ;
    rdfs:label "Sentence 76"@en ;
    domo:Text "Erhan, C."@en ;
    askg-onto:inSentence "Erhan, C."^^xsd:string ;
    askg-onto:index "76"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-erhan_c,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22477 a askg-onto:Sentence ;
    rdfs:label "Sentence 77"@en ;
    domo:Text "Szegedy, S."@en ;
    askg-onto:inSentence "Szegedy, S."^^xsd:string ;
    askg-onto:index "77"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-szegedy_s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22478 a askg-onto:Sentence ;
    rdfs:label "Sentence 78"@en ;
    domo:Text "Reed, C.- Y."@en ;
    askg-onto:inSentence "Reed, C.- Y."^^xsd:string ;
    askg-onto:index "78"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-reed_c-_y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22479 a askg-onto:Sentence ;
    rdfs:label "Sentence 79"@en ;
    domo:Text "Fu, and A."@en ;
    askg-onto:inSentence "Fu, and A."^^xsd:string ;
    askg-onto:index "79"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-fu .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2248 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "2, 5 [17] M."@en ;
    askg-onto:inSentence "2, 5 [17] M."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2_5_17,
        askg-data:Entity-m .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22480 a askg-onto:Sentence ;
    rdfs:label "Sentence 80"@en ;
    domo:Text "C."@en ;
    askg-onto:inSentence "C."^^xsd:string ;
    askg-onto:index "80"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22481 a askg-onto:Sentence ;
    rdfs:label "Sentence 81"@en ;
    domo:Text "Berg."@en ;
    askg-onto:inSentence "Berg."^^xsd:string ;
    askg-onto:index "81"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-berg,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22482 a askg-onto:Sentence ;
    rdfs:label "Sentence 82"@en ;
    domo:Text "SSD: Single shot multibox detector."@en ;
    askg-onto:inSentence "SSD: Single shot multibox detector."^^xsd:string ;
    askg-onto:index "82"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-single_shot_multibox_detector,
        askg-data:Entity-ssd .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22483 a askg-onto:Sentence ;
    rdfs:label "Sentence 83"@en ;
    domo:Text "arXiv preprint arXiv:1512.02325, 2015."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1512.02325, 2015."^^xsd:string ;
    askg-onto:index "83"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv151202325,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22484 a askg-onto:Sentence ;
    rdfs:label "Sentence 84"@en ;
    domo:Text "2 [26] J."@en ;
    askg-onto:inSentence "2 [26] J."^^xsd:string ;
    askg-onto:index "84"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22485 a askg-onto:Sentence ;
    rdfs:label "Sentence 85"@en ;
    domo:Text "Lu, X."@en ;
    askg-onto:inSentence "Lu, X."^^xsd:string ;
    askg-onto:index "85"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lu_x,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22486 a askg-onto:Sentence ;
    rdfs:label "Sentence 86"@en ;
    domo:Text "Lin, D."@en ;
    askg-onto:inSentence "Lin, D."^^xsd:string ;
    askg-onto:index "86"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lin_d,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22487 a askg-onto:Sentence ;
    rdfs:label "Sentence 87"@en ;
    domo:Text "Batra, and D."@en ;
    askg-onto:inSentence "Batra, and D."^^xsd:string ;
    askg-onto:index "87"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batra,
        askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22488 a askg-onto:Sentence ;
    rdfs:label "Sentence 88"@en ;
    domo:Text "Parikh."@en ;
    askg-onto:inSentence "Parikh."^^xsd:string ;
    askg-onto:index "88"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-parikh,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22489 a askg-onto:Sentence ;
    rdfs:label "Sentence 89"@en ;
    domo:Text "Deeper lstm and normalized cnn visual question answering model."@en ;
    askg-onto:inSentence "Deeper lstm and normalized cnn visual question answering model."^^xsd:string ;
    askg-onto:index "89"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deeper_lstm,
        askg-data:Entity-model,
        askg-data:Entity-normalized_cnn,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-2249 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Jaderberg, K."@en ;
    askg-onto:inSentence "Jaderberg, K."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jaderberg_k,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22490 a askg-onto:Sentence ;
    rdfs:label "Sentence 90"@en ;
    domo:Text "https://github.com/VT-vision-lab/ VQA_LSTM_CNN, 2015."@en ;
    askg-onto:inSentence "https://github.com/VT-vision-lab/ VQA_LSTM_CNN, 2015."^^xsd:string ;
    askg-onto:index "90"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-model,
        askg-data:Entity-vqa_lstm_cnn .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22491 a askg-onto:Sentence ;
    rdfs:label "Sentence 91"@en ;
    domo:Text "8 [27] J."@en ;
    askg-onto:inSentence "8 [27] J."^^xsd:string ;
    askg-onto:index "91"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22492 a askg-onto:Sentence ;
    rdfs:label "Sentence 92"@en ;
    domo:Text "Lu, C."@en ;
    askg-onto:inSentence "Lu, C."^^xsd:string ;
    askg-onto:index "92"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lu_c,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22493 a askg-onto:Sentence ;
    rdfs:label "Sentence 93"@en ;
    domo:Text "Xiong, D."@en ;
    askg-onto:inSentence "Xiong, D."^^xsd:string ;
    askg-onto:index "93"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-xiong_d .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22494 a askg-onto:Sentence ;
    rdfs:label "Sentence 94"@en ;
    domo:Text "Parikh, and R."@en ;
    askg-onto:inSentence "Parikh, and R."^^xsd:string ;
    askg-onto:index "94"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-parikh,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22495 a askg-onto:Sentence ;
    rdfs:label "Sentence 95"@en ;
    domo:Text "Socher."@en ;
    askg-onto:inSentence "Socher."^^xsd:string ;
    askg-onto:index "95"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-socher .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22496 a askg-onto:Sentence ;
    rdfs:label "Sentence 96"@en ;
    domo:Text "Knowing when to look: Adaptive attention via a visual sentinel for image captioning."@en ;
    askg-onto:inSentence "Knowing when to look: Adaptive attention via a visual sentinel for image captioning."^^xsd:string ;
    askg-onto:index "96"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_attention,
        askg-data:Entity-image_captioning,
        askg-data:Entity-visual_sentinel .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22497 a askg-onto:Sentence ;
    rdfs:label "Sentence 97"@en ;
    domo:Text "In *CVPR*, 2017."@en ;
    askg-onto:inSentence "In *CVPR*, 2017."^^xsd:string ;
    askg-onto:index "97"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22498 a askg-onto:Sentence ;
    rdfs:label "Sentence 98"@en ;
    domo:Text "1, 2, 3, 7 [28] J."@en ;
    askg-onto:inSentence "1, 2, 3, 7 [28] J."^^xsd:string ;
    askg-onto:index "98"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_3_7_28,
        askg-data:Entity-j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-224-Sentence-22499 a askg-onto:Sentence ;
    rdfs:label "Sentence 99"@en ;
    domo:Text "Lu, J."@en ;
    askg-onto:inSentence "Lu, J."^^xsd:string ;
    askg-onto:index "99"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lu_j,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "You only look once: Unified, real-time object detection. In CVPR, 2016. 2 [33] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards real-time object detection with region proposal networks. In *NIPS*, 2015. 2 [34] S. J. Rennie, E. Marcheret, Y. Mroueh, J. Ross, and V. Goel."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2251,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22510,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22511,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22512,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22513,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22514,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22515,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22516,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2252,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2253,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2254,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2255,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2256,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2257,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2258,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2259 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "You only look once: Unified, real-time object detection."@en ;
    askg-onto:inSentence "You only look once: Unified, real-time object detection."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-unified_real-time_object_detection,
        askg-data:Entity-you_only_look_once .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22510 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "2 [34] S."@en ;
    askg-onto:inSentence "2 [34] S."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-34,
        askg-data:Entity-s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22511 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "J."@en ;
    askg-onto:inSentence "J."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22512 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Rennie, E."@en ;
    askg-onto:inSentence "Rennie, E."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-rennie_e .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22513 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Marcheret, Y."@en ;
    askg-onto:inSentence "Marcheret, Y."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-marcheret_y,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22514 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Mroueh, J."@en ;
    askg-onto:inSentence "Mroueh, J."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mroueh_j,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22515 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Ross, and V."@en ;
    askg-onto:inSentence "Ross, and V."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-ross,
        askg-data:Entity-v .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-22516 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Goel."@en ;
    askg-onto:inSentence "Goel."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-goel .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In CVPR, 2016."@en ;
    askg-onto:inSentence "In CVPR, 2016."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-cvpr .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2253 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "2 [33] S."@en ;
    askg-onto:inSentence "2 [33] S."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-33,
        askg-data:Entity-s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2254 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Ren, K."@en ;
    askg-onto:inSentence "Ren, K."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ren_k,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2255 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "He, R."@en ;
    askg-onto:inSentence "He, R."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-he_r,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2256 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Girshick, and J."@en ;
    askg-onto:inSentence "Girshick, and J."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-girshick,
        askg-data:Entity-j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2257 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Sun."@en ;
    askg-onto:inSentence "Sun."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-celestial_body,
        askg-data:Entity-sun .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2258 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Faster R-CNN: Towards real-time object detection with region proposal networks."@en ;
    askg-onto:inSentence "Faster R-CNN: Towards real-time object detection with region proposal networks."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-225-Sentence-2259 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In *NIPS*, 2015."@en ;
    askg-onto:inSentence "In *NIPS*, 2015."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nips .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Self-critical sequence training for image captioning. In CVPR, 2017. 1, 2, 3, 4, 6, 7 [35] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. Imagenet large scale visual recognition challenge. *IJCV*, 2015. 2, 3, 7 [36] B. J. Scholl. Objects and attention: The state of the art. Cognition, 80(1):1–46, 2001. 2 [37] R. K. Srivastava, K. Greff, and J. Schmidhuber. Highway networks. *arXiv preprint arXiv:1505.00387v1*, 2015. 5 [38] D. Teney, P. Anderson, X. He, and A. van den Hengel. Tips and tricks for visual question answering: Learnings from the 2017 challenge. In *CVPR*, 2018. 5, 10 [39] D. Teney and A. van den Hengel. Zero-shot visual question answering. *arXiv preprint arXiv:1611.05546*, 2016. 5 [40] A. Treisman. Perceptual grouping and attention in visual search for features and for objects. Journal of Experimental Psychology: Human Perception and Performance, 8(2):194, 1982. 8 [41] A. M. Treisman and G. Gelade. A feature-integration theory of attention. *Cognitive Psychology*, 12:97–136, 1980. 8 [42] J. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2261,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22610,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22611,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22612,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22613,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22614,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22615,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22616,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22617,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22618,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22619,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2262,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22620,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22621,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22622,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22623,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22624,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22625,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22626,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22627,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22628,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22629,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2263,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22630,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22631,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22632,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22633,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22634,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22635,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22636,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22637,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22638,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22639,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2264,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22640,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22641,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22642,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22643,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22644,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22645,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22646,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22647,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22648,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22649,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2265,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22650,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22651,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22652,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22653,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22654,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22655,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22656,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22657,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22658,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22659,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2266,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2267,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2268,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2269 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Self-critical sequence training for image captioning."@en ;
    askg-onto:inSentence "Self-critical sequence training for image captioning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-method,
        askg-data:Entity-self-critical_sequence_training,
        askg-data:Entity-task .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22610 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Huang, A."@en ;
    askg-onto:inSentence "Huang, A."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-huang_a,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22611 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Karpathy, A."@en ;
    askg-onto:inSentence "Karpathy, A."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-karpathy_a,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22612 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Khosla, M."@en ;
    askg-onto:inSentence "Khosla, M."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-khosla_m,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22613 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Bernstein, A."@en ;
    askg-onto:inSentence "Bernstein, A."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bernstein_a,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22614 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "C."@en ;
    askg-onto:inSentence "C."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22615 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Berg, and L."@en ;
    askg-onto:inSentence "Berg, and L."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-berg,
        askg-data:Entity-l,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22616 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Fei-Fei."@en ;
    askg-onto:inSentence "Fei-Fei."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fei-fei,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22617 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Imagenet large scale visual recognition challenge."@en ;
    askg-onto:inSentence "Imagenet large scale visual recognition challenge."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-imagenet,
        askg-data:Entity-large_scale_visual_recognition_challenge .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22618 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "*IJCV*, 2015."@en ;
    askg-onto:inSentence "*IJCV*, 2015."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ijcv .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22619 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "2, 3, 7 [36] B."@en ;
    askg-onto:inSentence "2, 3, 7 [36] B."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In CVPR, 2017."@en ;
    askg-onto:inSentence "In CVPR, 2017."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017 .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22620 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "J."@en ;
    askg-onto:inSentence "J."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22621 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Scholl."@en ;
    askg-onto:inSentence "Scholl."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-scholl .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22622 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Objects and attention: The state of the art."@en ;
    askg-onto:inSentence "Objects and attention: The state of the art."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-objects_and_attention,
        askg-data:Entity-the_state_of_the_art .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22623 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Cognition, 80(1):1–46, 2001."@en ;
    askg-onto:inSentence "Cognition, 80(1):1–46, 2001."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-801146_2001,
        askg-data:Entity-cognition .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22624 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "2 [37] R."@en ;
    askg-onto:inSentence "2 [37] R."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-37,
        askg-data:Entity-r .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22625 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "K."@en ;
    askg-onto:inSentence "K."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22626 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Srivastava, K."@en ;
    askg-onto:inSentence "Srivastava, K."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-srivastava_k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22627 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Greff, and J."@en ;
    askg-onto:inSentence "Greff, and J."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-greff,
        askg-data:Entity-j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22628 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "Schmidhuber."@en ;
    askg-onto:inSentence "Schmidhuber."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-schmidhuber,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22629 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Highway networks."@en ;
    askg-onto:inSentence "Highway networks."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-highway_networks .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2263 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "1, 2, 3, 4, 6, 7 [35] O."@en ;
    askg-onto:inSentence "1, 2, 3, 4, 6, 7 [35] O."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_3_4_6_7,
        askg-data:Entity-o .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22630 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "*arXiv preprint arXiv:1505.00387v1*, 2015."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1505.00387v1*, 2015."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv150500387v1,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22631 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "5 [38] D."@en ;
    askg-onto:inSentence "5 [38] D."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_38,
        askg-data:Entity-d .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22632 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "Teney, P."@en ;
    askg-onto:inSentence "Teney, P."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_paper,
        askg-data:Entity-teney_p .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22633 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "Anderson, X."@en ;
    askg-onto:inSentence "Anderson, X."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anderson_x,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22634 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "He, and A."@en ;
    askg-onto:inSentence "He, and A."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-he .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22635 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "van den Hengel."@en ;
    askg-onto:inSentence "van den Hengel."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-van_den_hengel .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22636 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "Tips and tricks for visual question answering: Learnings from the 2017 challenge."@en ;
    askg-onto:inSentence "Tips and tricks for visual question answering: Learnings from the 2017 challenge."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-tips_and_tricks_for_visual_question_answering,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22637 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "In *CVPR*, 2018."@en ;
    askg-onto:inSentence "In *CVPR*, 2018."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22638 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "5, 10 [39] D."@en ;
    askg-onto:inSentence "5, 10 [39] D."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_10_39,
        askg-data:Entity-d .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22639 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "Teney and A."@en ;
    askg-onto:inSentence "Teney and A."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-person,
        askg-data:Entity-teney .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2264 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Russakovsky, J."@en ;
    askg-onto:inSentence "Russakovsky, J."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-russakovsky_j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22640 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "van den Hengel."@en ;
    askg-onto:inSentence "van den Hengel."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-van_den_hengel .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22641 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Zero-shot visual question answering."@en ;
    askg-onto:inSentence "Zero-shot visual question answering."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-zero-shot_visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22642 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "*arXiv preprint arXiv:1611.05546*, 2016."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1611.05546*, 2016."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv161105546,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22643 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "5 [40] A."@en ;
    askg-onto:inSentence "5 [40] A."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_40,
        askg-data:Entity-a .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22644 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "Treisman."@en ;
    askg-onto:inSentence "Treisman."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-treisman .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22645 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "Perceptual grouping and attention in visual search for features and for objects."@en ;
    askg-onto:inSentence "Perceptual grouping and attention in visual search for features and for objects."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_in_visual_search,
        askg-data:Entity-features_and_objects,
        askg-data:Entity-perceptual_grouping,
        askg-data:Entity-visual_search .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22646 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "Journal of Experimental Psychology: Human Perception and Performance, 8(2):194, 1982."@en ;
    askg-onto:inSentence "Journal of Experimental Psychology: Human Perception and Performance, 8(2):194, 1982."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-194,
        askg-data:Entity-2,
        askg-data:Entity-8,
        askg-data:Entity-journal_of_experimental_psychology_human_perception_and_performance,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22647 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "8 [41] A."@en ;
    askg-onto:inSentence "8 [41] A."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8_41,
        askg-data:Entity-a .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22648 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "M."@en ;
    askg-onto:inSentence "M."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-m,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22649 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "Treisman and G."@en ;
    askg-onto:inSentence "Treisman and G."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-scientist,
        askg-data:Entity-treisman .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2265 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Deng, H."@en ;
    askg-onto:inSentence "Deng, H."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deng_h,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22650 a askg-onto:Sentence ;
    rdfs:label "Sentence 50"@en ;
    domo:Text "Gelade."@en ;
    askg-onto:inSentence "Gelade."^^xsd:string ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gelade,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22651 a askg-onto:Sentence ;
    rdfs:label "Sentence 51"@en ;
    domo:Text "A feature-integration theory of attention."@en ;
    askg-onto:inSentence "A feature-integration theory of attention."^^xsd:string ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feature-integration_theory,
        askg-data:Entity-theory .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22652 a askg-onto:Sentence ;
    rdfs:label "Sentence 52"@en ;
    domo:Text "*Cognitive Psychology*, 12:97–136, 1980."@en ;
    askg-onto:inSentence "*Cognitive Psychology*, 12:97–136, 1980."^^xsd:string ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cognitive_psychology,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22653 a askg-onto:Sentence ;
    rdfs:label "Sentence 53"@en ;
    domo:Text "8 [42] J."@en ;
    askg-onto:inSentence "8 [42] J."^^xsd:string ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8_42,
        askg-data:Entity-j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22654 a askg-onto:Sentence ;
    rdfs:label "Sentence 54"@en ;
    domo:Text "R."@en ;
    askg-onto:inSentence "R."^^xsd:string ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-r,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22655 a askg-onto:Sentence ;
    rdfs:label "Sentence 55"@en ;
    domo:Text "Uijlings, K."@en ;
    askg-onto:inSentence "Uijlings, K."^^xsd:string ;
    askg-onto:index "55"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-uijlings_k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22656 a askg-onto:Sentence ;
    rdfs:label "Sentence 56"@en ;
    domo:Text "E."@en ;
    askg-onto:inSentence "E."^^xsd:string ;
    askg-onto:index "56"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e,
        askg-data:Entity-entity .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22657 a askg-onto:Sentence ;
    rdfs:label "Sentence 57"@en ;
    domo:Text "Van De Sande, T."@en ;
    askg-onto:inSentence "Van De Sande, T."^^xsd:string ;
    askg-onto:index "57"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-van_de_sande_t .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22658 a askg-onto:Sentence ;
    rdfs:label "Sentence 58"@en ;
    domo:Text "Gevers, and A."@en ;
    askg-onto:inSentence "Gevers, and A."^^xsd:string ;
    askg-onto:index "58"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gevers,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-22659 a askg-onto:Sentence ;
    rdfs:label "Sentence 59"@en ;
    domo:Text "W."@en ;
    askg-onto:inSentence "W."^^xsd:string ;
    askg-onto:index "59"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-unknown,
        askg-data:Entity-w .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2266 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Su, J."@en ;
    askg-onto:inSentence "Su, J."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_article,
        askg-data:Entity-su_j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2267 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Krause, S."@en ;
    askg-onto:inSentence "Krause, S."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-krause_s,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2268 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Satheesh, S."@en ;
    askg-onto:inSentence "Satheesh, S."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-satheesh_s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-226-Sentence-2269 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Ma, Z."@en ;
    askg-onto:inSentence "Ma, Z."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ma_z,
        askg-data:Entity-research_paper .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Smeulders. Selective search for object recognition. *IJCV*, 2013. 2 [43] R. Vedantam, C. L. Zitnick, and D. Parikh. CIDEr: Consensus-based image description evaluation. In *CVPR*, 2015. 4, 6 [44] R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. *Mach.* Learn., 8(3-4):229–256, May 1992. 4 [45] H. Xu and K. Saenko. Ask, attend and answer: Exploring question-guided spatial attention for visual question answering. In *ECCV*, 2016. 1, 2 [46] K. Xu, J. Ba, R. Kiros, K. Cho, A. C. Courville, R. Salakhutdinov, R. S. Zemel, and Y. Bengio. Show, attend and tell: Neural image caption generation with visual attention. In ICML, 2015. 1, 2, 3 [47] Z. Yang, X. He, J. Gao, L. Deng, and A. J. Smola. Stacked attention networks for image question answering. In *CVPR*, 2016. 1, 2 [48] Z. Yang, Y. Yuan, Y. Wu, R. Salakhutdinov, and W. W. Cohen. Review networks for caption generation. In *NIPS*, 2016. 1, 2, 7 [49] T. Yao, Y. Pan, Y. Li, Z. Qiu, and T. Mei. Boosting image captioning with attributes. In *ICCV*, 2017. 7 [50] M. D. Zeiler. ADADELTA: an adaptive learning rate method."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2271,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22710,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22711,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22712,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22713,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22714,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22715,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22716,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22717,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22718,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22719,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2272,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22720,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22721,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22722,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22723,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22724,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22725,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22726,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22727,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22728,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22729,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2273,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22730,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22731,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22732,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22733,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22734,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22735,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22736,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22737,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22738,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22739,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2274,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22740,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22741,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22742,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22743,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22744,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22745,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22746,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22747,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22748,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22749,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2275,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22750,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22751,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22752,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22753,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22754,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22755,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22756,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22757,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22758,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22759,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2276,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22760,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22761,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22762,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22763,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2277,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2278,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2279 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Smeulders."@en ;
    askg-onto:inSentence "Smeulders."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-smeulders .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22710 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "In *CVPR*, 2015."@en ;
    askg-onto:inSentence "In *CVPR*, 2015."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-cvpr .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22711 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "4, 6 [44] R."@en ;
    askg-onto:inSentence "4, 6 [44] R."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4_6_44,
        askg-data:Entity-r .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22712 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "J."@en ;
    askg-onto:inSentence "J."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22713 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Williams."@en ;
    askg-onto:inSentence "Williams."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-williams .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22714 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Simple statistical gradient-following algorithms for connectionist reinforcement learning."@en ;
    askg-onto:inSentence "Simple statistical gradient-following algorithms for connectionist reinforcement learning."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-connectionist_reinforcement_learning,
        askg-data:Entity-statistical_gradient-following_algorithms .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22715 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "*Mach.* Learn., 8(3-4):229–256, May 1992."@en ;
    askg-onto:inSentence "*Mach.* Learn., 8(3-4):229–256, May 1992."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-83-4229256,
        askg-data:Entity-mach_learn,
        askg-data:Entity-may_1992,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22716 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "4 [45] H."@en ;
    askg-onto:inSentence "4 [45] H."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4_45,
        askg-data:Entity-h .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22717 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Xu and K."@en ;
    askg-onto:inSentence "Xu and K."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-k,
        askg-data:Entity-xu .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22718 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Saenko."@en ;
    askg-onto:inSentence "Saenko."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-saenko,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22719 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Ask, attend and answer: Exploring question-guided spatial attention for visual question answering."@en ;
    askg-onto:inSentence "Ask, attend and answer: Exploring question-guided spatial attention for visual question answering."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-question-guided_spatial_attention,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2272 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Selective search for object recognition."@en ;
    askg-onto:inSentence "Selective search for object recognition."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-object_recognition,
        askg-data:Entity-selective_search .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22720 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "In *ECCV*, 2016."@en ;
    askg-onto:inSentence "In *ECCV*, 2016."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eccv,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22721 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "1, 2 [46] K."@en ;
    askg-onto:inSentence "1, 2 [46] K."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_46,
        askg-data:Entity-k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22722 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Xu, J."@en ;
    askg-onto:inSentence "Xu, J."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-xu_j .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22723 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Ba, R."@en ;
    askg-onto:inSentence "Ba, R."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ba_r,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22724 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Kiros, K."@en ;
    askg-onto:inSentence "Kiros, K."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-kiros_k .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22725 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Cho, A."@en ;
    askg-onto:inSentence "Cho, A."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cho_a,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22726 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "C."@en ;
    askg-onto:inSentence "C."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22727 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Courville, R."@en ;
    askg-onto:inSentence "Courville, R."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-courville_r,
        askg-data:Entity-research_work .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22728 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "Salakhutdinov, R."@en ;
    askg-onto:inSentence "Salakhutdinov, R."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-salakhutdinov_r,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22729 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "S."@en ;
    askg-onto:inSentence "S."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-s .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2273 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*IJCV*, 2013."@en ;
    askg-onto:inSentence "*IJCV*, 2013."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ijcv .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22730 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "Zemel, and Y."@en ;
    askg-onto:inSentence "Zemel, and Y."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-y,
        askg-data:Entity-zemel .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22731 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "Bengio."@en ;
    askg-onto:inSentence "Bengio."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_prominent_figure_in_ai,
        askg-data:Entity-bengio .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22732 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "Show, attend and tell: Neural image caption generation with visual attention."@en ;
    askg-onto:inSentence "Show, attend and tell: Neural image caption generation with visual attention."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-neural_image_caption_generation,
        askg-data:Entity-visual_attention .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22733 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "In ICML, 2015."@en ;
    askg-onto:inSentence "In ICML, 2015."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-icml .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22734 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "1, 2, 3 [47] Z."@en ;
    askg-onto:inSentence "1, 2, 3 [47] Z."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-z .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22735 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Yang, X."@en ;
    askg-onto:inSentence "Yang, X."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-yang_x .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22736 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "He, J."@en ;
    askg-onto:inSentence "He, J."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-he_j,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22737 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "Gao, L."@en ;
    askg-onto:inSentence "Gao, L."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gao_l,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22738 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "Deng, and A."@en ;
    askg-onto:inSentence "Deng, and A."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-deng,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22739 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "J."@en ;
    askg-onto:inSentence "J."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2274 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "2 [43] R."@en ;
    askg-onto:inSentence "2 [43] R."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2_43,
        askg-data:Entity-r .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22740 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "Smola."@en ;
    askg-onto:inSentence "Smola."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-smola .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22741 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Stacked attention networks for image question answering."@en ;
    askg-onto:inSentence "Stacked attention networks for image question answering."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_question_answering,
        askg-data:Entity-stacked_attention_networks .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22742 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "In *CVPR*, 2016."@en ;
    askg-onto:inSentence "In *CVPR*, 2016."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvpr .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22743 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "1, 2 [48] Z."@en ;
    askg-onto:inSentence "1, 2 [48] Z."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-z .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22744 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "Yang, Y."@en ;
    askg-onto:inSentence "Yang, Y."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-yang_y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22745 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "Yuan, Y."@en ;
    askg-onto:inSentence "Yuan, Y."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-yuan_y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22746 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "Wu, R."@en ;
    askg-onto:inSentence "Wu, R."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-wu_r .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22747 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "Salakhutdinov, and W."@en ;
    askg-onto:inSentence "Salakhutdinov, and W."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-salakhutdinov,
        askg-data:Entity-w .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22748 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "W."@en ;
    askg-onto:inSentence "W."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-unknown,
        askg-data:Entity-w .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22749 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "Cohen."@en ;
    askg-onto:inSentence "Cohen."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-cohen .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2275 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Vedantam, C."@en ;
    askg-onto:inSentence "Vedantam, C."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-vedantam_c .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22750 a askg-onto:Sentence ;
    rdfs:label "Sentence 50"@en ;
    domo:Text "Review networks for caption generation."@en ;
    askg-onto:inSentence "Review networks for caption generation."^^xsd:string ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-caption_generation,
        askg-data:Entity-review_networks .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22751 a askg-onto:Sentence ;
    rdfs:label "Sentence 51"@en ;
    domo:Text "In *NIPS*, 2016."@en ;
    askg-onto:inSentence "In *NIPS*, 2016."^^xsd:string ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nips,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22752 a askg-onto:Sentence ;
    rdfs:label "Sentence 52"@en ;
    domo:Text "1, 2, 7 [49] T."@en ;
    askg-onto:inSentence "1, 2, 7 [49] T."^^xsd:string ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-2,
        askg-data:Entity-7,
        askg-data:Entity-t .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22753 a askg-onto:Sentence ;
    rdfs:label "Sentence 53"@en ;
    domo:Text "Yao, Y."@en ;
    askg-onto:inSentence "Yao, Y."^^xsd:string ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-yao_y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22754 a askg-onto:Sentence ;
    rdfs:label "Sentence 54"@en ;
    domo:Text "Pan, Y."@en ;
    askg-onto:inSentence "Pan, Y."^^xsd:string ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pan_y,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22755 a askg-onto:Sentence ;
    rdfs:label "Sentence 55"@en ;
    domo:Text "Li, Z."@en ;
    askg-onto:inSentence "Li, Z."^^xsd:string ;
    askg-onto:index "55"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-li_z,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22756 a askg-onto:Sentence ;
    rdfs:label "Sentence 56"@en ;
    domo:Text "Qiu, and T."@en ;
    askg-onto:inSentence "Qiu, and T."^^xsd:string ;
    askg-onto:index "56"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-qiu,
        askg-data:Entity-t .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22757 a askg-onto:Sentence ;
    rdfs:label "Sentence 57"@en ;
    domo:Text "Mei."@en ;
    askg-onto:inSentence "Mei."^^xsd:string ;
    askg-onto:index "57"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mei,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22758 a askg-onto:Sentence ;
    rdfs:label "Sentence 58"@en ;
    domo:Text "Boosting image captioning with attributes."@en ;
    askg-onto:inSentence "Boosting image captioning with attributes."^^xsd:string ;
    askg-onto:index "58"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attributes,
        askg-data:Entity-image_captioning .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22759 a askg-onto:Sentence ;
    rdfs:label "Sentence 59"@en ;
    domo:Text "In *ICCV*, 2017."@en ;
    askg-onto:inSentence "In *ICCV*, 2017."^^xsd:string ;
    askg-onto:index "59"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iccv .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2276 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22760 a askg-onto:Sentence ;
    rdfs:label "Sentence 60"@en ;
    domo:Text "7 [50] M."@en ;
    askg-onto:inSentence "7 [50] M."^^xsd:string ;
    askg-onto:index "60"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7_50,
        askg-data:Entity-m .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22761 a askg-onto:Sentence ;
    rdfs:label "Sentence 61"@en ;
    domo:Text "D."@en ;
    askg-onto:inSentence "D."^^xsd:string ;
    askg-onto:index "61"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22762 a askg-onto:Sentence ;
    rdfs:label "Sentence 62"@en ;
    domo:Text "Zeiler."@en ;
    askg-onto:inSentence "Zeiler."^^xsd:string ;
    askg-onto:index "62"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-zeiler .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-22763 a askg-onto:Sentence ;
    rdfs:label "Sentence 63"@en ;
    domo:Text "ADADELTA: an adaptive learning rate method."@en ;
    askg-onto:inSentence "ADADELTA: an adaptive learning rate method."^^xsd:string ;
    askg-onto:index "63"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adadelta,
        askg-data:Entity-an_adaptive_learning_rate_method .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2277 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Zitnick, and D."@en ;
    askg-onto:inSentence "Zitnick, and D."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-zitnick .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2278 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Parikh."@en ;
    askg-onto:inSentence "Parikh."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-parikh,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-227-Sentence-2279 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "CIDEr: Consensus-based image description evaluation."@en ;
    askg-onto:inSentence "CIDEr: Consensus-based image description evaluation."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cider,
        askg-data:Entity-consensus-based_image_description_evaluation .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "arXiv preprint arXiv:1212.5701, 2012. 10 [51] Y. Zhu, O. Groth, M. Bernstein, and L. Fei-Fei. Visual7w: Grounded question answering in images. In CVPR, 2016. 1, 2 [52] L. Zitnick and P. Dollar. Edge boxes: Locating object pro- ´ posals from edges. In ECCV, 2014. 2"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2281,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22810,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22811,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22812,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22813,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22814,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2282,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2283,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2284,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2285,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2286,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2287,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2288,
        askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2289 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "arXiv preprint arXiv:1212.5701, 2012."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1212.5701, 2012."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv,
        askg-data:Entity-arxiv12125701,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22810 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Zitnick and P."@en ;
    askg-onto:inSentence "Zitnick and P."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-person,
        askg-data:Entity-zitnick .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22811 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Dollar."@en ;
    askg-onto:inSentence "Dollar."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-currency,
        askg-data:Entity-dollar .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22812 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Edge boxes: Locating object pro- ´ posals from edges."@en ;
    askg-onto:inSentence "Edge boxes: Locating object pro- ´ posals from edges."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-edge_boxes,
        askg-data:Entity-edges .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22813 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "In ECCV, 2014."@en ;
    askg-onto:inSentence "In ECCV, 2014."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eccv .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-22814 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "2"@en ;
    askg-onto:inSentence "2"^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-organization,
        askg-data:Entity-research_group,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2282 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "10 [51] Y."@en ;
    askg-onto:inSentence "10 [51] Y."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10_51,
        askg-data:Entity-y .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2283 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Zhu, O."@en ;
    askg-onto:inSentence "Zhu, O."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhu_o .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2284 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Groth, M."@en ;
    askg-onto:inSentence "Groth, M."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-groth_m,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2285 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Bernstein, and L."@en ;
    askg-onto:inSentence "Bernstein, and L."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bernstein,
        askg-data:Entity-l,
        askg-data:Entity-person .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2286 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Fei-Fei."@en ;
    askg-onto:inSentence "Fei-Fei."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fei-fei,
        askg-data:Entity-scientist .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2287 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Visual7w: Grounded question answering in images."@en ;
    askg-onto:inSentence "Visual7w: Grounded question answering in images."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-framework,
        askg-data:Entity-grounded_question_answering,
        askg-data:Entity-images,
        askg-data:Entity-visual7w .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2288 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In CVPR, 2016."@en ;
    askg-onto:inSentence "In CVPR, 2016."^^xsd:string ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-22-Paragraph-228-Sentence-2289 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "1, 2 [52] L."@en ;
    askg-onto:inSentence "1, 2 [52] L."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_52,
        askg-data:Entity-l .

askg-data:Paper-11712fbcb9a80fb4-Section-23 a askg-onto:Section ;
    rdfs:label "Section 23"@en ;
    domo:Text "Supplementary Materials 6. Implementation Details 6.1. Bottom-Up Attention Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231 ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Our bottom-up attention Faster R-CNN implementation uses an IoU threshold of 0.7 for region proposal suppression, and 0.3 for object class suppression. To select salient image regions, a class detection confidence threshold of 0.2 is used, allowing the number of regions per image k to vary with the complexity of the image, up to a maximum of 100. However, in initial experiments we find that simply selecting the top 36 features in each image works almost as well in both downstream tasks. Since Visual Genome [21] contains a relatively large number of annotations per image, the model is relatively intensive to train. Using 8 Nvidia M40 GPUs, we take around 5 days to complete 380K training iterations, although we suspect that faster training regimes could also be effective."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2311,
        askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2312,
        askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2313,
        askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2314,
        askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2315 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our bottom-up attention Faster R-CNN implementation uses an IoU threshold of 0.7 for region proposal suppression, and 0.3 for object class suppression."@en ;
    askg-onto:inSentence "Our bottom-up attention Faster R-CNN implementation uses an IoU threshold of 0.7 for region proposal suppression, and 0.3 for object class suppression."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-iou_threshold_of_03,
        askg-data:Entity-iou_threshold_of_07 .

askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To select salient image regions, a class detection confidence threshold of 0.2 is used, allowing the number of regions per image k to vary with the complexity of the image, up to a maximum of 100."@en ;
    askg-onto:inSentence "To select salient image regions, a class detection confidence threshold of 0.2 is used, allowing the number of regions per image k to vary with the complexity of the image, up to a maximum of 100."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-02,
        askg-data:Entity-100,
        askg-data:Entity-class_detection_confidence_threshold,
        askg-data:Entity-complexity_of_the_image,
        askg-data:Entity-image_regions,
        askg-data:Entity-maximum,
        askg-data:Entity-number_of_regions_per_image,
        askg-data:Entity-salient .

askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, in initial experiments we find that simply selecting the top 36 features in each image works almost as well in both downstream tasks."@en ;
    askg-onto:inSentence "However, in initial experiments we find that simply selecting the top 36 features in each image works almost as well in both downstream tasks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-downstream_tasks,
        askg-data:Entity-top_36_features .

askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Since Visual Genome [21] contains a relatively large number of annotations per image, the model is relatively intensive to train."@en ;
    askg-onto:inSentence "Since Visual Genome [21] contains a relatively large number of annotations per image, the model is relatively intensive to train."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-annotations,
        askg-data:Entity-intensive_to_train,
        askg-data:Entity-model,
        askg-data:Entity-visual_genome .

askg-data:Paper-11712fbcb9a80fb4-Section-23-Paragraph-231-Sentence-2315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Using 8 Nvidia M40 GPUs, we take around 5 days to complete 380K training iterations, although we suspect that faster training regimes could also be effective."@en ;
    askg-onto:inSentence "Using 8 Nvidia M40 GPUs, we take around 5 days to complete 380K training iterations, although we suspect that faster training regimes could also be effective."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-380k,
        askg-data:Entity-8,
        askg-data:Entity-faster,
        askg-data:Entity-nvidia_m40_gpus,
        askg-data:Entity-training_iterations,
        askg-data:Entity-training_regimes .

askg-data:Paper-11712fbcb9a80fb4-Section-24 a askg-onto:Section ;
    rdfs:label "Section 24"@en ;
    domo:Text "6.2. Captioning Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241 ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In the captioning model, we set the number of hidden units M in each LSTM to 1,000, the number of hidden units H in the attention layer to 512, and the size of the input word embedding E to 1,000. In training, we use a simple learning rate schedule, beginning with a learning rate of 0.01 which is reduced to zero on a straight-line basis over 60K iterations using a batch size of 100 and a momentum parameter of 0.9. Training using two Nvidia Titan X GPUs takes around 9 hours (including less than one hour for CIDEr optimization). During optimization and decoding we use a beam size of 5. When decoding we also enforce the constraint that a single word cannot be predicted twice in a row. Note that in both our captioning and VQA models, image features are fixed and not finetuned."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2411,
        askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2412,
        askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2413,
        askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2414,
        askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2415,
        askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2416 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the captioning model, we set the number of hidden units M in each LSTM to 1,000, the number of hidden units H in the attention layer to 512, and the size of the input word embedding E to 1,000."@en ;
    askg-onto:inSentence "In the captioning model, we set the number of hidden units M in each LSTM to 1,000, the number of hidden units H in the attention layer to 512, and the size of the input word embedding E to 1,000."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1000,
        askg-data:Entity-512,
        askg-data:Entity-attention_layer,
        askg-data:Entity-captioning_model,
        askg-data:Entity-input_word_embedding,
        askg-data:Entity-lstm,
        askg-data:Entity-m .

askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In training, we use a simple learning rate schedule, beginning with a learning rate of 0.01 which is reduced to zero on a straight-line basis over 60K iterations using a batch size of 100 and a momentum parameter of 0.9."@en ;
    askg-onto:inSentence "In training, we use a simple learning rate schedule, beginning with a learning rate of 0.01 which is reduced to zero on a straight-line basis over 60K iterations using a batch size of 100 and a momentum parameter of 0.9."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-09,
        askg-data:Entity-batch_size_of_100,
        askg-data:Entity-iterations,
        askg-data:Entity-learning_rate_of_001,
        askg-data:Entity-learning_rate_schedule,
        askg-data:Entity-momentum_parameter,
        askg-data:Entity-zero .

askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Training using two Nvidia Titan X GPUs takes around 9 hours (including less than one hour for CIDEr optimization)."@en ;
    askg-onto:inSentence "Training using two Nvidia Titan X GPUs takes around 9 hours (including less than one hour for CIDEr optimization)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nvidia_titan_x_gpus,
        askg-data:Entity-training .

askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "During optimization and decoding we use a beam size of 5."@en ;
    askg-onto:inSentence "During optimization and decoding we use a beam size of 5."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-beam_size,
        askg-data:Entity-optimization_and_decoding .

askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "When decoding we also enforce the constraint that a single word cannot be predicted twice in a row."@en ;
    askg-onto:inSentence "When decoding we also enforce the constraint that a single word cannot be predicted twice in a row."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constraint,
        askg-data:Entity-single_word .

askg-data:Paper-11712fbcb9a80fb4-Section-24-Paragraph-241-Sentence-2416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Note that in both our captioning and VQA models, image features are fixed and not finetuned."@en ;
    askg-onto:inSentence "Note that in both our captioning and VQA models, image features are fixed and not finetuned."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_models,
        askg-data:Entity-fixed,
        askg-data:Entity-image_features,
        askg-data:Entity-not_finetuned,
        askg-data:Entity-vqa_models .

askg-data:Paper-11712fbcb9a80fb4-Section-25 a askg-onto:Section ;
    rdfs:label "Section 25"@en ;
    domo:Text "6.3. Vqa Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251 ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In the VQA model, we use 300 dimension word embeddings, initialized with pretrained GloVe vectors [31], and we use hidden states of dimension 512. We train the VQA model using AdaDelta [50] and regularize with early stopping. The training of the model takes in the order of 12–18 hours on a single Nvidia K40 GPU. Refer to Teney et al. [38] for further details of the VQA model implementation."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2511,
        askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2512,
        askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2513,
        askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2514,
        askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2515 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the VQA model, we use 300 dimension word embeddings, initialized with pretrained GloVe vectors [31], and we use hidden states of dimension 512."@en ;
    askg-onto:inSentence "In the VQA model, we use 300 dimension word embeddings, initialized with pretrained GloVe vectors [31], and we use hidden states of dimension 512."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-300_dimension_word_embeddings,
        askg-data:Entity-hidden_states_of_dimension_512,
        askg-data:Entity-pretrained_glove_vectors,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We train the VQA model using AdaDelta [50] and regularize with early stopping."@en ;
    askg-onto:inSentence "We train the VQA model using AdaDelta [50] and regularize with early stopping."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adadelta,
        askg-data:Entity-early_stopping,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The training of the model takes in the order of 12–18 hours on a single Nvidia K40 GPU."@en ;
    askg-onto:inSentence "The training of the model takes in the order of 12–18 hours on a single Nvidia K40 GPU."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1218_hours,
        askg-data:Entity-equipment,
        askg-data:Entity-model,
        askg-data:Entity-nvidia_k40_gpu .

askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Refer to Teney et al."@en ;
    askg-onto:inSentence "Refer to Teney et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-teney_et_al .

askg-data:Paper-11712fbcb9a80fb4-Section-25-Paragraph-251-Sentence-2515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "[38] for further details of the VQA model implementation."@en ;
    askg-onto:inSentence "[38] for further details of the VQA model implementation."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-details,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-26 a askg-onto:Section ;
    rdfs:label "Section 26"@en ;
    domo:Text "7. Additional Examples"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2610,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2611,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2612,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2613,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2615,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-262,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-264,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-265,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-266,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-268,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269 ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Figure 7 we qualitatively compare attention methodologies for image caption generation, by illustrating attention weights for the ResNet baseline and our full Up-Down model on the same image. The baseline ResNet model hallucinates a toilet and therefore generates a poor quality caption. In contrast, our Up-Down model correctly identifies the couch, despite the novel scene composition. Additional examples of generated captions can be found in Figures 8 and 9. Additional visual question answering examples can be found in Figures 10 and 11."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2611,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2612,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2613,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2614,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2615 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Figure 7 we qualitatively compare attention methodologies for image caption generation, by illustrating attention weights for the ResNet baseline and our full Up-Down model on the same image."@en ;
    askg-onto:inSentence "In Figure 7 we qualitatively compare attention methodologies for image caption generation, by illustrating attention weights for the ResNet baseline and our full Up-Down model on the same image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_methodologies,
        askg-data:Entity-attention_weights,
        askg-data:Entity-image,
        askg-data:Entity-image_caption_generation,
        askg-data:Entity-model,
        askg-data:Entity-resnet_baseline,
        askg-data:Entity-up-down_model .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The baseline ResNet model hallucinates a toilet and therefore generates a poor quality caption."@en ;
    askg-onto:inSentence "The baseline ResNet model hallucinates a toilet and therefore generates a poor quality caption."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-poor_quality_caption,
        askg-data:Entity-resnet_model,
        askg-data:Entity-toilet .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In contrast, our Up-Down model correctly identifies the couch, despite the novel scene composition."@en ;
    askg-onto:inSentence "In contrast, our Up-Down model correctly identifies the couch, despite the novel scene composition."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-couch,
        askg-data:Entity-up-down_model .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Additional examples of generated captions can be found in Figures 8 and 9."@en ;
    askg-onto:inSentence "Additional examples of generated captions can be found in Figures 8 and 9."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figures_8_and_9,
        askg-data:Entity-generated_captions .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-261-Sentence-2615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Additional visual question answering examples can be found in Figures 10 and 11."@en ;
    askg-onto:inSentence "Additional visual question answering examples can be found in Figures 10 and 11."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-visual_question_answering_examples .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2610 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "region cropping that misses the dog's head and feet."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2610-Sentence-26101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2610-Sentence-26101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "region cropping that misses the dog's head and feet."@en ;
    askg-onto:inSentence "region cropping that misses the dog's head and feet."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dogs_head_and_feet,
        askg-data:Entity-region_cropping .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2611 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2611-Sentence-26111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2611-Sentence-26111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:inSentence "![13_image_0.png](13_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-university,
        askg-data:Entity-university_of_california_berkeley .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2612 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "Figure 10. Further examples of successful visual question answering results, showing attended image regions."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2612-Sentence-26121,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2612-Sentence-26122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2612-Sentence-26121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 10."@en ;
    askg-onto:inSentence "Figure 10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_10 .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2612-Sentence-26122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Further examples of successful visual question answering results, showing attended image regions."@en ;
    askg-onto:inSentence "Further examples of successful visual question answering results, showing attended image regions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attended_image_regions,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2613 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2613-Sentence-26131 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2613-Sentence-26131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:inSentence "![14_image_0.png](14_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coco,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-deeplab,
        askg-data:Entity-deeplab_v3,
        askg-data:Entity-faster_r-cnn,
        askg-data:Entity-image_classification,
        askg-data:Entity-image_segmentation_model,
        askg-data:Entity-image_segmentation_tasks,
        askg-data:Entity-imagenet,
        askg-data:Entity-mask_r-cnn,
        askg-data:Entity-object_detection_and_segmentation,
        askg-data:Entity-object_detection_model,
        askg-data:Entity-pascal_voc,
        askg-data:Entity-pascal_voc_2012,
        askg-data:Entity-university_of_california_san_diego .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "Figure 11. Examples of visual question answering (VQA) failure cases. Although our simple VQA model has limited reading and counting"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614-Sentence-26141,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614-Sentence-26142,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614-Sentence-26143 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614-Sentence-26141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 11."@en ;
    askg-onto:inSentence "Figure 11."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614-Sentence-26142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Examples of visual question answering (VQA) failure cases."@en ;
    askg-onto:inSentence "Examples of visual question answering (VQA) failure cases."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-failure_cases,
        askg-data:Entity-visual_question_answering .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2614-Sentence-26143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Although our simple VQA model has limited reading and counting"@en ;
    askg-onto:inSentence "Although our simple VQA model has limited reading and counting"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-limited_reading_and_counting,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2615 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "capabilities, the attention maps are often correctly focused."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2615-Sentence-26151 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-2615-Sentence-26151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "capabilities, the attention maps are often correctly focused."@en ;
    askg-onto:inSentence "capabilities, the attention maps are often correctly focused."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_maps,
        askg-data:Entity-capabilities .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-262 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![10_image_0.png](10_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-262-Sentence-2621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-262-Sentence-2621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![10_image_0.png](10_image_0.png)"@en ;
    askg-onto:inSentence "![10_image_0.png](10_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-city,
        askg-data:Entity-concept,
        askg-data:Entity-database,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-scientist,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 7. Qualitative differences between attention methodologies in caption generation. For each generated word, we visualize the attended image region, outlining the region with the maximum attention weight in red. The selected image is unusual because it depicts a bathroom containing a couch but no toilet. Nevertheless, our baseline ResNet model (top) hallucinates a toilet, presumably from language priors, and therefore generates a poor quality caption. In contrast, our Up-Down model (bottom) clearly identifies the out-of-context couch, generating a correct caption while also providing more interpretable attention weights."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2631,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2632,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2633,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2634,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2635,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2636 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 7."@en ;
    askg-onto:inSentence "Figure 7."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Qualitative differences between attention methodologies in caption generation."@en ;
    askg-onto:inSentence "Qualitative differences between attention methodologies in caption generation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_methodologies,
        askg-data:Entity-caption_generation .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For each generated word, we visualize the attended image region, outlining the region with the maximum attention weight in red."@en ;
    askg-onto:inSentence "For each generated word, we visualize the attended image region, outlining the region with the maximum attention weight in red."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attended_image_region,
        askg-data:Entity-generated_word,
        askg-data:Entity-maximum_attention_weight .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The selected image is unusual because it depicts a bathroom containing a couch but no toilet."@en ;
    askg-onto:inSentence "The selected image is unusual because it depicts a bathroom containing a couch but no toilet."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bathroom,
        askg-data:Entity-couch,
        askg-data:Entity-image,
        askg-data:Entity-toilet .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2635 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Nevertheless, our baseline ResNet model (top) hallucinates a toilet, presumably from language priors, and therefore generates a poor quality caption."@en ;
    askg-onto:inSentence "Nevertheless, our baseline ResNet model (top) hallucinates a toilet, presumably from language priors, and therefore generates a poor quality caption."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-resnet_model,
        askg-data:Entity-toilet .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-263-Sentence-2636 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In contrast, our Up-Down model (bottom) clearly identifies the out-of-context couch, generating a correct caption while also providing more interpretable attention weights."@en ;
    askg-onto:inSentence "In contrast, our Up-Down model (bottom) clearly identifies the out-of-context couch, generating a correct caption while also providing more interpretable attention weights."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-caption,
        askg-data:Entity-model,
        askg-data:Entity-up-down_model .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-264 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "A group of people are playing a video game."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-264-Sentence-2641 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-264-Sentence-2641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A group of people are playing a video game."@en ;
    askg-onto:inSentence "A group of people are playing a video game."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-group_of_people,
        askg-data:Entity-video_game .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-265 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![11_image_0.png](11_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-265-Sentence-2651 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-265-Sentence-2651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![11_image_0.png](11_image_0.png)"@en ;
    askg-onto:inSentence "![11_image_0.png](11_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bioengineering_methods,
        askg-data:Entity-engineering,
        askg-data:Entity-tissue_engineering,
        askg-data:Entity-university_of_california_san_francisco .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-266 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![11_image_1.png](11_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-266-Sentence-2661 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-266-Sentence-2661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![11_image_1.png](11_image_1.png)"@en ;
    askg-onto:inSentence "![11_image_1.png](11_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_analysis,
        askg-data:Entity-institution,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-protein,
        askg-data:Entity-protein_structure,
        askg-data:Entity-research_group,
        askg-data:Entity-scientific_method,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Figure 8. Examples of generated captions showing attended image regions. Attention is given to fine details, such as: (1) the man's hands holding the game controllers in the top image, and (2) the sheep's legs when generating the word 'standing' in the middle image. Our approach can avoid the trade-off between coarse and fine levels of detail."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2671,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2672,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2673,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2674 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 8."@en ;
    askg-onto:inSentence "Figure 8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_8 .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2672 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Examples of generated captions showing attended image regions."@en ;
    askg-onto:inSentence "Examples of generated captions showing attended image regions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attended_image_regions,
        askg-data:Entity-captions .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2673 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Attention is given to fine details, such as: (1) the man's hands holding the game controllers in the top image, and (2) the sheep's legs when generating the word 'standing' in the middle image."@en ;
    askg-onto:inSentence "Attention is given to fine details, such as: (1) the man's hands holding the game controllers in the top image, and (2) the sheep's legs when generating the word 'standing' in the middle image."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-game_controllers,
        askg-data:Entity-legs,
        askg-data:Entity-man,
        askg-data:Entity-sheeps_legs,
        askg-data:Entity-word_standing .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-267-Sentence-2674 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our approach can avoid the trade-off between coarse and fine levels of detail."@en ;
    askg-onto:inSentence "Our approach can avoid the trade-off between coarse and fine levels of detail."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_approach,
        askg-data:Entity-the_trade-off_between_coarse_and_fine_levels_of_detail .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-268 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-268-Sentence-2681 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-268-Sentence-2681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:inSentence "![12_image_0.png](12_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-study,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Figure 9. Further examples of generated captions showing attended image regions. The first example suggests an understanding of spatial relationships when generating the word 'together'. The middle image demonstrates the successful captioning of a compositionally novel scene. The bottom example is a failure case. The dog's pose is mistaken for laying, rather than jumping - possibly due to poor salient"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2691,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2692,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2693,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2694,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2695,
        askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2696 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 9."@en ;
    askg-onto:inSentence "Figure 9."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_9 .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2692 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Further examples of generated captions showing attended image regions."@en ;
    askg-onto:inSentence "Further examples of generated captions showing attended image regions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captions,
        askg-data:Entity-image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2693 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The first example suggests an understanding of spatial relationships when generating the word 'together'."@en ;
    askg-onto:inSentence "The first example suggests an understanding of spatial relationships when generating the word 'together'."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-spatial_relationships,
        askg-data:Entity-the_word_together .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2694 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The middle image demonstrates the successful captioning of a compositionally novel scene."@en ;
    askg-onto:inSentence "The middle image demonstrates the successful captioning of a compositionally novel scene."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_of_a_compositionally_novel_scene,
        askg-data:Entity-middle_image .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2695 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The bottom example is a failure case."@en ;
    askg-onto:inSentence "The bottom example is a failure case."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-failure_case,
        askg-data:Entity-finding .

askg-data:Paper-11712fbcb9a80fb4-Section-26-Paragraph-269-Sentence-2696 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The dog's pose is mistaken for laying, rather than jumping - possibly due to poor salient"@en ;
    askg-onto:inSentence "The dog's pose is mistaken for laying, rather than jumping - possibly due to poor salient"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dog,
        askg-data:Entity-jumping,
        askg-data:Entity-laying .

askg-data:Paper-11712fbcb9a80fb4-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "1. Introduction"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-33,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37 ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Problems combining image and language understanding such as image captioning [4] and visual question answering (VQA) [12] continue to inspire considerable research at the boundary of computer vision and natural language processing. In both these tasks it is often necessary to perform some fine-grained visual processing, or even multiple steps of reasoning to generate high quality outputs. As a result, visual attention mechanisms have been widely adopted in both image captioning [34, 27, 48, 46] and VQA [11, 28, 45, 47, 51]. These mechanisms improve performance by learning to focus on the regions of the image that are salient and are currently based on deep neural network architectures."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-311,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-312,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-313,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-314 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Problems combining image and language understanding such as image captioning [4] and visual question answering (VQA) [12] continue to inspire considerable research at the boundary of computer vision and natural language processing."@en ;
    askg-onto:inSentence "Problems combining image and language understanding such as image captioning [4] and visual question answering (VQA) [12] continue to inspire considerable research at the boundary of computer vision and natural language processing."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision,
        askg-data:Entity-computer_vision_and_natural_language_processing,
        askg-data:Entity-image_captioning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-visual_question_answering_vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In both these tasks it is often necessary to perform some fine-grained visual processing, or even multiple steps of reasoning to generate high quality outputs."@en ;
    askg-onto:inSentence "In both these tasks it is often necessary to perform some fine-grained visual processing, or even multiple steps of reasoning to generate high quality outputs."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fine-grained_visual_processing,
        askg-data:Entity-high_quality_outputs,
        askg-data:Entity-multiple_steps_of_reasoning .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As a result, visual attention mechanisms have been widely adopted in both image captioning [34, 27, 48, 46] and VQA [11, 28, 45, 47, 51]."@en ;
    askg-onto:inSentence "As a result, visual attention mechanisms have been widely adopted in both image captioning [34, 27, 48, 46] and VQA [11, 28, 45, 47, 51]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-visual_attention_mechanisms,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-31-Sentence-314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These mechanisms improve performance by learning to focus on the regions of the image that are salient and are currently based on deep neural network architectures."@en ;
    askg-onto:inSentence "These mechanisms improve performance by learning to focus on the regions of the image that are salient and are currently based on deep neural network architectures."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_neural_network_architectures,
        askg-data:Entity-mechanisms,
        askg-data:Entity-regions_of_the_image_that_are_salient .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Figure 1. Typically, attention models operate on CNN features corresponding to a uniform grid of equally-sized image regions (left). Our approach enables attention to be calculated at the level of objects and other salient image regions (right)."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32-Sentence-321,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32-Sentence-322,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32-Sentence-323 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32-Sentence-321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 1."@en ;
    askg-onto:inSentence "Figure 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-figure_1 .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32-Sentence-322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Typically, attention models operate on CNN features corresponding to a uniform grid of equally-sized image regions (left)."@en ;
    askg-onto:inSentence "Typically, attention models operate on CNN features corresponding to a uniform grid of equally-sized image regions (left)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_models,
        askg-data:Entity-cnn_features .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-32-Sentence-323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our approach enables attention to be calculated at the level of objects and other salient image regions (right)."@en ;
    askg-onto:inSentence "Our approach enables attention to be calculated at the level of objects and other salient image regions (right)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-calculations_at_the_level_of_objects_and_other_salient_image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-33 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "In the human visual system, attention can be focused volitionally by top-down signals determined by the current task (e.g., looking for something), and automatically by bottom-up signals associated with unexpected, novel or salient stimuli [3, 6]. In this paper we adopt similar terminology and refer to attention mechanisms driven by nonvisual or task-specific context as 'top-down', and purely visual feed-forward attention mechanisms as 'bottom-up'."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-33-Sentence-331,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-33-Sentence-332 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-33-Sentence-331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the human visual system, attention can be focused volitionally by top-down signals determined by the current task (e.g., looking for something), and automatically by bottom-up signals associated with unexpected, novel or salient stimuli [3, 6]."@en ;
    askg-onto:inSentence "In the human visual system, attention can be focused volitionally by top-down signals determined by the current task (e.g., looking for something), and automatically by bottom-up signals associated with unexpected, novel or salient stimuli [3, 6]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-bottom-up_signals,
        askg-data:Entity-current_task,
        askg-data:Entity-human_visual_system,
        askg-data:Entity-novel_stimuli,
        askg-data:Entity-salient_stimuli,
        askg-data:Entity-top-down_signals,
        askg-data:Entity-unexpected_stimuli .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-33-Sentence-332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In this paper we adopt similar terminology and refer to attention mechanisms driven by nonvisual or task-specific context as 'top-down', and purely visual feed-forward attention mechanisms as 'bottom-up'."@en ;
    askg-onto:inSentence "In this paper we adopt similar terminology and refer to attention mechanisms driven by nonvisual or task-specific context as 'top-down', and purely visual feed-forward attention mechanisms as 'bottom-up'."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_mechanisms,
        askg-data:Entity-bottom-up,
        askg-data:Entity-nonvisual_or_task-specific_context,
        askg-data:Entity-top-down .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Most conventional visual attention mechanisms used in image captioning and VQA are of the top-down variety. Taking as context a representation of a partially-completed caption output, or a question relating to the image, these mechanisms are typically trained to selectively attend to the output of one or more layers of a convolutional neural net (CNN). However, this approach gives little consideration to how the image regions that are subject to attention are determined. As illustrated conceptually in Figure 1, the resulting 1"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-341,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-342,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-343,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-344 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Most conventional visual attention mechanisms used in image captioning and VQA are of the top-down variety."@en ;
    askg-onto:inSentence "Most conventional visual attention mechanisms used in image captioning and VQA are of the top-down variety."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-top-down_variety,
        askg-data:Entity-visual_attention_mechanisms,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Taking as context a representation of a partially-completed caption output, or a question relating to the image, these mechanisms are typically trained to selectively attend to the output of one or more layers of a convolutional neural net (CNN)."@en ;
    askg-onto:inSentence "Taking as context a representation of a partially-completed caption output, or a question relating to the image, these mechanisms are typically trained to selectively attend to the output of one or more layers of a convolutional neural net (CNN)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn,
        askg-data:Entity-convolutional_neural_net,
        askg-data:Entity-mechanisms,
        askg-data:Entity-output_of_layers_of_convolutional_neural_net .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, this approach gives little consideration to how the image regions that are subject to attention are determined."@en ;
    askg-onto:inSentence "However, this approach gives little consideration to how the image regions that are subject to attention are determined."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-34-Sentence-344 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As illustrated conceptually in Figure 1, the resulting 1"@en ;
    askg-onto:inSentence "As illustrated conceptually in Figure 1, the resulting 1"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_1,
        askg-data:Entity-resulting_1 .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "∗Work performed while interning at Microsoft. input regions correspond to a uniform grid of equally sized and shaped neural receptive fields - irrespective of the content of the image. To generate more human-like captions and question answers, objects and other salient image regions are a much more natural basis for attention [10, 36]."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35-Sentence-351,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35-Sentence-352,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35-Sentence-353 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35-Sentence-351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "∗Work performed while interning at Microsoft."@en ;
    askg-onto:inSentence "∗Work performed while interning at Microsoft."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-microsoft,
        askg-data:Entity-work .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35-Sentence-352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "input regions correspond to a uniform grid of equally sized and shaped neural receptive fields - irrespective of the content of the image."@en ;
    askg-onto:inSentence "input regions correspond to a uniform grid of equally sized and shaped neural receptive fields - irrespective of the content of the image."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_regions,
        askg-data:Entity-uniform_grid_of_equally_sized_and_shaped_neural_receptive_fields .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-35-Sentence-353 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To generate more human-like captions and question answers, objects and other salient image regions are a much more natural basis for attention [10, 36]."@en ;
    askg-onto:inSentence "To generate more human-like captions and question answers, objects and other salient image regions are a much more natural basis for attention [10, 36]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-objects,
        askg-data:Entity-salient_image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "In this paper we propose a combined bottom-up and topdown visual attention mechanism. The bottom-up mechanism proposes a set of salient image regions, with each region represented by a pooled convolutional feature vector. Practically, we implement bottom-up attention using Faster R-CNN [33], which represents a natural expression of a bottom-up attention mechanism. The top-down mechanism uses task-specific context to predict an attention distribution over the image regions. The attended feature vector is then computed as a weighted average of image features over all regions."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-361,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-362,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-363,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-364,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-365 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this paper we propose a combined bottom-up and topdown visual attention mechanism."@en ;
    askg-onto:inSentence "In this paper we propose a combined bottom-up and topdown visual attention mechanism."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-combined_bottom-up_and_topdown,
        askg-data:Entity-visual_attention_mechanism .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The bottom-up mechanism proposes a set of salient image regions, with each region represented by a pooled convolutional feature vector."@en ;
    askg-onto:inSentence "The bottom-up mechanism proposes a set of salient image regions, with each region represented by a pooled convolutional feature vector."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_mechanism,
        askg-data:Entity-salient_image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-363 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Practically, we implement bottom-up attention using Faster R-CNN [33], which represents a natural expression of a bottom-up attention mechanism."@en ;
    askg-onto:inSentence "Practically, we implement bottom-up attention using Faster R-CNN [33], which represents a natural expression of a bottom-up attention mechanism."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-faster_r-cnn .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-364 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The top-down mechanism uses task-specific context to predict an attention distribution over the image regions."@en ;
    askg-onto:inSentence "The top-down mechanism uses task-specific context to predict an attention distribution over the image regions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_distribution,
        askg-data:Entity-image_regions,
        askg-data:Entity-task-specific_context,
        askg-data:Entity-top-down_mechanism .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-36-Sentence-365 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The attended feature vector is then computed as a weighted average of image features over all regions."@en ;
    askg-onto:inSentence "The attended feature vector is then computed as a weighted average of image features over all regions."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attended_feature_vector,
        askg-data:Entity-weighted_average_of_image_features .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "We evaluate the impact of combining bottom-up and topdown attention on two tasks. We first present an image captioning model that takes multiple glimpses of salient image regions during caption generation. Empirically, we find that the inclusion of bottom-up attention has a significant positive benefit for image captioning. Our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9. respectively (outperforming all published and unpublished work at the time). Demonstrating the broad applicability of the method, we additionally present a VQA model using the same bottom-up attention features. Using this model we obtain first place in the 2017 VQA Challenge, achieving 70.3% overall accuracy on the VQA v2.0 test-standard server. Code, models and pre-computed image features are available from the project website1."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-371,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-372,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-373,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-374,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-375,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-376,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-377,
        askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-378 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We evaluate the impact of combining bottom-up and topdown attention on two tasks."@en ;
    askg-onto:inSentence "We evaluate the impact of combining bottom-up and topdown attention on two tasks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_and_topdown_attention,
        askg-data:Entity-two_tasks .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-372 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We first present an image captioning model that takes multiple glimpses of salient image regions during caption generation."@en ;
    askg-onto:inSentence "We first present an image captioning model that takes multiple glimpses of salient image regions during caption generation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning_model,
        askg-data:Entity-multiple_glimpses_of_salient_image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-373 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Empirically, we find that the inclusion of bottom-up attention has a significant positive benefit for image captioning."@en ;
    askg-onto:inSentence "Empirically, we find that the inclusion of bottom-up attention has a significant positive benefit for image captioning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-image_captioning .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-374 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9."@en ;
    askg-onto:inSentence "Our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1179_215_and_369,
        askg-data:Entity-cider__spice__bleu-4_scores,
        askg-data:Entity-mscoco_test_server,
        askg-data:Entity-new_state-of-the-art .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-375 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "respectively (outperforming all published and unpublished work at the time)."@en ;
    askg-onto:inSentence "respectively (outperforming all published and unpublished work at the time)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-published_and_unpublished_work,
        askg-data:Entity-work .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-376 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Demonstrating the broad applicability of the method, we additionally present a VQA model using the same bottom-up attention features."@en ;
    askg-onto:inSentence "Demonstrating the broad applicability of the method, we additionally present a VQA model using the same bottom-up attention features."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention_features,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-377 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Using this model we obtain first place in the 2017 VQA Challenge, achieving 70.3% overall accuracy on the VQA v2.0 test-standard server."@en ;
    askg-onto:inSentence "Using this model we obtain first place in the 2017 VQA Challenge, achieving 70.3% overall accuracy on the VQA v2.0 test-standard server."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-703_overall_accuracy,
        askg-data:Entity-first_place_in_the_2017_vqa_challenge,
        askg-data:Entity-model,
        askg-data:Entity-vqa_v20_test-standard_server .

askg-data:Paper-11712fbcb9a80fb4-Section-3-Paragraph-37-Sentence-378 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Code, models and pre-computed image features are available from the project website1."@en ;
    askg-onto:inSentence "Code, models and pre-computed image features are available from the project website1."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-code_models_and_pre-computed_image_features,
        askg-data:Entity-project_website .

askg-data:Paper-11712fbcb9a80fb4-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "2. Related Work"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "A large number of attention-based deep neural networks have been proposed for image captioning and VQA. Typically, these models can be characterized as top-down approaches, with context provided by a representation of a partially-completed caption in the case of image captioning [34, 27, 48, 46], or a representation of the question in the case of VQA [11, 28, 45, 47, 51]. In each case attention is applied to the output of one or more layers of a CNN, by predicting a weighting for each spatial location in the CNN output. However, determining the optimal number of image regions invariably requires an unwinnable trade-off between coarse and fine levels of detail. Furthermore, the arbitrary positioning of the regions with respect to image content may make it more difficult to detect objects that are poorly aligned to regions and to bind visual concepts associated with the same object."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-413,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-414,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-415 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A large number of attention-based deep neural networks have been proposed for image captioning and VQA."@en ;
    askg-onto:inSentence "A large number of attention-based deep neural networks have been proposed for image captioning and VQA."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention-based_deep_neural_networks,
        askg-data:Entity-image_captioning,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Typically, these models can be characterized as top-down approaches, with context provided by a representation of a partially-completed caption in the case of image captioning [34, 27, 48, 46], or a representation of the question in the case of VQA [11, 28, 45, 47, 51]."@en ;
    askg-onto:inSentence "Typically, these models can be characterized as top-down approaches, with context provided by a representation of a partially-completed caption in the case of image captioning [34, 27, 48, 46], or a representation of the question in the case of VQA [11, 28, 45, 47, 51]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning,
        askg-data:Entity-models,
        askg-data:Entity-representation_of_a_partially-completed_caption,
        askg-data:Entity-representation_of_the_question,
        askg-data:Entity-top-down_approaches,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In each case attention is applied to the output of one or more layers of a CNN, by predicting a weighting for each spatial location in the CNN output."@en ;
    askg-onto:inSentence "In each case attention is applied to the output of one or more layers of a CNN, by predicting a weighting for each spatial location in the CNN output."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-cnn,
        askg-data:Entity-cnn_output,
        askg-data:Entity-output_of_one_or_more_layers_of_a_cnn,
        askg-data:Entity-spatial_location .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, determining the optimal number of image regions invariably requires an unwinnable trade-off between coarse and fine levels of detail."@en ;
    askg-onto:inSentence "However, determining the optimal number of image regions invariably requires an unwinnable trade-off between coarse and fine levels of detail."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimal_number_of_image_regions,
        askg-data:Entity-trade-off_between_coarse_and_fine_levels_of_detail .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-41-Sentence-415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Furthermore, the arbitrary positioning of the regions with respect to image content may make it more difficult to detect objects that are poorly aligned to regions and to bind visual concepts associated with the same object."@en ;
    askg-onto:inSentence "Furthermore, the arbitrary positioning of the regions with respect to image content may make it more difficult to detect objects that are poorly aligned to regions and to bind visual concepts associated with the same object."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_content,
        askg-data:Entity-object,
        askg-data:Entity-objects,
        askg-data:Entity-regions,
        askg-data:Entity-visual_concepts .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Comparatively few previous works have considered applying attention to salient image regions. We are aware of two papers. Jin et al. [18] use selective search [42] to identify salient image regions, which are filtered with a classifier then resized and CNN-encoded as input to an image captioning model with attention. The Areas of Attention captioning model [30] uses either edge boxes [52] or spatial transformer networks [17] to generate image features, which are processed using an attention model based on three bi-linear pairwise interactions [30]. In this work, rather than using hand-crafted or differentiable region proposals [42, 52, 17], we leverage Faster R-CNN [33], establishing a closer link between vision and language tasks and recent progress in object detection. With this approach we are able to pre-train our region proposals on object detection datasets. Conceptually, the advantages should be similar to pre-training visual representations on ImageNet [35] and leveraging significantly larger cross-domain knowledge. We additionally apply our method to VQA, establishing the broad applicability of our approach."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-421,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-422,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-423,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-424,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-425,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-426,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-427,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-428,
        askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-429 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Comparatively few previous works have considered applying attention to salient image regions."@en ;
    askg-onto:inSentence "Comparatively few previous works have considered applying attention to salient image regions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-salient_image_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We are aware of two papers."@en ;
    askg-onto:inSentence "We are aware of two papers."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-two_papers,
        askg-data:Entity-we .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Jin et al."@en ;
    askg-onto:inSentence "Jin et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jin_et_al,
        askg-data:Entity-research_group .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "[18] use selective search [42] to identify salient image regions, which are filtered with a classifier then resized and CNN-encoded as input to an image captioning model with attention."@en ;
    askg-onto:inSentence "[18] use selective search [42] to identify salient image regions, which are filtered with a classifier then resized and CNN-encoded as input to an image captioning model with attention."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-classifier,
        askg-data:Entity-image_captioning_model,
        askg-data:Entity-image_regions,
        askg-data:Entity-selective_search .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The Areas of Attention captioning model [30] uses either edge boxes [52] or spatial transformer networks [17] to generate image features, which are processed using an attention model based on three bi-linear pairwise interactions [30]."@en ;
    askg-onto:inSentence "The Areas of Attention captioning model [30] uses either edge boxes [52] or spatial transformer networks [17] to generate image features, which are processed using an attention model based on three bi-linear pairwise interactions [30]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-areas_of_attention_captioning_model,
        askg-data:Entity-attention_model,
        askg-data:Entity-edge_boxes,
        askg-data:Entity-image_features,
        askg-data:Entity-spatial_transformer_networks,
        askg-data:Entity-three_bi-linear_pairwise_interactions .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In this work, rather than using hand-crafted or differentiable region proposals [42, 52, 17], we leverage Faster R-CNN [33], establishing a closer link between vision and language tasks and recent progress in object detection."@en ;
    askg-onto:inSentence "In this work, rather than using hand-crafted or differentiable region proposals [42, 52, 17], we leverage Faster R-CNN [33], establishing a closer link between vision and language tasks and recent progress in object detection."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-object_detection .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-427 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "With this approach we are able to pre-train our region proposals on object detection datasets."@en ;
    askg-onto:inSentence "With this approach we are able to pre-train our region proposals on object detection datasets."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-object_detection_datasets,
        askg-data:Entity-region_proposals .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-428 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Conceptually, the advantages should be similar to pre-training visual representations on ImageNet [35] and leveraging significantly larger cross-domain knowledge."@en ;
    askg-onto:inSentence "Conceptually, the advantages should be similar to pre-training visual representations on ImageNet [35] and leveraging significantly larger cross-domain knowledge."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cross-domain_knowledge,
        askg-data:Entity-imagenet,
        askg-data:Entity-larger_knowledge,
        askg-data:Entity-visual_representations .

askg-data:Paper-11712fbcb9a80fb4-Section-4-Paragraph-42-Sentence-429 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "We additionally apply our method to VQA, establishing the broad applicability of our approach."@en ;
    askg-onto:inSentence "We additionally apply our method to VQA, establishing the broad applicability of our approach."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "3. Approach"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-51,
        askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Given an image I, both our image captioning model and our VQA model take as input a possibly variably-sized set of k image features, V = {v1*, ...,* vk}, vi ∈ R D, such that each image feature encodes a salient region of the image."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-51-Sentence-511 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Given an image I, both our image captioning model and our VQA model take as input a possibly variably-sized set of k image features, V = {v1*, ...,* vk}, vi ∈ R D, such that each image feature encodes a salient region of the image."@en ;
    askg-onto:inSentence "Given an image I, both our image captioning model and our VQA model take as input a possibly variably-sized set of k image features, V = {v1*, ...,* vk}, vi ∈ R D, such that each image feature encodes a salient region of the image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning_model,
        askg-data:Entity-image_features,
        askg-data:Entity-salient_region_of_the_image,
        askg-data:Entity-set_of_k_image_features,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The spatial image features V can be variously defined as the output of our bottom-up attention model, or, following standard practice, as the spatial output layer of a CNN. We describe our approach to implementing a bottom-up attention model in Section 3.1. In Section 3.2 we outline the architecture of our image captioning model and in Section 3.3 we outline our VQA model. We note that for the top-down attention component, both models use simple one-pass attention mechanisms, as opposed to the more complex schemes of recent models such as stacked, multi-headed, or bidirectional attention [47, 16, 20, 28] that could also be applied."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-521,
        askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-522,
        askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-523,
        askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-524 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The spatial image features V can be variously defined as the output of our bottom-up attention model, or, following standard practice, as the spatial output layer of a CNN."@en ;
    askg-onto:inSentence "The spatial image features V can be variously defined as the output of our bottom-up attention model, or, following standard practice, as the spatial output layer of a CNN."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-output_of_our_bottom-up_attention_model,
        askg-data:Entity-spatial_image_features_v,
        askg-data:Entity-spatial_output_layer_of_a_cnn .

askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We describe our approach to implementing a bottom-up attention model in Section 3.1."@en ;
    askg-onto:inSentence "We describe our approach to implementing a bottom-up attention model in Section 3.1."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-bottom-up_attention_model .

askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In Section 3.2 we outline the architecture of our image captioning model and in Section 3.3 we outline our VQA model."@en ;
    askg-onto:inSentence "In Section 3.2 we outline the architecture of our image captioning model and in Section 3.3 we outline our VQA model."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_captioning_model,
        askg-data:Entity-vqa_model .

askg-data:Paper-11712fbcb9a80fb4-Section-5-Paragraph-52-Sentence-524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We note that for the top-down attention component, both models use simple one-pass attention mechanisms, as opposed to the more complex schemes of recent models such as stacked, multi-headed, or bidirectional attention [47, 16, 20, 28] that could also be applied."@en ;
    askg-onto:inSentence "We note that for the top-down attention component, both models use simple one-pass attention mechanisms, as opposed to the more complex schemes of recent models such as stacked, multi-headed, or bidirectional attention [47, 16, 20, 28] that could also be applied."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_mechanisms,
        askg-data:Entity-bidirectional_attention,
        askg-data:Entity-models,
        askg-data:Entity-multi-headed_attention,
        askg-data:Entity-recent_models,
        askg-data:Entity-simple_one-pass_attention_mechanisms,
        askg-data:Entity-stacked_attention,
        askg-data:Entity-top-down_attention_component .

askg-data:Paper-11712fbcb9a80fb4-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "3.1. Bottom-Up Attention Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-61,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-610,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-611,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-64,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-65,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-68,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-69 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The definition of spatial image features V is generic."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-61-Sentence-611 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The definition of spatial image features V is generic."@en ;
    askg-onto:inSentence "The definition of spatial image features V is generic."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generic,
        askg-data:Entity-spatial_image_features_v .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-610 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "![2_image_0.png](2_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-610-Sentence-6101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-610-Sentence-6101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![2_image_0.png](2_image_0.png)"@en ;
    askg-onto:inSentence "![2_image_0.png](2_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning,
        askg-data:Entity-imagenet,
        askg-data:Entity-machine_learning,
        askg-data:Entity-pytorch,
        askg-data:Entity-software,
        askg-data:Entity-technology,
        askg-data:Entity-tensorflow,
        askg-data:Entity-university_of_california .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-611 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "feature from this region, such that the dimension D of the image feature vectors is 2048. Used in this fashion, Faster R-CNN effectively functions as a 'hard' attention mechanism, as only a relatively small number of image bounding box features are selected from a large number of possible configurations."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-611-Sentence-6111,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-611-Sentence-6112 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-611-Sentence-6111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "feature from this region, such that the dimension D of the image feature vectors is 2048."@en ;
    askg-onto:inSentence "feature from this region, such that the dimension D of the image feature vectors is 2048."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2048,
        askg-data:Entity-image_feature_vectors .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-611-Sentence-6112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Used in this fashion, Faster R-CNN effectively functions as a 'hard' attention mechanism, as only a relatively small number of image bounding box features are selected from a large number of possible configurations."@en ;
    askg-onto:inSentence "Used in this fashion, Faster R-CNN effectively functions as a 'hard' attention mechanism, as only a relatively small number of image bounding box features are selected from a large number of possible configurations."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-hard_attention_mechanism,
        askg-data:Entity-image_bounding_box_features,
        askg-data:Entity-large_number_of_possible_configurations .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "To pretrain the bottom-up attention model, we first initialize Faster R-CNN with ResNet-101 pretrained for classification on ImageNet [35]. We then train on Visual Genome [21] data. To aid the learning of good feature representations, we add an additional training output for predicting attribute classes (in addition to object classes). To predict attributes for region i, we concatenate the mean pooled convolutional feature vi with a learned embedding of the ground-truth object class, and feed this into an additional output layer defining a softmax distribution over each attribute class plus a 'no attributes' class."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6121,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6122,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6123,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6124 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To pretrain the bottom-up attention model, we first initialize Faster R-CNN with ResNet-101 pretrained for classification on ImageNet [35]."@en ;
    askg-onto:inSentence "To pretrain the bottom-up attention model, we first initialize Faster R-CNN with ResNet-101 pretrained for classification on ImageNet [35]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classification_on_imagenet,
        askg-data:Entity-dataset,
        askg-data:Entity-faster_r-cnn,
        askg-data:Entity-imagenet,
        askg-data:Entity-resnet-101 .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We then train on Visual Genome [21] data."@en ;
    askg-onto:inSentence "We then train on Visual Genome [21] data."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-visual_genome .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To aid the learning of good feature representations, we add an additional training output for predicting attribute classes (in addition to object classes)."@en ;
    askg-onto:inSentence "To aid the learning of good feature representations, we add an additional training output for predicting attribute classes (in addition to object classes)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attribute_classes,
        askg-data:Entity-training_output .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-612-Sentence-6124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To predict attributes for region i, we concatenate the mean pooled convolutional feature vi with a learned embedding of the ground-truth object class, and feed this into an additional output layer defining a softmax distribution over each attribute class plus a 'no attributes' class."@en ;
    askg-onto:inSentence "To predict attributes for region i, we concatenate the mean pooled convolutional feature vi with a learned embedding of the ground-truth object class, and feed this into an additional output layer defining a softmax distribution over each attribute class plus a 'no attributes' class."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_output_layer,
        askg-data:Entity-learned_embedding_of_the_ground-truth_object_class,
        askg-data:Entity-mean_pooled_convolutional_feature_vi,
        askg-data:Entity-softmax_distribution_over_each_attribute_class_plus_a_no_attributes_class .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "The original Faster R-CNN multi-task loss function contains four components, defined over the classification and bounding box regression outputs for both the RPN and the final object class proposals respectively. We retain these components and add an additional multi-class loss component to train the attribute predictor. In Figure 2 we provide some examples of model output."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613-Sentence-6131,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613-Sentence-6132,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613-Sentence-6133 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613-Sentence-6131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The original Faster R-CNN multi-task loss function contains four components, defined over the classification and bounding box regression outputs for both the RPN and the final object class proposals respectively."@en ;
    askg-onto:inSentence "The original Faster R-CNN multi-task loss function contains four components, defined over the classification and bounding box regression outputs for both the RPN and the final object class proposals respectively."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-multi-task_loss_function,
        askg-data:Entity-rpn .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613-Sentence-6132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We retain these components and add an additional multi-class loss component to train the attribute predictor."@en ;
    askg-onto:inSentence "We retain these components and add an additional multi-class loss component to train the attribute predictor."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attribute_predictor,
        askg-data:Entity-multi-class_loss_component .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-613-Sentence-6133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In Figure 2 we provide some examples of model output."@en ;
    askg-onto:inSentence "In Figure 2 we provide some examples of model output."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-examples_of_model_output,
        askg-data:Entity-figure_2 .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "However, in this work we define spatial regions in terms of bounding boxes and implement bottom-up attention using Faster R-CNN [33]. Faster R-CNN is an object detection model designed to identify instances of objects belonging to certain classes and localize them with bounding boxes. Other region proposal networks could also be trained as an attentive mechanism [32, 25]."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62-Sentence-621,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62-Sentence-622,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62-Sentence-623 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "However, in this work we define spatial regions in terms of bounding boxes and implement bottom-up attention using Faster R-CNN [33]."@en ;
    askg-onto:inSentence "However, in this work we define spatial regions in terms of bounding boxes and implement bottom-up attention using Faster R-CNN [33]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-bounding_boxes,
        askg-data:Entity-faster_r-cnn,
        askg-data:Entity-spatial_regions .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62-Sentence-622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Faster R-CNN is an object detection model designed to identify instances of objects belonging to certain classes and localize them with bounding boxes."@en ;
    askg-onto:inSentence "Faster R-CNN is an object detection model designed to identify instances of objects belonging to certain classes and localize them with bounding boxes."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-object_detection_model .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-62-Sentence-623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Other region proposal networks could also be trained as an attentive mechanism [32, 25]."@en ;
    askg-onto:inSentence "Other region proposal networks could also be trained as an attentive mechanism [32, 25]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attentive_mechanism,
        askg-data:Entity-region_proposal_networks .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Faster R-CNN detects objects in two stages. The first stage, described as a Region Proposal Network (RPN), predicts object proposals. A small network is slid over features at an intermediate level of a CNN. At each spatial location the network predicts a class-agnostic objectness score and a bounding box refinement for anchor boxes of multiple scales and aspect ratios. Using greedy non-maximum"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-631,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-632,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-633,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-634,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-635 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Faster R-CNN detects objects in two stages."@en ;
    askg-onto:inSentence "Faster R-CNN detects objects in two stages."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-objects .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The first stage, described as a Region Proposal Network (RPN), predicts object proposals."@en ;
    askg-onto:inSentence "The first stage, described as a Region Proposal Network (RPN), predicts object proposals."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-object_proposals,
        askg-data:Entity-region_proposal_network .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A small network is slid over features at an intermediate level of a CNN."@en ;
    askg-onto:inSentence "A small network is slid over features at an intermediate level of a CNN."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn,
        askg-data:Entity-features,
        askg-data:Entity-intermediate_level,
        askg-data:Entity-small_network .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "At each spatial location the network predicts a class-agnostic objectness score and a bounding box refinement for anchor boxes of multiple scales and aspect ratios."@en ;
    askg-onto:inSentence "At each spatial location the network predicts a class-agnostic objectness score and a bounding box refinement for anchor boxes of multiple scales and aspect ratios."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anchor_boxes,
        askg-data:Entity-bounding_box_refinement,
        askg-data:Entity-multiple_scales_and_aspect_ratios,
        askg-data:Entity-network,
        askg-data:Entity-objectness_score .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-63-Sentence-635 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Using greedy non-maximum"@en ;
    askg-onto:inSentence "Using greedy non-maximum"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-greedy_non-maximum,
        askg-data:Entity-method .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-64 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "1http://www.panderson.me/up-down-attention"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-64-Sentence-641 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-64-Sentence-641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1http://www.panderson.me/up-down-attention"@en ;
    askg-onto:inSentence "1http://www.panderson.me/up-down-attention"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-up-down_attention .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-65 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Figure 2. Example output from our Faster R-CNN bottom-up at-"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-65-Sentence-651,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-65-Sentence-652 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-65-Sentence-651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 2."@en ;
    askg-onto:inSentence "Figure 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_2 .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-65-Sentence-652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Example output from our Faster R-CNN bottom-up at-"@en ;
    askg-onto:inSentence "Example output from our Faster R-CNN bottom-up at-"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_at,
        askg-data:Entity-faster_r-cnn .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![2_image_1.png](2_image_1.png) tention model. Each bounding box is labeled with an attribute class followed by an object class. Note however, that in captioning and VQA we utilize only the feature vectors - not the predicted labels."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66-Sentence-661,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66-Sentence-662,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66-Sentence-663 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66-Sentence-661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![2_image_1.png](2_image_1.png) tention model."@en ;
    askg-onto:inSentence "![2_image_1.png](2_image_1.png) tention model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_model,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66-Sentence-662 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Each bounding box is labeled with an attribute class followed by an object class."@en ;
    askg-onto:inSentence "Each bounding box is labeled with an attribute class followed by an object class."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attribute_class,
        askg-data:Entity-bounding_box,
        askg-data:Entity-object_class .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-66-Sentence-663 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Note however, that in captioning and VQA we utilize only the feature vectors - not the predicted labels."@en ;
    askg-onto:inSentence "Note however, that in captioning and VQA we utilize only the feature vectors - not the predicted labels."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning,
        askg-data:Entity-feature_vectors,
        askg-data:Entity-vqa .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "suppression with an intersection-over-union (IoU) threshold, the top box proposals are selected as input to the second stage. In the second stage, region of interest (RoI) pooling is used to extract a small feature map (e.g. 14×14) for each box proposal. These feature maps are then batched together as input to the final layers of the CNN. The final output of the model consists of a softmax distribution over class labels and class-specific bounding box refinements for each box proposal."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-671,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-672,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-673,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-674,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-675 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "suppression with an intersection-over-union (IoU) threshold, the top box proposals are selected as input to the second stage."@en ;
    askg-onto:inSentence "suppression with an intersection-over-union (IoU) threshold, the top box proposals are selected as input to the second stage."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-box_proposals,
        askg-data:Entity-intersection-over-union_iou_threshold,
        askg-data:Entity-second_stage,
        askg-data:Entity-suppression .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-672 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the second stage, region of interest (RoI) pooling is used to extract a small feature map (e.g."@en ;
    askg-onto:inSentence "In the second stage, region of interest (RoI) pooling is used to extract a small feature map (e.g."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-extract_a_small_feature_map,
        askg-data:Entity-region_of_interest_roi_pooling .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-673 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "14×14) for each box proposal."@en ;
    askg-onto:inSentence "14×14) for each box proposal."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1414,
        askg-data:Entity-box_proposal .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-674 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These feature maps are then batched together as input to the final layers of the CNN."@en ;
    askg-onto:inSentence "These feature maps are then batched together as input to the final layers of the CNN."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnn,
        askg-data:Entity-feature_maps,
        askg-data:Entity-final_layers,
        askg-data:Entity-final_layers_of_the_cnn .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-67-Sentence-675 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The final output of the model consists of a softmax distribution over class labels and class-specific bounding box refinements for each box proposal."@en ;
    askg-onto:inSentence "The final output of the model consists of a softmax distribution over class labels and class-specific bounding box refinements for each box proposal."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bounding_box_refinements,
        askg-data:Entity-box_proposal,
        askg-data:Entity-class-specific_bounding_box_refinements,
        askg-data:Entity-model,
        askg-data:Entity-softmax_distribution .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-68 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "In this work, we use Faster R-CNN in conjunction with the ResNet-101 [13] CNN. To generate an output set of image features V for use in image captioning or VQA, we take the final output of the model and perform non-maximum suppression for each object class using an IoU threshold."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-68-Sentence-681,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-68-Sentence-682 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-68-Sentence-681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this work, we use Faster R-CNN in conjunction with the ResNet-101 [13] CNN."@en ;
    askg-onto:inSentence "In this work, we use Faster R-CNN in conjunction with the ResNet-101 [13] CNN."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_r-cnn,
        askg-data:Entity-resnet-101 .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-68-Sentence-682 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To generate an output set of image features V for use in image captioning or VQA, we take the final output of the model and perform non-maximum suppression for each object class using an IoU threshold."@en ;
    askg-onto:inSentence "To generate an output set of image features V for use in image captioning or VQA, we take the final output of the model and perform non-maximum suppression for each object class using an IoU threshold."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image_features_v,
        askg-data:Entity-iou_threshold,
        askg-data:Entity-model,
        askg-data:Entity-non-maximum_suppression,
        askg-data:Entity-object_class,
        askg-data:Entity-output_set .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-69 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "We then select all regions where any class detection probability exceeds a confidence threshold. For each selected region i, viis defined as the mean-pooled convolutional"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-69-Sentence-691,
        askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-69-Sentence-692 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-69-Sentence-691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We then select all regions where any class detection probability exceeds a confidence threshold."@en ;
    askg-onto:inSentence "We then select all regions where any class detection probability exceeds a confidence threshold."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-class_detection_probability,
        askg-data:Entity-regions .

askg-data:Paper-11712fbcb9a80fb4-Section-6-Paragraph-69-Sentence-692 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For each selected region i, viis defined as the mean-pooled convolutional"@en ;
    askg-onto:inSentence "For each selected region i, viis defined as the mean-pooled convolutional"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mean-pooled_convolutional,
        askg-data:Entity-region_i .

askg-data:Paper-11712fbcb9a80fb4-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "3.2. Captioning Model"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-72,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73 ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Given a set of image features V , our proposed captioning model uses a 'soft' top-down attention mechanism to weight each feature during caption generation, using the existing partial output sequence as context. This approach is broadly similar to several previous works [34, 27, 46]. However, the particular design choices outlined below make for a relatively simple yet high-performing baseline model. Even without bottom-up attention, our captioning model achieves performance comparable to state-of-the-art on most evaluation metrics (refer Table 1)."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-711,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-712,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-713,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-714 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Given a set of image features V , our proposed captioning model uses a 'soft' top-down attention mechanism to weight each feature during caption generation, using the existing partial output sequence as context."@en ;
    askg-onto:inSentence "Given a set of image features V , our proposed captioning model uses a 'soft' top-down attention mechanism to weight each feature during caption generation, using the existing partial output sequence as context."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-caption,
        askg-data:Entity-captioning_model,
        askg-data:Entity-context,
        askg-data:Entity-existing_partial_output_sequence,
        askg-data:Entity-soft_top-down_attention_mechanism .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This approach is broadly similar to several previous works [34, 27, 46]."@en ;
    askg-onto:inSentence "This approach is broadly similar to several previous works [34, 27, 46]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-previous_works .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, the particular design choices outlined below make for a relatively simple yet high-performing baseline model."@en ;
    askg-onto:inSentence "However, the particular design choices outlined below make for a relatively simple yet high-performing baseline model."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baseline_model,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-71-Sentence-714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Even without bottom-up attention, our captioning model achieves performance comparable to state-of-the-art on most evaluation metrics (refer Table 1)."@en ;
    askg-onto:inSentence "Even without bottom-up attention, our captioning model achieves performance comparable to state-of-the-art on most evaluation metrics (refer Table 1)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_model,
        askg-data:Entity-state-of-the-art .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-72 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "At a high level, the captioning model is composed of two LSTM [15] layers using a standard implementation [9]. In the sections that follow we will refer to the operation of the LSTM over a single time step using the following notation:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-72-Sentence-721,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-72-Sentence-722 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-72-Sentence-721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "At a high level, the captioning model is composed of two LSTM [15] layers using a standard implementation [9]."@en ;
    askg-onto:inSentence "At a high level, the captioning model is composed of two LSTM [15] layers using a standard implementation [9]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_model,
        askg-data:Entity-lstm_layers,
        askg-data:Entity-standard_implementation,
        askg-data:Entity-two_lstm_layers .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-72-Sentence-722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the sections that follow we will refer to the operation of the LSTM over a single time step using the following notation:"@en ;
    askg-onto:inSentence "In the sections that follow we will refer to the operation of the LSTM over a single time step using the following notation:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lstm,
        askg-data:Entity-single_time_step .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$h_{t}=\\mathrm{LSTM}(x_{t},h_{t-1})$$ ht = LSTM(xt, ht−1) (1) where xt is the LSTM input vector and ht is the LSTM output vector. Here we have neglected the propagation of memory cells for notational convenience. We now describe the formulation of the LSTM input vector xt and the output vector ht for each layer of the model. The overall captioning model is illustrated in Figure 3."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-731,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-732,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-733,
        askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-734 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$h_{t}=\\mathrm{LSTM}(x_{t},h_{t-1})$$ ht = LSTM(xt, ht−1) (1) where xt is the LSTM input vector and ht is the LSTM output vector."@en ;
    askg-onto:inSentence "$$h_{t}=\\mathrm{LSTM}(x_{t},h_{t-1})$$ ht = LSTM(xt, ht−1) (1) where xt is the LSTM input vector and ht is the LSTM output vector."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lstm,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here we have neglected the propagation of memory cells for notational convenience."@en ;
    askg-onto:inSentence "Here we have neglected the propagation of memory cells for notational convenience."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-memory_cells,
        askg-data:Entity-propagation .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We now describe the formulation of the LSTM input vector xt and the output vector ht for each layer of the model."@en ;
    askg-onto:inSentence "We now describe the formulation of the LSTM input vector xt and the output vector ht for each layer of the model."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ht,
        askg-data:Entity-lstm_input_vector,
        askg-data:Entity-model,
        askg-data:Entity-output_vector,
        askg-data:Entity-xt .

askg-data:Paper-11712fbcb9a80fb4-Section-7-Paragraph-73-Sentence-734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The overall captioning model is illustrated in Figure 3."@en ;
    askg-onto:inSentence "The overall captioning model is illustrated in Figure 3."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_model,
        askg-data:Entity-figure_3 .

askg-data:Paper-11712fbcb9a80fb4-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "3.2.1 Top-Down Attention Lstm"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-83,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-84,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-85 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Within the captioning model, we characterize the first LSTM layer as a top-down visual attention model, and the second LSTM layer as a language model, indicating each layer with superscripts in the equations that follow. Note that the bottom-up attention model is described in Section 3.1, and in this section its outputs are simply considered as features V . The input vector to the attention LSTM at each time step consists of the previous output of the language LSTM, concatenated with the mean-pooled image feature v¯ =1k Pi vi and an encoding of the previously generated word, given by:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81-Sentence-811,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81-Sentence-812,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81-Sentence-813 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Within the captioning model, we characterize the first LSTM layer as a top-down visual attention model, and the second LSTM layer as a language model, indicating each layer with superscripts in the equations that follow."@en ;
    askg-onto:inSentence "Within the captioning model, we characterize the first LSTM layer as a top-down visual attention model, and the second LSTM layer as a language model, indicating each layer with superscripts in the equations that follow."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_lstm_layer,
        askg-data:Entity-language_model,
        askg-data:Entity-second_lstm_layer,
        askg-data:Entity-top-down_visual_attention_model .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81-Sentence-812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that the bottom-up attention model is described in Section 3.1, and in this section its outputs are simply considered as features V ."@en ;
    askg-onto:inSentence "Note that the bottom-up attention model is described in Section 3.1, and in this section its outputs are simply considered as features V ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention_model,
        askg-data:Entity-features_v,
        askg-data:Entity-outputs,
        askg-data:Entity-section_31 .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-81-Sentence-813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The input vector to the attention LSTM at each time step consists of the previous output of the language LSTM, concatenated with the mean-pooled image feature v¯ =1k Pi vi and an encoding of the previously generated word, given by:"@en ;
    askg-onto:inSentence "The input vector to the attention LSTM at each time step consists of the previous output of the language LSTM, concatenated with the mean-pooled image feature v¯ =1k Pi vi and an encoding of the previously generated word, given by:"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoding_of_the_previously_generated_word,
        askg-data:Entity-input_vector,
        askg-data:Entity-mean-pooled_image_feature_v_1k_pi_vi,
        askg-data:Entity-previous_output_of_the_language_lstm .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbf{x}_{t}^{1}=[\\mathbf{h}_{t-1}^{2},{\\bar{\\mathbf{v}}},W_{e}\\Pi_{t}]$$ , v¯, WeΠt] (2) where We ∈ R E×|Σ|is a word embedding matrix for a vocabulary Σ, and Πt is one-hot encoding of the input word at timestep t. These inputs provide the attention LSTM with maximum context regarding the state of the language LSTM, the overall content of the image, and the partial caption output generated so far, respectively. The word embedding is learned from random initialization without pretraining."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82-Sentence-821,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82-Sentence-822,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82-Sentence-823 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82-Sentence-821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{x}_{t}^{1}=[\\mathbf{h}_{t-1}^{2},{\\bar{\\mathbf{v}}},W_{e}\\Pi_{t}]$$ , v¯, WeΠt] (2) where We ∈ R E×|Σ|is a word embedding matrix for a vocabulary Σ, and Πt is one-hot encoding of the input word at timestep t."@en ;
    askg-onto:inSentence "$$\\mathbf{x}_{t}^{1}=[\\mathbf{h}_{t-1}^{2},{\\bar{\\mathbf{v}}},W_{e}\\Pi_{t}]$$ , v¯, WeΠt] (2) where We ∈ R E×|Σ|is a word embedding matrix for a vocabulary Σ, and Πt is one-hot encoding of the input word at timestep t."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%80t,
        askg-data:Entity-%CF%83,
        askg-data:Entity-list_of_components,
        askg-data:Entity-one-hot_encoding,
        askg-data:Entity-vocabulary,
        askg-data:Entity-we,
        askg-data:Entity-word_embedding_matrix,
        askg-data:Entity-x_t1 .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82-Sentence-822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These inputs provide the attention LSTM with maximum context regarding the state of the language LSTM, the overall content of the image, and the partial caption output generated so far, respectively."@en ;
    askg-onto:inSentence "These inputs provide the attention LSTM with maximum context regarding the state of the language LSTM, the overall content of the image, and the partial caption output generated so far, respectively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_lstm,
        askg-data:Entity-caption_output,
        askg-data:Entity-context,
        askg-data:Entity-image,
        askg-data:Entity-language_lstm .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-82-Sentence-823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The word embedding is learned from random initialization without pretraining."@en ;
    askg-onto:inSentence "The word embedding is learned from random initialization without pretraining."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-random_initialization,
        askg-data:Entity-word_embedding .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-83 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Given the output h 1 t of the attention LSTM, at each time step t we generate a normalized attention weight αi,t for each of the k image features vi as follows:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-83-Sentence-831 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-83-Sentence-831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Given the output h 1 t of the attention LSTM, at each time step t we generate a normalized attention weight αi,t for each of the k image features vi as follows:"@en ;
    askg-onto:inSentence "Given the output h 1 t of the attention LSTM, at each time step t we generate a normalized attention weight αi,t for each of the k image features vi as follows:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention_lstm,
        askg-data:Entity-normalized_attention_weight_%CE%B1it .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-84 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$\\begin{array}{l}{{a_{i,t}=\\mathbf{w}_{a}^{T}\\operatorname{tanh}\\left(W_{v a}\\mathbf{v}_{i}+W_{h a}\\mathbf{h}_{t}^{1}\\right)}}\\\\ {{\\mathbf{\\alpha}_{t}=\\operatorname{softmax}\\left(\\mathbf{a}_{t}\\right)}}\\end{array}$$ t) (3) where Wva ∈ R H×V, Wha ∈ R H×M and wa ∈ R H are learned parameters. The attended image feature used as input to the language LSTM is calculated as a convex combination of all input features:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-84-Sentence-841,
        askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-84-Sentence-842 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-84-Sentence-841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{{a_{i,t}=\\mathbf{w}_{a}^{T}\\operatorname{tanh}\\left(W_{v a}\\mathbf{v}_{i}+W_{h a}\\mathbf{h}_{t}^{1}\\right)}}\\\\ {{\\mathbf{\\alpha}_{t}=\\operatorname{softmax}\\left(\\mathbf{a}_{t}\\right)}}\\end{array}$$ t) (3) where Wva ∈ R H×V, Wha ∈ R H×M and wa ∈ R H are learned parameters."@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{{a_{i,t}=\\mathbf{w}_{a}^{T}\\operatorname{tanh}\\left(W_{v a}\\mathbf{v}_{i}+W_{h a}\\mathbf{h}_{t}^{1}\\right)}}\\\\ {{\\mathbf{\\alpha}_{t}=\\operatorname{softmax}\\left(\\mathbf{a}_{t}\\right)}}\\end{array}$$ t) (3) where Wva ∈ R H×V, Wha ∈ R H×M and wa ∈ R H are learned parameters."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-84-Sentence-842 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The attended image feature used as input to the language LSTM is calculated as a convex combination of all input features:"@en ;
    askg-onto:inSentence "The attended image feature used as input to the language LSTM is calculated as a convex combination of all input features:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convex_combination,
        askg-data:Entity-image_feature,
        askg-data:Entity-input_features,
        askg-data:Entity-language_lstm .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-85 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$${\\hat{\\mathbf{v}}}_{t}=\\sum_{i=1}^{K}\\alpha_{i,t}\\mathbf{v}_{i}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-85-Sentence-851 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-8-Paragraph-85-Sentence-851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\hat{\\mathbf{v}}}_{t}=\\sum_{i=1}^{K}\\alpha_{i,t}\\mathbf{v}_{i}$$"@en ;
    askg-onto:inSentence "$${\\hat{\\mathbf{v}}}_{t}=\\sum_{i=1}^{K}\\alpha_{i,t}\\mathbf{v}_{i}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extk%09ext%09ext_%09extv_i%09ext%09ext_%09ext%CE%B1_it,
        askg-data:Entity-%09extv_t .

askg-data:Paper-11712fbcb9a80fb4-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "3.2.2 Language Lstm"@en ;
    askg-onto:hasParagraph askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-91,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-92,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-93,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-94,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-95,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-96,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The input to the language model LSTM consists of the attended image feature, concatenated with the output of the attention LSTM, given by:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-91-Sentence-911 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The input to the language model LSTM consists of the attended image feature, concatenated with the output of the attention LSTM, given by:"@en ;
    askg-onto:inSentence "The input to the language model LSTM consists of the attended image feature, concatenated with the output of the attention LSTM, given by:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attended_image_feature,
        askg-data:Entity-lstm,
        askg-data:Entity-output_of_the_attention_lstm .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-92 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbf{x}_{t}^{2}=[{\\hat{\\mathbf{v}}}_{t},\\mathbf{h}_{t}^{1}]$$ t] (6) Using the notation y1:T to refer to a sequence of words (y1*, ..., y*T ), at each time step t the conditional distribution over possible output words is given by:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-92-Sentence-921 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-92-Sentence-921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{x}_{t}^{2}=[{\\hat{\\mathbf{v}}}_{t},\\mathbf{h}_{t}^{1}]$$ t] (6) Using the notation y1:T to refer to a sequence of words (y1*, ..., y*T ), at each time step t the conditional distribution over possible output words is given by:"@en ;
    askg-onto:inSentence "$$\\mathbf{x}_{t}^{2}=[{\\hat{\\mathbf{v}}}_{t},\\mathbf{h}_{t}^{1}]$$ t] (6) Using the notation y1:T to refer to a sequence of words (y1*, ..., y*T ), at each time step t the conditional distribution over possible output words is given by:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conditional_distribution,
        askg-data:Entity-sequence_of_words .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-93 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$p(y_{t}\\mid y_{1:t-1})=\\operatorname{softmax}\\left(W_{p}\\mathbf{h}_{t}^{2}+\\mathbf{b}_{p}\\right)$$ t + bp) (7) where Wp ∈ R |Σ|×M and bp ∈ R |Σ|are learned weights and biases. The distribution over complete output sequences is calculated as the product of conditional distributions:"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-93-Sentence-931,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-93-Sentence-932 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-93-Sentence-931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$p(y_{t}\\mid y_{1:t-1})=\\operatorname{softmax}\\left(W_{p}\\mathbf{h}_{t}^{2}+\\mathbf{b}_{p}\\right)$$ t + bp) (7) where Wp ∈ R |Σ|×M and bp ∈ R |Σ|are learned weights and biases."@en ;
    askg-onto:inSentence "$$p(y_{t}\\mid y_{1:t-1})=\\operatorname{softmax}\\left(W_{p}\\mathbf{h}_{t}^{2}+\\mathbf{b}_{p}\\right)$$ t + bp) (7) where Wp ∈ R |Σ|×M and bp ∈ R |Σ|are learned weights and biases."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learned_biases,
        askg-data:Entity-learned_weights,
        askg-data:Entity-py_ty_1t-1,
        askg-data:Entity-softmaxw_p%09extbfh_t2%09extbfb_p .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-93-Sentence-932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The distribution over complete output sequences is calculated as the product of conditional distributions:"@en ;
    askg-onto:inSentence "The distribution over complete output sequences is calculated as the product of conditional distributions:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-distribution,
        askg-data:Entity-product_of_conditional_distributions .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-94 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$p(y_{1:T})=\\prod_{t=1}^{T}p(y_{t}\\mid y_{1:t-1})$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-94-Sentence-941 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-94-Sentence-941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$p(y_{1:T})=\\prod_{t=1}^{T}p(y_{t}\\mid y_{1:t-1})$$"@en ;
    askg-onto:inSentence "$$p(y_{1:T})=\\prod_{t=1}^{T}p(y_{t}\\mid y_{1:t-1})$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Aprod_t1tpy_tmid_y_1t-1,
        askg-data:Entity-py_1t .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-95 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$(2)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-95-Sentence-951 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-95-Sentence-951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(2)$$"@en ;
    askg-onto:inSentence "$$(2)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-technique,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-96 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![3_image_0.png](3_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-96-Sentence-961 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-96-Sentence-961 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![3_image_0.png](3_image_0.png)"@en ;
    askg-onto:inSentence "![3_image_0.png](3_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-city,
        askg-data:Entity-company,
        askg-data:Entity-concept,
        askg-data:Entity-data,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-person,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Figure 3. Overview of the proposed captioning model. Two LSTM layers are used to selectively attend to spatial image features {v1*, ...,* vk}. These features can be defined as the spatial output of a CNN, or following our approach, generated using bottom-up attention."@en ;
    askg-onto:hasSentence askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-971,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-972,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-973,
        askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-974 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-971 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 3."@en ;
    askg-onto:inSentence "Figure 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-972 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Overview of the proposed captioning model."@en ;
    askg-onto:inSentence "Overview of the proposed captioning model."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-captioning_model,
        askg-data:Entity-model .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-973 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Two LSTM layers are used to selectively attend to spatial image features {v1*, ...,* vk}."@en ;
    askg-onto:inSentence "Two LSTM layers are used to selectively attend to spatial image features {v1*, ...,* vk}."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attend_to_spatial_image_features,
        askg-data:Entity-lstm_layers .

askg-data:Paper-11712fbcb9a80fb4-Section-9-Paragraph-97-Sentence-974 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These features can be defined as the spatial output of a CNN, or following our approach, generated using bottom-up attention."@en ;
    askg-onto:inSentence "These features can be defined as the spatial output of a CNN, or following our approach, generated using bottom-up attention."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottom-up_attention,
        askg-data:Entity-cnn,
        askg-data:Entity-our_approach,
        askg-data:Entity-spatial_output .

askg-data:Entity-%CF%83 rdfs:label "Σ"@en,
        "σ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1179_215_and_369 rdfs:label "117.9, 21.5 and 36.9"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-1414 rdfs:label "14×14"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2017 rdfs:label "2017"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-3 rdfs:label "(3)"@en,
        "3%"@en ;
    askg-onto:entityType "Concept"@en,
        "Rate"@en .

askg-data:Entity-4 rdfs:label "(4)"@en,
        "4"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-6 rdfs:label "6"@en,
        "6%"@en ;
    askg-onto:entityType "Publication"@en,
        "Rate"@en .

askg-data:Entity-7 rdfs:label "7"@en,
        "[7]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-a_scientist rdfs:label "a scientist"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-adadelta rdfs:label "ADADELTA"@en,
        "AdaDelta"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-algorithm rdfs:label "Algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-all_other_test_server_submissions rdfs:label "all other test server submissions"@en ;
    askg-onto:entityType "Finding"@en,
        "System"@en .

askg-data:Entity-attention_lstm rdfs:label "attention LSTM"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-attention_mechanisms rdfs:label "attention mechanisms"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-attention_methodologies rdfs:label "attention methodologies"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-attention_model rdfs:label "attention model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-attention_weights rdfs:label "attention weights"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-attribute_classes rdfs:label "attribute classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b rdfs:label "B"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-bengio rdfs:label "Bengio"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-berg rdfs:label "Berg"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bernstein rdfs:label "Bernstein"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bilinear_interpolation rdfs:label "bilinear interpolation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bleu rdfs:label "BLEU"@en,
        "Bleu"@en ;
    askg-onto:entityType "Method"@en,
        "Metric"@en .

askg-data:Entity-bottom-up_mechanism rdfs:label "bottom-up mechanism"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en .

askg-data:Entity-box_proposal rdfs:label "box proposal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-caption_generation rdfs:label "caption generation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-captioning rdfs:label "captioning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cider__spice__bleu-4_scores rdfs:label "CIDEr / SPICE / BLEU-4 scores"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-cider_score rdfs:label "CIDEr score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-context rdfs:label "context"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolutional_neural_networks rdfs:label "Convolutional Neural Networks"@en ;
    askg-onto:entityType "Model"@en,
        "Technology"@en .

askg-data:Entity-couch rdfs:label "couch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cross-entropy_loss rdfs:label "cross-entropy loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-darrell rdfs:label "Darrell"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distribution rdfs:label "distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e rdfs:label "E"@en,
        "E."@en ;
    askg-onto:entityType "Organization"@en,
        "Person"@en .

askg-data:Entity-edge_boxes rdfs:label "Edge boxes"@en,
        "edge boxes"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-equipment rdfs:label "Equipment"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-features rdfs:label "features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_1 rdfs:label "Figure 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_2 rdfs:label "Figure 2"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-frisbee rdfs:label "frisbee"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-g rdfs:label "G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-girshick rdfs:label "Girshick"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gradient rdfs:label "gradient"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-he_x rdfs:label "He, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-highway_networks rdfs:label "Highway networks"@en,
        "highway networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-human_visual_system rdfs:label "human visual system"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ijcv rdfs:label "IJCV"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-karpathy rdfs:label "Karpathy"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-karpathy_test_split rdfs:label "Karpathy test split"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitchen rdfs:label "kitchen"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-language_lstm rdfs:label "language LSTM"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-learned_biases rdfs:label "learned biases"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-learned_weights rdfs:label "learned weights"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-lstm_layers rdfs:label "LSTM layers"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-man rdfs:label "man"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-maximum_attention_weight rdfs:label "maximum attention weight"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-mechanisms rdfs:label "mechanisms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mscoco rdfs:label "MSCOCO"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mscoco_karpathy_test_split rdfs:label "MSCOCO Karpathy test split"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mscoco_test_server rdfs:label "MSCOCO test server"@en ;
    askg-onto:entityType "Dataset"@en,
        "Platform"@en .

askg-data:Entity-multiple_steps_of_reasoning rdfs:label "multiple steps of reasoning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-na rdfs:label "N/A"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-neural_networks rdfs:label "Neural Networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-new_state-of-the-art rdfs:label "new state-of-the-art"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-object rdfs:label "object"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_attributes rdfs:label "object attributes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_class rdfs:label "object class"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_detection rdfs:label "object detection"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-object_detection_model rdfs:label "Object detection model"@en,
        "object detection model"@en ;
    askg-onto:entityType "Framework"@en,
        "Model"@en .

askg-data:Entity-p rdfs:label "P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-published_and_unpublished_work rdfs:label "published and unpublished work"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-pytorch rdfs:label "PyTorch"@en ;
    askg-onto:entityType "Software"@en,
        "Technology"@en .

askg-data:Entity-rate rdfs:label "Rate"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-relative_improvement rdfs:label "Relative Improvement"@en ;
    askg-onto:entityType "Finding"@en,
        "Metric"@en .

askg-data:Entity-ren rdfs:label "Ren"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-research rdfs:label "research"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-research_paper rdfs:label "Research Paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-researcher rdfs:label "Researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-resnet rdfs:label "ResNet"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-room rdfs:label "room"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-saenko rdfs:label "Saenko"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-schmidhuber rdfs:label "Schmidhuber"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-scstatt2all rdfs:label "SCST:Att2all"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-selective_search rdfs:label "Selective search"@en,
        "selective search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-set_of_candidate_answers rdfs:label "set of candidate answers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-socher rdfs:label "Socher"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-spatial_image_features_v rdfs:label "spatial image features V"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spatial_transformer_networks rdfs:label "Spatial transformer networks"@en,
        "spatial transformer networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-star rdfs:label "star"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-of-the-art rdfs:label "state-of-the-art"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-submission rdfs:label "submission"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-table_3 rdfs:label "Table 3"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-teney_et_al rdfs:label "Teney et al."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-tensorflow rdfs:label "TensorFlow"@en ;
    askg-onto:entityType "Software"@en,
        "Technology"@en .

askg-data:Entity-this_approach rdfs:label "This approach"@en,
        "this approach"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-top-down_mechanism rdfs:label "top-down mechanism"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-training rdfs:label "Training"@en,
        "training"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-treisman rdfs:label "Treisman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-university_of_california rdfs:label "University of California"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-v rdfs:label "V."@en ;
    askg-onto:entityType "Person"@en,
        "Publication"@en .

askg-data:Entity-van_den_hengel rdfs:label "van den Hengel"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-visual_attention rdfs:label "visual attention"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_attention_mechanism rdfs:label "visual attention mechanism"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-visual_attention_mechanisms rdfs:label "visual attention mechanisms"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-visual_concepts rdfs:label "visual concepts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_question_answering_vqa rdfs:label "visual question answering (VQA)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vqa_v20_validation_set rdfs:label "VQA v2.0 validation set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-work rdfs:label "Work"@en,
        "work"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-year rdfs:label "Year"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-z rdfs:label "Z"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhang_s rdfs:label "Zhang, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhu_o rdfs:label "Zhu, O."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-8 rdfs:label "8"@en,
        "8%"@en ;
    askg-onto:entityType "Metric"@en,
        "Rate"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-attended_image_regions rdfs:label "attended image regions"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-batra rdfs:label "Batra"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-caption rdfs:label "caption"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-city rdfs:label "City"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-database rdfs:label "Database"@en ;
    askg-onto:entityType "Database"@en .

askg-data:Entity-dollar rdfs:label "Dollar"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-emnlp rdfs:label "EMNLP"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-fei-fei rdfs:label "Fei-Fei"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-first_place_in_the_2017_vqa_challenge rdfs:label "first place in the 2017 VQA Challenge"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-framework rdfs:label "Framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-iccv rdfs:label "ICCV"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-image rdfs:label "image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-images rdfs:label "images"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-metric rdfs:label "Metric"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-nips rdfs:label "NIPS"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-ours_up-down rdfs:label "Ours: Up-Down"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-paper rdfs:label "Paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-questions rdfs:label "Questions"@en,
        "questions"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-regions rdfs:label "regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-resnet-101 rdfs:label "ResNet-101"@en,
        "Resnet-101"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-resnet_model rdfs:label "ResNet model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-salient_image_regions rdfs:label "salient image regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-self-critical_sequence_training rdfs:label "Self-Critical Sequence Training"@en,
        "Self-critical Sequence Training"@en,
        "Self-critical sequence training"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-spatial_output rdfs:label "spatial output"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-spice rdfs:label "SPICE"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en,
        "Model"@en .

askg-data:Entity-sun rdfs:label "Sun"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-technique rdfs:label "Technique"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-theory rdfs:label "Theory"@en,
        "theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-toilet rdfs:label "toilet"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triples rdfs:label "triples"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-up-down rdfs:label "Up-Down"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-2 rdfs:label "2"@en ;
    askg-onto:entityType "Metric"@en,
        "Publication"@en .

askg-data:Entity-bottom-up_attention_model rdfs:label "bottom-up attention model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-captions rdfs:label "captions"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-cider_optimization rdfs:label "CIDEr optimization"@en ;
    askg-onto:entityType "Method"@en,
        "Metric"@en .

askg-data:Entity-eccv rdfs:label "ECCV"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-experiment rdfs:label "Experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-h rdfs:label "H."@en,
        "h"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Person"@en .

askg-data:Entity-image_captioning_model rdfs:label "image captioning model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-lstm rdfs:label "LSTM"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-models rdfs:label "models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-our_approach rdfs:label "Our approach"@en,
        "our approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-scst rdfs:label "SCST"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Framework"@en,
        "Model"@en .

askg-data:Entity-tool rdfs:label "Tool"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-unknown rdfs:label "unknown"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2015 rdfs:label "2015"@en ;
    askg-onto:entityType "Metric"@en,
        "Publication"@en .

askg-data:Entity-2016 rdfs:label "2016"@en ;
    askg-onto:entityType "Metric"@en,
        "Publication"@en .

askg-data:Entity-approach rdfs:label "approach"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-cider rdfs:label "CIDEr"@en ;
    askg-onto:entityType "Metric"@en,
        "Model"@en .

askg-data:Entity-data rdfs:label "Data"@en,
        "data"@en ;
    askg-onto:entityType "Corpus"@en,
        "Database"@en,
        "Dataset"@en,
        "Finding"@en .

askg-data:Entity-image_features rdfs:label "Image features"@en,
        "image features"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-platform rdfs:label "Platform"@en ;
    askg-onto:entityType "Concept"@en,
        "Platform"@en .

askg-data:Entity-t rdfs:label "T"@en,
        "T."@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en,
        "Publication"@en,
        "Researcher"@en .

askg-data:Entity-visual_genome rdfs:label "Visual Genome"@en,
        "Visual genome"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-w rdfs:label "W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-we rdfs:label "We"@en,
        "we"@en ;
    askg-onto:entityType "Person"@en,
        "Research Group"@en,
        "Technology"@en .

askg-data:Entity-y rdfs:label "Y"@en,
        "Y."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-zitnick rdfs:label "Zitnick"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-a_researcher rdfs:label "a researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-article rdfs:label "Article"@en ;
    askg-onto:entityType "Article"@en,
        "Publication"@en .

askg-data:Entity-arxiv_preprint rdfs:label "arXiv preprint"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-cnn rdfs:label "CNN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-finding rdfs:label "Finding"@en,
        "finding"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-image_regions rdfs:label "image regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-objects rdfs:label "objects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parikh rdfs:label "Parikh"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-imagenet rdfs:label "ImageNet"@en,
        "Imagenet"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-m rdfs:label "M"@en,
        "M."@en ;
    askg-onto:entityType "Metric"@en,
        "Person"@en .

askg-data:Entity-organization rdfs:label "Organization"@en ;
    askg-onto:entityType "Concept"@en,
        "Organization"@en .

askg-data:Entity-research_area rdfs:label "Research Area"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-resnet_baseline rdfs:label "ResNet baseline"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-s rdfs:label "S."@en ;
    askg-onto:entityType "Person"@en,
        "Publication"@en .

askg-data:Entity-software rdfs:label "Software"@en ;
    askg-onto:entityType "Concept"@en,
        "Software"@en,
        "Tool"@en .

askg-data:Entity-up-down_model rdfs:label "Up-Down model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-bottom-up_attention rdfs:label "bottom-up attention"@en ;
    askg-onto:entityType "Method"@en,
        "Technique"@en .

askg-data:Entity-c rdfs:label "C"@en,
        "C."@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-r rdfs:label "R"@en,
        "R."@en,
        "r"@en ;
    askg-onto:entityType "Author"@en,
        "Metric"@en,
        "Person"@en,
        "Publication"@en,
        "Software"@en .

askg-data:Entity-study rdfs:label "Study"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-captioning_model rdfs:label "captioning model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-cvpr rdfs:label "CVPR"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-data_visualization rdfs:label "data visualization"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-technology rdfs:label "Technology"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-vqa rdfs:label "VQA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-concept rdfs:label "Concept"@en,
        "concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-k rdfs:label "K."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-visual_question_answering rdfs:label "Visual Question Answering"@en,
        "Visual question answering"@en,
        "visual question answering"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-a rdfs:label "A"@en,
        "A."@en ;
    askg-onto:entityType "Article"@en,
        "Author"@en,
        "Concept"@en,
        "Person"@en,
        "Publication"@en .

askg-data:Entity-attention rdfs:label "attention"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-d rdfs:label "D."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en,
        "Publication"@en .

askg-data:Entity-l rdfs:label "L."@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Person"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-research_group rdfs:label "Research Group"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-university rdfs:label "University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-vqa_model rdfs:label "VQA model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-faster_r-cnn rdfs:label "Faster R-CNN"@en ;
    askg-onto:entityType "Framework"@en,
        "Model"@en .

askg-data:Entity-image_captioning rdfs:label "image captioning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-j rdfs:label "J."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-model rdfs:label "Model"@en,
        "model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-publication rdfs:label "Publication"@en,
        "publication"@en ;
    askg-onto:entityType "Metric"@en,
        "Publication"@en .

askg-data:Entity-scientist rdfs:label "Scientist"@en ;
    askg-onto:entityType "Person"@en,
        "Scientist"@en .

askg-data:Entity-person rdfs:label "Person"@en,
        "person"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

