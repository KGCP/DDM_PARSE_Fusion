@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-43d37e59d752bc41 a askg-onto:Paper ;
    rdfs:label "43d37e59d752bc41"@en ;
    dc:title "43d37e59d752bc41"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-43d37e59d752bc41-Section-1,
        askg-data:Paper-43d37e59d752bc41-Section-10,
        askg-data:Paper-43d37e59d752bc41-Section-11,
        askg-data:Paper-43d37e59d752bc41-Section-12,
        askg-data:Paper-43d37e59d752bc41-Section-13,
        askg-data:Paper-43d37e59d752bc41-Section-14,
        askg-data:Paper-43d37e59d752bc41-Section-15,
        askg-data:Paper-43d37e59d752bc41-Section-16,
        askg-data:Paper-43d37e59d752bc41-Section-17,
        askg-data:Paper-43d37e59d752bc41-Section-18,
        askg-data:Paper-43d37e59d752bc41-Section-19,
        askg-data:Paper-43d37e59d752bc41-Section-2,
        askg-data:Paper-43d37e59d752bc41-Section-20,
        askg-data:Paper-43d37e59d752bc41-Section-21,
        askg-data:Paper-43d37e59d752bc41-Section-22,
        askg-data:Paper-43d37e59d752bc41-Section-23,
        askg-data:Paper-43d37e59d752bc41-Section-24,
        askg-data:Paper-43d37e59d752bc41-Section-25,
        askg-data:Paper-43d37e59d752bc41-Section-26,
        askg-data:Paper-43d37e59d752bc41-Section-27,
        askg-data:Paper-43d37e59d752bc41-Section-28,
        askg-data:Paper-43d37e59d752bc41-Section-29,
        askg-data:Paper-43d37e59d752bc41-Section-3,
        askg-data:Paper-43d37e59d752bc41-Section-30,
        askg-data:Paper-43d37e59d752bc41-Section-31,
        askg-data:Paper-43d37e59d752bc41-Section-32,
        askg-data:Paper-43d37e59d752bc41-Section-33,
        askg-data:Paper-43d37e59d752bc41-Section-34,
        askg-data:Paper-43d37e59d752bc41-Section-35,
        askg-data:Paper-43d37e59d752bc41-Section-36,
        askg-data:Paper-43d37e59d752bc41-Section-37,
        askg-data:Paper-43d37e59d752bc41-Section-38,
        askg-data:Paper-43d37e59d752bc41-Section-39,
        askg-data:Paper-43d37e59d752bc41-Section-4,
        askg-data:Paper-43d37e59d752bc41-Section-5,
        askg-data:Paper-43d37e59d752bc41-Section-6,
        askg-data:Paper-43d37e59d752bc41-Section-7,
        askg-data:Paper-43d37e59d752bc41-Section-8,
        askg-data:Paper-43d37e59d752bc41-Section-9 .

askg-data:Entity- rdfs:label "âˆž"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extbfw rdfs:label "	extbf{w}^{*}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extbfw_k-%0Aabla_l_k%09extbfw rdfs:label """	extbf{w}_{k}-
abla L_{k}(	extbf{w})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extbfw_k1 rdfs:label "	extbf{w}_{k+1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extbfw_t rdfs:label "	extbf{w}_{t}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extdelta rdfs:label "	ext{delta}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extnar%09extmuar%09extsigma2 rdfs:label "	ext{N}(ar{	ext{mu}},ar{	ext{sigma}}^{2})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extnorm rdfs:label "	ext{norm}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extotherwise rdfs:label "	ext{otherwise}"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%09extscore rdfs:label "	ext{score}"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-%09extvector rdfs:label "	ext{vector}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0A rdfs:label """
"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0A%0A_%0A%0A_%0A%0Al%0A%0A_%0A%0Aw%0A%0A_%0A%0An%0A%0A rdfs:label """

 

 

L(

 

w

 

n

)"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Aabla_l_%09extbfw_t rdfs:label """
abla L_{	extbf{w}_{t}}"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Aabla_l_%09extbfw_t%09extbfw_t-%09extbfw rdfs:label """
abla L_{	extbf{w}_{t}}(	extbf{w}_{t}-	extbf{w}^{*})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Aabla_l_k%09extbfw rdfs:label """
abla L_{k}(	extbf{w})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Aalphabetasigmafracsqrttd-1 rdfs:label """$
\\alpha=(\\beta+\\sigma\\frac{\\sqrt{T}}{D})^{-1}$"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Amathcalnleftw_0mathrme-nalphalambdafracalphasigma2lambdaright rdfs:label """
\\mathcal{N}\\left(w_{0}\\mathrm{e}^{-n\\alpha\\lambda},{\\frac{\\alpha\\sigma^{2}}{\\lambda}}\\right)"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac%09extalpha%09extsigma2%09extlambda_n rdfs:label "rac{	ext{alpha}	ext{sigma}^{2}}{	ext{lambda} n}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac1%09extsqrtp%09extx%09ext_2 rdfs:label "rac{1}{	ext{sqrt}(P)}	ext{||}X	ext{||}_2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac1-1-%09extalpha%09extlambdan-2w_0n%09extalpha%09extlambda rdfs:label "rac{[1-(1-	ext{alpha}	ext{lambda})^{n-2}]w_{0}}{n	ext{alpha}	ext{lambda}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac12n2trh-1 rdfs:label "rac{1}{2n+2}Tr(H^{-1})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Crac1p%09extx%09ext_22 rdfs:label "rac{1}{P}	ext{||}X	ext{||}_2^{2}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Cracn-1n rdfs:label "rac{n-1}{n}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Cracn-kn rdfs:label "rac{n-k}{n}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Cractt rdfs:label "rac{t}{T}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Cractt_%09ext_being_less_than_or_equal_to__05 rdfs:label "rac{t}{T} 	ext{ being less than or equal to } 0.5"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CE%B1%CE%BB rdfs:label "|Î±Î»|"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B10 rdfs:label "Î±0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B1_01-1-%CE%B1_avg%CE%B1_0tt-0504_if_05__tt_avg__09 rdfs:label "Î±_{0}[1-(1-Î±_{avg}/Î±_{0})(t/T-0.5)/0.4] if 0.5 < t/T_{avg} â‰¤ 0.9"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B1_0_if_tt_avg__05 rdfs:label "Î±_{0} if t/T_{avg} â‰¤ 0.5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B1__05 rdfs:label "Î± = 0.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CE%B1_avg_otherwise rdfs:label "Î±_{avg} otherwise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B1avg rdfs:label "Î±avg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B1eff rdfs:label "Î±eff"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B1t__%CE%B1t rdfs:label "Î±t = Î±(t)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B2-lipschitz rdfs:label "Î²-Lipschitz"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B21 rdfs:label "Î²1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B21_%CE%B22 rdfs:label "{Î²1, Î²2}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B22 rdfs:label "Î²2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B8 rdfs:label "ËœÎ¸"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B8avg rdfs:label "Î¸avg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B8t rdfs:label "Î¸t"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BA rdfs:label "Îº"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BB rdfs:label "Î»"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%BB__0 rdfs:label "Î» = 0"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CE%BB__00005 rdfs:label "Î» *= 0.*0005"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83_2_dependence rdfs:label "Ïƒ 2 dependence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83g rdfs:label "Î£g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83g%F0%9D%91%A4 rdfs:label "Î£g(ð‘¤âˆ—)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%83gw rdfs:label "Î£g(w*)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0 rdfs:label "0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-00001 rdfs:label "0.0001"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-00003 rdfs:label "0.0003"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-00003_gadamx rdfs:label "0.0003 (GadamX)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0001_001_01 rdfs:label "{0.001, 0.01, 0.1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0001_others rdfs:label "0.001 (others)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0003 rdfs:label "0.003"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-003 rdfs:label "0.03"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-003_001_0003 rdfs:label "{0.03, 0.01, 0.003}"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0125_05_for_gadamx_gadam rdfs:label "{0.125, 0.5} for {GadamX, Gadam}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-039 rdfs:label "0.39%"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-05__%0Cractt_%09ext_being_less_than_or_equal_to__09 rdfs:label "0.5 < rac{t}{T} 	ext{ being less than or equal to } 0.9"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-09_0999 rdfs:label "{0.9, 0.999}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0_00005 rdfs:label "[0,* 0.0005]"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-0_09 rdfs:label "[0, 0.9]"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-1%CF%81_1%CF%81 rdfs:label "1âˆ’Ï 1+Ï"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-100 rdfs:label "100"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-101007978-3-642-35289-8 rdfs:label "10.1007/978-3-642-35289-8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-101007978-3-642-35289-8_25 rdfs:label "10.1007/978-3-642-35289-8_25"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-104_103 rdfs:label "[10âˆ’4, 10âˆ’3]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-105 rdfs:label "10âˆ’5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-108 rdfs:label "10âˆ’8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-10_repeats rdfs:label "10 repeats"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-10s rdfs:label "10s"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-11__103_0023 rdfs:label "1.1 Ã— 10âˆ’3 (0.023)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-11__104_51__104_ rdfs:label "1.1 Ã— 10âˆ’4 (5.1 Ã— 10âˆ’4 )"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-120_2500 rdfs:label "120 (2500)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-12__106 rdfs:label "1.2 Ã— 10âˆ’6"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-12jul rdfs:label "12(Jul)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-13 rdfs:label "13"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1313213143 rdfs:label "13132â€“13143"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-142 rdfs:label "1â€“42"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-14921500 rdfs:label "1492â€“1500"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-14__193_086 rdfs:label "1.4 Ã— 19âˆ’3 (0.86)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-17531763 rdfs:label "1753â€“1763"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1993 rdfs:label "1993"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1997 rdfs:label "1997"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1999 rdfs:label "1999"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1_100_of_the_initial_learning_rate rdfs:label "1 100 of the initial learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1_2_%CE%B10 rdfs:label "1 2 Î±0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1__%CF%81 rdfs:label "1 âˆ’ Ï"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1__1__%CE%B1%CE%BB_n2 rdfs:label "(1 âˆ’ (1 âˆ’ Î±Î») nâˆ’2)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1__n%CE%B1%CE%BB rdfs:label "(1 âˆ’ nÎ±Î»)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1__n%CE%B1%CE%BB_2 rdfs:label "(1 âˆ’ nÎ±Î» 2)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1_p rdfs:label "1 P"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1d_quadratic_function rdfs:label "1D quadratic function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-20 rdfs:label "20"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-200-epoch_budget rdfs:label "200-epoch budget"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2003 rdfs:label "2003"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2008 rdfs:label "2008"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2009 rdfs:label "2009"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-200_epochs rdfs:label "200 epochs"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-2015 rdfs:label "2015"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2018a rdfs:label "2018a"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2019a rdfs:label "2019a"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-20s rdfs:label "20s"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-21212159 rdfs:label "2121â€“2159"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-23 rdfs:label "23"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-24 rdfs:label "24"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-25 rdfs:label "25"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3-layer_long-short_term_memory_lstm_model rdfs:label "3-layer Long-short Term Memory (LSTM) model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-3-layer_lstm rdfs:label "3-layer LSTM"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-3-layer_lstm_ptb_word-level_modelling rdfs:label "3-layer LSTM PTB Word-level Modelling"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-30 rdfs:label "30"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-300 rdfs:label "300"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-300-epoch_budget rdfs:label "300-epoch budget"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-300_epochs rdfs:label "300 epochs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3104 rdfs:label "3Ã—10âˆ’4"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-3__104 rdfs:label "3 Ã— 10âˆ’4"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-3__104_3__105 rdfs:label "{3 Ã— 10âˆ’4, 3 Ã— 10âˆ’5}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3__105 rdfs:label "3 Ã— 10âˆ’5"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-3__106 rdfs:label "3 Ã— 10âˆ’6"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-3_times rdfs:label "3 times"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-41484158 rdfs:label "4148â€“4158"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-421436 rdfs:label "421â€“436"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-42614271 rdfs:label "4261â€“4271"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-43_280 rdfs:label "43 (280)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-47__105 rdfs:label "4.7 Ã— 10âˆ’5"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-500 rdfs:label "500"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-5000_samples rdfs:label "5000 samples"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-5371015 rdfs:label "53.71Â±0.15"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5427036 rdfs:label "54.27Â±0.36"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5437018 rdfs:label "54.37Â±0.18"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5445049 rdfs:label "54.45Â±0.49"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5484020 rdfs:label "54.84Â±0.20"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5497012 rdfs:label "54.97Â±0.12"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5551019 rdfs:label "55.51Â±0.19"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5877 rdfs:label "58.77"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-59048113 rdfs:label "59.04/81.13*"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5965017 rdfs:label "59.65Â±0.17"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-60048211 rdfs:label "60.04/82.11*"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6045 rdfs:label "60.45"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6050019 rdfs:label "60.50Â±0.19"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-612588 rdfs:label "61.2/58.8***"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6133011 rdfs:label "61.33Â±0.11"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6135 rdfs:label "61.35"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6151 rdfs:label "61.51"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-62 rdfs:label "62"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6232013 rdfs:label "62.32Â±0.13"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6304006 rdfs:label "63.04Â±0.06"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-630645 rdfs:label "630â€“645"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-6349 rdfs:label "63.49"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-63896399 rdfs:label "6389â€“6399"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-6399 rdfs:label "63.99"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6473 rdfs:label "64.73"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-64__105_22__103_ rdfs:label "6.4 Ã— 10âˆ’5 (2.2 Ã— 10âˆ’3 )"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6601 rdfs:label "66.01"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6943 rdfs:label "69.43"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6967_6716 rdfs:label "69.67 (67.16)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7 rdfs:label "7"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7155_6468 rdfs:label "71.55 (64.68)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7194 rdfs:label "71.94%"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7326030 rdfs:label "73.26Â±0.30"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7340 rdfs:label "73.40%"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7380 rdfs:label "73.80"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7393 rdfs:label "73.93"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7415006 rdfs:label "74.15Â±0.06"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7426 rdfs:label "74.26"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7456019 rdfs:label "74.56Â±0.19"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7457027 rdfs:label "74.57Â±0.27"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7539 rdfs:label "75.39"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7547021 rdfs:label "75.47Â±0.21"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7567 rdfs:label "75.67"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7573029 rdfs:label "75.73Â±0.29"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-76170661716 rdfs:label "7:61706â€“61716"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-7635 rdfs:label "76.35"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7685008 rdfs:label "76.85Â±0.08"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7722005 rdfs:label "77.22Â±0.05"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7730011 rdfs:label "77.30Â±0.11"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7731009 rdfs:label "77.31Â±0.09"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7737009 rdfs:label "77.37Â±0.09"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7790021 rdfs:label "77.90Â±0.21"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7791027 rdfs:label "77.91Â±0.27"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7792036 rdfs:label "77.92Â±0.36"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7796008 rdfs:label "77.96Â±0.08"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7804014 rdfs:label "78.04Â±0.14"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7843011 rdfs:label "78.43Â±0.11"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7848002 rdfs:label "78.48Â±0.02"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-7909033 rdfs:label "79.09Â±0.33"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8 rdfs:label "8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-8016016 rdfs:label "80.16Â±0.16"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8147017 rdfs:label "81.47Â±0.17"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8174016 rdfs:label "81.74Â±0.16"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-81948205 rdfs:label "8194â€“8205"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-8213020 rdfs:label "82.13Â±0.20"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8237035 rdfs:label "82.37Â±0.35"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8256013 rdfs:label "82.56Â±0.13"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8295028 rdfs:label "82.95Â±0.28"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8327011 rdfs:label "83.27Â±0.11"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8352014 rdfs:label "83.52Â±0.14"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8423005 rdfs:label "84.23Â±0.05"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-8475003 rdfs:label "84.75Â±0.03"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-849856 rdfs:label "849â€“856"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-87898798 rdfs:label "8789â€“8798"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9269 rdfs:label "92.69%"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9334 rdfs:label "93.34"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9363 rdfs:label "93.63"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9390 rdfs:label "93.90"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-93__104 rdfs:label "9.3 Ã— 10âˆ’4"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9414037 rdfs:label "94.14Â±0.37"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9506 rdfs:label "95.06"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-950957 rdfs:label "950â€“957"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-9540025 rdfs:label "95.40Â±0.25"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-95939604 rdfs:label "9593â€“9604"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-9862_8934 rdfs:label "98.62 (89.34)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9993 rdfs:label "99.93"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-9997_9412 rdfs:label "99.97 (94.12)"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-_1_n rdfs:label "âˆ 1 n"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-_1_standard_deviation rdfs:label "Â± 1 standard deviation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_constant_learning_rate rdfs:label "a constant learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_large_annotated_corpus_of_english rdfs:label "a large annotated corpus of English"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_mathematical_representation rdfs:label "a mathematical representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_placeholder rdfs:label "a placeholder"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_pre-set_starting_point rdfs:label "a pre-set starting point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_researcher rdfs:label "a researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-a_wider_range_of_problems rdfs:label "a wider range of problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ability_to_infer_on_unseen_data rdfs:label "ability to infer on unseen data"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-accelerated_method rdfs:label "accelerated method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-accelerating_deep_network_training rdfs:label "accelerating deep network training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-accuracy rdfs:label "accuracy"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-accuracy_of_the_iterate_average rdfs:label "accuracy of the iterate average"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-accuracy_of_the_iterates rdfs:label "accuracy of the iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-adam_b rdfs:label "Adam B"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-adam_paper rdfs:label "Adam paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-adamadam-ia rdfs:label "Adam/Adam-IA"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-adambased rdfs:label "Adambased"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-adamgadam rdfs:label "Adam/Gadam"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-adaptive_learning_rate rdfs:label "adaptive learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-adaptive_learning_rate_method rdfs:label "adaptive learning rate method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-adaptive_methods_such_as_adam rdfs:label "adaptive methods such as Adam"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-adaptive_subgradient_methods rdfs:label "Adaptive subgradient methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-additional_regularisation rdfs:label "additional regularisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-aggregated_residual_transformations rdfs:label "Aggregated residual transformations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-aggressive_reduction rdfs:label "aggressive reduction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-algorithm_optimization rdfs:label "algorithm optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-algorithmic_choices rdfs:label "algorithmic choices"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_gradients rdfs:label "all gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_others rdfs:label "all others"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-alpha rdfs:label "alpha"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-alternative_analysis_of_ema rdfs:label "alternative analysis of EMA"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-amsgrad rdfs:label "AMSGrad"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-an_automatic_trigger rdfs:label "an automatic trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-an_upper_bound_on_the_expected_loss rdfs:label "an upper bound on the expected loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anaconda_environment rdfs:label "Anaconda environment"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-analysis rdfs:label "analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-analysis_of_section_21 rdfs:label "analysis of Section 2.1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-analysis_tool rdfs:label "analysis tool"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-any_particular_choice_of_optimiser rdfs:label "any particular choice of optimiser"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-appendix_a4 rdfs:label "Appendix A.4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ar%09extmu rdfs:label "ar{	ext{mu}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ar%09extsigma2 rdfs:label "ar{	ext{sigma}}^{2}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arbitrary_value rdfs:label "arbitrary value"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-argmax_ix_i_phi_1 rdfs:label "argmax_{i}||X_{i}||_{\\phi_{1}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arxiv12125701 rdfs:label "arXiv:1212.5701"@en ;
    askg-onto:entityType "Article"@en,
        "Publication"@en .

askg-data:Entity-arxiv14091556 rdfs:label "arXiv:1409.1556"@en ;
    askg-onto:entityType "Article"@en,
        "Publication"@en .

askg-data:Entity-arxiv150203167 rdfs:label "arXiv:1502.03167"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv160507146 rdfs:label "arXiv:1605.07146"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv160904836 rdfs:label "arXiv:1609.04836"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv161103530 rdfs:label "arXiv:1611.03530"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv171104623 rdfs:label "arXiv:1711.04623"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv171207628 rdfs:label "arXiv:1712.07628"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv180102254 rdfs:label "arXiv:1801.02254"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv180305407 rdfs:label "arXiv:1803.05407"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv190200744 rdfs:label "arXiv:1902.00744"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv191209656 rdfs:label "arXiv:1912.09656"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv_preprint_arxiv14121193 rdfs:label "arXiv preprint arXiv:1412.1193"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv14126980 rdfs:label "arXiv preprint arXiv:1412.6980"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv160507146 rdfs:label "arXiv preprint arXiv:1605.07146"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv170708819 rdfs:label "arXiv preprint arXiv:1707.08819"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv170802182 rdfs:label "arXiv preprint arXiv:1708.02182"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv171104623 rdfs:label "arXiv preprint arXiv:1711.04623"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv171207628 rdfs:label "arXiv preprint arXiv:1712.07628"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv180208530 rdfs:label "arXiv preprint arXiv:1802.08530"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv180606763 rdfs:label "arXiv preprint arXiv:1806.06763"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv181012281 rdfs:label "arXiv preprint arXiv:1810.12281"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190409237 rdfs:label "arXiv preprint arXiv:1904.09237"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190504899 rdfs:label "arXiv preprint arXiv:1905.04899"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190803265 rdfs:label "arXiv preprint arXiv:1908.03265"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv_preprint_arxiv190913719 rdfs:label "arXiv preprint arXiv:1909.13719"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-asgd_schedule rdfs:label "ASGD schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-assumptions rdfs:label "assumptions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-asymmetric_valleys rdfs:label "Asymmetric valleys"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-asymptotically rdfs:label "asymptotically"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-at_least_not_as_important_as_bias rdfs:label "at least not as important as bias"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-authors rdfs:label "authors"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-authors_chen__gu_2018 rdfs:label "authors (Chen & Gu, 2018)"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-authors_of_he_et_al rdfs:label "authors of He et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-automatic_optimiser rdfs:label "automatic optimiser"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-automatic_trigger rdfs:label "automatic trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average rdfs:label "average"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average_iterate rdfs:label "average iterate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average_number_of_models rdfs:label "average number of models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average_of_iterates rdfs:label "average of iterates"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-average_of_the_iterates rdfs:label "average of the iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average_weight rdfs:label "average weight"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaged_and_normal_optimisers rdfs:label "averaged and normal optimisers"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-averaged_iterates rdfs:label "averaged iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaged_schemes rdfs:label "averaged schemes"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-averaged_stochastic_gradient_descent_asgd rdfs:label "Averaged Stochastic Gradient Descent (ASGD)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-averaging_adam_iterates rdfs:label "averaging Adam iterates"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-averaging_every_iteration rdfs:label "averaging every iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-averaging_frequencies rdfs:label "averaging frequencies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_frequency rdfs:label "averaging frequency"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_frequency_lookahead rdfs:label "Averaging Frequency Lookahead"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_less rdfs:label "averaging less"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_once_an_epoch rdfs:label "averaging once an epoch"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-averaging_once_per_epoch rdfs:label "averaging once per epoch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_once_per_n_iterations rdfs:label "averaging once per n iterations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_point rdfs:label "averaging point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_scheme rdfs:label "averaging scheme"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_starting_point rdfs:label "averaging starting point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_trigger rdfs:label "averaging trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_weights rdfs:label "Averaging weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-averaging_while_lookahead rdfs:label "Averaging While Lookahead"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b__i rdfs:label "B = I"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ballas_n rdfs:label "Ballas, N."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bansal_n rdfs:label "Bansal, N."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-base_learning_rate_of_01 rdfs:label "base learning rate of 0.1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-baseline rdfs:label "baseline"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-baseline_algorithms rdfs:label "baseline algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-batch_gradient_estimate rdfs:label "batch gradient estimate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_gradients rdfs:label "batch gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_normalization rdfs:label "Batch normalization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-batch_size_b rdfs:label "batch size B"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_size_of_128 rdfs:label "batch size of 128"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_sizes rdfs:label "batch sizes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bayesian rdfs:label "Bayesian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bayesian_uncertainty rdfs:label "Bayesian uncertainty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bayesian_viewpoint rdfs:label "Bayesian viewpoint"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bengio_s rdfs:label "Bengio, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bernsteins_inequality rdfs:label "Bernstein's inequality"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-bersteins_deviation_inequality rdfs:label "Berstein's deviation inequality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-best rdfs:label "best"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-best_ia rdfs:label "best IA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-best_performance rdfs:label "best performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-best_test_performance rdfs:label "best test performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-better-generalising_flat_minima rdfs:label "better-generalising flat minima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-better_bound_of_expected_loss rdfs:label "better bound of expected loss"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-better_expected_loss_bound rdfs:label "better expected loss bound"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-better_generalisation_performance rdfs:label "better generalisation performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-better_generalization rdfs:label "better generalization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-better_performance rdfs:label "better performance"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-better_robustness_to_gradient_noise rdfs:label "better robustness to gradient noise"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-better_solution rdfs:label "better solution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-better_validation_perplexity rdfs:label "better validation perplexity"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-bias-corrupted rdfs:label "bias-corrupted"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-bias_and_noise rdfs:label "bias and noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bias_in_batch_gradient_estimate rdfs:label "bias in batch gradient estimate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bias_term rdfs:label "bias term"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-biased_solution rdfs:label "biased solution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bn_networks rdfs:label "BN networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bottou_2012 rdfs:label "Bottou, 2012"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bounding_the_regret_o_t rdfs:label "bounding the regret O( âˆšT)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-brackets rdfs:label "brackets"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-break-even_point rdfs:label "break-even point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c2 rdfs:label "C.2."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-calculation rdfs:label "Calculation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cambridge_university_press rdfs:label "Cambridge university press"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-careful_learning_rate_scheduling rdfs:label "careful learning rate scheduling"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-cases rdfs:label "cases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-centered_unit_variance_version_of_the_random_variables rdfs:label "centered, unit variance version of the random variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-central_limit_theorem rdfs:label "Central Limit Theorem"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-chen__gu rdfs:label "Chen & Gu"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-chen_j rdfs:label "Chen, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chen_w rdfs:label "Chen, W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chen_x rdfs:label "Chen, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cho_k rdfs:label "Cho, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-choe_j rdfs:label "Choe, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chrabaszcz_p rdfs:label "Chrabaszcz, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-chun_s rdfs:label "Chun, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cifar_data-sets rdfs:label "CIFAR data-sets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-cifar_datasets rdfs:label "CIFAR datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-ck2 rdfs:label "CK^{2}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classification rdfs:label "classification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-code rdfs:label "code"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-codebase rdfs:label "codebase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-combinable_benefits rdfs:label "combinable benefits"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-combined_noise_reduction_and_implicit_learning_rate_decay_mechanism rdfs:label "combined noise reduction and implicit learning rate decay mechanism"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-community rdfs:label "community"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-company rdfs:label "Company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-comparable_methods rdfs:label "comparable methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-competitively rdfs:label "competitively"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-computational_budget rdfs:label "computational budget"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computational_savings rdfs:label "computational savings"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-computer_vision rdfs:label "Computer Vision"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computer_vision_and_language_tasks rdfs:label "computer vision and language tasks"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-constant_learning_rate rdfs:label "constant learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant_learning_rate_after_iterate_averaging_activation rdfs:label "(constant) learning rate after iterate averaging activation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant_learning_rate_schedule rdfs:label "constant learning rate schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant_schedule rdfs:label "constant schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant_schedules rdfs:label "constant schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-context rdfs:label "context"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-continual_prediction rdfs:label "Continual prediction"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-convergence rdfs:label "convergence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convergence_bound rdfs:label "convergence bound"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convergence_for_the_iterate_average rdfs:label "convergence for the iterate average"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convergence_rate rdfs:label "convergence rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convergence_speeds_of_the_optimisers rdfs:label "convergence speeds of the optimisers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolutional_neural_network rdfs:label "Convolutional Neural Network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-corresponding rdfs:label "corresponding"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-counter-intuitive_results rdfs:label "counter-intuitive results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-counterparts_without_ia rdfs:label "counterparts without IA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coursera rdfs:label "COURSERA"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-coursera_neural_networks_for_machine_learning rdfs:label "COURSERA: Neural networks for machine learning"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-cp rdfs:label "cP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-critical_assumption rdfs:label "critical assumption"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cubuk_e rdfs:label "Cubuk, E."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cummins_f rdfs:label "Cummins, F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-curvature rdfs:label "curvature"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cutmix rdfs:label "Cutmix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dahl_g rdfs:label "Dahl, G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dashed_lines rdfs:label "dashed lines"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-data-driven_sparse_structure_selection rdfs:label "Data-driven sparse structure selection"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data-set rdfs:label "data-set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-data_analysis rdfs:label "Data Analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_representation rdfs:label "data representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-database rdfs:label "database"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-datasets rdfs:label "datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-decay rdfs:label "decay"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-decoupled_weight_decay_regularization rdfs:label "Decoupled weight decay regularization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning_context rdfs:label "deep learning context"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning_loss_landscape rdfs:label "deep learning loss landscape"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning_optimisation rdfs:label "deep learning optimisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning_practitioners rdfs:label "deep learning practitioners"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-deep_residual_networks rdfs:label "deep residual networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-default_values rdfs:label "default values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-defazio__bottou rdfs:label "Defazio & Bottou"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-defazio__bottou_2019 rdfs:label "Defazio & Bottou, 2019"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-defazio_a rdfs:label "Defazio, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-density rdfs:label "density"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deployment rdfs:label "deployment"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-details rdfs:label "details"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-determination_of_the_averaging_activation rdfs:label "determination of the averaging activation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-diagb1 rdfs:label "diag(Bâˆ’1)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-difference rdfs:label "difference"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-difference_in_test_accuracy rdfs:label "difference in test accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-different_base rdfs:label "different base"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_update_rules rdfs:label "different update rules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-discussion rdfs:label "discussion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-disease_diagnosis rdfs:label "Disease Diagnosis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-doi rdfs:label "DOI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-doiorg rdfs:label "doi.org"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dollar_p rdfs:label "Dollar, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-domain rdfs:label "Domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-duchi rdfs:label "Duchi"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-duchi_et_al rdfs:label "Duchi et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-dynamic_switching_between_adam_and_sgd rdfs:label "dynamic switching between Adam and SGD"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e1 rdfs:label "E.1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e3 rdfs:label "E.3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_epoch_of_training rdfs:label "each epoch of training"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-early_stop_point rdfs:label "early stop point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-early_termination rdfs:label "early termination"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-education_system rdfs:label "Education System"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-effective_and_efficient_training rdfs:label "effective and efficient training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effective_learning rdfs:label "effective learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effective_learning_rate_of_%CE%B1_1%CF%81 rdfs:label "effective learning rate of Î± 1âˆ’Ï"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effective_performance rdfs:label "effective performance"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-effectiveness rdfs:label "effectiveness"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-effects rdfs:label "effects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-efficacy rdfs:label "efficacy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-efficacy_of_ia rdfs:label "efficacy of IA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-elw_avgnsgd rdfs:label "E(L(w_avg,n^SGD))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-elwavgn rdfs:label "EL(w*avg,n*)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-elwn rdfs:label "E(L(wn))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-empirical_counterpart rdfs:label "empirical counterpart"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-empirical_evaluations rdfs:label "empirical evaluations"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-empirical_performance rdfs:label "empirical performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-enhanced_performance rdfs:label "enhanced performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-ensemble_method rdfs:label "ensemble method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-epoch rdfs:label "epoch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-epoch_161 rdfs:label "epoch 161"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation rdfs:label "Equation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_17 rdfs:label "equation 17"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_27 rdfs:label "Equation 27"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equation_6 rdfs:label "Equation 6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equipped_network rdfs:label "equipped network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-error_bars rdfs:label "Error bars"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-et_al rdfs:label "et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-european_conference_on_computer_vision rdfs:label "European conference on computer vision"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-every_iteration rdfs:label "every iteration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ew_i rdfs:label "E(w_i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ew_i_22 rdfs:label "E(||w_i||_2^2)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ex2_i__1 rdfs:label "EX2 i = 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-example rdfs:label "example"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expectation_of_the_l2_weight_norm rdfs:label "expectation of the L2 weight norm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expected_loss_of_the_final_iterate rdfs:label "expected loss of the final iterate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expected_weight_norm_of_the_individual_iterates rdfs:label "expected weight norm of the individual iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiment_section rdfs:label "Experiment section"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-experimental_validations rdfs:label "experimental validations"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-explanation rdfs:label "explanation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expleft-textcminbiggfract2k2fractkbiggnright rdfs:label "exp\\left\\{-\\text{cmin}\\bigg{(}\\frac{t^{2}}{K^{2}},\\frac{t}{K}\\bigg{)}N\\right\\}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-exponential_weight rdfs:label "exponential weight"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-exponentially-weighted_moving_average rdfs:label "exponentially-weighted moving average"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-exponentially_moving_average rdfs:label "exponentially moving average"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expxt rdfs:label "exp|X|/t"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-extent_of_adaptivity rdfs:label "extent of adaptivity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fact rdfs:label "fact"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-factor_of_10 rdfs:label "factor of 10"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-factor_of_10_at_100_150-th_epochs rdfs:label "factor of 10 at {100, 150}-th epochs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fast-_and_slow-varying_weights rdfs:label "fast- and slow-varying weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fast_ensembling_of_dnns rdfs:label "fast ensembling of dnns"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-fewer_hyperparameters_to_tune rdfs:label "fewer hyperparameters to tune"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fewer_number_of_iterates rdfs:label "fewer number of iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fge_results rdfs:label "FGE results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-figure_1 rdfs:label "Figure 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_11 rdfs:label "Figure 11"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_14 rdfs:label "Figure 14"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_2 rdfs:label "Figure 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_3 rdfs:label "Figure 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_4 rdfs:label "Figure 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_5 rdfs:label "Figure 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_6 rdfs:label "Figure 6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figures_15 rdfs:label "Figures 15"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-figures_16 rdfs:label "Figures 16"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-final_accuracy rdfs:label "final accuracy"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-final_iterate_of_optimisation rdfs:label "final iterate of optimisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_iterates_with_realistic_schedules rdfs:label "final iterates with realistic schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_performance rdfs:label "final performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_point rdfs:label "final point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_result rdfs:label "final result"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-final_solutions rdfs:label "final solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_test_performance rdfs:label "final test performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_value_at_the_end_of_training rdfs:label "Final Value at the End of Training"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-finalaverage_iterate rdfs:label "final/average iterate"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-fine-tuned_sgd rdfs:label "fine-tuned SGD"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-first_moment_estimate rdfs:label "first moment estimate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fischer_a rdfs:label "Fischer, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-fisher_information_matrix rdfs:label "Fisher Information Matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fix_of_the_problem rdfs:label "fix of the problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flat_minima rdfs:label "Flat minima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flat_valleys rdfs:label "flat valleys"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flatness rdfs:label "flatness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flatter_minima rdfs:label "flatter minima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flatter_minima_generalise_better rdfs:label "flatter minima generalise better"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fluctuates_more_during_training rdfs:label "fluctuates more during training"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-formulas_for_geometric_sums rdfs:label "formulas for geometric sums"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fort_s rdfs:label "Fort, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-free_hyperparameter rdfs:label "free hyperparameter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-freq rdfs:label "Freq"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-freq350 rdfs:label "freq=350"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-function_ft rdfs:label "function ft"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-further_apart rdfs:label "further apart"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g_0 rdfs:label "g_0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gadam-auto_cifar-100 rdfs:label "GADAM-AUTO CIFAR-100"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-gadam2 rdfs:label "Gadam2"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-gadam_ours rdfs:label "GADAM (OURS)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-gadam_procedure rdfs:label "Gadam procedure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gadam_run rdfs:label "Gadam run"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-gadamgadamx_algorithm rdfs:label "Gadam/GadamX algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-gadamswa rdfs:label "Gadam/SWA"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-gadamx_ours rdfs:label "GADAMX (OURS)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-gao_j rdfs:label "Gao, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gap rdfs:label "gap"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-garipov rdfs:label "Garipov"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-garipov_et_al rdfs:label "Garipov et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-gaussian_noise rdfs:label "Gaussian noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gaussianity_of_the_noise rdfs:label "Gaussianity of the noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geforce_rtx_2080_ti rdfs:label "GeForce RTX 2080 Ti"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-general_bounds_on_the_loss_of_a_noisy_quadratic rdfs:label "general bounds on the loss of a noisy quadratic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-general_update_rule_wn1__w__%CE%B1b1lw rdfs:label "general update rule wn+1 â† w âˆ’ Î±Bâˆ’1âˆ‡Lw"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalisation_gain rdfs:label "generalisation gain"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalisation_technique rdfs:label "generalisation technique"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalization rdfs:label "generalization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalization_gap rdfs:label "Generalization gap"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometry_argument rdfs:label "geometry argument"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geras_k rdfs:label "Geras, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gers_f rdfs:label "Gers, F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-girshick_r rdfs:label "Girshick, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-goldstein_t rdfs:label "Goldstein, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-golowich_n rdfs:label "Golowich, N."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gpu_acceleration rdfs:label "GPU acceleration"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-gradient rdfs:label "gradient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradient_based_methods rdfs:label "gradient based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-gradient_estimate rdfs:label "gradient estimate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradient_noise rdfs:label "gradient noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradient_perturbation rdfs:label "gradient perturbation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gradients rdfs:label "gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-great_generalisation_performance rdfs:label "great generalisation performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-grid_search rdfs:label "grid search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-grid_searched_initial_learning_rates rdfs:label "grid searched initial learning rates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gt rdfs:label "gt"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gu_q rdfs:label "Gu, Q."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-gw rdfs:label "g(w*)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h-1 rdfs:label "H^{-1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h-12w_0sgd-w2 rdfs:label "||H^{-1/2}(w_0^{SGD}-w*)||^2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h1gza2ntwh rdfs:label "H1gza2NtwH"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-h_and_%CF%83g rdfs:label "H and Î£g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h_is_ill-conditioned rdfs:label "H is ill-conditioned"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-han_d rdfs:label "Han, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-han_j rdfs:label "Han, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hardt_m rdfs:label "Hardt, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hazan_e rdfs:label "Hazan, E."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-he_et_al rdfs:label "He et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-he_h rdfs:label "He, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-he_p rdfs:label "He, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hertz_j rdfs:label "Hertz, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hessian rdfs:label "Hessian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hessian_trace rdfs:label "Hessian trace"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-heuristically_motivated rdfs:label "heuristically motivated"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high-dimensional_deep_learning_regime rdfs:label "high-dimensional deep learning regime"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high-dimensional_probability rdfs:label "High-dimensional probability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high-dimensional_probability_an_introduction_with_applications_in_data_science rdfs:label "High-dimensional probability: An introduction with applications in data science"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-high_constant_learning_rate rdfs:label "high constant learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high_in_bn_networks rdfs:label "high in BN networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-higher_dimensions rdfs:label "higher dimensions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-highly_over-parameterised_neural_network_regime rdfs:label "highly over-parameterised neural network regime"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hochreiter_s rdfs:label "Hochreiter, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hovy_e rdfs:label "Hovy, E."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-httpsgithubcomsalesforceawd-lstm-lm rdfs:label "https://github.com/salesforce/awd-lstm-lm"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-huang__wang_2018 rdfs:label "(HUANG & WANG, 2018)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-huang_g rdfs:label "Huang, G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-huang_z rdfs:label "Huang, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hyper-parameter_setup rdfs:label "hyper-parameter setup"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hyperparameter_choice rdfs:label "hyperparameter choice"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hyperparameter_tuning rdfs:label "Hyperparameter Tuning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hyperparameters_%CE%B1_and_k rdfs:label "hyperparameters Î± and k"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ia_experiments rdfs:label "IA experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-ia_point_at_iteration_n rdfs:label "IA point at iteration n"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ia_schedule rdfs:label "IA schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ia_solution rdfs:label "IA solution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ia_solutions rdfs:label "IA solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-identifier rdfs:label "identifier"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-identity_mappings rdfs:label "Identity mappings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ieee_access rdfs:label "IEEE Access"@en ;
    askg-onto:entityType "Organization"@en,
        "Publication"@en .

askg-data:Entity-image_classification_tasks rdfs:label "Image classification tasks"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-image_classificationlanguage_tasks rdfs:label "image classification/language tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-imagenet_3232_data-set rdfs:label "ImageNet 32Ã—32 Data-set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-imagenet_classification rdfs:label "ImageNet classification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-imagenet_dataset rdfs:label "ImageNet dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-implementation_details rdfs:label "implementation details"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-implicit_learning_rate_decay rdfs:label "implicit learning rate decay"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-implicit_regularisation rdfs:label "implicit regularisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-implicit_regularisation_of_non-adaptive_methods rdfs:label "implicit regularisation of non-adaptive methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improved_generalisation rdfs:label "improved generalisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improvement rdfs:label "improvement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improvement_against_p rdfs:label "Improvement against P"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-improvement_in_generalisation_performance rdfs:label "improvement in generalisation performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-improvement_margin rdfs:label "improvement margin"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improvements rdfs:label "improvements"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-in-depth_investigations rdfs:label "in-depth investigations"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-in-equivalence_between_l2_regularisation_and_weight_decay rdfs:label "in-equivalence between L2 regularisation and weight decay"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-increasing rdfs:label "increasing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-increasing_the_batch_size rdfs:label "increasing the batch size"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-independent_iterates rdfs:label "independent iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-independent_sub-gaussian_coordinates rdfs:label "independent sub-gaussian coordinates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-independent_zero_mean_sub-exponential_random_variables rdfs:label "independent, zero mean, sub-exponential random variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-independently_evolving_iterates rdfs:label "independently evolving iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inequality rdfs:label "inequality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inherent_regularisation rdfs:label "inherent regularisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_learning_rate_of_00005 rdfs:label "initial learning rate of 0.0005"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_learning_rate_of_0001 rdfs:label "initial learning rate of 0.001"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_learning_rate_of_1 rdfs:label "initial learning rate of 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-insights rdfs:label "insights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-integer rdfs:label "Integer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-integral_under_the_density rdfs:label "integral under the density"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-internal_covariate_shift rdfs:label "internal covariate shift"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-introductory_lectures rdfs:label "Introductory lectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-introductory_lectures_on_convex_optimization rdfs:label "Introductory lectures on convex optimization"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-inverse_of_the_pre-conditioning_matrix_b1 rdfs:label "inverse of the pre-conditioning matrix Bâˆ’1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ioffe__szegedy rdfs:label "Ioffe & Szegedy"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-ioffe_s rdfs:label "Ioffe, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-irrelevance_of_local_geometry_argument rdfs:label "irrelevance of local geometry argument"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-isbn_978-3-642-35289-8 rdfs:label "ISBN 978-3-642-35289-8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-isotropic_noise rdfs:label "isotropic noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-it rdfs:label "it"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterate_averaging_activation rdfs:label "iterate averaging activation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterate_averaging_as_ineffective_for_deep_learning rdfs:label "Iterate Averaging as ineffective for deep learning"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-iterate_averaging_is_activated rdfs:label "iterate averaging is activated"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterate_l_norm rdfs:label "iterate Lâˆž norm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterate_lr rdfs:label "ITERATE LR"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-iterates_to_be_further_apart rdfs:label "iterates to be further apart"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterating_averaging rdfs:label "iterating averaging"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-iteration rdfs:label "iteration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterations rdfs:label "iterations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterative_averaging rdfs:label "iterative averaging"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iterative_spectral_methods rdfs:label "iterative spectral methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-its_efficacy rdfs:label "its efficacy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-izmailov rdfs:label "Izmailov"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-jastrzebski_et_al rdfs:label "Jastrzebski et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-jastrzebski_s rdfs:label "Jastrzebski, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-jastrzkebski_et_al rdfs:label "Jastrzkebski et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-jastrzkebski_s rdfs:label "Jastrzkebski, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-jensens_inequality rdfs:label "Jensen's inequality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-jiang_h rdfs:label "Jiang, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-john_doe rdfs:label "John Doe"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-journal_of_ai_research rdfs:label "Journal of AI Research"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-journal_of_machine_learning_research rdfs:label "Journal of machine learning research"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-k__5 rdfs:label "k = 5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-k_steps_forward_1_step_back rdfs:label "k steps forward, 1 step back"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-kale_s rdfs:label "Kale, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kenton_z rdfs:label "Kenton, Z."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-keras rdfs:label "Keras"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-keskar__socher rdfs:label "Keskar & Socher"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-keskar_et_al rdfs:label "Keskar et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kingma_d rdfs:label "Kingma, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-komodakis_n rdfs:label "Komodakis, N."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kondor_r rdfs:label "Kondor, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-krizhevsky_a rdfs:label "Krizhevsky, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-krogh__hertz rdfs:label "Krogh & Hertz"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-krogh_a rdfs:label "Krogh, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kumar_s rdfs:label "Kumar, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kushner__yin_2003 rdfs:label "Kushner & Yin, 2003"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kushner_h rdfs:label "Kushner, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-l%0A%0A_%0A%0Aw%0A%0A_%0A%0A__%0A%0A_%0A%0A%0A%0A__%0A%0A_%0A%0A_%0A%0A_%0A%0A_%0A%0A_%0A%0A%0Crac%0A%0A_%0A%0A%09extalpha4%09exttrigg1-%0Crac%09extalpha2%0A%0Ah%0A%0A-1%0A%0A%09extsigma_g%0A%0A_%0A%0Aw%0A%0A_%0A%0Aigg rdfs:label """L(

 

w

 *

) + 

 



  

 

 

 

 

 

rac{

 

	ext{alpha}}{4}	ext{Tr}igg{(}(1-rac{	ext{alpha}}{2}

H)

^{-1}

	ext{Sigma}_{g}(

 

w

 *

)igg{)}"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l2 rdfs:label "L2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l2_norm rdfs:label "L2 norm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l2_norm_axis rdfs:label "L2 norm axis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l2_solution rdfs:label "L2 solution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l2_weight_norm rdfs:label "L2 weight norm"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-l_%09extbfw_t rdfs:label "L_{	extbf{w}_{t}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-l_k rdfs:label "L_{k}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lanczos-based_spectral_tool rdfs:label "Lanczos-based spectral tool"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-language_classification_tasks rdfs:label "Language classification tasks"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-language_modelling_method rdfs:label "Language Modelling Method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-language_modelling_tasks rdfs:label "language modelling tasks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-language_tasks rdfs:label "language tasks"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-large-batch_training rdfs:label "large-batch training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-large-scale_image_recognition rdfs:label "large-scale image recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-larger_trace_and_frobenius_norm rdfs:label "larger trace and Frobenius norm"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-later_stage_of_training rdfs:label "later stage of training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-le rdfs:label "Le"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-le_q rdfs:label "Le, Q."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-learning rdfs:label "Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_paradigm rdfs:label "learning paradigm"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-learning_rate_method rdfs:label "learning rate method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_of_003 rdfs:label "learning rate of 0.03"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_schedule_choice rdfs:label "learning rate schedule choice"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_scheduler rdfs:label "learning rate scheduler"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_step rdfs:label "learning rate step"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_to_forget rdfs:label "Learning to forget"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lecture_6 rdfs:label "Lecture 6"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-lecun rdfs:label "lecun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lecun_1998 rdfs:label "LeCun, 1998"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-lecun_y rdfs:label "LeCun, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-less_independent_iterates rdfs:label "less independent iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-level_modelling rdfs:label "level modelling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lh rdfs:label "LH"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-li_et_al rdfs:label "Li et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-li_h rdfs:label "Li, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-li_l rdfs:label "Li, L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-liao_q rdfs:label "Liao, Q."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-linear_decay rdfs:label "linear decay"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_decay_schedules rdfs:label "linear decay schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_reduction rdfs:label "linear reduction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linearly rdfs:label "linearly"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-liu_et_al rdfs:label "Liu et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-liu_l rdfs:label "Liu, L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-liu_x rdfs:label "Liu, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-local_geometry rdfs:label "local geometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-local_geometry_arguments rdfs:label "local geometry arguments"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-local_geometry_of_the_minimum rdfs:label "local geometry of the minimum"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-logistic_regression_experiments rdfs:label "logistic regression experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-longer_training rdfs:label "longer training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lookahead_and_adaptive_optimisers rdfs:label "Lookahead and adaptive optimisers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lookahead_averaging_method rdfs:label "Lookahead Averaging Method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-lookahead_optimizer rdfs:label "Lookahead optimizer"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lookahead_paper rdfs:label "Lookahead paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-loss_at_minimum rdfs:label "loss at minimum"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_at_minimum_lw rdfs:label "loss at minimum L(wâˆ—)"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-loss_elwavgn rdfs:label "loss EL(w*avg,n*)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_elwn rdfs:label "loss EL(wn)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_landscape rdfs:label "loss landscape"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_of_the_average_of_the_iterates rdfs:label "loss of the average of the iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_of_the_average_point rdfs:label "loss of the average point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_surfaces rdfs:label "Loss surfaces"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-losses rdfs:label "losses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-losses_elwavgn rdfs:label "losses EL(wavg,n)"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-losses_elwn rdfs:label "losses EL(wn)"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-low_l2_weight_norm_solutions rdfs:label "low L2 weight norm solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-low_weight_norm_solutions rdfs:label "Low weight norm solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lstm_3-layer rdfs:label "LSTM 3-LAYER"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-lstm_language_models rdfs:label "LSTM language models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-lucas_j rdfs:label "Lucas, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-luong_m-t rdfs:label "Luong, M.-T."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-lw rdfs:label "L(w*)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lw__%CE%B14trb-1%CF%83_gw rdfs:label "L(w*) + (Î±/4)Tr(B^-1Î£_g(w*))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lw__min1n1trb-1%CF%83_gw_%CE%B12trb-1%CF%83_gw rdfs:label "L(w*) + min((1/(n+1))Tr(B^-1Î£_g(w*)), (Î±/2)Tr(B^-1Î£_g(w*))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lw_avgn rdfs:label "L(w_avg,n)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lw_avgnadam rdfs:label "L(w_{avg,n}^{Adam})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lw_avgnsgd rdfs:label "L(w_avg,n,SGD)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lw_n rdfs:label "L(w_n)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-m rdfs:label "M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-m0 rdfs:label "m0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning_algorithms rdfs:label "Machine Learning Algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning_research_group rdfs:label "Machine Learning Research Group"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-maddox_w rdfs:label "Maddox, W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-manually_triggered_asgd rdfs:label "manually triggered ASGD"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-manzagol_p-a rdfs:label "Manzagol, P.-A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-marcinkiewicz_m rdfs:label "Marcinkiewicz, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-marcus_et_al_1993 rdfs:label "Marcus et al., 1993"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-marcus_m rdfs:label "Marcus, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-margin_of_improvement_from_averaging rdfs:label "margin of improvement from averaging"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-margin_of_test_improvement rdfs:label "margin of test improvement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-markovs_inequality rdfs:label "Markov's inequality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-martens rdfs:label "Martens"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-mathbbe rdfs:label "\\mathbb{E}\","@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathcalnleftfracw_0nalphalambdafracalphasigma2lambda_nright rdfs:label "\\mathcal{N}\\left({\\frac{w_{0}}{n\\alpha\\lambda}},{\\frac{\\alpha\\sigma^{2}}{\\lambda n}}\\right)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathematical_expression rdfs:label "mathematical expression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathematical_operation rdfs:label "mathematical operation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mathematics_of_data rdfs:label "Mathematics of Data"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-max_of_previous_estimates rdfs:label "max of previous estimates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maximal_batch_size rdfs:label "maximal batch size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maximum_margin_solutions rdfs:label "maximum margin solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mcdonnell rdfs:label "McDonnell"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-mcdonnell_m rdfs:label "McDonnell, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-measures_of_sharpness_and_flatness rdfs:label "measures of sharpness and flatness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-measures_on_the_sharpness_of_the_solutions rdfs:label "measures on the sharpness of the solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mechanism rdfs:label "mechanism"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-merity_et_al_2017 rdfs:label "Merity et al. (2017)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-merity_s rdfs:label "Merity, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-methods_of_proof rdfs:label "Methods of proof"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-methods_that_precondition_the_gradient_with_a_non-identity_matrix_b1 rdfs:label "methods that precondition the gradient with a non-identity matrix Bâˆ’1"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-methods_to_determine_tavg rdfs:label "methods to determine Tavg"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-minibatch_size rdfs:label "minibatch size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-minima rdfs:label "minima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-minimising_true_loss_function rdfs:label "minimising true loss function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-minimum_w rdfs:label "minimum wâˆ—"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-miranda_b rdfs:label "Miranda, B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mixed_result rdfs:label "mixed result"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-mlrg_deep_curvature rdfs:label "MLRG deep curvature"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mnist_data-set rdfs:label "MNIST data-set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mnist_database rdfs:label "MNIST database"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mnist_dataset rdfs:label "MNIST dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-mode_connectivity rdfs:label "mode connectivity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model_expressiveness rdfs:label "model expressiveness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model_instances rdfs:label "model instances"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model_parameters rdfs:label "model parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-models rdfs:label "models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-modern_networks rdfs:label "modern networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-modest_improvements_in_test_performance rdfs:label "modest improvements in test performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-modified_wrn rdfs:label "MODIFIED WRN"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-momena_%CF%81 rdfs:label "momena Ï"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-momentum_%CF%81__0_09 rdfs:label "momentum Ï = [0, 0.9]"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-momentum_parameter_%CE%B2__09 rdfs:label "momentum parameter (Î² = 0.9)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-momentum_parameters rdfs:label "momentum parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-momentum_parameters_%CE%B21_%CE%B22__09_0999_and__108 rdfs:label "momentum parameters {Î²1, Î²2} = {0.9, 0.999} and = 10âˆ’8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-more_complex_models rdfs:label "more complex models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-more_effective_averaging rdfs:label "more effective averaging"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-more_probability_mass rdfs:label "more probability mass"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-more_recent_iterates rdfs:label "more recent iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mt rdfs:label "mt"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-much_worse rdfs:label "much worse"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-mudigere rdfs:label "Mudigere"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-multiple_layers rdfs:label "multiple layers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n_0_%CF%832 rdfs:label "N (0, Ïƒ2)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n__ne_b rdfs:label "n = NE B"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nado_z rdfs:label "Nado, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-natural_gradient_method rdfs:label "natural gradient method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-natural_number rdfs:label "natural number"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-near_linear_relation rdfs:label "near linear relation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nesterov_momentum rdfs:label "Nesterov momentum"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-nesterov_y rdfs:label "Nesterov, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-network rdfs:label "network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_architecture rdfs:label "Network architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-network_architectures rdfs:label "network architectures"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-networks rdfs:label "networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_computation rdfs:label "Neural Computation"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-neural_nets rdfs:label "neural nets"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_network rdfs:label "neural network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_network_architecture rdfs:label "Neural Network Architecture"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_networks_for_machine_learning rdfs:label "Neural networks for machine learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-new_version rdfs:label "new version"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nocedal rdfs:label "Nocedal"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-noise-independent_term rdfs:label "noise-independent term"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_in_the_gradient rdfs:label "noise in the gradient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_reducing_effects rdfs:label "noise reducing effects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_reduction rdfs:label "noise reduction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_reduction_scheme rdfs:label "noise reduction scheme"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_robustness rdfs:label "noise robustness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noiseless_convex_quadratic rdfs:label "noiseless convex quadratic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noisy_gradient rdfs:label "noisy gradient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noisy_gradient_at_%0A%09extbfw_t rdfs:label """noisy gradient at 
	extbf{w}_{t}"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-accelerated_methods rdfs:label "non-accelerated methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-non-adaptive_method rdfs:label "non-adaptive method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-adaptive_optimisers rdfs:label "non-adaptive optimisers"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-non-meaningful_entities rdfs:label "non-meaningful entities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-monotonic_trigger rdfs:label "Non-monotonic Trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-none rdfs:label "none"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normalized_sum_of_independent_mean_zero_variables rdfs:label "normalized sum of independent, mean zero variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-not_as_important_as_the_noise rdfs:label "not as important as the noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-not_sufficient rdfs:label "not sufficient"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-number_of_epochs_of_validation_accuracy_stagnation rdfs:label "number of epochs of validation accuracy stagnation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_parameters rdfs:label "number of parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_passes rdfs:label "number of passes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nvidia_geforce_gtx_1080_ti rdfs:label "NVIDIA GeForce GTX 1080 Ti"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-nvidia_geforce_rtx_2080_ti_gpu rdfs:label "NVIDIA GeForce RTX 2080 Ti GPU"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-o_%CE%B2r2_k2___%CF%83r_k_k%CE%B4 rdfs:label "O( Î²R2 k2 + âˆš ÏƒR k +kÎ´)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-o_%CE%B2r2_k___%CF%83r_k_%CE%B4 rdfs:label "O( Î²R2 k + âˆš ÏƒR k +Î´)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-o_p_n rdfs:label "O( âˆšP n)"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-oh_s rdfs:label "Oh, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-oldsymbolg_0 rdfs:label "oldsymbol{g}_0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oldsymbolg_k-1 rdfs:label "oldsymbol{g}_{k-1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oldsymbolh-12 rdfs:label "$oldsymbol{H}^{-1/2}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oldsymbolw-12oldsymbolh-12oldsymbolw_0%0Dm_sgd-oldsymbolw rdfs:label "$||oldsymbol{w}^{-1/2}||<||oldsymbol{H}^{-1/2}(oldsymbol{w}_0^{\rm SGD}-oldsymbol{w}^*)||$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oldsymbolw_%0Dm_avgn%0Dm_adam rdfs:label "$oldsymbol{w}_{\rm avg,n}^{\rm Adam}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-oldsymbolw_0 rdfs:label "$oldsymbol{w}_0$"@en,
        "$<oldsymbol{w}_0$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-olog_p_n rdfs:label "O(log P âˆšn)"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-once_per_epoch rdfs:label "once per epoch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-online_learning rdfs:label "online learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-online_stochastic_optimisation rdfs:label "online stochastic optimisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-openreviewnet rdfs:label "openreview.net"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-optima rdfs:label "optima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_convergence_rate rdfs:label "optimal convergence rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_performance rdfs:label "optimal performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-optimal_rate_of_convergence rdfs:label "optimal rate of convergence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_solution_l_w rdfs:label "optimal solution L âˆ—w"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_weight rdfs:label "optimal weight"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimisation_and_generalisation_benefits rdfs:label "optimisation and generalisation benefits"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-optimised_weights rdfs:label "optimised weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimiser_data-set rdfs:label "OPTIMISER DATA-SET"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-optimisers_tested rdfs:label "optimisers tested"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-optimisers_with_ia rdfs:label "optimisers with IA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization_for_deep_neural_networks rdfs:label "Optimization for deep neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization_technique rdfs:label "optimization technique"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-optimization_trajectories rdfs:label "optimization trajectories"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-organization rdfs:label "organization"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-orthogonality_regularizations rdfs:label "orthogonality regularizations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-other_optimisers rdfs:label "other optimisers"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-our_method rdfs:label "our method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-our_result_without_lookahead rdfs:label "our result without Lookahead"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-out-performance rdfs:label "out-performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-over-fitting rdfs:label "over-fitting"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-over-parameterisation rdfs:label "over-parameterisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-over-parameterised rdfs:label "over-parameterised"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-p__0_05 rdfs:label "p âˆˆ [0, 0.5]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p__n rdfs:label "P = N"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-padam_with_decoupled_weight_decay rdfs:label "Padam with decoupled weight decay"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-page_numbers rdfs:label "Page Numbers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pages rdfs:label "pages"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paper rdfs:label "Paper"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-paradigm rdfs:label "Paradigm"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-partial_adaptivity rdfs:label "partial adaptivity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-partially_adaptive_parameter rdfs:label "partially adaptive parameter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-partially_adaptive_parameter_p__02 rdfs:label "partially adaptive parameter p = 0.2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-partially_adaptive_variant_of_gadam rdfs:label "partially adaptive variant of Gadam"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-partially_valid_and_relevant rdfs:label "partially valid and relevant"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patience__10 rdfs:label "patience = 10"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-patient_outcomes rdfs:label "Patient Outcomes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-penn_treebank rdfs:label "Penn Treebank"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-penn_treebank_ptb_data-set rdfs:label "Penn Treebank (PTB) data-set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-per_parameter_estimation_noise rdfs:label "per parameter estimation noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-performance rdfs:label "performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-performance_and_hessian-based_sharpness_metrics rdfs:label "Performance and Hessian-based sharpness metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-phenomenon rdfs:label "phenomenon"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-poggio_t rdfs:label "Poggio, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-point_at_which_averaging_starts rdfs:label "point at which averaging starts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-polyak-style_ia rdfs:label "Polyak-style IA"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-polyak_momentum rdfs:label "Polyak momentum"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-poorest_training_accuracy rdfs:label "poorest training accuracy"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-positivesemidefinite_surrogate_of_hessian_h rdfs:label "positivesemidefinite surrogate of Hessian H"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-posterior_predictive_distribution rdfs:label "posterior predictive distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-practice rdfs:label "practice"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-preactivated_resnet_prn rdfs:label "Preactivated ResNet (PRN)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-preceding_section rdfs:label "preceding section"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-preliminary_study rdfs:label "preliminary study"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-previous_explanations rdfs:label "previous explanations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-previous_work rdfs:label "previous work"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-prior_literature rdfs:label "prior literature"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-prn-164 rdfs:label "PRN-164"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-probability_density rdfs:label "probability density"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probability_mass rdfs:label "probability mass"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-procedures rdfs:label "procedures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proceedings rdfs:label "Proceedings"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-process rdfs:label "process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proof_of_theorem_1 rdfs:label "Proof of Theorem 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proofs_of_convergence rdfs:label "proofs of convergence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-properties_of_the_ia_and_sgd_points rdfs:label "properties of the IA and SGD points"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposed_solutions rdfs:label "proposed solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prr_p_1dr rdfs:label "p(r)r P âˆ’1dr"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ptb_word rdfs:label "PTB word"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-pure_gradient_method rdfs:label "pure gradient method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pure_sgd_case rdfs:label "pure SGD case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-python_37 rdfs:label "Python 3.7"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-pytorch_11 rdfs:label "PyTorch 1.1"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-quadratic_analysis rdfs:label "quadratic analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quadratic_optimisation rdfs:label "quadratic optimisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r1g87c4kwb rdfs:label "r1g87C4KwB"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rakhlin_a rdfs:label "Rakhlin, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-randaugment rdfs:label "Randaugment"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-random_crops rdfs:label "random crops"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-random_matrix_theory rdfs:label "random matrix theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-random_vector rdfs:label "random vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rate rdfs:label "Rate"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-rate_scales rdfs:label "rate scales"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-rate_schedules rdfs:label "Rate Schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ratio_of_parameters_to_batch_size rdfs:label "ratio of parameters to batch size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rationale rdfs:label "rationale"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-real_networks rdfs:label "real networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-realistic_modern_network rdfs:label "realistic modern network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recent_attempt rdfs:label "recent attempt"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recent_creation rdfs:label "recent creation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recht rdfs:label "Recht"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-recht_b rdfs:label "Recht, B."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-rectified_adam rdfs:label "Rectified Adam"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-recursive_algorithms rdfs:label "recursive algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reddi_et_al_2019 rdfs:label "Reddi et al., 2019"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-reddi_s rdfs:label "Reddi, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-reducing_the_learning_rate rdfs:label "reducing the learning rate"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-regularising_effect_of_ia rdfs:label "Regularising Effect of IA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regularization_strategy rdfs:label "Regularization strategy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ren_s rdfs:label "Ren, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-research_activity rdfs:label "research activity"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_concept rdfs:label "Research Concept"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_data rdfs:label "research data"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_developments rdfs:label "Research developments"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_on_algorithms rdfs:label "Research on algorithms"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_on_neural_language_models rdfs:label "Research on neural language models"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_paper rdfs:label "Research Paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-research_papers rdfs:label "Research Papers"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-resnext rdfs:label "ResNeXt"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-rest_of_the_training rdfs:label "rest of the training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-results_on_the_noise_reduction_effect_of_iterate_averaging rdfs:label "results on the noise reduction effect of Iterate Averaging"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-rethinking_generalization rdfs:label "rethinking generalization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rigour rdfs:label "rigour"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rm-sprop rdfs:label "RM-Sprop"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-rmsprop rdfs:label "RMSProp"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-robustness rdfs:label "robustness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-robustness_to_choice_of_learning_rate_schedules rdfs:label "robustness to choice of learning rate schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-roelofs rdfs:label "Roelofs"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-room rdfs:label "room"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rough_estimation_of_posterior_mean rdfs:label "rough estimation of posterior mean"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-roux_et_al rdfs:label "Roux et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-roux_n rdfs:label "Roux, N."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-sachdeva_s rdfs:label "Sachdeva, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-santorini_b rdfs:label "Santorini, B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-schedule rdfs:label "schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scheduled_adam rdfs:label "SCHEDULED ADAM"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-schedules rdfs:label "schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-second_moment rdfs:label "second moment"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-second_moment_estimate rdfs:label "second moment estimate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-secondary_importance rdfs:label "secondary importance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_21 rdfs:label "Section 2.1"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-section_4 rdfs:label "Section 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sections_2_and_3 rdfs:label "Sections 2 and 3"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-selftraining_with_noisy_student rdfs:label "Selftraining with noisy student"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-setting rdfs:label "Setting"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-setup_and_hyperparameter_tuning rdfs:label "setup and hyperparameter tuning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-several_epochs rdfs:label "several epochs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sgd-based_optimisers rdfs:label "SGD-based optimisers"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-sgd4 rdfs:label "SGD4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sgd__lh_results rdfs:label "SGD + LH results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-sgd_iterates rdfs:label "SGD iterates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sgd_regret_bound rdfs:label "SGD regret bound"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sgd_run rdfs:label "SGD run"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-sgd_schedule rdfs:label "SGD schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shallue_c rdfs:label "Shallue, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-sharp_and_flat_local_minima rdfs:label "sharp and flat local minima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sharp_minima rdfs:label "sharp minima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sharpness_of_the_solutions rdfs:label "sharpness of the solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shift rdfs:label "shift"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shifts rdfs:label "shifts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shlens rdfs:label "Shlens"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-significant_effect rdfs:label "significant effect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-significant_generalisation_difference rdfs:label "significant generalisation difference"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-similar rdfs:label "similar"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-similar_assumption rdfs:label "similar assumption"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-similar_level_of_performance rdfs:label "similar level of performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simonyan__zisserman rdfs:label "Simonyan & Zisserman"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-simonyan_k rdfs:label "Simonyan, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-simple_average rdfs:label "simple average"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simple_averaging rdfs:label "simple averaging"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-simplifying rdfs:label "Simplifying"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-singer_y rdfs:label "Singer, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-single_bit rdfs:label "single bit"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-situations rdfs:label "situations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sizes_of_s__7500_2500_1000_250_100_50 rdfs:label "sizes of *||S||* = {7500, 2500, 1000, 250, 100, 50}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-slow_weights rdfs:label "slow weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-slowly rdfs:label "slowly"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-small_eigenvalue_directions rdfs:label "small eigenvalue directions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-small_terminal_learning_rates rdfs:label "small terminal learning rates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smaller rdfs:label "smaller"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-smaller_spectral_norm rdfs:label "smaller spectral norm"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-smaller_standard_deviation rdfs:label "smaller standard deviation"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-smaller_weight_decay rdfs:label "smaller weight decay"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smelyanskiy rdfs:label "Smelyanskiy"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-solid_lines rdfs:label "solid lines"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-solid_theoretical_foundations rdfs:label "solid theoretical foundations"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-solutions rdfs:label "solutions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-solutions_with_lower_curvature rdfs:label "solutions with lower curvature"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-specific_metric rdfs:label "specific metric"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spectral_norms rdfs:label "spectral norms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-springer rdfs:label "Springer"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-springer_berlin_heidelberg rdfs:label "Springer Berlin Heidelberg"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-square_root_of_the_diagonals_of_the_fisher_information_matrix rdfs:label "square root of the diagonals of the Fisher Information Matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-srebro rdfs:label "Srebro"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-stability rdfs:label "stability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-standard rdfs:label "standard"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-standard_deviation rdfs:label "standard deviation"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-starting_point_of_averaging rdfs:label "starting point of averaging"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-static_noise rdfs:label "static noise"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-statistical_methods rdfs:label "Statistical Methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-step_learning_rate_decay_schedule rdfs:label "step learning rate decay schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stephen_roberts rdfs:label "Stephen Roberts"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-stern rdfs:label "Stern"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-stochastic_approximation rdfs:label "Stochastic approximation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stochastic_approximation_and_recursive_algorithms rdfs:label "Stochastic approximation and recursive algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stochastic_convex_optimisation rdfs:label "stochastic convex optimisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stochastic_gradient_descent_tricks rdfs:label "Stochastic Gradient Descent Tricks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stochastic_weight_averaging rdfs:label "Stochastic Weight Averaging"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-storkey_a rdfs:label "Storkey, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-strong_performance rdfs:label "strong performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-strongest_test_performance rdfs:label "strongest test performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-studer_c rdfs:label "Studer, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-studies rdfs:label "Studies"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-study_on_expected_loss rdfs:label "study on expected loss"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-study_on_neural_networks rdfs:label "Study on Neural Networks"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-sub-exponential rdfs:label "sub-exponential"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-success rdfs:label "success"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-suggestions rdfs:label "suggestions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sums rdfs:label "sums"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sun_j rdfs:label "Sun, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-swa-auto_cifar-100 rdfs:label "SWA-AUTO CIFAR-100"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-swa-gaussian rdfs:label "SWA-Gaussian"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-swa_experiments rdfs:label "SWA experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-swagadamgadamx rdfs:label "SWA/Gadam/GadamX"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-szegedy_c rdfs:label "Szegedy, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-szymczak_m rdfs:label "Szymczak, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-t-th_epoch rdfs:label "t-th epoch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t_12%CE%B10 rdfs:label "t âˆ’1/2Î±0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t__1th_iterate rdfs:label "t + 1'th iterate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t__2 rdfs:label "T = 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_10 rdfs:label "Table 10"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_3 rdfs:label "Table 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_4 rdfs:label "Table 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_6 rdfs:label "Table 6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_7 rdfs:label "Table 7"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_8 rdfs:label "Table 8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_8_of_appendix_b2 rdfs:label "Table 8 of Appendix B.2"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-table_9 rdfs:label "Table 9"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tabor_j rdfs:label "Tabor, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-tang rdfs:label "Tang"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-taylor_g rdfs:label "Taylor, G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-techniques rdfs:label "techniques"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-terminal_ia_learning_rate rdfs:label "terminal IA learning rate"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-terminal_learning_rate rdfs:label "terminal learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-terminal_learning_rates rdfs:label "terminal learning rates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-termination rdfs:label "Termination"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tesla_v100 rdfs:label "Tesla V100"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-test_accuracy_evolution rdfs:label "Test Accuracy Evolution"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-test_and_train_surfaces rdfs:label "test and train surfaces"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-test_error rdfs:label "test error"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-test_errors rdfs:label "test errors"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-testing_error rdfs:label "Testing Error"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-testing_error_%CE%BB__0 rdfs:label "Testing Error Î» = 0"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-testing_performance rdfs:label "testing performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-testing_results rdfs:label "testing results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-the_covariance_of_the_gradients rdfs:label "the covariance of the gradients"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_experiments rdfs:label "the experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-the_extent_of_sub-sampling rdfs:label "the extent of sub-sampling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_final_iterate rdfs:label "the final iterate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_hessian_matrix rdfs:label "the Hessian matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_initial_stage_of_training rdfs:label "the initial stage of training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_number_of_iterations rdfs:label "the number of iterations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_optimal_point rdfs:label "the optimal point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_overall_loss_l rdfs:label "the (overall) loss L"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_parameters rdfs:label "the parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_penn_treebank rdfs:label "The penn treebank"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-the_same_data-set rdfs:label "the same data-set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-the_same_learning_rate rdfs:label "the same learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_theoretically_proposed_schedule rdfs:label "the theoretically proposed schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_training rdfs:label "the training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theorem rdfs:label "Theorem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theoretical_assumptions rdfs:label "theoretical assumptions"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-theoretical_bounds rdfs:label "theoretical bounds"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theoretical_insight rdfs:label "theoretical insight"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theoretically_and_experimentally rdfs:label "theoretically and experimentally"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theory_of_deep_learning_iib rdfs:label "Theory of deep learning IIb"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-thin-shell rdfs:label "thin-shell"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this rdfs:label "this"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_paper rdfs:label "this paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-this_works_well_empirically rdfs:label "this works well empirically"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tieleman__hinton_2012 rdfs:label "Tieleman & Hinton, 2012"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-tieleman_t rdfs:label "Tieleman, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-time_variable rdfs:label "time variable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tiny_images rdfs:label "tiny images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-tolerance rdfs:label "tolerance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-too_fast rdfs:label "too fast"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-top-1_test_accuracy rdfs:label "Top-1 Test Accuracy"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-top-5_accuracy rdfs:label "Top-5 accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-top-5_test_error rdfs:label "Top-5 Test Error"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-topmoumoute_online_natural_gradient_algorithm rdfs:label "Topmoumoute online natural gradient algorithm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-total_number_of_parameters_n_p rdfs:label "total number of parameters N P"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-total_training_budget_n rdfs:label "total training budget n"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tr rdfs:label "Tr"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trade-off rdfs:label "trade-off"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-traditional_measures_of_sharpness rdfs:label "traditional measures of sharpness"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-train_errors rdfs:label "train errors"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-train_strong_classifiers_with_localizable_features rdfs:label "train strong classifiers with localizable features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_accuracy rdfs:label "Training Accuracy"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-training_and_testing_loss_surface rdfs:label "training and testing loss surface"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_curve rdfs:label "training curve"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_deep_networks rdfs:label "training deep networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_deep_neural_networks rdfs:label "training deep neural networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_samples rdfs:label "training samples"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_termination rdfs:label "training termination"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-traintest_accuracy rdfs:label "Train/test accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-tran_p rdfs:label "Tran, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-trh-1%CF%83_gwn1__w_0adam-w2n12%CE%B12 rdfs:label "Tr(H^{-1}Î£_{g}(w^{*}))/n+1 + ||w_{0}^{Adam}-w^{*}||^{2}/((n+1)^{2}Î±^{2})"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trh-1sigma_gw rdfs:label "Tr(H^{-1}Sigma_g(w*))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triple_data rdfs:label "triple data"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trivedi__kondor rdfs:label "Trivedi & Kondor"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-trivedi__kondor_2017 rdfs:label "Trivedi & Kondor, 2017"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-trivedi_s rdfs:label "Trivedi, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-true_data_generating_distribution rdfs:label "true data generating distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_distribution rdfs:label "true distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_gradient_distribution rdfs:label "true gradient distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_loss_function rdfs:label "true loss function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_loss_surface rdfs:label "true loss surface"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_risk_surface rdfs:label "true risk surface"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tu_z rdfs:label "Tu, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-tuned_swa rdfs:label "tuned SWA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tuning_process rdfs:label "tuning process"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-u2u rdfs:label "(u^{2},u)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-universities rdfs:label "Universities"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-university_of_oxford rdfs:label "University of Oxford"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unspecified_work rdfs:label "unspecified work"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-url rdfs:label "URL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-v%CB%860 rdfs:label "vË†0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-v%CB%86t rdfs:label "vË†t"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-v0 rdfs:label "v0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validation_error rdfs:label "validation error"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validation_metrics rdfs:label "validation metrics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validation_perplexity rdfs:label "validation perplexity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validation_score rdfs:label "Validation Score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-validation_set rdfs:label "validation set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-validation_statistics rdfs:label "validation statistics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validationtest_perplexity rdfs:label "validation/test perplexity"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-variance_and_independence_in_the_weights_of_the_iterates_element-wise rdfs:label "variance and independence in the weights of the iterates element-wise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variance_of_test_accuracy rdfs:label "Variance of test accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-variance_reduced_optimization rdfs:label "variance reduced optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-various_scheduling_approaches rdfs:label "various scheduling approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-various_sgd_and_ia_experiments rdfs:label "various SGD and IA experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-vershynin_r rdfs:label "Vershynin, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-very_deep_convolutional_networks rdfs:label "Very deep convolutional networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-very_large_factor rdfs:label "very large factor"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-very_promisingly rdfs:label "very promisingly"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-vetrov rdfs:label "Vetrov"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-vgg-19 rdfs:label "VGG-19"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-vgg_network rdfs:label "VGG network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-vinyals_o rdfs:label "Vinyals, O."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-vision_and_language_processing_tasks rdfs:label "vision and language processing tasks"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-vision_tasks rdfs:label "vision tasks"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-volume_35 rdfs:label "volume 35"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-volume_47 rdfs:label "volume 47"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vt rdfs:label "vt"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w rdfs:label "w*"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w0 rdfs:label "w0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w0__w_ rdfs:label "|w0 âˆ’ w âˆ—|"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w1 rdfs:label "w1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_%09extavg rdfs:label "w_{	ext{avg}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_1 rdfs:label "w_{1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_2 rdfs:label "w_{2}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_avg rdfs:label "w_{avg}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_avg1 rdfs:label "w_{avg,1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_avgnadam rdfs:label "w_avg,n^Adam"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wadam_0__w rdfs:label "||wAdam 0 âˆ’ wâˆ—||"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-wan_x rdfs:label "Wan, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-wang_c rdfs:label "Wang, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-wang_n rdfs:label "Wang, N."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-wang_z rdfs:label "Wang, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-we rdfs:label "We"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-weak_performance rdfs:label "weak performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-weight-reducing_effect rdfs:label "weight-reducing effect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight-reducing_regularising_effect rdfs:label "weight-reducing regularising effect"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-weight_decay_%CE%BB rdfs:label "weight decay Î»"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_decay_%CE%BB__0_00005 rdfs:label "weight decay Î» = [0, 0.0005]"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-weight_decay_regularization rdfs:label "weight decay regularization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_norm_of_the_ia_point rdfs:label "weight norm of the IA point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_norm_reduction rdfs:label "weight norm reduction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_reduction_effect rdfs:label "weight reduction effect"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-weight_space_averaging rdfs:label "weight space averaging"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-wi_are_drawn_from_a_uniform_distribution rdfs:label "{wi} are drawn from a uniform distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wider_optima rdfs:label "wider optima"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wideresnet_28x10 rdfs:label "WideResNet 28x10"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-wideresnet_wrn rdfs:label "WideResNet (WRN)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wilson_et_al rdfs:label "Wilson et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-word_level_language_modelling rdfs:label "Word Level Language Modelling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-worse rdfs:label "worse"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-worse_dependence_on_noise_and_bias rdfs:label "worse dependence on noise and bias"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-worse_training rdfs:label "worse training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wrn rdfs:label "WRN"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-wrn_experiments rdfs:label "WRN experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-wsgd_0__w rdfs:label "||wSGD 0 âˆ’ wâˆ—||"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x1_xn rdfs:label "{X1*, ..X*n}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x2_i__1 rdfs:label "X2 i âˆ’ 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x2_i__1%CF%861 rdfs:label "||X2 i âˆ’ 1||Ï†1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_22 rdfs:label "|X|_{2}^{2}"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-x_phi_i rdfs:label "||X||_{\\phi_{i}}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xi rdfs:label "Xi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xie_q rdfs:label "Xie, Q."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-xie_s rdfs:label "Xie, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xu_b rdfs:label "Xu, B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xu_z rdfs:label "Xu, Z."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yann rdfs:label "yann"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yin_g rdfs:label "Yin, G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yoo_y rdfs:label "Yoo, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yuan_y rdfs:label "Yuan, Y."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yun_s rdfs:label "Yun, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zagoruyko_s rdfs:label "Zagoruyko, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zeiler_2012 rdfs:label "Zeiler, 2012"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zeiler_m rdfs:label "Zeiler, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhang_et_al_2016 rdfs:label "Zhang et al. (2016)"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zhang_et_al_2019a rdfs:label "Zhang et al., 2019a"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-zhang_m rdfs:label "Zhang, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhang_x rdfs:label "Zhang, X."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zisserman_a rdfs:label "Zisserman, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zohren_s rdfs:label "Zohren, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zoph rdfs:label "Zoph"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Paper-43d37e59d752bc41-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "Iterate Averaging Helps: An Alternative Perspective In Deep Learning"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-1-Paragraph-11 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Diego Granziol * 1 **Xingchen Wan** * 1 **Stephen Roberts** 1"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-1-Paragraph-11-Sentence-111 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Diego Granziol * 1 **Xingchen Wan** * 1 **Stephen Roberts** 1"@en ;
    askg-onto:inSentence "Diego Granziol * 1 **Xingchen Wan** * 1 **Stephen Roberts** 1"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-diego_granziol,
        askg-data:Entity-stephen_roberts,
        askg-data:Entity-xingchen_wan .

askg-data:Paper-43d37e59d752bc41-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "4. Gadam: Adam That Generalises"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1010,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1012,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-103,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-104,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-105,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-106,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-107,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-108,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-109 ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Whilst we compare SGD and IA with SGD in the preceding theoretical sections for a relative ease of exposition, we stress that the arguments we make with respect to the mechanisms of iterate averaging are mostly optimiser-agnostic: indeed, we repeat all our experimental validations in Sections 2 and 3, but replace SGD with adaptive methods, and we find that all the results hold (Appendix A.5). More importantly, we remark that in all conventional measures, adaptive methods indeed find *much* sharper solutions. Yet, when regularised properly and with IA, they deliver comparable testing results to SGD, further suggesting the irrelevance of local geometry argument in explaining generalisation. At the very least, this suggests that adaptive optimisers finding \"sharper\" solutions is not an argument against them *per se*."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1011,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1012,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1013,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1014 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Whilst we compare SGD and IA with SGD in the preceding theoretical sections for a relative ease of exposition, we stress that the arguments we make with respect to the mechanisms of iterate averaging are mostly optimiser-agnostic: indeed, we repeat all our experimental validations in Sections 2 and 3, but replace SGD with adaptive methods, and we find that all the results hold (Appendix A.5)."@en ;
    askg-onto:inSentence "Whilst we compare SGD and IA with SGD in the preceding theoretical sections for a relative ease of exposition, we stress that the arguments we make with respect to the mechanisms of iterate averaging are mostly optimiser-agnostic: indeed, we repeat all our experimental validations in Sections 2 and 3, but replace SGD with adaptive methods, and we find that all the results hold (Appendix A.5)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-appendix_a5,
        askg-data:Entity-experimental_validations,
        askg-data:Entity-ia,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-results,
        askg-data:Entity-sections_2_and_3,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "More importantly, we remark that in all conventional measures, adaptive methods indeed find *much* sharper solutions."@en ;
    askg-onto:inSentence "More importantly, we remark that in all conventional measures, adaptive methods indeed find *much* sharper solutions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-sharper_solutions .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Yet, when regularised properly and with IA, they deliver comparable testing results to SGD, further suggesting the irrelevance of local geometry argument in explaining generalisation."@en ;
    askg-onto:inSentence "Yet, when regularised properly and with IA, they deliver comparable testing results to SGD, further suggesting the irrelevance of local geometry argument in explaining generalisation."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-irrelevance_of_local_geometry_argument,
        askg-data:Entity-sgd,
        askg-data:Entity-testing_results .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-101-Sentence-1014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "At the very least, this suggests that adaptive optimisers finding \"sharper\" solutions is not an argument against them *per se*."@en ;
    askg-onto:inSentence "At the very least, this suggests that adaptive optimisers finding \"sharper\" solutions is not an argument against them *per se*."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-sharper_solutions .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1010 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "![6_image_1.png](6_image_1.png) Adam/Adam-IA and AdamW/Gadam on PRN-110 CIFAR-100."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1010-Sentence-10101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1010-Sentence-10101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_1.png](6_image_1.png) Adam/Adam-IA and AdamW/Gadam on PRN-110 CIFAR-100."@en ;
    askg-onto:inSentence "![6_image_1.png](6_image_1.png) Adam/Adam-IA and AdamW/Gadam on PRN-110 CIFAR-100."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamadam-ia,
        askg-data:Entity-adamwgadam,
        askg-data:Entity-cifar-100,
        askg-data:Entity-prn-110 .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "However, rather than attributing for this weak performance to the adaptive nature of Adam itself, we argue that the real culprit is the ineffective regularisation. Indeed, by comparing the weight norm of Adam and AdamW (Loshchilov & Hutter, 2018) in Figure 6(b), it is apparent that AdamW exerts a much stronger weight reduction effect. This effect should in turn keep the effective learning rate of iterates high in BN networks (Zhang et al., 2018b), which should lead to more effective averaging, as argued in Section 2.2."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011-Sentence-10111,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011-Sentence-10112,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011-Sentence-10113 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011-Sentence-10111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "However, rather than attributing for this weak performance to the adaptive nature of Adam itself, we argue that the real culprit is the ineffective regularisation."@en ;
    askg-onto:inSentence "However, rather than attributing for this weak performance to the adaptive nature of Adam itself, we argue that the real culprit is the ineffective regularisation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-regularisation,
        askg-data:Entity-weak_performance .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011-Sentence-10112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Indeed, by comparing the weight norm of Adam and AdamW (Loshchilov & Hutter, 2018) in Figure 6(b), it is apparent that AdamW exerts a much stronger weight reduction effect."@en ;
    askg-onto:inSentence "Indeed, by comparing the weight norm of Adam and AdamW (Loshchilov & Hutter, 2018) in Figure 6(b), it is apparent that AdamW exerts a much stronger weight reduction effect."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-adam,
        askg-data:Entity-adamw,
        askg-data:Entity-loshchilov__hutter,
        askg-data:Entity-weight_reduction_effect .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1011-Sentence-10113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This effect should in turn keep the effective learning rate of iterates high in BN networks (Zhang et al., 2018b), which should lead to more effective averaging, as argued in Section 2.2."@en ;
    askg-onto:inSentence "This effect should in turn keep the effective learning rate of iterates high in BN networks (Zhang et al., 2018b), which should lead to more effective averaging, as argued in Section 2.2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018b,
        askg-data:Entity-bn_networks,
        askg-data:Entity-effective_learning_rate,
        askg-data:Entity-high_in_bn_networks,
        askg-data:Entity-more_effective_averaging,
        askg-data:Entity-zhang_et_al .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1012 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "Indeed, as shown in Figure 6, replacing Adam iterates with AdamW (dashed lines) leads to an improved effectiveness in averaging that is on a par with SWA. We term this optimiser Gadam, whose full procedure (Algorithm 1) and additional details are shown in Appendix A."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1012-Sentence-10121,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1012-Sentence-10122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1012-Sentence-10121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Indeed, as shown in Figure 6, replacing Adam iterates with AdamW (dashed lines) leads to an improved effectiveness in averaging that is on a par with SWA."@en ;
    askg-onto:inSentence "Indeed, as shown in Figure 6, replacing Adam iterates with AdamW (dashed lines) leads to an improved effectiveness in averaging that is on a par with SWA."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-adamw,
        askg-data:Entity-averaging,
        askg-data:Entity-effectiveness,
        askg-data:Entity-swa .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1012-Sentence-10122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We term this optimiser Gadam, whose full procedure (Algorithm 1) and additional details are shown in Appendix A."@en ;
    askg-onto:inSentence "We term this optimiser Gadam, whose full procedure (Algorithm 1) and additional details are shown in Appendix A."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm_1,
        askg-data:Entity-gadam .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "GadamAuto The Gadam procedure requires us to determine the starting point of averaging Tavg, an important hyperparameter discussed in Section 2.1 (we stress it is not an *extra* hyperparameter - in normal schedules we need to determine when to decay the learning rate, and Tavg simply replaces that). While we use the simple heuristic of (Izmailov et al., 2018): they usually trigger averaging in the 161st epoch out of a 300-epoch budget. While this works well empirically, we also take inspiration from Merity et al. (2017) for an alternative heuristic to eliminate this free hyperparameter and to start averaging when validation accuracy does not improve for several epochs (the number of which is termed *patience*; after averaging, we use the same method to determine the early stop point, should a validation accuracy stagnates. We also use a *flat* learning rate schedule, thereby additionally eliminating the learning rate schedule choice. We term this variant GadamAuto, and from preliminary experiments it performs on par with the tuned Gadam2."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10131,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10132,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10133,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10134,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10135,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10136 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "GadamAuto The Gadam procedure requires us to determine the starting point of averaging Tavg, an important hyperparameter discussed in Section 2.1 (we stress it is not an *extra* hyperparameter - in normal schedules we need to determine when to decay the learning rate, and Tavg simply replaces that)."@en ;
    askg-onto:inSentence "GadamAuto The Gadam procedure requires us to determine the starting point of averaging Tavg, an important hyperparameter discussed in Section 2.1 (we stress it is not an *extra* hyperparameter - in normal schedules we need to determine when to decay the learning rate, and Tavg simply replaces that)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam_procedure,
        askg-data:Entity-learning_rate,
        askg-data:Entity-tavg .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While we use the simple heuristic of (Izmailov et al., 2018): they usually trigger averaging in the 161st epoch out of a 300-epoch budget."@en ;
    askg-onto:inSentence "While we use the simple heuristic of (Izmailov et al., 2018): they usually trigger averaging in the 161st epoch out of a 300-epoch budget."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-161st_epoch,
        askg-data:Entity-2018,
        askg-data:Entity-300-epoch_budget,
        askg-data:Entity-izmailov_et_al .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While this works well empirically, we also take inspiration from Merity et al."@en ;
    askg-onto:inSentence "While this works well empirically, we also take inspiration from Merity et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-merity_et_al,
        askg-data:Entity-this_works_well_empirically .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2017) for an alternative heuristic to eliminate this free hyperparameter and to start averaging when validation accuracy does not improve for several epochs (the number of which is termed *patience*; after averaging, we use the same method to determine the early stop point, should a validation accuracy stagnates."@en ;
    askg-onto:inSentence "(2017) for an alternative heuristic to eliminate this free hyperparameter and to start averaging when validation accuracy does not improve for several epochs (the number of which is termed *patience*; after averaging, we use the same method to determine the early stop point, should a validation accuracy stagnates."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-early_stop_point,
        askg-data:Entity-number_of_epochs,
        askg-data:Entity-patience,
        askg-data:Entity-several_epochs,
        askg-data:Entity-validation_accuracy .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We also use a *flat* learning rate schedule, thereby additionally eliminating the learning rate schedule choice."@en ;
    askg-onto:inSentence "We also use a *flat* learning rate schedule, thereby additionally eliminating the learning rate schedule choice."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning_rate_schedule,
        askg-data:Entity-learning_rate_schedule_choice .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1013-Sentence-10136 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We term this variant GadamAuto, and from preliminary experiments it performs on par with the tuned Gadam2."@en ;
    askg-onto:inSentence "We term this variant GadamAuto, and from preliminary experiments it performs on par with the tuned Gadam2."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam2,
        askg-data:Entity-gadamauto .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "Combinability We note that Gadam differs from to the many previous works that aim to generalise adaptive optimisers better by combining them with SGD in some form, and as an singular example, we propose **GadamX** that combines Gadam with Padam (Chen & Gu, 2018). We follow Chen & Gu (2018) and introduce an additional hyperparameter p, which controls the extent of adaptivity in the optimiser: for p = { 1 2 , 0}, we have fully adaptive Gadam/SWA (Izmailov et al., 2018) or ASGD (Merity et al., 2017) respectively. While adapting p may be desirable, for simplicity we follow the original authors suggestion and fix p to be 18 . We additionally implement decoupled weight decay in GadamX."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10141,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10142,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10143,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10144 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Combinability We note that Gadam differs from to the many previous works that aim to generalise adaptive optimisers better by combining them with SGD in some form, and as an singular example, we propose **GadamX** that combines Gadam with Padam (Chen & Gu, 2018)."@en ;
    askg-onto:inSentence "Combinability We note that Gadam differs from to the many previous works that aim to generalise adaptive optimisers better by combining them with SGD in some form, and as an singular example, we propose **GadamX** that combines Gadam with Padam (Chen & Gu, 2018)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chen__gu_2018,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-padam,
        askg-data:Entity-previous_works .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We follow Chen & Gu (2018) and introduce an additional hyperparameter p, which controls the extent of adaptivity in the optimiser: for p = { 1 2 , 0}, we have fully adaptive Gadam/SWA (Izmailov et al., 2018) or ASGD (Merity et al., 2017) respectively."@en ;
    askg-onto:inSentence "We follow Chen & Gu (2018) and introduce an additional hyperparameter p, which controls the extent of adaptivity in the optimiser: for p = { 1 2 , 0}, we have fully adaptive Gadam/SWA (Izmailov et al., 2018) or ASGD (Merity et al., 2017) respectively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asgd,
        askg-data:Entity-chen__gu_2018,
        askg-data:Entity-extent_of_adaptivity,
        askg-data:Entity-gadamswa,
        askg-data:Entity-izmailov_et_al_2018,
        askg-data:Entity-merity_et_al_2017 .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While adapting p may be desirable, for simplicity we follow the original authors suggestion and fix p to be 18 ."@en ;
    askg-onto:inSentence "While adapting p may be desirable, for simplicity we follow the original authors suggestion and fix p to be 18 ."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-18,
        askg-data:Entity-p .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-1014-Sentence-10144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We additionally implement decoupled weight decay in GadamX."@en ;
    askg-onto:inSentence "We additionally implement decoupled weight decay in GadamX."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decoupled_weight_decay,
        askg-data:Entity-gadamx .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Indeed, we argue that there are even cases for adaptive optimisers. As argued in Section 2.1, for the slower, linear convergence of IA to not impact efficiency of optimisation, it is critical for the optimiser to converge close to optima before averaging, and for this purpose adaptive optimisers are arguably faster (under some mild assumptions, we actually theoretically show that under some circumstances, averaging Adam iterates leads to a *better* bound of expected loss than SGD. See Appendix A.5). Furthermore, it has been claimed that adaptive optimisers are less sensitive to the need for learning rate schedules (Kingma & Ba, 2014), this would potentially allow us to run IA with a constant learning rate. The schedule and terminal learning rate at which averaging should be employed is often left as a free hyperparameter in prior literature (Izmailov et al., 2018)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1021,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1022,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1023,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1024,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1025 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Indeed, we argue that there are even cases for adaptive optimisers."@en ;
    askg-onto:inSentence "Indeed, we argue that there are even cases for adaptive optimisers."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-cases .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As argued in Section 2.1, for the slower, linear convergence of IA to not impact efficiency of optimisation, it is critical for the optimiser to converge close to optima before averaging, and for this purpose adaptive optimisers are arguably faster (under some mild assumptions, we actually theoretically show that under some circumstances, averaging Adam iterates leads to a *better* bound of expected loss than SGD."@en ;
    askg-onto:inSentence "As argued in Section 2.1, for the slower, linear convergence of IA to not impact efficiency of optimisation, it is critical for the optimiser to converge close to optima before averaging, and for this purpose adaptive optimisers are arguably faster (under some mild assumptions, we actually theoretically show that under some circumstances, averaging Adam iterates leads to a *better* bound of expected loss than SGD."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-averaging_adam_iterates,
        askg-data:Entity-better_bound_of_expected_loss,
        askg-data:Entity-faster,
        askg-data:Entity-ia,
        askg-data:Entity-optima,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "See Appendix A.5)."@en ;
    askg-onto:inSentence "See Appendix A.5)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appendix_a5,
        askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Furthermore, it has been claimed that adaptive optimisers are less sensitive to the need for learning rate schedules (Kingma & Ba, 2014), this would potentially allow us to run IA with a constant learning rate."@en ;
    askg-onto:inSentence "Furthermore, it has been claimed that adaptive optimisers are less sensitive to the need for learning rate schedules (Kingma & Ba, 2014), this would potentially allow us to run IA with a constant learning rate."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-a_constant_learning_rate,
        askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-ia,
        askg-data:Entity-kingma__ba,
        askg-data:Entity-learning_rate_schedules .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-102-Sentence-1025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The schedule and terminal learning rate at which averaging should be employed is often left as a free hyperparameter in prior literature (Izmailov et al., 2018)."@en ;
    askg-onto:inSentence "The schedule and terminal learning rate at which averaging should be employed is often left as a free hyperparameter in prior literature (Izmailov et al., 2018)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-free_hyperparameter,
        askg-data:Entity-izmailov_et_al_2018,
        askg-data:Entity-prior_literature,
        askg-data:Entity-terminal_learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-103 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Finally, the outperformance of SGD over Adam is often attributed to implicit regularisation present in the former (Zhang et al., 2016), and the regularising effect of IA as we have shown seems to complement this naturally."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-103-Sentence-1031 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-103-Sentence-1031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Finally, the outperformance of SGD over Adam is often attributed to implicit regularisation present in the former (Zhang et al., 2016), and the regularising effect of IA as we have shown seems to complement this naturally."@en ;
    askg-onto:inSentence "Finally, the outperformance of SGD over Adam is often attributed to implicit regularisation present in the former (Zhang et al., 2016), and the regularising effect of IA as we have shown seems to complement this naturally."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-ia,
        askg-data:Entity-regularisation,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-104 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Therefore, it is curious on why combining popular adaptive methods (such as Adam) with IA is not commonly used, despite the desirable theoretical properties of the latter and the fact that authors of Adam even suggest Polyak-style IA as a possible enhancement (Kingma & Ba, 2014). While we believe this can be partly attributed to the fact that IA is often"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-104-Sentence-1041,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-104-Sentence-1042 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-104-Sentence-1041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Therefore, it is curious on why combining popular adaptive methods (such as Adam) with IA is not commonly used, despite the desirable theoretical properties of the latter and the fact that authors of Adam even suggest Polyak-style IA as a possible enhancement (Kingma & Ba, 2014)."@en ;
    askg-onto:inSentence "Therefore, it is curious on why combining popular adaptive methods (such as Adam) with IA is not commonly used, despite the desirable theoretical properties of the latter and the fact that authors of Adam even suggest Polyak-style IA as a possible enhancement (Kingma & Ba, 2014)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-algorithm,
        askg-data:Entity-kingma__ba,
        askg-data:Entity-kingma__ba_2014,
        askg-data:Entity-polyak-style_ia,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-104-Sentence-1042 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While we believe this can be partly attributed to the fact that IA is often"@en ;
    askg-onto:inSentence "While we believe this can be partly attributed to the fact that IA is often"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fact,
        askg-data:Entity-ia .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-105 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "(a) VGG-16 (b) PRN-110 (c) ResNeXt-29 (d) Improvement against P"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-105-Sentence-1051 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-105-Sentence-1051 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) VGG-16 (b) PRN-110 (c) ResNeXt-29 (d) Improvement against P"@en ;
    askg-onto:inSentence "(a) VGG-16 (b) PRN-110 (c) ResNeXt-29 (d) Improvement against P"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_neural_network,
        askg-data:Entity-improvement_against_p,
        askg-data:Entity-prn-110,
        askg-data:Entity-research,
        askg-data:Entity-resnext-29,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-106 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-106-Sentence-1061 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-106-Sentence-1061 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:inSentence "![6_image_0.png](6_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-deep_learning,
        askg-data:Entity-image_recognition,
        askg-data:Entity-machine_learning,
        askg-data:Entity-machine_learning_algorithms,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-pytorch,
        askg-data:Entity-scikit-learn,
        askg-data:Entity-software,
        askg-data:Entity-technology,
        askg-data:Entity-tensorflow .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-107 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Figure 5. Test error on CIFAR-100 (a-c) and test improvement of best IA over its base optimiser against number of parameters (d)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-107-Sentence-1071,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-107-Sentence-1072 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-107-Sentence-1071 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 5."@en ;
    askg-onto:inSentence "Figure 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_5 .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-107-Sentence-1072 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Test error on CIFAR-100 (a-c) and test improvement of best IA over its base optimiser against number of parameters (d)"@en ;
    askg-onto:inSentence "Test error on CIFAR-100 (a-c) and test improvement of best IA over its base optimiser against number of parameters (d)"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-base_optimiser,
        askg-data:Entity-best_ia,
        askg-data:Entity-cifar-100,
        askg-data:Entity-number_of_parameters,
        askg-data:Entity-test_error,
        askg-data:Entity-test_improvement .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-108 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "seen as a theoretical tool that is sometimes labelled as not useful practically (Trivedi & Kondor, 2017) or the common beliefs on the geometry argument discussed previously, we also find naively combining Adam with IA (denoted as Adam-IA hereafter) to be uncompetitive, at least in the vision tasks. With reference to Figure 6, even though the iterates of Adam (solid lines) perform better than SGD (dotted lines) when we start averaging, the improvement from averaging and the final accuracy is much worse in Adam-IA."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-108-Sentence-1081,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-108-Sentence-1082 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-108-Sentence-1081 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "seen as a theoretical tool that is sometimes labelled as not useful practically (Trivedi & Kondor, 2017) or the common beliefs on the geometry argument discussed previously, we also find naively combining Adam with IA (denoted as Adam-IA hereafter) to be uncompetitive, at least in the vision tasks."@en ;
    askg-onto:inSentence "seen as a theoretical tool that is sometimes labelled as not useful practically (Trivedi & Kondor, 2017) or the common beliefs on the geometry argument discussed previously, we also find naively combining Adam with IA (denoted as Adam-IA hereafter) to be uncompetitive, at least in the vision tasks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-adam,
        askg-data:Entity-adam-ia,
        askg-data:Entity-ia,
        askg-data:Entity-trivedi__kondor,
        askg-data:Entity-vision_tasks .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-108-Sentence-1082 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "With reference to Figure 6, even though the iterates of Adam (solid lines) perform better than SGD (dotted lines) when we start averaging, the improvement from averaging and the final accuracy is much worse in Adam-IA."@en ;
    askg-onto:inSentence "With reference to Figure 6, even though the iterates of Adam (solid lines) perform better than SGD (dotted lines) when we start averaging, the improvement from averaging and the final accuracy is much worse in Adam-IA."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-accuracy,
        askg-data:Entity-adam,
        askg-data:Entity-adam-ia,
        askg-data:Entity-averaging,
        askg-data:Entity-much_worse,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-109 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Figure 6. Comparison of validation error and iterate Lâˆž norm of"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-109-Sentence-1091,
        askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-109-Sentence-1092 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-109-Sentence-1091 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 6."@en ;
    askg-onto:inSentence "Figure 6."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_6 .

askg-data:Paper-43d37e59d752bc41-Section-10-Paragraph-109-Sentence-1092 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Comparison of validation error and iterate Lâˆž norm of"@en ;
    askg-onto:inSentence "Comparison of validation error and iterate Lâˆž norm of"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iterate_l_norm,
        askg-data:Entity-validation_error .

askg-data:Paper-43d37e59d752bc41-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "5. Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this section, we test our proposed algorithms in multiple vision and language processing tasks. For robustness we run each experiment 3 times and we report the mean and standard deviation (in brackets in all of the tables). We include all the implementation details in Appendix B. We open-source our code to the community 3"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1112,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1113,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1114 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this section, we test our proposed algorithms in multiple vision and language processing tasks."@en ;
    askg-onto:inSentence "In this section, we test our proposed algorithms in multiple vision and language processing tasks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-vision_and_language_processing_tasks .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For robustness we run each experiment 3 times and we report the mean and standard deviation (in brackets in all of the tables)."@en ;
    askg-onto:inSentence "For robustness we run each experiment 3 times and we report the mean and standard deviation (in brackets in all of the tables)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_times,
        askg-data:Entity-experiment,
        askg-data:Entity-mean,
        askg-data:Entity-standard_deviation .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We include all the implementation details in Appendix B."@en ;
    askg-onto:inSentence "We include all the implementation details in Appendix B."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-implementation_details .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-111-Sentence-1114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We open-source our code to the community 3"@en ;
    askg-onto:inSentence "We open-source our code to the community 3"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-code,
        askg-data:Entity-community .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "7 2See Appendix A.4. 3https://github.com/diegogranziol/Gadam Here apart from SGD, Adam(W), Padam, we sometimes also include Padam with decoupled weight decay, which we term *PadamW* on various architectures (VGG-16, Preactivated ResNet (PRN) and ResNeXt (Simonyan & Zisserman, 2014; He et al., 2016; Xie et al., 2017)) on CIFAR data-sets (Krizhevsky et al., 2009), and show the evolution of test accuracy against number of epochs on CIFAR-100 in Figure 5 and the final value at the end of training in Table 3. The corresponding results on CIFAR-10 are in Appendix C.1. As AdamW always outperform Adam in our experiments, the curves for the latter are omitted. Similarly, we also only show either Padam or PadamW in our figures, whichever performs better in terms of final accuracy. To ensure our baselines are fairly tuned, we also include the results reported in the previous works in Table 8 of Appendix B.2."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1121,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1122,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1123,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1124,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1125,
        askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1126 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "7 2See Appendix A.4."@en ;
    askg-onto:inSentence "7 2See Appendix A.4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7,
        askg-data:Entity-appendix_a4 .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "3https://github.com/diegogranziol/Gadam Here apart from SGD, Adam(W), Padam, we sometimes also include Padam with decoupled weight decay, which we term *PadamW* on various architectures (VGG-16, Preactivated ResNet (PRN) and ResNeXt (Simonyan & Zisserman, 2014; He et al., 2016; Xie et al., 2017)) on CIFAR data-sets (Krizhevsky et al., 2009), and show the evolution of test accuracy against number of epochs on CIFAR-100 in Figure 5 and the final value at the end of training in Table 3."@en ;
    askg-onto:inSentence "3https://github.com/diegogranziol/Gadam Here apart from SGD, Adam(W), Padam, we sometimes also include Padam with decoupled weight decay, which we term *PadamW* on various architectures (VGG-16, Preactivated ResNet (PRN) and ResNeXt (Simonyan & Zisserman, 2014; He et al., 2016; Xie et al., 2017)) on CIFAR data-sets (Krizhevsky et al., 2009), and show the evolution of test accuracy against number of epochs on CIFAR-100 in Figure 5 and the final value at the end of training in Table 3."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-cifar-100,
        askg-data:Entity-cifar_data-sets,
        askg-data:Entity-dataset,
        askg-data:Entity-final_value_at_the_end_of_training,
        askg-data:Entity-neural_network_architecture,
        askg-data:Entity-optimization_algorithm,
        askg-data:Entity-padam,
        askg-data:Entity-padam_with_decoupled_weight_decay,
        askg-data:Entity-padamw,
        askg-data:Entity-preactivated_resnet_prn,
        askg-data:Entity-resnext,
        askg-data:Entity-sgd,
        askg-data:Entity-test_accuracy_evolution,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The corresponding results on CIFAR-10 are in Appendix C.1."@en ;
    askg-onto:inSentence "The corresponding results on CIFAR-10 are in Appendix C.1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As AdamW always outperform Adam in our experiments, the curves for the latter are omitted."@en ;
    askg-onto:inSentence "As AdamW always outperform Adam in our experiments, the curves for the latter are omitted."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-adamw .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Similarly, we also only show either Padam or PadamW in our figures, whichever performs better in terms of final accuracy."@en ;
    askg-onto:inSentence "Similarly, we also only show either Padam or PadamW in our figures, whichever performs better in terms of final accuracy."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_accuracy,
        askg-data:Entity-padam,
        askg-data:Entity-padamw .

askg-data:Paper-43d37e59d752bc41-Section-11-Paragraph-112-Sentence-1126 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "To ensure our baselines are fairly tuned, we also include the results reported in the previous works in Table 8 of Appendix B.2."@en ;
    askg-onto:inSentence "To ensure our baselines are fairly tuned, we also include the results reported in the previous works in Table 8 of Appendix B.2."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-previous_works,
        askg-data:Entity-table_8_of_appendix_b2 .

askg-data:Paper-43d37e59d752bc41-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "5.1. Image Classification On Cifar Data-Sets"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121,
        askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-122,
        askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-123,
        askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-124 ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The results show that optimisers with IA (SWA, Gadam and GadamX) invariably improve over their counterparts without IA, and in all cases GadamX delivers the strongest test performance by a considerable margin over baselines (except for PRN-110, where any difference between SWA and GadamX is not immediately significant, although GadamX does have a smaller standard deviation across different seeds and converge faster). Even without any modification to the adaptivity, it is remarkable that in all cases Gadam outperforms fine-tuned SGD and Padam - this seems to suggest that solutions found by adaptive optimisers are not necessarily inferior in their generalisation capability, in contrast to some common beliefs. Indeed, any generalisation gap seems to be closed by the simply using iterate averaging and an appropriately implemented weight decay."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121-Sentence-1211,
        askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121-Sentence-1212,
        askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121-Sentence-1213 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121-Sentence-1211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The results show that optimisers with IA (SWA, Gadam and GadamX) invariably improve over their counterparts without IA, and in all cases GadamX delivers the strongest test performance by a considerable margin over baselines (except for PRN-110, where any difference between SWA and GadamX is not immediately significant, although GadamX does have a smaller standard deviation across different seeds and converge faster)."@en ;
    askg-onto:inSentence "The results show that optimisers with IA (SWA, Gadam and GadamX) invariably improve over their counterparts without IA, and in all cases GadamX delivers the strongest test performance by a considerable margin over baselines (except for PRN-110, where any difference between SWA and GadamX is not immediately significant, although GadamX does have a smaller standard deviation across different seeds and converge faster)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-counterparts_without_ia,
        askg-data:Entity-faster,
        askg-data:Entity-gadamx,
        askg-data:Entity-optimisers_with_ia,
        askg-data:Entity-smaller_standard_deviation,
        askg-data:Entity-strongest_test_performance,
        askg-data:Entity-swa .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121-Sentence-1212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Even without any modification to the adaptivity, it is remarkable that in all cases Gadam outperforms fine-tuned SGD and Padam - this seems to suggest that solutions found by adaptive optimisers are not necessarily inferior in their generalisation capability, in contrast to some common beliefs."@en ;
    askg-onto:inSentence "Even without any modification to the adaptivity, it is remarkable that in all cases Gadam outperforms fine-tuned SGD and Padam - this seems to suggest that solutions found by adaptive optimisers are not necessarily inferior in their generalisation capability, in contrast to some common beliefs."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-fine-tuned_sgd,
        askg-data:Entity-gadam,
        askg-data:Entity-padam,
        askg-data:Entity-solutions .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-121-Sentence-1213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Indeed, any generalisation gap seems to be closed by the simply using iterate averaging and an appropriately implemented weight decay."@en ;
    askg-onto:inSentence "Indeed, any generalisation gap seems to be closed by the simply using iterate averaging and an appropriately implemented weight decay."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalisation_gap,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-method,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-122 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-122-Sentence-1221 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-122-Sentence-1221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:inSentence "![7_image_0.png](7_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-disease_diagnosis,
        askg-data:Entity-healthcare,
        askg-data:Entity-machine_learning,
        askg-data:Entity-metrics,
        askg-data:Entity-patient_outcomes,
        askg-data:Entity-research_area,
        askg-data:Entity-researchers,
        askg-data:Entity-statistical_methods,
        askg-data:Entity-studies .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-123 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 7. Top-5 Test Error on ImageNet 32Ã—32"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-123-Sentence-1231,
        askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-123-Sentence-1232 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-123-Sentence-1231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 7."@en ;
    askg-onto:inSentence "Figure 7."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_7 .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-123-Sentence-1232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Top-5 Test Error on ImageNet 32Ã—32"@en ;
    askg-onto:inSentence "Top-5 Test Error on ImageNet 32Ã—32"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-imagenet_3232,
        askg-data:Entity-top-5_test_error .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-124 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "8"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-124-Sentence-1241 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-12-Paragraph-124-Sentence-1241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "8"@en ;
    askg-onto:inSentence "8"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8,
        askg-data:Entity-number .

askg-data:Paper-43d37e59d752bc41-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "5.2. Image Classification On Imagenet 32Ã—32"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-134,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-135,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-136,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-137,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-138 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We conduct experiments on the ImageNet dataset with the resolution of each picture down-sampled to 32Ã—32 (Chrabaszcz et al., 2017) and results are shown in Figure 7. Similar to the CIFAR results, our proposed algorithms perform competitively. In PRN-110, again we see similar behaviour compared to the CIFAR experiments that IA only leads to modest improvements in test performance, which"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131-Sentence-1312,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131-Sentence-1313 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We conduct experiments on the ImageNet dataset with the resolution of each picture down-sampled to 32Ã—32 (Chrabaszcz et al., 2017) and results are shown in Figure 7."@en ;
    askg-onto:inSentence "We conduct experiments on the ImageNet dataset with the resolution of each picture down-sampled to 32Ã—32 (Chrabaszcz et al., 2017) and results are shown in Figure 7."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-figure_7,
        askg-data:Entity-imagenet_dataset,
        askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Similar to the CIFAR results, our proposed algorithms perform competitively."@en ;
    askg-onto:inSentence "Similar to the CIFAR results, our proposed algorithms perform competitively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-competitively .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-131-Sentence-1313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In PRN-110, again we see similar behaviour compared to the CIFAR experiments that IA only leads to modest improvements in test performance, which"@en ;
    askg-onto:inSentence "In PRN-110, again we see similar behaviour compared to the CIFAR experiments that IA only leads to modest improvements in test performance, which"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar_experiments,
        askg-data:Entity-ia,
        askg-data:Entity-modest_improvements_in_test_performance,
        askg-data:Entity-prn-110 .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "| Table 3. Top\\-1 Test Accuracy on CIFAR\\-100 Data\\-set. | | | |----------------------------------------------------------|-----------|---------------| | ARCHITECTURE | OPTIMISER | TEST ACCURACY | | VGG\\-16 | SGD | 74.15Â±0.06 | | | SWA | 74.57Â±0.27 | | | ADAM(W) | 73.26Â±0.30 | | | PADAM(W) | 74.56Â±0.19 | | | GADAM | 75.73Â±0.29 | | | GADAMX | 76.85Â±0.08 | | PRN\\-110 | SGD | 77.22Â±0.05 | | | SWA | 77.92Â±0.36 | | | ADAM(W) | 75.47Â±0.21 | | | PADAM(W) | 77.30Â±0.11 | | | GADAM | 77.37Â±0.09 | | | GADAMX | 77.90Â±0.21 | | RESNEXT\\-29 | SGD | 81.47Â±0.17 | | | SWA | 82.95Â±0.28 | | | ADAM(W) | 80.16Â±0.16 | | | PADAM(W) | 82.37Â±0.35 | | | GADAM | 82.13Â±0.20 | | | GADAMX | 83.27Â±0.11 |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132-Sentence-1321,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132-Sentence-1322,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132-Sentence-1323 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132-Sentence-1321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Table 3."@en ;
    askg-onto:inSentence "| Table 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132-Sentence-1322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Top\\-1 Test Accuracy on CIFAR\\-100 Data\\-set."@en ;
    askg-onto:inSentence "Top\\-1 Test Accuracy on CIFAR\\-100 Data\\-set."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100_dataset,
        askg-data:Entity-top-1_test_accuracy .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-132-Sentence-1323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "| | | |----------------------------------------------------------|-----------|---------------| | ARCHITECTURE | OPTIMISER | TEST ACCURACY | | VGG\\-16 | SGD | 74.15Â±0.06 | | | SWA | 74.57Â±0.27 | | | ADAM(W) | 73.26Â±0.30 | | | PADAM(W) | 74.56Â±0.19 | | | GADAM | 75.73Â±0.29 | | | GADAMX | 76.85Â±0.08 | | PRN\\-110 | SGD | 77.22Â±0.05 | | | SWA | 77.92Â±0.36 | | | ADAM(W) | 75.47Â±0.21 | | | PADAM(W) | 77.30Â±0.11 | | | GADAM | 77.37Â±0.09 | | | GADAMX | 77.90Â±0.21 | | RESNEXT\\-29 | SGD | 81.47Â±0.17 | | | SWA | 82.95Â±0.28 | | | ADAM(W) | 80.16Â±0.16 | | | PADAM(W) | 82.37Â±0.35 | | | GADAM | 82.13Â±0.20 | | | GADAMX | 83.27Â±0.11 |"@en ;
    askg-onto:inSentence "| | | |----------------------------------------------------------|-----------|---------------| | ARCHITECTURE | OPTIMISER | TEST ACCURACY | | VGG\\-16 | SGD | 74.15Â±0.06 | | | SWA | 74.57Â±0.27 | | | ADAM(W) | 73.26Â±0.30 | | | PADAM(W) | 74.56Â±0.19 | | | GADAM | 75.73Â±0.29 | | | GADAMX | 76.85Â±0.08 | | PRN\\-110 | SGD | 77.22Â±0.05 | | | SWA | 77.92Â±0.36 | | | ADAM(W) | 75.47Â±0.21 | | | PADAM(W) | 77.30Â±0.11 | | | GADAM | 77.37Â±0.09 | | | GADAMX | 77.90Â±0.21 | | RESNEXT\\-29 | SGD | 81.47Â±0.17 | | | SWA | 82.95Â±0.28 | | | ADAM(W) | 80.16Â±0.16 | | | PADAM(W) | 82.37Â±0.35 | | | GADAM | 82.13Â±0.20 | | | GADAMX | 83.27Â±0.11 |"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7326030,
        askg-data:Entity-7415006,
        askg-data:Entity-7456019,
        askg-data:Entity-7457027,
        askg-data:Entity-7547021,
        askg-data:Entity-7573029,
        askg-data:Entity-7685008,
        askg-data:Entity-7722005,
        askg-data:Entity-7730011,
        askg-data:Entity-7737009,
        askg-data:Entity-7790021,
        askg-data:Entity-7792036,
        askg-data:Entity-8016016,
        askg-data:Entity-8147017,
        askg-data:Entity-8213020,
        askg-data:Entity-8237035,
        askg-data:Entity-8295028,
        askg-data:Entity-8327011,
        askg-data:Entity-adamw,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-padamw,
        askg-data:Entity-prn-110,
        askg-data:Entity-resnext-29,
        askg-data:Entity-sgd,
        askg-data:Entity-swa,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "is really unsurprising, considering that this architecture has smallest extent of over-parameterisation if we use number of parameters P as a crude estimate of the model complexity (actually in ImageNet experiments, we almost have P = N, which might also explain the out-performance of Adambased over SGD-based optimisers, as overfitting and the resultant need for regularisation might be less important in this context). On the other hand, in WideResNet (WRN) (Zagoruyko & Komodakis, 2016) experiments, Gadam does not outperform our very strongly performing SGD4 perhaps due the default learning rate in AdamW/Gadam we use. Despite that, Gadam greatly improves upon AdamW, and already posts a performance stronger than baseline in literature with identical (Chrabaszcz et al., 2017) and improved (McDonnell, 2018) setups. On the other hand, GadamX performs very strongly, posting an out-performance of more than 3% compared to the baseline in Chrabaszcz et al. (2017) in Top-5 accuracy. In line with our noisy quadratic model and the results from Theorem 1, we observe a near linear relation between P and benefit of IA measured in terms of test improvement compared to the SGD baseline, shown in Figure 5d. Whilst we acknowledge that the variety in optimal hyper-parameter setup between the best runs may be significant and probably more data points are needed to conclusively and rigorously establish the linear relation, it is at least encouraging to see some agreement with our simplistic model in real networks. We also find that a similar pattern also holds in previous work (Izmailov et al., 2018) despite of using different architectures compared to ours (Appendix C.3)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1331,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1332,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1333,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1334,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1335,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1336,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1337,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1338 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "is really unsurprising, considering that this architecture has smallest extent of over-parameterisation if we use number of parameters P as a crude estimate of the model complexity (actually in ImageNet experiments, we almost have P = N, which might also explain the out-performance of Adambased over SGD-based optimisers, as overfitting and the resultant need for regularisation might be less important in this context)."@en ;
    askg-onto:inSentence "is really unsurprising, considering that this architecture has smallest extent of over-parameterisation if we use number of parameters P as a crude estimate of the model complexity (actually in ImageNet experiments, we almost have P = N, which might also explain the out-performance of Adambased over SGD-based optimisers, as overfitting and the resultant need for regularisation might be less important in this context)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adambased,
        askg-data:Entity-imagenet_experiments,
        askg-data:Entity-model_complexity,
        askg-data:Entity-number_of_parameters_p,
        askg-data:Entity-p__n,
        askg-data:Entity-sgd-based_optimisers .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "On the other hand, in WideResNet (WRN) (Zagoruyko & Komodakis, 2016) experiments, Gadam does not outperform our very strongly performing SGD4 perhaps due the default learning rate in AdamW/Gadam we use."@en ;
    askg-onto:inSentence "On the other hand, in WideResNet (WRN) (Zagoruyko & Komodakis, 2016) experiments, Gadam does not outperform our very strongly performing SGD4 perhaps due the default learning rate in AdamW/Gadam we use."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-algorithm,
        askg-data:Entity-gadam,
        askg-data:Entity-model,
        askg-data:Entity-sgd4,
        askg-data:Entity-wideresnet_wrn .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Despite that, Gadam greatly improves upon AdamW, and already posts a performance stronger than baseline in literature with identical (Chrabaszcz et al., 2017) and improved (McDonnell, 2018) setups."@en ;
    askg-onto:inSentence "Despite that, Gadam greatly improves upon AdamW, and already posts a performance stronger than baseline in literature with identical (Chrabaszcz et al., 2017) and improved (McDonnell, 2018) setups."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-baseline,
        askg-data:Entity-chrabaszcz_et_al,
        askg-data:Entity-gadam,
        askg-data:Entity-literature,
        askg-data:Entity-mcdonnell,
        askg-data:Entity-setup .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1334 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "On the other hand, GadamX performs very strongly, posting an out-performance of more than 3% compared to the baseline in Chrabaszcz et al."@en ;
    askg-onto:inSentence "On the other hand, GadamX performs very strongly, posting an out-performance of more than 3% compared to the baseline in Chrabaszcz et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chrabaszcz_et_al,
        askg-data:Entity-gadamx,
        askg-data:Entity-out-performance .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1335 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2017) in Top-5 accuracy."@en ;
    askg-onto:inSentence "(2017) in Top-5 accuracy."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-top-5_accuracy .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1336 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In line with our noisy quadratic model and the results from Theorem 1, we observe a near linear relation between P and benefit of IA measured in terms of test improvement compared to the SGD baseline, shown in Figure 5d."@en ;
    askg-onto:inSentence "In line with our noisy quadratic model and the results from Theorem 1, we observe a near linear relation between P and benefit of IA measured in terms of test improvement compared to the SGD baseline, shown in Figure 5d."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-benefit_of_ia,
        askg-data:Entity-near_linear_relation,
        askg-data:Entity-noisy_quadratic_model,
        askg-data:Entity-sgd_baseline,
        askg-data:Entity-test_improvement .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1337 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Whilst we acknowledge that the variety in optimal hyper-parameter setup between the best runs may be significant and probably more data points are needed to conclusively and rigorously establish the linear relation, it is at least encouraging to see some agreement with our simplistic model in real networks."@en ;
    askg-onto:inSentence "Whilst we acknowledge that the variety in optimal hyper-parameter setup between the best runs may be significant and probably more data points are needed to conclusively and rigorously establish the linear relation, it is at least encouraging to see some agreement with our simplistic model in real networks."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-domain,
        askg-data:Entity-hyper-parameter_setup,
        askg-data:Entity-model,
        askg-data:Entity-real_networks .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-133-Sentence-1338 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We also find that a similar pattern also holds in previous work (Izmailov et al., 2018) despite of using different architectures compared to ours (Appendix C.3)."@en ;
    askg-onto:inSentence "We also find that a similar pattern also holds in previous work (Izmailov et al., 2018) despite of using different architectures compared to ours (Appendix C.3)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-izmailov_et_al .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-134 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "4The SGD baseline we report is much stronger (2% higher) than literature. See Appendix B.4 for details."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-134-Sentence-1341,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-134-Sentence-1342 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-134-Sentence-1341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4The SGD baseline we report is much stronger (2% higher) than literature."@en ;
    askg-onto:inSentence "4The SGD baseline we report is much stronger (2% higher) than literature."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-literature,
        askg-data:Entity-sgd_baseline .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-134-Sentence-1342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "See Appendix B.4 for details."@en ;
    askg-onto:inSentence "See Appendix B.4 for details."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-details .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-135 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "| ARCHITECTURE | OPTIMISER | TEST ACCURACY | | |----------------|-------------|-----------------|------------| | | | TOP\\-1 | TOP\\-5 | | PRN\\-110 | SGD | 54.27Â±0.36 | 77.96Â±0.08 | | | SWA | 54.37Â±0.18 | 78.04Â±0.14 | | | ADAMW | 54.84Â±0.20 | 78.43Â±0.11 | | | PADAM | 53.71Â±0.15 | 77.31Â±0.09 | | | GADAM | 54.97Â±0.12 | 78.48Â±0.02 | | | GADAMX | 54.45Â±0.49 | 77.91Â±0.27 | | WRN\\-28\\-10 | SGD | 61.33Â±0.11 | 83.52Â±0.14 | | | SWA | 62.32Â±0.13 | 84.23Â±0.05 | | | ADAMW | 55.51Â±0.19 | 79.09Â±0.33 | | | PADAM | 59.65Â±0.17 | 81.74Â±0.16 | | | GADAM | 60.50Â±0.19 | 82.56Â±0.13 | | | GADAMX | 63.04Â±0.06 | 84.75Â±0.03 |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-135-Sentence-1351 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-135-Sentence-1351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| ARCHITECTURE | OPTIMISER | TEST ACCURACY | | |----------------|-------------|-----------------|------------| | | | TOP\\-1 | TOP\\-5 | | PRN\\-110 | SGD | 54.27Â±0.36 | 77.96Â±0.08 | | | SWA | 54.37Â±0.18 | 78.04Â±0.14 | | | ADAMW | 54.84Â±0.20 | 78.43Â±0.11 | | | PADAM | 53.71Â±0.15 | 77.31Â±0.09 | | | GADAM | 54.97Â±0.12 | 78.48Â±0.02 | | | GADAMX | 54.45Â±0.49 | 77.91Â±0.27 | | WRN\\-28\\-10 | SGD | 61.33Â±0.11 | 83.52Â±0.14 | | | SWA | 62.32Â±0.13 | 84.23Â±0.05 | | | ADAMW | 55.51Â±0.19 | 79.09Â±0.33 | | | PADAM | 59.65Â±0.17 | 81.74Â±0.16 | | | GADAM | 60.50Â±0.19 | 82.56Â±0.13 | | | GADAMX | 63.04Â±0.06 | 84.75Â±0.03 |"@en ;
    askg-onto:inSentence "| ARCHITECTURE | OPTIMISER | TEST ACCURACY | | |----------------|-------------|-----------------|------------| | | | TOP\\-1 | TOP\\-5 | | PRN\\-110 | SGD | 54.27Â±0.36 | 77.96Â±0.08 | | | SWA | 54.37Â±0.18 | 78.04Â±0.14 | | | ADAMW | 54.84Â±0.20 | 78.43Â±0.11 | | | PADAM | 53.71Â±0.15 | 77.31Â±0.09 | | | GADAM | 54.97Â±0.12 | 78.48Â±0.02 | | | GADAMX | 54.45Â±0.49 | 77.91Â±0.27 | | WRN\\-28\\-10 | SGD | 61.33Â±0.11 | 83.52Â±0.14 | | | SWA | 62.32Â±0.13 | 84.23Â±0.05 | | | ADAMW | 55.51Â±0.19 | 79.09Â±0.33 | | | PADAM | 59.65Â±0.17 | 81.74Â±0.16 | | | GADAM | 60.50Â±0.19 | 82.56Â±0.13 | | | GADAMX | 63.04Â±0.06 | 84.75Â±0.03 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5371015,
        askg-data:Entity-5427036,
        askg-data:Entity-5437018,
        askg-data:Entity-5445049,
        askg-data:Entity-5484020,
        askg-data:Entity-5497012,
        askg-data:Entity-5551019,
        askg-data:Entity-5965017,
        askg-data:Entity-6050019,
        askg-data:Entity-6133011,
        askg-data:Entity-6232013,
        askg-data:Entity-6304006,
        askg-data:Entity-7731009,
        askg-data:Entity-7791027,
        askg-data:Entity-7796008,
        askg-data:Entity-7804014,
        askg-data:Entity-7843011,
        askg-data:Entity-7848002,
        askg-data:Entity-7909033,
        askg-data:Entity-8174016,
        askg-data:Entity-8256013,
        askg-data:Entity-8352014,
        askg-data:Entity-8423005,
        askg-data:Entity-8475003,
        askg-data:Entity-adamw,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-padam,
        askg-data:Entity-prn-110,
        askg-data:Entity-sgd,
        askg-data:Entity-swa,
        askg-data:Entity-wrn-28-10 .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-136 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Table 4. Test Accuracy on ImageNet 32Ã—32 Data-set."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-136-Sentence-1361,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-136-Sentence-1362 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-136-Sentence-1361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 4."@en ;
    askg-onto:inSentence "Table 4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_4,
        askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-136-Sentence-1362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Test Accuracy on ImageNet 32Ã—32 Data-set."@en ;
    askg-onto:inSentence "Test Accuracy on ImageNet 32Ã—32 Data-set."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-imagenet_3232_data-set,
        askg-data:Entity-test_accuracy .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-137 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "| DATA\\-SET | OPTIMISER | PERPLEXITY | | |-------------|-------------|--------------|------------| | | | VALIDATION | TEST | | PTB | ASGD | 64.88Â±0.07 | 61.98Â±0.19 | | | ADAM | 65.96Â±0.08 | 63.16Â±0.24 | | | PADAM | 65.69Â±0.07 | 62.15Â±0.12 | | | GADAM | 61.35Â±0.05 | 58.77Â±0.08 | | | GADAMX | 63.49Â±0.19 | 60.45Â±0.04 |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-137-Sentence-1371 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-137-Sentence-1371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| DATA\\-SET | OPTIMISER | PERPLEXITY | | |-------------|-------------|--------------|------------| | | | VALIDATION | TEST | | PTB | ASGD | 64.88Â±0.07 | 61.98Â±0.19 | | | ADAM | 65.96Â±0.08 | 63.16Â±0.24 | | | PADAM | 65.69Â±0.07 | 62.15Â±0.12 | | | GADAM | 61.35Â±0.05 | 58.77Â±0.08 | | | GADAMX | 63.49Â±0.19 | 60.45Â±0.04 |"@en ;
    askg-onto:inSentence "| DATA\\-SET | OPTIMISER | PERPLEXITY | | |-------------|-------------|--------------|------------| | | | VALIDATION | TEST | | PTB | ASGD | 64.88Â±0.07 | 61.98Â±0.19 | | | ADAM | 65.96Â±0.08 | 63.16Â±0.24 | | | PADAM | 65.69Â±0.07 | 62.15Â±0.12 | | | GADAM | 61.35Â±0.05 | 58.77Â±0.08 | | | GADAMX | 63.49Â±0.19 | 60.45Â±0.04 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-asgd,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-padam,
        askg-data:Entity-ptb .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-138 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Table 5. Validation and Test Perplexity on Word-level Language Modelling."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-138-Sentence-1381,
        askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-138-Sentence-1382 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-138-Sentence-1381 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 5."@en ;
    askg-onto:inSentence "Table 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_5,
        askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-13-Paragraph-138-Sentence-1382 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Validation and Test Perplexity on Word-level Language Modelling."@en ;
    askg-onto:inSentence "Validation and Test Perplexity on Word-level Language Modelling."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-validation_and_test_perplexity,
        askg-data:Entity-word-level_language_modelling .

askg-data:Paper-43d37e59d752bc41-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "5.3. Word-Level Language Modelling On Ptb"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-142,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-143,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-144 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Lastly, we also run word-level language modelling using a 3-layer Long-short Term Memory (LSTM) model (Gers et al., 1999) on the Penn Treebank (PTB) data-set (Marcus et al., 1993) and we present the results in Table 5 and Figure 8. Remarkably, Gadam even achieves an better result than the baseline NT-ASGD in Merity et al. (2017), although the latter runs an additional 300 epochs on an identical network (Appendix B.4). Note that since, by default, the ASGD uses a constant learning rate, we do not schedule the learning rate except Padam which requires scheduling to converge. Also, for consistency, we use a manual trigger to start averaging at the 100th epoch for ASGD (which actually outperforms the NT-ASGD variant). We additionally conduct experiments with scheduling and NT-ASGD (Appendix C)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1411,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1412,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1413,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1414,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1415,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1416 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Lastly, we also run word-level language modelling using a 3-layer Long-short Term Memory (LSTM) model (Gers et al., 1999) on the Penn Treebank (PTB) data-set (Marcus et al., 1993) and we present the results in Table 5 and Figure 8."@en ;
    askg-onto:inSentence "Lastly, we also run word-level language modelling using a 3-layer Long-short Term Memory (LSTM) model (Gers et al., 1999) on the Penn Treebank (PTB) data-set (Marcus et al., 1993) and we present the results in Table 5 and Figure 8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3-layer_long-short_term_memory_lstm_model,
        askg-data:Entity-marcus_et_al_1993,
        askg-data:Entity-penn_treebank_ptb_data-set,
        askg-data:Entity-word-level_language_modelling .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Remarkably, Gadam even achieves an better result than the baseline NT-ASGD in Merity et al."@en ;
    askg-onto:inSentence "Remarkably, Gadam even achieves an better result than the baseline NT-ASGD in Merity et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-merity_et_al,
        askg-data:Entity-nt-asgd,
        askg-data:Entity-result .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2017), although the latter runs an additional 300 epochs on an identical network (Appendix B.4)."@en ;
    askg-onto:inSentence "(2017), although the latter runs an additional 300 epochs on an identical network (Appendix B.4)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-300_epochs,
        askg-data:Entity-network .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Note that since, by default, the ASGD uses a constant learning rate, we do not schedule the learning rate except Padam which requires scheduling to converge."@en ;
    askg-onto:inSentence "Note that since, by default, the ASGD uses a constant learning rate, we do not schedule the learning rate except Padam which requires scheduling to converge."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asgd,
        askg-data:Entity-constant_learning_rate,
        askg-data:Entity-padam,
        askg-data:Entity-scheduling .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Also, for consistency, we use a manual trigger to start averaging at the 100th epoch for ASGD (which actually outperforms the NT-ASGD variant)."@en ;
    askg-onto:inSentence "Also, for consistency, we use a manual trigger to start averaging at the 100th epoch for ASGD (which actually outperforms the NT-ASGD variant)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asgd,
        askg-data:Entity-nt-asgd .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-141-Sentence-1416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We additionally conduct experiments with scheduling and NT-ASGD (Appendix C)."@en ;
    askg-onto:inSentence "We additionally conduct experiments with scheduling and NT-ASGD (Appendix C)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nt-asgd,
        askg-data:Entity-scheduling .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-142 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Figure 8. Validation perplexity of 3-layer LSTM on PTB word-"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-142-Sentence-1421,
        askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-142-Sentence-1422 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-142-Sentence-1421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 8."@en ;
    askg-onto:inSentence "Figure 8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-figure_8 .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-142-Sentence-1422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Validation perplexity of 3-layer LSTM on PTB word-"@en ;
    askg-onto:inSentence "Validation perplexity of 3-layer LSTM on PTB word-"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3-layer_lstm,
        askg-data:Entity-ptb_word .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-143 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![8_image_0.png](8_image_0.png) level modelling against the number of epochs."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-143-Sentence-1431 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-143-Sentence-1431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![8_image_0.png](8_image_0.png) level modelling against the number of epochs."@en ;
    askg-onto:inSentence "![8_image_0.png](8_image_0.png) level modelling against the number of epochs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-level_modelling,
        askg-data:Entity-number_of_epochs .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-144 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "9"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-144-Sentence-1441 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-14-Paragraph-144-Sentence-1441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "9"@en ;
    askg-onto:inSentence "9"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-9,
        askg-data:Entity-none .

askg-data:Paper-43d37e59d752bc41-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "6. Conclusion And Discussion"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-152 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this paper, we analyse the mechanisms of IA in deep learning. We show that, for high-dimensional noisy problems, we expect IA to be superior to taking the final or the EMA point. We show that IA works as a combined noise reduction and implicit learning rate decay mechanism and hence to some extent alleviates the need to use learning rate schedules. We also find that at least in the frameworks we consider, the traditional measures of sharpness are not necessarily strong predictors of generalisation performance. Inspired by our theoretical results, we propose **Gadam** (and its partially adaptive variant **GadamX**), an adaptive optimiser incorporating IA that is shown to perform well across a range of computer vision and language tasks. Despite the previous publication of results on the noise reduction effect of Iterate Averaging, along with its stability and robustness to choice of learning rate (schedules) (Kushner & Yin, 2003; Bottou, 2012) the use of iterate averaging, has often been dismissed as ineffective for deep learning (Trivedi & Kondor, 2017; Martens, 2014; Defazio & Bottou, 2019). Perhaps this is due to being confounded or used in association with other variance reduction techniques which average the gradients and affect the optimization trajectory, often giving poor results or diverging (Defazio & Bottou, 2019) or implementation details such as averaging over the batch-normalization statistics, instead of recomputing them over the IA point, which has been shown to drastically alter the results (Izmailov et al., 2018). Our results suggest that Iterate Averaging near the end of optimization can be very effective and significantly outperform the final iterate."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1511,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1512,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1513,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1514,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1515,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1516,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1517,
        askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1518 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this paper, we analyse the mechanisms of IA in deep learning."@en ;
    askg-onto:inSentence "In this paper, we analyse the mechanisms of IA in deep learning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-ia .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We show that, for high-dimensional noisy problems, we expect IA to be superior to taking the final or the EMA point."@en ;
    askg-onto:inSentence "We show that, for high-dimensional noisy problems, we expect IA to be superior to taking the final or the EMA point."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema_point,
        askg-data:Entity-final_point,
        askg-data:Entity-ia .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We show that IA works as a combined noise reduction and implicit learning rate decay mechanism and hence to some extent alleviates the need to use learning rate schedules."@en ;
    askg-onto:inSentence "We show that IA works as a combined noise reduction and implicit learning rate decay mechanism and hence to some extent alleviates the need to use learning rate schedules."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-combined_noise_reduction_and_implicit_learning_rate_decay_mechanism,
        askg-data:Entity-ia .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We also find that at least in the frameworks we consider, the traditional measures of sharpness are not necessarily strong predictors of generalisation performance."@en ;
    askg-onto:inSentence "We also find that at least in the frameworks we consider, the traditional measures of sharpness are not necessarily strong predictors of generalisation performance."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalisation_performance,
        askg-data:Entity-traditional_measures_of_sharpness .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Inspired by our theoretical results, we propose **Gadam** (and its partially adaptive variant **GadamX**), an adaptive optimiser incorporating IA that is shown to perform well across a range of computer vision and language tasks."@en ;
    askg-onto:inSentence "Inspired by our theoretical results, we propose **Gadam** (and its partially adaptive variant **GadamX**), an adaptive optimiser incorporating IA that is shown to perform well across a range of computer vision and language tasks."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimiser,
        askg-data:Entity-computer_vision_and_language_tasks,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-ia,
        askg-data:Entity-partially_adaptive_variant_of_gadam .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Despite the previous publication of results on the noise reduction effect of Iterate Averaging, along with its stability and robustness to choice of learning rate (schedules) (Kushner & Yin, 2003; Bottou, 2012) the use of iterate averaging, has often been dismissed as ineffective for deep learning (Trivedi & Kondor, 2017; Martens, 2014; Defazio & Bottou, 2019)."@en ;
    askg-onto:inSentence "Despite the previous publication of results on the noise reduction effect of Iterate Averaging, along with its stability and robustness to choice of learning rate (schedules) (Kushner & Yin, 2003; Bottou, 2012) the use of iterate averaging, has often been dismissed as ineffective for deep learning (Trivedi & Kondor, 2017; Martens, 2014; Defazio & Bottou, 2019)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottou_2012,
        askg-data:Entity-defazio__bottou_2019,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-iterate_averaging_as_ineffective_for_deep_learning,
        askg-data:Entity-kushner__yin_2003,
        askg-data:Entity-martens_2014,
        askg-data:Entity-noise_reduction,
        askg-data:Entity-results_on_the_noise_reduction_effect_of_iterate_averaging,
        askg-data:Entity-robustness_to_choice_of_learning_rate_schedules,
        askg-data:Entity-stability,
        askg-data:Entity-trivedi__kondor_2017 .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1517 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Perhaps this is due to being confounded or used in association with other variance reduction techniques which average the gradients and affect the optimization trajectory, often giving poor results or diverging (Defazio & Bottou, 2019) or implementation details such as averaging over the batch-normalization statistics, instead of recomputing them over the IA point, which has been shown to drastically alter the results (Izmailov et al., 2018)."@en ;
    askg-onto:inSentence "Perhaps this is due to being confounded or used in association with other variance reduction techniques which average the gradients and affect the optimization trajectory, often giving poor results or diverging (Defazio & Bottou, 2019) or implementation details such as averaging over the batch-normalization statistics, instead of recomputing them over the IA point, which has been shown to drastically alter the results (Izmailov et al., 2018)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-2019,
        askg-data:Entity-defazio__bottou,
        askg-data:Entity-izmailov_et_al .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-151-Sentence-1518 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Our results suggest that Iterate Averaging near the end of optimization can be very effective and significantly outperform the final iterate."@en ;
    askg-onto:inSentence "Our results suggest that Iterate Averaging near the end of optimization can be very effective and significantly outperform the final iterate."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effective_performance,
        askg-data:Entity-final_iterate,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-optimization .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-152 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Our results also suggest that when correctly implemented Iterate Averaging with adaptive methods can achieve great generalisation performance."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-152-Sentence-1521 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-15-Paragraph-152-Sentence-1521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our results also suggest that when correctly implemented Iterate Averaging with adaptive methods can achieve great generalisation performance."@en ;
    askg-onto:inSentence "Our results also suggest that when correctly implemented Iterate Averaging with adaptive methods can achieve great generalisation performance."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-great_generalisation_performance,
        askg-data:Entity-iterate_averaging .

askg-data:Paper-43d37e59d752bc41-Section-16 a askg-onto:Section ;
    rdfs:label "Section 16"@en ;
    domo:Text "References"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1612,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1623,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1643,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1646,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1650,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1651,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1654,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1656,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1657,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1658,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169 ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Bansal, N., Chen, X., and Wang, Z. Can we gain more from orthogonality regularizations in training deep networks? In *Advances in Neural Information Processing Systems*, pp. 4261â€“4271, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1611,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1612,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1613,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1614 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Bansal, N., Chen, X., and Wang, Z."@en ;
    askg-onto:inSentence "Bansal, N., Chen, X., and Wang, Z."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bansal_n,
        askg-data:Entity-chen_x,
        askg-data:Entity-wang_z .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Can we gain more from orthogonality regularizations in training deep networks?"@en ;
    askg-onto:inSentence "Can we gain more from orthogonality regularizations in training deep networks?"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-orthogonality_regularizations,
        askg-data:Entity-training_deep_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In *Advances in Neural Information Processing Systems*, pp."@en ;
    askg-onto:inSentence "In *Advances in Neural Information Processing Systems*, pp."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-161-Sentence-1614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "4261â€“4271, 2018."@en ;
    askg-onto:inSentence "4261â€“4271, 2018."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-42614271 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Keskar, N. S. and Socher, R. Improving generalization performance by switching from Adam to SGD. arXiv preprint arXiv:1712.07628, 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16101,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16102,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16103,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16104,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16105 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Keskar, N."@en ;
    askg-onto:inSentence "Keskar, N."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-keskar_n .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "S."@en ;
    askg-onto:inSentence "S."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s,
        askg-data:Entity-unknown .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16103 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "and Socher, R."@en ;
    askg-onto:inSentence "and Socher, R."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-socher_r .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16104 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Improving generalization performance by switching from Adam to SGD."@en ;
    askg-onto:inSentence "Improving generalization performance by switching from Adam to SGD."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1610-Sentence-16105 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "arXiv preprint arXiv:1712.07628, 2017."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1712.07628, 2017."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv171207628,
        askg-data:Entity-arxiv_preprint_arxiv171207628,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Duchi, J. C. Introductory lectures on stochastic optimization."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611-Sentence-16111,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611-Sentence-16112,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611-Sentence-16113 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611-Sentence-16111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Duchi, J."@en ;
    askg-onto:inSentence "Duchi, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-duchi_j .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611-Sentence-16112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "C."@en ;
    askg-onto:inSentence "C."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-concept .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1611-Sentence-16113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Introductory lectures on stochastic optimization."@en ;
    askg-onto:inSentence "Introductory lectures on stochastic optimization."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-introductory_lectures,
        askg-data:Entity-stochastic_optimization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1612 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "The Mathematics of Data, 25:99, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1612-Sentence-16121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1612-Sentence-16121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The Mathematics of Data, 25:99, 2018."@en ;
    askg-onto:inSentence "The Mathematics of Data, 25:99, 2018."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mathematics_of_data .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "Keskar, N. S., Mudigere, D., Nocedal, J., Smelyanskiy, M., and Tang, P. T. P. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv preprint arXiv:1609.04836, 2016."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16131,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16132,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16133,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16134,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16135,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16136 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Keskar, N."@en ;
    askg-onto:inSentence "Keskar, N."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-keskar_n .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "S., Mudigere, D., Nocedal, J., Smelyanskiy, M., and Tang, P."@en ;
    askg-onto:inSentence "S., Mudigere, D., Nocedal, J., Smelyanskiy, M., and Tang, P."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-d,
        askg-data:Entity-j,
        askg-data:Entity-m,
        askg-data:Entity-mudigere,
        askg-data:Entity-nocedal,
        askg-data:Entity-p,
        askg-data:Entity-s,
        askg-data:Entity-smelyanskiy,
        askg-data:Entity-tang .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "T."@en ;
    askg-onto:inSentence "T."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-t,
        askg-data:Entity-unknown .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "P."@en ;
    askg-onto:inSentence "P."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-unknown .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "On large-batch training for deep learning: Generalization gap and sharp minima."@en ;
    askg-onto:inSentence "On large-batch training for deep learning: Generalization gap and sharp minima."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-deep_learning,
        askg-data:Entity-generalization_gap,
        askg-data:Entity-large-batch_training,
        askg-data:Entity-sharp_minima .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1613-Sentence-16136 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "arXiv preprint arXiv:1609.04836, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1609.04836, 2016."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-article,
        askg-data:Entity-arxiv160904836,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D. P., and Wilson, A. G. Loss surfaces, mode connectivity, and fast ensembling of dnns. In Advances in Neural Information Processing Systems, pp. 8789â€“8798, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16141,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16142,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16143,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16144,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16145,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16146 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D."@en ;
    askg-onto:inSentence "Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-garipov_t,
        askg-data:Entity-izmailov_p,
        askg-data:Entity-podoprikhin_d,
        askg-data:Entity-vetrov_d .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "P., and Wilson, A."@en ;
    askg-onto:inSentence "P., and Wilson, A."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-wilson_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "G."@en ;
    askg-onto:inSentence "G."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Loss surfaces, mode connectivity, and fast ensembling of dnns."@en ;
    askg-onto:inSentence "Loss surfaces, mode connectivity, and fast ensembling of dnns."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_neural_networks,
        askg-data:Entity-fast_ensembling_of_dnns,
        askg-data:Entity-loss_surfaces,
        askg-data:Entity-mode_connectivity .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16145 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pp."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-pp .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1614-Sentence-16146 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "8789â€“8798, 2018."@en ;
    askg-onto:inSentence "8789â€“8798, 2018."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-87898798 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. *arXiv preprint arXiv:1412.6980*, 2014."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16151,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16152,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16153,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16154,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16155 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Kingma, D."@en ;
    askg-onto:inSentence "Kingma, D."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-kingma_d .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "P."@en ;
    askg-onto:inSentence "P."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-person .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "and Ba, J."@en ;
    askg-onto:inSentence "and Ba, J."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ba_j,
        askg-data:Entity-research_paper .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Adam: A method for stochastic optimization."@en ;
    askg-onto:inSentence "Adam: A method for stochastic optimization."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-stochastic_optimization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1615-Sentence-16155 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "*arXiv preprint arXiv:1412.6980*, 2014."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1412.6980*, 2014."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-arxiv_preprint_arxiv14126980,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "Gers, F. A., Schmidhuber, J., and Cummins, F. Learning to forget: Continual prediction with LSTM. 1999."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16161,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16162,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16163,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16164 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Gers, F."@en ;
    askg-onto:inSentence "Gers, F."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-gers_f .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A., Schmidhuber, J., and Cummins, F."@en ;
    askg-onto:inSentence "A., Schmidhuber, J., and Cummins, F."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-cummins_f,
        askg-data:Entity-schmidhuber_j .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16163 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Learning to forget: Continual prediction with LSTM."@en ;
    askg-onto:inSentence "Learning to forget: Continual prediction with LSTM."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-continual_prediction,
        askg-data:Entity-learning_to_forget,
        askg-data:Entity-lstm,
        askg-data:Entity-technology .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1616-Sentence-16164 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "1999."@en ;
    askg-onto:inSentence "1999."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1999,
        askg-data:Entity-na .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "Krizhevsky, A., Hinton, G., et al. Learning multiple layers of features from tiny images. 2009."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617-Sentence-16171,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617-Sentence-16172,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617-Sentence-16173 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617-Sentence-16171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Krizhevsky, A., Hinton, G., et al."@en ;
    askg-onto:inSentence "Krizhevsky, A., Hinton, G., et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hinton_g,
        askg-data:Entity-krizhevsky_a,
        askg-data:Entity-scientist .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617-Sentence-16172 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Learning multiple layers of features from tiny images."@en ;
    askg-onto:inSentence "Learning multiple layers of features from tiny images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-multiple_layers,
        askg-data:Entity-tiny_images .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1617-Sentence-16173 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "2009."@en ;
    askg-onto:inSentence "2009."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2009,
        askg-data:Entity-na .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "Granziol, D., Wan, X., Garipov, T., Vetrov, D., and Roberts, S. MLRG deep curvature. *arXiv preprint* arXiv:1912.09656, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618-Sentence-16181,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618-Sentence-16182,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618-Sentence-16183 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618-Sentence-16181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Granziol, D., Wan, X., Garipov, T., Vetrov, D., and Roberts, S."@en ;
    askg-onto:inSentence "Granziol, D., Wan, X., Garipov, T., Vetrov, D., and Roberts, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-garipov_t,
        askg-data:Entity-granziol_d,
        askg-data:Entity-roberts_s,
        askg-data:Entity-vetrov_d,
        askg-data:Entity-wan_x .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618-Sentence-16182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "MLRG deep curvature."@en ;
    askg-onto:inSentence "MLRG deep curvature."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-mlrg_deep_curvature .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1618-Sentence-16183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*arXiv preprint* arXiv:1912.09656, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint* arXiv:1912.09656, 2019."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv191209656,
        askg-data:Entity-arxiv_preprint .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "Krogh, A. and Hertz, J. A. A simple weight decay can improve generalization. In Advances in neural information processing systems, pp. 950â€“957, 1992."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16191,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16192,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16193,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16194,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16195,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16196 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Krogh, A."@en ;
    askg-onto:inSentence "Krogh, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-krogh_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Hertz, J."@en ;
    askg-onto:inSentence "and Hertz, J."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hertz_j,
        askg-data:Entity-unspecified_work .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16193 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A."@en ;
    askg-onto:inSentence "A."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-text .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16194 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "A simple weight decay can improve generalization."@en ;
    askg-onto:inSentence "A simple weight decay can improve generalization."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalization,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16195 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In Advances in neural information processing systems, pp."@en ;
    askg-onto:inSentence "In Advances in neural information processing systems, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1619-Sentence-16196 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "950â€“957, 1992."@en ;
    askg-onto:inSentence "950â€“957, 1992."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1992,
        askg-data:Entity-950957 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Bottou, L. *Stochastic Gradient Descent Tricks*, pp. 421â€“ 436. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012. ISBN 978-3-642-35289-8. doi: 10.1007/ 978-3-642-35289-8 25. URL https://doi.org/ 10.1007/978-3-642-35289-8_25."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1621,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1622,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1623,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1624,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1625,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1626,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1627 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Bottou, L."@en ;
    askg-onto:inSentence "Bottou, L."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bottou_l .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "*Stochastic Gradient Descent Tricks*, pp."@en ;
    askg-onto:inSentence "*Stochastic Gradient Descent Tricks*, pp."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-stochastic_gradient_descent_tricks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "421â€“ 436."@en ;
    askg-onto:inSentence "421â€“ 436."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-421436,
        askg-data:Entity-pages .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1624 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Springer Berlin Heidelberg, Berlin, Heidelberg, 2012."@en ;
    askg-onto:inSentence "Springer Berlin Heidelberg, Berlin, Heidelberg, 2012."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2012,
        askg-data:Entity-springer_berlin_heidelberg .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1625 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "ISBN 978-3-642-35289-8."@en ;
    askg-onto:inSentence "ISBN 978-3-642-35289-8."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-identifier,
        askg-data:Entity-isbn_978-3-642-35289-8 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1626 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "doi: 10.1007/ 978-3-642-35289-8 25."@en ;
    askg-onto:inSentence "doi: 10.1007/ 978-3-642-35289-8 25."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-101007978-3-642-35289-8,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-162-Sentence-1627 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "URL https://doi.org/ 10.1007/978-3-642-35289-8_25."@en ;
    askg-onto:inSentence "URL https://doi.org/ 10.1007/978-3-642-35289-8_25."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-101007978-3-642-35289-8_25,
        askg-data:Entity-doi,
        askg-data:Entity-doiorg,
        askg-data:Entity-url .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "Granziol, D., Garipov, T., Vetrov, D., Zohren, S., Roberts, S., and Wilson, A. G. Towards understanding the true loss surface of deep neural networks using random matrix theory and iterative spectral methods, 2020. URL https: //openreview.net/forum?id=H1gza2NtwH."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16201,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16202,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16203,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16204 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Granziol, D., Garipov, T., Vetrov, D., Zohren, S., Roberts, S., and Wilson, A."@en ;
    askg-onto:inSentence "Granziol, D., Garipov, T., Vetrov, D., Zohren, S., Roberts, S., and Wilson, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-garipov_t,
        askg-data:Entity-granziol_d,
        askg-data:Entity-publication,
        askg-data:Entity-roberts_s,
        askg-data:Entity-vetrov_d,
        askg-data:Entity-wilson_a,
        askg-data:Entity-zohren_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16202 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "G."@en ;
    askg-onto:inSentence "G."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-unknown .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16203 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Towards understanding the true loss surface of deep neural networks using random matrix theory and iterative spectral methods, 2020."@en ;
    askg-onto:inSentence "Towards understanding the true loss surface of deep neural networks using random matrix theory and iterative spectral methods, 2020."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_neural_networks,
        askg-data:Entity-iterative_spectral_methods,
        askg-data:Entity-random_matrix_theory,
        askg-data:Entity-true_loss_surface .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1620-Sentence-16204 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "URL https: //openreview.net/forum?id=H1gza2NtwH."@en ;
    askg-onto:inSentence "URL https: //openreview.net/forum?id=H1gza2NtwH."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h1gza2ntwh,
        askg-data:Entity-openreviewnet .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 21"@en ;
    domo:Text "Kushner, H. and Yin, G. G. Stochastic approximation and recursive algorithms and applications, volume 35. Springer Science & Business Media, 2003."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16211,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16212,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16213,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16214,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16215 ;
    askg-onto:index "21"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Kushner, H."@en ;
    askg-onto:inSentence "Kushner, H."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-kushner_h .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Yin, G."@en ;
    askg-onto:inSentence "and Yin, G."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-yin_g .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "G."@en ;
    askg-onto:inSentence "G."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-person .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Stochastic approximation and recursive algorithms and applications, volume 35."@en ;
    askg-onto:inSentence "Stochastic approximation and recursive algorithms and applications, volume 35."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-recursive_algorithms,
        askg-data:Entity-stochastic_approximation,
        askg-data:Entity-stochastic_approximation_and_recursive_algorithms,
        askg-data:Entity-volume_35 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1621-Sentence-16215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Springer Science & Business Media, 2003."@en ;
    askg-onto:inSentence "Springer Science & Business Media, 2003."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2003,
        askg-data:Entity-springer_science__business_media .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 22"@en ;
    domo:Text "He, H., Huang, G., and Yuan, Y. Asymmetric valleys: Beyond sharp and flat local minima. arXiv preprint arXiv:1902.00744, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622-Sentence-16221,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622-Sentence-16222,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622-Sentence-16223 ;
    askg-onto:index "22"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622-Sentence-16221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "He, H., Huang, G., and Yuan, Y."@en ;
    askg-onto:inSentence "He, H., Huang, G., and Yuan, Y."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-he_h,
        askg-data:Entity-huang_g,
        askg-data:Entity-yuan_y .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622-Sentence-16222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Asymmetric valleys: Beyond sharp and flat local minima."@en ;
    askg-onto:inSentence "Asymmetric valleys: Beyond sharp and flat local minima."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asymmetric_valleys,
        askg-data:Entity-sharp_and_flat_local_minima .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1622-Sentence-16223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "arXiv preprint arXiv:1902.00744, 2019."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1902.00744, 2019."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv190200744,
        askg-data:Entity-arxiv_preprint .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1623 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 23"@en ;
    domo:Text "LeCun, Y. The MNIST database of handwritten digits."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1623-Sentence-16231,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1623-Sentence-16232 ;
    askg-onto:index "23"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1623-Sentence-16231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "LeCun, Y."@en ;
    askg-onto:inSentence "LeCun, Y."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lecun_y,
        askg-data:Entity-researcher .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1623-Sentence-16232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The MNIST database of handwritten digits."@en ;
    askg-onto:inSentence "The MNIST database of handwritten digits."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-database,
        askg-data:Entity-mnist_database .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 24"@en ;
    domo:Text "http://yann. lecun. com/exdb/mnist/, 1998."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624-Sentence-16241,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624-Sentence-16242,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624-Sentence-16243 ;
    askg-onto:index "24"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624-Sentence-16241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "http://yann."@en ;
    askg-onto:inSentence "http://yann."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-yann .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624-Sentence-16242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "lecun."@en ;
    askg-onto:inSentence "lecun."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lecun,
        askg-data:Entity-scientist .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1624-Sentence-16243 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "com/exdb/mnist/, 1998."@en ;
    askg-onto:inSentence "com/exdb/mnist/, 1998."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-mnist .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 25"@en ;
    domo:Text "Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T. Visualizing the loss landscape of neural nets. In Advances in Neural Information Processing Systems, pp. 6389â€“6399, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16251,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16252,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16253,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16254 ;
    askg-onto:index "25"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T."@en ;
    askg-onto:inSentence "Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-goldstein_t,
        askg-data:Entity-li_h,
        askg-data:Entity-studer_c,
        askg-data:Entity-taylor_g,
        askg-data:Entity-xu_z .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Visualizing the loss landscape of neural nets."@en ;
    askg-onto:inSentence "Visualizing the loss landscape of neural nets."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-loss_landscape,
        askg-data:Entity-neural_nets .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16253 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pp."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pp."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-pp .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1625-Sentence-16254 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "6389â€“6399, 2018."@en ;
    askg-onto:inSentence "6389â€“6399, 2018."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-63896399 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 26"@en ;
    domo:Text "He, K., Zhang, X., Ren, S., and Sun, J. Identity mappings in deep residual networks. In European conference on computer vision, pp. 630â€“645. Springer, 2016."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16261,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16262,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16263,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16264,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16265 ;
    askg-onto:index "26"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "He, K., Zhang, X., Ren, S., and Sun, J."@en ;
    askg-onto:inSentence "He, K., Zhang, X., Ren, S., and Sun, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-he_k,
        askg-data:Entity-ren_s,
        askg-data:Entity-sun_j,
        askg-data:Entity-zhang_x .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Identity mappings in deep residual networks."@en ;
    askg-onto:inSentence "Identity mappings in deep residual networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_residual_networks,
        askg-data:Entity-identity_mappings .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16263 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In European conference on computer vision, pp."@en ;
    askg-onto:inSentence "In European conference on computer vision, pp."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-european_conference_on_computer_vision,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16264 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "630â€“645."@en ;
    askg-onto:inSentence "630â€“645."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-630645,
        askg-data:Entity-page_numbers .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1626-Sentence-16265 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Springer, 2016."@en ;
    askg-onto:inSentence "Springer, 2016."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-springer .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 27"@en ;
    domo:Text "Hochreiter, S. and Schmidhuber, J. Flat minima. Neural Computation, 9(1):1â€“42, 1997."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16271,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16272,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16273,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16274 ;
    askg-onto:index "27"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Hochreiter, S."@en ;
    askg-onto:inSentence "Hochreiter, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hochreiter_s,
        askg-data:Entity-scientist .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16272 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Schmidhuber, J."@en ;
    askg-onto:inSentence "and Schmidhuber, J."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-schmidhuber_j,
        askg-data:Entity-scientist .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16273 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Flat minima."@en ;
    askg-onto:inSentence "Flat minima."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flat_minima,
        askg-data:Entity-optimization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1627-Sentence-16274 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Neural Computation, 9(1):1â€“42, 1997."@en ;
    askg-onto:inSentence "Neural Computation, 9(1):1â€“42, 1997."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-142,
        askg-data:Entity-1997,
        askg-data:Entity-9,
        askg-data:Entity-neural_computation,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 28"@en ;
    domo:Text "Liu, L., Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Han, J. On the variance of the adaptive learning rate and beyond. *arXiv preprint arXiv:1908.03265*, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628-Sentence-16281,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628-Sentence-16282,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628-Sentence-16283 ;
    askg-onto:index "28"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628-Sentence-16281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Liu, L., Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Han, J."@en ;
    askg-onto:inSentence "Liu, L., Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Han, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-chen_w,
        askg-data:Entity-gao_j,
        askg-data:Entity-han_j,
        askg-data:Entity-he_p,
        askg-data:Entity-jiang_h,
        askg-data:Entity-liu_l,
        askg-data:Entity-liu_x .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628-Sentence-16282 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "On the variance of the adaptive learning rate and beyond."@en ;
    askg-onto:inSentence "On the variance of the adaptive learning rate and beyond."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_learning_rate,
        askg-data:Entity-concept,
        askg-data:Entity-variance .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1628-Sentence-16283 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*arXiv preprint arXiv:1908.03265*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1908.03265*, 2019."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv_preprint_arxiv190803265,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 29"@en ;
    domo:Text "Huang, Z. and Wang, N. Data-driven sparse structure selection for deep neural networks. In Proceedings of the European conference on computer vision (ECCV), pp. 304â€“320, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16291,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16292,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16293,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16294,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16295 ;
    askg-onto:index "29"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16291 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Huang, Z."@en ;
    askg-onto:inSentence "Huang, Z."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-huang_z .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16292 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Wang, N."@en ;
    askg-onto:inSentence "and Wang, N."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-wang_n .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16293 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Data-driven sparse structure selection for deep neural networks."@en ;
    askg-onto:inSentence "Data-driven sparse structure selection for deep neural networks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data-driven_sparse_structure_selection,
        askg-data:Entity-deep_neural_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16294 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Proceedings of the European conference on computer vision (ECCV), pp."@en ;
    askg-onto:inSentence "In Proceedings of the European conference on computer vision (ECCV), pp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1629-Sentence-16295 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "304â€“320, 2018."@en ;
    askg-onto:inSentence "304â€“320, 2018."^^xsd:string ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Chen, J. and Gu, Q. Closing the generalization gap of adaptive gradient methods in training deep neural networks. arXiv preprint arXiv:1806.06763, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1631,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1632,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1633,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1634 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Chen, J."@en ;
    askg-onto:inSentence "Chen, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-chen_j .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Gu, Q."@en ;
    askg-onto:inSentence "and Gu, Q."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gu_q .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Closing the generalization gap of adaptive gradient methods in training deep neural networks."@en ;
    askg-onto:inSentence "Closing the generalization gap of adaptive gradient methods in training deep neural networks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_gradient_methods,
        askg-data:Entity-training_deep_neural_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-163-Sentence-1634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "arXiv preprint arXiv:1806.06763, 2018."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1806.06763, 2018."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv180606763,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 30"@en ;
    domo:Text "Loshchilov, I. and Hutter, F. Decoupled weight decay regularization. 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16301,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16302,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16303,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16304 ;
    askg-onto:index "30"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16301 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Loshchilov, I."@en ;
    askg-onto:inSentence "Loshchilov, I."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-loshchilov_i,
        askg-data:Entity-researcher .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16302 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Hutter, F."@en ;
    askg-onto:inSentence "and Hutter, F."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-hutter_f .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16303 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Decoupled weight decay regularization."@en ;
    askg-onto:inSentence "Decoupled weight decay regularization."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-decoupled_weight_decay_regularization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1630-Sentence-16304 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "2018."@en ;
    askg-onto:inSentence "2018."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-research_activity .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 31"@en ;
    domo:Text "Maddox, W. J., Izmailov, P., Garipov, T., Vetrov, D. P., and Wilson, A. G. A simple baseline for Bayesian uncertainty in deep learning. In Advances in Neural Information Processing Systems, pp. 13132â€“13143, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16311,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16312,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16313,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16314,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16315,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16316,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16317 ;
    askg-onto:index "31"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Maddox, W."@en ;
    askg-onto:inSentence "Maddox, W."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-maddox_w .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "J., Izmailov, P., Garipov, T., Vetrov, D."@en ;
    askg-onto:inSentence "J., Izmailov, P., Garipov, T., Vetrov, D."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-garipov,
        askg-data:Entity-izmailov,
        askg-data:Entity-j,
        askg-data:Entity-publication,
        askg-data:Entity-vetrov .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "P., and Wilson, A."@en ;
    askg-onto:inSentence "P., and Wilson, A."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-wilson_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "G."@en ;
    askg-onto:inSentence "G."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "A simple baseline for Bayesian uncertainty in deep learning."@en ;
    askg-onto:inSentence "A simple baseline for Bayesian uncertainty in deep learning."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bayesian_uncertainty,
        askg-data:Entity-deep_learning .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16316 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pp."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pp."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1631-Sentence-16317 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "13132â€“13143, 2019."@en ;
    askg-onto:inSentence "13132â€“13143, 2019."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1313213143,
        askg-data:Entity-2019 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 32"@en ;
    domo:Text "Ioffe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16321,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16322,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16323,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16324 ;
    askg-onto:index "32"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Ioffe, S."@en ;
    askg-onto:inSentence "Ioffe, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-ioffe_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Szegedy, C."@en ;
    askg-onto:inSentence "and Szegedy, C."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-szegedy_c .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Batch normalization: Accelerating deep network training by reducing internal covariate shift."@en ;
    askg-onto:inSentence "Batch normalization: Accelerating deep network training by reducing internal covariate shift."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-accelerating_deep_network_training,
        askg-data:Entity-batch_normalization,
        askg-data:Entity-internal_covariate_shift .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1632-Sentence-16324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "arXiv preprint arXiv:1502.03167, 2015."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1502.03167, 2015."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2015,
        askg-data:Entity-arxiv150203167,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 33"@en ;
    domo:Text "Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., and Wilson, A. G. Averaging weights leads to wider optima and better generalization. arXiv preprint arXiv:1803.05407, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16331,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16332,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16333,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16334 ;
    askg-onto:index "33"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., and Wilson, A."@en ;
    askg-onto:inSentence "Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., and Wilson, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-garipov_t,
        askg-data:Entity-izmailov_p,
        askg-data:Entity-podoprikhin_d,
        askg-data:Entity-vetrov_d,
        askg-data:Entity-wilson_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "G."@en ;
    askg-onto:inSentence "G."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-person .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Averaging weights leads to wider optima and better generalization."@en ;
    askg-onto:inSentence "Averaging weights leads to wider optima and better generalization."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging_weights,
        askg-data:Entity-better_generalization,
        askg-data:Entity-wider_optima .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1633-Sentence-16334 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "arXiv preprint arXiv:1803.05407, 2018."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1803.05407, 2018."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-article,
        askg-data:Entity-arxiv180305407,
        askg-data:Entity-arxiv_preprint .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 34"@en ;
    domo:Text "Marcus, M., Santorini, B., and Marcinkiewicz, M. A. Building a large annotated corpus of English: The penn treebank. 1993."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16341,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16342,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16343,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16344 ;
    askg-onto:index "34"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Marcus, M., Santorini, B., and Marcinkiewicz, M."@en ;
    askg-onto:inSentence "Marcus, M., Santorini, B., and Marcinkiewicz, M."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-marcinkiewicz_m,
        askg-data:Entity-marcus_m,
        askg-data:Entity-santorini_b .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A."@en ;
    askg-onto:inSentence "A."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-text_to_analyze .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Building a large annotated corpus of English: The penn treebank."@en ;
    askg-onto:inSentence "Building a large annotated corpus of English: The penn treebank."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_large_annotated_corpus_of_english,
        askg-data:Entity-the_penn_treebank .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1634-Sentence-16344 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "1993."@en ;
    askg-onto:inSentence "1993."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1993,
        askg-data:Entity-research_developments .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 35"@en ;
    domo:Text "10 Martens, J. New insights and perspectives on the natural gradient method. *arXiv preprint arXiv:1412.1193*, 2014."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635-Sentence-16351,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635-Sentence-16352,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635-Sentence-16353 ;
    askg-onto:index "35"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635-Sentence-16351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "10 Martens, J."@en ;
    askg-onto:inSentence "10 Martens, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-martens_j .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635-Sentence-16352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "New insights and perspectives on the natural gradient method."@en ;
    askg-onto:inSentence "New insights and perspectives on the natural gradient method."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-natural_gradient_method .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1635-Sentence-16353 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*arXiv preprint arXiv:1412.1193*, 2014."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1412.1193*, 2014."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv14121193,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 36"@en ;
    domo:Text "McDonnell, M. D. Training wide residual networks for deployment using a single bit for each weight. arXiv preprint arXiv:1802.08530, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16361,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16362,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16363,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16364 ;
    askg-onto:index "36"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "McDonnell, M."@en ;
    askg-onto:inSentence "McDonnell, M."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mcdonnell_m,
        askg-data:Entity-research_papers .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "D."@en ;
    askg-onto:inSentence "D."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-device .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16363 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Training wide residual networks for deployment using a single bit for each weight."@en ;
    askg-onto:inSentence "Training wide residual networks for deployment using a single bit for each weight."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deployment,
        askg-data:Entity-single_bit,
        askg-data:Entity-weight,
        askg-data:Entity-wide_residual_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1636-Sentence-16364 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "arXiv preprint arXiv:1802.08530, 2018."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1802.08530, 2018."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-arxiv_preprint_arxiv180208530,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 37"@en ;
    domo:Text "Merity, S., Keskar, N. S., and Socher, R. Regularizing and optimizing LSTM language models. arXiv preprint arXiv:1708.02182, 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16371,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16372,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16373,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16374 ;
    askg-onto:index "37"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Merity, S., Keskar, N."@en ;
    askg-onto:inSentence "Merity, S., Keskar, N."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-keskar_n,
        askg-data:Entity-merity_s,
        askg-data:Entity-research_on_neural_language_models .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16372 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "S., and Socher, R."@en ;
    askg-onto:inSentence "S., and Socher, R."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s,
        askg-data:Entity-socher_r .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16373 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Regularizing and optimizing LSTM language models."@en ;
    askg-onto:inSentence "Regularizing and optimizing LSTM language models."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lstm_language_models .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1637-Sentence-16374 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "arXiv preprint arXiv:1708.02182, 2017."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1708.02182, 2017."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-arxiv_preprint_arxiv170802182,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 38"@en ;
    domo:Text "Nesterov, Y. Introductory lectures on convex optimization: A basic course, volume 87. Springer Science & Business Media, 2013."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638-Sentence-16381,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638-Sentence-16382,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638-Sentence-16383 ;
    askg-onto:index "38"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638-Sentence-16381 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Nesterov, Y."@en ;
    askg-onto:inSentence "Nesterov, Y."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nesterov_y,
        askg-data:Entity-scientist .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638-Sentence-16382 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Introductory lectures on convex optimization: A basic course, volume 87."@en ;
    askg-onto:inSentence "Introductory lectures on convex optimization: A basic course, volume 87."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-introductory_lectures_on_convex_optimization,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1638-Sentence-16383 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Springer Science & Business Media, 2013."@en ;
    askg-onto:inSentence "Springer Science & Business Media, 2013."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2013,
        askg-data:Entity-springer_science__business_media .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 39"@en ;
    domo:Text "Reddi, S. J., Kale, S., and Kumar, S. On the convergence of Adam and beyond. *arXiv preprint arXiv:1904.09237*, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16391,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16392,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16393,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16394 ;
    askg-onto:index "39"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16391 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Reddi, S."@en ;
    askg-onto:inSentence "Reddi, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reddi_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16392 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "J., Kale, S., and Kumar, S."@en ;
    askg-onto:inSentence "J., Kale, S., and Kumar, S."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-kale_s,
        askg-data:Entity-kumar_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16393 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "On the convergence of Adam and beyond."@en ;
    askg-onto:inSentence "On the convergence of Adam and beyond."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-optimization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1639-Sentence-16394 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "*arXiv preprint arXiv:1904.09237*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1904.09237*, 2019."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv_preprint_arxiv190409237,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Chrabaszcz, P., Loshchilov, I., and Hutter, F. A downsampled variant of ImageNet as an alternative to the CIFAR datasets. *arXiv preprint arXiv:1707.08819*, 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164-Sentence-1641,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164-Sentence-1642,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164-Sentence-1643 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164-Sentence-1641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Chrabaszcz, P., Loshchilov, I., and Hutter, F."@en ;
    askg-onto:inSentence "Chrabaszcz, P., Loshchilov, I., and Hutter, F."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chrabaszcz_p,
        askg-data:Entity-hutter_f,
        askg-data:Entity-loshchilov_i,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164-Sentence-1642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A downsampled variant of ImageNet as an alternative to the CIFAR datasets."@en ;
    askg-onto:inSentence "A downsampled variant of ImageNet as an alternative to the CIFAR datasets."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar_datasets,
        askg-data:Entity-imagenet .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-164-Sentence-1643 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*arXiv preprint arXiv:1707.08819*, 2017."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1707.08819*, 2017."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv170708819,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 40"@en ;
    domo:Text "Roux, N. L., Manzagol, P.-A., and Bengio, Y. Topmoumoute online natural gradient algorithm. In Advances in neural information processing systems, pp. 849â€“856, 2008."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16401,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16402,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16403,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16404,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16405 ;
    askg-onto:index "40"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16401 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Roux, N."@en ;
    askg-onto:inSentence "Roux, N."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-roux_n .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16402 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "L., Manzagol, P.-A., and Bengio, Y."@en ;
    askg-onto:inSentence "L., Manzagol, P.-A., and Bengio, Y."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bengio_y,
        askg-data:Entity-l,
        askg-data:Entity-manzagol_p-a,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16403 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Topmoumoute online natural gradient algorithm."@en ;
    askg-onto:inSentence "Topmoumoute online natural gradient algorithm."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-topmoumoute_online_natural_gradient_algorithm .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16404 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Advances in neural information processing systems, pp."@en ;
    askg-onto:inSentence "In Advances in neural information processing systems, pp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-pp .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1640-Sentence-16405 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "849â€“856, 2008."@en ;
    askg-onto:inSentence "849â€“856, 2008."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2008,
        askg-data:Entity-849856 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 41"@en ;
    domo:Text "Simonyan, K. and Zisserman, A. Very deep convolutional networks for large-scale image recognition. *arXiv* preprint arXiv:1409.1556, 2014."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16411,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16412,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16413,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16414 ;
    askg-onto:index "41"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Simonyan, K."@en ;
    askg-onto:inSentence "Simonyan, K."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-simonyan_k .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Zisserman, A."@en ;
    askg-onto:inSentence "and Zisserman, A."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zisserman_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Very deep convolutional networks for large-scale image recognition."@en ;
    askg-onto:inSentence "Very deep convolutional networks for large-scale image recognition."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-large-scale_image_recognition,
        askg-data:Entity-very_deep_convolutional_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1641-Sentence-16414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "*arXiv* preprint arXiv:1409.1556, 2014."@en ;
    askg-onto:inSentence "*arXiv* preprint arXiv:1409.1556, 2014."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2014,
        askg-data:Entity-arxiv,
        askg-data:Entity-arxiv14091556,
        askg-data:Entity-platform,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 42"@en ;
    domo:Text "Tieleman, T. and Hinton, G. Lecture 6.5-RMSProp: Divide the gradient by a running average of its recent magnitude."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642-Sentence-16421,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642-Sentence-16422,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642-Sentence-16423 ;
    askg-onto:index "42"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642-Sentence-16421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Tieleman, T."@en ;
    askg-onto:inSentence "Tieleman, T."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-tieleman_t .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642-Sentence-16422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Hinton, G."@en ;
    askg-onto:inSentence "and Hinton, G."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-hinton_g .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1642-Sentence-16423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Lecture 6.5-RMSProp: Divide the gradient by a running average of its recent magnitude."@en ;
    askg-onto:inSentence "Lecture 6.5-RMSProp: Divide the gradient by a running average of its recent magnitude."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-rmsprop .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1643 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 43"@en ;
    domo:Text "COURSERA: Neural networks for machine learning, 4 (2):26â€“31, 2012."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1643-Sentence-16431 ;
    askg-onto:index "43"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1643-Sentence-16431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "COURSERA: Neural networks for machine learning, 4 (2):26â€“31, 2012."@en ;
    askg-onto:inSentence "COURSERA: Neural networks for machine learning, 4 (2):26â€“31, 2012."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2012,
        askg-data:Entity-concept,
        askg-data:Entity-coursera,
        askg-data:Entity-coursera_neural_networks_for_machine_learning,
        askg-data:Entity-neural_networks_for_machine_learning,
        askg-data:Entity-platform,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 44"@en ;
    domo:Text "Tran, P. T. et al. On the convergence proof of AMSGrad and a new version. *IEEE Access*, 7:61706â€“61716, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16441,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16442,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16443,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16444,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16445 ;
    askg-onto:index "44"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Tran, P."@en ;
    askg-onto:inSentence "Tran, P."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-tran_p .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "T."@en ;
    askg-onto:inSentence "T."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_placeholder,
        askg-data:Entity-t .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "et al."@en ;
    askg-onto:inSentence "et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-et_al,
        askg-data:Entity-na .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16444 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "On the convergence proof of AMSGrad and a new version."@en ;
    askg-onto:inSentence "On the convergence proof of AMSGrad and a new version."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-amsgrad,
        askg-data:Entity-concept,
        askg-data:Entity-new_version .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1644-Sentence-16445 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "*IEEE Access*, 7:61706â€“61716, 2019."@en ;
    askg-onto:inSentence "*IEEE Access*, 7:61706â€“61716, 2019."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-76170661716,
        askg-data:Entity-ieee_access,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 45"@en ;
    domo:Text "Trivedi, S. and Kondor, R. Cmsc 35246: Deep learning."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645-Sentence-16451,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645-Sentence-16452,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645-Sentence-16453 ;
    askg-onto:index "45"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645-Sentence-16451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Trivedi, S."@en ;
    askg-onto:inSentence "Trivedi, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-trivedi_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645-Sentence-16452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Kondor, R."@en ;
    askg-onto:inSentence "and Kondor, R."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-kondor_r .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1645-Sentence-16453 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Cmsc 35246: Deep learning."@en ;
    askg-onto:inSentence "Cmsc 35246: Deep learning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1646 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 46"@en ;
    domo:Text "lecture 6: Optimization for deep neural networks. 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1646-Sentence-16461,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1646-Sentence-16462 ;
    askg-onto:index "46"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1646-Sentence-16461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "lecture 6: Optimization for deep neural networks."@en ;
    askg-onto:inSentence "lecture 6: Optimization for deep neural networks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lecture_6,
        askg-data:Entity-optimization_for_deep_neural_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1646-Sentence-16462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "2017."@en ;
    askg-onto:inSentence "2017."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-research .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 47"@en ;
    domo:Text "Vershynin, R. High-dimensional probability: An introduction with applications in data science, volume 47. Cambridge university press, 2018."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647-Sentence-16471,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647-Sentence-16472,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647-Sentence-16473 ;
    askg-onto:index "47"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647-Sentence-16471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Vershynin, R."@en ;
    askg-onto:inSentence "Vershynin, R."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-vershynin_r .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647-Sentence-16472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "High-dimensional probability: An introduction with applications in data science, volume 47."@en ;
    askg-onto:inSentence "High-dimensional probability: An introduction with applications in data science, volume 47."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-data_science,
        askg-data:Entity-high-dimensional_probability,
        askg-data:Entity-high-dimensional_probability_an_introduction_with_applications_in_data_science,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-volume_47 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1647-Sentence-16473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Cambridge university press, 2018."@en ;
    askg-onto:inSentence "Cambridge university press, 2018."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-cambridge_university_press .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 48"@en ;
    domo:Text "Wilson, A. C., Roelofs, R., Stern, M., Srebro, N., and Recht, B. The marginal value of adaptive gradient methods in machine learning. In *Advances in Neural Information* Processing Systems, pp. 4148â€“4158, 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16481,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16482,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16483,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16484,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16485 ;
    askg-onto:index "48"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Wilson, A."@en ;
    askg-onto:inSentence "Wilson, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-wilson_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16482 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "C., Roelofs, R., Stern, M., Srebro, N., and Recht, B."@en ;
    askg-onto:inSentence "C., Roelofs, R., Stern, M., Srebro, N., and Recht, B."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-publication,
        askg-data:Entity-recht,
        askg-data:Entity-roelofs,
        askg-data:Entity-srebro,
        askg-data:Entity-stern .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16483 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The marginal value of adaptive gradient methods in machine learning."@en ;
    askg-onto:inSentence "The marginal value of adaptive gradient methods in machine learning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_gradient_methods,
        askg-data:Entity-machine_learning .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16484 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In *Advances in Neural Information* Processing Systems, pp."@en ;
    askg-onto:inSentence "In *Advances in Neural Information* Processing Systems, pp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1648-Sentence-16485 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "4148â€“4158, 2017."@en ;
    askg-onto:inSentence "4148â€“4158, 2017."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-41484158 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 49"@en ;
    domo:Text "Xie, Q., Hovy, E., Luong, M.-T., and Le, Q. V. Selftraining with noisy student improves ImageNet classification, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649-Sentence-16491,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649-Sentence-16492,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649-Sentence-16493 ;
    askg-onto:index "49"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649-Sentence-16491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Xie, Q., Hovy, E., Luong, M.-T., and Le, Q."@en ;
    askg-onto:inSentence "Xie, Q., Hovy, E., Luong, M.-T., and Le, Q."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hovy_e,
        askg-data:Entity-le_q,
        askg-data:Entity-luong_m-t,
        askg-data:Entity-publication,
        askg-data:Entity-xie_q .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649-Sentence-16492 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "V."@en ;
    askg-onto:inSentence "V."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-v .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1649-Sentence-16493 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Selftraining with noisy student improves ImageNet classification, 2019."@en ;
    askg-onto:inSentence "Selftraining with noisy student improves ImageNet classification, 2019."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classification,
        askg-data:Entity-imagenet,
        askg-data:Entity-imagenet_classification,
        askg-data:Entity-selftraining_with_noisy_student,
        askg-data:Entity-study .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Cubuk, E. D., Zoph, B., Shlens, J., and Le, Q. V. Randaugment: Practical data augmentation with no separate search. *arXiv preprint arXiv:1909.13719*, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1651,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1652,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1653,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1654,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1655 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Cubuk, E."@en ;
    askg-onto:inSentence "Cubuk, E."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-cubuk_e .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "D., Zoph, B., Shlens, J., and Le, Q."@en ;
    askg-onto:inSentence "D., Zoph, B., Shlens, J., and Le, Q."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-le,
        askg-data:Entity-publication,
        askg-data:Entity-shlens,
        askg-data:Entity-zoph .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1653 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "V."@en ;
    askg-onto:inSentence "V."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-v .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1654 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Randaugment: Practical data augmentation with no separate search."@en ;
    askg-onto:inSentence "Randaugment: Practical data augmentation with no separate search."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_augmentation,
        askg-data:Entity-randaugment .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-165-Sentence-1655 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "*arXiv preprint arXiv:1909.13719*, 2019."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1909.13719*, 2019."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv190913719,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1650 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 50"@en ;
    domo:Text "Xie, S., Girshick, R., Dollar, P., Tu, Z., and He, K. Aggre- Â´ gated residual transformations for deep neural networks."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1650-Sentence-16501,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1650-Sentence-16502 ;
    askg-onto:index "50"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1650-Sentence-16501 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Xie, S., Girshick, R., Dollar, P., Tu, Z., and He, K."@en ;
    askg-onto:inSentence "Xie, S., Girshick, R., Dollar, P., Tu, Z., and He, K."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-dollar_p,
        askg-data:Entity-girshick_r,
        askg-data:Entity-he_k,
        askg-data:Entity-tu_z,
        askg-data:Entity-xie_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1650-Sentence-16502 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Aggre- Â´ gated residual transformations for deep neural networks."@en ;
    askg-onto:inSentence "Aggre- Â´ gated residual transformations for deep neural networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aggregated_residual_transformations,
        askg-data:Entity-deep_neural_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1651 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 51"@en ;
    domo:Text "In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1492â€“1500, 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1651-Sentence-16511,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1651-Sentence-16512 ;
    askg-onto:index "51"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1651-Sentence-16511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Proceedings of the IEEE conference on computer vision and pattern recognition, pp."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE conference on computer vision and pattern recognition, pp."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1651-Sentence-16512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "1492â€“1500, 2017."@en ;
    askg-onto:inSentence "1492â€“1500, 2017."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-14921500,
        askg-data:Entity-2017 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 52"@en ;
    domo:Text "Yun, S., Han, D., Oh, S. J., Chun, S., Choe, J., and Yoo, Y. Cutmix: Regularization strategy to train strong classifiers with localizable features. arXiv preprint arXiv:1905.04899, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16521,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16522,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16523,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16524 ;
    askg-onto:index "52"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Yun, S., Han, D., Oh, S."@en ;
    askg-onto:inSentence "Yun, S., Han, D., Oh, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-han_d,
        askg-data:Entity-oh_s,
        askg-data:Entity-publication,
        askg-data:Entity-yun_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "J., Chun, S., Choe, J., and Yoo, Y."@en ;
    askg-onto:inSentence "J., Chun, S., Choe, J., and Yoo, Y."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-choe_j,
        askg-data:Entity-chun_s,
        askg-data:Entity-j,
        askg-data:Entity-yoo_y .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Cutmix: Regularization strategy to train strong classifiers with localizable features."@en ;
    askg-onto:inSentence "Cutmix: Regularization strategy to train strong classifiers with localizable features."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cutmix,
        askg-data:Entity-regularization_strategy,
        askg-data:Entity-train_strong_classifiers_with_localizable_features .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1652-Sentence-16524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "arXiv preprint arXiv:1905.04899, 2019."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1905.04899, 2019."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-arxiv_preprint_arxiv190504899,
        askg-data:Entity-paper .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 53"@en ;
    domo:Text "Zagoruyko, S. and Komodakis, N. Wide residual networks."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653-Sentence-16531,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653-Sentence-16532,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653-Sentence-16533 ;
    askg-onto:index "53"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653-Sentence-16531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zagoruyko, S."@en ;
    askg-onto:inSentence "Zagoruyko, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-zagoruyko_s .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653-Sentence-16532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Komodakis, N."@en ;
    askg-onto:inSentence "and Komodakis, N."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-komodakis_n .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1653-Sentence-16533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Wide residual networks."@en ;
    askg-onto:inSentence "Wide residual networks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network_architecture,
        askg-data:Entity-wide_residual_networks .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1654 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 54"@en ;
    domo:Text "arXiv preprint arXiv:1605.07146, 2016."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1654-Sentence-16541 ;
    askg-onto:index "54"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1654-Sentence-16541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "arXiv preprint arXiv:1605.07146, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1605.07146, 2016."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-arxiv160507146,
        askg-data:Entity-arxiv_preprint_arxiv160507146,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 55"@en ;
    domo:Text "Zeiler, M. D. Adadelta: an adaptive learning rate method."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655-Sentence-16551,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655-Sentence-16552,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655-Sentence-16553 ;
    askg-onto:index "55"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655-Sentence-16551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zeiler, M."@en ;
    askg-onto:inSentence "Zeiler, M."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-zeiler_m .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655-Sentence-16552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "D."@en ;
    askg-onto:inSentence "D."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1655-Sentence-16553 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Adadelta: an adaptive learning rate method."@en ;
    askg-onto:inSentence "Adadelta: an adaptive learning rate method."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adadelta,
        askg-data:Entity-adaptive_learning_rate_method .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1656 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 56"@en ;
    domo:Text "arXiv preprint arXiv:1212.5701, 2012."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1656-Sentence-16561 ;
    askg-onto:index "56"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1656-Sentence-16561 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "arXiv preprint arXiv:1212.5701, 2012."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1212.5701, 2012."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2012,
        askg-data:Entity-arxiv,
        askg-data:Entity-arxiv12125701,
        askg-data:Entity-platform,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1657 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 57"@en ;
    domo:Text "Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1657-Sentence-16571 ;
    askg-onto:index "57"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1657-Sentence-16571 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O."@en ;
    askg-onto:inSentence "Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bengio_s,
        askg-data:Entity-hardt_m,
        askg-data:Entity-recht_b,
        askg-data:Entity-vinyals_o,
        askg-data:Entity-zhang_c .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1658 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 58"@en ;
    domo:Text "Understanding deep learning requires rethinking generalization. *arXiv preprint arXiv:1611.03530*, 2016."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1658-Sentence-16581,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1658-Sentence-16582 ;
    askg-onto:index "58"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1658-Sentence-16581 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Understanding deep learning requires rethinking generalization."@en ;
    askg-onto:inSentence "Understanding deep learning requires rethinking generalization."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-rethinking_generalization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1658-Sentence-16582 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "*arXiv preprint arXiv:1611.03530*, 2016."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1611.03530*, 2016."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv161103530,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 59"@en ;
    domo:Text "Zhang, C., Liao, Q., Rakhlin, A., Miranda, B., Golowich, N., and Poggio, T. Theory of deep learning IIb: Optimization properties of SGD. *arXiv preprint arXiv:1801.02254*, 2018a."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659-Sentence-16591,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659-Sentence-16592,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659-Sentence-16593 ;
    askg-onto:index "59"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659-Sentence-16591 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zhang, C., Liao, Q., Rakhlin, A., Miranda, B., Golowich, N., and Poggio, T."@en ;
    askg-onto:inSentence "Zhang, C., Liao, Q., Rakhlin, A., Miranda, B., Golowich, N., and Poggio, T."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-golowich_n,
        askg-data:Entity-liao_q,
        askg-data:Entity-miranda_b,
        askg-data:Entity-poggio_t,
        askg-data:Entity-rakhlin_a,
        askg-data:Entity-zhang_c .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659-Sentence-16592 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Theory of deep learning IIb: Optimization properties of SGD."@en ;
    askg-onto:inSentence "Theory of deep learning IIb: Optimization properties of SGD."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-sgd,
        askg-data:Entity-theory_of_deep_learning_iib .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1659-Sentence-16593 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*arXiv preprint arXiv:1801.02254*, 2018a."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1801.02254*, 2018a."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018a,
        askg-data:Entity-arxiv180102254,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Jastrzebski, S., Szymczak, M., Fort, S., Arpit, D., Tabor, J., Cho, K., and Geras, K. The break-even point on the optimization trajectories of deep neural networks. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum? id=r1g87C4KwB."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1661,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1662,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1663,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1664,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1665 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Jastrzebski, S., Szymczak, M., Fort, S., Arpit, D., Tabor, J., Cho, K., and Geras, K."@en ;
    askg-onto:inSentence "Jastrzebski, S., Szymczak, M., Fort, S., Arpit, D., Tabor, J., Cho, K., and Geras, K."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arpit_d,
        askg-data:Entity-author,
        askg-data:Entity-cho_k,
        askg-data:Entity-fort_s,
        askg-data:Entity-geras_k,
        askg-data:Entity-jastrzebski_s,
        askg-data:Entity-szymczak_m,
        askg-data:Entity-tabor_j .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1662 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The break-even point on the optimization trajectories of deep neural networks."@en ;
    askg-onto:inSentence "The break-even point on the optimization trajectories of deep neural networks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-break-even_point,
        askg-data:Entity-deep_neural_networks,
        askg-data:Entity-optimization_trajectories .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1663 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In International Conference on Learning Representations, 2020."@en ;
    askg-onto:inSentence "In International Conference on Learning Representations, 2020."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1664 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "URL https://openreview.net/forum?"@en ;
    askg-onto:inSentence "URL https://openreview.net/forum?"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-platform .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-166-Sentence-1665 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "id=r1g87C4KwB."@en ;
    askg-onto:inSentence "id=r1g87C4KwB."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-r1g87c4kwb .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 60"@en ;
    domo:Text "Zhang, G., Wang, C., Xu, B., and Grosse, R. Three mechanisms of weight decay regularization. arXiv preprint arXiv:1810.12281, 2018b."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660-Sentence-16601,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660-Sentence-16602,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660-Sentence-16603 ;
    askg-onto:index "60"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660-Sentence-16601 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zhang, G., Wang, C., Xu, B., and Grosse, R."@en ;
    askg-onto:inSentence "Zhang, G., Wang, C., Xu, B., and Grosse, R."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-grosse_r,
        askg-data:Entity-wang_c,
        askg-data:Entity-xu_b,
        askg-data:Entity-zhang_g .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660-Sentence-16602 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Three mechanisms of weight decay regularization."@en ;
    askg-onto:inSentence "Three mechanisms of weight decay regularization."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mechanism,
        askg-data:Entity-weight_decay_regularization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1660-Sentence-16603 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "arXiv preprint arXiv:1810.12281, 2018b."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1810.12281, 2018b."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv_preprint_arxiv181012281,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 61"@en ;
    domo:Text "Zhang, G., Li, L., Nado, Z., Martens, J., Sachdeva, S., Dahl, G., Shallue, C., and Grosse, R. B. Which algorithmic choices matter at which batch sizes? insights from a noisy quadratic model. In Advances in Neural Information Processing Systems, pp. 8194â€“8205, 2019a."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16611,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16612,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16613,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16614,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16615,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16616 ;
    askg-onto:index "61"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zhang, G., Li, L., Nado, Z., Martens, J., Sachdeva, S., Dahl, G., Shallue, C., and Grosse, R."@en ;
    askg-onto:inSentence "Zhang, G., Li, L., Nado, Z., Martens, J., Sachdeva, S., Dahl, G., Shallue, C., and Grosse, R."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-dahl_g,
        askg-data:Entity-grosse_r,
        askg-data:Entity-li_l,
        askg-data:Entity-martens_j,
        askg-data:Entity-nado_z,
        askg-data:Entity-sachdeva_s,
        askg-data:Entity-shallue_c,
        askg-data:Entity-zhang_g .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "B."@en ;
    askg-onto:inSentence "B."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-text_to_analyze .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Which algorithmic choices matter at which batch sizes?"@en ;
    askg-onto:inSentence "Which algorithmic choices matter at which batch sizes?"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithmic_choices,
        askg-data:Entity-batch_sizes .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "insights from a noisy quadratic model."@en ;
    askg-onto:inSentence "insights from a noisy quadratic model."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-insights,
        askg-data:Entity-noisy_quadratic_model .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pp."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1661-Sentence-16616 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "8194â€“8205, 2019a."@en ;
    askg-onto:inSentence "8194â€“8205, 2019a."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019a,
        askg-data:Entity-81948205 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 62"@en ;
    domo:Text "Zhang, M., Lucas, J., Ba, J., and Hinton, G. E. Lookahead optimizer: k steps forward, 1 step back. In Advances in Neural Information Processing Systems, pp. 9593â€“9604, 2019b."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16621,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16622,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16623,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16624,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16625 ;
    askg-onto:index "62"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Zhang, M., Lucas, J., Ba, J., and Hinton, G."@en ;
    askg-onto:inSentence "Zhang, M., Lucas, J., Ba, J., and Hinton, G."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-ba_j,
        askg-data:Entity-hinton_g,
        askg-data:Entity-lucas_j,
        askg-data:Entity-zhang_m .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "E."@en ;
    askg-onto:inSentence "E."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e,
        askg-data:Entity-research .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Lookahead optimizer: k steps forward, 1 step back."@en ;
    askg-onto:inSentence "Lookahead optimizer: k steps forward, 1 step back."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k_steps_forward_1_step_back,
        askg-data:Entity-lookahead_optimizer,
        askg-data:Entity-optimizer .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16624 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pp."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-1662-Sentence-16625 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "9593â€“9604, 2019b."@en ;
    askg-onto:inSentence "9593â€“9604, 2019b."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019b,
        askg-data:Entity-95939604 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Defazio, A. and Bottou, L. On the ineffectiveness of variance reduced optimization for deep learning. In Advances in Neural Information Processing Systems, pp. 1753â€“1763, 2019."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1671,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1672,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1673,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1674,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1675 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Defazio, A."@en ;
    askg-onto:inSentence "Defazio, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-defazio_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1672 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "and Bottou, L."@en ;
    askg-onto:inSentence "and Bottou, L."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bottou_l .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1673 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "On the ineffectiveness of variance reduced optimization for deep learning."@en ;
    askg-onto:inSentence "On the ineffectiveness of variance reduced optimization for deep learning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-learning_paradigm,
        askg-data:Entity-optimization_technique,
        askg-data:Entity-variance_reduced_optimization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1674 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pp."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-167-Sentence-1675 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "1753â€“1763, 2019."@en ;
    askg-onto:inSentence "1753â€“1763, 2019."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-17531763,
        askg-data:Entity-2019 .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Jastrzkebski, S., Kenton, Z., Arpit, D., Ballas, N., Fischer, A., Bengio, Y., and Storkey, A. Three factors influencing minima in sgd. *arXiv preprint arXiv:1711.04623*, 2017."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168-Sentence-1681,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168-Sentence-1682,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168-Sentence-1683 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168-Sentence-1681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Jastrzkebski, S., Kenton, Z., Arpit, D., Ballas, N., Fischer, A., Bengio, Y., and Storkey, A."@en ;
    askg-onto:inSentence "Jastrzkebski, S., Kenton, Z., Arpit, D., Ballas, N., Fischer, A., Bengio, Y., and Storkey, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arpit_d,
        askg-data:Entity-ballas_n,
        askg-data:Entity-bengio_y,
        askg-data:Entity-fischer_a,
        askg-data:Entity-jastrzkebski_s,
        askg-data:Entity-kenton_z,
        askg-data:Entity-research_on_neural_networks,
        askg-data:Entity-storkey_a .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168-Sentence-1682 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Three factors influencing minima in sgd."@en ;
    askg-onto:inSentence "Three factors influencing minima in sgd."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-minima,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-168-Sentence-1683 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*arXiv preprint arXiv:1711.04623*, 2017."@en ;
    askg-onto:inSentence "*arXiv preprint arXiv:1711.04623*, 2017."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-arxiv171104623,
        askg-data:Entity-arxiv_preprint_arxiv171104623,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Duchi, J., Hazan, E., and Singer, Y. Adaptive subgradient methods for online learning and stochastic optimization. *Journal of machine learning research*, 12(Jul):2121â€“ 2159, 2011."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169-Sentence-1691,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169-Sentence-1692,
        askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169-Sentence-1693 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169-Sentence-1691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Duchi, J., Hazan, E., and Singer, Y."@en ;
    askg-onto:inSentence "Duchi, J., Hazan, E., and Singer, Y."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-duchi_j,
        askg-data:Entity-hazan_e,
        askg-data:Entity-publication,
        askg-data:Entity-singer_y .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169-Sentence-1692 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Adaptive subgradient methods for online learning and stochastic optimization."@en ;
    askg-onto:inSentence "Adaptive subgradient methods for online learning and stochastic optimization."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_subgradient_methods,
        askg-data:Entity-online_learning,
        askg-data:Entity-stochastic_optimization .

askg-data:Paper-43d37e59d752bc41-Section-16-Paragraph-169-Sentence-1693 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "*Journal of machine learning research*, 12(Jul):2121â€“ 2159, 2011."@en ;
    askg-onto:inSentence "*Journal of machine learning research*, 12(Jul):2121â€“ 2159, 2011."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-12jul,
        askg-data:Entity-21212159,
        askg-data:Entity-journal_of_machine_learning_research,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-17 a askg-onto:Section ;
    rdfs:label "Section 17"@en ;
    domo:Text "A. Supplementary Materials Of Gadam"@en ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-18 a askg-onto:Section ;
    rdfs:label "Section 18"@en ;
    domo:Text "A.1. Gadam/Gadamx Algorithm"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181 ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Here we present the full Gadam/GadamX algorithm. Note that for simplicity, in Algorthm 1 we present a Polyak-style averaging of every iteration, in practice we find both practical and theoretical results why averaging *less* frequently is almost equally good, if not better. We include a discussion on this in Appendix A.3."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181-Sentence-1811,
        askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181-Sentence-1812,
        askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181-Sentence-1813 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181-Sentence-1811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Here we present the full Gadam/GadamX algorithm."@en ;
    askg-onto:inSentence "Here we present the full Gadam/GadamX algorithm."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-gadamgadamx_algorithm .

askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181-Sentence-1812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that for simplicity, in Algorthm 1 we present a Polyak-style averaging of every iteration, in practice we find both practical and theoretical results why averaging *less* frequently is almost equally good, if not better."@en ;
    askg-onto:inSentence "Note that for simplicity, in Algorthm 1 we present a Polyak-style averaging of every iteration, in practice we find both practical and theoretical results why averaging *less* frequently is almost equally good, if not better."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm_1,
        askg-data:Entity-polyak-style_averaging .

askg-data:Paper-43d37e59d752bc41-Section-18-Paragraph-181-Sentence-1813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We include a discussion on this in Appendix A.3."@en ;
    askg-onto:inSentence "We include a discussion on this in Appendix A.3."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appendix_a3,
        askg-data:Entity-discussion .

askg-data:Paper-43d37e59d752bc41-Section-19 a askg-onto:Section ;
    rdfs:label "Section 19"@en ;
    domo:Text "Algorithm 1 Gadam/Gadamx"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-191,
        askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-192 ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-191 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Require: initial weights Î¸0; learning rate scheduler Î±t = Î±(t); momentum parameters {Î²1, Î²2} (Default to {0.9, 0.999} respectively); partially adaptive parameter p âˆˆ [0, 0.5] Default to {0.125, 0.5} for {GadamX, Gadam}; decoupled weight decay Î»; averaging starting point Tavg; tolerance (default to 10âˆ’8) Ensure: Optimised weights ËœÎ¸ Set m0 = 0, v0 = 0, vË†0 = 0, nmodels = 0."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-191-Sentence-1911 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-191-Sentence-1911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Require: initial weights Î¸0; learning rate scheduler Î±t = Î±(t); momentum parameters {Î²1, Î²2} (Default to {0.9, 0.999} respectively); partially adaptive parameter p âˆˆ [0, 0.5] Default to {0.125, 0.5} for {GadamX, Gadam}; decoupled weight decay Î»; averaging starting point Tavg; tolerance (default to 10âˆ’8) Ensure: Optimised weights ËœÎ¸ Set m0 = 0, v0 = 0, vË†0 = 0, nmodels = 0."@en ;
    askg-onto:inSentence "Require: initial weights Î¸0; learning rate scheduler Î±t = Î±(t); momentum parameters {Î²1, Î²2} (Default to {0.9, 0.999} respectively); partially adaptive parameter p âˆˆ [0, 0.5] Default to {0.125, 0.5} for {GadamX, Gadam}; decoupled weight decay Î»; averaging starting point Tavg; tolerance (default to 10âˆ’8) Ensure: Optimised weights ËœÎ¸ Set m0 = 0, v0 = 0, vË†0 = 0, nmodels = 0."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1t__%CE%B1t,
        askg-data:Entity-%CE%B21_%CE%B22,
        askg-data:Entity-%CE%B8,
        askg-data:Entity-%CE%BB,
        askg-data:Entity-0,
        askg-data:Entity-0125_05_for_gadamx_gadam,
        askg-data:Entity-09_0999,
        askg-data:Entity-108,
        askg-data:Entity-averaging_starting_point,
        askg-data:Entity-decoupled_weight_decay,
        askg-data:Entity-learning_rate_scheduler,
        askg-data:Entity-m0,
        askg-data:Entity-momentum_parameters,
        askg-data:Entity-nmodels,
        askg-data:Entity-optimised_weights,
        askg-data:Entity-p__0_05,
        askg-data:Entity-partially_adaptive_parameter,
        askg-data:Entity-tavg,
        askg-data:Entity-tolerance,
        askg-data:Entity-v%CB%860,
        askg-data:Entity-v0 .

askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-192 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "for t = 1, ... T do Î±t = Î±(t) gt = âˆ‡ft(Î¸t) mt = Î²1mtâˆ’1 + (1 âˆ’ Î²1)gt/(1 âˆ’ Î² t1) vt = Î²2vtâˆ’1 + (1 âˆ’ Î²2)g 2 t /(1 âˆ’ Î² t2) vË†t = max(vË†tâˆ’1, vË†t) (If using Amsgrad) Î¸t = (1 âˆ’ Î±tÎ»)Î¸tâˆ’1 âˆ’ Î±tmË† t (vË†t+) p if T â‰¥ Tavg **then** nmodels = nmodels + 1 Î¸avg = Î¸avgÂ·nmodels+Î¸t nmodels+1 else Î¸avg = Î¸t end if end for return ËœÎ¸ = Î¸avg"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-192-Sentence-1921,
        askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-192-Sentence-1922 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-192-Sentence-1921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "for t = 1, ..."@en ;
    askg-onto:inSentence "for t = 1, ..."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-t,
        askg-data:Entity-variable .

askg-data:Paper-43d37e59d752bc41-Section-19-Paragraph-192-Sentence-1922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "T do Î±t = Î±(t) gt = âˆ‡ft(Î¸t) mt = Î²1mtâˆ’1 + (1 âˆ’ Î²1)gt/(1 âˆ’ Î² t1) vt = Î²2vtâˆ’1 + (1 âˆ’ Î²2)g 2 t /(1 âˆ’ Î² t2) vË†t = max(vË†tâˆ’1, vË†t) (If using Amsgrad) Î¸t = (1 âˆ’ Î±tÎ»)Î¸tâˆ’1 âˆ’ Î±tmË† t (vË†t+) p if T â‰¥ Tavg **then** nmodels = nmodels + 1 Î¸avg = Î¸avgÂ·nmodels+Î¸t nmodels+1 else Î¸avg = Î¸t end if end for return ËœÎ¸ = Î¸avg"@en ;
    askg-onto:inSentence "T do Î±t = Î±(t) gt = âˆ‡ft(Î¸t) mt = Î²1mtâˆ’1 + (1 âˆ’ Î²1)gt/(1 âˆ’ Î² t1) vt = Î²2vtâˆ’1 + (1 âˆ’ Î²2)g 2 t /(1 âˆ’ Î² t2) vË†t = max(vË†tâˆ’1, vË†t) (If using Amsgrad) Î¸t = (1 âˆ’ Î±tÎ»)Î¸tâˆ’1 âˆ’ Î±tmË† t (vË†t+) p if T â‰¥ Tavg **then** nmodels = nmodels + 1 Î¸avg = Î¸avgÂ·nmodels+Î¸t nmodels+1 else Î¸avg = Î¸t end if end for return ËœÎ¸ = Î¸avg"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1t,
        askg-data:Entity-%CE%B21,
        askg-data:Entity-%CE%B22,
        askg-data:Entity-%CE%B8avg,
        askg-data:Entity-%CE%B8t,
        askg-data:Entity-average_number_of_models,
        askg-data:Entity-first_moment_estimate,
        askg-data:Entity-function_ft,
        askg-data:Entity-gt,
        askg-data:Entity-learning_rate,
        askg-data:Entity-max_of_previous_estimates,
        askg-data:Entity-model_instances,
        askg-data:Entity-model_parameters,
        askg-data:Entity-momentum,
        askg-data:Entity-mt,
        askg-data:Entity-nmodels,
        askg-data:Entity-second_moment,
        askg-data:Entity-second_moment_estimate,
        askg-data:Entity-t,
        askg-data:Entity-v%CB%86t,
        askg-data:Entity-vt .

askg-data:Paper-43d37e59d752bc41-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "Abstract"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Iterate averaging has a rich history in optimisation, but has only very recently been popularised in deep learning. We investigate its effects in a deep learning context, and argue that previous explanations on its efficacy, which place a high importance on the local geometry (flatness vs sharpness) of final solutions, are not necessarily relevant. We instead argue that the robustness of iterate averaging towards the typically very high estimation noise in deep learning and the various regularisation effects averaging exert, are the key reasons for the performance gain, indeed this effect is made even more prominent due to the over-parameterisation of modern networks. Inspired by this, we propose Gadam, which combines Adam with iterate averaging to address one of key problems of adaptive optimisers that they often generalise worse. Without compromising adaptivity and with minimal additional computational burden, we show that Gadam (and its variant GadamX) achieve a generalisation performance that is consistently superior to tuned SGD and is even on par or better compared to SGD with iterate averaging on various image classification (CIFAR 10/100 and ImageNet 32Ã—32) and language tasks (PTB)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-211,
        askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-212,
        askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-213,
        askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-214,
        askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-215 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Iterate averaging has a rich history in optimisation, but has only very recently been popularised in deep learning."@en ;
    askg-onto:inSentence "Iterate averaging has a rich history in optimisation, but has only very recently been popularised in deep learning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-optimisation .

askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We investigate its effects in a deep learning context, and argue that previous explanations on its efficacy, which place a high importance on the local geometry (flatness vs sharpness) of final solutions, are not necessarily relevant."@en ;
    askg-onto:inSentence "We investigate its effects in a deep learning context, and argue that previous explanations on its efficacy, which place a high importance on the local geometry (flatness vs sharpness) of final solutions, are not necessarily relevant."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-effects,
        askg-data:Entity-efficacy,
        askg-data:Entity-final_solutions,
        askg-data:Entity-flatness,
        askg-data:Entity-local_geometry,
        askg-data:Entity-previous_explanations,
        askg-data:Entity-sharpness .

askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We instead argue that the robustness of iterate averaging towards the typically very high estimation noise in deep learning and the various regularisation effects averaging exert, are the key reasons for the performance gain, indeed this effect is made even more prominent due to the over-parameterisation of modern networks."@en ;
    askg-onto:inSentence "We instead argue that the robustness of iterate averaging towards the typically very high estimation noise in deep learning and the various regularisation effects averaging exert, are the key reasons for the performance gain, indeed this effect is made even more prominent due to the over-parameterisation of modern networks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-method,
        askg-data:Entity-modern_networks,
        askg-data:Entity-paradigm,
        askg-data:Entity-system .

askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Inspired by this, we propose Gadam, which combines Adam with iterate averaging to address one of key problems of adaptive optimisers that they often generalise worse."@en ;
    askg-onto:inSentence "Inspired by this, we propose Gadam, which combines Adam with iterate averaging to address one of key problems of adaptive optimisers that they often generalise worse."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-gadam,
        askg-data:Entity-iterate_averaging .

askg-data:Paper-43d37e59d752bc41-Section-2-Paragraph-21-Sentence-215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Without compromising adaptivity and with minimal additional computational burden, we show that Gadam (and its variant GadamX) achieve a generalisation performance that is consistently superior to tuned SGD and is even on par or better compared to SGD with iterate averaging on various image classification (CIFAR 10/100 and ImageNet 32Ã—32) and language tasks (PTB)."@en ;
    askg-onto:inSentence "Without compromising adaptivity and with minimal additional computational burden, we show that Gadam (and its variant GadamX) achieve a generalisation performance that is consistently superior to tuned SGD and is even on par or better compared to SGD with iterate averaging on various image classification (CIFAR 10/100 and ImageNet 32Ã—32) and language tasks (PTB)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar_10100,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-generalisation_performance,
        askg-data:Entity-image_classification,
        askg-data:Entity-imagenet_3232,
        askg-data:Entity-language_tasks,
        askg-data:Entity-ptb,
        askg-data:Entity-sgd_with_iterate_averaging,
        askg-data:Entity-tuned_sgd .

askg-data:Paper-43d37e59d752bc41-Section-20 a askg-onto:Section ;
    rdfs:label "Section 20"@en ;
    domo:Text "A.2. Gadam And Lookahead"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-203,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204 ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Lookahead (Zhang et al., 2019b) is a very recent attempt that also features weight space averaging in order to achieve optimisation and generalisation benefits. However, instead of using simple averaging in our proposed algorithms, Lookahead maintains different update rules for the *fast* and *slow* weights, and uses exponentially moving average to update the parameters. In this section, we both comment on the key theoretical differences between Gadam and Lookahead and make some preliminary practical comparisons. We also offer an attempt to bring together the *optimisation* benefit of Lookahead and the *generalisation* benefit of Gadam, with promising preliminary results."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2011,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2012,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2013,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2014 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Lookahead (Zhang et al., 2019b) is a very recent attempt that also features weight space averaging in order to achieve optimisation and generalisation benefits."@en ;
    askg-onto:inSentence "Lookahead (Zhang et al., 2019b) is a very recent attempt that also features weight space averaging in order to achieve optimisation and generalisation benefits."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019b,
        askg-data:Entity-author,
        askg-data:Entity-lookahead,
        askg-data:Entity-optimisation_and_generalisation_benefits,
        askg-data:Entity-recent_attempt,
        askg-data:Entity-weight_space_averaging,
        askg-data:Entity-zhang_et_al .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, instead of using simple averaging in our proposed algorithms, Lookahead maintains different update rules for the *fast* and *slow* weights, and uses exponentially moving average to update the parameters."@en ;
    askg-onto:inSentence "However, instead of using simple averaging in our proposed algorithms, Lookahead maintains different update rules for the *fast* and *slow* weights, and uses exponentially moving average to update the parameters."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_update_rules,
        askg-data:Entity-exponentially_moving_average,
        askg-data:Entity-lookahead,
        askg-data:Entity-the_parameters .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In this section, we both comment on the key theoretical differences between Gadam and Lookahead and make some preliminary practical comparisons."@en ;
    askg-onto:inSentence "In this section, we both comment on the key theoretical differences between Gadam and Lookahead and make some preliminary practical comparisons."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-lookahead .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-201-Sentence-2014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We also offer an attempt to bring together the *optimisation* benefit of Lookahead and the *generalisation* benefit of Gadam, with promising preliminary results."@en ;
    askg-onto:inSentence "We also offer an attempt to bring together the *optimisation* benefit of Lookahead and the *generalisation* benefit of Gadam, with promising preliminary results."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-generalisation,
        askg-data:Entity-lookahead,
        askg-data:Entity-optimisation .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "12 MAJOR DIFFERENCES BETWEEN GADAM AND LOOKAHEAD Averaging Method Lookahead opts for a more complicated averaging scheme: they determine the 'fast'- and 'slow'- varying weights during optimisation, and maintains an EMA to average the weight. On the other hand, Gadam uses a more straightforward simple average. As we discussed in the main text, EMA is more theoretically justified during the initial rather than later stage of training. This can also be argued from a Bayesian viewpoint following Maddox et al. (2019), who argued that iterates are simply the draws from the posterior predictive distribution of the neural network, where as averaging leads to a rough estimation of its posterior mean. It is apparent that if the draws from this distribution are *equally* good (which is likely to be the case if we start averaging only if validation metrics stop improving), assigning the iterates with an exponential weight just based on when they are drawn constitutes a rather arbitrary prior in Bayesian sense."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2021,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2022,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2023,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2024,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2025,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2026 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "12 MAJOR DIFFERENCES BETWEEN GADAM AND LOOKAHEAD Averaging Method Lookahead opts for a more complicated averaging scheme: they determine the 'fast'- and 'slow'- varying weights during optimisation, and maintains an EMA to average the weight."@en ;
    askg-onto:inSentence "12 MAJOR DIFFERENCES BETWEEN GADAM AND LOOKAHEAD Averaging Method Lookahead opts for a more complicated averaging scheme: they determine the 'fast'- and 'slow'- varying weights during optimisation, and maintains an EMA to average the weight."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_weight,
        askg-data:Entity-averaging_scheme,
        askg-data:Entity-ema,
        askg-data:Entity-fast-_and_slow-varying_weights,
        askg-data:Entity-lookahead,
        askg-data:Entity-lookahead_averaging_method .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "On the other hand, Gadam uses a more straightforward simple average."@en ;
    askg-onto:inSentence "On the other hand, Gadam uses a more straightforward simple average."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-simple_average .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As we discussed in the main text, EMA is more theoretically justified during the initial rather than later stage of training."@en ;
    askg-onto:inSentence "As we discussed in the main text, EMA is more theoretically justified during the initial rather than later stage of training."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-later_stage_of_training,
        askg-data:Entity-the_initial_stage_of_training .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This can also be argued from a Bayesian viewpoint following Maddox et al."@en ;
    askg-onto:inSentence "This can also be argued from a Bayesian viewpoint following Maddox et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bayesian_viewpoint,
        askg-data:Entity-maddox_et_al .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2019), who argued that iterates are simply the draws from the posterior predictive distribution of the neural network, where as averaging leads to a rough estimation of its posterior mean."@en ;
    askg-onto:inSentence "(2019), who argued that iterates are simply the draws from the posterior predictive distribution of the neural network, where as averaging leads to a rough estimation of its posterior mean."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-neural_network,
        askg-data:Entity-posterior_predictive_distribution,
        askg-data:Entity-rough_estimation_of_posterior_mean .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-202-Sentence-2026 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "It is apparent that if the draws from this distribution are *equally* good (which is likely to be the case if we start averaging only if validation metrics stop improving), assigning the iterates with an exponential weight just based on when they are drawn constitutes a rather arbitrary prior in Bayesian sense."@en ;
    askg-onto:inSentence "It is apparent that if the draws from this distribution are *equally* good (which is likely to be the case if we start averaging only if validation metrics stop improving), assigning the iterates with an exponential weight just based on when they are drawn constitutes a rather arbitrary prior in Bayesian sense."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bayesian,
        askg-data:Entity-concept,
        askg-data:Entity-exponential_weight,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-validation_metrics .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-203 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Averaging Frequency Lookahead averages every iteration whereas in Gadam, while possible to do so as well, by default averages much less frequently. We detail our rationale for this in Appendix A.3."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-203-Sentence-2031,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-203-Sentence-2032 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-203-Sentence-2031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Averaging Frequency Lookahead averages every iteration whereas in Gadam, while possible to do so as well, by default averages much less frequently."@en ;
    askg-onto:inSentence "Averaging Frequency Lookahead averages every iteration whereas in Gadam, while possible to do so as well, by default averages much less frequently."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging_frequency_lookahead,
        askg-data:Entity-every_iteration,
        askg-data:Entity-gadam .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-203-Sentence-2032 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We detail our rationale for this in Appendix A.3."@en ;
    askg-onto:inSentence "We detail our rationale for this in Appendix A.3."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appendix_a3,
        askg-data:Entity-rationale .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Starting Point of Averaging While Lookahead starts averaging at the beginning of the training, Gadam starts averaging either from a pre-set starting point or an automatic trigger (for GadamAuto). While authors of Lookahead (Zhang et al., 2019b) argue that starting averaging eliminates the hyperparameter on when to start averaging, it is worth noting that Lookahead also introduces two additional hyperparameters Î± and k, which are non-trivially determined from grid search (although the authors argue that the final result is not very sensitive to them). We believe the difference here is caused by the different design philosophies of Gadam and Lookahead: by using EMA and starting averaging from the beginning, Lookahead benefits from faster convergence and some generalisation improvement whereas in Gadam, since the averages of iterates are not used during training to promote independece between iterates, Gadam does not additionally accelerate optimisation but, by our theory, should generalise better. As we will see in the next section, this theoretical insight is validated by the experiments and leads to combinable benefits."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2041,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2042,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2043,
        askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2044 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Starting Point of Averaging While Lookahead starts averaging at the beginning of the training, Gadam starts averaging either from a pre-set starting point or an automatic trigger (for GadamAuto)."@en ;
    askg-onto:inSentence "Starting Point of Averaging While Lookahead starts averaging at the beginning of the training, Gadam starts averaging either from a pre-set starting point or an automatic trigger (for GadamAuto)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_pre-set_starting_point,
        askg-data:Entity-an_automatic_trigger,
        askg-data:Entity-averaging_while_lookahead,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamauto,
        askg-data:Entity-the_training .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2042 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While authors of Lookahead (Zhang et al., 2019b) argue that starting averaging eliminates the hyperparameter on when to start averaging, it is worth noting that Lookahead also introduces two additional hyperparameters Î± and k, which are non-trivially determined from grid search (although the authors argue that the final result is not very sensitive to them)."@en ;
    askg-onto:inSentence "While authors of Lookahead (Zhang et al., 2019b) argue that starting averaging eliminates the hyperparameter on when to start averaging, it is worth noting that Lookahead also introduces two additional hyperparameters Î± and k, which are non-trivially determined from grid search (although the authors argue that the final result is not very sensitive to them)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-grid_search,
        askg-data:Entity-hyperparameters_%CE%B1_and_k,
        askg-data:Entity-lookahead,
        askg-data:Entity-zhang_et_al .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2043 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We believe the difference here is caused by the different design philosophies of Gadam and Lookahead: by using EMA and starting averaging from the beginning, Lookahead benefits from faster convergence and some generalisation improvement whereas in Gadam, since the averages of iterates are not used during training to promote independece between iterates, Gadam does not additionally accelerate optimisation but, by our theory, should generalise better."@en ;
    askg-onto:inSentence "We believe the difference here is caused by the different design philosophies of Gadam and Lookahead: by using EMA and starting averaging from the beginning, Lookahead benefits from faster convergence and some generalisation improvement whereas in Gadam, since the averages of iterates are not used during training to promote independece between iterates, Gadam does not additionally accelerate optimisation but, by our theory, should generalise better."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-faster_convergence,
        askg-data:Entity-gadam,
        askg-data:Entity-generalisation,
        askg-data:Entity-lookahead,
        askg-data:Entity-optimisation .

askg-data:Paper-43d37e59d752bc41-Section-20-Paragraph-204-Sentence-2044 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As we will see in the next section, this theoretical insight is validated by the experiments and leads to combinable benefits."@en ;
    askg-onto:inSentence "As we will see in the next section, this theoretical insight is validated by the experiments and leads to combinable benefits."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-combinable_benefits,
        askg-data:Entity-experiments,
        askg-data:Entity-theoretical_insight .

askg-data:Paper-43d37e59d752bc41-Section-21 a askg-onto:Section ;
    rdfs:label "Section 21"@en ;
    domo:Text "Empirical Comparison"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-212,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-213,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-214,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-215,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-217 ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We make some empirical evaluations on CIFAR-100 dataset with different network architectures, and we use different base optimiser for Lookahead. For all experiments, we use the author-recommended default values of k = 5 (number of lookahead steps) and Î± = 0.5. We focus on the combination of Lookahead and adaptive optimisers, as this is the key focus of this paper, although we do include results with Lookahead with SGD as the base optimiser. We first test AdamW and SGD with and without Lookahead and the results are in Figure 9. Whilst SGD + LH outperforms SGD in final test accuracy by a rather significant margin in both architectures, Lookahead does not always lead to better final test accuracy in AdamW (although it does improve the convergence speed and reduce fluctuations in test error during training, which is unsurprising as EMA shares similar characteristics with IA in reducing sensitivity to gradient noise). On the other hand, it is clear that Gadam delivers both more significant and more consistent improvements over AdamW, both here and in the rest of the paper."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2111,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2112,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2113,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2114,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2115,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2116 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We make some empirical evaluations on CIFAR-100 dataset with different network architectures, and we use different base optimiser for Lookahead."@en ;
    askg-onto:inSentence "We make some empirical evaluations on CIFAR-100 dataset with different network architectures, and we use different base optimiser for Lookahead."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100_dataset,
        askg-data:Entity-different_base,
        askg-data:Entity-empirical_evaluations,
        askg-data:Entity-lookahead .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For all experiments, we use the author-recommended default values of k = 5 (number of lookahead steps) and Î± = 0.5."@en ;
    askg-onto:inSentence "For all experiments, we use the author-recommended default values of k = 5 (number of lookahead steps) and Î± = 0.5."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1__05,
        askg-data:Entity-default_values,
        askg-data:Entity-k__5 .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We focus on the combination of Lookahead and adaptive optimisers, as this is the key focus of this paper, although we do include results with Lookahead with SGD as the base optimiser."@en ;
    askg-onto:inSentence "We focus on the combination of Lookahead and adaptive optimisers, as this is the key focus of this paper, although we do include results with Lookahead with SGD as the base optimiser."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-lookahead,
        askg-data:Entity-lookahead_and_adaptive_optimisers,
        askg-data:Entity-sgd,
        askg-data:Entity-this_paper .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We first test AdamW and SGD with and without Lookahead and the results are in Figure 9."@en ;
    askg-onto:inSentence "We first test AdamW and SGD with and without Lookahead and the results are in Figure 9."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-figure_9,
        askg-data:Entity-lookahead,
        askg-data:Entity-results,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Whilst SGD + LH outperforms SGD in final test accuracy by a rather significant margin in both architectures, Lookahead does not always lead to better final test accuracy in AdamW (although it does improve the convergence speed and reduce fluctuations in test error during training, which is unsurprising as EMA shares similar characteristics with IA in reducing sensitivity to gradient noise)."@en ;
    askg-onto:inSentence "Whilst SGD + LH outperforms SGD in final test accuracy by a rather significant margin in both architectures, Lookahead does not always lead to better final test accuracy in AdamW (although it does improve the convergence speed and reduce fluctuations in test error during training, which is unsurprising as EMA shares similar characteristics with IA in reducing sensitivity to gradient noise)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence_speed,
        askg-data:Entity-ema,
        askg-data:Entity-final_test_accuracy,
        askg-data:Entity-gradient_noise,
        askg-data:Entity-ia,
        askg-data:Entity-lookahead,
        askg-data:Entity-sgd,
        askg-data:Entity-sgd__lh .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-211-Sentence-2116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "On the other hand, it is clear that Gadam delivers both more significant and more consistent improvements over AdamW, both here and in the rest of the paper."@en ;
    askg-onto:inSentence "On the other hand, it is clear that Gadam delivers both more significant and more consistent improvements over AdamW, both here and in the rest of the paper."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-gadam,
        askg-data:Entity-improvements .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-212 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "(a) VGG-16 (b) PRN-110"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-212-Sentence-2121 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-212-Sentence-2121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) VGG-16 (b) PRN-110"@en ;
    askg-onto:inSentence "(a) VGG-16 (b) PRN-110"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-prn-110,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-213 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-213-Sentence-2131 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-213-Sentence-2131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:inSentence "![12_image_0.png](12_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-datasets,
        askg-data:Entity-framework,
        askg-data:Entity-methods,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_concepts,
        askg-data:Entity-researcher,
        askg-data:Entity-results,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-system,
        askg-data:Entity-techniques,
        askg-data:Entity-tool .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-214 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Figure 9. Test accuracy of Lookahead in CIFAR-100 against number of epochs."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-214-Sentence-2141,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-214-Sentence-2142 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-214-Sentence-2141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 9."@en ;
    askg-onto:inSentence "Figure 9."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_9 .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-214-Sentence-2142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Test accuracy of Lookahead in CIFAR-100 against number of epochs."@en ;
    askg-onto:inSentence "Test accuracy of Lookahead in CIFAR-100 against number of epochs."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100,
        askg-data:Entity-lookahead,
        askg-data:Entity-number_of_epochs .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-215 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "13"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-215-Sentence-2151 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-215-Sentence-2151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "13"@en ;
    askg-onto:inSentence "13"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-13,
        askg-data:Entity-integer .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Nonetheless, we believe that Lookahead, being an easy-touse plug-in optimiser that clearly improves convergence speed, offers significant combinable potential with Gadam, which focuses on generalisation. Indeed, by using Lookahead *before* the 161st epoch where we start IA, and switching to IA *after* the starting point, we successfully combine Gadam and LH into a new optimiser which we term Gadam + LH. With reference to Figure 9, in VGG-16, Gadam + LH both converges at the fastest speed in all the optimisers tested and achieves a final test accuracy only marginally worse than Gadam (but still stronger than all others). On the other hand, in PRN-110, perhaps due to the specific architecture choice, the initial difference in convergence speed of all optimisers is minimal, but Gadam + LH clearly performs very promisingly in the end: it is not only stronger than our result without Lookahead in Figure 9(b), but also, by visual inspection, significantly stronger than the SGD + LH results on the same data-set and using the same architecture reported in the original Lookahead paper (Zhang et al., 2019b). Due to the fact that Lookahead is a very recent creation and our constraint on computational resources, we have not been able to fully test Gadam + LH on a wider range of problems."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2161,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2162,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2163,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2164,
        askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2165 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Nonetheless, we believe that Lookahead, being an easy-touse plug-in optimiser that clearly improves convergence speed, offers significant combinable potential with Gadam, which focuses on generalisation."@en ;
    askg-onto:inSentence "Nonetheless, we believe that Lookahead, being an easy-touse plug-in optimiser that clearly improves convergence speed, offers significant combinable potential with Gadam, which focuses on generalisation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence_speed,
        askg-data:Entity-gadam,
        askg-data:Entity-generalisation,
        askg-data:Entity-lookahead,
        askg-data:Entity-plug-in_optimiser .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Indeed, by using Lookahead *before* the 161st epoch where we start IA, and switching to IA *after* the starting point, we successfully combine Gadam and LH into a new optimiser which we term Gadam + LH."@en ;
    askg-onto:inSentence "Indeed, by using Lookahead *before* the 161st epoch where we start IA, and switching to IA *after* the starting point, we successfully combine Gadam and LH into a new optimiser which we term Gadam + LH."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-gadam__lh,
        askg-data:Entity-lh,
        askg-data:Entity-lookahead,
        askg-data:Entity-optimizer .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2163 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "With reference to Figure 9, in VGG-16, Gadam + LH both converges at the fastest speed in all the optimisers tested and achieves a final test accuracy only marginally worse than Gadam (but still stronger than all others)."@en ;
    askg-onto:inSentence "With reference to Figure 9, in VGG-16, Gadam + LH both converges at the fastest speed in all the optimisers tested and achieves a final test accuracy only marginally worse than Gadam (but still stronger than all others)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_others,
        askg-data:Entity-final_test_accuracy,
        askg-data:Entity-gadam,
        askg-data:Entity-gadam__lh,
        askg-data:Entity-model,
        askg-data:Entity-optimisers_tested,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2164 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "On the other hand, in PRN-110, perhaps due to the specific architecture choice, the initial difference in convergence speed of all optimisers is minimal, but Gadam + LH clearly performs very promisingly in the end: it is not only stronger than our result without Lookahead in Figure 9(b), but also, by visual inspection, significantly stronger than the SGD + LH results on the same data-set and using the same architecture reported in the original Lookahead paper (Zhang et al., 2019b)."@en ;
    askg-onto:inSentence "On the other hand, in PRN-110, perhaps due to the specific architecture choice, the initial difference in convergence speed of all optimisers is minimal, but Gadam + LH clearly performs very promisingly in the end: it is not only stronger than our result without Lookahead in Figure 9(b), but also, by visual inspection, significantly stronger than the SGD + LH results on the same data-set and using the same architecture reported in the original Lookahead paper (Zhang et al., 2019b)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam__lh,
        askg-data:Entity-lookahead_paper,
        askg-data:Entity-our_result_without_lookahead,
        askg-data:Entity-sgd__lh,
        askg-data:Entity-sgd__lh_results,
        askg-data:Entity-the_same_data-set,
        askg-data:Entity-very_promisingly,
        askg-data:Entity-zhang_et_al_2019b .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-216-Sentence-2165 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Due to the fact that Lookahead is a very recent creation and our constraint on computational resources, we have not been able to fully test Gadam + LH on a wider range of problems."@en ;
    askg-onto:inSentence "Due to the fact that Lookahead is a very recent creation and our constraint on computational resources, we have not been able to fully test Gadam + LH on a wider range of problems."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_wider_range_of_problems,
        askg-data:Entity-gadam__lh,
        askg-data:Entity-lookahead,
        askg-data:Entity-recent_creation .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-217 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Nonetheless, we believe that the results obtained here are encouraging, and should merit more in-depth investigations in the future works."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-217-Sentence-2171 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-21-Paragraph-217-Sentence-2171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Nonetheless, we believe that the results obtained here are encouraging, and should merit more in-depth investigations in the future works."@en ;
    askg-onto:inSentence "Nonetheless, we believe that the results obtained here are encouraging, and should merit more in-depth investigations in the future works."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-in-depth_investigations,
        askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-22 a askg-onto:Section ;
    rdfs:label "Section 22"@en ;
    domo:Text "A.3. Effect Of Frequency Of Averaging"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-222,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-224 ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "While we derive the theoretical bounds using Polyak-style averaging on every *iteration*, practically we average *much* less: we either average once per *epoch* similar to Izmailov et al. (2018), or select a rather arbitrary value such as averaging once per 100 iterations. The reason is both practical and theoretical: averaging much less leads to significant computational savings, and at the same time as we argued in Sections 2.1 and 2.2, on more independent iterates the benefit from averaging is better, because our theoretical assumptions on independence are more likely met in these situations. In this case, averaging less causes the iterates to be further apart and more independent, and thus fewer number of iterates is required to achieve the similar level of performance if less independent iterates are used. We verify this both on the language and the vision experiments using the identical setup as the main text. With reference to Figure 10(a), not only is the final perplexity very insensitive to averaging frequency (note that the y-axis scale is very small), it is also interesting that averaging *less* actually leads to a slightly better validation perplexity compared to schemes that, say, average every iteration. We see a similar picture emerges in Figure 10(b), where the despite of following very close trajectories, averaging every iteration gives a slightly worse testing performance compared to once an epoch and is also significantly more expensive (with a NVIDIA GeForce RTX 2080 Ti GPU, each epoch of training takes around 10s if we average once per epoch but averaging every iteration takes around 20s)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2211,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2212,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2213,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2214,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2215,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2216,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2217 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "While we derive the theoretical bounds using Polyak-style averaging on every *iteration*, practically we average *much* less: we either average once per *epoch* similar to Izmailov et al."@en ;
    askg-onto:inSentence "While we derive the theoretical bounds using Polyak-style averaging on every *iteration*, practically we average *much* less: we either average once per *epoch* similar to Izmailov et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average,
        askg-data:Entity-epoch,
        askg-data:Entity-iteration,
        askg-data:Entity-izmailov_et_al,
        askg-data:Entity-polyak-style_averaging .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2018), or select a rather arbitrary value such as averaging once per 100 iterations."@en ;
    askg-onto:inSentence "(2018), or select a rather arbitrary value such as averaging once per 100 iterations."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-100,
        askg-data:Entity-2018,
        askg-data:Entity-arbitrary_value,
        askg-data:Entity-iterations .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The reason is both practical and theoretical: averaging much less leads to significant computational savings, and at the same time as we argued in Sections 2.1 and 2.2, on more independent iterates the benefit from averaging is better, because our theoretical assumptions on independence are more likely met in these situations."@en ;
    askg-onto:inSentence "The reason is both practical and theoretical: averaging much less leads to significant computational savings, and at the same time as we argued in Sections 2.1 and 2.2, on more independent iterates the benefit from averaging is better, because our theoretical assumptions on independence are more likely met in these situations."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-computational_savings,
        askg-data:Entity-independent_iterates,
        askg-data:Entity-situations,
        askg-data:Entity-theoretical_assumptions .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In this case, averaging less causes the iterates to be further apart and more independent, and thus fewer number of iterates is required to achieve the similar level of performance if less independent iterates are used."@en ;
    askg-onto:inSentence "In this case, averaging less causes the iterates to be further apart and more independent, and thus fewer number of iterates is required to achieve the similar level of performance if less independent iterates are used."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging_less,
        askg-data:Entity-fewer_number_of_iterates,
        askg-data:Entity-further_apart,
        askg-data:Entity-iterates,
        askg-data:Entity-iterates_to_be_further_apart,
        askg-data:Entity-less_independent_iterates,
        askg-data:Entity-similar_level_of_performance .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We verify this both on the language and the vision experiments using the identical setup as the main text."@en ;
    askg-onto:inSentence "We verify this both on the language and the vision experiments using the identical setup as the main text."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-setup .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "With reference to Figure 10(a), not only is the final perplexity very insensitive to averaging frequency (note that the y-axis scale is very small), it is also interesting that averaging *less* actually leads to a slightly better validation perplexity compared to schemes that, say, average every iteration."@en ;
    askg-onto:inSentence "With reference to Figure 10(a), not only is the final perplexity very insensitive to averaging frequency (note that the y-axis scale is very small), it is also interesting that averaging *less* actually leads to a slightly better validation perplexity compared to schemes that, say, average every iteration."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-averaging_frequency,
        askg-data:Entity-better_validation_perplexity .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-221-Sentence-2217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We see a similar picture emerges in Figure 10(b), where the despite of following very close trajectories, averaging every iteration gives a slightly worse testing performance compared to once an epoch and is also significantly more expensive (with a NVIDIA GeForce RTX 2080 Ti GPU, each epoch of training takes around 10s if we average once per epoch but averaging every iteration takes around 20s)."@en ;
    askg-onto:inSentence "We see a similar picture emerges in Figure 10(b), where the despite of following very close trajectories, averaging every iteration gives a slightly worse testing performance compared to once an epoch and is also significantly more expensive (with a NVIDIA GeForce RTX 2080 Ti GPU, each epoch of training takes around 10s if we average once per epoch but averaging every iteration takes around 20s)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10s,
        askg-data:Entity-20s,
        askg-data:Entity-averaging_every_iteration,
        askg-data:Entity-averaging_once_an_epoch,
        askg-data:Entity-device,
        askg-data:Entity-each_epoch_of_training,
        askg-data:Entity-nvidia_geforce_rtx_2080_ti_gpu .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-222 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![12_image_1.png](12_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-222-Sentence-2221 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-222-Sentence-2221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![12_image_1.png](12_image_1.png)"@en ;
    askg-onto:inSentence "![12_image_1.png](12_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-company,
        askg-data:Entity-data_analysis,
        askg-data:Entity-healthcare,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-research_area,
        askg-data:Entity-researcher,
        askg-data:Entity-software,
        askg-data:Entity-study_on_neural_networks,
        askg-data:Entity-technology .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "(b) VGG-16 on CIFAR-100 Figure 10. Effect of different averaging frequencies on validation perplexity of Gadam on representative (a) Language and (b) Image classification tasks. Freq=n suggests averaging once per n iterations. freq=350 in (b) is equivalently averaging once per epoch."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2231,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2232,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2233,
        askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2234 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(b) VGG-16 on CIFAR-100 Figure 10."@en ;
    askg-onto:inSentence "(b) VGG-16 on CIFAR-100 Figure 10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Effect of different averaging frequencies on validation perplexity of Gadam on representative (a) Language and (b) Image classification tasks."@en ;
    askg-onto:inSentence "Effect of different averaging frequencies on validation perplexity of Gadam on representative (a) Language and (b) Image classification tasks."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging_frequencies,
        askg-data:Entity-gadam,
        askg-data:Entity-image_classification_tasks,
        askg-data:Entity-language_classification_tasks,
        askg-data:Entity-validation_perplexity .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Freq=n suggests averaging once per n iterations."@en ;
    askg-onto:inSentence "Freq=n suggests averaging once per n iterations."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging_once_per_n_iterations,
        askg-data:Entity-freq .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-223-Sentence-2234 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "freq=350 in (b) is equivalently averaging once per epoch."@en ;
    askg-onto:inSentence "freq=350 in (b) is equivalently averaging once per epoch."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging_once_per_epoch,
        askg-data:Entity-freq350 .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-224 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "(a) LSTM on PTB"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-224-Sentence-2241 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-22-Paragraph-224-Sentence-2241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) LSTM on PTB"@en ;
    askg-onto:inSentence "(a) LSTM on PTB"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lstm,
        askg-data:Entity-ptb .

askg-data:Paper-43d37e59d752bc41-Section-23 a askg-onto:Section ;
    rdfs:label "Section 23"@en ;
    domo:Text "A.4. Gadamauto Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233 ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Here we conduct preliminary experiments on GadamAuto, a variant of Gadam that uses a constant learning rate schedule and automatically determines the starting point of averaging and training termination - this is desirable as the optimiser both has fewer hyperparameters to tune and trains faster. We use VGG-16 network on CIFAR-100. For all experiments, we simply use a flat learning rate schedule. The results are shown in Table 6. We use a patience of 10 for both the determination of the averaging activation and early termination. We also include SWA experiments with SGD iterates."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2311,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2312,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2313,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2314,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2315,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2316 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Here we conduct preliminary experiments on GadamAuto, a variant of Gadam that uses a constant learning rate schedule and automatically determines the starting point of averaging and training termination - this is desirable as the optimiser both has fewer hyperparameters to tune and trains faster."@en ;
    askg-onto:inSentence "Here we conduct preliminary experiments on GadamAuto, a variant of Gadam that uses a constant learning rate schedule and automatically determines the starting point of averaging and training termination - this is desirable as the optimiser both has fewer hyperparameters to tune and trains faster."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constant_learning_rate_schedule,
        askg-data:Entity-faster,
        askg-data:Entity-fewer_hyperparameters_to_tune,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamauto,
        askg-data:Entity-optimizer,
        askg-data:Entity-starting_point_of_averaging,
        askg-data:Entity-training_termination .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We use VGG-16 network on CIFAR-100."@en ;
    askg-onto:inSentence "We use VGG-16 network on CIFAR-100."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100,
        askg-data:Entity-vgg-16_network .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For all experiments, we simply use a flat learning rate schedule."@en ;
    askg-onto:inSentence "For all experiments, we simply use a flat learning rate schedule."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-learning_rate_schedule .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The results are shown in Table 6."@en ;
    askg-onto:inSentence "The results are shown in Table 6."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We use a patience of 10 for both the determination of the averaging activation and early termination."@en ;
    askg-onto:inSentence "We use a patience of 10 for both the determination of the averaging activation and early termination."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10,
        askg-data:Entity-determination_of_the_averaging_activation,
        askg-data:Entity-early_termination,
        askg-data:Entity-patience .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-231-Sentence-2316 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We also include SWA experiments with SGD iterates."@en ;
    askg-onto:inSentence "We also include SWA experiments with SGD iterates."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-sgd_iterates,
        askg-data:Entity-swa_experiments .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "| Table 6. GadamAuto Test Performance at Termination. | | |-------------------------------------------------------|---------------| | OPTIMISER DATA\\-SET | TEST ACCURACY | | GADAM\\-AUTO CIFAR\\-100 | 75.39 | | SWA\\-AUTO CIFAR\\-100 | 73.93 |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232-Sentence-2321,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232-Sentence-2322,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232-Sentence-2323 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232-Sentence-2321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Table 6."@en ;
    askg-onto:inSentence "| Table 6."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_6,
        askg-data:Entity-triple_data .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232-Sentence-2322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "GadamAuto Test Performance at Termination."@en ;
    askg-onto:inSentence "GadamAuto Test Performance at Termination."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadamauto,
        askg-data:Entity-termination .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-232-Sentence-2323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "| | |-------------------------------------------------------|---------------| | OPTIMISER DATA\\-SET | TEST ACCURACY | | GADAM\\-AUTO CIFAR\\-100 | 75.39 | | SWA\\-AUTO CIFAR\\-100 | 73.93 |"@en ;
    askg-onto:inSentence "| | |-------------------------------------------------------|---------------| | OPTIMISER DATA\\-SET | TEST ACCURACY | | GADAM\\-AUTO CIFAR\\-100 | 75.39 | | SWA\\-AUTO CIFAR\\-100 | 73.93 |"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7393,
        askg-data:Entity-7539,
        askg-data:Entity-gadam-auto_cifar-100,
        askg-data:Entity-optimiser_data-set,
        askg-data:Entity-score,
        askg-data:Entity-swa-auto_cifar-100 .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "It can be seen that while automatic determination for averaging trigger and early termination work well for Gadam (GadamAuto posts a performance only marginally worse than the manually tuned Gadam), they lead to a rather significant deterioration in test in SWA (SWA-Auto performs worse than tuned SWA, and even worse than tuned SGD. See Table 3). This highlights the benefit of using adaptive optimiser as the base optimiser in IA, as the poor performance in SWA-Auto is likely attributed to the fact that SGD is much more hyperparameter-sensitive (to initial learning rate and learning rate schedule, for example. SWA-Auto uses a constant schedule, which is sub-optimal for SGD), and that validation performance often fluctuates more during training for SGD: SWA-Auto determines averaging point based on the number of epochs of validation accuracy stagnation. For a noisy training curve, averaging might be triggered too early; while this can be ameliorated by setting a higher patience, doing so will eventually defeat the purpose of using an automatic trigger. Both issues highlighted here are less serious in adaptive optimisation, which likely leads to the better performance of GadamAuto. Nonetheless, the fact that scheduled Gadam still outperforms GadamAuto suggests that there is still ample room of improvement to develop a truly automatic optimiser that performs as strong as or even stronger than tuned ones. One desirable alternative we propose for the future work is the integration of *Rectified Adam* (Liu et al., 2019), which is shown to be much more insensitive to choice of hyperparameter even compared to Adam."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2331,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2332,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2333,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2334,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2335,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2336,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2337,
        askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2338 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "It can be seen that while automatic determination for averaging trigger and early termination work well for Gadam (GadamAuto posts a performance only marginally worse than the manually tuned Gadam), they lead to a rather significant deterioration in test in SWA (SWA-Auto performs worse than tuned SWA, and even worse than tuned SGD."@en ;
    askg-onto:inSentence "It can be seen that while automatic determination for averaging trigger and early termination work well for Gadam (GadamAuto posts a performance only marginally worse than the manually tuned Gadam), they lead to a rather significant deterioration in test in SWA (SWA-Auto performs worse than tuned SWA, and even worse than tuned SGD."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-gadamauto,
        askg-data:Entity-swa,
        askg-data:Entity-tuned_sgd,
        askg-data:Entity-tuned_swa .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "See Table 3)."@en ;
    askg-onto:inSentence "See Table 3)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_3,
        askg-data:Entity-text .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This highlights the benefit of using adaptive optimiser as the base optimiser in IA, as the poor performance in SWA-Auto is likely attributed to the fact that SGD is much more hyperparameter-sensitive (to initial learning rate and learning rate schedule, for example."@en ;
    askg-onto:inSentence "This highlights the benefit of using adaptive optimiser as the base optimiser in IA, as the poor performance in SWA-Auto is likely attributed to the fact that SGD is much more hyperparameter-sensitive (to initial learning rate and learning rate schedule, for example."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimiser,
        askg-data:Entity-base_optimiser,
        askg-data:Entity-sgd,
        askg-data:Entity-swa-auto .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2334 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "SWA-Auto uses a constant schedule, which is sub-optimal for SGD), and that validation performance often fluctuates more during training for SGD: SWA-Auto determines averaging point based on the number of epochs of validation accuracy stagnation."@en ;
    askg-onto:inSentence "SWA-Auto uses a constant schedule, which is sub-optimal for SGD), and that validation performance often fluctuates more during training for SGD: SWA-Auto determines averaging point based on the number of epochs of validation accuracy stagnation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging_point,
        askg-data:Entity-constant_schedule,
        askg-data:Entity-fluctuates_more_during_training,
        askg-data:Entity-number_of_epochs_of_validation_accuracy_stagnation,
        askg-data:Entity-sgd,
        askg-data:Entity-swa-auto .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2335 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For a noisy training curve, averaging might be triggered too early; while this can be ameliorated by setting a higher patience, doing so will eventually defeat the purpose of using an automatic trigger."@en ;
    askg-onto:inSentence "For a noisy training curve, averaging might be triggered too early; while this can be ameliorated by setting a higher patience, doing so will eventually defeat the purpose of using an automatic trigger."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_trigger,
        askg-data:Entity-averaging,
        askg-data:Entity-averaging_trigger,
        askg-data:Entity-noise,
        askg-data:Entity-patience,
        askg-data:Entity-training_curve .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2336 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Both issues highlighted here are less serious in adaptive optimisation, which likely leads to the better performance of GadamAuto."@en ;
    askg-onto:inSentence "Both issues highlighted here are less serious in adaptive optimisation, which likely leads to the better performance of GadamAuto."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisation,
        askg-data:Entity-gadamauto .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2337 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Nonetheless, the fact that scheduled Gadam still outperforms GadamAuto suggests that there is still ample room of improvement to develop a truly automatic optimiser that performs as strong as or even stronger than tuned ones."@en ;
    askg-onto:inSentence "Nonetheless, the fact that scheduled Gadam still outperforms GadamAuto suggests that there is still ample room of improvement to develop a truly automatic optimiser that performs as strong as or even stronger than tuned ones."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_optimiser,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamauto,
        askg-data:Entity-strong_performance .

askg-data:Paper-43d37e59d752bc41-Section-23-Paragraph-233-Sentence-2338 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "One desirable alternative we propose for the future work is the integration of *Rectified Adam* (Liu et al., 2019), which is shown to be much more insensitive to choice of hyperparameter even compared to Adam."@en ;
    askg-onto:inSentence "One desirable alternative we propose for the future work is the integration of *Rectified Adam* (Liu et al., 2019), which is shown to be much more insensitive to choice of hyperparameter even compared to Adam."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-algorithm,
        askg-data:Entity-liu_et_al,
        askg-data:Entity-rectified_adam .

askg-data:Paper-43d37e59d752bc41-Section-24 a askg-onto:Section ;
    rdfs:label "Section 24"@en ;
    domo:Text "A.5. Applicability Of Theoretical Analysis"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-24-Paragraph-241 ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-24-Paragraph-241 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In the main text, we make the claim that despite of using pure, non-adaptive gradient descent as the analysis tool for derivations of our theoretical results, the results apply in adaptive optimisation. Here we substantiate that claim by establishing the applicability of our arguments in Sections 2 and 3 to adaptive optimisation, both theoretically and experimentally."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-24-Paragraph-241-Sentence-2411,
        askg-data:Paper-43d37e59d752bc41-Section-24-Paragraph-241-Sentence-2412 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-24-Paragraph-241-Sentence-2411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the main text, we make the claim that despite of using pure, non-adaptive gradient descent as the analysis tool for derivations of our theoretical results, the results apply in adaptive optimisation."@en ;
    askg-onto:inSentence "In the main text, we make the claim that despite of using pure, non-adaptive gradient descent as the analysis tool for derivations of our theoretical results, the results apply in adaptive optimisation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisation,
        askg-data:Entity-analysis_tool,
        askg-data:Entity-gradient_descent,
        askg-data:Entity-theoretical_results .

askg-data:Paper-43d37e59d752bc41-Section-24-Paragraph-241-Sentence-2412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here we substantiate that claim by establishing the applicability of our arguments in Sections 2 and 3 to adaptive optimisation, both theoretically and experimentally."@en ;
    askg-onto:inSentence "Here we substantiate that claim by establishing the applicability of our arguments in Sections 2 and 3 to adaptive optimisation, both theoretically and experimentally."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisation,
        askg-data:Entity-theoretically_and_experimentally .

askg-data:Paper-43d37e59d752bc41-Section-25 a askg-onto:Section ;
    rdfs:label "Section 25"@en ;
    domo:Text "On Expected Loss From Averaging"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-251,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-2510,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-252,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-254,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-255,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-256,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-258,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259 ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-251 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "On our analysis on the quadratic optimisation with noisy gradients, we first argue that with IA there is an asymptotic equivalence between SGD and adaptive methods, and therefore all our theoretical results in Section 2.1 hold. In Martens (2014), the authors derive general bounds on the loss of a noisy quadratic and show that, for methods that precondition the gradient with a non-identity matrix Bâˆ’1 (including adaptive methods such as Adam), for a fixed step size Î± the n-th iterate and the average of the iterates will tend to losses EL(wn), EL(wavg,n) respectively:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-251-Sentence-2511,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-251-Sentence-2512 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-251-Sentence-2511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "On our analysis on the quadratic optimisation with noisy gradients, we first argue that with IA there is an asymptotic equivalence between SGD and adaptive methods, and therefore all our theoretical results in Section 2.1 hold."@en ;
    askg-onto:inSentence "On our analysis on the quadratic optimisation with noisy gradients, we first argue that with IA there is an asymptotic equivalence between SGD and adaptive methods, and therefore all our theoretical results in Section 2.1 hold."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-concept,
        askg-data:Entity-quadratic_optimisation,
        askg-data:Entity-section_21,
        askg-data:Entity-sgd,
        askg-data:Entity-theoretical_results .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-251-Sentence-2512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In Martens (2014), the authors derive general bounds on the loss of a noisy quadratic and show that, for methods that precondition the gradient with a non-identity matrix Bâˆ’1 (including adaptive methods such as Adam), for a fixed step size Î± the n-th iterate and the average of the iterates will tend to losses EL(wn), EL(wavg,n) respectively:"@en ;
    askg-onto:inSentence "In Martens (2014), the authors derive general bounds on the loss of a noisy quadratic and show that, for methods that precondition the gradient with a non-identity matrix Bâˆ’1 (including adaptive methods such as Adam), for a fixed step size Î± the n-th iterate and the average of the iterates will tend to losses EL(wn), EL(wavg,n) respectively:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods_such_as_adam,
        askg-data:Entity-average_of_the_iterates,
        askg-data:Entity-general_bounds_on_the_loss_of_a_noisy_quadratic,
        askg-data:Entity-losses_elwavgn,
        askg-data:Entity-losses_elwn,
        askg-data:Entity-martens_2014,
        askg-data:Entity-methods_that_precondition_the_gradient_with_a_non-identity_matrix_b1,
        askg-data:Entity-n-th_iterate .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-2510 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "conditioning by $\\boldsymbol{H}^{-1/2}$ could lead to $||\\boldsymbol{w}_0||<\\boldsymbol{w}^{-1/2}||<||\\boldsymbol{H}^{-1/2}(\\boldsymbol{w}_0^{\\rm SGD}-\\boldsymbol{w}^*)||$ and as a result, $\\mathbb{E}\\bigg(L(\\boldsymbol{w}_{\\rm avg,n}^{\\rm Adam})\\bigg)<\\boldsymbol{w}_0$. $\\big{(}\\boldsymbol{w}_{\\rm avg,n}^{\\rm Adam}\\big{)}$ $$\\mathbb{E}\\bigg(L(\\mathbf{w}_{\\mathrm{avg,n}}^{\\mathrm{SGD}})\\bigg).$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-2510-Sentence-25101,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-2510-Sentence-25102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-2510-Sentence-25101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "conditioning by $\\boldsymbol{H}^{-1/2}$ could lead to $||\\boldsymbol{w}_0||<\\boldsymbol{w}^{-1/2}||<||\\boldsymbol{H}^{-1/2}(\\boldsymbol{w}_0^{\\rm SGD}-\\boldsymbol{w}^*)||$ and as a result, $\\mathbb{E}\\bigg(L(\\boldsymbol{w}_{\\rm avg,n}^{\\rm Adam})\\bigg)<\\boldsymbol{w}_0$."@en ;
    askg-onto:inSentence "conditioning by $\\boldsymbol{H}^{-1/2}$ could lead to $||\\boldsymbol{w}_0||<\\boldsymbol{w}^{-1/2}||<||\\boldsymbol{H}^{-1/2}(\\boldsymbol{w}_0^{\\rm SGD}-\\boldsymbol{w}^*)||$ and as a result, $\\mathbb{E}\\bigg(L(\\boldsymbol{w}_{\\rm avg,n}^{\\rm Adam})\\bigg)<\\boldsymbol{w}_0$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-oldsymbolh-12,
        askg-data:Entity-oldsymbolw-12oldsymbolh-12oldsymbolw_0%0Dm_sgd-oldsymbolw,
        askg-data:Entity-oldsymbolw_%0Dm_avgn%0Dm_adam,
        askg-data:Entity-oldsymbolw_0 .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-2510-Sentence-25102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "$\\big{(}\\boldsymbol{w}_{\\rm avg,n}^{\\rm Adam}\\big{)}$ $$\\mathbb{E}\\bigg(L(\\mathbf{w}_{\\mathrm{avg,n}}^{\\mathrm{SGD}})\\bigg).$$"@en ;
    askg-onto:inSentence "$\\big{(}\\boldsymbol{w}_{\\rm avg,n}^{\\rm Adam}\\big{)}$ $$\\mathbb{E}\\bigg(L(\\mathbf{w}_{\\mathrm{avg,n}}^{\\mathrm{SGD}})\\bigg).$$"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elw_avgnsgd,
        askg-data:Entity-w_avgnadam .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-252 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{\\alpha}{4}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))$$ $$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{\\text{avg},n})\\bigg{)}$$ $$\\leq L(\\mathbf{w}^{*})+\\min\\bigg{(}\\frac{1}{n+1}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})),\\frac{\\alpha}{2}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})\\bigg{)}\\bigg{)}\\tag{5}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-252-Sentence-2521 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-252-Sentence-2521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{\\alpha}{4}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))$$ $$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{\\text{avg},n})\\bigg{)}$$ $$\\leq L(\\mathbf{w}^{*})+\\min\\bigg{(}\\frac{1}{n+1}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})),\\frac{\\alpha}{2}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})\\bigg{)}\\bigg{)}\\tag{5}$$"@en ;
    askg-onto:inSentence "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{\\alpha}{4}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))$$ $$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{\\text{avg},n})\\bigg{)}$$ $$\\leq L(\\mathbf{w}^{*})+\\min\\bigg{(}\\frac{1}{n+1}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})),\\frac{\\alpha}{2}\\text{Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})\\bigg{)}\\bigg{)}\\tag{5}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lw__%CE%B14trb-1%CF%83_gw,
        askg-data:Entity-lw__min1n1trb-1%CF%83_gw_%CE%B12trb-1%CF%83_gw,
        askg-data:Entity-lw_avgn,
        askg-data:Entity-lw_n .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "where wâˆ—is the optimal point and Î£g(wâˆ—) is the covariance of the gradients at that point, and H is the (surrogate of) the Hessian matrix. This is to be contrasted to the pure SGD case, where the two losses are stated in equation 17. Hence, in the limit n â†’ âˆž, for both non-adaptive and adaptive methods EL(w*avg,n*)) tends to the minimum whereas E(L(wn)) does not5. Further, we note that the asymptotic limit is independent of B and Î±, so the result for adaptive optimisers and non-adaptive optimisers is identical for averaging in the asymptotic limit. Beyond the asymptotic equivalence, in fact we argue that with some mild assumptions, in some circumstances averaging iterates of adaptive methods could lead to even better expected loss bound during training. Formally, from Martens (2014), suppose we start averaging at a point w0 in the weight space that is different from minimum wâˆ—, the difference between the expected loss at the average of iterates E(w*avg,n*) and the loss at minimum L(wâˆ—) is given by:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2531,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2532,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2533,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2534,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2535,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2536 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where wâˆ—is the optimal point and Î£g(wâˆ—) is the covariance of the gradients at that point, and H is the (surrogate of) the Hessian matrix."@en ;
    askg-onto:inSentence "where wâˆ—is the optimal point and Î£g(wâˆ—) is the covariance of the gradients at that point, and H is the (surrogate of) the Hessian matrix."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%83gw,
        askg-data:Entity-h,
        askg-data:Entity-the_covariance_of_the_gradients,
        askg-data:Entity-the_hessian_matrix,
        askg-data:Entity-the_optimal_point,
        askg-data:Entity-w .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This is to be contrasted to the pure SGD case, where the two losses are stated in equation 17."@en ;
    askg-onto:inSentence "This is to be contrasted to the pure SGD case, where the two losses are stated in equation 17."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equation_17,
        askg-data:Entity-losses,
        askg-data:Entity-pure_sgd_case,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Hence, in the limit n â†’ âˆž, for both non-adaptive and adaptive methods EL(w*avg,n*)) tends to the minimum whereas E(L(wn)) does not5."@en ;
    askg-onto:inSentence "Hence, in the limit n â†’ âˆž, for both non-adaptive and adaptive methods EL(w*avg,n*)) tends to the minimum whereas E(L(wn)) does not5."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elwavgn,
        askg-data:Entity-elwn,
        askg-data:Entity-minimum .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Further, we note that the asymptotic limit is independent of B and Î±, so the result for adaptive optimisers and non-adaptive optimisers is identical for averaging in the asymptotic limit."@en ;
    askg-onto:inSentence "Further, we note that the asymptotic limit is independent of B and Î±, so the result for adaptive optimisers and non-adaptive optimisers is identical for averaging in the asymptotic limit."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1,
        askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-asymptotic_limit,
        askg-data:Entity-averaging,
        askg-data:Entity-b,
        askg-data:Entity-non-adaptive_optimisers,
        askg-data:Entity-result .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2535 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Beyond the asymptotic equivalence, in fact we argue that with some mild assumptions, in some circumstances averaging iterates of adaptive methods could lead to even better expected loss bound during training."@en ;
    askg-onto:inSentence "Beyond the asymptotic equivalence, in fact we argue that with some mild assumptions, in some circumstances averaging iterates of adaptive methods could lead to even better expected loss bound during training."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-better_expected_loss_bound .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-253-Sentence-2536 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Formally, from Martens (2014), suppose we start averaging at a point w0 in the weight space that is different from minimum wâˆ—, the difference between the expected loss at the average of iterates E(w*avg,n*) and the loss at minimum L(wâˆ—) is given by:"@en ;
    askg-onto:inSentence "Formally, from Martens (2014), suppose we start averaging at a point w0 in the weight space that is different from minimum wâˆ—, the difference between the expected loss at the average of iterates E(w*avg,n*) and the loss at minimum L(wâˆ—) is given by:"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm_optimization,
        askg-data:Entity-average_of_iterates,
        askg-data:Entity-expected_loss,
        askg-data:Entity-loss_at_minimum,
        askg-data:Entity-loss_at_minimum_lw,
        askg-data:Entity-martens_2014,
        askg-data:Entity-minimum_w,
        askg-data:Entity-study_on_expected_loss,
        askg-data:Entity-weight_space .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-254 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w_{\\rm avg,n}})\\bigg{)}-L(\\mathbf{w}^{*})$$ $$\\leq\\min\\bigg{(}\\frac{1}{n+1}{\\rm Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})),\\frac{\\alpha}{2}{\\rm Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))\\bigg{)}$$ $$+\\min\\bigg{(}\\frac{1}{(n+1)^{2}\\alpha^{2}}||\\mathbf{H}^{-1/2}\\mathbf{B}(\\mathbf{w_{0}}-\\mathbf{w}^{*})||^{2},$$ $$\\frac{1}{(n+1)\\alpha}||\\mathbf{B}^{1/2}(\\mathbf{w_{0}}-\\mathbf{w}^{*})||^{2},3L(\\mathbf{w_{0}})\\bigg{)}\\tag{6}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-254-Sentence-2541 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-254-Sentence-2541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w_{\\rm avg,n}})\\bigg{)}-L(\\mathbf{w}^{*})$$ $$\\leq\\min\\bigg{(}\\frac{1}{n+1}{\\rm Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*})),\\frac{\\alpha}{2}{\\rm Tr}(\\mathbf{B}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))\\bigg{)}$$ $$+\\min\\bigg{(}\\frac{1}{(n+1)^{2}\\alpha^{2}}||\\mathbf{H}^{-1/2}\\mathbf{B}(\\mathbf{w_{0}}-\\mathbf{w}^{*})||^{2},$$ $$\\frac{1}{(n+1)\\alpha}||\\mathbf{B}^{1/2}(\\mathbf{w_{0}}-\\mathbf{w}^{*})||^{2},3L(\\mathbf{w_{0}})\\bigg{)}\\tag{6}$$"@en ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-255 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "5the discussion on pure SGD case is used for proof of Theorem 2. See Appendix E 14 For SGD, we have B = I, and thus Equation 6 reduces to"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-255-Sentence-2551,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-255-Sentence-2552 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-255-Sentence-2551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "5the discussion on pure SGD case is used for proof of Theorem 2."@en ;
    askg-onto:inSentence "5the discussion on pure SGD case is used for proof of Theorem 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-sgd,
        askg-data:Entity-theorem_2 .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-255-Sentence-2552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "See Appendix E 14 For SGD, we have B = I, and thus Equation 6 reduces to"@en ;
    askg-onto:inSentence "See Appendix E 14 For SGD, we have B = I, and thus Equation 6 reduces to"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b__i,
        askg-data:Entity-equation_6,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-256 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{\\text{avg},\\text{n}}^{\\text{SGD}})\\bigg{)}-L(\\mathbf{w}^{*})$$ $$\\leq\\frac{\\text{Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))}{n+1}+\\frac{||\\mathbf{H}^{-1/2}(\\mathbf{w}_{0}^{\\text{SGD}}-\\mathbf{w}^{*})||^{2}}{(n+1)^{2}\\alpha^{2}}\\tag{7}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-256-Sentence-2561 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-256-Sentence-2561 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{\\text{avg},\\text{n}}^{\\text{SGD}})\\bigg{)}-L(\\mathbf{w}^{*})$$ $$\\leq\\frac{\\text{Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))}{n+1}+\\frac{||\\mathbf{H}^{-1/2}(\\mathbf{w}_{0}^{\\text{SGD}}-\\mathbf{w}^{*})||^{2}}{(n+1)^{2}\\alpha^{2}}\\tag{7}$$"@en ;
    askg-onto:inSentence "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{\\text{avg},\\text{n}}^{\\text{SGD}})\\bigg{)}-L(\\mathbf{w}^{*})$$ $$\\leq\\frac{\\text{Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))}{n+1}+\\frac{||\\mathbf{H}^{-1/2}(\\mathbf{w}_{0}^{\\text{SGD}}-\\mathbf{w}^{*})||^{2}}{(n+1)^{2}\\alpha^{2}}\\tag{7}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alpha,
        askg-data:Entity-h-12w_0sgd-w2,
        askg-data:Entity-lw,
        askg-data:Entity-lw_avgnsgd,
        askg-data:Entity-n,
        askg-data:Entity-trh-1sigma_gw .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "On the other hand, adaptive methods has general update rule wn+1 â† w âˆ’ Î±Bâˆ’1âˆ‡Lw, where the inverse of the pre-conditioning matrix Bâˆ’1is generally intractable and is often approximated by diag(Bâˆ’1) (Duchi et al., 2011). Kingma & Ba (2014) argues that for Adam, the pre-conditioning matrix approximates the square root of the diagonals of the Fisher Information Matrix, a positivesemidefinite surrogate of Hessian H. Therefore, along these arguments, we assume that in Adam B â‰ˆ H1/2. This yields,"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2571,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2572,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2573,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2574 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2571 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "On the other hand, adaptive methods has general update rule wn+1 â† w âˆ’ Î±Bâˆ’1âˆ‡Lw, where the inverse of the pre-conditioning matrix Bâˆ’1is generally intractable and is often approximated by diag(Bâˆ’1) (Duchi et al., 2011)."@en ;
    askg-onto:inSentence "On the other hand, adaptive methods has general update rule wn+1 â† w âˆ’ Î±Bâˆ’1âˆ‡Lw, where the inverse of the pre-conditioning matrix Bâˆ’1is generally intractable and is often approximated by diag(Bâˆ’1) (Duchi et al., 2011)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-diagb1,
        askg-data:Entity-duchi_et_al,
        askg-data:Entity-general_update_rule_wn1__w__%CE%B1b1lw,
        askg-data:Entity-inverse_of_the_pre-conditioning_matrix_b1 .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2572 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Kingma & Ba (2014) argues that for Adam, the pre-conditioning matrix approximates the square root of the diagonals of the Fisher Information Matrix, a positivesemidefinite surrogate of Hessian H."@en ;
    askg-onto:inSentence "Kingma & Ba (2014) argues that for Adam, the pre-conditioning matrix approximates the square root of the diagonals of the Fisher Information Matrix, a positivesemidefinite surrogate of Hessian H."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-fisher_information_matrix,
        askg-data:Entity-kingma__ba,
        askg-data:Entity-positivesemidefinite_surrogate_of_hessian_h,
        askg-data:Entity-square_root_of_the_diagonals_of_the_fisher_information_matrix .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2573 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Therefore, along these arguments, we assume that in Adam B â‰ˆ H1/2."@en ;
    askg-onto:inSentence "Therefore, along these arguments, we assume that in Adam B â‰ˆ H1/2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam_b,
        askg-data:Entity-h12 .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-257-Sentence-2574 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This yields,"@en ;
    askg-onto:inSentence "This yields,"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-result,
        askg-data:Entity-triple .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-258 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "$$\\begin{array}{l}{{\\mathbb{E}\\bigg(L(\\mathbf{w}_{\\mathrm{avg,n}}^{\\mathrm{Adam}})\\bigg)-L(\\mathbf{w}^{*})}}\\\\ {{\\leq\\frac{\\mathrm{Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))}{n+1}+\\frac{||\\mathbf{w}_{0}^{\\mathrm{Adam}}-\\mathbf{w}^{*}||^{2}}{(n+1)^{2}\\alpha^{2}}}}\\end{array}$$ $$(8)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-258-Sentence-2581 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-258-Sentence-2581 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{{\\mathbb{E}\\bigg(L(\\mathbf{w}_{\\mathrm{avg,n}}^{\\mathrm{Adam}})\\bigg)-L(\\mathbf{w}^{*})}}\\\\ {{\\leq\\frac{\\mathrm{Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))}{n+1}+\\frac{||\\mathbf{w}_{0}^{\\mathrm{Adam}}-\\mathbf{w}^{*}||^{2}}{(n+1)^{2}\\alpha^{2}}}}\\end{array}$$ $$(8)$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{{\\mathbb{E}\\bigg(L(\\mathbf{w}_{\\mathrm{avg,n}}^{\\mathrm{Adam}})\\bigg)-L(\\mathbf{w}^{*})}}\\\\ {{\\leq\\frac{\\mathrm{Tr}(\\mathbf{H}^{-1}\\Sigma_{g}(\\mathbf{w}^{*}))}{n+1}+\\frac{||\\mathbf{w}_{0}^{\\mathrm{Adam}}-\\mathbf{w}^{*}||^{2}}{(n+1)^{2}\\alpha^{2}}}}\\end{array}$$ $$(8)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lw_avgnadam,
        askg-data:Entity-trh-1%CF%83_gwn1__w_0adam-w2n12%CE%B12 .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "and therefore, the difference compared to the SGD regret bound is on the *noise-independent term*. With same number of iterations n, we expect ||wAdam 0 âˆ’wâˆ—|| < ||wSGD 0 âˆ’wâˆ—|| due to the faster convergence of Adam (In particular, as argued in the original Adam paper (Kingma & Ba, 2014), for sparse-bounded gradients, the regret and hence convergence bound derived in Appendix F is reduced from O( âˆšP n) to O(log P âˆšn)). Furthermore, as argued by Martens (2014), when H is ill-conditioned, ||wSGD 0 âˆ’ wâˆ—|| is likely to have large component in small eigenvalue directions, and the preconditioning by Hâˆ’1/2could lead to ||wAdam 0 âˆ’ wâˆ—|| <<"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259-Sentence-2591,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259-Sentence-2592,
        askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259-Sentence-2593 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259-Sentence-2591 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and therefore, the difference compared to the SGD regret bound is on the *noise-independent term*."@en ;
    askg-onto:inSentence "and therefore, the difference compared to the SGD regret bound is on the *noise-independent term*."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-noise-independent_term,
        askg-data:Entity-sgd_regret_bound .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259-Sentence-2592 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "With same number of iterations n, we expect ||wAdam 0 âˆ’wâˆ—|| < ||wSGD 0 âˆ’wâˆ—|| due to the faster convergence of Adam (In particular, as argued in the original Adam paper (Kingma & Ba, 2014), for sparse-bounded gradients, the regret and hence convergence bound derived in Appendix F is reduced from O( âˆšP n) to O(log P âˆšn))."@en ;
    askg-onto:inSentence "With same number of iterations n, we expect ||wAdam 0 âˆ’wâˆ—|| < ||wSGD 0 âˆ’wâˆ—|| due to the faster convergence of Adam (In particular, as argued in the original Adam paper (Kingma & Ba, 2014), for sparse-bounded gradients, the regret and hence convergence bound derived in Appendix F is reduced from O( âˆšP n) to O(log P âˆšn))."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-adam_paper,
        askg-data:Entity-convergence_bound,
        askg-data:Entity-kingma__ba,
        askg-data:Entity-o_p_n,
        askg-data:Entity-olog_p_n,
        askg-data:Entity-regret,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-25-Paragraph-259-Sentence-2593 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, as argued by Martens (2014), when H is ill-conditioned, ||wSGD 0 âˆ’ wâˆ—|| is likely to have large component in small eigenvalue directions, and the preconditioning by Hâˆ’1/2could lead to ||wAdam 0 âˆ’ wâˆ—|| <<"@en ;
    askg-onto:inSentence "Furthermore, as argued by Martens (2014), when H is ill-conditioned, ||wSGD 0 âˆ’ wâˆ—|| is likely to have large component in small eigenvalue directions, and the preconditioning by Hâˆ’1/2could lead to ||wAdam 0 âˆ’ wâˆ—|| <<"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h12,
        askg-data:Entity-h_is_ill-conditioned,
        askg-data:Entity-martens_2014,
        askg-data:Entity-small_eigenvalue_directions,
        askg-data:Entity-wadam_0__w,
        askg-data:Entity-wsgd_0__w .

askg-data:Paper-43d37e59d752bc41-Section-26 a askg-onto:Section ;
    rdfs:label "Section 26"@en ;
    domo:Text "On Regularising Effect"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261 ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "It is apparent that Theorem 3 is not specific on any particular choice of optimiser. Nonetheless, we empirically show it that in simple VGG-16 experiments on CIFAR-100 that the weight-reducing regularising effect is present in all optimisers with IA. The results are shown in Figure 11. It is also very interesting to see that although fully adaptive AdamW iterates initially lead to a very high L2 weight norm, with effective regularisation the optimiser nevertheless finds a L2 solution comparable to SGD/SWA eventually."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2611,
        askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2612,
        askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2613,
        askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2614 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "It is apparent that Theorem 3 is not specific on any particular choice of optimiser."@en ;
    askg-onto:inSentence "It is apparent that Theorem 3 is not specific on any particular choice of optimiser."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_particular_choice_of_optimiser,
        askg-data:Entity-theorem_3 .

askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Nonetheless, we empirically show it that in simple VGG-16 experiments on CIFAR-100 that the weight-reducing regularising effect is present in all optimisers with IA."@en ;
    askg-onto:inSentence "Nonetheless, we empirically show it that in simple VGG-16 experiments on CIFAR-100 that the weight-reducing regularising effect is present in all optimisers with IA."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-ia,
        askg-data:Entity-optimisers,
        askg-data:Entity-vgg-16,
        askg-data:Entity-weight-reducing_regularising_effect .

askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The results are shown in Figure 11."@en ;
    askg-onto:inSentence "The results are shown in Figure 11."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-26-Paragraph-261-Sentence-2614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "It is also very interesting to see that although fully adaptive AdamW iterates initially lead to a very high L2 weight norm, with effective regularisation the optimiser nevertheless finds a L2 solution comparable to SGD/SWA eventually."@en ;
    askg-onto:inSentence "It is also very interesting to see that although fully adaptive AdamW iterates initially lead to a very high L2 weight norm, with effective regularisation the optimiser nevertheless finds a L2 solution comparable to SGD/SWA eventually."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-l2_solution,
        askg-data:Entity-l2_weight_norm,
        askg-data:Entity-optimiser,
        askg-data:Entity-regularisation,
        askg-data:Entity-sgdswa .

askg-data:Paper-43d37e59d752bc41-Section-27 a askg-onto:Section ;
    rdfs:label "Section 27"@en ;
    domo:Text "On Local Geometry Of Mimina"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271 ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We repeat the experiments shown in Table 1, but replace SGD with AdamW and IA with Gadam. We again use the same VGG-16 network *without* batch normalisation on CIFAR-100, and in this case we set all initial learning rate to be 3Ã—10âˆ’4. For Adam, we run the usual learning rate schedule such that the terminal LR is 1 100 of the initial learning rate. For Gadam, we again start averaging at 161st epoch, with terminal learning rate {3 Ã— 10âˆ’4, 3 Ã— 10âˆ’5}, and decay the learning rate linearly when the terminal and initial learning rates differ. We present our results in Table 7. We observe that all remarks we make in Section 3.1 hold, and the result gives further evidence to our argument against the relevance of local geometry of minima in explaining the efficacy of averaging for generalisation: for example, compared to the SGD run in Table 1, the best performing Gadam run has 14Ã— larger spectral norm, 92Ã— larger Frobenius norm and 23Ã— larger Hessian trace, yet the test accuracy is only 0.39% worse."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2711,
        askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2712,
        askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2713,
        askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2714,
        askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2715,
        askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2716 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We repeat the experiments shown in Table 1, but replace SGD with AdamW and IA with Gadam."@en ;
    askg-onto:inSentence "We repeat the experiments shown in Table 1, but replace SGD with AdamW and IA with Gadam."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-gadam,
        askg-data:Entity-ia,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We again use the same VGG-16 network *without* batch normalisation on CIFAR-100, and in this case we set all initial learning rate to be 3Ã—10âˆ’4."@en ;
    askg-onto:inSentence "We again use the same VGG-16 network *without* batch normalisation on CIFAR-100, and in this case we set all initial learning rate to be 3Ã—10âˆ’4."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3104,
        askg-data:Entity-cifar-100,
        askg-data:Entity-initial_learning_rate,
        askg-data:Entity-vgg-16_network .

askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For Adam, we run the usual learning rate schedule such that the terminal LR is 1 100 of the initial learning rate."@en ;
    askg-onto:inSentence "For Adam, we run the usual learning rate schedule such that the terminal LR is 1 100 of the initial learning rate."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_100_of_the_initial_learning_rate,
        askg-data:Entity-adam,
        askg-data:Entity-learning_rate_schedule .

askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For Gadam, we again start averaging at 161st epoch, with terminal learning rate {3 Ã— 10âˆ’4, 3 Ã— 10âˆ’5}, and decay the learning rate linearly when the terminal and initial learning rates differ."@en ;
    askg-onto:inSentence "For Gadam, we again start averaging at 161st epoch, with terminal learning rate {3 Ã— 10âˆ’4, 3 Ã— 10âˆ’5}, and decay the learning rate linearly when the terminal and initial learning rates differ."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-161st_epoch,
        askg-data:Entity-3__104_3__105,
        askg-data:Entity-gadam,
        askg-data:Entity-learning_rate,
        askg-data:Entity-linearly .

askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We present our results in Table 7."@en ;
    askg-onto:inSentence "We present our results in Table 7."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-27-Paragraph-271-Sentence-2716 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We observe that all remarks we make in Section 3.1 hold, and the result gives further evidence to our argument against the relevance of local geometry of minima in explaining the efficacy of averaging for generalisation: for example, compared to the SGD run in Table 1, the best performing Gadam run has 14Ã— larger spectral norm, 92Ã— larger Frobenius norm and 23Ã— larger Hessian trace, yet the test accuracy is only 0.39% worse."@en ;
    askg-onto:inSentence "We observe that all remarks we make in Section 3.1 hold, and the result gives further evidence to our argument against the relevance of local geometry of minima in explaining the efficacy of averaging for generalisation: for example, compared to the SGD run in Table 1, the best performing Gadam run has 14Ã— larger spectral norm, 92Ã— larger Frobenius norm and 23Ã— larger Hessian trace, yet the test accuracy is only 0.39% worse."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-039,
        askg-data:Entity-frobenius_norm,
        askg-data:Entity-gadam,
        askg-data:Entity-gadam_run,
        askg-data:Entity-hessian_trace,
        askg-data:Entity-sgd_run,
        askg-data:Entity-spectral_norm,
        askg-data:Entity-test_accuracy .

askg-data:Paper-43d37e59d752bc41-Section-28 a askg-onto:Section ;
    rdfs:label "Section 28"@en ;
    domo:Text "B. Experiment Setup"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281 ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Unless otherwise stated, all experiments are run with Py- Torch 1.1 on Python 3.7 Anaconda environment with GPU acceleration. We use one of the three possible GPUs for our experiment: NVIDIA GeForce GTX 1080 Ti, GeForce RTX 2080 Ti or Tesla V100. We always use a single GPU for any single run of experiment."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281-Sentence-2811,
        askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281-Sentence-2812,
        askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281-Sentence-2813 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281-Sentence-2811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Unless otherwise stated, all experiments are run with Py- Torch 1.1 on Python 3.7 Anaconda environment with GPU acceleration."@en ;
    askg-onto:inSentence "Unless otherwise stated, all experiments are run with Py- Torch 1.1 on Python 3.7 Anaconda environment with GPU acceleration."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anaconda_environment,
        askg-data:Entity-gpu_acceleration,
        askg-data:Entity-python_37,
        askg-data:Entity-pytorch_11 .

askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281-Sentence-2812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We use one of the three possible GPUs for our experiment: NVIDIA GeForce GTX 1080 Ti, GeForce RTX 2080 Ti or Tesla V100."@en ;
    askg-onto:inSentence "We use one of the three possible GPUs for our experiment: NVIDIA GeForce GTX 1080 Ti, GeForce RTX 2080 Ti or Tesla V100."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geforce_rtx_2080_ti,
        askg-data:Entity-gpu,
        askg-data:Entity-nvidia_geforce_gtx_1080_ti,
        askg-data:Entity-tesla_v100 .

askg-data:Paper-43d37e59d752bc41-Section-28-Paragraph-281-Sentence-2813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We always use a single GPU for any single run of experiment."@en ;
    askg-onto:inSentence "We always use a single GPU for any single run of experiment."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiment,
        askg-data:Entity-gpu .

askg-data:Paper-43d37e59d752bc41-Section-29 a askg-onto:Section ;
    rdfs:label "Section 29"@en ;
    domo:Text "B.1. Validating Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292 ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Logistic Regression on MNIST For logistic regression on MNIST, we start with a learning rate of 0.1, and decay the learning rate by a factor of 10 at {40, 70}-th epochs. At each learning rate step, we also run iterate averaging concurrently (we average once per epoch similar to Izmailov et al. (2018)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291-Sentence-2911,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291-Sentence-2912,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291-Sentence-2913 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291-Sentence-2911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Logistic Regression on MNIST For logistic regression on MNIST, we start with a learning rate of 0.1, and decay the learning rate by a factor of 10 at {40, 70}-th epochs."@en ;
    askg-onto:inSentence "Logistic Regression on MNIST For logistic regression on MNIST, we start with a learning rate of 0.1, and decay the learning rate by a factor of 10 at {40, 70}-th epochs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-logistic_regression,
        askg-data:Entity-mnist .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291-Sentence-2912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "At each learning rate step, we also run iterate averaging concurrently (we average once per epoch similar to Izmailov et al."@en ;
    askg-onto:inSentence "At each learning rate step, we also run iterate averaging concurrently (we average once per epoch similar to Izmailov et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iterate_averaging,
        askg-data:Entity-izmailov_et_al,
        askg-data:Entity-learning_rate_step .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-291-Sentence-2913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2018)."@en ;
    askg-onto:inSentence "(2018)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "VGG-16 on CIFAR-100 In this expository experiment, we use the original VGG-16 *without* batch normalisation (batch normalisation has non-trivial impact on conventional measures of sharpness and flatness. See Li et al. (2018)). We conduct all experiments with initial learning rate 0.05. For fair comparison to previous literature, we use the linear decay schedules advocated in Izmailov et al. (2018), for both SGD and IA. For IA we run the set of terminal learning rates during averaging {0.03, 0.01, 0.003}, whereas for SGD we decay it linearly to 0.0005"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2921,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2922,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2923,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2924,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2925,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2926,
        askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2927 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "VGG-16 on CIFAR-100 In this expository experiment, we use the original VGG-16 *without* batch normalisation (batch normalisation has non-trivial impact on conventional measures of sharpness and flatness."@en ;
    askg-onto:inSentence "VGG-16 on CIFAR-100 In this expository experiment, we use the original VGG-16 *without* batch normalisation (batch normalisation has non-trivial impact on conventional measures of sharpness and flatness."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalisation,
        askg-data:Entity-cifar-100,
        askg-data:Entity-measures_of_sharpness_and_flatness,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "See Li et al."@en ;
    askg-onto:inSentence "See Li et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-li_et_al,
        askg-data:Entity-research .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2018))."@en ;
    askg-onto:inSentence "(2018))."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2924 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We conduct all experiments with initial learning rate 0.05."@en ;
    askg-onto:inSentence "We conduct all experiments with initial learning rate 0.05."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-initial_learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2925 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For fair comparison to previous literature, we use the linear decay schedules advocated in Izmailov et al."@en ;
    askg-onto:inSentence "For fair comparison to previous literature, we use the linear decay schedules advocated in Izmailov et al."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-izmailov_et_al,
        askg-data:Entity-linear_decay_schedules .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2926 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "(2018), for both SGD and IA."@en ;
    askg-onto:inSentence "(2018), for both SGD and IA."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-29-Paragraph-292-Sentence-2927 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "For IA we run the set of terminal learning rates during averaging {0.03, 0.01, 0.003}, whereas for SGD we decay it linearly to 0.0005"@en ;
    askg-onto:inSentence "For IA we run the set of terminal learning rates during averaging {0.03, 0.01, 0.003}, whereas for SGD we decay it linearly to 0.0005"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-00005,
        askg-data:Entity-003_001_0003,
        askg-data:Entity-sgd,
        askg-data:Entity-terminal_learning_rates .

askg-data:Paper-43d37e59d752bc41-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "1. Introduction"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34 ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Deep learning's success across a wide variety of tasks, from speech recognition to image classification, has drawn wideranging interest in their *optimisation*, which aims for effective and efficient training, and arguably more important generalisation, which aims to improve its ability to infer on the unseen data. Iterate averaging (IA) along the weight space trajectory, being an established technique in optimisation, has seen a resurgence of interest in deep learning recently, especially for generalisation. Izmailov et al. (2018); Maddox et al. (2019) propose Stochastic Weight Averaging (SWA) and its variant SWA-Gaussian, and have shown promising improvement in generalisation performance. Merity et al. (2017) adapts the classical Averaged Stochastic Gradient Descent (ASGD) (Bottou, 2012) to NT-ASGD, in which the point to start averaging is learned specifically for language modelling tasks. However, to our knowledge, its application has been limited to Stochastic Gradient Descent (SGD) only, and its mechanism of action has not been extensively investigated in the deep learning context. It is therefore of great interest on why it helps, and under what context will it help and not help. This forms the first part of this paper: We first take an alternative perspective from previous works to explore the effects of iterate averaging on both deep learning optimisation and regularisation. We then critically examine the commonly-held beliefs on why IA works, which revolve around the local geometry argument of the solution found. We demonstrate that at least in the simple examples we consider, such arguments might be only partially valid and relevant. Instead, we argue that it is the noise reducing effects of iterate averaging, which are particularly prevalent in the highly over-parameterised neural network regime, are at the root of its efficacy. We also compare and contrast IA with related but different averaging scheme, exponentially-weighted moving average."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-311,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3110,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3111,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3112,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3113,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3114,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-312,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-313,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-314,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-315,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-316,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-317,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-318,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-319 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Deep learning's success across a wide variety of tasks, from speech recognition to image classification, has drawn wideranging interest in their *optimisation*, which aims for effective and efficient training, and arguably more important generalisation, which aims to improve its ability to infer on the unseen data."@en ;
    askg-onto:inSentence "Deep learning's success across a wide variety of tasks, from speech recognition to image classification, has drawn wideranging interest in their *optimisation*, which aims for effective and efficient training, and arguably more important generalisation, which aims to improve its ability to infer on the unseen data."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ability_to_infer_on_unseen_data,
        askg-data:Entity-deep_learning,
        askg-data:Entity-effective_and_efficient_training,
        askg-data:Entity-generalisation,
        askg-data:Entity-optimisation .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "This forms the first part of this paper: We first take an alternative perspective from previous works to explore the effects of iterate averaging on both deep learning optimisation and regularisation."@en ;
    askg-onto:inSentence "This forms the first part of this paper: We first take an alternative perspective from previous works to explore the effects of iterate averaging on both deep learning optimisation and regularisation."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_optimisation,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-regularisation .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "We then critically examine the commonly-held beliefs on why IA works, which revolve around the local geometry argument of the solution found."@en ;
    askg-onto:inSentence "We then critically examine the commonly-held beliefs on why IA works, which revolve around the local geometry argument of the solution found."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-local_geometry_argument .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "We demonstrate that at least in the simple examples we consider, such arguments might be only partially valid and relevant."@en ;
    askg-onto:inSentence "We demonstrate that at least in the simple examples we consider, such arguments might be only partially valid and relevant."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arguments,
        askg-data:Entity-partially_valid_and_relevant .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Instead, we argue that it is the noise reducing effects of iterate averaging, which are particularly prevalent in the highly over-parameterised neural network regime, are at the root of its efficacy."@en ;
    askg-onto:inSentence "Instead, we argue that it is the noise reducing effects of iterate averaging, which are particularly prevalent in the highly over-parameterised neural network regime, are at the root of its efficacy."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-highly_over-parameterised_neural_network_regime,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-its_efficacy,
        askg-data:Entity-noise_reducing_effects .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-3114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "We also compare and contrast IA with related but different averaging scheme, exponentially-weighted moving average."@en ;
    askg-onto:inSentence "We also compare and contrast IA with related but different averaging scheme, exponentially-weighted moving average."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-exponentially-weighted_moving_average,
        askg-data:Entity-ia .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Iterate averaging (IA) along the weight space trajectory, being an established technique in optimisation, has seen a resurgence of interest in deep learning recently, especially for generalisation."@en ;
    askg-onto:inSentence "Iterate averaging (IA) along the weight space trajectory, being an established technique in optimisation, has seen a resurgence of interest in deep learning recently, especially for generalisation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-generalisation,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-optimisation .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Izmailov et al."@en ;
    askg-onto:inSentence "Izmailov et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-izmailov_et_al,
        askg-data:Entity-research_on_algorithms .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2018); Maddox et al."@en ;
    askg-onto:inSentence "(2018); Maddox et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-maddox_et_al .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2019) propose Stochastic Weight Averaging (SWA) and its variant SWA-Gaussian, and have shown promising improvement in generalisation performance."@en ;
    askg-onto:inSentence "(2019) propose Stochastic Weight Averaging (SWA) and its variant SWA-Gaussian, and have shown promising improvement in generalisation performance."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-improvement_in_generalisation_performance,
        askg-data:Entity-stochastic_weight_averaging,
        askg-data:Entity-swa-gaussian .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-316 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Merity et al."@en ;
    askg-onto:inSentence "Merity et al."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-merity_et_al,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-317 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "(2017) adapts the classical Averaged Stochastic Gradient Descent (ASGD) (Bottou, 2012) to NT-ASGD, in which the point to start averaging is learned specifically for language modelling tasks."@en ;
    askg-onto:inSentence "(2017) adapts the classical Averaged Stochastic Gradient Descent (ASGD) (Bottou, 2012) to NT-ASGD, in which the point to start averaging is learned specifically for language modelling tasks."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaged_stochastic_gradient_descent_asgd,
        askg-data:Entity-language_modelling_tasks,
        askg-data:Entity-nt-asgd .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-318 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "However, to our knowledge, its application has been limited to Stochastic Gradient Descent (SGD) only, and its mechanism of action has not been extensively investigated in the deep learning context."@en ;
    askg-onto:inSentence "However, to our knowledge, its application has been limited to Stochastic Gradient Descent (SGD) only, and its mechanism of action has not been extensively investigated in the deep learning context."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_context,
        askg-data:Entity-stochastic_gradient_descent_sgd .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-31-Sentence-319 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "It is therefore of great interest on why it helps, and under what context will it help and not help."@en ;
    askg-onto:inSentence "It is therefore of great interest on why it helps, and under what context will it help and not help."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-context,
        askg-data:Entity-it .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Adaptive optimisers, such as Adam (the most prolific) (Kingma & Ba, 2014), AdaDelta (Zeiler, 2012) and RM- Sprop (Tieleman & Hinton, 2012) are popular deep learning optimisers, but are known to generalise worse compared to SGD (Wilson et al., 2017) (We denote the difference in test accuracy between adaptive and non-adaptive methods the *generalisation difference*). Due to this, many state-ofthe-art models, especially for image classification datasets such as CIFAR (Yun et al., 2019) and ImageNet (Xie et al., 2019; Cubuk et al., 2019) are still trained using simple nonadaptive Stochastic Gradient Descent (SGD) with momentum (Nesterov, 2013). There has been much of the research interest to *explain* and *reduce* this difference: Wilson et al. (2017) argue that unlike adaptive optimisers, SGD finds better-generalising low L2 weight norm solutions; Zhang et al. (2018a) argue that SGD concentrates probability on better-generalising flat minima (Hochreiter & Schmidhuber, 1997; Keskar et al., 2016; Jastrzkebski et al., 2017)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-321,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-322,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-323,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-324,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-325 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Adaptive optimisers, such as Adam (the most prolific) (Kingma & Ba, 2014), AdaDelta (Zeiler, 2012) and RM- Sprop (Tieleman & Hinton, 2012) are popular deep learning optimisers, but are known to generalise worse compared to SGD (Wilson et al., 2017) (We denote the difference in test accuracy between adaptive and non-adaptive methods the *generalisation difference*)."@en ;
    askg-onto:inSentence "Adaptive optimisers, such as Adam (the most prolific) (Kingma & Ba, 2014), AdaDelta (Zeiler, 2012) and RM- Sprop (Tieleman & Hinton, 2012) are popular deep learning optimisers, but are known to generalise worse compared to SGD (Wilson et al., 2017) (We denote the difference in test accuracy between adaptive and non-adaptive methods the *generalisation difference*)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adadelta,
        askg-data:Entity-adam,
        askg-data:Entity-adaptive_optimiser,
        askg-data:Entity-difference_in_test_accuracy,
        askg-data:Entity-generalisation_difference,
        askg-data:Entity-kingma__ba_2014,
        askg-data:Entity-non-adaptive_method,
        askg-data:Entity-rm-sprop,
        askg-data:Entity-sgd,
        askg-data:Entity-tieleman__hinton_2012,
        askg-data:Entity-wilson_et_al_2017,
        askg-data:Entity-zeiler_2012 .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Due to this, many state-ofthe-art models, especially for image classification datasets such as CIFAR (Yun et al., 2019) and ImageNet (Xie et al., 2019; Cubuk et al., 2019) are still trained using simple nonadaptive Stochastic Gradient Descent (SGD) with momentum (Nesterov, 2013)."@en ;
    askg-onto:inSentence "Due to this, many state-ofthe-art models, especially for image classification datasets such as CIFAR (Yun et al., 2019) and ImageNet (Xie et al., 2019; Cubuk et al., 2019) are still trained using simple nonadaptive Stochastic Gradient Descent (SGD) with momentum (Nesterov, 2013)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-author,
        askg-data:Entity-cifar,
        askg-data:Entity-dataset,
        askg-data:Entity-imagenet,
        askg-data:Entity-nesterov,
        askg-data:Entity-stochastic_gradient_descent_sgd .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "There has been much of the research interest to *explain* and *reduce* this difference: Wilson et al."@en ;
    askg-onto:inSentence "There has been much of the research interest to *explain* and *reduce* this difference: Wilson et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-difference,
        askg-data:Entity-wilson_et_al .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2017) argue that unlike adaptive optimisers, SGD finds better-generalising low L2 weight norm solutions; Zhang et al."@en ;
    askg-onto:inSentence "(2017) argue that unlike adaptive optimisers, SGD finds better-generalising low L2 weight norm solutions; Zhang et al."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-low_l2_weight_norm_solutions,
        askg-data:Entity-sgd,
        askg-data:Entity-zhang_et_al .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-32-Sentence-325 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2018a) argue that SGD concentrates probability on better-generalising flat minima (Hochreiter & Schmidhuber, 1997; Keskar et al., 2016; Jastrzkebski et al., 2017)."@en ;
    askg-onto:inSentence "(2018a) argue that SGD concentrates probability on better-generalising flat minima (Hochreiter & Schmidhuber, 1997; Keskar et al., 2016; Jastrzkebski et al., 2017)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-better-generalising_flat_minima,
        askg-data:Entity-hochreiter__schmidhuber,
        askg-data:Entity-jastrzkebski_et_al,
        askg-data:Entity-keskar_et_al,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "*Equal contribution 1Machine Learning Research Group, University of Oxford, Oxford, UK. Correspondence to: Xingchen Wan , Diego Granziol . Keskar & Socher (2017) suggests dynamic switching between Adam and SGD; Chen & Gu (2018) suggests *Padam*, a partially adaptive optimiser uniting Adam and SGD. However, to our knowledge, there has not been a complete success to fully close the generalisation difference. Furthermore, many of the proposed solutions are heuristically motivated and often lack solid theoretical foundations. We hypothesise that proper *explicit regularisation* could be central to any fix of the problem: for example, Loshchilov & Hutter (2018) shows the in-equivalence between L2 regularisation and weight decay for adaptive methods, with use of the latter closing a large part, but not all, of the generalisation difference. However, even without any weight decay, there is still significant generalisation difference, which is often attributed to the implicit regularisation of SGD (Zhang et al., 2016). It is hence of interest to consider whether any form of explicit regularisation beyond weight decay can make adaptive methods competitive compared to SGD."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-331,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-332,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-333,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-334,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-335,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-336,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-337,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-338 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "*Equal contribution 1Machine Learning Research Group, University of Oxford, Oxford, UK."@en ;
    askg-onto:inSentence "*Equal contribution 1Machine Learning Research Group, University of Oxford, Oxford, UK."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-machine_learning_research_group,
        askg-data:Entity-university_of_oxford .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Correspondence to: Xingchen Wan , Diego Granziol ."@en ;
    askg-onto:inSentence "Correspondence to: Xingchen Wan , Diego Granziol ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-diego_granziol,
        askg-data:Entity-xingchen_wan .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Keskar & Socher (2017) suggests dynamic switching between Adam and SGD; Chen & Gu (2018) suggests *Padam*, a partially adaptive optimiser uniting Adam and SGD."@en ;
    askg-onto:inSentence "Keskar & Socher (2017) suggests dynamic switching between Adam and SGD; Chen & Gu (2018) suggests *Padam*, a partially adaptive optimiser uniting Adam and SGD."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-chen__gu,
        askg-data:Entity-dynamic_switching_between_adam_and_sgd,
        askg-data:Entity-keskar__socher,
        askg-data:Entity-padam,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-334 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, to our knowledge, there has not been a complete success to fully close the generalisation difference."@en ;
    askg-onto:inSentence "However, to our knowledge, there has not been a complete success to fully close the generalisation difference."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalisation_difference,
        askg-data:Entity-success .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-335 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Furthermore, many of the proposed solutions are heuristically motivated and often lack solid theoretical foundations."@en ;
    askg-onto:inSentence "Furthermore, many of the proposed solutions are heuristically motivated and often lack solid theoretical foundations."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristically_motivated,
        askg-data:Entity-proposed_solutions,
        askg-data:Entity-solid_theoretical_foundations .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-336 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We hypothesise that proper *explicit regularisation* could be central to any fix of the problem: for example, Loshchilov & Hutter (2018) shows the in-equivalence between L2 regularisation and weight decay for adaptive methods, with use of the latter closing a large part, but not all, of the generalisation difference."@en ;
    askg-onto:inSentence "We hypothesise that proper *explicit regularisation* could be central to any fix of the problem: for example, Loshchilov & Hutter (2018) shows the in-equivalence between L2 regularisation and weight decay for adaptive methods, with use of the latter closing a large part, but not all, of the generalisation difference."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-explicit_regularisation,
        askg-data:Entity-fix_of_the_problem,
        askg-data:Entity-generalisation_difference,
        askg-data:Entity-in-equivalence_between_l2_regularisation_and_weight_decay,
        askg-data:Entity-l2_regularisation,
        askg-data:Entity-loshchilov__hutter_2018,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-337 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "However, even without any weight decay, there is still significant generalisation difference, which is often attributed to the implicit regularisation of SGD (Zhang et al., 2016)."@en ;
    askg-onto:inSentence "However, even without any weight decay, there is still significant generalisation difference, which is often attributed to the implicit regularisation of SGD (Zhang et al., 2016)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-implicit_regularisation,
        askg-data:Entity-sgd,
        askg-data:Entity-significant_generalisation_difference,
        askg-data:Entity-zhang_et_al_2016 .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-33-Sentence-338 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "It is hence of interest to consider whether any form of explicit regularisation beyond weight decay can make adaptive methods competitive compared to SGD."@en ;
    askg-onto:inSentence "It is hence of interest to consider whether any form of explicit regularisation beyond weight decay can make adaptive methods competitive compared to SGD."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-explicit_regularisation,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "To the best of our knowledge, there has been little focus on using IA in adaptive methods to improve their generalisation, except for some very recent works (Zhang et al., 2019b). In this paper, we provide such a perspective, and argue that IA could actually provide regularisation benefits when used along with adaptive methods. Theoretically inspired, we then introduce **Gadam**, which combines Adam, decoupled weight decay and iterate averaging. We show that our algorithm consistently outperforms test performances of finely-tuned SGD and is competitive against SGD with iterate averaging, *without compromising adaptivity*, in image classification (CIFAR 10/100, ImageNet 32Ã—32) and natural language processing (Penn Treebank). We further show that by combining Gadam with partial adaptivity (which we term **GadamX**), empirical results can be further improved, to even outperform SGD with iterate averaging yet still converge faster."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-341,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-342,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-343,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-344,
        askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-345 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To the best of our knowledge, there has been little focus on using IA in adaptive methods to improve their generalisation, except for some very recent works (Zhang et al., 2019b)."@en ;
    askg-onto:inSentence "To the best of our knowledge, there has been little focus on using IA in adaptive methods to improve their generalisation, except for some very recent works (Zhang et al., 2019b)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-generalisation,
        askg-data:Entity-ia,
        askg-data:Entity-zhang_et_al_2019b .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In this paper, we provide such a perspective, and argue that IA could actually provide regularisation benefits when used along with adaptive methods."@en ;
    askg-onto:inSentence "In this paper, we provide such a perspective, and argue that IA could actually provide regularisation benefits when used along with adaptive methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_methods,
        askg-data:Entity-ia,
        askg-data:Entity-regularisation_benefits .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Theoretically inspired, we then introduce **Gadam**, which combines Adam, decoupled weight decay and iterate averaging."@en ;
    askg-onto:inSentence "Theoretically inspired, we then introduce **Gadam**, which combines Adam, decoupled weight decay and iterate averaging."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-decoupled_weight_decay,
        askg-data:Entity-gadam,
        askg-data:Entity-iterate_averaging .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-344 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We show that our algorithm consistently outperforms test performances of finely-tuned SGD and is competitive against SGD with iterate averaging, *without compromising adaptivity*, in image classification (CIFAR 10/100, ImageNet 32Ã—32) and natural language processing (Penn Treebank)."@en ;
    askg-onto:inSentence "We show that our algorithm consistently outperforms test performances of finely-tuned SGD and is competitive against SGD with iterate averaging, *without compromising adaptivity*, in image classification (CIFAR 10/100, ImageNet 32Ã—32) and natural language processing (Penn Treebank)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-cifar_10100,
        askg-data:Entity-dataset,
        askg-data:Entity-image_classification,
        askg-data:Entity-imagenet_3232,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-penn_treebank,
        askg-data:Entity-sgd,
        askg-data:Entity-sgd_with_iterate_averaging .

askg-data:Paper-43d37e59d752bc41-Section-3-Paragraph-34-Sentence-345 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We further show that by combining Gadam with partial adaptivity (which we term **GadamX**), empirical results can be further improved, to even outperform SGD with iterate averaging yet still converge faster."@en ;
    askg-onto:inSentence "We further show that by combining Gadam with partial adaptivity (which we term **GadamX**), empirical results can be further improved, to even outperform SGD with iterate averaging yet still converge faster."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-partial_adaptivity,
        askg-data:Entity-sgd,
        askg-data:Entity-sgd_with_iterate_averaging .

askg-data:Paper-43d37e59d752bc41-Section-30 a askg-onto:Section ;
    rdfs:label "Section 30"@en ;
    domo:Text "B.2. Image Classification Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-301,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3010,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3012,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3014,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-302,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-308,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-309 ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-301 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Hyperparameter Tuning In CIFAR experiments, we tune the base optimisers (i.e. SGD, Adam(W), Padam(W)) only, and assuming that the ideal hyperparameters in base optimisers apply to IA, and apply the same hyperparame15"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-301-Sentence-3011,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-301-Sentence-3012 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-301-Sentence-3011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Hyperparameter Tuning In CIFAR experiments, we tune the base optimisers (i.e."@en ;
    askg-onto:inSentence "Hyperparameter Tuning In CIFAR experiments, we tune the base optimisers (i.e."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-base_optimisers,
        askg-data:Entity-cifar,
        askg-data:Entity-concept,
        askg-data:Entity-dataset,
        askg-data:Entity-hyperparameter_tuning .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-301-Sentence-3012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "SGD, Adam(W), Padam(W)) only, and assuming that the ideal hyperparameters in base optimisers apply to IA, and apply the same hyperparame15"@en ;
    askg-onto:inSentence "SGD, Adam(W), Padam(W)) only, and assuming that the ideal hyperparameters in base optimisers apply to IA, and apply the same hyperparame15"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-base_optimisers,
        askg-data:Entity-hyperparameters,
        askg-data:Entity-ia,
        askg-data:Entity-optimization_algorithm,
        askg-data:Entity-padamw,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3010 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "| | | Table 8. Baseline Results from Previous Works | | |--------------------------|-----------|-------------------------------------------------|---------------------------| | NETWORK | OPTIMISER | ACCURACY/PERPLEXITY | REFERENCE | | CIFAR\\-100 | | | | | VGG\\-16 | SGD | 73.80 | (HUANG & WANG, 2018) | | VGG\\-16 | FGE | 74.26 | (IZMAILOV ET AL., 2018) | | PRN\\-164 | SGD | 75.67 | (HE ET AL., 2016) | | PRN\\-110 | SGD | 76.35 | ONLINE REPOSITORY** | | RESNET\\-164 | FGE | 79.84 | (IZMAILOV ET AL., 2018) | | RESNEXT\\-29 | SGD | 82.20 | (XIE ET AL., 2017) | | RESNEXT\\-29 | SGD | 81.47 | (BANSAL ET AL., 2018) | | CIFAR\\-10 | | | | | VGG\\-19 | SGD | 93.34 | ONLINE REPOSITORY** | | VGG\\-16 | SGD | 93.90 | (HUANG & WANG, 2018) | | PRN\\-110 | SGD | 93.63 | (HE ET AL., 2016) | | PRN\\-110 | SGD | 95.06 | ONLINE REPOSITORY** | | IMAGENET 32Ã—32 | | | | | WRN\\-28\\-10 | SGD | 59.04/81.13* | (CHRABASZCZ ET AL., 2017) | | MODIFIED WRN | SGD | 60.04/82.11* | (MCDONNELL, 2018) | | PTB | | | | | LSTM 3\\-LAYER | NT\\-ASGD | 61.2/58.8*** | (MERITY ET AL., 2017) | | NOTES: | | | | | * TOP\\-1/TOP\\-5 ACCURACY | | | |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3010-Sentence-30101,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3010-Sentence-30102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3010-Sentence-30101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | | Table 8."@en ;
    askg-onto:inSentence "| | | Table 8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-table_8 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3010-Sentence-30102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Baseline Results from Previous Works | | |--------------------------|-----------|-------------------------------------------------|---------------------------| | NETWORK | OPTIMISER | ACCURACY/PERPLEXITY | REFERENCE | | CIFAR\\-100 | | | | | VGG\\-16 | SGD | 73.80 | (HUANG & WANG, 2018) | | VGG\\-16 | FGE | 74.26 | (IZMAILOV ET AL., 2018) | | PRN\\-164 | SGD | 75.67 | (HE ET AL., 2016) | | PRN\\-110 | SGD | 76.35 | ONLINE REPOSITORY** | | RESNET\\-164 | FGE | 79.84 | (IZMAILOV ET AL., 2018) | | RESNEXT\\-29 | SGD | 82.20 | (XIE ET AL., 2017) | | RESNEXT\\-29 | SGD | 81.47 | (BANSAL ET AL., 2018) | | CIFAR\\-10 | | | | | VGG\\-19 | SGD | 93.34 | ONLINE REPOSITORY** | | VGG\\-16 | SGD | 93.90 | (HUANG & WANG, 2018) | | PRN\\-110 | SGD | 93.63 | (HE ET AL., 2016) | | PRN\\-110 | SGD | 95.06 | ONLINE REPOSITORY** | | IMAGENET 32Ã—32 | | | | | WRN\\-28\\-10 | SGD | 59.04/81.13* | (CHRABASZCZ ET AL., 2017) | | MODIFIED WRN | SGD | 60.04/82.11* | (MCDONNELL, 2018) | | PTB | | | | | LSTM 3\\-LAYER | NT\\-ASGD | 61.2/58.8*** | (MERITY ET AL., 2017) | | NOTES: | | | | | * TOP\\-1/TOP\\-5 ACCURACY | | | |"@en ;
    askg-onto:inSentence "Baseline Results from Previous Works | | |--------------------------|-----------|-------------------------------------------------|---------------------------| | NETWORK | OPTIMISER | ACCURACY/PERPLEXITY | REFERENCE | | CIFAR\\-100 | | | | | VGG\\-16 | SGD | 73.80 | (HUANG & WANG, 2018) | | VGG\\-16 | FGE | 74.26 | (IZMAILOV ET AL., 2018) | | PRN\\-164 | SGD | 75.67 | (HE ET AL., 2016) | | PRN\\-110 | SGD | 76.35 | ONLINE REPOSITORY** | | RESNET\\-164 | FGE | 79.84 | (IZMAILOV ET AL., 2018) | | RESNEXT\\-29 | SGD | 82.20 | (XIE ET AL., 2017) | | RESNEXT\\-29 | SGD | 81.47 | (BANSAL ET AL., 2018) | | CIFAR\\-10 | | | | | VGG\\-19 | SGD | 93.34 | ONLINE REPOSITORY** | | VGG\\-16 | SGD | 93.90 | (HUANG & WANG, 2018) | | PRN\\-110 | SGD | 93.63 | (HE ET AL., 2016) | | PRN\\-110 | SGD | 95.06 | ONLINE REPOSITORY** | | IMAGENET 32Ã—32 | | | | | WRN\\-28\\-10 | SGD | 59.04/81.13* | (CHRABASZCZ ET AL., 2017) | | MODIFIED WRN | SGD | 60.04/82.11* | (MCDONNELL, 2018) | | PTB | | | | | LSTM 3\\-LAYER | NT\\-ASGD | 61.2/58.8*** | (MERITY ET AL., 2017) | | NOTES: | | | | | * TOP\\-1/TOP\\-5 ACCURACY | | | |"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-59048113,
        askg-data:Entity-60048211,
        askg-data:Entity-612588,
        askg-data:Entity-7380,
        askg-data:Entity-7426,
        askg-data:Entity-7567,
        askg-data:Entity-7635,
        askg-data:Entity-9334,
        askg-data:Entity-9363,
        askg-data:Entity-9390,
        askg-data:Entity-9506,
        askg-data:Entity-cifar-10,
        askg-data:Entity-cifar-100,
        askg-data:Entity-fge,
        askg-data:Entity-huang__wang_2018,
        askg-data:Entity-imagenet_3232,
        askg-data:Entity-lstm_3-layer,
        askg-data:Entity-modified_wrn,
        askg-data:Entity-nt-asgd,
        askg-data:Entity-prn-110,
        askg-data:Entity-prn-164,
        askg-data:Entity-ptb,
        askg-data:Entity-sgd,
        askg-data:Entity-vgg-16,
        askg-data:Entity-vgg-19,
        askg-data:Entity-wrn-28-10 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "** LINK: H T T P S://G I T H U B.C O M/B E A R P A W/P Y T O R C H-C L A S S I F I C A T I O N *** VALIDATION/TEST PERPLEXITY where Î±0 is the initial learning rate. In the motivating logistic regression experiments on MNIST, we used T = 50. T = 300 is the total number of epochs budgeted for all CIFAR experiments, whereas we used T = 200 and 50 respectively for PRN-110 and WideResNet 28x10 in ImageNet. We set r = 0.01 for all experiments. For experiments with iterate averaging, we use the following learning rate schedule instead:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30111,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30112,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30113,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30114,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30115 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "** LINK: H T T P S://G I T H U B.C O M/B E A R P A W/P Y T O R C H-C L A S S I F I C A T I O N *** VALIDATION/TEST PERPLEXITY where Î±0 is the initial learning rate."@en ;
    askg-onto:inSentence "** LINK: H T T P S://G I T H U B.C O M/B E A R P A W/P Y T O R C H-C L A S S I F I C A T I O N *** VALIDATION/TEST PERPLEXITY where Î±0 is the initial learning rate."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B10,
        askg-data:Entity-framework,
        askg-data:Entity-pytorch,
        askg-data:Entity-validationtest_perplexity .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the motivating logistic regression experiments on MNIST, we used T = 50."@en ;
    askg-onto:inSentence "In the motivating logistic regression experiments on MNIST, we used T = 50."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-50,
        askg-data:Entity-logistic_regression_experiments,
        askg-data:Entity-mnist,
        askg-data:Entity-t .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "T = 300 is the total number of epochs budgeted for all CIFAR experiments, whereas we used T = 200 and 50 respectively for PRN-110 and WideResNet 28x10 in ImageNet."@en ;
    askg-onto:inSentence "T = 300 is the total number of epochs budgeted for all CIFAR experiments, whereas we used T = 200 and 50 respectively for PRN-110 and WideResNet 28x10 in ImageNet."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-200,
        askg-data:Entity-300,
        askg-data:Entity-50,
        askg-data:Entity-cifar,
        askg-data:Entity-imagenet,
        askg-data:Entity-prn-110,
        askg-data:Entity-wideresnet_28x10 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We set r = 0.01 for all experiments."@en ;
    askg-onto:inSentence "We set r = 0.01 for all experiments."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-001,
        askg-data:Entity-r .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3011-Sentence-30115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For experiments with iterate averaging, we use the following learning rate schedule instead:"@en ;
    askg-onto:inSentence "For experiments with iterate averaging, we use the following learning rate schedule instead:"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iterate_averaging,
        askg-data:Entity-method .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3012 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "$$\\alpha_{t}=\\begin{cases}\\alpha_{0},&\\text{if}\\frac{t}{T_{\\text{avg}}}\\leq0.5\\\\ \\alpha_{0}[1-\\frac{(1-\\frac{\\alpha_{\\text{avg}}}{\\alpha_{0}})(\\frac{t}{T}-0.5)}{0.4}]&\\text{if}0.5<\\frac{t}{T_{\\text{avg}}}\\leq0.9\\\\ \\alpha_{\\text{avg}},&\\text{otherwise}\\end{cases}\\tag{10}$$ $\\left(10\\right)$. where Î±avg refers to the (constant) learning rate after iterate averaging activation, and in this paper we set Î±avg = 1 2 Î±0."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3012-Sentence-30121,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3012-Sentence-30122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3012-Sentence-30121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\alpha_{t}=\\begin{cases}\\alpha_{0},&\\text{if}\\frac{t}{T_{\\text{avg}}}\\leq0.5\\\\ \\alpha_{0}[1-\\frac{(1-\\frac{\\alpha_{\\text{avg}}}{\\alpha_{0}})(\\frac{t}{T}-0.5)}{0.4}]&\\text{if}0.5<\\frac{t}{T_{\\text{avg}}}\\leq0.9\\\\ \\alpha_{\\text{avg}},&\\text{otherwise}\\end{cases}\\tag{10}$$ $\\left(10\\right)$."@en ;
    askg-onto:inSentence "$$\\alpha_{t}=\\begin{cases}\\alpha_{0},&\\text{if}\\frac{t}{T_{\\text{avg}}}\\leq0.5\\\\ \\alpha_{0}[1-\\frac{(1-\\frac{\\alpha_{\\text{avg}}}{\\alpha_{0}})(\\frac{t}{T}-0.5)}{0.4}]&\\text{if}0.5<\\frac{t}{T_{\\text{avg}}}\\leq0.9\\\\ \\alpha_{\\text{avg}},&\\text{otherwise}\\end{cases}\\tag{10}$$ $\\left(10\\right)$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1_01-1-%CE%B1_avg%CE%B1_0tt-0504_if_05__tt_avg__09,
        askg-data:Entity-%CE%B1_0_if_tt_avg__05,
        askg-data:Entity-%CE%B1_avg_otherwise,
        askg-data:Entity-%CE%B1_t .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3012-Sentence-30122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "where Î±avg refers to the (constant) learning rate after iterate averaging activation, and in this paper we set Î±avg = 1 2 Î±0."@en ;
    askg-onto:inSentence "where Î±avg refers to the (constant) learning rate after iterate averaging activation, and in this paper we set Î±avg = 1 2 Î±0."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1avg,
        askg-data:Entity-1_2_%CE%B10,
        askg-data:Entity-constant_learning_rate_after_iterate_averaging_activation .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "Tavg is the epoch after which iterate averaging is activated, and the methods to determine Tavg was described in the main text. This schedule allows us to adjust learning rate smoothly in the epochs leading up to iterate averaging activation through a similar linear decay mechanism in the experiments without iterate averaging, as described above. The only exception is the WRN experiments on ImageNet 32Ã—32, where we only run 50 epochs of training and start averaging from 30th epoch. We found that when using the schedule described above for the IA schedules (SWA/Gadam/GadamX), we start decay the learning rate too early and the final result is not satisfactory. Therefore, for this particular set of experiments, we use the same learning rate schedule for both averaged and normal optimisers."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30131,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30132,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30133,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30134,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30135 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Tavg is the epoch after which iterate averaging is activated, and the methods to determine Tavg was described in the main text."@en ;
    askg-onto:inSentence "Tavg is the epoch after which iterate averaging is activated, and the methods to determine Tavg was described in the main text."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iterate_averaging_is_activated,
        askg-data:Entity-methods_to_determine_tavg,
        askg-data:Entity-tavg,
        askg-data:Entity-the_main_text .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This schedule allows us to adjust learning rate smoothly in the epochs leading up to iterate averaging activation through a similar linear decay mechanism in the experiments without iterate averaging, as described above."@en ;
    askg-onto:inSentence "This schedule allows us to adjust learning rate smoothly in the epochs leading up to iterate averaging activation through a similar linear decay mechanism in the experiments without iterate averaging, as described above."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epochs,
        askg-data:Entity-experiments,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-iterate_averaging_activation,
        askg-data:Entity-learning_rate,
        askg-data:Entity-linear_decay .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The only exception is the WRN experiments on ImageNet 32Ã—32, where we only run 50 epochs of training and start averaging from 30th epoch."@en ;
    askg-onto:inSentence "The only exception is the WRN experiments on ImageNet 32Ã—32, where we only run 50 epochs of training and start averaging from 30th epoch."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30th_epoch,
        askg-data:Entity-averaging,
        askg-data:Entity-epochs,
        askg-data:Entity-imagenet_3232,
        askg-data:Entity-training,
        askg-data:Entity-wrn_experiments .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We found that when using the schedule described above for the IA schedules (SWA/Gadam/GadamX), we start decay the learning rate too early and the final result is not satisfactory."@en ;
    askg-onto:inSentence "We found that when using the schedule described above for the IA schedules (SWA/Gadam/GadamX), we start decay the learning rate too early and the final result is not satisfactory."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_result,
        askg-data:Entity-ia_schedules,
        askg-data:Entity-learning_rate,
        askg-data:Entity-swagadamgadamx .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3013-Sentence-30135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Therefore, for this particular set of experiments, we use the same learning rate schedule for both averaged and normal optimisers."@en ;
    askg-onto:inSentence "Therefore, for this particular set of experiments, we use the same learning rate schedule for both averaged and normal optimisers."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaged_and_normal_optimisers,
        askg-data:Entity-learning_rate_schedule .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3014 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "17 The only difference is that for IA experiments, we decay the learning rate until the 30th epoch and keep it fixed for the rest of the training."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3014-Sentence-30141 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-3014-Sentence-30141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "17 The only difference is that for IA experiments, we decay the learning rate until the 30th epoch and keep it fixed for the rest of the training."@en ;
    askg-onto:inSentence "17 The only difference is that for IA experiments, we decay the learning rate until the 30th epoch and keep it fixed for the rest of the training."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30th_epoch,
        askg-data:Entity-ia_experiments,
        askg-data:Entity-learning_rate,
        askg-data:Entity-rest_of_the_training .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-302 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-302-Sentence-3021 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-302-Sentence-3021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:inSentence "![15_image_0.png](15_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_concepts,
        askg-data:Entity-technology .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 11. Regularising Effect of IA in different optimisers. (c) reproduces Figure 3 but standardises the L2 norm axis for consistency. In all cases IA imposes additional regularisation."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3031,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3032,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3033,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3034 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 11."@en ;
    askg-onto:inSentence "Figure 11."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_representation,
        askg-data:Entity-figure_11 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3032 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Regularising Effect of IA in different optimisers."@en ;
    askg-onto:inSentence "Regularising Effect of IA in different optimisers."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimisers,
        askg-data:Entity-regularising_effect_of_ia .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3033 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(c) reproduces Figure 3 but standardises the L2 norm axis for consistency."@en ;
    askg-onto:inSentence "(c) reproduces Figure 3 but standardises the L2 norm axis for consistency."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l2_norm_axis .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-303-Sentence-3034 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In all cases IA imposes additional regularisation."@en ;
    askg-onto:inSentence "In all cases IA imposes additional regularisation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_regularisation,
        askg-data:Entity-ia .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Table 7. Performance and Hessian-based sharpness metrics of AdamW and Gadam experiments on CIFAR-100 using VGG-16. The numerical results for iterates of Gadam are in brackets."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304-Sentence-3041,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304-Sentence-3042,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304-Sentence-3043 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304-Sentence-3041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 7."@en ;
    askg-onto:inSentence "Table 7."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_7,
        askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304-Sentence-3042 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Performance and Hessian-based sharpness metrics of AdamW and Gadam experiments on CIFAR-100 using VGG-16."@en ;
    askg-onto:inSentence "Performance and Hessian-based sharpness metrics of AdamW and Gadam experiments on CIFAR-100 using VGG-16."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-algorithm,
        askg-data:Entity-cifar-100,
        askg-data:Entity-dataset,
        askg-data:Entity-gadam,
        askg-data:Entity-model,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-304-Sentence-3043 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The numerical results for iterates of Gadam are in brackets."@en ;
    askg-onto:inSentence "The numerical results for iterates of Gadam are in brackets."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-iterates .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "| OPTIMISER | TERMINAL LR | TRAIN ACC. | TEST ACC. | SPECTRAL NORM | FROBENIUS NORM | TRACE | |-------------|---------------|---------------|---------------|-----------------|--------------------|--------------------------| | ADAMW | 3 Ã— 10âˆ’6 | 99.93 | 69.43 | 62 | 9.3 Ã— 10âˆ’4 | 4.7 Ã— 10âˆ’5 | | GADAM | 3 Ã— 10âˆ’4 | 98.62 (89.34) | 71.55 (64.68) | 43 (280) | 1.1 Ã— 10âˆ’3 (0.023) | 1.1 Ã— 10âˆ’4 (5.1 Ã— 10âˆ’4 ) | | GADAM | 3 Ã— 10âˆ’5 | 99.97 (94.12) | 69.67 (67.16) | 120 (2500) | 1.4 Ã— 19âˆ’3 (0.86) | 6.4 Ã— 10âˆ’5 (2.2 Ã— 10âˆ’3 ) |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305-Sentence-3051,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305-Sentence-3052,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305-Sentence-3053 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305-Sentence-3051 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| OPTIMISER | TERMINAL LR | TRAIN ACC."@en ;
    askg-onto:inSentence "| OPTIMISER | TERMINAL LR | TRAIN ACC."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimiser,
        askg-data:Entity-terminal_lr,
        askg-data:Entity-train_acc .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305-Sentence-3052 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "| TEST ACC."@en ;
    askg-onto:inSentence "| TEST ACC."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-score,
        askg-data:Entity-test_acc .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-305-Sentence-3053 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "| SPECTRAL NORM | FROBENIUS NORM | TRACE | |-------------|---------------|---------------|---------------|-----------------|--------------------|--------------------------| | ADAMW | 3 Ã— 10âˆ’6 | 99.93 | 69.43 | 62 | 9.3 Ã— 10âˆ’4 | 4.7 Ã— 10âˆ’5 | | GADAM | 3 Ã— 10âˆ’4 | 98.62 (89.34) | 71.55 (64.68) | 43 (280) | 1.1 Ã— 10âˆ’3 (0.023) | 1.1 Ã— 10âˆ’4 (5.1 Ã— 10âˆ’4 ) | | GADAM | 3 Ã— 10âˆ’5 | 99.97 (94.12) | 69.67 (67.16) | 120 (2500) | 1.4 Ã— 19âˆ’3 (0.86) | 6.4 Ã— 10âˆ’5 (2.2 Ã— 10âˆ’3 ) |"@en ;
    askg-onto:inSentence "| SPECTRAL NORM | FROBENIUS NORM | TRACE | |-------------|---------------|---------------|---------------|-----------------|--------------------|--------------------------| | ADAMW | 3 Ã— 10âˆ’6 | 99.93 | 69.43 | 62 | 9.3 Ã— 10âˆ’4 | 4.7 Ã— 10âˆ’5 | | GADAM | 3 Ã— 10âˆ’4 | 98.62 (89.34) | 71.55 (64.68) | 43 (280) | 1.1 Ã— 10âˆ’3 (0.023) | 1.1 Ã— 10âˆ’4 (5.1 Ã— 10âˆ’4 ) | | GADAM | 3 Ã— 10âˆ’5 | 99.97 (94.12) | 69.67 (67.16) | 120 (2500) | 1.4 Ã— 19âˆ’3 (0.86) | 6.4 Ã— 10âˆ’5 (2.2 Ã— 10âˆ’3 ) |"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11__103_0023,
        askg-data:Entity-11__104_51__104_,
        askg-data:Entity-120_2500,
        askg-data:Entity-14__193_086,
        askg-data:Entity-3__104,
        askg-data:Entity-3__105,
        askg-data:Entity-3__106,
        askg-data:Entity-43_280,
        askg-data:Entity-47__105,
        askg-data:Entity-62,
        askg-data:Entity-64__105_22__103_,
        askg-data:Entity-6943,
        askg-data:Entity-6967_6716,
        askg-data:Entity-7155_6468,
        askg-data:Entity-93__104,
        askg-data:Entity-9862_8934,
        askg-data:Entity-9993,
        askg-data:Entity-9997_9412,
        askg-data:Entity-adamw,
        askg-data:Entity-gadam .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "ter setting for the corresponding IA optimisers (i.e. SWA, Gadam, GadamX). For SGD, we use a base learning rate of 0.1 and use a grid searched initial learning rates in the range of {0.001, 0.01, 0.1} and use the same learning rate for Padam, similar to the procedues suggested in Chen & Gu (2018). For Adam(W), we simply use the default initial learning rate of 0.001 except in VGG-16, where we use initial learning rate of 0.0005. After the best learning rate has been identified, we conduct a further search on the weight decay, which we find often leads to a trade-off between the convergence speed and final performance; again we search on the base optimisers only and use the same value for the IA optimisers. For CIFAR experiments, we search in the range of [10âˆ’4, 10âˆ’3], from the suggestions of Loshchilov & Hutter (2018). For decoupled weight decay, we search the same range for the weight decay scaled by initial learning rate. On ImageNet experiments, we conduct the following process. On WRN we use the settings recommended by Chrabaszcz et al. (2017), who conducted a thorough hyperparameter search: we set the learning rate at 0.03 and weight decay at 0.0001 for SGD/SWA and Padam, based on their searched optimal values. for AdamW/Gadam, we set decoupled weight decay at 0.01 and initial learning rate to be 0.001 (default Adam learning rate). For GadamX, we again use the same learning rate of 0.03, but since the weight decay in GadamX is partially decoupled, we set the decoupled weight decay to 0.0003. On PRN-110, we follow the recommendations of the authors of He et al. (2016) to set the initial learning rate for SGD, Padam and GadamX to be 0.1."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3061,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30610,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30611,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30612,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30613,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30614,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3062,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3063,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3064,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3065,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3066,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3067,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3068,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3069 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3061 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "ter setting for the corresponding IA optimisers (i.e."@en ;
    askg-onto:inSentence "ter setting for the corresponding IA optimisers (i.e."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-corresponding,
        askg-data:Entity-ia_optimisers .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30610 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(2017), who conducted a thorough hyperparameter search: we set the learning rate at 0.03 and weight decay at 0.0001 for SGD/SWA and Padam, based on their searched optimal values."@en ;
    askg-onto:inSentence "(2017), who conducted a thorough hyperparameter search: we set the learning rate at 0.03 and weight decay at 0.0001 for SGD/SWA and Padam, based on their searched optimal values."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-00001,
        askg-data:Entity-003,
        askg-data:Entity-learning_rate,
        askg-data:Entity-optimization_algorithm,
        askg-data:Entity-padam,
        askg-data:Entity-sgdswa,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30611 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "for AdamW/Gadam, we set decoupled weight decay at 0.01 and initial learning rate to be 0.001 (default Adam learning rate)."@en ;
    askg-onto:inSentence "for AdamW/Gadam, we set decoupled weight decay at 0.01 and initial learning rate to be 0.001 (default Adam learning rate)."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0001,
        askg-data:Entity-001,
        askg-data:Entity-adamw,
        askg-data:Entity-adamwgadam .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30612 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "For GadamX, we again use the same learning rate of 0.03, but since the weight decay in GadamX is partially decoupled, we set the decoupled weight decay to 0.0003."@en ;
    askg-onto:inSentence "For GadamX, we again use the same learning rate of 0.03, but since the weight decay in GadamX is partially decoupled, we set the decoupled weight decay to 0.0003."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-00003,
        askg-data:Entity-decoupled_weight_decay,
        askg-data:Entity-gadamx,
        askg-data:Entity-learning_rate_of_003 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30613 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "On PRN-110, we follow the recommendations of the authors of He et al."@en ;
    askg-onto:inSentence "On PRN-110, we follow the recommendations of the authors of He et al."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-authors_of_he_et_al,
        askg-data:Entity-prn-110 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-30614 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "(2016) to set the initial learning rate for SGD, Padam and GadamX to be 0.1."@en ;
    askg-onto:inSentence "(2016) to set the initial learning rate for SGD, Padam and GadamX to be 0.1."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-01,
        askg-data:Entity-gadamx,
        askg-data:Entity-padam,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3062 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "SWA, Gadam, GadamX)."@en ;
    askg-onto:inSentence "SWA, Gadam, GadamX)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-swa .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3063 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For SGD, we use a base learning rate of 0.1 and use a grid searched initial learning rates in the range of {0.001, 0.01, 0.1} and use the same learning rate for Padam, similar to the procedues suggested in Chen & Gu (2018)."@en ;
    askg-onto:inSentence "For SGD, we use a base learning rate of 0.1 and use a grid searched initial learning rates in the range of {0.001, 0.01, 0.1} and use the same learning rate for Padam, similar to the procedues suggested in Chen & Gu (2018)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0001_001_01,
        askg-data:Entity-base_learning_rate_of_01,
        askg-data:Entity-chen__gu_2018,
        askg-data:Entity-grid_searched_initial_learning_rates,
        askg-data:Entity-padam,
        askg-data:Entity-procedures,
        askg-data:Entity-sgd,
        askg-data:Entity-the_same_learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3064 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For Adam(W), we simply use the default initial learning rate of 0.001 except in VGG-16, where we use initial learning rate of 0.0005."@en ;
    askg-onto:inSentence "For Adam(W), we simply use the default initial learning rate of 0.001 except in VGG-16, where we use initial learning rate of 0.0005."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-initial_learning_rate_of_00005,
        askg-data:Entity-initial_learning_rate_of_0001,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3065 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "After the best learning rate has been identified, we conduct a further search on the weight decay, which we find often leads to a trade-off between the convergence speed and final performance; again we search on the base optimisers only and use the same value for the IA optimisers."@en ;
    askg-onto:inSentence "After the best learning rate has been identified, we conduct a further search on the weight decay, which we find often leads to a trade-off between the convergence speed and final performance; again we search on the base optimisers only and use the same value for the IA optimisers."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-base_optimisers,
        askg-data:Entity-best,
        askg-data:Entity-convergence_speed,
        askg-data:Entity-final_performance,
        askg-data:Entity-ia_optimisers,
        askg-data:Entity-learning_rate,
        askg-data:Entity-trade-off,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3066 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "For CIFAR experiments, we search in the range of [10âˆ’4, 10âˆ’3], from the suggestions of Loshchilov & Hutter (2018)."@en ;
    askg-onto:inSentence "For CIFAR experiments, we search in the range of [10âˆ’4, 10âˆ’3], from the suggestions of Loshchilov & Hutter (2018)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-104_103,
        askg-data:Entity-cifar_experiments,
        askg-data:Entity-loshchilov__hutter,
        askg-data:Entity-loshchilov__hutter_2018,
        askg-data:Entity-suggestions .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3067 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "For decoupled weight decay, we search the same range for the weight decay scaled by initial learning rate."@en ;
    askg-onto:inSentence "For decoupled weight decay, we search the same range for the weight decay scaled by initial learning rate."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-initial_learning_rate,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3068 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "On ImageNet experiments, we conduct the following process."@en ;
    askg-onto:inSentence "On ImageNet experiments, we conduct the following process."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-imagenet_experiments,
        askg-data:Entity-process .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-306-Sentence-3069 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "On WRN we use the settings recommended by Chrabaszcz et al."@en ;
    askg-onto:inSentence "On WRN we use the settings recommended by Chrabaszcz et al."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chrabaszcz_et_al,
        askg-data:Entity-wrn .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "For AdamW and Gadam, we again use the default learning rate of 0.001. Following the observation by Loshchilov & Hutter (2018) that smaller weight decay should be used for longer training (in PRN-110 we train for 200 epochs), we set weight decay at 10âˆ’5and decoupled weight decay at 0.0003 (GadamX)/0.001 (others) respectively, where applicable. Overall, we do not tune adaptive methods (Adam and Gadam) as much (most noticeably, we usually fix their learning rate to 0.001), and therefore in particular the AdamW results we obtain may or may not be at their optimal performance. Nonetheless, the rationale is that by design, one of the key advantage claimed is that adaptive optimiser should be less sensitive to hyperparameter choice, and in this paper, the key message is that Gadam performs well, despite of AdamW, its base optimiser, is rather crudely tuned. In all experiments, momentum parameter (Î² = 0.9) for SGD and {Î²1, Î²2} = {0.9, 0.999} and = 10âˆ’8for Adam and its variants are left at their respective default values. For all experiments unless otherwise stated, we average once per epoch. We also apply standard data augmentation (e.g. flip, random crops) and use a batch size of 128 for all experiments conducted."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3071,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3072,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3073,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3074,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3075,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3076,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3077,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3078 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3071 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For AdamW and Gadam, we again use the default learning rate of 0.001."@en ;
    askg-onto:inSentence "For AdamW and Gadam, we again use the default learning rate of 0.001."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0001,
        askg-data:Entity-adamw,
        askg-data:Entity-algorithm,
        askg-data:Entity-gadam,
        askg-data:Entity-learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3072 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Following the observation by Loshchilov & Hutter (2018) that smaller weight decay should be used for longer training (in PRN-110 we train for 200 epochs), we set weight decay at 10âˆ’5and decoupled weight decay at 0.0003 (GadamX)/0.001 (others) respectively, where applicable."@en ;
    askg-onto:inSentence "Following the observation by Loshchilov & Hutter (2018) that smaller weight decay should be used for longer training (in PRN-110 we train for 200 epochs), we set weight decay at 10âˆ’5and decoupled weight decay at 0.0003 (GadamX)/0.001 (others) respectively, where applicable."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-00003_gadamx,
        askg-data:Entity-0001_others,
        askg-data:Entity-105,
        askg-data:Entity-200_epochs,
        askg-data:Entity-longer_training,
        askg-data:Entity-loshchilov__hutter,
        askg-data:Entity-prn-110,
        askg-data:Entity-smaller_weight_decay,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3073 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Overall, we do not tune adaptive methods (Adam and Gadam) as much (most noticeably, we usually fix their learning rate to 0.001), and therefore in particular the AdamW results we obtain may or may not be at their optimal performance."@en ;
    askg-onto:inSentence "Overall, we do not tune adaptive methods (Adam and Gadam) as much (most noticeably, we usually fix their learning rate to 0.001), and therefore in particular the AdamW results we obtain may or may not be at their optimal performance."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0001,
        askg-data:Entity-adam,
        askg-data:Entity-adamw,
        askg-data:Entity-algorithm,
        askg-data:Entity-gadam,
        askg-data:Entity-learning_rate,
        askg-data:Entity-optimal_performance .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3074 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Nonetheless, the rationale is that by design, one of the key advantage claimed is that adaptive optimiser should be less sensitive to hyperparameter choice, and in this paper, the key message is that Gadam performs well, despite of AdamW, its base optimiser, is rather crudely tuned."@en ;
    askg-onto:inSentence "Nonetheless, the rationale is that by design, one of the key advantage claimed is that adaptive optimiser should be less sensitive to hyperparameter choice, and in this paper, the key message is that Gadam performs well, despite of AdamW, its base optimiser, is rather crudely tuned."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamw,
        askg-data:Entity-adaptive_optimiser,
        askg-data:Entity-gadam,
        askg-data:Entity-hyperparameter_choice .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3075 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In all experiments, momentum parameter (Î² = 0.9) for SGD and {Î²1, Î²2} = {0.9, 0.999} and = 10âˆ’8for Adam and its variants are left at their respective default values."@en ;
    askg-onto:inSentence "In all experiments, momentum parameter (Î² = 0.9) for SGD and {Î²1, Î²2} = {0.9, 0.999} and = 10âˆ’8for Adam and its variants are left at their respective default values."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-momentum_parameter_%CE%B2__09,
        askg-data:Entity-momentum_parameters_%CE%B21_%CE%B22__09_0999_and__108,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3076 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "For all experiments unless otherwise stated, we average once per epoch."@en ;
    askg-onto:inSentence "For all experiments unless otherwise stated, we average once per epoch."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-once_per_epoch .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3077 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We also apply standard data augmentation (e.g."@en ;
    askg-onto:inSentence "We also apply standard data augmentation (e.g."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_augmentation,
        askg-data:Entity-standard .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-307-Sentence-3078 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "flip, random crops) and use a batch size of 128 for all experiments conducted."@en ;
    askg-onto:inSentence "flip, random crops) and use a batch size of 128 for all experiments conducted."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_size_of_128,
        askg-data:Entity-random_crops .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-308 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Learning Rate Schedule For all experiments without IA, we use the following learning rate schedule for the learning rate at the t-th epoch, similar to Izmailov et al. (2018):"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-308-Sentence-3081,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-308-Sentence-3082 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-308-Sentence-3081 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Learning Rate Schedule For all experiments without IA, we use the following learning rate schedule for the learning rate at the t-th epoch, similar to Izmailov et al."@en ;
    askg-onto:inSentence "Learning Rate Schedule For all experiments without IA, we use the following learning rate schedule for the learning rate at the t-th epoch, similar to Izmailov et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-ia,
        askg-data:Entity-izmailov_et_al,
        askg-data:Entity-learning_rate,
        askg-data:Entity-learning_rate_schedule,
        askg-data:Entity-t-th_epoch .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-308-Sentence-3082 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2018):"@en ;
    askg-onto:inSentence "(2018):"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-research .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-309 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$\\alpha_t=$. $$\\begin{cases}\\alpha_{0},&\\text{if}\\frac{t}{T}\\leq0.5\\\\ \\alpha_{0}[1-\\frac{(1-r)(\\frac{t}{T}-0.5)}{0.4}]&\\text{if}0.5<\\frac{t}{T}\\leq0.9\\\\ \\alpha_{0}r,&\\text{otherwise}\\end{cases}\\tag{9}$$ 16"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-309-Sentence-3091,
        askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-309-Sentence-3092 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-309-Sentence-3091 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\alpha_t=$."@en ;
    askg-onto:inSentence "$\\alpha_t=$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1_t,
        askg-data:Entity-a_mathematical_representation .

askg-data:Paper-43d37e59d752bc41-Section-30-Paragraph-309-Sentence-3092 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "$$\\begin{cases}\\alpha_{0},&\\text{if}\\frac{t}{T}\\leq0.5\\\\ \\alpha_{0}[1-\\frac{(1-r)(\\frac{t}{T}-0.5)}{0.4}]&\\text{if}0.5<\\frac{t}{T}\\leq0.9\\\\ \\alpha_{0}r,&\\text{otherwise}\\end{cases}\\tag{9}$$ 16"@en ;
    askg-onto:inSentence "$$\\begin{cases}\\alpha_{0},&\\text{if}\\frac{t}{T}\\leq0.5\\\\ \\alpha_{0}[1-\\frac{(1-r)(\\frac{t}{T}-0.5)}{0.4}]&\\text{if}0.5<\\frac{t}{T}\\leq0.9\\\\ \\alpha_{0}r,&\\text{otherwise}\\end{cases}\\tag{9}$$ 16"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extotherwise,
        askg-data:Entity-%0Cractt,
        askg-data:Entity-%0Cractt_%09ext_being_less_than_or_equal_to__05,
        askg-data:Entity-05__%0Cractt_%09ext_being_less_than_or_equal_to__09,
        askg-data:Entity-t .

askg-data:Paper-43d37e59d752bc41-Section-31 a askg-onto:Section ;
    rdfs:label "Section 31"@en ;
    domo:Text "B.3. Language Modelling Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312 ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In language modelling experiments, we use the codebase provided by https://github.com/salesforce/ awd-lstm-lm. For ASGD, we use the hyperparameters recommended by Merity et al. (2017) and set the initial learning rate to be 30. Note that in language experiments, consistent with other findings decoupled weight decay seems to be not as effective L2, possibly due to LSTM could be more well-regularised already, and that batch normalisation, which we argue to be central to the efficacy of decoupled weight decay, is not used in LSTM. Thus, for this set of experiments we simply use Adam and Padam as the iterates for Gadam and GadamX. For Adam/Gadam, we tune the learning rate by searching initial learning rate in the range of {0.0003, 0.001, 0.003, 0.01} and for Padam and GadamX, we set the initial learning rate to be 1 and partially adaptive parameter p = 0.2, as recommended by the authors (Chen & Gu, 2018). We further set the weight decay to be their recommended value of 1.2 Ã— 10âˆ’6. For the learning rate schedule, we again follow Merity et al. (2017) for a piecewise constant schedule, and decay the learning rate by a factor of 10 at the {100, 150}-th epochs for all experiments without using iterate averaging. For experiments with iterate averaging, instead of decaying the learning rate by half before averaging starts, we keep the learning rate constant thoughout to make our experiment comparable with the ASGD schedule. We run all experiments for 200 (instead of 500 in Merity et al. (2017)) epochs."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3111,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-31110,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-31111,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-31112,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3112,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3113,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3114,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3115,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3116,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3117,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3118,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3119 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In language modelling experiments, we use the codebase provided by https://github.com/salesforce/ awd-lstm-lm."@en ;
    askg-onto:inSentence "In language modelling experiments, we use the codebase provided by https://github.com/salesforce/ awd-lstm-lm."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-codebase,
        askg-data:Entity-httpsgithubcomsalesforceawd-lstm-lm .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-31110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "For experiments with iterate averaging, instead of decaying the learning rate by half before averaging starts, we keep the learning rate constant thoughout to make our experiment comparable with the ASGD schedule."@en ;
    askg-onto:inSentence "For experiments with iterate averaging, instead of decaying the learning rate by half before averaging starts, we keep the learning rate constant thoughout to make our experiment comparable with the ASGD schedule."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asgd_schedule,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-learning_rate,
        askg-data:Entity-method .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-31111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "We run all experiments for 200 (instead of 500 in Merity et al."@en ;
    askg-onto:inSentence "We run all experiments for 200 (instead of 500 in Merity et al."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-200,
        askg-data:Entity-500,
        askg-data:Entity-experiments,
        askg-data:Entity-merity_et_al .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-31112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "(2017)) epochs."@en ;
    askg-onto:inSentence "(2017)) epochs."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-epochs,
        askg-data:Entity-study .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For ASGD, we use the hyperparameters recommended by Merity et al."@en ;
    askg-onto:inSentence "For ASGD, we use the hyperparameters recommended by Merity et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asgd,
        askg-data:Entity-hyperparameters,
        askg-data:Entity-merity_et_al .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2017) and set the initial learning rate to be 30."@en ;
    askg-onto:inSentence "(2017) and set the initial learning rate to be 30."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30,
        askg-data:Entity-learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Note that in language experiments, consistent with other findings decoupled weight decay seems to be not as effective L2, possibly due to LSTM could be more well-regularised already, and that batch normalisation, which we argue to be central to the efficacy of decoupled weight decay, is not used in LSTM."@en ;
    askg-onto:inSentence "Note that in language experiments, consistent with other findings decoupled weight decay seems to be not as effective L2, possibly due to LSTM could be more well-regularised already, and that batch normalisation, which we argue to be central to the efficacy of decoupled weight decay, is not used in LSTM."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalisation,
        askg-data:Entity-decoupled_weight_decay,
        askg-data:Entity-l2,
        askg-data:Entity-lstm,
        askg-data:Entity-model,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Thus, for this set of experiments we simply use Adam and Padam as the iterates for Gadam and GadamX."@en ;
    askg-onto:inSentence "Thus, for this set of experiments we simply use Adam and Padam as the iterates for Gadam and GadamX."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-padam .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "For Adam/Gadam, we tune the learning rate by searching initial learning rate in the range of {0.0003, 0.001, 0.003, 0.01} and for Padam and GadamX, we set the initial learning rate to be 1 and partially adaptive parameter p = 0.2, as recommended by the authors (Chen & Gu, 2018)."@en ;
    askg-onto:inSentence "For Adam/Gadam, we tune the learning rate by searching initial learning rate in the range of {0.0003, 0.001, 0.003, 0.01} and for Padam and GadamX, we set the initial learning rate to be 1 and partially adaptive parameter p = 0.2, as recommended by the authors (Chen & Gu, 2018)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adamgadam,
        askg-data:Entity-authors_chen__gu_2018,
        askg-data:Entity-gadamx,
        askg-data:Entity-initial_learning_rate,
        askg-data:Entity-initial_learning_rate_of_1,
        askg-data:Entity-learning_rate,
        askg-data:Entity-padam,
        askg-data:Entity-partially_adaptive_parameter_p__02 .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3117 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We further set the weight decay to be their recommended value of 1.2 Ã— 10âˆ’6."@en ;
    askg-onto:inSentence "We further set the weight decay to be their recommended value of 1.2 Ã— 10âˆ’6."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-12__106,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3118 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "For the learning rate schedule, we again follow Merity et al."@en ;
    askg-onto:inSentence "For the learning rate schedule, we again follow Merity et al."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning_rate_schedule,
        askg-data:Entity-merity_et_al .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-311-Sentence-3119 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "(2017) for a piecewise constant schedule, and decay the learning rate by a factor of 10 at the {100, 150}-th epochs for all experiments without using iterate averaging."@en ;
    askg-onto:inSentence "(2017) for a piecewise constant schedule, and decay the learning rate by a factor of 10 at the {100, 150}-th epochs for all experiments without using iterate averaging."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-100_150,
        askg-data:Entity-epochs,
        askg-data:Entity-experiments,
        askg-data:Entity-factor_of_10,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Learning Rate Schedule As discussed in the main text, the experiments shown in Table 5 and Figure 8 are run with constant schedules (except for Padam). Padam runs with a step decay of factor of 10 at {100, 150}-th epochs. However, often even the adaptive methods such as Adam are scheduled with learning rate decay for enhanced performance. Therefore, we also conduct additional scheduled experiments with Adam, where we follow the same schedule of Padam. The results are shown in Appendix C.2."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3121,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3122,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3123,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3124,
        askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3125 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Learning Rate Schedule As discussed in the main text, the experiments shown in Table 5 and Figure 8 are run with constant schedules (except for Padam)."@en ;
    askg-onto:inSentence "Learning Rate Schedule As discussed in the main text, the experiments shown in Table 5 and Figure 8 are run with constant schedules (except for Padam)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constant_schedules,
        askg-data:Entity-figure_8,
        askg-data:Entity-learning_rate_schedule,
        askg-data:Entity-padam,
        askg-data:Entity-table_5,
        askg-data:Entity-the_experiments,
        askg-data:Entity-the_main_text .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Padam runs with a step decay of factor of 10 at {100, 150}-th epochs."@en ;
    askg-onto:inSentence "Padam runs with a step decay of factor of 10 at {100, 150}-th epochs."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-factor_of_10_at_100_150-th_epochs,
        askg-data:Entity-padam .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, often even the adaptive methods such as Adam are scheduled with learning rate decay for enhanced performance."@en ;
    askg-onto:inSentence "However, often even the adaptive methods such as Adam are scheduled with learning rate decay for enhanced performance."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-adaptive_methods,
        askg-data:Entity-enhanced_performance,
        askg-data:Entity-learning_rate_decay .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Therefore, we also conduct additional scheduled experiments with Adam, where we follow the same schedule of Padam."@en ;
    askg-onto:inSentence "Therefore, we also conduct additional scheduled experiments with Adam, where we follow the same schedule of Padam."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-experiments,
        askg-data:Entity-padam .

askg-data:Paper-43d37e59d752bc41-Section-31-Paragraph-312-Sentence-3125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The results are shown in Appendix C.2."@en ;
    askg-onto:inSentence "The results are shown in Appendix C.2."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-32 a askg-onto:Section ;
    rdfs:label "Section 32"@en ;
    domo:Text "B.4. Experiment Baselines"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-32-Paragraph-321 ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-32-Paragraph-321 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To validate the results we obtain and to make sure that any baseline algorithms we use are properly and fairly tuned, we also survey the previous literature for baseline results where the authors use same (or similar) network architectures on the same image classification/language tasks, and the comparison of our results against theirs is presented in Table 8. It is clear that for most of the settings, our baseline results achieve similar or better performance compared to the previous work for comparable methods; this validates the rigour of our tuning process."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-32-Paragraph-321-Sentence-3211,
        askg-data:Paper-43d37e59d752bc41-Section-32-Paragraph-321-Sentence-3212 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-32-Paragraph-321-Sentence-3211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To validate the results we obtain and to make sure that any baseline algorithms we use are properly and fairly tuned, we also survey the previous literature for baseline results where the authors use same (or similar) network architectures on the same image classification/language tasks, and the comparison of our results against theirs is presented in Table 8."@en ;
    askg-onto:inSentence "To validate the results we obtain and to make sure that any baseline algorithms we use are properly and fairly tuned, we also survey the previous literature for baseline results where the authors use same (or similar) network architectures on the same image classification/language tasks, and the comparison of our results against theirs is presented in Table 8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-authors,
        askg-data:Entity-baseline_algorithms,
        askg-data:Entity-baseline_results,
        askg-data:Entity-image_classificationlanguage_tasks,
        askg-data:Entity-network_architectures,
        askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-32-Paragraph-321-Sentence-3212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It is clear that for most of the settings, our baseline results achieve similar or better performance compared to the previous work for comparable methods; this validates the rigour of our tuning process."@en ;
    askg-onto:inSentence "It is clear that for most of the settings, our baseline results achieve similar or better performance compared to the previous work for comparable methods; this validates the rigour of our tuning process."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baseline_results,
        askg-data:Entity-better_performance,
        askg-data:Entity-comparable_methods,
        askg-data:Entity-previous_work,
        askg-data:Entity-rigour,
        askg-data:Entity-tuning_process .

askg-data:Paper-43d37e59d752bc41-Section-33 a askg-onto:Section ;
    rdfs:label "Section 33"@en ;
    domo:Text "C. Additional Experimental Results"@en ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34 a askg-onto:Section ;
    rdfs:label "Section 34"@en ;
    domo:Text "C.1. Testing Performance Of Cifar-10"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-3410,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-342,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-343,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-345,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-346,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-348,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-349 ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We report the testing performance of VGG-16 and PRN- 110 on CIFAR-10 in Figure 12 and Table 9. Perhaps due to the fact that CIFAR-10 poses a simpler problem compared to CIFAR-100 and ImageNet in the main text, the convergence speeds of the optimisers differ rather minimally. Nonetheless, we find that GadamX still outperforms all other optimisers by a non-trivial margin in terms of final test accuracy."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341-Sentence-3411,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341-Sentence-3412,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341-Sentence-3413 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341-Sentence-3411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We report the testing performance of VGG-16 and PRN- 110 on CIFAR-10 in Figure 12 and Table 9."@en ;
    askg-onto:inSentence "We report the testing performance of VGG-16 and PRN- 110 on CIFAR-10 in Figure 12 and Table 9."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-prn-110,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341-Sentence-3412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Perhaps due to the fact that CIFAR-10 poses a simpler problem compared to CIFAR-100 and ImageNet in the main text, the convergence speeds of the optimisers differ rather minimally."@en ;
    askg-onto:inSentence "Perhaps due to the fact that CIFAR-10 poses a simpler problem compared to CIFAR-100 and ImageNet in the main text, the convergence speeds of the optimisers differ rather minimally."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-10,
        askg-data:Entity-cifar-100,
        askg-data:Entity-convergence_speeds_of_the_optimisers,
        askg-data:Entity-imagenet,
        askg-data:Entity-optimisers .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-341-Sentence-3413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Nonetheless, we find that GadamX still outperforms all other optimisers by a non-trivial margin in terms of final test accuracy."@en ;
    askg-onto:inSentence "Nonetheless, we find that GadamX still outperforms all other optimisers by a non-trivial margin in terms of final test accuracy."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_test_accuracy,
        askg-data:Entity-gadamx,
        askg-data:Entity-other_optimisers .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-3410 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "18"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-3410-Sentence-34101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-3410-Sentence-34101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "18"@en ;
    askg-onto:inSentence "18"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-18,
        askg-data:Entity-unknown .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-342 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "| Table 9. Top\\-1 Test Accuracy on CIFAR\\-10 Data\\-set | | | |--------------------------------------------------------|-----------|---------------| | ARCHITECTURE | OPTIMISER | TEST ACCURACY | | VGG\\-16 | SGD | 94.14Â±0.37 | | | SWA | 94.69Â±0.36 | | | ADAM(W) | 93.90Â±0.11 | | | PADAM(W) | 94.13Â±0.06 | | | GADAM | 94.62Â±0.15 | | | GADAMX | 94.88Â±0.03 | | PRN\\-110 | SGD | 95.40Â±0.25 | | | SWA | 95.55Â±0.12 | | | ADAM(W) | 94.69Â±0.14 | | | PADAM(W) | 95.28Â±0.13 | | | GADAM | 95.27Â±0.02 | | | GADAMX | 95.95Â±0.06 |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-342-Sentence-3421,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-342-Sentence-3422 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-342-Sentence-3421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Table 9."@en ;
    askg-onto:inSentence "| Table 9."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_9,
        askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-342-Sentence-3422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Top\\-1 Test Accuracy on CIFAR\\-10 Data\\-set | | | |--------------------------------------------------------|-----------|---------------| | ARCHITECTURE | OPTIMISER | TEST ACCURACY | | VGG\\-16 | SGD | 94.14Â±0.37 | | | SWA | 94.69Â±0.36 | | | ADAM(W) | 93.90Â±0.11 | | | PADAM(W) | 94.13Â±0.06 | | | GADAM | 94.62Â±0.15 | | | GADAMX | 94.88Â±0.03 | | PRN\\-110 | SGD | 95.40Â±0.25 | | | SWA | 95.55Â±0.12 | | | ADAM(W) | 94.69Â±0.14 | | | PADAM(W) | 95.28Â±0.13 | | | GADAM | 95.27Â±0.02 | | | GADAMX | 95.95Â±0.06 |"@en ;
    askg-onto:inSentence "Top\\-1 Test Accuracy on CIFAR\\-10 Data\\-set | | | |--------------------------------------------------------|-----------|---------------| | ARCHITECTURE | OPTIMISER | TEST ACCURACY | | VGG\\-16 | SGD | 94.14Â±0.37 | | | SWA | 94.69Â±0.36 | | | ADAM(W) | 93.90Â±0.11 | | | PADAM(W) | 94.13Â±0.06 | | | GADAM | 94.62Â±0.15 | | | GADAMX | 94.88Â±0.03 | | PRN\\-110 | SGD | 95.40Â±0.25 | | | SWA | 95.55Â±0.12 | | | ADAM(W) | 94.69Â±0.14 | | | PADAM(W) | 95.28Â±0.13 | | | GADAM | 95.27Â±0.02 | | | GADAMX | 95.95Â±0.06 |"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-9414037,
        askg-data:Entity-9540025,
        askg-data:Entity-cifar-10,
        askg-data:Entity-prn-110,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-343 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "| DATA\\-SET | OPTIMISER | PERPLEXITY | | |-------------|----------------|--------------|-------| | | | VALIDATION | TEST | | PTB | NT\\-ASGD | 66.01 | 64.73 | | | SCHEDULED ADAM | 63.99 | 61.51 | | | GADAM (OURS) | 61.35 | 58.77 | | | GADAMX (OURS) | 63.49 | 60.45 |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-343-Sentence-3431 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-343-Sentence-3431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| DATA\\-SET | OPTIMISER | PERPLEXITY | | |-------------|----------------|--------------|-------| | | | VALIDATION | TEST | | PTB | NT\\-ASGD | 66.01 | 64.73 | | | SCHEDULED ADAM | 63.99 | 61.51 | | | GADAM (OURS) | 61.35 | 58.77 | | | GADAMX (OURS) | 63.49 | 60.45 |"@en ;
    askg-onto:inSentence "| DATA\\-SET | OPTIMISER | PERPLEXITY | | |-------------|----------------|--------------|-------| | | | VALIDATION | TEST | | PTB | NT\\-ASGD | 66.01 | 64.73 | | | SCHEDULED ADAM | 63.99 | 61.51 | | | GADAM (OURS) | 61.35 | 58.77 | | | GADAMX (OURS) | 63.49 | 60.45 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5877,
        askg-data:Entity-6045,
        askg-data:Entity-6135,
        askg-data:Entity-6151,
        askg-data:Entity-6349,
        askg-data:Entity-6399,
        askg-data:Entity-6473,
        askg-data:Entity-6601,
        askg-data:Entity-gadam_ours,
        askg-data:Entity-gadamx_ours,
        askg-data:Entity-nt-asgd,
        askg-data:Entity-ptb,
        askg-data:Entity-scheduled_adam,
        askg-data:Entity-validation_score .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Table 10. Validation and Test Perplexity on Word-level Language Modelling. The Gadam(X) results are lifted from Table 5."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344-Sentence-3441,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344-Sentence-3442,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344-Sentence-3443 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344-Sentence-3441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 10."@en ;
    askg-onto:inSentence "Table 10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_data,
        askg-data:Entity-table_10 .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344-Sentence-3442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Validation and Test Perplexity on Word-level Language Modelling."@en ;
    askg-onto:inSentence "Validation and Test Perplexity on Word-level Language Modelling."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-validation_and_test_perplexity,
        askg-data:Entity-word-level_language_modelling .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-344-Sentence-3443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The Gadam(X) results are lifted from Table 5."@en ;
    askg-onto:inSentence "The Gadam(X) results are lifted from Table 5."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gadamx,
        askg-data:Entity-table_5 .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-345 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "C.2. Word Level Language Modelling with Learning"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-345-Sentence-3451,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-345-Sentence-3452 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-345-Sentence-3451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "C.2."@en ;
    askg-onto:inSentence "C.2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c2 .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-345-Sentence-3452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Word Level Language Modelling with Learning"@en ;
    askg-onto:inSentence "Word Level Language Modelling with Learning"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-language_modelling_method,
        askg-data:Entity-learning,
        askg-data:Entity-word_level_language_modelling .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-346 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Rate Schedules and Non-monotonic Trigger"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-346-Sentence-3461 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-346-Sentence-3461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Rate Schedules and Non-monotonic Trigger"@en ;
    askg-onto:inSentence "Rate Schedules and Non-monotonic Trigger"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-non-monotonic_trigger,
        askg-data:Entity-rate_schedules .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Here we include additional results on word-level language modelling using *scheduled* Adam and NT-ASGD, where the point to start averaging is learned non-monotonically and automatically. Where scheduling further improves the Adam performance marginally, the automatically triggered ASGD actually does not perform as well as the manually triggered ASGD that starts averaging from 100th epoch onwards, as we discussed in the main text - this could be because that ASGD converges rather slowly, the 200-epoch budget is not sufficient, or the patience (we use patience = 10) requires further tuning. Otherwise, our proposed Gadam and GadamX without schedules still outperform the variants tested here *without careful learning rate scheduling*. The results are summarised in Figure 13 and Table 10."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3471,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3472,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3473,
        askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3474 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Here we include additional results on word-level language modelling using *scheduled* Adam and NT-ASGD, where the point to start averaging is learned non-monotonically and automatically."@en ;
    askg-onto:inSentence "Here we include additional results on word-level language modelling using *scheduled* Adam and NT-ASGD, where the point to start averaging is learned non-monotonically and automatically."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adam,
        askg-data:Entity-nt-asgd,
        askg-data:Entity-optimization_algorithm,
        askg-data:Entity-research_concept,
        askg-data:Entity-word-level_language_modelling .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Where scheduling further improves the Adam performance marginally, the automatically triggered ASGD actually does not perform as well as the manually triggered ASGD that starts averaging from 100th epoch onwards, as we discussed in the main text - this could be because that ASGD converges rather slowly, the 200-epoch budget is not sufficient, or the patience (we use patience = 10) requires further tuning."@en ;
    askg-onto:inSentence "Where scheduling further improves the Adam performance marginally, the automatically triggered ASGD actually does not perform as well as the manually triggered ASGD that starts averaging from 100th epoch onwards, as we discussed in the main text - this could be because that ASGD converges rather slowly, the 200-epoch budget is not sufficient, or the patience (we use patience = 10) requires further tuning."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-200-epoch_budget,
        askg-data:Entity-asgd,
        askg-data:Entity-manually_triggered_asgd,
        askg-data:Entity-not_sufficient,
        askg-data:Entity-patience__10,
        askg-data:Entity-slowly .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Otherwise, our proposed Gadam and GadamX without schedules still outperform the variants tested here *without careful learning rate scheduling*."@en ;
    askg-onto:inSentence "Otherwise, our proposed Gadam and GadamX without schedules still outperform the variants tested here *without careful learning rate scheduling*."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-careful_learning_rate_scheduling,
        askg-data:Entity-gadam,
        askg-data:Entity-gadamx,
        askg-data:Entity-learning_rate_scheduling,
        askg-data:Entity-schedules .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-347-Sentence-3474 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The results are summarised in Figure 13 and Table 10."@en ;
    askg-onto:inSentence "The results are summarised in Figure 13 and Table 10."^^xsd:string ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-348 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "![17_image_0.png](17_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-348-Sentence-3481 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-348-Sentence-3481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![17_image_0.png](17_image_0.png)"@en ;
    askg-onto:inSentence "![17_image_0.png](17_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-education_system,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-research,
        askg-data:Entity-research_area,
        askg-data:Entity-researchers,
        askg-data:Entity-technology,
        askg-data:Entity-universities .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-349 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Adam on 3-layer LSTM PTB Word-level Modelling."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-349-Sentence-3491 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-34-Paragraph-349-Sentence-3491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Adam on 3-layer LSTM PTB Word-level Modelling."@en ;
    askg-onto:inSentence "Adam on 3-layer LSTM PTB Word-level Modelling."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3-layer_lstm_ptb_word-level_modelling,
        askg-data:Entity-adam .

askg-data:Paper-43d37e59d752bc41-Section-35 a askg-onto:Section ;
    rdfs:label "Section 35"@en ;
    domo:Text "C.3. Relation Between Improvement From Averaging And Number Of Parameters In Previous Work"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-352,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-353 ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this section we demonstrate that our claim that there should be a dependence on number of parameters P on the margin of improvement from averaging is also present in previous works that use IA or a related ensemble method. Here we use the results from Table 1 of Izmailov et al. (2018). Since the different network architectures are trained with different budget of epochs which make the direct comparison of SWA results difficult, we instead consider their FGE (Garipov et al., 2018) results which the author argue to have the similar properties to and that is actually approximated by SWA. We plot their result along with us in Figure 14. While we do not obtain a perfect linear relationship possibly due to a wide range of possible interfering factors such as difference in architecture, use of batch normalisation, choice of optimiser and hyperparameter tuning, again we nevertheless observe that there exists a roughly positive relationship between P and the margin of test improvement."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3511,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3512,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3513,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3514,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3515,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3516 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this section we demonstrate that our claim that there should be a dependence on number of parameters P on the margin of improvement from averaging is also present in previous works that use IA or a related ensemble method."@en ;
    askg-onto:inSentence "In this section we demonstrate that our claim that there should be a dependence on number of parameters P on the margin of improvement from averaging is also present in previous works that use IA or a related ensemble method."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ensemble_method,
        askg-data:Entity-ia,
        askg-data:Entity-margin_of_improvement_from_averaging,
        askg-data:Entity-number_of_parameters_p,
        askg-data:Entity-previous_works .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here we use the results from Table 1 of Izmailov et al."@en ;
    askg-onto:inSentence "Here we use the results from Table 1 of Izmailov et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-izmailov_et_al .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2018)."@en ;
    askg-onto:inSentence "(2018)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-publication .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Since the different network architectures are trained with different budget of epochs which make the direct comparison of SWA results difficult, we instead consider their FGE (Garipov et al., 2018) results which the author argue to have the similar properties to and that is actually approximated by SWA."@en ;
    askg-onto:inSentence "Since the different network architectures are trained with different budget of epochs which make the direct comparison of SWA results difficult, we instead consider their FGE (Garipov et al., 2018) results which the author argue to have the similar properties to and that is actually approximated by SWA."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-fge,
        askg-data:Entity-fge_results,
        askg-data:Entity-garipov_et_al,
        askg-data:Entity-swa .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We plot their result along with us in Figure 14."@en ;
    askg-onto:inSentence "We plot their result along with us in Figure 14."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-result,
        askg-data:Entity-us .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-351-Sentence-3516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "While we do not obtain a perfect linear relationship possibly due to a wide range of possible interfering factors such as difference in architecture, use of batch normalisation, choice of optimiser and hyperparameter tuning, again we nevertheless observe that there exists a roughly positive relationship between P and the margin of test improvement."@en ;
    askg-onto:inSentence "While we do not obtain a perfect linear relationship possibly due to a wide range of possible interfering factors such as difference in architecture, use of batch normalisation, choice of optimiser and hyperparameter tuning, again we nevertheless observe that there exists a roughly positive relationship between P and the margin of test improvement."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-margin_of_test_improvement,
        askg-data:Entity-p .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-352 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Figure 14. Number of parameters P against improvement margin"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-352-Sentence-3521,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-352-Sentence-3522 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-352-Sentence-3521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 14."@en ;
    askg-onto:inSentence "Figure 14."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_14,
        askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-352-Sentence-3522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Number of parameters P against improvement margin"@en ;
    askg-onto:inSentence "Number of parameters P against improvement margin"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-improvement_margin,
        askg-data:Entity-number_of_parameters_p .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-353 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![18_image_1.png](18_image_1.png) for both results obtained by us and in Izmailov et al. (2018) (annotated with asterisks) on CIFAR-100"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-353-Sentence-3531,
        askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-353-Sentence-3532 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-353-Sentence-3531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![18_image_1.png](18_image_1.png) for both results obtained by us and in Izmailov et al."@en ;
    askg-onto:inSentence "![18_image_1.png](18_image_1.png) for both results obtained by us and in Izmailov et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-izmailov_et_al,
        askg-data:Entity-results,
        askg-data:Entity-us .

askg-data:Paper-43d37e59d752bc41-Section-35-Paragraph-353-Sentence-3532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2018) (annotated with asterisks) on CIFAR-100"@en ;
    askg-onto:inSentence "(2018) (annotated with asterisks) on CIFAR-100"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-cifar-100 .

askg-data:Paper-43d37e59d752bc41-Section-36 a askg-onto:Section ;
    rdfs:label "Section 36"@en ;
    domo:Text "D. Momentum: An Insight Into Gradient Bias In Deep Learning Optimisation"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-362,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-363,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-364,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-365,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-367 ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We argue that any bias in batch gradient estimate with respect to the true gradient, if present, is not as important as noise, at least in the framework we consider. However, since bias from the true data generating distribution is always unknown, we make an indirect argument from the results from biased optimisation, and in particular, the momentum. From a classical optimisation perspective, accelerated methods such as Polyak or Nesterov momentum, which are incorporated into adaptive optimisers, are considered advantageous in the deterministic case, where they can be shown to have the optimal rate of convergence for gradient based methods (Nesterov, 2013). Interestingly, from a biased online stochastic optimisation perspective, they can be shown to have a worse dependence on both the noise Ïƒ in the gradient 6and the bias Î´. As opposed to non-accelerated methods which have an optimal convergence rate of O( Î²R2 k + âˆš ÏƒR k +Î´) accelerated methods optain a rate O( Î²R2 k2 + âˆš ÏƒR k +kÎ´), where R = |w0 âˆ’ w âˆ—| and k is the number of iterations. In order to test whether the machinery of biased stochastic optimisation is relevant for deep learning, we run train the original VGG-16 network (Simonyan & Zisserman, 2014) with and without batch normalisation (Ioffe & Szegedy, 2015) on the CIFAR-100 data-set, again with and without L2 regularisation."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3611,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3612,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3613,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3614,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3615,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3616 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We argue that any bias in batch gradient estimate with respect to the true gradient, if present, is not as important as noise, at least in the framework we consider."@en ;
    askg-onto:inSentence "We argue that any bias in batch gradient estimate with respect to the true gradient, if present, is not as important as noise, at least in the framework we consider."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bias_in_batch_gradient_estimate,
        askg-data:Entity-framework,
        askg-data:Entity-gradient_estimate,
        askg-data:Entity-noise .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, since bias from the true data generating distribution is always unknown, we make an indirect argument from the results from biased optimisation, and in particular, the momentum."@en ;
    askg-onto:inSentence "However, since bias from the true data generating distribution is always unknown, we make an indirect argument from the results from biased optimisation, and in particular, the momentum."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bias,
        askg-data:Entity-biased_optimisation,
        askg-data:Entity-momentum,
        askg-data:Entity-true_data_generating_distribution .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "From a classical optimisation perspective, accelerated methods such as Polyak or Nesterov momentum, which are incorporated into adaptive optimisers, are considered advantageous in the deterministic case, where they can be shown to have the optimal rate of convergence for gradient based methods (Nesterov, 2013)."@en ;
    askg-onto:inSentence "From a classical optimisation perspective, accelerated methods such as Polyak or Nesterov momentum, which are incorporated into adaptive optimisers, are considered advantageous in the deterministic case, where they can be shown to have the optimal rate of convergence for gradient based methods (Nesterov, 2013)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2013,
        askg-data:Entity-accelerated_method,
        askg-data:Entity-accelerated_methods,
        askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-author,
        askg-data:Entity-gradient_based_methods,
        askg-data:Entity-nesterov,
        askg-data:Entity-nesterov_momentum,
        askg-data:Entity-optimal_rate_of_convergence,
        askg-data:Entity-polyak_momentum .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Interestingly, from a biased online stochastic optimisation perspective, they can be shown to have a worse dependence on both the noise Ïƒ in the gradient 6and the bias Î´."@en ;
    askg-onto:inSentence "Interestingly, from a biased online stochastic optimisation perspective, they can be shown to have a worse dependence on both the noise Ïƒ in the gradient 6and the bias Î´."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-online_stochastic_optimisation,
        askg-data:Entity-worse_dependence_on_noise_and_bias .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "As opposed to non-accelerated methods which have an optimal convergence rate of O( Î²R2 k + âˆš ÏƒR k +Î´) accelerated methods optain a rate O( Î²R2 k2 + âˆš ÏƒR k +kÎ´), where R = |w0 âˆ’ w âˆ—| and k is the number of iterations."@en ;
    askg-onto:inSentence "As opposed to non-accelerated methods which have an optimal convergence rate of O( Î²R2 k + âˆš ÏƒR k +Î´) accelerated methods optain a rate O( Î²R2 k2 + âˆš ÏƒR k +kÎ´), where R = |w0 âˆ’ w âˆ—| and k is the number of iterations."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-accelerated_methods,
        askg-data:Entity-k,
        askg-data:Entity-non-accelerated_methods,
        askg-data:Entity-o_%CE%B2r2_k2___%CF%83r_k_k%CE%B4,
        askg-data:Entity-o_%CE%B2r2_k___%CF%83r_k_%CE%B4,
        askg-data:Entity-r,
        askg-data:Entity-the_number_of_iterations,
        askg-data:Entity-w0__w_ .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-361-Sentence-3616 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In order to test whether the machinery of biased stochastic optimisation is relevant for deep learning, we run train the original VGG-16 network (Simonyan & Zisserman, 2014) with and without batch normalisation (Ioffe & Szegedy, 2015) on the CIFAR-100 data-set, again with and without L2 regularisation."@en ;
    askg-onto:inSentence "In order to test whether the machinery of biased stochastic optimisation is relevant for deep learning, we run train the original VGG-16 network (Simonyan & Zisserman, 2014) with and without batch normalisation (Ioffe & Szegedy, 2015) on the CIFAR-100 data-set, again with and without L2 regularisation."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalisation,
        askg-data:Entity-cifar-100_data-set,
        askg-data:Entity-ioffe__szegedy,
        askg-data:Entity-l2_regularisation,
        askg-data:Entity-simonyan__zisserman,
        askg-data:Entity-vgg-16_network .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-362 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![18_image_0.png](18_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-362-Sentence-3621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-362-Sentence-3621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![18_image_0.png](18_image_0.png)"@en ;
    askg-onto:inSentence "![18_image_0.png](18_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_vision,
        askg-data:Entity-image_recognition,
        askg-data:Entity-john_doe,
        askg-data:Entity-journal_of_ai_research,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-publication,
        askg-data:Entity-research_on_neural_networks .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-363 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "(b) Training Error Î» *= 0.*0005 Figure 15. VGG16 Training Accuracy for momenta Ï = [0, 0.9] and weight decay Î» *= [0,* 0.0005] (a) Training Error Î» = 0"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-363-Sentence-3631,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-363-Sentence-3632 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-363-Sentence-3631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(b) Training Error Î» *= 0.*0005 Figure 15."@en ;
    askg-onto:inSentence "(b) Training Error Î» *= 0.*0005 Figure 15."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-00005,
        askg-data:Entity-training_error .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-363-Sentence-3632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "VGG16 Training Accuracy for momenta Ï = [0, 0.9] and weight decay Î» *= [0,* 0.0005] (a) Training Error Î» = 0"@en ;
    askg-onto:inSentence "VGG16 Training Accuracy for momenta Ï = [0, 0.9] and weight decay Î» *= [0,* 0.0005] (a) Training Error Î» = 0"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB__0,
        askg-data:Entity-0_00005,
        askg-data:Entity-0_09,
        askg-data:Entity-momena_%CF%81,
        askg-data:Entity-training_accuracy,
        askg-data:Entity-training_error,
        askg-data:Entity-vgg16,
        askg-data:Entity-weight_decay_%CE%BB .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-364 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![18_image_2.png](18_image_2.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-364-Sentence-3641 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-364-Sentence-3641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![18_image_2.png](18_image_2.png)"@en ;
    askg-onto:inSentence "![18_image_2.png](18_image_2.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-data_science,
        askg-data:Entity-deep_learning,
        askg-data:Entity-keras,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-scikit-learn,
        askg-data:Entity-tensorflow .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-365 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "(b) Testing Error Î» *= 0.*0005 Figure 16. VGG16 Testing Accuracy for momenta Ï = [0, 0.9] and weight decay Î» = [0, 0.0005] (a) Testing Error Î» = 0"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-365-Sentence-3651,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-365-Sentence-3652 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-365-Sentence-3651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(b) Testing Error Î» *= 0.*0005 Figure 16."@en ;
    askg-onto:inSentence "(b) Testing Error Î» *= 0.*0005 Figure 16."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB__00005,
        askg-data:Entity-testing_error .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-365-Sentence-3652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "VGG16 Testing Accuracy for momenta Ï = [0, 0.9] and weight decay Î» = [0, 0.0005] (a) Testing Error Î» = 0"@en ;
    askg-onto:inSentence "VGG16 Testing Accuracy for momenta Ï = [0, 0.9] and weight decay Î» = [0, 0.0005] (a) Testing Error Î» = 0"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-momentum_%CF%81__0_09,
        askg-data:Entity-testing_error_%CE%BB__0,
        askg-data:Entity-vgg16,
        askg-data:Entity-weight_decay_%CE%BB__0_00005 .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Interestingly, for both networks, with or without weight decay (set at a typical value of Î» = 0.0005 for simplicity) we see that whilst the training curves are not always more benign for momentum as shown in Figures 15 the testing performance shown in Figures 16 is. This holds with or without weight decay, hence we isolate the effect to momentum. Note that for the VGG-16 without batch normalization or weight decay, the typically used values of the learning rate all diverge early in training as shown in Figure 15a and hence a significantly smaller learning rate must be used. We note that on the noiseless convex quadratic the compounding of the momenta gives an effective learning rate of Î± 1âˆ’Ï and hence we mutiply by 1 âˆ’ Ï to correct for this. The key message of this result is that if bias is important, we would expect optimisation with momentum to generalise"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3661,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3662,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3663,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3664,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3665 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Interestingly, for both networks, with or without weight decay (set at a typical value of Î» = 0.0005 for simplicity) we see that whilst the training curves are not always more benign for momentum as shown in Figures 15 the testing performance shown in Figures 16 is."@en ;
    askg-onto:inSentence "Interestingly, for both networks, with or without weight decay (set at a typical value of Î» = 0.0005 for simplicity) we see that whilst the training curves are not always more benign for momentum as shown in Figures 15 the testing performance shown in Figures 16 is."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-00005,
        askg-data:Entity-figures_15,
        askg-data:Entity-figures_16,
        askg-data:Entity-momentum,
        askg-data:Entity-networks,
        askg-data:Entity-testing_performance,
        askg-data:Entity-training_curves,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3662 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This holds with or without weight decay, hence we isolate the effect to momentum."@en ;
    askg-onto:inSentence "This holds with or without weight decay, hence we isolate the effect to momentum."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-momentum,
        askg-data:Entity-weight_decay .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3663 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Note that for the VGG-16 without batch normalization or weight decay, the typically used values of the learning rate all diverge early in training as shown in Figure 15a and hence a significantly smaller learning rate must be used."@en ;
    askg-onto:inSentence "Note that for the VGG-16 without batch normalization or weight decay, the typically used values of the learning rate all diverge early in training as shown in Figure 15a and hence a significantly smaller learning rate must be used."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-learning_rate,
        askg-data:Entity-model,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3664 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We note that on the noiseless convex quadratic the compounding of the momenta gives an effective learning rate of Î± 1âˆ’Ï and hence we mutiply by 1 âˆ’ Ï to correct for this."@en ;
    askg-onto:inSentence "We note that on the noiseless convex quadratic the compounding of the momenta gives an effective learning rate of Î± 1âˆ’Ï and hence we mutiply by 1 âˆ’ Ï to correct for this."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1__%CF%81,
        askg-data:Entity-effective_learning_rate_of_%CE%B1_1%CF%81,
        askg-data:Entity-noiseless_convex_quadratic .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-366-Sentence-3665 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The key message of this result is that if bias is important, we would expect optimisation with momentum to generalise"@en ;
    askg-onto:inSentence "The key message of this result is that if bias is important, we would expect optimisation with momentum to generalise"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bias,
        askg-data:Entity-optimisation_with_momentum,
        askg-data:Entity-result .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-367 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "19 6hence requiring a more aggressive reduction in learning rate to achieve convergence worse, due to the worse dependence from the theoretical results. The fact that optimisation with momentum generalises *better*, seems to suggest that any bias, if present, is of secondary importance, and we demonstrate this on a realistic modern network."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-367-Sentence-3671,
        askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-367-Sentence-3672 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-367-Sentence-3671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "19 6hence requiring a more aggressive reduction in learning rate to achieve convergence worse, due to the worse dependence from the theoretical results."@en ;
    askg-onto:inSentence "19 6hence requiring a more aggressive reduction in learning rate to achieve convergence worse, due to the worse dependence from the theoretical results."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aggressive_reduction,
        askg-data:Entity-learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-36-Paragraph-367-Sentence-3672 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The fact that optimisation with momentum generalises *better*, seems to suggest that any bias, if present, is of secondary importance, and we demonstrate this on a realistic modern network."@en ;
    askg-onto:inSentence "The fact that optimisation with momentum generalises *better*, seems to suggest that any bias, if present, is of secondary importance, and we demonstrate this on a realistic modern network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-better,
        askg-data:Entity-bias,
        askg-data:Entity-optimisation_with_momentum,
        askg-data:Entity-realistic_modern_network,
        askg-data:Entity-secondary_importance .

askg-data:Paper-43d37e59d752bc41-Section-37 a askg-onto:Section ;
    rdfs:label "Section 37"@en ;
    domo:Text "E. Derivations"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-371,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3710,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3711,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3712,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3713,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-372,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-373,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-376,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-377,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-378,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-379 ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-371 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "E.1. Proof of Theorem 1 The basic idea, is that since"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-371-Sentence-3711,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-371-Sentence-3712 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-371-Sentence-3711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "E.1."@en ;
    askg-onto:inSentence "E.1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e1,
        askg-data:Entity-text .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-371-Sentence-3712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Proof of Theorem 1 The basic idea, is that since"@en ;
    askg-onto:inSentence "Proof of Theorem 1 The basic idea, is that since"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proof_of_theorem_1,
        askg-data:Entity-theorem_1 .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3710 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "$$\\begin{array}{l l}{{\\mathbb{P}\\{\\left|{\\frac{1}{\\sqrt{P}}}\\|X\\|_{2}-1\\right|\\geq\\delta\\}}}\\\\ {{}}\\\\ {{}}\\\\ {{\\leq\\mathbb{P}\\{\\left|{\\frac{1}{P}}\\|X\\|_{2}^{2}-1\\right|\\geq\\max(\\delta,\\delta^{2})\\}}}\\\\ {{}}\\\\ {{}}\\\\ {{\\leq2\\exp-{\\frac{c P}{K^{4}\\delta^{2}}}}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3710-Sentence-37101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3710-Sentence-37101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l l}{{\\mathbb{P}\\{\\left|{\\frac{1}{\\sqrt{P}}}\\|X\\|_{2}-1\\right|\\geq\\delta\\}}}\\\\ {{}}\\\\ {{}}\\\\ {{\\leq\\mathbb{P}\\{\\left|{\\frac{1}{P}}\\|X\\|_{2}^{2}-1\\right|\\geq\\max(\\delta,\\delta^{2})\\}}}\\\\ {{}}\\\\ {{}}\\\\ {{\\leq2\\exp-{\\frac{c P}{K^{4}\\delta^{2}}}}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{l l}{{\\mathbb{P}\\{\\left|{\\frac{1}{\\sqrt{P}}}\\|X\\|_{2}-1\\right|\\geq\\delta\\}}}\\\\ {{}}\\\\ {{}}\\\\ {{\\leq\\mathbb{P}\\{\\left|{\\frac{1}{P}}\\|X\\|_{2}^{2}-1\\right|\\geq\\max(\\delta,\\delta^{2})\\}}}\\\\ {{}}\\\\ {{}}\\\\ {{\\leq2\\exp-{\\frac{c P}{K^{4}\\delta^{2}}}}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extdelta,
        askg-data:Entity-%09extnorm,
        askg-data:Entity-%09extscore,
        askg-data:Entity-%09extvector,
        askg-data:Entity-%0Crac1%09extsqrtp%09extx%09ext_2,
        askg-data:Entity-%0Crac1p%09extx%09ext_22,
        askg-data:Entity-p,
        askg-data:Entity-x .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3711 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "$$(20)^{\\frac{1}{2}}$$ . 1 n"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3711-Sentence-37111,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3711-Sentence-37112 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3711-Sentence-37111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(20)^{\\frac{1}{2}}$$ ."@en ;
    askg-onto:inSentence "$$(20)^{\\frac{1}{2}}$$ ."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-20,
        askg-data:Entity-number .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3711-Sentence-37112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "1 n"@en ;
    askg-onto:inSentence "1 n"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-n .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3712 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "$$(15)$$ $$(16)^{\\frac{1}{2}}$$ to $t=\\delta\\sqrt{P}$ we obtain. âˆšP we obtain changing variables to t = Î´"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3712-Sentence-37121,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3712-Sentence-37122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3712-Sentence-37121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(15)$$ $$(16)^{\\frac{1}{2}}$$ to $t=\\delta\\sqrt{P}$ we obtain."@en ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3712-Sentence-37122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "âˆšP we obtain changing variables to t = Î´"@en ;
    askg-onto:inSentence "âˆšP we obtain changing variables to t = Î´"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B4,
        askg-data:Entity-t .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3713 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "$$\\mathbb{P}\\{||X||_{2}-{\\sqrt{P}}|\\geq t\\}\\leq2\\exp-{\\frac{c t^{2}}{K^{4}}}$$ K4(16) for all t â‰¥ 0 Our proofs follows by noting that the significance of the 1 in equation 15 is simply the mean of the square and hence by replacing it by the mean squared plus variance we obtain Theorem 1."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3713-Sentence-37131 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-3713-Sentence-37131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbb{P}\\{||X||_{2}-{\\sqrt{P}}|\\geq t\\}\\leq2\\exp-{\\frac{c t^{2}}{K^{4}}}$$ K4(16) for all t â‰¥ 0 Our proofs follows by noting that the significance of the 1 in equation 15 is simply the mean of the square and hence by replacing it by the mean squared plus variance we obtain Theorem 1."@en ;
    askg-onto:inSentence "$$\\mathbb{P}\\{||X||_{2}-{\\sqrt{P}}|\\geq t\\}\\leq2\\exp-{\\frac{c t^{2}}{K^{4}}}$$ K4(16) for all t â‰¥ 0 Our proofs follows by noting that the significance of the 1 in equation 15 is simply the mean of the square and hence by replacing it by the mean squared plus variance we obtain Theorem 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-result,
        askg-data:Entity-theorem_1 .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-372 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbb{E}||\\mathbf{w}||_{2}^{2}=\\sum_{i}^{P}\\mathbb{E}(w_{i}^{2})=\\sum_{i}^{P}\\left(\\left(\\mathbb{E}(w_{i})\\right)^{2}+\\mathbb{V}(w_{i})\\right)\\tag{11}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-372-Sentence-3721 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-372-Sentence-3721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbb{E}||\\mathbf{w}||_{2}^{2}=\\sum_{i}^{P}\\mathbb{E}(w_{i}^{2})=\\sum_{i}^{P}\\left(\\left(\\mathbb{E}(w_{i})\\right)^{2}+\\mathbb{V}(w_{i})\\right)\\tag{11}$$"@en ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-373 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "we expect ||w||2 to be approximately the square root of this."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-373-Sentence-3731 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-373-Sentence-3731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "we expect ||w||2 to be approximately the square root of this."@en ;
    askg-onto:inSentence "we expect ||w||2 to be approximately the square root of this."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-this,
        askg-data:Entity-w2 .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Our proof follows very closely from Vershynin (2018) (p.51) except that the variables we consider are not zero-mean or unit-variance. We sketch the proof below: Proof Sketch: To show that Theorem 1 is indeed true with high probability, we consider the centered, unit variance version of the random variables i.e Xi = (XËœi âˆ’ Âµi)/Ïƒi Lemma 1 *(Bernstein's inequality)*: Let {X1*, ..X*n} be independent, zero mean, sub-exponential random variables. Then for every t â‰¥ 0, we have"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374-Sentence-3741,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374-Sentence-3742,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374-Sentence-3743 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374-Sentence-3741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our proof follows very closely from Vershynin (2018) (p.51) except that the variables we consider are not zero-mean or unit-variance."@en ;
    askg-onto:inSentence "Our proof follows very closely from Vershynin (2018) (p.51) except that the variables we consider are not zero-mean or unit-variance."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proof,
        askg-data:Entity-vershynin .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374-Sentence-3742 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We sketch the proof below: Proof Sketch: To show that Theorem 1 is indeed true with high probability, we consider the centered, unit variance version of the random variables i.e Xi = (XËœi âˆ’ Âµi)/Ïƒi Lemma 1 *(Bernstein's inequality)*: Let {X1*, ..X*n} be independent, zero mean, sub-exponential random variables."@en ;
    askg-onto:inSentence "We sketch the proof below: Proof Sketch: To show that Theorem 1 is indeed true with high probability, we consider the centered, unit variance version of the random variables i.e Xi = (XËœi âˆ’ Âµi)/Ïƒi Lemma 1 *(Bernstein's inequality)*: Let {X1*, ..X*n} be independent, zero mean, sub-exponential random variables."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bernsteins_inequality,
        askg-data:Entity-centered_unit_variance_version_of_the_random_variables,
        askg-data:Entity-independent_zero_mean_sub-exponential_random_variables,
        askg-data:Entity-theorem_1,
        askg-data:Entity-x1_xn .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-374-Sentence-3743 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Then for every t â‰¥ 0, we have"@en ;
    askg-onto:inSentence "Then for every t â‰¥ 0, we have"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-t,
        askg-data:Entity-time_variable .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\mathbb{P}\\Bigg{\\{}\\left|\\frac{1}{N}\\sum_{i}\\sum_{i}^{N}X_{i}\\right|\\geq t\\Bigg{\\}}\\leq2\\exp\\left\\{-\\text{cmin}\\bigg{(}\\frac{t^{2}}{K^{2}},\\frac{t}{K}\\bigg{)}N\\right\\}\\tag{12}$$ where $K=\\arg\\max_{i}||X_{i}||_{\\phi_{1}}$, and $||X||_{\\phi_{i}}=\\inf\\{t>0:\\mathbb{E}\\exp|X|/t\\leq2$. Proof. The proof is standard and can be found in Vershynin (2018) p.45, essentially we multiply both sides of the inequality by Î», exponentiate, use Markov's inequality and independence assumption. Then we bound the MGF of each Xi and optimise for Î» Let X = (X1*, ..., X*n) âˆˆ R P be a random vector with independent sub-gaussian coordinates Xi, that satisfy EX2 i = 1."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3751,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3752,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3753,
        askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3754 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbb{P}\\Bigg{\\{}\\left|\\frac{1}{N}\\sum_{i}\\sum_{i}^{N}X_{i}\\right|\\geq t\\Bigg{\\}}\\leq2\\exp\\left\\{-\\text{cmin}\\bigg{(}\\frac{t^{2}}{K^{2}},\\frac{t}{K}\\bigg{)}N\\right\\}\\tag{12}$$ where $K=\\arg\\max_{i}||X_{i}||_{\\phi_{1}}$, and $||X||_{\\phi_{i}}=\\inf\\{t>0:\\mathbb{E}\\exp|X|/t\\leq2$."@en ;
    askg-onto:inSentence "$$\\mathbb{P}\\Bigg{\\{}\\left|\\frac{1}{N}\\sum_{i}\\sum_{i}^{N}X_{i}\\right|\\geq t\\Bigg{\\}}\\leq2\\exp\\left\\{-\\text{cmin}\\bigg{(}\\frac{t^{2}}{K^{2}},\\frac{t}{K}\\bigg{)}N\\right\\}\\tag{12}$$ where $K=\\arg\\max_{i}||X_{i}||_{\\phi_{1}}$, and $||X||_{\\phi_{i}}=\\inf\\{t>0:\\mathbb{E}\\exp|X|/t\\leq2$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-argmax_ix_i_phi_1,
        askg-data:Entity-expleft-textcminbiggfract2k2fractkbiggnright,
        askg-data:Entity-expxt,
        askg-data:Entity-k,
        askg-data:Entity-mathbbe,
        askg-data:Entity-t,
        askg-data:Entity-x_i,
        askg-data:Entity-x_phi_i .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3752 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Proof."@en ;
    askg-onto:inSentence "Proof."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-proof .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3753 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The proof is standard and can be found in Vershynin (2018) p.45, essentially we multiply both sides of the inequality by Î», exponentiate, use Markov's inequality and independence assumption."@en ;
    askg-onto:inSentence "The proof is standard and can be found in Vershynin (2018) p.45, essentially we multiply both sides of the inequality by Î», exponentiate, use Markov's inequality and independence assumption."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018,
        askg-data:Entity-inequality,
        askg-data:Entity-markovs_inequality,
        askg-data:Entity-vershynin .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-375-Sentence-3754 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Then we bound the MGF of each Xi and optimise for Î» Let X = (X1*, ..., X*n) âˆˆ R P be a random vector with independent sub-gaussian coordinates Xi, that satisfy EX2 i = 1."@en ;
    askg-onto:inSentence "Then we bound the MGF of each Xi and optimise for Î» Let X = (X1*, ..., X*n) âˆˆ R P be a random vector with independent sub-gaussian coordinates Xi, that satisfy EX2 i = 1."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ex2_i__1,
        askg-data:Entity-independent_sub-gaussian_coordinates,
        askg-data:Entity-mgf,
        askg-data:Entity-random_vector,
        askg-data:Entity-xi .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-376 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "We then apply Berstein's deviation inequality (Lemma 1) for the normalized sum of independent, mean zero variables"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-376-Sentence-3761 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-376-Sentence-3761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We then apply Berstein's deviation inequality (Lemma 1) for the normalized sum of independent, mean zero variables"@en ;
    askg-onto:inSentence "We then apply Berstein's deviation inequality (Lemma 1) for the normalized sum of independent, mean zero variables"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bersteins_deviation_inequality,
        askg-data:Entity-normalized_sum_of_independent_mean_zero_variables .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-377 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$\\frac{1}{P}||X||_{2}^{2}-1=\\frac{1}{n}\\sum_{i}^{P}(X_{i}^{2}-1)\\tag{13}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-377-Sentence-3771 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-377-Sentence-3771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\frac{1}{P}||X||_{2}^{2}-1=\\frac{1}{n}\\sum_{i}^{P}(X_{i}^{2}-1)\\tag{13}$$"@en ;
    askg-onto:inSentence "$$\\frac{1}{P}||X||_{2}^{2}-1=\\frac{1}{n}\\sum_{i}^{P}(X_{i}^{2}-1)\\tag{13}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-n,
        askg-data:Entity-p,
        askg-data:Entity-x,
        askg-data:Entity-x_i .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-378 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Since Xiis sub-gaussian X2 i âˆ’ 1 is sub-exponential and by centering and the boundedness of the MGF ||X2 i âˆ’ 1||Ï†1 â‰¤"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-378-Sentence-3781 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-378-Sentence-3781 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Since Xiis sub-gaussian X2 i âˆ’ 1 is sub-exponential and by centering and the boundedness of the MGF ||X2 i âˆ’ 1||Ï†1 â‰¤"@en ;
    askg-onto:inSentence "Since Xiis sub-gaussian X2 i âˆ’ 1 is sub-exponential and by centering and the boundedness of the MGF ||X2 i âˆ’ 1||Ï†1 â‰¤"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mgf,
        askg-data:Entity-sub-exponential,
        askg-data:Entity-x2_i__1,
        askg-data:Entity-x2_i__1%CF%861 .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-379 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$CK^{2}$ hence assuming $K\\geq1$ $$\\mathbb{P}\\bigg{\\{}\\left|\\frac{1}{P}||X||_{2}^{2}-1\\right|\\geq u\\bigg{\\}}\\leq2\\exp\\bigg{(}-\\frac{cP}{K^{4}}\\min(u^{2},u)\\bigg{)}\\tag{14}$$ Then using |z âˆ’ 1| â‰¥ Î´ implies |z 2 âˆ’ 1| â‰¥ max(*Î´, Î´*2)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-379-Sentence-3791 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-37-Paragraph-379-Sentence-3791 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$CK^{2}$ hence assuming $K\\geq1$ $$\\mathbb{P}\\bigg{\\{}\\left|\\frac{1}{P}||X||_{2}^{2}-1\\right|\\geq u\\bigg{\\}}\\leq2\\exp\\bigg{(}-\\frac{cP}{K^{4}}\\min(u^{2},u)\\bigg{)}\\tag{14}$$ Then using |z âˆ’ 1| â‰¥ Î´ implies |z 2 âˆ’ 1| â‰¥ max(*Î´, Î´*2)"@en ;
    askg-onto:inSentence "$CK^{2}$ hence assuming $K\\geq1$ $$\\mathbb{P}\\bigg{\\{}\\left|\\frac{1}{P}||X||_{2}^{2}-1\\right|\\geq u\\bigg{\\}}\\leq2\\exp\\bigg{(}-\\frac{cP}{K^{4}}\\min(u^{2},u)\\bigg{)}\\tag{14}$$ Then using |z âˆ’ 1| â‰¥ Î´ implies |z 2 âˆ’ 1| â‰¥ max(*Î´, Î´*2)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ck2,
        askg-data:Entity-cp,
        askg-data:Entity-k,
        askg-data:Entity-u2u,
        askg-data:Entity-x_22 .

askg-data:Paper-43d37e59d752bc41-Section-38 a askg-onto:Section ;
    rdfs:label "Section 38"@en ;
    domo:Text "E.2. Proof Of Theorem 2"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-381,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-382,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-383,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-384,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-385,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-386,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387 ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-381 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Building on the quadratic analysis in Martens (2014), we first consider result for a fixed learning rate pure gradient method where, the final/average iterate will tends to a loss EL(wn), EL(w*avg,n*) respectively as n â†’ âˆž:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-381-Sentence-3811 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-381-Sentence-3811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Building on the quadratic analysis in Martens (2014), we first consider result for a fixed learning rate pure gradient method where, the final/average iterate will tends to a loss EL(wn), EL(w*avg,n*) respectively as n â†’ âˆž:"@en ;
    askg-onto:inSentence "Building on the quadratic analysis in Martens (2014), we first consider result for a fixed learning rate pure gradient method where, the final/average iterate will tends to a loss EL(wn), EL(w*avg,n*) respectively as n â†’ âˆž:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finalaverage_iterate,
        askg-data:Entity-learning_rate_method,
        askg-data:Entity-loss_elwavgn,
        askg-data:Entity-loss_elwn,
        askg-data:Entity-martens_2014,
        askg-data:Entity-pure_gradient_method,
        askg-data:Entity-quadratic_analysis .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-382 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{\\alpha}{4}\\text{Tr}\\bigg{(}(1-\\frac{\\alpha}{2}\\mathbf{H})^{-1}\\mathbf{\\Sigma}_{g}(\\mathbf{w}^{*})\\bigg{)}$$ $$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{avg,n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{1}{2n+2}\\text{Tr}\\bigg{(}\\mathbf{H}^{-1}\\mathbf{\\Sigma}_{g}(\\mathbf{w}^{*})\\bigg{)}\\tag{17}$$ where $\\mathbf{\\Sigma}_{g}$ is the gradient noise covariance. Thus, for the expected loss of the iterate to be lower, we need:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-382-Sentence-3821,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-382-Sentence-3822 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-382-Sentence-3821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{\\alpha}{4}\\text{Tr}\\bigg{(}(1-\\frac{\\alpha}{2}\\mathbf{H})^{-1}\\mathbf{\\Sigma}_{g}(\\mathbf{w}^{*})\\bigg{)}$$ $$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{avg,n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{1}{2n+2}\\text{Tr}\\bigg{(}\\mathbf{H}^{-1}\\mathbf{\\Sigma}_{g}(\\mathbf{w}^{*})\\bigg{)}\\tag{17}$$ where $\\mathbf{\\Sigma}_{g}$ is the gradient noise covariance."@en ;
    askg-onto:inSentence "$$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{\\alpha}{4}\\text{Tr}\\bigg{(}(1-\\frac{\\alpha}{2}\\mathbf{H})^{-1}\\mathbf{\\Sigma}_{g}(\\mathbf{w}^{*})\\bigg{)}$$ $$\\mathbb{E}\\bigg{(}L(\\mathbf{w}_{avg,n})\\bigg{)}\\leq L(\\mathbf{w}^{*})+\\frac{1}{2n+2}\\text{Tr}\\bigg{(}\\mathbf{H}^{-1}\\mathbf{\\Sigma}_{g}(\\mathbf{w}^{*})\\bigg{)}\\tag{17}$$ where $\\mathbf{\\Sigma}_{g}$ is the gradient noise covariance."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0A%0A_%0A%0A_%0A%0Al%0A%0A_%0A%0Aw%0A%0A_%0A%0An%0A%0A,
        askg-data:Entity-l%0A%0A_%0A%0Aw%0A%0A_%0A%0A__%0A%0A_%0A%0A%0A%0A__%0A%0A_%0A%0A_%0A%0A_%0A%0A_%0A%0A_%0A%0A%0Crac%0A%0A_%0A%0A%09extalpha4%09exttrigg1-%0Crac%09extalpha2%0A%0Ah%0A%0A-1%0A%0A%09extsigma_g%0A%0A_%0A%0Aw%0A%0A_%0A%0Aigg .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-382-Sentence-3822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Thus, for the expected loss of the iterate to be lower, we need:"@en ;
    askg-onto:inSentence "Thus, for the expected loss of the iterate to be lower, we need:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expected_loss,
        askg-data:Entity-iterate .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-383 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$${\\frac{\\alpha}{4}}\\mathrm{Tr}\\!\\left((1-{\\frac{\\alpha}{2}}H)^{-1}\\Sigma_{g}(\\mathbf{w}^{*})\\right)\\leq{\\frac{1}{2n+2}}\\mathrm{Tr}\\!\\left(H^{-1}\\right)$$ TrHâˆ’1Î£g(wâˆ—) $$(19)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-383-Sentence-3831 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-383-Sentence-3831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\frac{\\alpha}{4}}\\mathrm{Tr}\\!\\left((1-{\\frac{\\alpha}{2}}H)^{-1}\\Sigma_{g}(\\mathbf{w}^{*})\\right)\\leq{\\frac{1}{2n+2}}\\mathrm{Tr}\\!\\left(H^{-1}\\right)$$ TrHâˆ’1Î£g(wâˆ—) $$(19)$$"@en ;
    askg-onto:inSentence "$${\\frac{\\alpha}{4}}\\mathrm{Tr}\\!\\left((1-{\\frac{\\alpha}{2}}H)^{-1}\\Sigma_{g}(\\mathbf{w}^{*})\\right)\\leq{\\frac{1}{2n+2}}\\mathrm{Tr}\\!\\left(H^{-1}\\right)$$ TrHâˆ’1Î£g(wâˆ—) $$(19)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Crac12n2trh-1,
        askg-data:Entity-%CF%83g%F0%9D%91%A4,
        askg-data:Entity-h,
        askg-data:Entity-h-1,
        askg-data:Entity-tr .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-384 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$\\begin{array}{c}{{g\\left(\\mathbf{w}^{*}\\right)}}\\\\ {{}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-384-Sentence-3841 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-384-Sentence-3841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{c}{{g\\left(\\mathbf{w}^{*}\\right)}}\\\\ {{}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{c}{{g\\left(\\mathbf{w}^{*}\\right)}}\\\\ {{}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function,
        askg-data:Entity-gw .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-385 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Simplifying yields"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-385-Sentence-3851 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-385-Sentence-3851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Simplifying yields"@en ;
    askg-onto:inSentence "Simplifying yields"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-result,
        askg-data:Entity-simplifying .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-386 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$\\alpha\\leq{\\frac{2}{2+n}}{\\frac{\\mathrm{Tr}H^{-1}}{P}}$$ P(19) which requires Î± âˆ E.3. Proof of Theorem 3 For T = 2"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-386-Sentence-3861,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-386-Sentence-3862 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-386-Sentence-3861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\alpha\\leq{\\frac{2}{2+n}}{\\frac{\\mathrm{Tr}H^{-1}}{P}}$$ P(19) which requires Î± âˆ E.3."@en ;
    askg-onto:inSentence "$$\\alpha\\leq{\\frac{2}{2+n}}{\\frac{\\mathrm{Tr}H^{-1}}{P}}$$ P(19) which requires Î± âˆ E.3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1,
        askg-data:Entity-e3 .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-386-Sentence-3862 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Proof of Theorem 3 For T = 2"@en ;
    askg-onto:inSentence "Proof of Theorem 3 For T = 2"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-t__2,
        askg-data:Entity-theorem_3 .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$${\\frac{(\\mathbf{w}_{1}+\\mathbf{w}_{2})^{2}}{4}}\\leq{\\frac{\\mathbf{w}_{1}^{2}+\\mathbf{w}_{2}^{2}}{2}}$$ 2(20) $$0\\leq(\\mathbf{w}_{1}-\\mathbf{w}_{2})^{2}\\tag{21}$$ Assume for $T=n$, for $T=n+1$ i.e. $(\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{w}_{i})^{2}\\leq\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}$ $$\\left(\\frac{1}{n+1}\\sum_{i=1}^{n+1}\\mathbf{w}_{i}\\right)^{2}\\leq\\frac{1}{n}\\sum_{i=1}^{n+1}\\mathbf{w}_{i}^{2}+\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}\\tag{22}$$ $$\\left(\\sum_{i=1}^{n}\\mathbf{w}_{i}\\right)^{2}+2\\mathbf{w}_{n+1}\\sum_{i=1}^{n}\\mathbf{w}_{i}+\\mathbf{w}_{n+1}^{2}$$ $$\\leq n\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}+\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}+(n+1)\\mathbf{w}_{n+1}^{2}$$ $$0\\leq\\sum_{i=1}^{n}(\\mathbf{w}_{i}-\\mathbf{w}_{n+1})^{2}$$ wi + w2n+1 (23) 2(24) : 21 $$\\mathbf{w}_{k+1}\\leftarrow\\mathbf{w}_{k}-\\alpha\\bar{\\mathbf{B}}^{-1}\\nabla L_{k}(\\mathbf{w})\\tag{29}$$ $$\\left({\\frac{1}{T}}\\sum_{i=1}^{T}\\mathbf{w}_{i}\\right)^{2}\\leq{\\frac{1}{T}}\\sum_{i=1}^{T}\\mathbf{w}_{i}^{2}$$ i(25) $$\\delta L=L_{\\mathbf{w}_{t+1}}-L_{\\mathbf{w}^{*}}\\leq\\nabla L_{\\mathbf{w}_{t}}(\\mathbf{w}_{t+1}-\\mathbf{w}^{*})+\\frac{\\beta}{2}||\\mathbf{w}_{t+1}-\\mathbf{w}_{t}||^{2},$$ $$\\mathbb{E}(\\delta L)\\leq\\hat{\\nabla}L_{\\mathbf{w}_{t}}(\\mathbf{w}_{t}-\\mathbf{w}^{*})-(\\alpha-\\frac{\\beta\\alpha^{2}}{2})||\\hat{\\nabla}L_{\\mathbf{w}_{t}}||^{2}+\\alpha\\sigma_{t}^{2}\\tag{26}$$ where $\\hat{\\nabla}L_{\\mathbf{w}_{t}}$ is the noisy gradient at $\\mathbf{w}_{t}$ and $\\sigma_{t}^{2}$ is its vari tis its vari- $${\\frac{R}{T}}=\\mathbb{E}\\Big[{\\frac{1}{T}}\\sum_{t=1}^{T-1}L_{\\mathbf{w}_{t+1}}-L_{\\mathbf{w}^{*}}\\Big]\\qquad\\qquad(27)$$ $$\\frac{R}{T}\\leq\\frac{1}{T}\\sum_{t=0}^{T-1}\\frac{||\\mathbf{w_{t}-w^{*}}||^{2}-||\\mathbf{w_{t+1}-w^{*}}||^{2}}{2\\alpha}+\\alpha\\sigma_{t}^{2}$$ $$\\mathbb{E}[L_{\\frac{1}{T}\\sum_{t=1}^{T-1}\\mathbf{w_{t+1}}}-L_{\\mathbf{w^{*}}}]\\leq\\frac{R}{T}\\leq\\frac{||\\mathbf{w_{0}-w^{*}}||^{2}}{2\\alpha T}+\\alpha\\sigma_{m}^{2}\\tag{28}$$ where $\\sigma_{m}^{2}=\\arg\\max_{\\mathbf{w_{t}}}\\mathbb{E}||\\tilde{\\nabla}L_{\\mathbf{w_{t}}}-\\nabla L_{\\mathbf{w_{t}}}||^{2}$, and $R$ is the regret. Setting $\\alpha=(\\beta+\\sigma\\frac{\\sqrt{T}}{D})^{-1}$ in equation 27 gives us D"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387-Sentence-3871,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387-Sentence-3872,
        askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387-Sentence-3873 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387-Sentence-3871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\frac{(\\mathbf{w}_{1}+\\mathbf{w}_{2})^{2}}{4}}\\leq{\\frac{\\mathbf{w}_{1}^{2}+\\mathbf{w}_{2}^{2}}{2}}$$ 2(20) $$0\\leq(\\mathbf{w}_{1}-\\mathbf{w}_{2})^{2}\\tag{21}$$ Assume for $T=n$, for $T=n+1$ i.e."@en ;
    askg-onto:inSentence "$${\\frac{(\\mathbf{w}_{1}+\\mathbf{w}_{2})^{2}}{4}}\\leq{\\frac{\\mathbf{w}_{1}^{2}+\\mathbf{w}_{2}^{2}}{2}}$$ 2(20) $$0\\leq(\\mathbf{w}_{1}-\\mathbf{w}_{2})^{2}\\tag{21}$$ Assume for $T=n$, for $T=n+1$ i.e."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-natural_number,
        askg-data:Entity-t,
        askg-data:Entity-w1,
        askg-data:Entity-w2,
        askg-data:Entity-weight .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387-Sentence-3872 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "$(\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{w}_{i})^{2}\\leq\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}$ $$\\left(\\frac{1}{n+1}\\sum_{i=1}^{n+1}\\mathbf{w}_{i}\\right)^{2}\\leq\\frac{1}{n}\\sum_{i=1}^{n+1}\\mathbf{w}_{i}^{2}+\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}\\tag{22}$$ $$\\left(\\sum_{i=1}^{n}\\mathbf{w}_{i}\\right)^{2}+2\\mathbf{w}_{n+1}\\sum_{i=1}^{n}\\mathbf{w}_{i}+\\mathbf{w}_{n+1}^{2}$$ $$\\leq n\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}+\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}+(n+1)\\mathbf{w}_{n+1}^{2}$$ $$0\\leq\\sum_{i=1}^{n}(\\mathbf{w}_{i}-\\mathbf{w}_{n+1})^{2}$$ wi + w2n+1 (23) 2(24) : 21 $$\\mathbf{w}_{k+1}\\leftarrow\\mathbf{w}_{k}-\\alpha\\bar{\\mathbf{B}}^{-1}\\nabla L_{k}(\\mathbf{w})\\tag{29}$$ $$\\left({\\frac{1}{T}}\\sum_{i=1}^{T}\\mathbf{w}_{i}\\right)^{2}\\leq{\\frac{1}{T}}\\sum_{i=1}^{T}\\mathbf{w}_{i}^{2}$$ i(25) $$\\delta L=L_{\\mathbf{w}_{t+1}}-L_{\\mathbf{w}^{*}}\\leq\\nabla L_{\\mathbf{w}_{t}}(\\mathbf{w}_{t+1}-\\mathbf{w}^{*})+\\frac{\\beta}{2}||\\mathbf{w}_{t+1}-\\mathbf{w}_{t}||^{2},$$ $$\\mathbb{E}(\\delta L)\\leq\\hat{\\nabla}L_{\\mathbf{w}_{t}}(\\mathbf{w}_{t}-\\mathbf{w}^{*})-(\\alpha-\\frac{\\beta\\alpha^{2}}{2})||\\hat{\\nabla}L_{\\mathbf{w}_{t}}||^{2}+\\alpha\\sigma_{t}^{2}\\tag{26}$$ where $\\hat{\\nabla}L_{\\mathbf{w}_{t}}$ is the noisy gradient at $\\mathbf{w}_{t}$ and $\\sigma_{t}^{2}$ is its vari tis its vari- $${\\frac{R}{T}}=\\mathbb{E}\\Big[{\\frac{1}{T}}\\sum_{t=1}^{T-1}L_{\\mathbf{w}_{t+1}}-L_{\\mathbf{w}^{*}}\\Big]\\qquad\\qquad(27)$$ $$\\frac{R}{T}\\leq\\frac{1}{T}\\sum_{t=0}^{T-1}\\frac{||\\mathbf{w_{t}-w^{*}}||^{2}-||\\mathbf{w_{t+1}-w^{*}}||^{2}}{2\\alpha}+\\alpha\\sigma_{t}^{2}$$ $$\\mathbb{E}[L_{\\frac{1}{T}\\sum_{t=1}^{T-1}\\mathbf{w_{t+1}}}-L_{\\mathbf{w^{*}}}]\\leq\\frac{R}{T}\\leq\\frac{||\\mathbf{w_{0}-w^{*}}||^{2}}{2\\alpha T}+\\alpha\\sigma_{m}^{2}\\tag{28}$$ where $\\sigma_{m}^{2}=\\arg\\max_{\\mathbf{w_{t}}}\\mathbb{E}||\\tilde{\\nabla}L_{\\mathbf{w_{t}}}-\\nabla L_{\\mathbf{w_{t}}}||^{2}$, and $R$ is the regret."@en ;
    askg-onto:inSentence "$(\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{w}_{i})^{2}\\leq\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}$ $$\\left(\\frac{1}{n+1}\\sum_{i=1}^{n+1}\\mathbf{w}_{i}\\right)^{2}\\leq\\frac{1}{n}\\sum_{i=1}^{n+1}\\mathbf{w}_{i}^{2}+\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}\\tag{22}$$ $$\\left(\\sum_{i=1}^{n}\\mathbf{w}_{i}\\right)^{2}+2\\mathbf{w}_{n+1}\\sum_{i=1}^{n}\\mathbf{w}_{i}+\\mathbf{w}_{n+1}^{2}$$ $$\\leq n\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}+\\sum_{i=1}^{n}\\mathbf{w}_{i}^{2}+(n+1)\\mathbf{w}_{n+1}^{2}$$ $$0\\leq\\sum_{i=1}^{n}(\\mathbf{w}_{i}-\\mathbf{w}_{n+1})^{2}$$ wi + w2n+1 (23) 2(24) : 21 $$\\mathbf{w}_{k+1}\\leftarrow\\mathbf{w}_{k}-\\alpha\\bar{\\mathbf{B}}^{-1}\\nabla L_{k}(\\mathbf{w})\\tag{29}$$ $$\\left({\\frac{1}{T}}\\sum_{i=1}^{T}\\mathbf{w}_{i}\\right)^{2}\\leq{\\frac{1}{T}}\\sum_{i=1}^{T}\\mathbf{w}_{i}^{2}$$ i(25) $$\\delta L=L_{\\mathbf{w}_{t+1}}-L_{\\mathbf{w}^{*}}\\leq\\nabla L_{\\mathbf{w}_{t}}(\\mathbf{w}_{t+1}-\\mathbf{w}^{*})+\\frac{\\beta}{2}||\\mathbf{w}_{t+1}-\\mathbf{w}_{t}||^{2},$$ $$\\mathbb{E}(\\delta L)\\leq\\hat{\\nabla}L_{\\mathbf{w}_{t}}(\\mathbf{w}_{t}-\\mathbf{w}^{*})-(\\alpha-\\frac{\\beta\\alpha^{2}}{2})||\\hat{\\nabla}L_{\\mathbf{w}_{t}}||^{2}+\\alpha\\sigma_{t}^{2}\\tag{26}$$ where $\\hat{\\nabla}L_{\\mathbf{w}_{t}}$ is the noisy gradient at $\\mathbf{w}_{t}$ and $\\sigma_{t}^{2}$ is its vari tis its vari- $${\\frac{R}{T}}=\\mathbb{E}\\Big[{\\frac{1}{T}}\\sum_{t=1}^{T-1}L_{\\mathbf{w}_{t+1}}-L_{\\mathbf{w}^{*}}\\Big]\\qquad\\qquad(27)$$ $$\\frac{R}{T}\\leq\\frac{1}{T}\\sum_{t=0}^{T-1}\\frac{||\\mathbf{w_{t}-w^{*}}||^{2}-||\\mathbf{w_{t+1}-w^{*}}||^{2}}{2\\alpha}+\\alpha\\sigma_{t}^{2}$$ $$\\mathbb{E}[L_{\\frac{1}{T}\\sum_{t=1}^{T-1}\\mathbf{w_{t+1}}}-L_{\\mathbf{w^{*}}}]\\leq\\frac{R}{T}\\leq\\frac{||\\mathbf{w_{0}-w^{*}}||^{2}}{2\\alpha T}+\\alpha\\sigma_{m}^{2}\\tag{28}$$ where $\\sigma_{m}^{2}=\\arg\\max_{\\mathbf{w_{t}}}\\mathbb{E}||\\tilde{\\nabla}L_{\\mathbf{w_{t}}}-\\nabla L_{\\mathbf{w_{t}}}||^{2}$, and $R$ is the regret."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extbfw,
        askg-data:Entity-%09extbfw_k-%0Aabla_l_k%09extbfw,
        askg-data:Entity-%09extbfw_k1,
        askg-data:Entity-%09extbfw_t,
        askg-data:Entity-%0Aabla_l_%09extbfw_t,
        askg-data:Entity-%0Aabla_l_%09extbfw_t%09extbfw_t-%09extbfw,
        askg-data:Entity-%0Aabla_l_k%09extbfw,
        askg-data:Entity-l_%09extbfw_t,
        askg-data:Entity-l_k,
        askg-data:Entity-noisy_gradient_at_%0A%09extbfw_t,
        askg-data:Entity-optimal_weight,
        askg-data:Entity-r,
        askg-data:Entity-regret .

askg-data:Paper-43d37e59d752bc41-Section-38-Paragraph-387-Sentence-3873 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Setting $\\alpha=(\\beta+\\sigma\\frac{\\sqrt{T}}{D})^{-1}$ in equation 27 gives us D"@en ;
    askg-onto:inSentence "Setting $\\alpha=(\\beta+\\sigma\\frac{\\sqrt{T}}{D})^{-1}$ in equation 27 gives us D"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Aalphabetasigmafracsqrttd-1,
        askg-data:Entity-concept,
        askg-data:Entity-d,
        askg-data:Entity-equation,
        askg-data:Entity-setting,
        askg-data:Entity-variable .

askg-data:Paper-43d37e59d752bc41-Section-39 a askg-onto:Section ;
    rdfs:label "Section 39"@en ;
    domo:Text "F. Importance Of Iterate Averaging For Convergence"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-391,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-392,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-393,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-394,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-395,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397 ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-391 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "$$(23)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-391-Sentence-3911 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-391-Sentence-3911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(23)$$"@en ;
    askg-onto:inSentence "$$(23)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-23,
        askg-data:Entity-study .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-392 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "can be given for a decreasing step size Î±t âˆ t âˆ’1/2Î±0. For adaptive optimisers, the noisy gradient is preconditioned by some non-identity matrix BÂ¯ âˆ’1:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-392-Sentence-3921,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-392-Sentence-3922 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-392-Sentence-3921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "can be given for a decreasing step size Î±t âˆ t âˆ’1/2Î±0."@en ;
    askg-onto:inSentence "can be given for a decreasing step size Î±t âˆ t âˆ’1/2Î±0."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1t,
        askg-data:Entity-t_12%CE%B10 .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-392-Sentence-3922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For adaptive optimisers, the noisy gradient is preconditioned by some non-identity matrix BÂ¯ âˆ’1:"@en ;
    askg-onto:inSentence "For adaptive optimisers, the noisy gradient is preconditioned by some non-identity matrix BÂ¯ âˆ’1:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-noisy_gradient .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-393 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$(24)$$ $$(25)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-393-Sentence-3931 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-393-Sentence-3931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(24)$$ $$(25)$$"@en ;
    askg-onto:inSentence "$$(24)$$ $$(25)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-24,
        askg-data:Entity-25 .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-394 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Methods of proof (Reddi et al., 2019; Tran et al., 2019) rely on bounding the regret O( âˆšT) and showing that the average regret R T â†’ 0 and Equation 27 explicitly demonstrates that the average regret is an upper bound on the expected loss for the average point in the trajectory. Hence existing convergence results in the literature prove convergence for the iterate average, but not the final iterate."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-394-Sentence-3941,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-394-Sentence-3942 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-394-Sentence-3941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Methods of proof (Reddi et al., 2019; Tran et al., 2019) rely on bounding the regret O( âˆšT) and showing that the average regret R T â†’ 0 and Equation 27 explicitly demonstrates that the average regret is an upper bound on the expected loss for the average point in the trajectory."@en ;
    askg-onto:inSentence "Methods of proof (Reddi et al., 2019; Tran et al., 2019) rely on bounding the regret O( âˆšT) and showing that the average regret R T â†’ 0 and Equation 27 explicitly demonstrates that the average regret is an upper bound on the expected loss for the average point in the trajectory."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_upper_bound_on_the_expected_loss,
        askg-data:Entity-average_regret,
        askg-data:Entity-bounding_the_regret_o_t,
        askg-data:Entity-equation_27,
        askg-data:Entity-methods_of_proof .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-394-Sentence-3942 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Hence existing convergence results in the literature prove convergence for the iterate average, but not the final iterate."@en ;
    askg-onto:inSentence "Hence existing convergence results in the literature prove convergence for the iterate average, but not the final iterate."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence_for_the_iterate_average,
        askg-data:Entity-convergence_results,
        askg-data:Entity-the_final_iterate .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-395 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "and by mathematical induction, for any T = n â‰¥ 2 and that n âˆˆ N +, we have: Assuming that {wi} are drawn from a uniform distribution, Theorem 3 follows."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-395-Sentence-3951 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-395-Sentence-3951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and by mathematical induction, for any T = n â‰¥ 2 and that n âˆˆ N +, we have: Assuming that {wi} are drawn from a uniform distribution, Theorem 3 follows."@en ;
    askg-onto:inSentence "and by mathematical induction, for any T = n â‰¥ 2 and that n âˆˆ N +, we have: Assuming that {wi} are drawn from a uniform distribution, Theorem 3 follows."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-theorem_3,
        askg-data:Entity-wi_are_drawn_from_a_uniform_distribution .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "We argue that despite of the universal practical use of the final iterate of optimisation, it is heuristically motivated and in most proofs of convergence, some form of iterative averaging is required and used implicitly to derive the theoretical bounds. For Î²-Lipschitz, convex empirical risks, denoted the (overall) loss L. The difference between the t + 1'th iterate and the optimal solution L âˆ—w can be bounded."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396-Sentence-3961,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396-Sentence-3962,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396-Sentence-3963 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396-Sentence-3961 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We argue that despite of the universal practical use of the final iterate of optimisation, it is heuristically motivated and in most proofs of convergence, some form of iterative averaging is required and used implicitly to derive the theoretical bounds."@en ;
    askg-onto:inSentence "We argue that despite of the universal practical use of the final iterate of optimisation, it is heuristically motivated and in most proofs of convergence, some form of iterative averaging is required and used implicitly to derive the theoretical bounds."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-final_iterate_of_optimisation,
        askg-data:Entity-iterative_averaging,
        askg-data:Entity-method,
        askg-data:Entity-theoretical_bounds .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396-Sentence-3962 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For Î²-Lipschitz, convex empirical risks, denoted the (overall) loss L."@en ;
    askg-onto:inSentence "For Î²-Lipschitz, convex empirical risks, denoted the (overall) loss L."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B2-lipschitz,
        askg-data:Entity-the_overall_loss_l .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-396-Sentence-3963 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The difference between the t + 1'th iterate and the optimal solution L âˆ—w can be bounded."@en ;
    askg-onto:inSentence "The difference between the t + 1'th iterate and the optimal solution L âˆ—w can be bounded."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimal_solution_l_w,
        askg-data:Entity-t__1th_iterate .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "The sum of differences along the trajectory (known as the regret) telescopes, hence resulting in a convergence rate for the average regret which is an upper bound for the loss of the average point (Nesterov, 2013; Duchi, 2018): ance: Var(âˆ‡Ë†Lwt ). Noting that wt+1 = wt âˆ’ Î±âˆ‡Ë†Lwt Using Jensen's inequality, we have: the optimal convergence rate. Similar convergence results"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397-Sentence-3971,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397-Sentence-3972,
        askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397-Sentence-3973 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397-Sentence-3971 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The sum of differences along the trajectory (known as the regret) telescopes, hence resulting in a convergence rate for the average regret which is an upper bound for the loss of the average point (Nesterov, 2013; Duchi, 2018): ance: Var(âˆ‡Ë†Lwt )."@en ;
    askg-onto:inSentence "The sum of differences along the trajectory (known as the regret) telescopes, hence resulting in a convergence rate for the average regret which is an upper bound for the loss of the average point (Nesterov, 2013; Duchi, 2018): ance: Var(âˆ‡Ë†Lwt )."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2013,
        askg-data:Entity-2018,
        askg-data:Entity-average_regret,
        askg-data:Entity-convergence_rate,
        askg-data:Entity-duchi,
        askg-data:Entity-loss_of_the_average_point,
        askg-data:Entity-nesterov,
        askg-data:Entity-regret .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397-Sentence-3972 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Noting that wt+1 = wt âˆ’ Î±âˆ‡Ë†Lwt Using Jensen's inequality, we have: the optimal convergence rate."@en ;
    askg-onto:inSentence "Noting that wt+1 = wt âˆ’ Î±âˆ‡Ë†Lwt Using Jensen's inequality, we have: the optimal convergence rate."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jensens_inequality,
        askg-data:Entity-optimal_convergence_rate .

askg-data:Paper-43d37e59d752bc41-Section-39-Paragraph-397-Sentence-3973 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Similar convergence results"@en ;
    askg-onto:inSentence "Similar convergence results"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence_results,
        askg-data:Entity-similar .

askg-data:Paper-43d37e59d752bc41-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "2. Implicit Learning Rate Decay And Noise Reduction In Iterate Averaging"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-43,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-44,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-45,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To achieve the best performance, deep learning practitioners employ learning rate *scheduling*. While it is often argued that adaptive optimisers do not *need* scheduling to converge, scheduling improves their empirical performance (Loshchilov & Hutter, 2018; Wilson et al., 2017) and is required in proofs of convergence (Reddi et al., 2019). For constant high learning rates, the gap between training and test curves is small, but the final test performance is poor. Whilst decaying the learning rate increases test performance, the generalisation gap also increases as shown in Figure 1, suggesting more over-fitting. This prompts us to consider whether we can preserve the regularisation benefits of large learning rates, whilst improving the final test performance."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-413,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-414,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-415 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To achieve the best performance, deep learning practitioners employ learning rate *scheduling*."@en ;
    askg-onto:inSentence "To achieve the best performance, deep learning practitioners employ learning rate *scheduling*."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_practitioners,
        askg-data:Entity-learning_rate_scheduling .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While it is often argued that adaptive optimisers do not *need* scheduling to converge, scheduling improves their empirical performance (Loshchilov & Hutter, 2018; Wilson et al., 2017) and is required in proofs of convergence (Reddi et al., 2019)."@en ;
    askg-onto:inSentence "While it is often argued that adaptive optimisers do not *need* scheduling to converge, scheduling improves their empirical performance (Loshchilov & Hutter, 2018; Wilson et al., 2017) and is required in proofs of convergence (Reddi et al., 2019)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adaptive_optimisers,
        askg-data:Entity-empirical_performance,
        askg-data:Entity-loshchilov__hutter_2018,
        askg-data:Entity-proofs_of_convergence,
        askg-data:Entity-reddi_et_al_2019,
        askg-data:Entity-scheduling,
        askg-data:Entity-study,
        askg-data:Entity-wilson_et_al_2017 .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For constant high learning rates, the gap between training and test curves is small, but the final test performance is poor."@en ;
    askg-onto:inSentence "For constant high learning rates, the gap between training and test curves is small, but the final test performance is poor."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning_rates,
        askg-data:Entity-test_performance .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Whilst decaying the learning rate increases test performance, the generalisation gap also increases as shown in Figure 1, suggesting more over-fitting."@en ;
    askg-onto:inSentence "Whilst decaying the learning rate increases test performance, the generalisation gap also increases as shown in Figure 1, suggesting more over-fitting."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalisation_gap,
        askg-data:Entity-learning_rate,
        askg-data:Entity-over-fitting,
        askg-data:Entity-test_performance .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-41-Sentence-415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This prompts us to consider whether we can preserve the regularisation benefits of large learning rates, whilst improving the final test performance."@en ;
    askg-onto:inSentence "This prompts us to consider whether we can preserve the regularisation benefits of large learning rates, whilst improving the final test performance."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_test_performance,
        askg-data:Entity-large_learning_rates,
        askg-data:Entity-regularisation_benefits .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Figure 1. An example illustrating the *generalisation gap*. We run"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42-Sentence-421,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42-Sentence-422,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42-Sentence-423 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 1."@en ;
    askg-onto:inSentence "Figure 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_1,
        askg-data:Entity-research_concepts .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42-Sentence-422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "An example illustrating the *generalisation gap*."@en ;
    askg-onto:inSentence "An example illustrating the *generalisation gap*."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-example,
        askg-data:Entity-generalisation_gap .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-42-Sentence-423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We run"@en ;
    askg-onto:inSentence "We run"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-we .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-43 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![1_image_0.png](1_image_0.png) VGG-16 on CIFAR-100, with *flat* learning rate of 0.1, and with step decay with a factor of 10 at {100, 150}-th epochs. It can be seen that at high constant learning rate there is no generalisation gap, but as we decay more and more the test performance improves but the gap also increases (âˆ†E2 > âˆ†E1)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-43-Sentence-431,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-43-Sentence-432 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-43-Sentence-431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![1_image_0.png](1_image_0.png) VGG-16 on CIFAR-100, with *flat* learning rate of 0.1, and with step decay with a factor of 10 at {100, 150}-th epochs."@en ;
    askg-onto:inSentence "![1_image_0.png](1_image_0.png) VGG-16 on CIFAR-100, with *flat* learning rate of 0.1, and with step decay with a factor of 10 at {100, 150}-th epochs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-01,
        askg-data:Entity-10,
        askg-data:Entity-100_150,
        askg-data:Entity-cifar-100,
        askg-data:Entity-epochs,
        askg-data:Entity-learning_rate,
        askg-data:Entity-step_decay,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-43-Sentence-432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It can be seen that at high constant learning rate there is no generalisation gap, but as we decay more and more the test performance improves but the gap also increases (âˆ†E2 > âˆ†E1)."@en ;
    askg-onto:inSentence "It can be seen that at high constant learning rate there is no generalisation gap, but as we decay more and more the test performance improves but the gap also increases (âˆ†E2 > âˆ†E1)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decay,
        askg-data:Entity-gap,
        askg-data:Entity-generalisation_gap,
        askg-data:Entity-high_constant_learning_rate,
        askg-data:Entity-test_performance .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-44 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "As we discussed in introduction, most recent works running IA with high constant learning rate, have mainly considered IA as a *generalisation* technique, and have not explored its connection to the more commonly employed learning rate scheduling which we argue to exist. Denoting w0 as the point at which averaging starts and githe gradient at point i and assuming that learning rate Î± is kept constant for the duration of averaging (which is always the case in this paper), the average of the iterates is given by"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-44-Sentence-441,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-44-Sentence-442 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-44-Sentence-441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As we discussed in introduction, most recent works running IA with high constant learning rate, have mainly considered IA as a *generalisation* technique, and have not explored its connection to the more commonly employed learning rate scheduling which we argue to exist."@en ;
    askg-onto:inSentence "As we discussed in introduction, most recent works running IA with high constant learning rate, have mainly considered IA as a *generalisation* technique, and have not explored its connection to the more commonly employed learning rate scheduling which we argue to exist."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalisation_technique,
        askg-data:Entity-ia,
        askg-data:Entity-learning_rate_scheduling .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-44-Sentence-442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Denoting w0 as the point at which averaging starts and githe gradient at point i and assuming that learning rate Î± is kept constant for the duration of averaging (which is always the case in this paper), the average of the iterates is given by"@en ;
    askg-onto:inSentence "Denoting w0 as the point at which averaging starts and githe gradient at point i and assuming that learning rate Î± is kept constant for the duration of averaging (which is always the case in this paper), the average of the iterates is given by"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-iterates,
        askg-data:Entity-learning_rate,
        askg-data:Entity-point_at_which_averaging_starts,
        askg-data:Entity-w0 .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-45 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\mathbf{w}_{0}+{\\frac{n-1}{n}}\\alpha\\mathbf{g}_{0}+...+{\\frac{n-k}{n}}\\alpha\\mathbf{g}_{k-1}\\,,1\\leq k\\leq n-1\\tag{1}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-45-Sentence-451 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-45-Sentence-451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{w}_{0}+{\\frac{n-1}{n}}\\alpha\\mathbf{g}_{0}+...+{\\frac{n-k}{n}}\\alpha\\mathbf{g}_{k-1}\\,,1\\leq k\\leq n-1\\tag{1}$$"@en ;
    askg-onto:inSentence "$$\\mathbf{w}_{0}+{\\frac{n-1}{n}}\\alpha\\mathbf{g}_{0}+...+{\\frac{n-k}{n}}\\alpha\\mathbf{g}_{k-1}\\,,1\\leq k\\leq n-1\\tag{1}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Cracn-1n,
        askg-data:Entity-%0Cracn-kn,
        askg-data:Entity-k,
        askg-data:Entity-mathematical_expression,
        askg-data:Entity-mathematical_operation,
        askg-data:Entity-n,
        askg-data:Entity-oldsymbolg_0,
        askg-data:Entity-oldsymbolg_k-1,
        askg-data:Entity-w_0 .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "and hence we linearly reduce the effective learning rate. It is worth noting that when we begin averaging, we update both n and k on the fly. This means that for the first iterate of averaging, we have essentially halved the learning rate"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46-Sentence-461,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46-Sentence-462,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46-Sentence-463 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46-Sentence-461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and hence we linearly reduce the effective learning rate."@en ;
    askg-onto:inSentence "and hence we linearly reduce the effective learning rate."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning_rate,
        askg-data:Entity-linear_reduction .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46-Sentence-462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It is worth noting that when we begin averaging, we update both n and k on the fly."@en ;
    askg-onto:inSentence "It is worth noting that when we begin averaging, we update both n and k on the fly."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-k,
        askg-data:Entity-n .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-46-Sentence-463 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This means that for the first iterate of averaging, we have essentially halved the learning rate"@en ;
    askg-onto:inSentence "This means that for the first iterate of averaging, we have essentially halved the learning rate"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$ \\color{blue}{w_{avg,1}=\\frac{w_0+w_0-\\alpha g_0}{2}=w_0-\\frac{1}{2}\\alpha g_0}$ (2) we expect the training curves to mean already room. Hence, we expect the training curves to more closely resemble that of step decay, which is what we observe in practice. However, the benefits of IA extend beyond implicit learning rate decay and we analyse this in the following section."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47-Sentence-471,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47-Sentence-472,
        askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47-Sentence-473 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47-Sentence-471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$ \\color{blue}{w_{avg,1}=\\frac{w_0+w_0-\\alpha g_0}{2}=w_0-\\frac{1}{2}\\alpha g_0}$ (2) we expect the training curves to mean already room."@en ;
    askg-onto:inSentence "$ \\color{blue}{w_{avg,1}=\\frac{w_0+w_0-\\alpha g_0}{2}=w_0-\\frac{1}{2}\\alpha g_0}$ (2) we expect the training curves to mean already room."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g_0,
        askg-data:Entity-room,
        askg-data:Entity-training_curves,
        askg-data:Entity-w_0,
        askg-data:Entity-w_avg1 .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47-Sentence-472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Hence, we expect the training curves to more closely resemble that of step decay, which is what we observe in practice."@en ;
    askg-onto:inSentence "Hence, we expect the training curves to more closely resemble that of step decay, which is what we observe in practice."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-step_decay,
        askg-data:Entity-training_curves .

askg-data:Paper-43d37e59d752bc41-Section-4-Paragraph-47-Sentence-473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, the benefits of IA extend beyond implicit learning rate decay and we analyse this in the following section."@en ;
    askg-onto:inSentence "However, the benefits of IA extend beyond implicit learning rate decay and we analyse this in the following section."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-implicit_learning_rate_decay .

askg-data:Paper-43d37e59d752bc41-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "2.1. Quadratic Optimisation With Gradient Noise"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-510,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-511,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-514,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-516,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-517,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-52,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-53,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-54,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-55,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-56,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-57,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-58,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-59 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Common schedules often involve decaying the learning rate and return the final iterate as the solution. In order to compare these against the IA, we consider the 1D quadratic function f(w) = Î»2 ||w||2as a proxy of our true loss function, minimised using gradient descent with learning rate Î±. At each iteration the gradient is perturbed by some i.i.d."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51-Sentence-511,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51-Sentence-512,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51-Sentence-513 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Common schedules often involve decaying the learning rate and return the final iterate as the solution."@en ;
    askg-onto:inSentence "Common schedules often involve decaying the learning rate and return the final iterate as the solution."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_iterate,
        askg-data:Entity-learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51-Sentence-512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In order to compare these against the IA, we consider the 1D quadratic function f(w) = Î»2 ||w||2as a proxy of our true loss function, minimised using gradient descent with learning rate Î±."@en ;
    askg-onto:inSentence "In order to compare these against the IA, we consider the 1D quadratic function f(w) = Î»2 ||w||2as a proxy of our true loss function, minimised using gradient descent with learning rate Î±."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1d_quadratic_function,
        askg-data:Entity-gradient_descent,
        askg-data:Entity-learning_rate_%CE%B1,
        askg-data:Entity-minimising_true_loss_function,
        askg-data:Entity-true_loss_function .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-51-Sentence-513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "At each iteration the gradient is perturbed by some i.i.d."@en ;
    askg-onto:inSentence "At each iteration the gradient is perturbed by some i.i.d."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gradient,
        askg-data:Entity-iid .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-510 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Whilst we attain exponential convergence in the mean for the end point, we do not control the noise in the gradient, whereas for the averaged iterates, although the convergence in the mean is worse (linear), the variance vanishes asymptotically. In higher dimensions, where P is large, the iterates evolve independently along the eigenbasis of H = âˆ‡âˆ‡L and assuming isotropic noise:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-510-Sentence-5101,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-510-Sentence-5102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-510-Sentence-5101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Whilst we attain exponential convergence in the mean for the end point, we do not control the noise in the gradient, whereas for the averaged iterates, although the convergence in the mean is worse (linear), the variance vanishes asymptotically."@en ;
    askg-onto:inSentence "Whilst we attain exponential convergence in the mean for the end point, we do not control the noise in the gradient, whereas for the averaged iterates, although the convergence in the mean is worse (linear), the variance vanishes asymptotically."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asymptotically,
        askg-data:Entity-averaged_iterates,
        askg-data:Entity-convergence_in_the_mean,
        askg-data:Entity-noise_in_the_gradient,
        askg-data:Entity-variance .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-510-Sentence-5102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In higher dimensions, where P is large, the iterates evolve independently along the eigenbasis of H = âˆ‡âˆ‡L and assuming isotropic noise:"@en ;
    askg-onto:inSentence "In higher dimensions, where P is large, the iterates evolve independently along the eigenbasis of H = âˆ‡âˆ‡L and assuming isotropic noise:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h,
        askg-data:Entity-higher_dimensions,
        askg-data:Entity-independently_evolving_iterates,
        askg-data:Entity-isotropic_noise,
        askg-data:Entity-l,
        askg-data:Entity-p .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-511 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "$$\\begin{array}{l}{{w_{n}\\sim\\mathcal{N}\\left(\\sum_{j=1}^{P}w_{0,j}\\mathrm{e}^{-n\\alpha\\lambda_{j}},\\sum_{j=1}^{P}\\frac{\\alpha\\sigma^{2}}{B\\lambda_{j}}\\right)}}\\\\ {{w_{\\mathrm{avg}}\\sim\\mathcal{N}\\left(\\sum_{j=1}^{P}\\frac{w_{0,j}}{n\\alpha\\lambda_{j}},\\sum_{j=1}^{P}\\frac{\\alpha\\sigma^{2}}{B\\lambda_{j}n}\\right)}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-511-Sentence-5111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-511-Sentence-5111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{{w_{n}\\sim\\mathcal{N}\\left(\\sum_{j=1}^{P}w_{0,j}\\mathrm{e}^{-n\\alpha\\lambda_{j}},\\sum_{j=1}^{P}\\frac{\\alpha\\sigma^{2}}{B\\lambda_{j}}\\right)}}\\\\ {{w_{\\mathrm{avg}}\\sim\\mathcal{N}\\left(\\sum_{j=1}^{P}\\frac{w_{0,j}}{n\\alpha\\lambda_{j}},\\sum_{j=1}^{P}\\frac{\\alpha\\sigma^{2}}{B\\lambda_{j}n}\\right)}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{{w_{n}\\sim\\mathcal{N}\\left(\\sum_{j=1}^{P}w_{0,j}\\mathrm{e}^{-n\\alpha\\lambda_{j}},\\sum_{j=1}^{P}\\frac{\\alpha\\sigma^{2}}{B\\lambda_{j}}\\right)}}\\\\ {{w_{\\mathrm{avg}}\\sim\\mathcal{N}\\left(\\sum_{j=1}^{P}\\frac{w_{0,j}}{n\\alpha\\lambda_{j}},\\sum_{j=1}^{P}\\frac{\\alpha\\sigma^{2}}{B\\lambda_{j}n}\\right)}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-normal_distribution .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "where B is the minibatch size. In the asymptotic limit n â†’ âˆž, wavg converges to the minimum, whereas the wn does not. In high dimensions, the low dimensional intuition that majority of the probability mass is concentrated around the mean fails, as the relevant quantity is not the probability density at a point, but the integral under the density in the immediate vicinity of that point, which scales as p(r)r P âˆ’1dr for P dimensions. Formally, Theorem 1. Under the assumptions in the preceding section (Proof in Appendix E),"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5121,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5122,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5123,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5124,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5125 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where B is the minibatch size."@en ;
    askg-onto:inSentence "where B is the minibatch size."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-minibatch_size .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the asymptotic limit n â†’ âˆž, wavg converges to the minimum, whereas the wn does not."@en ;
    askg-onto:inSentence "In the asymptotic limit n â†’ âˆž, wavg converges to the minimum, whereas the wn does not."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-minimum,
        askg-data:Entity-wavg,
        askg-data:Entity-wn .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In high dimensions, the low dimensional intuition that majority of the probability mass is concentrated around the mean fails, as the relevant quantity is not the probability density at a point, but the integral under the density in the immediate vicinity of that point, which scales as p(r)r P âˆ’1dr for P dimensions."@en ;
    askg-onto:inSentence "In high dimensions, the low dimensional intuition that majority of the probability mass is concentrated around the mean fails, as the relevant quantity is not the probability density at a point, but the integral under the density in the immediate vicinity of that point, which scales as p(r)r P âˆ’1dr for P dimensions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-density,
        askg-data:Entity-integral_under_the_density,
        askg-data:Entity-mean,
        askg-data:Entity-probability_density,
        askg-data:Entity-probability_mass,
        askg-data:Entity-prr_p_1dr .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Formally, Theorem 1."@en ;
    askg-onto:inSentence "Formally, Theorem 1."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-theorem_1 .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-512-Sentence-5125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Under the assumptions in the preceding section (Proof in Appendix E),"@en ;
    askg-onto:inSentence "Under the assumptions in the preceding section (Proof in Appendix E),"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appendix_e,
        askg-data:Entity-assumptions,
        askg-data:Entity-preceding_section,
        askg-data:Entity-triple .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "||wn|| âˆ’ vuutX P i w20,ieâˆ’2nÎ±Î»i + P Î±Ïƒ2 B h 1 Î» i â‰¥ t â‰¤ Î½ P P ||wavg|| âˆ’ vuutX P i w2 0,i Î» 2 i n2Î±2 + P Î±Ïƒ2 Bnh 1 Î» i â‰¥ t â‰¤ Î½ (3) 1 $\\textit{where}\\ \\nu=2\\exp(-ct^2)\\textit{and}\\ \\langle\\lambda^k\\rangle=\\frac{1}{P}\\mathrm{Tr}\\mathbf{H}^k.$ IMPLICATIONS OF THEOREM 1 In the high-dimensional regime typical of deep learning, the effect of noise may very well dominate the convergence in the mean, provided one starts averaging in a region reasonably close to the minimum - this highlights why one should only start averaging when a specific metric (e.g. validation accuracy) stagnates. While the iterates will be located in a thin-shell with a high probability, the robustness to the gradient noise will drive the IA closer to the minimum. Unless the per parameter estimation noise scales âˆ 1 P which is an odd assumption to make, we expect this effect to be more and more significant when the number of parameters P gets larger. With P being a rough gauge of the model complexity, this implies that in more complex, over-parameterised models, we expect the benefit of IA to be larger. Theorem 1 also unifies the various scheduling approaches and highlights why IA is a desirable alternative. Observing the Ïƒ 2 dependence in Theorem 1, reducing the learning rate Î± is an obvious way to reduce the noise effect. However, there is a limit to how much one may reduce Î±: for very small Î±, wn converges at a rate (1 âˆ’ nÎ±Î») whereas wavg converges at (1 âˆ’ nÎ±Î» 2). An alternative is increasing the batch size B. However, the maximal batch size possible is using the full data-set, which for deep learning is significantly smaller than the total number of parameters N P. Furthermore, the number of passes through the data is typically kept fixed, so n = NE B , where E is the number of epochs. For the same computational budget, the convergence in the mean will also be reduced. Hence for a large number of functional evaluations, it can be seen that IA will outperform both reducing the learning rate and increasing the batch size. Indeed, we argue that in terms of asymptotic expected loss, IA will *always* better the final iterates with realistic schedules. Building on previous analysis of quadratics (Martens, 2014), we have Theorem 2. Denote (the positive semidefinite surrogate of) Hessian as H and covariance matrix of gradients as Î£g, if we further assume H and Î£g *are co-diagonalisable (Zhang* et al., 2019a), then for the expected loss of the final iterate to be smaller than that of the average iterate, the learning rate must decay in a rate âˆ 1 n . (Proof in Appendix E)."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5131,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51310,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51311,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51312,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51313,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51314,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51315,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51316,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51317,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5132,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5133,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5134,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5135,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5136,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5137,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5138,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5139 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "||wn|| âˆ’ vuutX P i w20,ieâˆ’2nÎ±Î»i + P Î±Ïƒ2 B h 1 Î» i â‰¥ t â‰¤ Î½ P P ||wavg|| âˆ’ vuutX P i w2 0,i Î» 2 i n2Î±2 + P Î±Ïƒ2 Bnh 1 Î» i â‰¥ t â‰¤ Î½ (3) 1 $\\textit{where}\\ \\nu=2\\exp(-ct^2)\\textit{and}\\ \\langle\\lambda^k\\rangle=\\frac{1}{P}\\mathrm{Tr}\\mathbf{H}^k.$ IMPLICATIONS OF THEOREM 1 In the high-dimensional regime typical of deep learning, the effect of noise may very well dominate the convergence in the mean, provided one starts averaging in a region reasonably close to the minimum - this highlights why one should only start averaging when a specific metric (e.g."@en ;
    askg-onto:inSentence "||wn|| âˆ’ vuutX P i w20,ieâˆ’2nÎ±Î»i + P Î±Ïƒ2 B h 1 Î» i â‰¥ t â‰¤ Î½ P P ||wavg|| âˆ’ vuutX P i w2 0,i Î» 2 i n2Î±2 + P Î±Ïƒ2 Bnh 1 Î» i â‰¥ t â‰¤ Î½ (3) 1 $\\textit{where}\\ \\nu=2\\exp(-ct^2)\\textit{and}\\ \\langle\\lambda^k\\rangle=\\frac{1}{P}\\mathrm{Tr}\\mathbf{H}^k.$ IMPLICATIONS OF THEOREM 1 In the high-dimensional regime typical of deep learning, the effect of noise may very well dominate the convergence in the mean, provided one starts averaging in a region reasonably close to the minimum - this highlights why one should only start averaging when a specific metric (e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-deep_learning,
        askg-data:Entity-noise_effect,
        askg-data:Entity-specific_metric .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "However, the maximal batch size possible is using the full data-set, which for deep learning is significantly smaller than the total number of parameters N P."@en ;
    askg-onto:inSentence "However, the maximal batch size possible is using the full data-set, which for deep learning is significantly smaller than the total number of parameters N P."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data-set,
        askg-data:Entity-deep_learning,
        askg-data:Entity-maximal_batch_size,
        askg-data:Entity-total_number_of_parameters_n_p .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Furthermore, the number of passes through the data is typically kept fixed, so n = NE B , where E is the number of epochs."@en ;
    askg-onto:inSentence "Furthermore, the number of passes through the data is typically kept fixed, so n = NE B , where E is the number of epochs."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e,
        askg-data:Entity-epochs,
        askg-data:Entity-n__ne_b,
        askg-data:Entity-number_of_passes .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "For the same computational budget, the convergence in the mean will also be reduced."@en ;
    askg-onto:inSentence "For the same computational budget, the convergence in the mean will also be reduced."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computational_budget,
        askg-data:Entity-convergence_in_the_mean .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Hence for a large number of functional evaluations, it can be seen that IA will outperform both reducing the learning rate and increasing the batch size."@en ;
    askg-onto:inSentence "Hence for a large number of functional evaluations, it can be seen that IA will outperform both reducing the learning rate and increasing the batch size."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-increasing_the_batch_size,
        askg-data:Entity-reducing_the_learning_rate .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51314 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Indeed, we argue that in terms of asymptotic expected loss, IA will *always* better the final iterates with realistic schedules."@en ;
    askg-onto:inSentence "Indeed, we argue that in terms of asymptotic expected loss, IA will *always* better the final iterates with realistic schedules."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_iterates_with_realistic_schedules,
        askg-data:Entity-ia .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51315 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Building on previous analysis of quadratics (Martens, 2014), we have Theorem 2."@en ;
    askg-onto:inSentence "Building on previous analysis of quadratics (Martens, 2014), we have Theorem 2."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-martens,
        askg-data:Entity-theorem_2 .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51316 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Denote (the positive semidefinite surrogate of) Hessian as H and covariance matrix of gradients as Î£g, if we further assume H and Î£g *are co-diagonalisable (Zhang* et al., 2019a), then for the expected loss of the final iterate to be smaller than that of the average iterate, the learning rate must decay in a rate âˆ 1 n ."@en ;
    askg-onto:inSentence "Denote (the positive semidefinite surrogate of) Hessian as H and covariance matrix of gradients as Î£g, if we further assume H and Î£g *are co-diagonalisable (Zhang* et al., 2019a), then for the expected loss of the final iterate to be smaller than that of the average iterate, the learning rate must decay in a rate âˆ 1 n ."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%83g,
        askg-data:Entity-_1_n,
        askg-data:Entity-average_iterate,
        askg-data:Entity-expected_loss_of_the_final_iterate,
        askg-data:Entity-gradients,
        askg-data:Entity-h,
        askg-data:Entity-h_and_%CF%83g,
        askg-data:Entity-hessian,
        askg-data:Entity-learning_rate,
        askg-data:Entity-zhang_et_al_2019a .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-51317 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "(Proof in Appendix E)."@en ;
    askg-onto:inSentence "(Proof in Appendix E)."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appendix_e,
        askg-data:Entity-proof .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "validation accuracy) stagnates."@en ;
    askg-onto:inSentence "validation accuracy) stagnates."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-validation_accuracy .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While the iterates will be located in a thin-shell with a high probability, the robustness to the gradient noise will drive the IA closer to the minimum."@en ;
    askg-onto:inSentence "While the iterates will be located in a thin-shell with a high probability, the robustness to the gradient noise will drive the IA closer to the minimum."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-iterates,
        askg-data:Entity-minimum,
        askg-data:Entity-robustness,
        askg-data:Entity-thin-shell .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Unless the per parameter estimation noise scales âˆ 1 P which is an odd assumption to make, we expect this effect to be more and more significant when the number of parameters P gets larger."@en ;
    askg-onto:inSentence "Unless the per parameter estimation noise scales âˆ 1 P which is an odd assumption to make, we expect this effect to be more and more significant when the number of parameters P gets larger."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_p,
        askg-data:Entity-number_of_parameters_p,
        askg-data:Entity-per_parameter_estimation_noise,
        askg-data:Entity-significant_effect .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "With P being a rough gauge of the model complexity, this implies that in more complex, over-parameterised models, we expect the benefit of IA to be larger."@en ;
    askg-onto:inSentence "With P being a rough gauge of the model complexity, this implies that in more complex, over-parameterised models, we expect the benefit of IA to be larger."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-benefit_of_ia,
        askg-data:Entity-model_complexity,
        askg-data:Entity-models,
        askg-data:Entity-more_complex_models,
        askg-data:Entity-over-parameterised,
        askg-data:Entity-p .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5136 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Theorem 1 also unifies the various scheduling approaches and highlights why IA is a desirable alternative."@en ;
    askg-onto:inSentence "Theorem 1 also unifies the various scheduling approaches and highlights why IA is a desirable alternative."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-theorem_1,
        askg-data:Entity-various_scheduling_approaches .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5137 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Observing the Ïƒ 2 dependence in Theorem 1, reducing the learning rate Î± is an obvious way to reduce the noise effect."@en ;
    askg-onto:inSentence "Observing the Ïƒ 2 dependence in Theorem 1, reducing the learning rate Î± is an obvious way to reduce the noise effect."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%83_2_dependence,
        askg-data:Entity-learning_rate_%CE%B1,
        askg-data:Entity-noise_effect,
        askg-data:Entity-theorem_1 .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5138 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "However, there is a limit to how much one may reduce Î±: for very small Î±, wn converges at a rate (1 âˆ’ nÎ±Î») whereas wavg converges at (1 âˆ’ nÎ±Î» 2)."@en ;
    askg-onto:inSentence "However, there is a limit to how much one may reduce Î±: for very small Î±, wn converges at a rate (1 âˆ’ nÎ±Î») whereas wavg converges at (1 âˆ’ nÎ±Î» 2)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1,
        askg-data:Entity-1__n%CE%B1%CE%BB,
        askg-data:Entity-1__n%CE%B1%CE%BB_2,
        askg-data:Entity-wavg,
        askg-data:Entity-wn .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-513-Sentence-5139 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "An alternative is increasing the batch size B."@en ;
    askg-onto:inSentence "An alternative is increasing the batch size B."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_size_b,
        askg-data:Entity-increasing .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-514 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "This implies a learning rate decay greater than the theoretically proposed schedule of Î± âˆ âˆš 1 n (discussed in Appendix F). This schedule is already almost never used in practice, as it decays the learning rate too fast and strongly harms the convergence in mean."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-514-Sentence-5141,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-514-Sentence-5142 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-514-Sentence-5141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This implies a learning rate decay greater than the theoretically proposed schedule of Î± âˆ âˆš 1 n (discussed in Appendix F)."@en ;
    askg-onto:inSentence "This implies a learning rate decay greater than the theoretically proposed schedule of Î± âˆ âˆš 1 n (discussed in Appendix F)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning_rate_decay,
        askg-data:Entity-the_theoretically_proposed_schedule .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-514-Sentence-5142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This schedule is already almost never used in practice, as it decays the learning rate too fast and strongly harms the convergence in mean."@en ;
    askg-onto:inSentence "This schedule is already almost never used in practice, as it decays the learning rate too fast and strongly harms the convergence in mean."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence,
        askg-data:Entity-learning_rate,
        askg-data:Entity-mean,
        askg-data:Entity-practice,
        askg-data:Entity-schedule,
        askg-data:Entity-too_fast .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Note on Assumptions We make the similar assumption as Roux et al. (2008) that the batch gradients are draws from the *true* gradient distribution and all gradients are i.i.d. By the Central Limit Theorem, the analysis of Section 2.1 holds."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515-Sentence-5151,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515-Sentence-5152,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515-Sentence-5153 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515-Sentence-5151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Note on Assumptions We make the similar assumption as Roux et al."@en ;
    askg-onto:inSentence "Note on Assumptions We make the similar assumption as Roux et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-roux_et_al,
        askg-data:Entity-similar_assumption .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515-Sentence-5152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2008) that the batch gradients are draws from the *true* gradient distribution and all gradients are i.i.d."@en ;
    askg-onto:inSentence "(2008) that the batch gradients are draws from the *true* gradient distribution and all gradients are i.i.d."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_gradients,
        askg-data:Entity-batch_gradients,
        askg-data:Entity-iid,
        askg-data:Entity-true_gradient_distribution .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-515-Sentence-5153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "By the Central Limit Theorem, the analysis of Section 2.1 holds."@en ;
    askg-onto:inSentence "By the Central Limit Theorem, the analysis of Section 2.1 holds."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis_of_section_21,
        askg-data:Entity-central_limit_theorem .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-516 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "Nonetheless, for a finite dataset, it can be argued that *bias*, in addition to *noise*, is present in the batch gradient estimate. We argue that even with bias present IA still leads to a better solution: if we assume each gradient perturbation to have an equal bias of Î´, it can be shown that the bias of the IA point at iteration n is strictly smaller than the n-th iterate:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-516-Sentence-5161,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-516-Sentence-5162 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-516-Sentence-5161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Nonetheless, for a finite dataset, it can be argued that *bias*, in addition to *noise*, is present in the batch gradient estimate."@en ;
    askg-onto:inSentence "Nonetheless, for a finite dataset, it can be argued that *bias*, in addition to *noise*, is present in the batch gradient estimate."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_gradient_estimate,
        askg-data:Entity-bias,
        askg-data:Entity-noise .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-516-Sentence-5162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We argue that even with bias present IA still leads to a better solution: if we assume each gradient perturbation to have an equal bias of Î´, it can be shown that the bias of the IA point at iteration n is strictly smaller than the n-th iterate:"@en ;
    askg-onto:inSentence "We argue that even with bias present IA still leads to a better solution: if we assume each gradient perturbation to have an equal bias of Î´, it can be shown that the bias of the IA point at iteration n is strictly smaller than the n-th iterate:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B4,
        askg-data:Entity-better_solution,
        askg-data:Entity-gradient_perturbation,
        askg-data:Entity-ia,
        askg-data:Entity-ia_point_at_iteration_n,
        askg-data:Entity-n-th_iterate .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-517 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "$$\\sum_{i=1}^{n}(1-\\frac{i}{n})(1-\\alpha\\lambda)^{n}\\alpha\\delta<\\sum_{i=1}^{n}(1-\\alpha\\lambda)^{n}\\alpha\\delta$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-517-Sentence-5171 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-517-Sentence-5171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\sum_{i=1}^{n}(1-\\frac{i}{n})(1-\\alpha\\lambda)^{n}\\alpha\\delta<\\sum_{i=1}^{n}(1-\\alpha\\lambda)^{n}\\alpha\\delta$$"@en ;
    askg-onto:inSentence "$$\\sum_{i=1}^{n}(1-\\frac{i}{n})(1-\\alpha\\lambda)^{n}\\alpha\\delta<\\sum_{i=1}^{n}(1-\\alpha\\lambda)^{n}\\alpha\\delta$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0A .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "although this improvement vanishes in the asymptotic limit. Furthermore, adding the bias term to Theorem 1 makes faster convergence in the mean of using the final iterate even less relevant, as we now observe both bias and noise and mean is bias-corrupted. Nonetheless, we analyse results from biased optimisation more concretely in Appendix D and show counter-intuitive results for deep learning. Specifically, we would expect accelerated methods, which suffer worse from bias to converge to points of lower generalisation, which is the opposite of what we see in practice - this seems to imply that at least any bias, being inherently unobservable (since the *true* distribution is unknown), is at least not as important as the noise."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5181,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5182,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5183,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5184 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "although this improvement vanishes in the asymptotic limit."@en ;
    askg-onto:inSentence "although this improvement vanishes in the asymptotic limit."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asymptotic_limit,
        askg-data:Entity-improvement .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Furthermore, adding the bias term to Theorem 1 makes faster convergence in the mean of using the final iterate even less relevant, as we now observe both bias and noise and mean is bias-corrupted."@en ;
    askg-onto:inSentence "Furthermore, adding the bias term to Theorem 1 makes faster convergence in the mean of using the final iterate even less relevant, as we now observe both bias and noise and mean is bias-corrupted."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bias-corrupted,
        askg-data:Entity-bias_and_noise,
        askg-data:Entity-bias_term,
        askg-data:Entity-faster_convergence,
        askg-data:Entity-mean,
        askg-data:Entity-theorem_1 .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Nonetheless, we analyse results from biased optimisation more concretely in Appendix D and show counter-intuitive results for deep learning."@en ;
    askg-onto:inSentence "Nonetheless, we analyse results from biased optimisation more concretely in Appendix D and show counter-intuitive results for deep learning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-biased_optimisation,
        askg-data:Entity-counter-intuitive_results,
        askg-data:Entity-deep_learning,
        askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-518-Sentence-5184 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Specifically, we would expect accelerated methods, which suffer worse from bias to converge to points of lower generalisation, which is the opposite of what we see in practice - this seems to imply that at least any bias, being inherently unobservable (since the *true* distribution is unknown), is at least not as important as the noise."@en ;
    askg-onto:inSentence "Specifically, we would expect accelerated methods, which suffer worse from bias to converge to points of lower generalisation, which is the opposite of what we see in practice - this seems to imply that at least any bias, being inherently unobservable (since the *true* distribution is unknown), is at least not as important as the noise."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-accelerated_methods,
        askg-data:Entity-at_least_not_as_important_as_bias,
        askg-data:Entity-bias,
        askg-data:Entity-noise,
        askg-data:Entity-not_as_important_as_the_noise,
        askg-data:Entity-true_distribution,
        askg-data:Entity-unknown .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "Experimental Validation The key result from our analysis is that IA leads to better robustness to gradient noise, and this effect scales with the ratio of parameters to batch size. To see this effect in action even on simple convex models (although as we will show, this is also present in real deep networks), we run logistic regression on the MNIST dataset with different sub-sampling to imitate the different extent of over-parameterisation. We randomly draw training samples of sizes of *||S||* = {7500, 2500, 1000, 250, 100, 50} for 10 different random seeds, use a validation set with 5000 samples and show the results in Figure 2. Consistent with our theoretical prediction, not only do the margins of improvement of IA increase as the extent of sub-sampling increases, as a further demonstration of noise robustness the variance ![3_image_0.png](3_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5191,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5192,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5193,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5194 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Experimental Validation The key result from our analysis is that IA leads to better robustness to gradient noise, and this effect scales with the ratio of parameters to batch size."@en ;
    askg-onto:inSentence "Experimental Validation The key result from our analysis is that IA leads to better robustness to gradient noise, and this effect scales with the ratio of parameters to batch size."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-better_robustness_to_gradient_noise,
        askg-data:Entity-ia,
        askg-data:Entity-ratio_of_parameters_to_batch_size .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To see this effect in action even on simple convex models (although as we will show, this is also present in real deep networks), we run logistic regression on the MNIST dataset with different sub-sampling to imitate the different extent of over-parameterisation."@en ;
    askg-onto:inSentence "To see this effect in action even on simple convex models (although as we will show, this is also present in real deep networks), we run logistic regression on the MNIST dataset with different sub-sampling to imitate the different extent of over-parameterisation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-logistic_regression,
        askg-data:Entity-mnist_dataset .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5193 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We randomly draw training samples of sizes of *||S||* = {7500, 2500, 1000, 250, 100, 50} for 10 different random seeds, use a validation set with 5000 samples and show the results in Figure 2."@en ;
    askg-onto:inSentence "We randomly draw training samples of sizes of *||S||* = {7500, 2500, 1000, 250, 100, 50} for 10 different random seeds, use a validation set with 5000 samples and show the results in Figure 2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5000_samples,
        askg-data:Entity-figure_2,
        askg-data:Entity-results,
        askg-data:Entity-sizes_of_s__7500_2500_1000_250_100_50,
        askg-data:Entity-training_samples,
        askg-data:Entity-validation_set .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-519-Sentence-5194 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Consistent with our theoretical prediction, not only do the margins of improvement of IA increase as the extent of sub-sampling increases, as a further demonstration of noise robustness the variance ![3_image_0.png](3_image_0.png)"@en ;
    askg-onto:inSentence "Consistent with our theoretical prediction, not only do the margins of improvement of IA increase as the extent of sub-sampling increases, as a further demonstration of noise robustness the variance ![3_image_0.png](3_image_0.png)"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-noise_robustness,
        askg-data:Entity-the_extent_of_sub-sampling,
        askg-data:Entity-variance .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-52 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Gaussian noise, âˆ¼ N (0, Ïƒ2). The final iterate, with a total training budget n is given by:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-52-Sentence-521,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-52-Sentence-522 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-52-Sentence-521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Gaussian noise, âˆ¼ N (0, Ïƒ2)."@en ;
    askg-onto:inSentence "Gaussian noise, âˆ¼ N (0, Ïƒ2)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gaussian_noise,
        askg-data:Entity-n_0_%CF%832 .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-52-Sentence-522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The final iterate, with a total training budget n is given by:"@en ;
    askg-onto:inSentence "The final iterate, with a total training budget n is given by:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_iterate,
        askg-data:Entity-total_training_budget_n .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "(a) Train/test accuracy (b) Variance of test accuracy Figure 2. SGD and IA performance with different sub-sampling on MNIST. Error bars representing Â± 1 standard deviation in (a) and variance in (b) are computed from 10 repeats."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520-Sentence-5201,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520-Sentence-5202,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520-Sentence-5203 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520-Sentence-5201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "(a) Train/test accuracy (b) Variance of test accuracy Figure 2."@en ;
    askg-onto:inSentence "(a) Train/test accuracy (b) Variance of test accuracy Figure 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-traintest_accuracy,
        askg-data:Entity-variance_of_test_accuracy .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520-Sentence-5202 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "SGD and IA performance with different sub-sampling on MNIST."@en ;
    askg-onto:inSentence "SGD and IA performance with different sub-sampling on MNIST."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-mnist,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-520-Sentence-5203 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Error bars representing Â± 1 standard deviation in (a) and variance in (b) are computed from 10 repeats."@en ;
    askg-onto:inSentence "Error bars representing Â± 1 standard deviation in (a) and variance in (b) are computed from 10 repeats."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10_repeats,
        askg-data:Entity-_1_standard_deviation,
        askg-data:Entity-error_bars,
        askg-data:Entity-variance .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-53 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$\\begin{array}{l}{{w_{1}=(1-\\alpha\\lambda)w_{0}+\\alpha\\epsilon,\\,w_{2}=(1-\\alpha\\lambda)^{2}w_{0}+(1-\\alpha\\lambda)\\alpha\\epsilon+\\alpha\\epsilon,}}\\\\ {{w_{n}\\sim\\mathcal{N}\\bigg((1-\\alpha\\lambda)^{n}w_{0},\\frac{\\alpha\\sigma^{2}(1-(1-\\alpha\\lambda)^{n-2})}{\\lambda}\\bigg)}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-53-Sentence-531 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-53-Sentence-531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{{w_{1}=(1-\\alpha\\lambda)w_{0}+\\alpha\\epsilon,\\,w_{2}=(1-\\alpha\\lambda)^{2}w_{0}+(1-\\alpha\\lambda)\\alpha\\epsilon+\\alpha\\epsilon,}}\\\\ {{w_{n}\\sim\\mathcal{N}\\bigg((1-\\alpha\\lambda)^{n}w_{0},\\frac{\\alpha\\sigma^{2}(1-(1-\\alpha\\lambda)^{n-2})}{\\lambda}\\bigg)}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{{w_{1}=(1-\\alpha\\lambda)w_{0}+\\alpha\\epsilon,\\,w_{2}=(1-\\alpha\\lambda)^{2}w_{0}+(1-\\alpha\\lambda)\\alpha\\epsilon+\\alpha\\epsilon,}}\\\\ {{w_{n}\\sim\\mathcal{N}\\bigg((1-\\alpha\\lambda)^{n}w_{0},\\frac{\\alpha\\sigma^{2}(1-(1-\\alpha\\lambda)^{n-2})}{\\lambda}\\bigg)}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-calculation,
        askg-data:Entity-normal_distribution,
        askg-data:Entity-w_1,
        askg-data:Entity-w_2,
        askg-data:Entity-w_n .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-54 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "where we have exploited the formulas for geometric sums and independence and Gaussianity of the noise. For the 2 average iterate wavg, the variance is,"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-54-Sentence-541,
        askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-54-Sentence-542 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-54-Sentence-541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where we have exploited the formulas for geometric sums and independence and Gaussianity of the noise."@en ;
    askg-onto:inSentence "where we have exploited the formulas for geometric sums and independence and Gaussianity of the noise."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulas_for_geometric_sums,
        askg-data:Entity-gaussianity_of_the_noise .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-54-Sentence-542 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For the 2 average iterate wavg, the variance is,"@en ;
    askg-onto:inSentence "For the 2 average iterate wavg, the variance is,"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-variance,
        askg-data:Entity-wavg .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-55 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\forall{\\frac{1}{n}}{\\bigg(}\\sum_{i=1}^{n-1-j}(1-\\alpha\\lambda)^{i}\\alpha\\epsilon_{j}{\\bigg)}<\\forall{\\frac{1}{n}}{\\bigg(}\\sum_{i=1}^{n}(1-\\alpha\\lambda)^{i}\\alpha\\epsilon_{j}{\\bigg)}\\,,\\forall j$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-55-Sentence-551 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-55-Sentence-551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\forall{\\frac{1}{n}}{\\bigg(}\\sum_{i=1}^{n-1-j}(1-\\alpha\\lambda)^{i}\\alpha\\epsilon_{j}{\\bigg)}<\\forall{\\frac{1}{n}}{\\bigg(}\\sum_{i=1}^{n}(1-\\alpha\\lambda)^{i}\\alpha\\epsilon_{j}{\\bigg)}\\,,\\forall j$$"@en ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-56 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "3 and hence, as there are n such sums we have"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-56-Sentence-561 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-56-Sentence-561 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3 and hence, as there are n such sums we have"@en ;
    askg-onto:inSentence "3 and hence, as there are n such sums we have"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n,
        askg-data:Entity-sums .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-57 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$w_{\\mathrm{avg}}\\sim{\\mathcal{N}}({\\bar{\\mu}},{\\bar{\\sigma}}^{2}),{\\bar{\\mu}}={\\frac{[1-(1-\\alpha\\lambda)^{n-2}]w_{0}}{n\\alpha\\lambda}},\\ {\\bar{\\sigma}}^{2}<{\\frac{\\alpha\\sigma^{2}}{\\lambda n}}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-57-Sentence-571 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-57-Sentence-571 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$w_{\\mathrm{avg}}\\sim{\\mathcal{N}}({\\bar{\\mu}},{\\bar{\\sigma}}^{2}),{\\bar{\\mu}}={\\frac{[1-(1-\\alpha\\lambda)^{n-2}]w_{0}}{n\\alpha\\lambda}},\\ {\\bar{\\sigma}}^{2}<{\\frac{\\alpha\\sigma^{2}}{\\lambda n}}$$"@en ;
    askg-onto:inSentence "$$w_{\\mathrm{avg}}\\sim{\\mathcal{N}}({\\bar{\\mu}},{\\bar{\\sigma}}^{2}),{\\bar{\\mu}}={\\frac{[1-(1-\\alpha\\lambda)^{n-2}]w_{0}}{n\\alpha\\lambda}},\\ {\\bar{\\sigma}}^{2}<{\\frac{\\alpha\\sigma^{2}}{\\lambda n}}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extnar%09extmuar%09extsigma2,
        askg-data:Entity-%0Crac%09extalpha%09extsigma2%09extlambda_n,
        askg-data:Entity-%0Crac1-1-%09extalpha%09extlambdan-2w_0n%09extalpha%09extlambda,
        askg-data:Entity-ar%09extmu,
        askg-data:Entity-ar%09extsigma2,
        askg-data:Entity-w_%09extavg .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-58 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Let us now assume that n â†’ âˆž and that |Î±Î»| 1 Then the terms above simplify to"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-58-Sentence-581 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-58-Sentence-581 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Let us now assume that n â†’ âˆž and that |Î±Î»| 1 Then the terms above simplify to"@en ;
    askg-onto:inSentence "Let us now assume that n â†’ âˆž and that |Î±Î»| 1 Then the terms above simplify to"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B1%CE%BB,
        askg-data:Entity-1,
        askg-data:Entity-n .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-59 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$$w_{n}\\sim{\\mathcal{N}}\\left(w_{0}\\mathrm{e}^{-n\\alpha\\lambda},{\\frac{\\alpha\\sigma^{2}}{\\lambda}}\\right),\\,\\,\\,w_{\\mathrm{avg}}\\sim{\\mathcal{N}}\\left({\\frac{w_{0}}{n\\alpha\\lambda}},{\\frac{\\alpha\\sigma^{2}}{\\lambda n}}\\right)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-59-Sentence-591 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-5-Paragraph-59-Sentence-591 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$w_{n}\\sim{\\mathcal{N}}\\left(w_{0}\\mathrm{e}^{-n\\alpha\\lambda},{\\frac{\\alpha\\sigma^{2}}{\\lambda}}\\right),\\,\\,\\,w_{\\mathrm{avg}}\\sim{\\mathcal{N}}\\left({\\frac{w_{0}}{n\\alpha\\lambda}},{\\frac{\\alpha\\sigma^{2}}{\\lambda n}}\\right)$$"@en ;
    askg-onto:inSentence "$$w_{n}\\sim{\\mathcal{N}}\\left(w_{0}\\mathrm{e}^{-n\\alpha\\lambda},{\\frac{\\alpha\\sigma^{2}}{\\lambda}}\\right),\\,\\,\\,w_{\\mathrm{avg}}\\sim{\\mathcal{N}}\\left({\\frac{w_{0}}{n\\alpha\\lambda}},{\\frac{\\alpha\\sigma^{2}}{\\lambda n}}\\right)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Amathcalnleftw_0mathrme-nalphalambdafracalphasigma2lambdaright,
        askg-data:Entity-mathcalnleftfracw_0nalphalambdafracalphasigma2lambda_nright,
        askg-data:Entity-w_avg,
        askg-data:Entity-w_n .

askg-data:Paper-43d37e59d752bc41-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "2.2. Regularising Effects Of Ia"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-62,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-67 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Related to our first claim, we also argue that IA exerts regularisation through weight reduction. Formally: Theorem 3. If iterates {wi} are drawn from a uniform distribution in the weight space, then the L2 norm of the expected IA point is smaller or equal to the expectation of the L2 *weight norm of the iterates. (Proof in Appendix* E)"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-611,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-612,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-613,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-614 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Related to our first claim, we also argue that IA exerts regularisation through weight reduction."@en ;
    askg-onto:inSentence "Related to our first claim, we also argue that IA exerts regularisation through weight reduction."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-regularisation,
        askg-data:Entity-weight_reduction .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Formally: Theorem 3."@en ;
    askg-onto:inSentence "Formally: Theorem 3."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-theorem,
        askg-data:Entity-theorem_3 .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "If iterates {wi} are drawn from a uniform distribution in the weight space, then the L2 norm of the expected IA point is smaller or equal to the expectation of the L2 *weight norm of the iterates."@en ;
    askg-onto:inSentence "If iterates {wi} are drawn from a uniform distribution in the weight space, then the L2 norm of the expected IA point is smaller or equal to the expectation of the L2 *weight norm of the iterates."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expectation_of_the_l2_weight_norm,
        askg-data:Entity-iterates,
        askg-data:Entity-l2_norm,
        askg-data:Entity-uniform_distribution .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-61-Sentence-614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(Proof in Appendix* E)"@en ;
    askg-onto:inSentence "(Proof in Appendix* E)"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proof .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$||\\mathbb{E}(\\mathbf{w_{i}})||_{2}^{2}\\leq\\mathbb{E}\\left(||\\mathbf{w_{i}}||_{2}^{2}\\right)\\tag{4}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-62-Sentence-621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$||\\mathbb{E}(\\mathbf{w_{i}})||_{2}^{2}\\leq\\mathbb{E}\\left(||\\mathbf{w_{i}}||_{2}^{2}\\right)\\tag{4}$$"@en ;
    askg-onto:inSentence "$$||\\mathbb{E}(\\mathbf{w_{i}})||_{2}^{2}\\leq\\mathbb{E}\\left(||\\mathbf{w_{i}}||_{2}^{2}\\right)\\tag{4}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ew_i,
        askg-data:Entity-ew_i_22 .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The assumption on the uniform distribution is more likely to be met near the end of training when the validation statistics stop improving and iterates oscillate around the minimum. Hence, by Theorem 3, we expect the weight norm of the IA point to be less than the expected weight norm of the individual iterates. Low weight norm solutions correspond to maximum margin solutions, which have a fruitful history in machine learning and have been touted as a major reason for the implicit regularisation of non-adaptive methods (Wilson et al., 2017). L2 regularisation is extensively adopted and can be shown to reduce the effect of static noise on the targets (Krogh & Hertz, 1992). To showcase the relevance of Theorem 3, we plot the weight norm of the VGG-16 on the CIFAR-100 data-set along with test accuracy (Figure 3). We see that as soon as iterate averaging is enabled at epoch 161 that the weight norm begins to decrease from that of the iterates and that the accuracy of the iterate average surpasses that of the iterates. The extent of weight reduction will depend on the variance and independence in the weights of the iterates element-wise, and hence we only expect a significant reduction for large moves in the weight-space, corresponding to a high learning rate - this could explain why in IA, a high learning rate usually leads to the best performance."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-631,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-632,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-633,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-634,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-635,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-636,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-637 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The assumption on the uniform distribution is more likely to be met near the end of training when the validation statistics stop improving and iterates oscillate around the minimum."@en ;
    askg-onto:inSentence "The assumption on the uniform distribution is more likely to be met near the end of training when the validation statistics stop improving and iterates oscillate around the minimum."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iterates,
        askg-data:Entity-minimum,
        askg-data:Entity-training,
        askg-data:Entity-uniform_distribution,
        askg-data:Entity-validation_statistics .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Hence, by Theorem 3, we expect the weight norm of the IA point to be less than the expected weight norm of the individual iterates."@en ;
    askg-onto:inSentence "Hence, by Theorem 3, we expect the weight norm of the IA point to be less than the expected weight norm of the individual iterates."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expected_weight_norm_of_the_individual_iterates,
        askg-data:Entity-theorem_3,
        askg-data:Entity-weight_norm_of_the_ia_point .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Low weight norm solutions correspond to maximum margin solutions, which have a fruitful history in machine learning and have been touted as a major reason for the implicit regularisation of non-adaptive methods (Wilson et al., 2017)."@en ;
    askg-onto:inSentence "Low weight norm solutions correspond to maximum margin solutions, which have a fruitful history in machine learning and have been touted as a major reason for the implicit regularisation of non-adaptive methods (Wilson et al., 2017)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-implicit_regularisation_of_non-adaptive_methods,
        askg-data:Entity-low_weight_norm_solutions,
        askg-data:Entity-machine_learning,
        askg-data:Entity-maximum_margin_solutions,
        askg-data:Entity-wilson_et_al_2017 .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "L2 regularisation is extensively adopted and can be shown to reduce the effect of static noise on the targets (Krogh & Hertz, 1992)."@en ;
    askg-onto:inSentence "L2 regularisation is extensively adopted and can be shown to reduce the effect of static noise on the targets (Krogh & Hertz, 1992)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1992,
        askg-data:Entity-krogh__hertz,
        askg-data:Entity-l2_regularisation,
        askg-data:Entity-static_noise .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-635 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To showcase the relevance of Theorem 3, we plot the weight norm of the VGG-16 on the CIFAR-100 data-set along with test accuracy (Figure 3)."@en ;
    askg-onto:inSentence "To showcase the relevance of Theorem 3, we plot the weight norm of the VGG-16 on the CIFAR-100 data-set along with test accuracy (Figure 3)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100_data-set,
        askg-data:Entity-figure_3,
        askg-data:Entity-test_accuracy,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-636 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We see that as soon as iterate averaging is enabled at epoch 161 that the weight norm begins to decrease from that of the iterates and that the accuracy of the iterate average surpasses that of the iterates."@en ;
    askg-onto:inSentence "We see that as soon as iterate averaging is enabled at epoch 161 that the weight norm begins to decrease from that of the iterates and that the accuracy of the iterate average surpasses that of the iterates."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-accuracy_of_the_iterate_average,
        askg-data:Entity-accuracy_of_the_iterates,
        askg-data:Entity-epoch_161,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-iterates,
        askg-data:Entity-weight_norm .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-63-Sentence-637 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The extent of weight reduction will depend on the variance and independence in the weights of the iterates element-wise, and hence we only expect a significant reduction for large moves in the weight-space, corresponding to a high learning rate - this could explain why in IA, a high learning rate usually leads to the best performance."@en ;
    askg-onto:inSentence "The extent of weight reduction will depend on the variance and independence in the weights of the iterates element-wise, and hence we only expect a significant reduction for large moves in the weight-space, corresponding to a high learning rate - this could explain why in IA, a high learning rate usually leads to the best performance."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_performance,
        askg-data:Entity-high_learning_rate,
        askg-data:Entity-variance_and_independence_in_the_weights_of_the_iterates_element-wise,
        askg-data:Entity-weight_reduction .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "equipped network (Ioffe & Szegedy, 2015) where reduction in weight norm is not necessarily connected to limiting of the model expressiveness, the weight-reducing effect still regularises in a different form. We follow the arguments of Zhang et al. (2018b), who showed that the effective learning 4"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64-Sentence-641,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64-Sentence-642,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64-Sentence-643 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64-Sentence-641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "equipped network (Ioffe & Szegedy, 2015) where reduction in weight norm is not necessarily connected to limiting of the model expressiveness, the weight-reducing effect still regularises in a different form."@en ;
    askg-onto:inSentence "equipped network (Ioffe & Szegedy, 2015) where reduction in weight norm is not necessarily connected to limiting of the model expressiveness, the weight-reducing effect still regularises in a different form."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equipped_network,
        askg-data:Entity-model_expressiveness,
        askg-data:Entity-regularisation,
        askg-data:Entity-weight-reducing_effect,
        askg-data:Entity-weight_norm,
        askg-data:Entity-weight_norm_reduction .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64-Sentence-642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We follow the arguments of Zhang et al."@en ;
    askg-onto:inSentence "We follow the arguments of Zhang et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arguments,
        askg-data:Entity-zhang_et_al .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-64-Sentence-643 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2018b), who showed that the effective learning 4"@en ;
    askg-onto:inSentence "(2018b), who showed that the effective learning 4"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2018b,
        askg-data:Entity-effective_learning .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "| OPTIMISER | TERMINAL LR | TRAIN ACC. | TEST ACC. | SPECTRAL NORM | FROBENIUS NORM | TRACE | |-------------|---------------|---------------|---------------|-----------------|--------------------------|--------------------------| | SGD | 0.0005 | 99.75 | 71.94 | 4.40 | 1.2 Ã— 10âˆ’5 | 4.7 Ã— 10âˆ’6 | | IA | 0.003 | 99.98 (98.87) | 71.32 (69.88) | 1.85 (14.6) | 4.4 Ã— 10âˆ’6 (1.3 Ã— 10âˆ’4 ) | 1.1 Ã— 10âˆ’6 (8.6 Ã— 10âˆ’5 ) | | IA | 0.01 | 99.83 (94.81) | 73.02 (68.80) | 2.37 (14.7) | 1.2 Ã— 10âˆ’6 (1.6 Ã— 10âˆ’4 ) | 5.5 Ã— 10âˆ’6 (1.2 Ã— 10âˆ’4 ) | | IA | 0.03 | 91.58 (77.29) | 73.40 (63.42) | 1.35 (12.0) | 8.4 Ã— 10âˆ’6 (7.0 Ã— 10âˆ’5 ) | 1.8 Ã— 10âˆ’5 (9.8 Ã— 10âˆ’5 ) |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65-Sentence-651,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65-Sentence-652,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65-Sentence-653 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65-Sentence-651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| OPTIMISER | TERMINAL LR | TRAIN ACC."@en ;
    askg-onto:inSentence "| OPTIMISER | TERMINAL LR | TRAIN ACC."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-metric,
        askg-data:Entity-optimiser,
        askg-data:Entity-terminal_lr,
        askg-data:Entity-tool,
        askg-data:Entity-train_acc .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65-Sentence-652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "| TEST ACC."@en ;
    askg-onto:inSentence "| TEST ACC."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-result,
        askg-data:Entity-test_acc .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-65-Sentence-653 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "| SPECTRAL NORM | FROBENIUS NORM | TRACE | |-------------|---------------|---------------|---------------|-----------------|--------------------------|--------------------------| | SGD | 0.0005 | 99.75 | 71.94 | 4.40 | 1.2 Ã— 10âˆ’5 | 4.7 Ã— 10âˆ’6 | | IA | 0.003 | 99.98 (98.87) | 71.32 (69.88) | 1.85 (14.6) | 4.4 Ã— 10âˆ’6 (1.3 Ã— 10âˆ’4 ) | 1.1 Ã— 10âˆ’6 (8.6 Ã— 10âˆ’5 ) | | IA | 0.01 | 99.83 (94.81) | 73.02 (68.80) | 2.37 (14.7) | 1.2 Ã— 10âˆ’6 (1.6 Ã— 10âˆ’4 ) | 5.5 Ã— 10âˆ’6 (1.2 Ã— 10âˆ’4 ) | | IA | 0.03 | 91.58 (77.29) | 73.40 (63.42) | 1.35 (12.0) | 8.4 Ã— 10âˆ’6 (7.0 Ã— 10âˆ’5 ) | 1.8 Ã— 10âˆ’5 (9.8 Ã— 10âˆ’5 ) |"@en ;
    askg-onto:inSentence "| SPECTRAL NORM | FROBENIUS NORM | TRACE | |-------------|---------------|---------------|---------------|-----------------|--------------------------|--------------------------| | SGD | 0.0005 | 99.75 | 71.94 | 4.40 | 1.2 Ã— 10âˆ’5 | 4.7 Ã— 10âˆ’6 | | IA | 0.003 | 99.98 (98.87) | 71.32 (69.88) | 1.85 (14.6) | 4.4 Ã— 10âˆ’6 (1.3 Ã— 10âˆ’4 ) | 1.1 Ã— 10âˆ’6 (8.6 Ã— 10âˆ’5 ) | | IA | 0.01 | 99.83 (94.81) | 73.02 (68.80) | 2.37 (14.7) | 1.2 Ã— 10âˆ’6 (1.6 Ã— 10âˆ’4 ) | 5.5 Ã— 10âˆ’6 (1.2 Ã— 10âˆ’4 ) | | IA | 0.03 | 91.58 (77.29) | 73.40 (63.42) | 1.35 (12.0) | 8.4 Ã— 10âˆ’6 (7.0 Ã— 10âˆ’5 ) | 1.8 Ã— 10âˆ’5 (9.8 Ã— 10âˆ’5 ) |"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-frobenius_norm,
        askg-data:Entity-ia,
        askg-data:Entity-sgd,
        askg-data:Entity-spectral_norm,
        askg-data:Entity-trace .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Table 1. Performance and Hessian-based sharpness metrics of various SGD and IA experiments on CIFAR-100 using VGG-16. The statistics corresponding to the *iterate* of at the end of training for IA schedules are shown in brackets."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66-Sentence-661,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66-Sentence-662,
        askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66-Sentence-663 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66-Sentence-661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 1."@en ;
    askg-onto:inSentence "Table 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_1,
        askg-data:Entity-triples .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66-Sentence-662 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Performance and Hessian-based sharpness metrics of various SGD and IA experiments on CIFAR-100 using VGG-16."@en ;
    askg-onto:inSentence "Performance and Hessian-based sharpness metrics of various SGD and IA experiments on CIFAR-100 using VGG-16."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100,
        askg-data:Entity-ia,
        askg-data:Entity-model,
        askg-data:Entity-performance_and_hessian-based_sharpness_metrics,
        askg-data:Entity-sgd,
        askg-data:Entity-various_sgd_and_ia_experiments,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-66-Sentence-663 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The statistics corresponding to the *iterate* of at the end of training for IA schedules are shown in brackets."@en ;
    askg-onto:inSentence "The statistics corresponding to the *iterate* of at the end of training for IA schedules are shown in brackets."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia_schedules,
        askg-data:Entity-iterate,
        askg-data:Entity-training .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-67 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "rate scales Î±eff âˆ1 ||w||2 , and thus weight reduction still implicitly regularises by promoting and maintaining a high effective learning rate."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-67-Sentence-671 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-6-Paragraph-67-Sentence-671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "rate scales Î±eff âˆ1 ||w||2 , and thus weight reduction still implicitly regularises by promoting and maintaining a high effective learning rate."@en ;
    askg-onto:inSentence "rate scales Î±eff âˆ1 ||w||2 , and thus weight reduction still implicitly regularises by promoting and maintaining a high effective learning rate."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B1eff,
        askg-data:Entity-effective_learning_rate,
        askg-data:Entity-rate_scales,
        askg-data:Entity-weight_reduction .

askg-data:Paper-43d37e59d752bc41-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "3. Examining Related Works"@en ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "3.1. Local Geometry Of Minima"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Previous works (Izmailov et al., 2018) primarily attribute the efficacy of IA to the local geometry of the minimum which it finds. From both Bayesian and minimum description length arguments (Hochreiter & Schmidhuber, 1997), flatter minima generalise better, as they capture more probability mass. He et al. (2019) formalise this intuition under the assumption of a shift between the training and testing loss surface and investigate the presence of \"flat valleys\" in deep learning loss landscape. They argue that averaging leads to a biased solution to the \"flatter\" valley, which has worse training but better generalisation performance due to the shift. However, the aforementioned train their SGD baseline and their averaged schemes on completely different learning rate schedules. While this is practically justified, and even desirable, exactly because IA schedules perform better with high learning rate as argued in Section 2.2, for theoretical analysis this could introduce interfering factors because it is known that the learning rate schedule can have a significant impact on both performance and curvature (Jastrzebski et al., 2020). We address this by evaluating properties of the IA and SGD points, for the same learning rate on logistic regression and for different terminal IA learning rate on the VGG network. We use a step learning rate decay schedule, for logistic regression on the MNIST data-set (LeCun, 1998), and for each flat learning rate we concurrently compute the average of the iterates. We present the results in Table 2 and Figure 4. Clearly for the same learning rate, iterate averaging helps both optimisation and generalisation *compared to iterates* of the same learning rate schedule; there is no trade-off (similar results are also found in real networks. See Table 1). Given that all stochastic convex optimisation proofs bound the average regret, which is an upper bound to the loss of the average of the iterates, it is not surprising that iterate averaging is helpful for optimisation; we include a full discussion of this in Appendix F. Moreover, it is also interesting that consistent on our hypothesis that links efficacy of IA to the extent over-parameterisation, whilst IA does not improve test performance in logistic regression (in Table 2, both best-performing IA and SGD have test accuracy of 92.69%), it does remarkably improve in VGG-16 (in Table 1, best-performing IA and SGD have test accuracy 73.40% and 71.94%, respectively). This phenomenon will be further validated in the Experiment section. We also evaluate the local geometry arguments on non-"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-811,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8110,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8111,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8112,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8113,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8114,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8115,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8116,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-812,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-813,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-814,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-815,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-816,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-817,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-818,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-819 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Previous works (Izmailov et al., 2018) primarily attribute the efficacy of IA to the local geometry of the minimum which it finds."@en ;
    askg-onto:inSentence "Previous works (Izmailov et al., 2018) primarily attribute the efficacy of IA to the local geometry of the minimum which it finds."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-efficacy_of_ia,
        askg-data:Entity-ia,
        askg-data:Entity-izmailov_et_al,
        askg-data:Entity-local_geometry_of_the_minimum .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "We present the results in Table 2 and Figure 4."@en ;
    askg-onto:inSentence "We present the results in Table 2 and Figure 4."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Clearly for the same learning rate, iterate averaging helps both optimisation and generalisation *compared to iterates* of the same learning rate schedule; there is no trade-off (similar results are also found in real networks."@en ;
    askg-onto:inSentence "Clearly for the same learning rate, iterate averaging helps both optimisation and generalisation *compared to iterates* of the same learning rate schedule; there is no trade-off (similar results are also found in real networks."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalisation,
        askg-data:Entity-iterates,
        askg-data:Entity-iterating_averaging,
        askg-data:Entity-optimisation .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "See Table 1)."@en ;
    askg-onto:inSentence "See Table 1)."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-table_1 .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Given that all stochastic convex optimisation proofs bound the average regret, which is an upper bound to the loss of the average of the iterates, it is not surprising that iterate averaging is helpful for optimisation; we include a full discussion of this in Appendix F."@en ;
    askg-onto:inSentence "Given that all stochastic convex optimisation proofs bound the average regret, which is an upper bound to the loss of the average of the iterates, it is not surprising that iterate averaging is helpful for optimisation; we include a full discussion of this in Appendix F."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_regret,
        askg-data:Entity-iterate_averaging,
        askg-data:Entity-loss_of_the_average_of_the_iterates,
        askg-data:Entity-optimisation,
        askg-data:Entity-stochastic_convex_optimisation .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Moreover, it is also interesting that consistent on our hypothesis that links efficacy of IA to the extent over-parameterisation, whilst IA does not improve test performance in logistic regression (in Table 2, both best-performing IA and SGD have test accuracy of 92.69%), it does remarkably improve in VGG-16 (in Table 1, best-performing IA and SGD have test accuracy 73.40% and 71.94%, respectively)."@en ;
    askg-onto:inSentence "Moreover, it is also interesting that consistent on our hypothesis that links efficacy of IA to the extent over-parameterisation, whilst IA does not improve test performance in logistic regression (in Table 2, both best-performing IA and SGD have test accuracy of 92.69%), it does remarkably improve in VGG-16 (in Table 1, best-performing IA and SGD have test accuracy 73.40% and 71.94%, respectively)."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7194,
        askg-data:Entity-7340,
        askg-data:Entity-9269,
        askg-data:Entity-ia,
        askg-data:Entity-logistic_regression,
        askg-data:Entity-over-parameterisation,
        askg-data:Entity-sgd,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "This phenomenon will be further validated in the Experiment section."@en ;
    askg-onto:inSentence "This phenomenon will be further validated in the Experiment section."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiment_section,
        askg-data:Entity-phenomenon .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-8116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "We also evaluate the local geometry arguments on non-"@en ;
    askg-onto:inSentence "We also evaluate the local geometry arguments on non-"^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-local_geometry_arguments,
        askg-data:Entity-non-meaningful_entities .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "From both Bayesian and minimum description length arguments (Hochreiter & Schmidhuber, 1997), flatter minima generalise better, as they capture more probability mass."@en ;
    askg-onto:inSentence "From both Bayesian and minimum description length arguments (Hochreiter & Schmidhuber, 1997), flatter minima generalise better, as they capture more probability mass."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flatter_minima,
        askg-data:Entity-flatter_minima_generalise_better,
        askg-data:Entity-hochreiter__schmidhuber,
        askg-data:Entity-more_probability_mass .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "He et al."@en ;
    askg-onto:inSentence "He et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-he_et_al .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2019) formalise this intuition under the assumption of a shift between the training and testing loss surface and investigate the presence of \"flat valleys\" in deep learning loss landscape."@en ;
    askg-onto:inSentence "(2019) formalise this intuition under the assumption of a shift between the training and testing loss surface and investigate the presence of \"flat valleys\" in deep learning loss landscape."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning_loss_landscape,
        askg-data:Entity-flat_valleys,
        askg-data:Entity-training_and_testing_loss_surface .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "They argue that averaging leads to a biased solution to the \"flatter\" valley, which has worse training but better generalisation performance due to the shift."@en ;
    askg-onto:inSentence "They argue that averaging leads to a biased solution to the \"flatter\" valley, which has worse training but better generalisation performance due to the shift."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-better_generalisation_performance,
        askg-data:Entity-biased_solution,
        askg-data:Entity-shift,
        askg-data:Entity-worse_training .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-816 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "However, the aforementioned train their SGD baseline and their averaged schemes on completely different learning rate schedules."@en ;
    askg-onto:inSentence "However, the aforementioned train their SGD baseline and their averaged schemes on completely different learning rate schedules."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaged_schemes,
        askg-data:Entity-learning_rate_schedules,
        askg-data:Entity-sgd_baseline .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-817 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "While this is practically justified, and even desirable, exactly because IA schedules perform better with high learning rate as argued in Section 2.2, for theoretical analysis this could introduce interfering factors because it is known that the learning rate schedule can have a significant impact on both performance and curvature (Jastrzebski et al., 2020)."@en ;
    askg-onto:inSentence "While this is practically justified, and even desirable, exactly because IA schedules perform better with high learning rate as argued in Section 2.2, for theoretical analysis this could introduce interfering factors because it is known that the learning rate schedule can have a significant impact on both performance and curvature (Jastrzebski et al., 2020)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2020,
        askg-data:Entity-curvature,
        askg-data:Entity-high_learning_rate,
        askg-data:Entity-ia_schedules,
        askg-data:Entity-jastrzebski_et_al,
        askg-data:Entity-learning_rate_schedule,
        askg-data:Entity-performance .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-818 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We address this by evaluating properties of the IA and SGD points, for the same learning rate on logistic regression and for different terminal IA learning rate on the VGG network."@en ;
    askg-onto:inSentence "We address this by evaluating properties of the IA and SGD points, for the same learning rate on logistic regression and for different terminal IA learning rate on the VGG network."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-logistic_regression,
        askg-data:Entity-properties_of_the_ia_and_sgd_points,
        askg-data:Entity-terminal_ia_learning_rate,
        askg-data:Entity-vgg_network .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-81-Sentence-819 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "We use a step learning rate decay schedule, for logistic regression on the MNIST data-set (LeCun, 1998), and for each flat learning rate we concurrently compute the average of the iterates."@en ;
    askg-onto:inSentence "We use a step learning rate decay schedule, for logistic regression on the MNIST data-set (LeCun, 1998), and for each flat learning rate we concurrently compute the average of the iterates."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lecun_1998,
        askg-data:Entity-logistic_regression,
        askg-data:Entity-mnist_data-set,
        askg-data:Entity-step_learning_rate_decay_schedule .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![4_image_0.png](4_image_0.png) convex real practical networks: we train the VGG-16 (Simonyan & Zisserman, 2014) network on the CIFAR-100 data-set1. We examine the spectral norm (maximum eigenvalue of Hessian), Frobenius norm and trace which serve as different measures on the \"sharpness\" of the solutions using the Lanczos-based spectral tool (Granziol et al., 2019). We summarise the results in Table 1."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82-Sentence-821,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82-Sentence-822,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82-Sentence-823 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82-Sentence-821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![4_image_0.png](4_image_0.png) convex real practical networks: we train the VGG-16 (Simonyan & Zisserman, 2014) network on the CIFAR-100 data-set1."@en ;
    askg-onto:inSentence "![4_image_0.png](4_image_0.png) convex real practical networks: we train the VGG-16 (Simonyan & Zisserman, 2014) network on the CIFAR-100 data-set1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cifar-100_dataset,
        askg-data:Entity-vgg-16 .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82-Sentence-822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We examine the spectral norm (maximum eigenvalue of Hessian), Frobenius norm and trace which serve as different measures on the \"sharpness\" of the solutions using the Lanczos-based spectral tool (Granziol et al., 2019)."@en ;
    askg-onto:inSentence "We examine the spectral norm (maximum eigenvalue of Hessian), Frobenius norm and trace which serve as different measures on the \"sharpness\" of the solutions using the Lanczos-based spectral tool (Granziol et al., 2019)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2019,
        askg-data:Entity-frobenius_norm,
        askg-data:Entity-granziol_et_al,
        askg-data:Entity-lanczos-based_spectral_tool,
        askg-data:Entity-measures_on_the_sharpness_of_the_solutions,
        askg-data:Entity-sharpness_of_the_solutions,
        askg-data:Entity-spectral_norm,
        askg-data:Entity-trace .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-82-Sentence-823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We summarise the results in Table 1."@en ;
    askg-onto:inSentence "We summarise the results in Table 1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-results .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 4. Train and test errors of the SGD and IA of different learning rates in logistic regression on MNIST. Dashed lines denote test errors and solid lines denote *train errors*"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83-Sentence-831,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83-Sentence-832,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83-Sentence-833 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83-Sentence-831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 4."@en ;
    askg-onto:inSentence "Figure 4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_4 .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83-Sentence-832 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Train and test errors of the SGD and IA of different learning rates in logistic regression on MNIST."@en ;
    askg-onto:inSentence "Train and test errors of the SGD and IA of different learning rates in logistic regression on MNIST."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-dataset,
        askg-data:Entity-ia,
        askg-data:Entity-learning_rates,
        askg-data:Entity-logistic_regression,
        askg-data:Entity-method,
        askg-data:Entity-mnist,
        askg-data:Entity-rate,
        askg-data:Entity-sgd .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-83-Sentence-833 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Dashed lines denote test errors and solid lines denote *train errors*"@en ;
    askg-onto:inSentence "Dashed lines denote test errors and solid lines denote *train errors*"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dashed_lines,
        askg-data:Entity-solid_lines,
        askg-data:Entity-test_errors,
        askg-data:Entity-train_errors .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "As shown, we find a rather mixed result with respect to the local geometry argument. Whilst the spectral norms of all the IA solutions are smaller than that of SGD, this does not correlate with generalisation performance. For the IA solution with terminal learning rate 0.003, we see smaller spectral/Frobenius norm and trace than the SGD schedule, yet better training accuracy and worse testing accuracy. The IA schedule with best test performance (terminal learning rate of 0.03), has the poorest training accuracy and a larger trace and Frobenius norm than the other two solutions, but smaller spectral norm. While the statement that averaging leads to solutions with lower curvature is valid, we find no clear correlation be-"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-841,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-842,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-843,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-844,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-845 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As shown, we find a rather mixed result with respect to the local geometry argument."@en ;
    askg-onto:inSentence "As shown, we find a rather mixed result with respect to the local geometry argument."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-local_geometry_argument,
        askg-data:Entity-mixed_result .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-842 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Whilst the spectral norms of all the IA solutions are smaller than that of SGD, this does not correlate with generalisation performance."@en ;
    askg-onto:inSentence "Whilst the spectral norms of all the IA solutions are smaller than that of SGD, this does not correlate with generalisation performance."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generalisation_performance,
        askg-data:Entity-ia_solutions,
        askg-data:Entity-sgd,
        askg-data:Entity-spectral_norms .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-843 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For the IA solution with terminal learning rate 0.003, we see smaller spectral/Frobenius norm and trace than the SGD schedule, yet better training accuracy and worse testing accuracy."@en ;
    askg-onto:inSentence "For the IA solution with terminal learning rate 0.003, we see smaller spectral/Frobenius norm and trace than the SGD schedule, yet better training accuracy and worse testing accuracy."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0003,
        askg-data:Entity-better,
        askg-data:Entity-ia_solution,
        askg-data:Entity-sgd_schedule,
        askg-data:Entity-smaller,
        askg-data:Entity-worse .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-844 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The IA schedule with best test performance (terminal learning rate of 0.03), has the poorest training accuracy and a larger trace and Frobenius norm than the other two solutions, but smaller spectral norm."@en ;
    askg-onto:inSentence "The IA schedule with best test performance (terminal learning rate of 0.03), has the poorest training accuracy and a larger trace and Frobenius norm than the other two solutions, but smaller spectral norm."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_test_performance,
        askg-data:Entity-ia_schedule,
        askg-data:Entity-larger_trace_and_frobenius_norm,
        askg-data:Entity-poorest_training_accuracy,
        askg-data:Entity-smaller_spectral_norm .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-84-Sentence-845 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "While the statement that averaging leads to solutions with lower curvature is valid, we find no clear correlation be-"@en ;
    askg-onto:inSentence "While the statement that averaging leads to solutions with lower curvature is valid, we find no clear correlation be-"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-solutions_with_lower_curvature .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "5 1For details of the setup and hyperparameter tuning, see Appendix B.2 tween flatness and generalisation. Either our metrics do not sufficiently represent sharpness, which is unlikely since we included multiple metrics commonly used. or that it is not the most relevant *explanation* for the generalisation gain (or, at the very least, difficult to verify). We hypothesise the reason here is that the critical assumption, upon which the geometry argument builds, that there exist only *shifts* between test and train surfaces is unsound despite a sound analysis *given* that. For example, recent work has shown under certain assumptions that the true risk surface is everywhere flatter than the empirical counterpart (Granziol et al., 2020). Furthermore, from a practical standpoint, we observe that the use of IA with small terminal learning rates seems as though it could be used primarily to aid optimisation, whereas its combination with large learning rates, which are known to possess inherent regularisation, leads to improved generalisation."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-851,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-852,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-853,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-854,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-855,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-856 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "5 1For details of the setup and hyperparameter tuning, see Appendix B.2 tween flatness and generalisation."@en ;
    askg-onto:inSentence "5 1For details of the setup and hyperparameter tuning, see Appendix B.2 tween flatness and generalisation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-setup_and_hyperparameter_tuning .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-852 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Either our metrics do not sufficiently represent sharpness, which is unlikely since we included multiple metrics commonly used."@en ;
    askg-onto:inSentence "Either our metrics do not sufficiently represent sharpness, which is unlikely since we included multiple metrics commonly used."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-metrics,
        askg-data:Entity-sharpness .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-853 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "or that it is not the most relevant *explanation* for the generalisation gain (or, at the very least, difficult to verify)."@en ;
    askg-onto:inSentence "or that it is not the most relevant *explanation* for the generalisation gain (or, at the very least, difficult to verify)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-explanation,
        askg-data:Entity-generalisation_gain .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-854 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We hypothesise the reason here is that the critical assumption, upon which the geometry argument builds, that there exist only *shifts* between test and train surfaces is unsound despite a sound analysis *given* that."@en ;
    askg-onto:inSentence "We hypothesise the reason here is that the critical assumption, upon which the geometry argument builds, that there exist only *shifts* between test and train surfaces is unsound despite a sound analysis *given* that."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-critical_assumption,
        askg-data:Entity-geometry_argument,
        askg-data:Entity-shifts,
        askg-data:Entity-test_and_train_surfaces .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-855 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For example, recent work has shown under certain assumptions that the true risk surface is everywhere flatter than the empirical counterpart (Granziol et al., 2020)."@en ;
    askg-onto:inSentence "For example, recent work has shown under certain assumptions that the true risk surface is everywhere flatter than the empirical counterpart (Granziol et al., 2020)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2020,
        askg-data:Entity-empirical_counterpart,
        askg-data:Entity-granziol_et_al,
        askg-data:Entity-true_risk_surface .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-85-Sentence-856 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Furthermore, from a practical standpoint, we observe that the use of IA with small terminal learning rates seems as though it could be used primarily to aid optimisation, whereas its combination with large learning rates, which are known to possess inherent regularisation, leads to improved generalisation."@en ;
    askg-onto:inSentence "Furthermore, from a practical standpoint, we observe that the use of IA with small terminal learning rates seems as though it could be used primarily to aid optimisation, whereas its combination with large learning rates, which are known to possess inherent regularisation, leads to improved generalisation."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ia,
        askg-data:Entity-improved_generalisation,
        askg-data:Entity-inherent_regularisation,
        askg-data:Entity-large_learning_rates,
        askg-data:Entity-small_terminal_learning_rates .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "| ITERATE LR | Table 2. Logistic regression on MNIST. Iterate result in brackets. TRAIN ACC. | TEST ACC. | |--------------|-----------------------------------------------------------------------------------|---------------| | 0.1 | 92.70 (87.75) | 92.28 (89.63) | | 0.01 | 93.37 (92.84) | 92.65 (92.50) | | 0.001 | 93.38 (93.36) | 92.69 (92.69) |"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-861,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-862,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-863,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-864,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-865,
        askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-866 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| ITERATE LR | Table 2."@en ;
    askg-onto:inSentence "| ITERATE LR | Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-iterate_lr .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-862 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Logistic regression on MNIST."@en ;
    askg-onto:inSentence "Logistic regression on MNIST."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-logistic_regression,
        askg-data:Entity-mnist .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-863 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Iterate result in brackets."@en ;
    askg-onto:inSentence "Iterate result in brackets."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brackets,
        askg-data:Entity-result .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-864 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "TRAIN ACC."@en ;
    askg-onto:inSentence "TRAIN ACC."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-train_acc .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-865 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "| TEST ACC."@en ;
    askg-onto:inSentence "| TEST ACC."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-metric,
        askg-data:Entity-test_acc .

askg-data:Paper-43d37e59d752bc41-Section-8-Paragraph-86-Sentence-866 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "| |--------------|-----------------------------------------------------------------------------------|---------------| | 0.1 | 92.70 (87.75) | 92.28 (89.63) | | 0.01 | 93.37 (92.84) | 92.65 (92.50) | | 0.001 | 93.38 (93.36) | 92.69 (92.69) |"@en ;
    askg-onto:inSentence "| |--------------|-----------------------------------------------------------------------------------|---------------| | 0.1 | 92.70 (87.75) | 92.28 (89.63) | | 0.01 | 93.37 (92.84) | 92.65 (92.50) | | 0.001 | 93.38 (93.36) | 92.69 (92.69) |"^^xsd:string ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "3.2. Exponentially-Weighted Moving Average (Ema)"@en ;
    askg-onto:hasParagraph askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-92,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Various previous works also use EMA in weight space to achieve optimisation and/or generalisation improvements: Izmailov et al. (2018) entertain the use of EMA in SWA, although they conclude simple averaging is more competitive. Very recently, Zhang et al. (2019b) proposes *Lookahead*, a plug-in optimiser that uses EMA on the slow weights to improve convergence and generalisation. Nonetheless, having argued the dominance of noise in the high-dimensional deep learning regime, we argue that simple averaging is more theoretically desirable *for generalisation*: following the identical analysis to Section 2.1, we keep in the 1D case w.l.o.g and denote Ï âˆˆ [0, 1] as the coefficient of decay, asymptotically the EMA point wema is governed by the normal distribution:"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-911,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-912,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-913,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-914,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-915 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Various previous works also use EMA in weight space to achieve optimisation and/or generalisation improvements: Izmailov et al."@en ;
    askg-onto:inSentence "Various previous works also use EMA in weight space to achieve optimisation and/or generalisation improvements: Izmailov et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-izmailov_et_al,
        askg-data:Entity-previous_works,
        askg-data:Entity-weight_space .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2018) entertain the use of EMA in SWA, although they conclude simple averaging is more competitive."@en ;
    askg-onto:inSentence "(2018) entertain the use of EMA in SWA, although they conclude simple averaging is more competitive."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-simple_averaging,
        askg-data:Entity-swa .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Very recently, Zhang et al."@en ;
    askg-onto:inSentence "Very recently, Zhang et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-zhang_et_al .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2019b) proposes *Lookahead*, a plug-in optimiser that uses EMA on the slow weights to improve convergence and generalisation."@en ;
    askg-onto:inSentence "(2019b) proposes *Lookahead*, a plug-in optimiser that uses EMA on the slow weights to improve convergence and generalisation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-lookahead,
        askg-data:Entity-plug-in_optimiser,
        askg-data:Entity-slow_weights .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-91-Sentence-915 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Nonetheless, having argued the dominance of noise in the high-dimensional deep learning regime, we argue that simple averaging is more theoretically desirable *for generalisation*: following the identical analysis to Section 2.1, we keep in the 1D case w.l.o.g and denote Ï âˆˆ [0, 1] as the coefficient of decay, asymptotically the EMA point wema is governed by the normal distribution:"@en ;
    askg-onto:inSentence "Nonetheless, having argued the dominance of noise in the high-dimensional deep learning regime, we argue that simple averaging is more theoretically desirable *for generalisation*: following the identical analysis to Section 2.1, we keep in the 1D case w.l.o.g and denote Ï âˆˆ [0, 1] as the coefficient of decay, asymptotically the EMA point wema is governed by the normal distribution:"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averaging,
        askg-data:Entity-ema_point,
        askg-data:Entity-generalisation,
        askg-data:Entity-high-dimensional_deep_learning_regime,
        askg-data:Entity-noise,
        askg-data:Entity-normal_distribution .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-92 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathcal{N}\\!\\left(\\frac{(1-\\rho)w_{0}(1-\\alpha\\lambda)^{n+1}[1-(\\frac{\\rho}{1-\\alpha\\lambda})^{n-1}]}{1-\\alpha\\lambda-\\rho},\\frac{1-\\rho}{1+\\rho}\\frac{\\alpha\\sigma^{2}\\kappa}{\\lambda}\\right)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-92-Sentence-921 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-92-Sentence-921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathcal{N}\\!\\left(\\frac{(1-\\rho)w_{0}(1-\\alpha\\lambda)^{n+1}[1-(\\frac{\\rho}{1-\\alpha\\lambda})^{n-1}]}{1-\\alpha\\lambda-\\rho},\\frac{1-\\rho}{1+\\rho}\\frac{\\alpha\\sigma^{2}\\kappa}{\\lambda}\\right)$$"@en ;
    askg-onto:inSentence "$$\\mathcal{N}\\!\\left(\\frac{(1-\\rho)w_{0}(1-\\alpha\\lambda)^{n+1}[1-(\\frac{\\rho}{1-\\alpha\\lambda})^{n-1}]}{1-\\alpha\\lambda-\\rho},\\frac{1-\\rho}{1+\\rho}\\frac{\\alpha\\sigma^{2}\\kappa}{\\lambda}\\right)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function,
        askg-data:Entity-n .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "6 where Îº = (1 âˆ’ (1 âˆ’ Î±Î») nâˆ’2). An alternative analysis of EMA arriving at similar result was also done in Zhang et al. (2019a), but their emphasis of comparison is between the EMA point and *iterates* instead of the former and the IA point in our case. Therefore, although the convergence in mean is less strongly affected, the noise is reduced by a factor of 1âˆ’Ï 1+Ï . So whilst we reduce the noise (possibly by a very large factor), it does not vanish in the asymptotic limit. Hence viewing EMA or IA as noise reduction schemes, we can consider IA a far more aggressive noise reduction scheme than EMA. Secondly, EMA implicitly assumes that more recent iterates are better, or otherwise more important, than the previous iterates. While justified initially (partially explaining EMA's efficacy in accelerating optimisation), it is less so in the late stage of training when we typically start averaging. We nonetheless believe methods using EMA could be of great combinable value, and include a preliminary study of Lookahead and our method (to be proposed in the Section 4) in Appendix A.2."@en ;
    askg-onto:hasSentence askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-931,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-932,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-933,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-934,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-935,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-936,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-937,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-938,
        askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-939 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "6 where Îº = (1 âˆ’ (1 âˆ’ Î±Î») nâˆ’2)."@en ;
    askg-onto:inSentence "6 where Îº = (1 âˆ’ (1 âˆ’ Î±Î») nâˆ’2)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BA,
        askg-data:Entity-1__1__%CE%B1%CE%BB_n2 .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "An alternative analysis of EMA arriving at similar result was also done in Zhang et al."@en ;
    askg-onto:inSentence "An alternative analysis of EMA arriving at similar result was also done in Zhang et al."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alternative_analysis_of_ema,
        askg-data:Entity-zhang_et_al .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-933 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "(2019a), but their emphasis of comparison is between the EMA point and *iterates* instead of the former and the IA point in our case."@en ;
    askg-onto:inSentence "(2019a), but their emphasis of comparison is between the EMA point and *iterates* instead of the former and the IA point in our case."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema_point,
        askg-data:Entity-iterates .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-934 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Therefore, although the convergence in mean is less strongly affected, the noise is reduced by a factor of 1âˆ’Ï 1+Ï ."@en ;
    askg-onto:inSentence "Therefore, although the convergence in mean is less strongly affected, the noise is reduced by a factor of 1âˆ’Ï 1+Ï ."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1%CF%81_1%CF%81,
        askg-data:Entity-noise .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-935 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "So whilst we reduce the noise (possibly by a very large factor), it does not vanish in the asymptotic limit."@en ;
    askg-onto:inSentence "So whilst we reduce the noise (possibly by a very large factor), it does not vanish in the asymptotic limit."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-noise,
        askg-data:Entity-very_large_factor .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-936 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Hence viewing EMA or IA as noise reduction schemes, we can consider IA a far more aggressive noise reduction scheme than EMA."@en ;
    askg-onto:inSentence "Hence viewing EMA or IA as noise reduction schemes, we can consider IA a far more aggressive noise reduction scheme than EMA."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-ia,
        askg-data:Entity-noise_reduction_scheme .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-937 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Secondly, EMA implicitly assumes that more recent iterates are better, or otherwise more important, than the previous iterates."@en ;
    askg-onto:inSentence "Secondly, EMA implicitly assumes that more recent iterates are better, or otherwise more important, than the previous iterates."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-more_recent_iterates .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-938 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "While justified initially (partially explaining EMA's efficacy in accelerating optimisation), it is less so in the late stage of training when we typically start averaging."@en ;
    askg-onto:inSentence "While justified initially (partially explaining EMA's efficacy in accelerating optimisation), it is less so in the late stage of training when we typically start averaging."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-optimisation .

askg-data:Paper-43d37e59d752bc41-Section-9-Paragraph-93-Sentence-939 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "We nonetheless believe methods using EMA could be of great combinable value, and include a preliminary study of Lookahead and our method (to be proposed in the Section 4) in Appendix A.2."@en ;
    askg-onto:inSentence "We nonetheless believe methods using EMA could be of great combinable value, and include a preliminary study of Lookahead and our method (to be proposed in the Section 4) in Appendix A.2."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ema,
        askg-data:Entity-lookahead,
        askg-data:Entity-methods,
        askg-data:Entity-our_method,
        askg-data:Entity-preliminary_study,
        askg-data:Entity-section_4 .

askg-data:Entity-%CE%B1_t rdfs:label "Î±_t"@en,
        "Î±_{t}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B1t rdfs:label "Î±t"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B4 rdfs:label "Î´"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-001 rdfs:label "0.01"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-01 rdfs:label "0.1"@en ;
    askg-onto:entityType "Metric"@en,
        "Rate"@en .

askg-data:Entity-10 rdfs:label "10"@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-100_150 rdfs:label "100, 150"@en,
        "{100, 150}"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-161st_epoch rdfs:label "161st epoch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-18 rdfs:label "18"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-1992 rdfs:label "1992"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-200 rdfs:label "200"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-2018b rdfs:label "2018b"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2019b rdfs:label "2019b"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2020 rdfs:label "2020"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-30th_epoch rdfs:label "30th epoch"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-50 rdfs:label "50"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-9 rdfs:label "9"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-adadelta rdfs:label "AdaDelta"@en,
        "Adadelta"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-adam-ia rdfs:label "Adam-IA"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-adamwgadam rdfs:label "AdamW/Gadam"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-adaptive_gradient_methods rdfs:label "adaptive gradient methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-algorithm_1 rdfs:label "Algorithm 1"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-appendix_a3 rdfs:label "Appendix A.3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-appendix_a5 rdfs:label "Appendix A.5"@en ;
    askg-onto:entityType "Article"@en,
        "Concept"@en .

askg-data:Entity-appendix_e rdfs:label "Appendix E"@en,
        "appendix E"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arguments rdfs:label "arguments"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arpit_d rdfs:label "Arpit, D."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-article rdfs:label "Article"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv rdfs:label "arXiv"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-asymptotic_limit rdfs:label "asymptotic limit"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ba_j rdfs:label "Ba, J."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-base_optimiser rdfs:label "base optimiser"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-baseline_results rdfs:label "baseline results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-benefit_of_ia rdfs:label "benefit of IA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bengio_y rdfs:label "Bengio, Y."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-better rdfs:label "better"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-biased_optimisation rdfs:label "biased optimisation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-bottou_l rdfs:label "Bottou, L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-c rdfs:label "C."@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en .

askg-data:Entity-cifar-100_data-set rdfs:label "CIFAR-100 data-set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-cifar_10100 rdfs:label "CIFAR 10/100"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-cifar_experiments rdfs:label "CIFAR experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-convergence_in_the_mean rdfs:label "convergence in the mean"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convergence_results rdfs:label "convergence results"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-data_augmentation rdfs:label "data augmentation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_science rdfs:label "Data Science"@en,
        "data science"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-device rdfs:label "Device"@en ;
    askg-onto:entityType "Concept"@en,
        "Device"@en .

askg-data:Entity-diego_granziol rdfs:label "Diego Granziol"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-duchi_j rdfs:label "Duchi, J."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-e rdfs:label "E"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effective_learning_rate rdfs:label "effective learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expected_loss rdfs:label "expected loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-explicit_regularisation rdfs:label "explicit regularisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-faster_convergence rdfs:label "faster convergence"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-fge rdfs:label "FGE"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-figure_7 rdfs:label "Figure 7"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_8 rdfs:label "Figure 8"@en ;
    askg-onto:entityType "Concept"@en,
        "Index"@en .

askg-data:Entity-figure_9 rdfs:label "Figure 9"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-function rdfs:label "Function"@en,
        "function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gpu rdfs:label "GPU"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-gradient_descent rdfs:label "gradient descent"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-granziol_d rdfs:label "Granziol, D."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-granziol_et_al rdfs:label "Granziol et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-grosse_r rdfs:label "Grosse, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-h12 rdfs:label "H1/2"@en,
        "Hâˆ’1/2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-he_k rdfs:label "He, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-healthcare rdfs:label "Healthcare"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-high_learning_rate rdfs:label "high learning rate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hochreiter__schmidhuber rdfs:label "Hochreiter & Schmidhuber"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hutter_f rdfs:label "Hutter, F."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-hyperparameters rdfs:label "hyperparameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ia_optimisers rdfs:label "IA optimisers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-iid rdfs:label "i.i.d."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_classification rdfs:label "image classification"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-image_recognition rdfs:label "Image Recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-imagenet_experiments rdfs:label "ImageNet experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-iterate rdfs:label "iterate"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-izmailov_et_al_2018 rdfs:label "Izmailov et al. (2018)"@en,
        "Izmailov et al., 2018"@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-izmailov_p rdfs:label "Izmailov, P."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-kingma__ba_2014 rdfs:label "Kingma & Ba, 2014"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-l rdfs:label "L."@en,
        "âˆ‡âˆ‡L"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en .

askg-data:Entity-large_learning_rates rdfs:label "large learning rates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_%CE%B1 rdfs:label "learning rate Î±"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_decay rdfs:label "learning rate decay"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_schedules rdfs:label "learning rate schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rates rdfs:label "learning rates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-literature rdfs:label "literature"@en ;
    askg-onto:entityType "Concept"@en,
        "Corpus"@en .

askg-data:Entity-local_geometry_argument rdfs:label "local geometry argument"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loshchilov_i rdfs:label "Loshchilov, I."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-maddox_et_al rdfs:label "Maddox et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-martens_j rdfs:label "Martens, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-methods rdfs:label "methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-metrics rdfs:label "Metrics"@en,
        "metrics"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mgf rdfs:label "MGF"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model_complexity rdfs:label "model complexity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n-th_iterate rdfs:label "n-th iterate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-natural_language_processing rdfs:label "Natural Language Processing"@en,
        "natural language processing"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-nmodels rdfs:label "nmodels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noise_effect rdfs:label "noise effect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-noisy_quadratic_model rdfs:label "noisy quadratic model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-number rdfs:label "Number"@en,
        "number"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimisation_with_momentum rdfs:label "optimisation with momentum"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-plug-in_optimiser rdfs:label "plug-in optimiser"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-podoprikhin_d rdfs:label "Podoprikhin, D."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-polyak-style_averaging rdfs:label "Polyak-style averaging"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-pytorch rdfs:label "PyTorch"@en ;
    askg-onto:entityType "Technology"@en,
        "Tool"@en .

askg-data:Entity-regularisation_benefits rdfs:label "regularisation benefits"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_on_neural_networks rdfs:label "Research on Neural Networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-researchers rdfs:label "Researchers"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-resnext-29 rdfs:label "RESNEXT-29"@en,
        "ResNeXt-29"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-roberts_s rdfs:label "Roberts, S."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-schmidhuber_j rdfs:label "Schmidhuber, J."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-scikit-learn rdfs:label "Scikit-learn"@en ;
    askg-onto:entityType "Technology"@en,
        "Tool"@en .

askg-data:Entity-score rdfs:label "Score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-setup rdfs:label "setup"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sgd__lh rdfs:label "SGD + LH"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-sgdswa rdfs:label "SGD/SWA"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-sharper_solutions rdfs:label "sharper solutions"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-sharpness rdfs:label "sharpness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-socher_r rdfs:label "Socher, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-software rdfs:label "Software"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-springer_science__business_media rdfs:label "Springer Science & Business Media"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-step_decay rdfs:label "step decay"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stochastic_gradient_descent_sgd rdfs:label "Stochastic Gradient Descent (SGD)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-swa-auto rdfs:label "SWA-Auto"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-system rdfs:label "System"@en,
        "system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-table_1 rdfs:label "Table 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tensorflow rdfs:label "TensorFlow"@en ;
    askg-onto:entityType "Technology"@en,
        "Tool"@en .

askg-data:Entity-terminal_lr rdfs:label "TERMINAL LR"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-test_improvement rdfs:label "test improvement"@en ;
    askg-onto:entityType "Result"@en,
        "Score"@en .

askg-data:Entity-text_to_analyze rdfs:label "Text to analyze"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_main_text rdfs:label "the main text"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theorem_2 rdfs:label "Theorem 2"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-theoretical_results rdfs:label "theoretical results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-tool rdfs:label "Tool"@en,
        "tool"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-trace rdfs:label "TRACE"@en,
        "trace"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-training_error rdfs:label "Training Error"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-triple rdfs:label "triple"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tuned_sgd rdfs:label "tuned SGD"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-uniform_distribution rdfs:label "uniform distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-us rdfs:label "us"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-v rdfs:label "V"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-validation_accuracy rdfs:label "validation accuracy"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-validation_and_test_perplexity rdfs:label "Validation and Test Perplexity"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-variable rdfs:label "Variable"@en,
        "variable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vershynin rdfs:label "Vershynin"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-vgg16 rdfs:label "VGG16"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-w2 rdfs:label "w2"@en,
        "||w||2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_0 rdfs:label "w_0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-w_n rdfs:label "w_{n}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight rdfs:label "weight"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_norm rdfs:label "weight norm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_space rdfs:label "weight space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wide_residual_networks rdfs:label "Wide residual networks"@en,
        "wide residual networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-wn rdfs:label "wn"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wrn-28-10 rdfs:label "WRN-28-10"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-x rdfs:label "X"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_i rdfs:label "X_{i}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xingchen_wan rdfs:label "Xingchen Wan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhang_c rdfs:label "Zhang, C."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-zhang_et_al_2019b rdfs:label "Zhang et al., 2019b"@en ;
    askg-onto:entityType "Article"@en,
        "Publication"@en .

askg-data:Entity-zhang_g rdfs:label "Zhang, G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-%CE%B1 rdfs:label "Î±"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-00005 rdfs:label "0.0005"@en ;
    askg-onto:entityType "Rate"@en,
        "Score"@en .

askg-data:Entity-0001 rdfs:label "0.001"@en ;
    askg-onto:entityType "Concept"@en,
        "Score"@en .

askg-data:Entity-1 rdfs:label "1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2012 rdfs:label "2012"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2013 rdfs:label "2013"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2014 rdfs:label "2014"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2016 rdfs:label "2016"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-a rdfs:label "A"@en,
        "A."@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en .

askg-data:Entity-accelerated_methods rdfs:label "accelerated methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-adaptive_optimisation rdfs:label "adaptive optimisation"@en ;
    askg-onto:entityType "Concept"@en,
        "Paradigm"@en .

askg-data:Entity-algorithms rdfs:label "Algorithms"@en,
        "algorithms"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-average_regret rdfs:label "average regret"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b rdfs:label "B"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-base_optimisers rdfs:label "base optimisers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-batch_normalisation rdfs:label "batch normalisation"@en ;
    askg-onto:entityType "Method"@en,
        "Technique"@en .

askg-data:Entity-chen__gu_2018 rdfs:label "Chen & Gu (2018)"@en,
        "Chen & Gu, 2018"@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-chrabaszcz_et_al rdfs:label "Chrabaszcz et al."@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-cifar rdfs:label "CIFAR"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-cifar-100_dataset rdfs:label "CIFAR-100 Dataset"@en,
        "CIFAR-100 dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-convergence_speed rdfs:label "convergence speed"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-data rdfs:label "data"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-ema_point rdfs:label "EMA point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiment rdfs:label "Experiment"@en,
        "experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-faster rdfs:label "faster"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-final_iterate rdfs:label "final iterate"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Result"@en .

askg-data:Entity-final_test_accuracy rdfs:label "final test accuracy"@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-framework rdfs:label "Framework"@en,
        "framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-frobenius_norm rdfs:label "FROBENIUS NORM"@en,
        "Frobenius norm"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-generalisation_difference rdfs:label "generalisation difference"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalisation_performance rdfs:label "generalisation performance"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-hinton_g rdfs:label "Hinton, G."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-ia_schedules rdfs:label "IA schedules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-keskar_n rdfs:label "Keskar, N."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-l2_regularisation rdfs:label "L2 regularisation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-learning_rate_scheduling rdfs:label "learning rate scheduling"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-loshchilov__hutter rdfs:label "Loshchilov & Hutter"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-loshchilov__hutter_2018 rdfs:label "Loshchilov & Hutter (2018)"@en,
        "Loshchilov & Hutter, 2018"@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-lstm rdfs:label "LSTM"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-metric rdfs:label "Metric"@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-na rdfs:label "n/a"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nesterov rdfs:label "Nesterov"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en,
        "Publication"@en .

askg-data:Entity-normal_distribution rdfs:label "Normal Distribution"@en,
        "normal distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_epochs rdfs:label "number of epochs"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-optimiser rdfs:label "OPTIMISER"@en,
        "optimiser"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Tool"@en .

askg-data:Entity-optimisers rdfs:label "optimisers"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-optimization rdfs:label "optimization"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-optimizer rdfs:label "optimizer"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-patience rdfs:label "patience"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pp rdfs:label "pp."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r rdfs:label "R"@en,
        "r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regret rdfs:label "regret"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_concepts rdfs:label "research concepts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s rdfs:label "S."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-scheduling rdfs:label "scheduling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sgd_baseline rdfs:label "SGD baseline"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Score"@en .

askg-data:Entity-sgd_with_iterate_averaging rdfs:label "SGD with iterate averaging"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-spectral_norm rdfs:label "SPECTRAL NORM"@en,
        "spectral norm"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-stochastic_optimization rdfs:label "stochastic optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_5 rdfs:label "Table 5"@en ;
    askg-onto:entityType "Concept"@en,
        "Index"@en,
        "Result"@en .

askg-data:Entity-tavg rdfs:label "Tavg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-test_acc rdfs:label "TEST ACC."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-test_accuracy rdfs:label "Test Accuracy"@en,
        "test accuracy"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-test_performance rdfs:label "test performance"@en ;
    askg-onto:entityType "Result"@en,
        "Score"@en .

askg-data:Entity-text rdfs:label "Text"@en,
        "text"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-train_acc rdfs:label "TRAIN ACC."@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en,
        "Score"@en .

askg-data:Entity-training rdfs:label "training"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_curves rdfs:label "training curves"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-vgg-16_network rdfs:label "VGG-16 network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-wavg rdfs:label "wavg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weight_reduction rdfs:label "weight reduction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wilson_et_al_2017 rdfs:label "Wilson et al., 2017"@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-adaptive_optimiser rdfs:label "adaptive optimiser"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-gadam__lh rdfs:label "Gadam + LH"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Tool"@en .

askg-data:Entity-garipov_t rdfs:label "Garipov, T."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-generalisation_gap rdfs:label "generalisation gap"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h rdfs:label "H"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_learning_rate rdfs:label "initial learning rate"@en ;
    askg-onto:entityType "Concept"@en,
        "Rate"@en .

askg-data:Entity-j rdfs:label "J."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-kingma__ba rdfs:label "Kingma & Ba"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-mean rdfs:label "mean"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-minimum rdfs:label "minimum"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-momentum rdfs:label "momentum"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_parameters_p rdfs:label "Number of parameters P"@en,
        "number of parameters P"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-optimization_algorithm rdfs:label "Optimization Algorithm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-padamw rdfs:label "PADAM(W)"@en,
        "Padam(W)"@en,
        "PadamW"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Tool"@en .

askg-data:Entity-platform rdfs:label "Platform"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-previous_works rdfs:label "previous works"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-proof rdfs:label "Proof"@en,
        "proof"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-researcher rdfs:label "Researcher"@en,
        "researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-vetrov_d rdfs:label "Vetrov, D."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-word-level_language_modelling rdfs:label "Word-level Language Modelling"@en,
        "word-level language modelling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bias rdfs:label "bias"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cifar-10 rdfs:label "CIFAR-10"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-d rdfs:label "D"@en,
        "D."@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Person"@en .

askg-data:Entity-data_visualization rdfs:label "data visualization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decoupled_weight_decay rdfs:label "decoupled weight decay"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_neural_networks rdfs:label "deep neural networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-g rdfs:label "G"@en,
        "G."@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-imagenet rdfs:label "ImageNet"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-imagenet_3232 rdfs:label "IMAGENET 32Ã—32"@en,
        "ImageNet 32Ã—32"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-k rdfs:label "K"@en,
        "k"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-martens_2014 rdfs:label "Martens (2014)"@en,
        "Martens, 2014"@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-neural_networks rdfs:label "Neural Networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-person rdfs:label "Person"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-ptb rdfs:label "PTB"@en ;
    askg-onto:entityType "Corpus"@en,
        "Dataset"@en .

askg-data:Entity-research_area rdfs:label "Research Area"@en,
        "research area"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-study rdfs:label "study"@en ;
    askg-onto:entityType "Research Area"@en,
        "Study"@en .

askg-data:Entity-technology rdfs:label "Technology"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-theorem_3 rdfs:label "Theorem 3"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-variance rdfs:label "variance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-wilson_a rdfs:label "Wilson, A."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-2017 rdfs:label "2017"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arxiv_preprint rdfs:label "arXiv preprint"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-asgd rdfs:label "ASGD"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-epochs rdfs:label "epochs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-merity_et_al rdfs:label "Merity et al."@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-mnist rdfs:label "MNIST"@en,
        "mnist"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-regularisation rdfs:label "regularisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research rdfs:label "Research"@en,
        "research"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-unknown rdfs:label "unknown"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gadamauto rdfs:label "GadamAuto"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Technology"@en,
        "Tool"@en .

askg-data:Entity-logistic_regression rdfs:label "Logistic Regression"@en,
        "Logistic regression"@en,
        "logistic regression"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-noise rdfs:label "noise"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-nt-asgd rdfs:label "NT-ASGD"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-scientist rdfs:label "Scientist"@en,
        "scientist"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-theorem_1 rdfs:label "Theorem 1"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-zhang_et_al rdfs:label "Zhang et al."@en ;
    askg-onto:entityType "Author"@en,
        "Researcher"@en .

askg-data:Entity-generalisation rdfs:label "generalisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate_schedule rdfs:label "Learning Rate Schedule"@en,
        "learning rate schedule"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en,
        "machine learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-model rdfs:label "Model"@en,
        "model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-n rdfs:label "N"@en,
        "n"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimisation rdfs:label "optimisation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-swa rdfs:label "SWA"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-triples rdfs:label "triples"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-adaptive_optimisers rdfs:label "adaptive optimisers"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-iterates rdfs:label "iterates"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-result rdfs:label "Result"@en,
        "result"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-2019 rdfs:label "2019"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-adaptive_methods rdfs:label "adaptive methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-advances_in_neural_information_processing_systems rdfs:label "Advances in Neural Information Processing Systems"@en,
        "Advances in neural information processing systems"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-ema rdfs:label "EMA"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-t rdfs:label "T"@en,
        "t"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiments rdfs:label "experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-p rdfs:label "P"@en,
        "P."@en,
        "p"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Person"@en .

askg-data:Entity-weight_decay rdfs:label "weight decay"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Metric"@en .

askg-data:Entity-izmailov_et_al rdfs:label "Izmailov et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-prn-110 rdfs:label "PRN-110"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-cifar-100 rdfs:label "CIFAR-100"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en,
        "Deep learning"@en,
        "deep learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-padam rdfs:label "PADAM"@en,
        "Padam"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Tool"@en .

askg-data:Entity-results rdfs:label "results"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-algorithm rdfs:label "Algorithm"@en,
        "algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-averaging rdfs:label "averaging"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-lookahead rdfs:label "Lookahead"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en,
        "Technique"@en,
        "Tool"@en .

askg-data:Entity-gadamx rdfs:label "GADAMX"@en,
        "Gadam(X)"@en,
        "GadamX"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Model"@en,
        "Tool"@en .

askg-data:Entity-adamw rdfs:label "ADAM(W)"@en,
        "ADAMW"@en,
        "Adam(W)"@en,
        "AdamW"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-iterate_averaging rdfs:label "Iterate Averaging"@en,
        "Iterate averaging"@en,
        "iterate averaging"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-vgg-16 rdfs:label "VGG-16"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-2018 rdfs:label "(2018)"@en,
        "2018"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-concept rdfs:label "Concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_rate rdfs:label "learning rate"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-adam rdfs:label "ADAM"@en,
        "Adam"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en,
        "Person"@en .

askg-data:Entity-gadam rdfs:label "GADAM"@en,
        "Gadam"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Author"@en,
        "Concept"@en,
        "Model"@en,
        "Person"@en,
        "Researcher"@en,
        "Tool"@en .

askg-data:Entity-ia rdfs:label "IA"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Technology"@en .

askg-data:Entity-sgd rdfs:label "SGD"@en,
        "sgd"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-publication rdfs:label "Publication"@en,
        "publication"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-author rdfs:label "Author"@en,
        "author"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Person"@en .

