@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-c253584c3f1ff2a2 a askg-onto:Paper ;
    rdfs:label "c253584c3f1ff2a2"@en ;
    dc:title "c253584c3f1ff2a2"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-c253584c3f1ff2a2-Section-1,
        askg-data:Paper-c253584c3f1ff2a2-Section-10,
        askg-data:Paper-c253584c3f1ff2a2-Section-11,
        askg-data:Paper-c253584c3f1ff2a2-Section-12,
        askg-data:Paper-c253584c3f1ff2a2-Section-13,
        askg-data:Paper-c253584c3f1ff2a2-Section-14,
        askg-data:Paper-c253584c3f1ff2a2-Section-15,
        askg-data:Paper-c253584c3f1ff2a2-Section-16,
        askg-data:Paper-c253584c3f1ff2a2-Section-17,
        askg-data:Paper-c253584c3f1ff2a2-Section-18,
        askg-data:Paper-c253584c3f1ff2a2-Section-19,
        askg-data:Paper-c253584c3f1ff2a2-Section-2,
        askg-data:Paper-c253584c3f1ff2a2-Section-20,
        askg-data:Paper-c253584c3f1ff2a2-Section-21,
        askg-data:Paper-c253584c3f1ff2a2-Section-22,
        askg-data:Paper-c253584c3f1ff2a2-Section-23,
        askg-data:Paper-c253584c3f1ff2a2-Section-24,
        askg-data:Paper-c253584c3f1ff2a2-Section-25,
        askg-data:Paper-c253584c3f1ff2a2-Section-26,
        askg-data:Paper-c253584c3f1ff2a2-Section-27,
        askg-data:Paper-c253584c3f1ff2a2-Section-28,
        askg-data:Paper-c253584c3f1ff2a2-Section-29,
        askg-data:Paper-c253584c3f1ff2a2-Section-3,
        askg-data:Paper-c253584c3f1ff2a2-Section-30,
        askg-data:Paper-c253584c3f1ff2a2-Section-31,
        askg-data:Paper-c253584c3f1ff2a2-Section-32,
        askg-data:Paper-c253584c3f1ff2a2-Section-33,
        askg-data:Paper-c253584c3f1ff2a2-Section-34,
        askg-data:Paper-c253584c3f1ff2a2-Section-35,
        askg-data:Paper-c253584c3f1ff2a2-Section-36,
        askg-data:Paper-c253584c3f1ff2a2-Section-37,
        askg-data:Paper-c253584c3f1ff2a2-Section-38,
        askg-data:Paper-c253584c3f1ff2a2-Section-39,
        askg-data:Paper-c253584c3f1ff2a2-Section-4,
        askg-data:Paper-c253584c3f1ff2a2-Section-40,
        askg-data:Paper-c253584c3f1ff2a2-Section-41,
        askg-data:Paper-c253584c3f1ff2a2-Section-42,
        askg-data:Paper-c253584c3f1ff2a2-Section-43,
        askg-data:Paper-c253584c3f1ff2a2-Section-44,
        askg-data:Paper-c253584c3f1ff2a2-Section-45,
        askg-data:Paper-c253584c3f1ff2a2-Section-46,
        askg-data:Paper-c253584c3f1ff2a2-Section-47,
        askg-data:Paper-c253584c3f1ff2a2-Section-48,
        askg-data:Paper-c253584c3f1ff2a2-Section-49,
        askg-data:Paper-c253584c3f1ff2a2-Section-5,
        askg-data:Paper-c253584c3f1ff2a2-Section-50,
        askg-data:Paper-c253584c3f1ff2a2-Section-51,
        askg-data:Paper-c253584c3f1ff2a2-Section-52,
        askg-data:Paper-c253584c3f1ff2a2-Section-53,
        askg-data:Paper-c253584c3f1ff2a2-Section-54,
        askg-data:Paper-c253584c3f1ff2a2-Section-6,
        askg-data:Paper-c253584c3f1ff2a2-Section-7,
        askg-data:Paper-c253584c3f1ff2a2-Section-8,
        askg-data:Paper-c253584c3f1ff2a2-Section-9 .

askg-data:Entity-%09extl rdfs:label "	ext{L}"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%09extprsa rdfs:label "$	ext{Pr}(s,a)$"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%09extprulletoldsymbolsoldsymbol%09ext%CF%86aoldsymbolsulletoldsymbol%09ext%CF%86ullet rdfs:label "$	ext{Pr}^{ullet}(oldsymbol{s},oldsymbol{	ext{φ}},a,oldsymbol{s}^{ullet},oldsymbol{	ext{φ}}^{ullet})$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extprulletoldsymbolsoldsymbol%09ext%CF%86aullet rdfs:label "$	ext{Pr}^{ullet}(oldsymbol{s},oldsymbol{	ext{φ}},a,ullet)$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0A%0A%09extl%0A rdfs:label """$
{
	ext{L}}
$"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0A%0A%09extp%0A rdfs:label """$
{
	ext{P}}
$"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%0Aeginpmatrixs%09extphi%09ext_%09extbf_%09ext_sum_of__fr_%09ext_in__%09extphi%09ext_such_that__%09extnewsf rdfs:label """
egin{pmatrix}s,	ext{phi}	ext{ 	extbf{}} =	ext {sum of } (f:r) 	ext{ in } 	ext{phi}	ext{ such that } 	ext{New}(s,f)"""@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-%0Dhoe rdfs:label "$\rho(e)$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%C2%B5 rdfs:label "µ**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%C2%B5s_1 rdfs:label "µ(s ′1)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%C2%B5s_1___%C2%B5s_2_ rdfs:label "µ(s ′1 ) = µ(s ′2 )"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%C2%B5s_2 rdfs:label "µ(s ′2)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CE%B2 rdfs:label "β"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3%CE%B30_%CE%B3__b rdfs:label "{γ|Γ0; γ ∈ B}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B30_ rdfs:label "Γ0; ∆"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B31 rdfs:label "Γ1"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CE%B3_6b_g_ rdfs:label "Γ** 6|=B g **"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3_6b_h rdfs:label "Γ** 6|=B h**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3_b_f rdfs:label "Γ |=B f"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CE%B3_i rdfs:label "Γ ′(i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3i__s rdfs:label "Γi = s"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CE%B3i_in_e_to_a%CE%B3i rdfs:label "Γ(i) in E to A(Γi**)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3ib_f rdfs:label "(Γ,i)|=B f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3ib_g rdfs:label "(Γ,i)|=B g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3ib_h rdfs:label "(Γ,i)|=B h"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3ihs2i rdfs:label "[Γ(**i);hs2i]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3ii rdfs:label "Γii"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%80-ctl_goals rdfs:label "π-CTL* goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%80s rdfs:label "π(s)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%81s_1 rdfs:label "ρ(s ′1)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%81s_2 rdfs:label "ρ(s ′2)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%84_s_1___%CF%84_s_2_ rdfs:label "τ (s ′1 ) = τ (s ′2 )"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-%CF%84_x rdfs:label "τ (X)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%84s rdfs:label "τ(s')"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-%CF%86_ rdfs:label "φ ′"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%86__fltl__ir rdfs:label "φ ⊆ $FLTL × IR"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%86_be_a_reward-normal_reward_function_specification rdfs:label "φ be a reward-normal reward function specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%86i rdfs:label "φi"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-%CF%88 rdfs:label "ψ'"@en,
        "⊖ψ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%880 rdfs:label "Ψ0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%88_ rdfs:label "ψ ′"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-- rdfs:label "♦-"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity--_f rdfs:label "¬♦- ¬f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity--free_formula rdfs:label "$-free formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-01 rdfs:label "0.1"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-08 rdfs:label "0.8"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-09 rdfs:label "0.9"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-100_of_the_runs rdfs:label "100% of the runs"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-10_probability rdfs:label "10% probability"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-11601167 rdfs:label "1160–1167"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-11_block_blocks_world_problem rdfs:label "11 block blocks world problem"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-12 rdfs:label "12"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1211-2_49107 rdfs:label "121(1-2), 49–107."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-122000 rdfs:label "1.22000"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-14 rdfs:label "14"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-15 rdfs:label "15"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-153 rdfs:label "153"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-15mn_to_run_whatever_computation_they_saw_as_appropriate rdfs:label "15mn to run whatever computation they saw as appropriate"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-17 rdfs:label "17"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-177 rdfs:label "177"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-19 rdfs:label "19"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-191 rdfs:label "191"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-191198 rdfs:label "191–198"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-193 rdfs:label "193"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-194 rdfs:label "1–94"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1987 rdfs:label "1987"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1989 rdfs:label "1989"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1992 rdfs:label "1992"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1gb_of_ram rdfs:label "1GB of ram"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-2002a rdfs:label "2002a"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2002b rdfs:label "2002b"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2003a rdfs:label "2003a"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2003b rdfs:label "2003b"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2005_paper rdfs:label "2005 paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-2087 rdfs:label "2087"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-20_passengers rdfs:label "20 passengers"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-24 rdfs:label "24"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2459 rdfs:label "2459"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-253302 rdfs:label "253–302"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-2f1 rdfs:label "⊖2f1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2n_states rdfs:label "2n states"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-3 rdfs:label "3"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-30_trial_runs_of_the_generated_policy_from_an_initial_state_to_a_goal_state rdfs:label "30 trial runs of the generated policy from an initial state to a goal state"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-30_trials rdfs:label "30 trials"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-331338 rdfs:label "331–338"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-3_times_that_of_the_nmrdp rdfs:label "3 times that of the NMRDP"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-400 rdfs:label "400"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-40_floors rdfs:label "40 floors"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-40_image_2png rdfs:label "40_image_2.png"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-4229 rdfs:label "4229"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-4475 rdfs:label "4475"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-479484 rdfs:label "479–484"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-4846 rdfs:label "4846"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-494 rdfs:label "494"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5 rdfs:label "5"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5-tuple rdfs:label "5-tuple"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-500mb_of_ram rdfs:label "500MB of ram"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-50_each_time_a_passenger_is_first_served rdfs:label "50 each time a passenger is first served"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-5183 rdfs:label "5183"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-567 rdfs:label "567"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-5_8_11_15_18_and_21_blocks rdfs:label "5, 8, 11, 15, 18, and 21 blocks"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-5th_action rdfs:label "5th action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-600 rdfs:label "600"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-603606 rdfs:label "603–606"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-632 rdfs:label "632"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-65 rdfs:label "65%"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-7 rdfs:label "7"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-75123 rdfs:label "75–123."@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-8 rdfs:label "8"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-851887 rdfs:label "851–887"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-8_blocks rdfs:label "8 blocks"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-9 rdfs:label "9"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-9971072 rdfs:label "997–1072"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-_%CE%B3i__1 rdfs:label "⊤ (Γ,i + 1)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-__ rdfs:label "⊤ → $"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-__h%CE%B31ii rdfs:label "∆ =** hΓ1ii"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-__n_i1_pi_n__r rdfs:label "(⊖ ∧ n i=1 pi: n ∗ r)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-__r rdfs:label "(⊥ : r)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-_in_fltl rdfs:label "$ in $FLTL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-_modality rdfs:label "⊖ modality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-_r rdfs:label "(⊙ r)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_ rdfs:label "A ′"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_class_of_behaviours rdfs:label "a class of behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_decision_diagram_containing_a_particular_proposition rdfs:label "a decision diagram containing a particular proposition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_family_of_methods rdfs:label "a family of methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-a_fixed_reachability_goal rdfs:label "a fixed reachability goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_long_sequence_of_events_or_when_the_desired_behaviour_is_composed_of_many_elements_with_identical_rewards rdfs:label "a long sequence of events or when the desired behaviour is composed of many elements with identical rewards"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-a_meaningful_extension rdfs:label "a meaningful extension"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_meaningful_extension_of_goalp rdfs:label "a meaningful extension of GOALP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_name rdfs:label "a name"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_number rdfs:label "a number"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_position rdfs:label "a position"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_prefix rdfs:label "a prefix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_priori rdfs:label "a priori"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-a_random_action_specification rdfs:label "a random action specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_range_of_statistics_about_the_space_and_time_behaviour rdfs:label "a range of statistics about the space and time behaviour"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-a_real_number rdfs:label "a real number"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-a_richer_class rdfs:label "a richer class"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_richer_class_of_decision_processes rdfs:label "a richer class of decision processes"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-a_set_of_basic_propositions_p rdfs:label "a set of basic propositions P"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_set_of_pairs_fi_ri rdfs:label "a set of pairs (fi: ri)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_single_reward_formula rdfs:label "a single reward formula"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-a_software_platform rdfs:label "a software platform"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-a_state_and_a_reward_function_specification rdfs:label "a state and a reward function specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_suboptimal_policy rdfs:label "a suboptimal policy"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-a_tree rdfs:label "a tree"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-a_unique_minimum rdfs:label "a unique minimum"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-a_very_general_probabilistic_planning_framework rdfs:label "A very general probabilistic planning framework"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-a_wider_range_of_domains rdfs:label "a wider range of domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-aaai rdfs:label "AAAI"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-absolute_minimality rdfs:label "absolute minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-absorbing rdfs:label "absorbing"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-abstract rdfs:label "abstract"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-achievement_of_a_goal_within_a_given_number_of_steps rdfs:label "achievement of a goal within a given number of steps"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-achievement_of_c rdfs:label "achievement of ¬c"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-achievements_of_p rdfs:label "achievements of ¬p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-achievements_of_the_goal_p rdfs:label "achievements of the goal p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-acm_transactions_on_database_systems rdfs:label "ACM Transactions on Database Systems"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-action_applicability_condition rdfs:label "action applicability condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-action_flip rdfs:label "action flip"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-action_specification rdfs:label "action specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-action_specification_trees rdfs:label "action specification trees"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-action_tilt rdfs:label "action tilt"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-actions_and_planning rdfs:label "actions and planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-actions_c_and_d rdfs:label "actions c and d"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-actions_in_d rdfs:label "actions in D"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-add rdfs:label "ADD"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-add-based_nmrdpp_version rdfs:label "ADD-based nmrdpp version"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-additional_actions_up_down rdfs:label "additional actions (up, down)"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-additional_bits_of_information_memorising_the_truth_of_f_over_the_last_k_steps rdfs:label "additional bits of information memorising the truth of f over the last k steps"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-additional_effect rdfs:label "additional effect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-additional_variables rdfs:label "additional variables"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-additional_work rdfs:label "Additional work"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-additive rdfs:label "additive"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-admissible_heuristic_values rdfs:label "admissible heuristic values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-afrom_s_0 rdfs:label "A′**from** s ′0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ahs%CF%86i rdfs:label "A′(hs,φi)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ai_solutions rdfs:label "AI Solutions"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-ai_tools rdfs:label "AI Tools"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-aips rdfs:label "AIPS"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-aips_workshop rdfs:label "AIPS Workshop"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-airport rdfs:label "airport"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-airport_city rdfs:label "airport city"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-airports_and_other_locations_within_a_city rdfs:label "airports and other locations within a city"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-algebraic_decision_diagrams rdfs:label "algebraic decision diagrams"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-all_ rdfs:label "all ∆"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-all_e-states_in_the_equivalent_mdp rdfs:label "all e-states in the equivalent MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_goal_states rdfs:label "all goal states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_leaf_nodes_having_random_values_from_a_uniform_distribution rdfs:label "all leaf nodes having random values from a uniform distribution"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-all_propositions_are_false rdfs:label "all propositions are false"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-all_sequences rdfs:label "all sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_stages_i_of_%CE%B3 rdfs:label "all stages i of Γ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_states_in_s rdfs:label "all states in S"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_subformulae rdfs:label "all subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_subformulae_of_this_reward_formula rdfs:label "all subformulae of this reward formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_such_choices rdfs:label "all such choices"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-alternative rdfs:label "alternative"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-american_national_conference_on_artificial_intelligence rdfs:label "American National Conference on Artificial Intelligence"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-an_arbitrary_goal_state rdfs:label "an arbitrary goal state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-an_example rdfs:label "an example"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-analyses rdfs:label "analyses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-analysis_of_irrelevance rdfs:label "analysis of irrelevance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-analysis_of_rewards rdfs:label "analysis of rewards"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-analyze rdfs:label "analyze"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ancestors rdfs:label "ancestors"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-anecdotal rdfs:label "anecdotal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-annals_of_mathematics_and_artificial_intelligence rdfs:label "Annals of Mathematics and Artificial Intelligence"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-anonymous_reviewers rdfs:label "anonymous reviewers"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-another_simple_nmrdp rdfs:label "Another Simple NMRDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-any rdfs:label "any"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-any_material_formula rdfs:label "any material formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-any_problem_it_detects rdfs:label "any problem it detects"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-any_sequence_of_states_feasible_under_the_generated_policies rdfs:label "any sequence of states feasible under the generated policies"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-any_two_airports rdfs:label "any two airports"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-any_two_locations_in_a_city rdfs:label "any two locations in a city"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anytime_algorithm rdfs:label "anytime algorithm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anytime_planning rdfs:label "anytime planning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-anytime_search_algorithm rdfs:label "anytime search algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-anytime_solution_method rdfs:label "anytime solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-anytime_state-based_algorithms rdfs:label "anytime state-based algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-anytime_state-based_methods rdfs:label "anytime state-based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-anyway rdfs:label "anyway"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-appendix_b rdfs:label "Appendix B"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-applicability_of_state-based_methods rdfs:label "applicability of state-based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-apply_a rdfs:label "apply a"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-apply_a_or_b rdfs:label "apply a or b"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-approach_to_search_control_in_the_presence_of_temporally_extended_goals rdfs:label "approach to search control in the presence of temporally extended goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approaches_making_use_of_control_knowledge rdfs:label "approaches making use of control knowledge"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-appropriate_supervision rdfs:label "appropriate supervision"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approximate_solution_methods rdfs:label "approximate solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-arbitrary rdfs:label "arbitrary"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-arcs rdfs:label "arcs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arithmetic rdfs:label "arithmetic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-article rdfs:label "Article"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-article_on_ai_research rdfs:label "Article on AI Research"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-article_on_neural_networks rdfs:label "Article on Neural Networks"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-artificial_domains rdfs:label "artificial domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-artificial_intelligence_42_189211 rdfs:label "Artificial Intelligence, 42**, 189–211."@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-artificial_problems rdfs:label "artificial problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-as_follows rdfs:label "as follows"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-as_prsas rdfs:label "A(s) Pr(**s,a,s**′)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-asmuth rdfs:label "Asmuth"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-assigning_rewards rdfs:label "assigning rewards"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-asymptotic_convergence_guarantees rdfs:label "asymptotic convergence guarantees"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-atfloorj rdfs:label "AtFloorj"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-atfloork rdfs:label "AtFloork"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-attainable rdfs:label "attainable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-attention rdfs:label "attention"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-aulletoldsymbolsoldsymbol%09ext%CF%86 rdfs:label "$A^{ullet}(oldsymbol{s},oldsymbol{	ext{φ}})$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-author_of_a_paper rdfs:label "author of a paper"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-auxiliary_relations rdfs:label "auxiliary relations"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-availability_of_good_heuristics rdfs:label "availability of good heuristics"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-average_run_time_of_the_methods rdfs:label "average run time of the methods"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-averages_of_the_running_times rdfs:label "averages of the running times"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-b%C3%BCchi_tree_automata rdfs:label "Büchi tree automata"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-b_f_%CE%B3i__b_b rdfs:label "B f Γ(i) ∈ B b"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b_h rdfs:label "B h"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b_progb_%CE%B3if rdfs:label "B Prog(b, Γi,f)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-b_until_q_gets_produced rdfs:label "b until q gets produced"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bacchus_boutilier__grove rdfs:label "Bacchus, Boutilier, & Grove"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-backtracking_forward_search rdfs:label "backtracking forward search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bahadori_s rdfs:label "Bahadori, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-baier_c rdfs:label "Baier, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-baier_et_al_2004 rdfs:label "Baier et al., 2004"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-baral__zhao_2004 rdfs:label "Baral & Zhao, 2004"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-baral_c rdfs:label "Baral, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bardtke rdfs:label "Bardtke"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bardtke_s rdfs:label "Bardtke, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-barto rdfs:label "Barto"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-barto_a rdfs:label "Barto, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-basic_propositions_p rdfs:label "basic propositions P"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bdd_representation rdfs:label "BDD representation"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-behaviors rdfs:label "behaviors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-behaviour_bf rdfs:label "behaviour Bf"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-behavioural_distinctions rdfs:label "behavioural distinctions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-behaviours_b rdfs:label "behaviours B"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-behaviours_of_interest rdfs:label "behaviours of interest"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-behaviours_to_be_rewarded rdfs:label "behaviours to be rewarded"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bert rdfs:label "BERT"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-better_policies rdfs:label "better policies"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-beverage rdfs:label "beverage"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-bg rdfs:label "Bg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-big_data rdfs:label "Big Data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-biological_research rdfs:label "biological research"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-blind-minimal rdfs:label "blind-minimal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blind-minimal_mdps rdfs:label "blind-minimal MDPs"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-blind-minimal_one rdfs:label "blind-minimal one"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-blind-minimality rdfs:label "blind-minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blind_minimal rdfs:label "blind minimal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-blindness rdfs:label "blindness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blocks rdfs:label "blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blocks_and_box_worlds rdfs:label "blocks and box worlds"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-blocks_world_and_logistic_domains rdfs:label "blocks world and logistic domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-blocks_world_domain rdfs:label "blocks world domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-bollig_b rdfs:label "Bollig, B."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-boolean_combinations_of_atoms rdfs:label "boolean combinations of atoms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-boolean_flag rdfs:label "boolean flag"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-boolean_flags rdfs:label "boolean flags"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-boolean_value_b rdfs:label "boolean value b"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-both_conditions rdfs:label "both conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-bounded_history_encoding rdfs:label "bounded history encoding"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bounded_variants rdfs:label "bounded variants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-boutilier rdfs:label "Boutilier"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-boutilier_dean__hanks rdfs:label "Boutilier, Dean, & Hanks"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-boutilier_dearden__goldszmidt rdfs:label "Boutilier, Dearden, & Goldszmidt"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-boutilier_et_al rdfs:label "Boutilier et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-boutilier_et_al_1999 rdfs:label "Boutilier et al., 1999"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-box_world rdfs:label "box world"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-box_world_generator rdfs:label "box world generator"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-box_world_problems rdfs:label "box world problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-box_world_search_space rdfs:label "box world search space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-branching_or_probabilistic_logics rdfs:label "branching or probabilistic logics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bushiness_of_the_internal_part_of_the_adds rdfs:label "bushiness of the internal part of the ADDs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bushiness_of_their_leaves rdfs:label "bushiness of their leaves"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-business_analytics rdfs:label "Business Analytics"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-bw-c-nr rdfs:label "bw-c-nr"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bw-c-r rdfs:label "bw-c-r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bw-nc-nr rdfs:label "bw-nc-nr"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-bwnc-r rdfs:label "bwnc-r"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-c0 rdfs:label "c0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-calvanese_d rdfs:label "Calvanese, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-calvanese_de_giacomo__vardi_2002 rdfs:label "Calvanese, De Giacomo, & Vardi, 2002"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-canadian_natural_sciences_and_engineering_research_council_nserc rdfs:label "Canadian Natural Sciences and Engineering Research Council (NSERC)"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-care rdfs:label "Care"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-carnegie_mellon_university rdfs:label "Carnegie Mellon University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-case_f__g_uh rdfs:label "Case f = g Uh**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-categories rdfs:label "categories"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-certain_circumstances rdfs:label "certain circumstances"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-cesta_a rdfs:label "Cesta, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-cesta_et_al rdfs:label "Cesta et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-chance rdfs:label "chance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-changing rdfs:label "Changing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-changing_the_syntax rdfs:label "Changing the Syntax"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-chomicki rdfs:label "Chomicki"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chomicki_j rdfs:label "Chomicki, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ciesinski_f rdfs:label "Ciesinski, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-city_of_destination rdfs:label "city of destination"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-city_of_origin rdfs:label "city of origin"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-claim rdfs:label "claim"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-claim_of_minimality rdfs:label "claim of minimality"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-class_of_behaviours rdfs:label "class of behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-class_of_mdp_solution_methods rdfs:label "class of MDP solution methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classical__and_ rdfs:label "classical ∧ and ∨"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classical_planning_version rdfs:label "classical planning version"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-classical_propositional_logic_formula rdfs:label "classical propositional logic formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classical_state-based_solution_methods rdfs:label "classical state-based solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-classification_problems rdfs:label "Classification Problems"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-clinical_trials rdfs:label "Clinical Trials"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-closure_of_ rdfs:label "closure of {$}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cluster rdfs:label "cluster"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-clusters rdfs:label "clusters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coffee rdfs:label "coffee"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cognitive_systems rdfs:label "Cognitive systems"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-coin_example rdfs:label "Coin Example"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-commonsense_precautions rdfs:label "commonsense precautions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-compact_form rdfs:label "compact form"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compact_representation_of_the_reward_function rdfs:label "compact representation of the reward function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-company_alpha rdfs:label "Company Alpha"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-comparing_behaviours rdfs:label "comparing behaviours"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-comparison rdfs:label "comparison"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-competition_organisers rdfs:label "competition organisers"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-competition_overview_paper rdfs:label "competition overview paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-competition_participants rdfs:label "Competition Participants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complementary rdfs:label "complementary"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complete rdfs:label "complete"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-complete_policies rdfs:label "complete policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complex_preconditions rdfs:label "complex preconditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-complex_to_encode rdfs:label "complex to encode"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-compromise rdfs:label "compromise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computational_intelligence rdfs:label "Computational Intelligence"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-computational_leverage rdfs:label "Computational leverage"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computational_model rdfs:label "computational model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-computations rdfs:label "computations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computing_the_labels_ls_for_each_state_s rdfs:label "computing the labels l(s) for each state s**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-concept_e rdfs:label "Concept E"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-concurrency rdfs:label "concurrency"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-condition_1 rdfs:label "Condition 1"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-condition_2 rdfs:label "Condition 2"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-condition_4 rdfs:label "Condition 4"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-condition_c rdfs:label "condition c"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-conditional rdfs:label "conditional"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-condp_ rdfs:label "cond[p, **$]"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-conference_and_workshop_papers rdfs:label "conference and workshop papers"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-conference_on_uncertainty_in_artificial_intelligence_uai rdfs:label "Conference on Uncertainty in Artificial Intelligence (UAI)"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-conjunction rdfs:label "conjunction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-connectives rdfs:label "connectives"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant_ rdfs:label "constant $"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant_factor rdfs:label "constant factor"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-constant_number_of_states rdfs:label "constant number of states"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-construction_and_comparison rdfs:label "construction and comparison"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-constructors rdfs:label "constructors"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-contexts_where_the_principle_of_directionality_must_be_enforced rdfs:label "contexts where the principle of directionality must be enforced"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-continuations_of_a_given_state_sequence rdfs:label "continuations of a given state sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-continuations_of_the_sequences rdfs:label "continuations of the sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-continuous-time_stochastic_domains rdfs:label "continuous-time stochastic domains"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-control-knowledge rdfs:label "control-knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-control-knowledge_mode rdfs:label "control-knowledge mode"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-control_knowledge_formula rdfs:label "control knowledge formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-control_knowledge_formulae rdfs:label "Control knowledge formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-controller_synthesis rdfs:label "Controller synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-controller_synthesis_for_probabilistic_systems rdfs:label "Controller synthesis for probabilistic systems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-converge rdfs:label "converge"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-convergence_of_real-time_dynamic_programming rdfs:label "convergence of real-time dynamic programming"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convergence_speed_up rdfs:label "convergence speed up"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-corpus rdfs:label "Corpus"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-correct_minimal_behaviour rdfs:label "correct minimal behaviour"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-cost_of_the_translation rdfs:label "cost of the translation"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-counterexamples rdfs:label "counterexamples"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-creating_a_random_action_specification rdfs:label "creating a random action specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-crispr-cas9 rdfs:label "CRISPR-Cas9"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-csl rdfs:label "CSL"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-ctl_or_pctl_variants rdfs:label "CTL or PCTL variants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cu_decision_diagram_package rdfs:label "CU Decision Diagram Package"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-current_policy rdfs:label "current policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_reward rdfs:label "current reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_reward_specification_label rdfs:label "current reward specification label"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_values_of_formulae rdfs:label "current values of formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-customers rdfs:label "customers"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-dal_lago_et_al rdfs:label "Dal Lago et al."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dal_lago_et_al_2002 rdfs:label "Dal Lago et al., 2002"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-dal_lago_u rdfs:label "Dal Lago, U."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-data_augmentation rdfs:label "Data Augmentation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-data_collection rdfs:label "Data Collection"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-data_point rdfs:label "data point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_points rdfs:label "Data Points"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-data_structures rdfs:label "data structures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_visualization rdfs:label "Data Visualization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-databases rdfs:label "databases"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-dataset_c rdfs:label "Dataset C"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-dataset_x rdfs:label "Dataset X"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-datasets rdfs:label "Datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-david_smith rdfs:label "David Smith"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-de_giacomo_g rdfs:label "De Giacomo, G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-deadline_goals rdfs:label "deadline goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dealing rdfs:label "dealing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dean rdfs:label "Dean"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dean__kanazawa_1989 rdfs:label "Dean & Kanazawa, 1989"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-dean_et_al rdfs:label "Dean et al."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dearden_r rdfs:label "Dearden, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-decision-theoretic_planning_problems rdfs:label "decision-theoretic planning problems"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-decision_diagram rdfs:label "decision diagram"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_problem_for_fltl rdfs:label "decision problem for FLTL"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-decision_procedure rdfs:label "decision procedure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_process_d rdfs:label "decision process D"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_process_with_non-markovian_rewards rdfs:label "decision process with non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_process_with_non-markovian_rewards_nmrdp rdfs:label "decision process with non-Markovian rewards (NMRDP)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_processes_with_non-markovian_rewards rdfs:label "decision processes with non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decisiontheoretic_planning rdfs:label "decisiontheoretic planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning_paper rdfs:label "Deep Learning Paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-definition1 rdfs:label "Definition1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-definition_1 rdfs:label "Definition 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-definition_5 rdfs:label "Definition 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-definitions rdfs:label "definitions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degree_of_structure_or_uncertainty rdfs:label "degree of structure or uncertainty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-delay_cond_loop_union rdfs:label "delay, cond, loop, union"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deliberate rdfs:label "deliberate"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-departement_dinformatique_universite_de_sherbrooke rdfs:label "D´epartement d'Informatique Universit´e de Sherbrooke"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-dependence_on_the_future rdfs:label "dependence on the future"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-des_0 rdfs:label "De′(s ′0)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-description_and_processing rdfs:label "description and processing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-desired_properties rdfs:label "desired properties"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-destination rdfs:label "destination"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-detecting_irrelevance_of_variables rdfs:label "detecting irrelevance of variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deterministic_blocks_world rdfs:label "deterministic blocks world"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deterministic_domains rdfs:label "deterministic domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-deterministic_planners rdfs:label "deterministic planners"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-deterministic_search_spaces rdfs:label "deterministic search spaces"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deterministic_version rdfs:label "deterministic version"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-development_and_experimentation_of_methods_for_decision-theoretic_planning_with_non-markovian_rewards rdfs:label "development and experimentation of methods for decision-theoretic planning with non-Markovian rewards"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-dfs_0 rdfs:label "Df′(s ′0)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-diagnostic_reports rdfs:label "Diagnostic Reports"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-differences rdfs:label "differences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_approaches rdfs:label "different approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_methods rdfs:label "different methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-different_phases rdfs:label "different phases"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-difficult rdfs:label "difficult"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-difficulty_of_the_problem rdfs:label "difficulty of the problem"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-direct-travel rdfs:label "direct-travel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-direct_travel rdfs:label "direct travel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-directpi rdfs:label "DirectPi"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-dis_blind_minimal rdfs:label "D′is blind minimal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-discounted_cumulative_reward rdfs:label "discounted cumulative reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-discounted_stochastic_shortest_path_problems rdfs:label "discounted stochastic shortest path problems"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-discounts_rewards rdfs:label "discounts rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-disembarking_at_the_wrong_floor rdfs:label "disembarking at the wrong floor"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-display_add_of_value_function rdfs:label "display ADD of value function"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-distinct_e-states_s1_and_s2 rdfs:label "distinct e-states s'1 and s'2"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-distinct_phases rdfs:label "distinct phases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distinction rdfs:label "distinction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distribution_of_rewards rdfs:label "distribution of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-do-maintain_p rdfs:label "do-maintain p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-do-reach_p rdfs:label "do-reach p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain-independent rdfs:label "domain-independent"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-domain-independent_mode rdfs:label "domain-independent mode"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain-independent_planners rdfs:label "domain-independent planners"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-domain-independent_subtrack rdfs:label "domain-independent subtrack"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain-independent_track rdfs:label "domain-independent track"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-domain-specific_heuristics rdfs:label "domain-specific heuristics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain_features rdfs:label "domain features"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-domain_o rdfs:label "Domain O"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-domainstatesize rdfs:label "domainStateSize"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-dot rdfs:label "DOT"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-drummond rdfs:label "Drummond"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-drummond_m rdfs:label "Drummond, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-dual_pentium4_34ghz rdfs:label "Dual Pentium4 3.4GHz"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-dynamic_analyses_of_rewards rdfs:label "dynamic analyses of rewards"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-dynamic_analysis rdfs:label "dynamic analysis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-dynamic_analysis_of_the_reward_formulae rdfs:label "dynamic analysis of the reward formulae"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-dynamic_aspects rdfs:label "dynamic aspects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_bayesian_networks rdfs:label "dynamic Bayesian networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-dynamic_irrelevance rdfs:label "dynamic irrelevance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_irrelevance_of_the_goal rdfs:label "dynamic irrelevance of the goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_propositions rdfs:label "dynamic propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamics_of_temporal_variables rdfs:label "dynamics of temporal variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamics_of_the_domain rdfs:label "dynamics of the domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-e-state_hs%CF%86i rdfs:label "e-state hs',φ'i"@en,
        "e-state hs,φi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e-states_hs%CF%86i rdfs:label "e-states hs,φi"@en,
        "e-states hs,φ′i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_patients_request_answered_within_the_appropriate_time-frame rdfs:label "each patient's request answered within the appropriate time-frame"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-each_proposition rdfs:label "each proposition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_scheme rdfs:label "each scheme"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eagle_goals rdfs:label "Eagle goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eagle_language rdfs:label "Eagle language"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effective rdfs:label "effective"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-effectiveness_of_many_solution_methods rdfs:label "effectiveness of many solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-effects_of_actions_a_and_b rdfs:label "effects of actions a and b"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-efficiency rdfs:label "efficiency"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-efficient_sparse_matrix_operations rdfs:label "efficient sparse matrix operations"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-elderly_or_disabled_people rdfs:label "elderly or disabled people"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-elevator_control rdfs:label "Elevator control"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-elevator_movement_planning rdfs:label "elevator movement planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-elsevier rdfs:label "Elsevier"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-embedding_formula_simplification rdfs:label "embedding formula simplification"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-emerson rdfs:label "Emerson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-emerson_e rdfs:label "Emerson, E."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-encoded_history_features rdfs:label "encoded history features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-entire_state_space rdfs:label "entire state space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-envelope rdfs:label "envelope"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equipment rdfs:label "Equipment"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-equivalence rdfs:label "equivalence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equivalence_check rdfs:label "equivalence check"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equivalence_class_%CE%B3i rdfs:label "equivalence class [Γ(i)]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equivalence_class_of_%CE%B3i rdfs:label "equivalence class of Γ(i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equivalence_class_of_finite_sequences_of_states_of_d rdfs:label "equivalence class of finite sequences of states of D**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equivalence_f1_s_f2__f2__f1__f1_s_f2 rdfs:label "equivalence f1 S f2 ≡ f2 ∨ (f1 ∧ ⊖(f1 S f2**))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-et_al rdfs:label "et al."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-european_conference_on_artificial_intelligence_ecai rdfs:label "European Conference on Artificial Intelligence (ECAI)"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-evaluation rdfs:label "evaluation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-evaluation_software rdfs:label "evaluation software"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-event_calculus rdfs:label "Event Calculus"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-events rdfs:label "events"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-every_behaviour_satisfying_f rdfs:label "every behaviour satisfying f"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-every_e-state_in_s_is_reachable rdfs:label "every e-state in S' is reachable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-every_time_p_is_true rdfs:label "every time p is true"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-exactly_one_action rdfs:label "exactly one action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-example rdfs:label "example"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-exception_mechanism rdfs:label "exception mechanism"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-excessive_memory_requirements rdfs:label "excessive memory requirements"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-execution_sequence rdfs:label "execution sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-executive_summary rdfs:label "executive summary"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expand rdfs:label "expand"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-expanded_state_e-state rdfs:label "expanded state (e-state)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expanded_state_hs%CF%86i rdfs:label "expanded state hs,φi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expansion_phase rdfs:label "expansion phase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expectation rdfs:label "expectation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expected_future_rewards rdfs:label "expected future rewards"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-expensive_preprocessing rdfs:label "expensive preprocessing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-experiment_c rdfs:label "Experiment C"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-experiment_h rdfs:label "Experiment H"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-experimental_investigation rdfs:label "experimental investigation"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-experimental_results rdfs:label "experimental results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-expl-bw rdfs:label "expl-bw"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-explicitly_enumerate_all_states_reachable_from_s0_in_the_entire_mdp rdfs:label "explicitly enumerate all states reachable from s0 in the entire MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expression_in_pltl rdfs:label "expression in PLTL"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-expression_of_attempted_reachability_and_maintenance_goals rdfs:label "expression of attempted reachability and maintenance goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expressive rdfs:label "expressive"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-extended_goals rdfs:label "extended goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-extra_state_at_the_bottom_left_of_the_figure rdfs:label "extra state at the bottom left of the Figure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f10 rdfs:label "f10"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f1f2f3 rdfs:label "{f1,f2,f3}"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f2__f1__f1_s_f2 rdfs:label "f2 ∨ (f1 ∧ ⊖(f1 S f2))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f4 rdfs:label "f4"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f5 rdfs:label "f5"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f6 rdfs:label "f6"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f7 rdfs:label "f7"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f8 rdfs:label "f8"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f9 rdfs:label "f9"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-f_ rdfs:label "f ′"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_-_f__r rdfs:label "(f ∧¬⊖♦- f : r)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-f__g__h rdfs:label "f = g ∨ h"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f__l__f__f__f__f__f__f_u_f rdfs:label "F ::= L | F ∧ F | F ∨ F | F | F U F"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_cannot_be_satisfied rdfs:label "f cannot be satisfied"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-f_is_true_of_a_finite_sequence_%CE%B3i rdfs:label "f is true of a finite sequence Γ(i)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-f_never_progresses_to_ rdfs:label "f never progresses to ⊥"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-f_u rdfs:label "f U⊥"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f_u_m rdfs:label "f U m"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fabiani_p rdfs:label "Fabiani, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-fact rdfs:label "fact"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-fact_2 rdfs:label "Fact 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fact_3 rdfs:label "Fact 3"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-factor rdfs:label "factor"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-factor_exponential_in_the_length_of_the_formula rdfs:label "factor exponential in the length of the formula"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-factored_markov_decision_processes rdfs:label "factored Markov decision processes"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-factored_representations rdfs:label "factored representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-factors rdfs:label "factors"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-facts_14 rdfs:label "facts 1–4"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-fahiem_bacchus rdfs:label "Fahiem Bacchus"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-failing_to_prevent_the_patient_from_taking_the_pill_more_than_once_within_this_time_frame rdfs:label "failing to prevent the patient from taking the pill more than once within this time frame"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-fails rdfs:label "fails"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-failure rdfs:label "failure"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-false_1_step_ago rdfs:label "false 1 step ago"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-family_of_probability_distributions rdfs:label "family of probability distributions"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-feasible rdfs:label "feasible"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feasible_continuations rdfs:label "feasible continuations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feasible_futures rdfs:label "feasible futures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feasible_state_sequence rdfs:label "feasible state sequence"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-features rdfs:label "features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feng__hansen rdfs:label "Feng & Hansen"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-feng_et_al_2003 rdfs:label "Feng et al., 2003"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-feng_hansen__zilberstein_2003 rdfs:label "Feng, Hansen, & Zilberstein, 2003"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-fern_a rdfs:label "Fern, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-fewer_states rdfs:label "fewer states"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-ff_first_50 rdfs:label "ff [first, 5.0]"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-ff_planning_system rdfs:label "FF planning system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-fi1 rdfs:label "fi+1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_14 rdfs:label "Figure 14"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_8 rdfs:label "Figure 8"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-file rdfs:label "file"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-final_experiment rdfs:label "final experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-finding_e rdfs:label "Finding E"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-finite_prefixes rdfs:label "finite prefixes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_sequence rdfs:label "finite sequence"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-finite_sequences_of_states rdfs:label "finite sequences of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_sequences_of_states_over_s rdfs:label "finite sequences of states over S"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-finite_set_of_actions rdfs:label "finite set of actions"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-finite_set_of_fully_observable_states rdfs:label "finite set of fully observable states"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-finite_state_sequence_%CE%B3i rdfs:label "finite state sequence Γ(i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_state_sequences rdfs:label "finite state sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_time_convergence_guarantees rdfs:label "finite time convergence guarantees"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-first-class_reward_propositions rdfs:label "first-class reward propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first-order_heuristic_search_in_the_fluent_calculus rdfs:label "first-order heuristic search in the fluent calculus"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first-order_mdps rdfs:label "First-Order MDPs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_achievement_of_a_goal rdfs:label "first achievement of a goal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-first_n_steps rdfs:label "first n steps"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-first_occurrence_of_f rdfs:label "first occurrence of f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_occurrence_of_p rdfs:label "first occurrence of p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_step rdfs:label "first step"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_time_p_is_true rdfs:label "first time p is true"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-first_two rdfs:label "first two"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fixed_reward rdfs:label "fixed reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-fltl__ir rdfs:label "FLTL × IR"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl_formula_progression rdfs:label "FLTL formula progression"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-fltl_mdp rdfs:label "fltl MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-fltl_search_control_knowledge rdfs:label "FLTL search control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl_space rdfs:label "$FLTL space"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-fltl_version_of_nmrdp_example rdfs:label "FLTL version of NMRDP example"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formula_c0 rdfs:label "formula c0**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formula_fi rdfs:label "formula fi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formula_kf rdfs:label "formula ⊖kf"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formula_p__q rdfs:label "formula (p → q**)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-formula_pup rdfs:label "formula ¬pU(p∧$)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formula_pup__ rdfs:label "formula ¬pU(p ∧ $)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formulae_in_%CF%86i rdfs:label "formulae in φi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formulae_in_the_two_sets rdfs:label "formulae in the two sets"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formulae_of_fltl rdfs:label "formulae of $FLTL"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-formulae_of_the_form___servedpi rdfs:label "formulae of the form ⊖ ⊟ ¬ServedPi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formulae_of_type_2_and_3 rdfs:label "Formulae of type (2) and (3)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-four_facts rdfs:label "four facts"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-four_hand-coded_domains rdfs:label "four hand-coded domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-fourman_m rdfs:label "Fourman, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-frequency rdfs:label "frequency"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-fringe rdfs:label "fringe"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ftpvlsicoloradoedupub rdfs:label "ftp://vlsi.colorado.edu/pub/"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-fully_connected_reflexive_domain rdfs:label "fully connected reflexive domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-fully_markovian_decision_process rdfs:label "fully Markovian decision process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-function_%CF%84 rdfs:label "function τ"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-functions_a rdfs:label "functions A"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-functions_r rdfs:label "functions R"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-functions_t rdfs:label "functions T"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future rdfs:label "future"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_behaviours rdfs:label "future behaviours"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-future_linear_temporal_logic rdfs:label "future linear temporal logic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_linear_temporal_logic_fltl rdfs:label "future linear temporal logic (FLTL)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-future_of_the_sequence rdfs:label "future of the sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_starting_with_s rdfs:label "future starting with s'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_work rdfs:label "Future work"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-g1_fail_g2 rdfs:label "g1 fail g2"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-g__ rdfs:label "g' ∨ ⊥"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-g__kc rdfs:label "g ∧ ⊖kc"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g_c rdfs:label "G, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-g_uh rdfs:label "g Uh"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gap rdfs:label "gap"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gene_m rdfs:label "Gene M"@en ;
    askg-onto:entityType "Gene"@en .

askg-data:Entity-general_observations rdfs:label "general observations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generalised_semi-markov_processes rdfs:label "generalised semi-Markov processes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generated_dynamics rdfs:label "generated dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generated_mdp rdfs:label "generated MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-generated_policy rdfs:label "generated policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generation_phase rdfs:label "generation phase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-genetic_analysis rdfs:label "genetic analysis"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-genetic_engineering rdfs:label "genetic engineering"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-genetic_research rdfs:label "genetic research"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-genetics rdfs:label "genetics"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-genome_sequencing rdfs:label "Genome sequencing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-getpolicy rdfs:label "getPolicy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-github rdfs:label "GitHub"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-giuliani_m rdfs:label "Giuliani, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-givan_r rdfs:label "Givan, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-given_behaviour rdfs:label "given behaviour"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-glory rdfs:label "glory"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gn1_near-optimal_strategy rdfs:label "GN1 near-optimal strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-gnulinux_2420 rdfs:label "GNU/Linux 2.4.20"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-gnulinux_2611 rdfs:label "GNU/Linux 2.6.11"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-goal-achievement_percentage rdfs:label "goal-achievement percentage"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-goal-based rdfs:label "goal-based"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal-based_version rdfs:label "goal-based version"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal-state_selected rdfs:label "goal-state selected"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal_achievement rdfs:label "goal achievement"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-goal_p rdfs:label "goal p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal_specification rdfs:label "Goal specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goalbf rdfs:label "GOALB(f)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goalp rdfs:label "GOALP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goalp_modality rdfs:label "GOALP modality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goalpf rdfs:label "GOALP(f)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goals_cannot_simultaneously_be_satisfied rdfs:label "goals cannot simultaneously be satisfied"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-goldszmidt_m rdfs:label "Goldszmidt, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-good_heuristics rdfs:label "Good heuristics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-google rdfs:label "Google"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-gr%C3%B6%C3%9Fer_m rdfs:label "Größer, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-graph rdfs:label "graph"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-graph_neural_networks rdfs:label "Graph Neural Networks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-graphical_display rdfs:label "graphical display"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-graphs rdfs:label "graphs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-greater_expressive_power rdfs:label "greater expressive power"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-greedy_policy rdfs:label "greedy policy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-gretton_price__thiebaux rdfs:label "Gretton, Price, & Thi´ebaux"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-grisetti_g rdfs:label "Grisetti, G."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-grove rdfs:label "Grove"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-h%CF%860%CF%861_i rdfs:label "hφ0,φ1 ...i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h__g__g_uh rdfs:label "h ∨ (g ∧ (g Uh**)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-haddawy__hanks rdfs:label "Haddawy & Hanks"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-haddawy_p rdfs:label "Haddawy, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hand-coded_domain rdfs:label "hand-coded domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-hand-coded_domains rdfs:label "hand-coded domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-handbook_of_theoretical_computer_science rdfs:label "Handbook of Theoretical Computer Science"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-hanoise rdfs:label "hanoise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-heads_or_tails rdfs:label "heads or tails"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-health_care_robot rdfs:label "health care robot"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-health_informatics rdfs:label "Health Informatics"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-healthcare_system rdfs:label "Healthcare System"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-healthcare_technology rdfs:label "Healthcare Technology"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-hertzberg rdfs:label "Hertzberg"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hertzberg_j rdfs:label "Hertzberg, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-heuristic_functions rdfs:label "heuristic functions"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-heuristic_search_methods rdfs:label "heuristic search methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-heuristic_value rdfs:label "heuristic value"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hg__f rdfs:label "h∨(g ∧ f**)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hg_f_ rdfs:label "h∨(g ∧f ′)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-high_negative_score rdfs:label "high negative score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-histories rdfs:label "histories"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-history_distinctions rdfs:label "history distinctions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hoey_et_al_1999 rdfs:label "Hoey et al., 1999"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-hoey_j_st-aubin_r_hu_a__boutilier_c rdfs:label "Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hoey_st-aubin_hu__boutilier rdfs:label "Hoey, St-Aubin, Hu, & Boutilier"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hoffmann_2002 rdfs:label "Hoffmann (2002)"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hope rdfs:label "hope"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hospitals rdfs:label "Hospitals"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-how_far_into_the_future_they_occur rdfs:label "how far into the future they occur"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-howard_r rdfs:label "Howard, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hs0%CF%860i rdfs:label "hs0,φ0i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hs_s0_a_pr_ri rdfs:label "hS, s0, A, Pr, Ri"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hss0aprri rdfs:label "hS,s0,A,Pr,Ri"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-httprsiseanueduaucharlesgnmrdpp rdfs:label "http://rsise.anu.edu.au/~charlesg/nmrdpp"@en ;
    askg-onto:entityType "Database"@en .

askg-data:Entity-human-encoded_policies rdfs:label "human-encoded policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-i-th_stage rdfs:label "i-th stage"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-i1 rdfs:label "i+1"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-ibm_watson rdfs:label "IBM Watson"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-identical_future_rewards rdfs:label "identical future rewards"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-idle rdfs:label "idle"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-if_f rdfs:label "if f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ifip_international_conference rdfs:label "IFIP International Conference"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-igtriangleup rdfs:label "$igtriangleup$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-igtriangleup_0%09ext%CE%B3_i rdfs:label "$igtriangleup_{0}=	ext{Γ}_{i}$"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-image_analysis rdfs:label "Image Analysis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-immediate_reward rdfs:label "immediate reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-immediate_reward_for_being_in_state_s rdfs:label "immediate reward for being in state s"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-impact_factor rdfs:label "impact factor"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-implementation rdfs:label "implementation"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-implementation_of_their_approaches rdfs:label "implementation of their approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-implementations_of_classical_dynamic_programming_methods rdfs:label "implementations of classical dynamic programming methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-improvement rdfs:label "improvement"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-inability_to_deal_with_rewards_specified_as_long_sequences_of_events rdfs:label "inability to deal with rewards specified as long sequences of events"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-inappropriateness rdfs:label "(in)appropriateness"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-incomplete_policies rdfs:label "incomplete policies"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-incremental_algorithm rdfs:label "incremental algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-incremental_construction rdfs:label "incremental construction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-indifferently_forever rdfs:label "indifferently forever"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-induction_case_2 rdfs:label "Induction case 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-induction_case_3 rdfs:label "Induction case 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-infinite_horizon rdfs:label "infinite horizon"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-infinite_sequence_of_formulae rdfs:label "infinite sequence of formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-influence rdfs:label "influence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-influence_of_factors rdfs:label "influence of factors"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-initial_state_in_mdp rdfs:label "initial state in MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_states rdfs:label "Initial states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input rdfs:label "input"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_language rdfs:label "input language"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-institution rdfs:label "Institution"@en ;
    askg-onto:entityType "Institution"@en .

askg-data:Entity-intended_one rdfs:label "intended one"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-interaction rdfs:label "interaction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-internal_nodes rdfs:label "internal nodes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-international_conference_on_ai_planning_and_scheduling rdfs:label "International Conference on AI Planning and Scheduling"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-international_conference_on_automated_planning_and_scheduling rdfs:label "International Conference on Automated Planning and Scheduling"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-international_conference_on_the_principles_of_knowledge_representation_and_reasoning rdfs:label "International Conference on the Principles of Knowledge Representation and Reasoning"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-international_joint_conference_on_artificial_intelligence_ijcai rdfs:label "International Joint Conference on Artificial Intelligence (IJCAI)"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-international_journal_of_intelligent_systems rdfs:label "International Journal of Intelligent Systems"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-international_planning_competition rdfs:label "International Planning Competition"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-interpreter_of_hand_written_classy_policies rdfs:label "interpreter of hand written classy policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-intersection_concatenation_union rdfs:label "intersection, concatenation, union"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-interviews rdfs:label "Interviews"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-intuition rdfs:label "intuition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-invited_paper rdfs:label "Invited paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-ipc-3 rdfs:label "IPC-3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevance rdfs:label "irrelevance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevance_of_the_goal rdfs:label "irrelevance of the goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevance_of_the_trigger rdfs:label "irrelevance of the trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevant_extensions rdfs:label "irrelevant extensions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevant_information rdfs:label "irrelevant information"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-it_rains rdfs:label "it rains"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-it_through_the_successive_states_of_a_sequence_%CE%B3 rdfs:label "it through the successive states of a sequence Γ"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-item_5 rdfs:label "Item 5"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-item_6 rdfs:label "item 6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-its_length rdfs:label "its length"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-j_1_of_ rdfs:label "j −1 of ∆"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-journal rdfs:label "Journal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-journal_of_ai rdfs:label "Journal of AI"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-journal_of_genetic_engineering__biotechnology rdfs:label "Journal of Genetic Engineering & Biotechnology"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-k_iterations_of_the__modality rdfs:label "k iterations of the ⊖ modality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-k_steps_from_a_state_satisfying_p rdfs:label "k steps from a state satisfying p"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-kabanza_and_thiebaux rdfs:label "Kabanza and Thi´ebaux"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kaelbling rdfs:label "Kaelbling"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kaelbling_l rdfs:label "Kaelbling, L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kaggle rdfs:label "Kaggle"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-kanazawa_k rdfs:label "Kanazawa, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-karabaev_e rdfs:label "Karabaev, E."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-keep_things_normal rdfs:label "keep things normal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kf_for__k_i1_i_f rdfs:label "kf for ∧ k i=1 ⊖i f"@en,
        "kf for ∨ k i=1 ⊖i f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kg rdfs:label "kg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kids rdfs:label "kids"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kirman rdfs:label "Kirman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kirman_j rdfs:label "Kirman, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kk_times_ago rdfs:label "k(k times ago)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-knowledge rdfs:label "Knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-knowledge_graph rdfs:label "knowledge graph"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-knowledge_representation_and_reasoning rdfs:label "Knowledge Representation and Reasoning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-knowledge_representation_and_reasoning_kr rdfs:label "Knowledge Representation and Reasoning (KR)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-known_ones rdfs:label "known ones"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-koehler__schuster_2000 rdfs:label "Koehler & Schuster, 2000"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-koehler_j rdfs:label "Koehler, J."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-korf_r rdfs:label "Korf, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-kushmerick_hanks__weld_1995 rdfs:label "Kushmerick, Hanks, & Weld, 1995"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-kushmerick_n_hanks_s__weld_d rdfs:label "Kushmerick, N., Hanks, S., & Weld, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-labeled_rtdp rdfs:label "Labeled RTDP"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-labels rdfs:label "labels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lack_of_structure rdfs:label "Lack of structure"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-language_for_extended_goals rdfs:label "language for extended goals"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-lao_algorithm rdfs:label "LAO∗ algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-laoh rdfs:label "LAO(h)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-large_mdp rdfs:label "large MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-larger_problems rdfs:label "larger problems"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-larger_state_spaces rdfs:label "larger state spaces"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-last_result rdfs:label "last result"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-last_state rdfs:label "last state"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-last_state_%CE%B3i rdfs:label "last state Γi"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-latter rdfs:label "latter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-leaf_nodes_having_values_0_or_1_with_an_equal_probability rdfs:label "leaf nodes having values 0 or 1 with an equal probability"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-learning rdfs:label "Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_domain-specific_knowledge rdfs:label "Learning domain-specific knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning_real-time_a rdfs:label "learning real-time A∗"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-learns_classy_policies_from_random_walks rdfs:label "learns classy policies from random walks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-leaves rdfs:label "leaves"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-left-hand_side_of_the_tables rdfs:label "left-hand side of the tables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-length rdfs:label "length"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-lenore_zuck rdfs:label "Lenore Zuck"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-leone_g rdfs:label "Leone, G."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-less rdfs:label "less"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-leucker_m rdfs:label "Leucker, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-li_l rdfs:label "Li, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-libraries rdfs:label "libraries"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lichtenstein rdfs:label "Lichtenstein"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lichtenstein_o rdfs:label "Lichtenstein, O."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-line_of_work rdfs:label "line of work"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-linear-time_formalisms rdfs:label "linear-time formalisms"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-linear_in_n rdfs:label "linear in n"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-linear_time_in_the_length_of_f rdfs:label "linear time in the length of f"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-literal rdfs:label "literal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-littman rdfs:label "Littman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-littman_m rdfs:label "Littman, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-liveness rdfs:label "liveness"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-lncs rdfs:label "LNCS"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-lncs_398 rdfs:label "LNCS 398"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-lncs_volume_193 rdfs:label "LNCS, volume 193"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-local_search_topology rdfs:label "Local search topology"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-logic rdfs:label "logic"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-logic_journal_of_the_igpl rdfs:label "Logic Journal of the IGPL"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-logically_equivalent_to_ rdfs:label "logically equivalent to $"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-logics_of_programs rdfs:label "Logics of Programs"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-logistics_problems rdfs:label "logistics problems"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-logistics_problems_from_ipc-2 rdfs:label "Logistics problems from IPC-2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loochi_l rdfs:label "Loochi, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-loop rdfs:label "loop"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-loop_condp_delaycondq_ rdfs:label "loop[⊥, cond[p, delay[cond[q, $]]]]"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-loopmf rdfs:label "loop[m,f]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loops rdfs:label "loops"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-low_probability_of_reaching_the_goal rdfs:label "low probability of reaching the goal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-low_probability_of_reaching_the_triggering_condition rdfs:label "low probability of reaching the triggering condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-ls rdfs:label "l(s)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ls0 rdfs:label "l(s0)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ls_ rdfs:label "l(s ′)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ltl rdfs:label "LTL"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-machine_learning_framework rdfs:label "Machine Learning Framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-machine_learning_model rdfs:label "Machine Learning Model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-machine_learning_techniques rdfs:label "Machine Learning Techniques"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-main_features rdfs:label "main features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maintenance_of_some_property rdfs:label "maintenance of some property"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-making_sure_a_given_patient_takes_his_pill_exactly_once_every_8_hours rdfs:label "making sure a given patient takes his pill exactly once every 8 hours"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-manipulating_adds rdfs:label "manipulating ADDs"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-map_of_the_truck_and_plane_connections rdfs:label "map of the truck and plane connections"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mapping_%CF%84 rdfs:label "mapping τ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-marco_pistore rdfs:label "Marco Pistore"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-markov_decision_processes_mdps rdfs:label "Markov decision processes (MDPs)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-markov_processes rdfs:label "Markov Processes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-markovian_dynamics rdfs:label "Markovian dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-markovian_reward rdfs:label "Markovian reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-markovian_setting rdfs:label "Markovian setting"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-material_formula rdfs:label "material formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-material_trigger rdfs:label "material trigger"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-mathematical_expression rdfs:label "Mathematical expression"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-mathematical_symbol rdfs:label "Mathematical symbol"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-matrix_operations rdfs:label "matrix operations"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-maximal_pruning rdfs:label "maximal pruning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mdp_d__hs_s0aprri rdfs:label "MDP D′ = hS ′,s′0,A′,Pr′,R′i"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-mdp_dc rdfs:label "MDP Dc**"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-mdp_formulation rdfs:label "MDP formulation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mdp_representations rdfs:label "MDP representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-meaning rdfs:label "meaning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-meaningful_notion_of_minimality rdfs:label "meaningful notion of minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-measuring_the_size_of_the_generated_mdp rdfs:label "measuring the size of the generated MDP"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mechanism rdfs:label "mechanism"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-medical_images rdfs:label "Medical Images"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-medical_research rdfs:label "Medical Research"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-memory_earlier rdfs:label "memory earlier"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-mendelian_genetics rdfs:label "Mendelian genetics"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-method_i rdfs:label "Method I"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-method_performance rdfs:label "Method Performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-method_x rdfs:label "Method X"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-method_y rdfs:label "Method Y"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-methods_based_on_pltl rdfs:label "methods based on PLTL"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-metric_j rdfs:label "Metric J"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mgpt_lrtdp_with_automatically_extracted_heuristics rdfs:label "mgpt: lrtdp with automatically extracted heuristics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-miconic_deterministic_planning_benchmark rdfs:label "Miconic deterministic planning benchmark"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-miconic_elevator_classical_planning_benchmark rdfs:label "Miconic elevator classical planning benchmark"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-miconic_problem rdfs:label "Miconic problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-middle_way rdfs:label "middle way"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-minimal_mdp_achievable_without_expensive_pre-processing rdfs:label "minimal MDP achievable without expensive pre-processing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-minimal_mdps rdfs:label "minimal MDPs"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-minimal_size rdfs:label "minimal size"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-minimal_size_achievable rdfs:label "minimal size achievable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-minimisation rdfs:label "minimisation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-minimum_allocation_of_rewards rdfs:label "minimum allocation of rewards"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mistakes rdfs:label "mistakes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mmx rdfs:label "MMX"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-modal_logic rdfs:label "Modal Logic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model-checking_approach rdfs:label "model-checking approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-model-checking_technique rdfs:label "model-checking technique"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-model-theoretic_approaches rdfs:label "Model-Theoretic Approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model_a rdfs:label "Model A"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-modeller rdfs:label "modeller"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-models_of_temporal_logic rdfs:label "models of temporal logic"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-modern_processor_features rdfs:label "modern processor features"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-more_generous_distribution rdfs:label "more generous distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-more_substantial_probabilistic_reasoning rdfs:label "more substantial probabilistic reasoning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-moshe_vardi rdfs:label "Moshe Vardi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-most_appropriate_method rdfs:label "most appropriate method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-most_efficient_mdp_solution_methods rdfs:label "most efficient MDP solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mpltl rdfs:label "mPltl"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-mri rdfs:label "MRI"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-much_less_powerful_machine rdfs:label "much less powerful machine"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-multiset rdfs:label "multiset"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n rdfs:label "n"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-n__ rdfs:label "⊖n¬ ⊖ ⊥"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n_n_i1pi rdfs:label "⊖n(∧ n i=1pi)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-n_propositions rdfs:label "n propositions"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-n_th_state rdfs:label "n th state"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-nardi_d rdfs:label "Nardi, D."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-natural_number rdfs:label "natural number"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-natural_specification_of_non-markovian_rewards rdfs:label "natural specification of non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-naturalness rdfs:label "naturalness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nature rdfs:label "Nature"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-nebel_b rdfs:label "Nebel, B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-negated_dollar rdfs:label "negated dollar"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-negation rdfs:label "negation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-negation_normal_form_nnf rdfs:label "negation normal form (NNF)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-new rdfs:label "New"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-new_approach rdfs:label "new approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-next rdfs:label "next"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-next_state rdfs:label "next state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-next_week rdfs:label "next week"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-nf rdfs:label "⊖nf**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nicholson rdfs:label "Nicholson"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-nicholson_a rdfs:label "Nicholson, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-nicta rdfs:label "NICTA"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-nmrdp_approaches rdfs:label "NMRDP approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdp_d rdfs:label "NMRDP D"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-nmrdp_example rdfs:label "NMRDP example"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdp_state rdfs:label "NMRDP state"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-nmrdpp_with_control_knowledge rdfs:label "nmrdpp with control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdpp_without_control_knowledge rdfs:label "nmrdpp without control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nnf rdfs:label "NNF"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-no_assumptions rdfs:label "no assumptions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-no_effect rdfs:label "no effect"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-no_funny_business rdfs:label "no funny business"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-no_reward rdfs:label "no reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-no_state_satisfying_q rdfs:label "no state satisfying q"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-no_two_distinct_e-states_s_1_and_s_2 rdfs:label "no two distinct e-states s ′1 and s ′2"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-no_two_distinct_estates_s_1_and_s_2 rdfs:label "no two distinct estates s ′1 and s ′2"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-non-colored_blocks_world_problems rdfs:label "non-colored blocks world problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-completely_connected rdfs:label "non-completely connected"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-non-deterministic_planning rdfs:label "non-deterministic planning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-non-deterministic_search_control_policy rdfs:label "non-deterministic search control policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-markovian_constraints rdfs:label "non-Markovian constraints"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-non-markovian_decision_processes rdfs:label "non-Markovian decision processes"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-non-markovian_reward rdfs:label "non-Markovian reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-markovian_reward_decision_process_planner rdfs:label "Non-Markovian Reward Decision Process Planner"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-non-markovian_reward_specification_language rdfs:label "non-Markovian reward specification language"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-non-minimality rdfs:label "non-minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-regular_behaviours rdfs:label "non-regular behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-stationary_policy rdfs:label "non-stationary policy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-non-stop rdfs:label "non-stop"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-zero_probabilities rdfs:label "Non-zero probabilities"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-non_star-free_behaviours rdfs:label "non star-free behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nondeterministic_actions rdfs:label "nondeterministic actions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-none rdfs:label "none"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nonstopp rdfs:label "NonStopP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-not_complete rdfs:label "not complete"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-not_represented_in_the_table rdfs:label "not represented in the table"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-not_reward-normal rdfs:label "not reward-normal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-notation rdfs:label "notation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_n_of_floors_and_passengers rdfs:label "number n of floors and passengers"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-number_n_of_propositions rdfs:label "number n of propositions"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-number_n_of_propositions_in_the_domain rdfs:label "number n of propositions in the domain"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-number_of_actions_to_be_produced rdfs:label "number of actions to be produced"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-number_of_iterations rdfs:label "number of iterations"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-number_of_reachable_and_unreachable_rewards rdfs:label "number of reachable and unreachable rewards"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-numbers rdfs:label "Numbers"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-numerical_value rdfs:label "Numerical Value"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-oddi_a rdfs:label "Oddi, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-off-line_expansion rdfs:label "off-line expansion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-okay rdfs:label "okay"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-on-line_off-line rdfs:label "on-line, off-line"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-on-line_planning rdfs:label "on-line planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-onder_n rdfs:label "Onder, N."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-one_direction rdfs:label "one direction"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-one_of_the_methods rdfs:label "one of the methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-one_of_the_pltl_approaches rdfs:label "one of the PLTL approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-one_or_more_formulae rdfs:label "one or more formulae"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-ones rdfs:label "ones"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-operating_system rdfs:label "Operating System"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-operations rdfs:label "operations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-operator_always rdfs:label "operator (always)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-operatornamelim_ntoinftymathsfeleftsum_i0nbetairgamma_imidpigamma_0s_0right rdfs:label "\\operatorname*{lim}_{n\\to\\infty}\\;\\mathsf{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma_{i})\\mid\\pi,\\Gamma_{0}=s_{0}\\right]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-operators__and_s rdfs:label "operators ⊖ and S"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_policies rdfs:label "optimal policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_sequences_of_actions rdfs:label "optimal sequences of actions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimality_consideration rdfs:label "optimality consideration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimised rdfs:label "optimised"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-optional rdfs:label "optional"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-order_of_events rdfs:label "order of events"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-organization_y rdfs:label "Organization Y"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-organized_structure rdfs:label "organized structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-origin_and_destination_floors rdfs:label "origin and destination floors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-origin_floor rdfs:label "origin floor"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-original_reward_function_specification rdfs:label "original reward function specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-other_states rdfs:label "other states"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-otherwise rdfs:label "otherwise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-our_formulation rdfs:label "our formulation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-our_own rdfs:label "our own"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-overall_best_method rdfs:label "overall best method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-overall_worst_method rdfs:label "Overall worst method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p___p rdfs:label "{⊖p, ⊖ ⊖ p}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p__q__ rdfs:label "((p ∧ q) → $)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-p__up rdfs:label "(p → $)Up"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p_gets_produced rdfs:label "p gets produced"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-p_holds rdfs:label "p holds"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-p_holds_and_q_does_not rdfs:label "p holds and q does not"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-p_is_going_to_hold_next rdfs:label "p **is going to hold** next"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-p_nq_n rdfs:label "p nq n"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p_s_q rdfs:label "p S q"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p_s_q_r rdfs:label "(p S (q∨⊙ r))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-packages rdfs:label "packages"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-page_range rdfs:label "Page Range"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-pair_hs%CF%86i rdfs:label "pair hs,φi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paper_1 rdfs:label "Paper 1"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-paper_g rdfs:label "Paper G"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-paper_y rdfs:label "Paper Y"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-parameter rdfs:label "Parameter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parameters rdfs:label "parameters"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-part rdfs:label "Part"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-part_of_the_control_knowledge rdfs:label "part of the control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-participants_in_a_competition rdfs:label "Participants in a competition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-participating_planners rdfs:label "participating planners"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-particular_policies rdfs:label "particular policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-particular_prefix rdfs:label "particular prefix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-passenger_pi rdfs:label "Passenger Pi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-passengers_served_or_boarded rdfs:label "passengers served or boarded"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-passengers_with_disabilities_or_young_children rdfs:label "passengers with disabilities or young children"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-past-oriented_account_of_rewards rdfs:label "past-oriented account of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-past_behaviours rdfs:label "past behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-past_conditions rdfs:label "past conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-past_linear_temporal_logic_pltl rdfs:label "past linear temporal logic (PLTL)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-path rdfs:label "path"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-path_quantifiers rdfs:label "path quantifiers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paths rdfs:label "paths"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paths_feasible_under_any_of_the_domain_actions rdfs:label "paths feasible under any of the domain actions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paths_feasible_under_the_generated_policy rdfs:label "paths feasible under the generated policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patients_with_condition_y rdfs:label "Patients with Condition Y"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-patterns rdfs:label "patterns"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pctl rdfs:label "PCTL"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-pddl_description_of_hard_miconic rdfs:label "PDDL description of hard miconic"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-pddl_parser rdfs:label "PDDL parser"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-pdi rdfs:label "pdi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pdi_heads rdfs:label "pdi heads"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pecora_f rdfs:label "Pecora, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-pentium4_26ghz rdfs:label "Pentium4 2.6GHz"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-perform_well rdfs:label "perform well"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-performance_in_solution_quality rdfs:label "performance in solution quality"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-performance_results rdfs:label "Performance results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-period rdfs:label "Period"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-periodic_achievement_of_some_goal rdfs:label "periodic achievement of some goal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-person_x rdfs:label "Person X"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pfr%CF%86r____bf rdfs:label "P(f:r)∈φ{r | ∆ ∈ Bf}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-phi rdfs:label "phi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pistore__traverso rdfs:label "Pistore & Traverso"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pistore__traverso_2001 rdfs:label "Pistore & Traverso, 2001"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-pj rdfs:label "pj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-planner_versions rdfs:label "planner versions"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-planners_e_g2_j1_and_j2 rdfs:label "Planners E, G2, J1, and J2"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-planning_and_controller_synthesis rdfs:label "planning and controller synthesis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-planning_benchmarks rdfs:label "planning benchmarks"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-planning_domains_with_probabilistic_effects rdfs:label "planning domains with probabilistic effects"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-planning_operators rdfs:label "planning operators"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-planning_problem rdfs:label "planning problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-planning_under_uncertainty_for_autonomous_systems rdfs:label "Planning under Uncertainty for Autonomous Systems"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-platform rdfs:label "platform"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-platform_for_the_development_and_experimentation_of_approaches_to_nmrdps rdfs:label "platform for the development and experimentation of approaches to NMRDPs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_and_fltl_version_of_the_reward_formulae rdfs:label "PLTL and $FLTL version of the reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_based_algorithms rdfs:label "PLTL based algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-pltl_expansion_phase rdfs:label "PLTL expansion phase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_formula rdfs:label "PLTL formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_formula_regression rdfs:label "PLTL formula regression"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pltl_formulation rdfs:label "PLTL formulation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_methods rdfs:label "PLTL methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pltl_over_a_finite_past rdfs:label "PLTL over a finite past"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pltl_representation_of_rewards rdfs:label "PLTL representation of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltlmin_mdp rdfs:label "pltlmin MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-pltlmin_preprocessing rdfs:label "pltlmin preprocessing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pltlsim_translation rdfs:label "pltlsim translation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pltlstra_and_pltlsim rdfs:label "pltlstr(a) and pltlsim"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-pnueli__zuck_1985 rdfs:label "(Pnueli, & Zuck, 1985)"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-pnueli_a rdfs:label "Pnueli, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-point rdfs:label "point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policy_%CF%80 rdfs:label "policy π"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policy_generation rdfs:label "Policy generation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policytodot rdfs:label "policyToDot"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-possible_futures rdfs:label "possible futures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-possible_predecessor_states rdfs:label "possible predecessor states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-possibly_incomplete_but_often_useful rdfs:label "possibly incomplete but often useful"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-possibly_infinite_state_sequence rdfs:label "possibly infinite state sequence"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-possibly_infinite_state_sequences rdfs:label "possibly infinite state sequences"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-post-hoc_minimisation_of_the_mdp rdfs:label "post-hoc minimisation of the MDP"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-postcript_rendering_of_mdp rdfs:label "postcript rendering of MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-posteriori_p rdfs:label "posteriori p"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-postprocessed_for_minimisation rdfs:label "postprocessed for minimisation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pp_447454 rdfs:label "pp. 447–454"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-pp_455460 rdfs:label "pp. 455–460"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-pp_reward_an_even_number_of_states_all_containing_p rdfs:label "(pp)∗ (reward an even number of states all containing p)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-ppddl10 rdfs:label "PPDDL1.0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pr%CE%B3i_a_s rdfs:label "Pr(Γi, a, s)"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-practical_abilities_of_the_methods rdfs:label "practical abilities of the methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-practical_translation rdfs:label "practical translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prefix rdfs:label "prefix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prefix_%CE%B3i__1 rdfs:label "prefix Γ(i − 1)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-prefix_h%CE%B30 rdfs:label "prefix hΓ0,..."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-preprocessing_expansion_and_solving rdfs:label "preprocessing, expansion, and solving"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-presence_of_rewards_unreachable_or_irrelevant_to_the_optimal_policy rdfs:label "presence of rewards unreachable or irrelevant to the optimal policy"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-previous_values rdfs:label "previous values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-principle_that_present_rewards_do_not_depend_on_future_states rdfs:label "principle that present rewards do not depend on future states"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-priority_service_constraints rdfs:label "priority service constraints"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-priority_services rdfs:label "priority services"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probabilistic_effects rdfs:label "probabilistic effects"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-probabilistic_extensions_of_traditional_planning_languages rdfs:label "probabilistic extensions of traditional planning languages"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-probabilistic_planning rdfs:label "probabilistic planning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-probabilistic_planning_operators rdfs:label "probabilistic planning operators"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-probabilistic_systems rdfs:label "probabilistic systems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probabilistic_temporal_logics rdfs:label "probabilistic temporal logics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probabilistic_track rdfs:label "probabilistic track"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probabilistic_variants_of_blocks_world_and_logistics_problems rdfs:label "probabilistic variants of blocks world and logistics problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probability_distribution rdfs:label "probability distribution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probability_of_a_non_zeroone_value_as_a_leaf_node rdfs:label "probability of a non zero/one value as a leaf node"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-probaprop_conformant_probabilistic_planner rdfs:label "ProbaProp: conformant probabilistic planner"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-problem_features rdfs:label "problem features"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-problems_at_hand rdfs:label "problems at hand"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-problems_from_the_unknown_domains rdfs:label "Problems from the unknown domains"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proceedings rdfs:label "Proceedings"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-progb_%CE%B3ig rdfs:label "Prog(b, Γi,g)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-progb_%CE%B3ig__progb_%CE%B3ih rdfs:label "Prog(b, Γi,g) ∧ Prog(b, Γi,h)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-progb_%CE%B3ih rdfs:label "Prog(b, Γi,h)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-progbs_ rdfs:label "Prog(b,s, ⊤)"@en,
        "Prog(b,s, ⊥)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progbsf rdfs:label "Prog(b,s,f**)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-progbsf1_f2 rdfs:label "Prog(b,s,f1 f2)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progbsf1_uf2 rdfs:label "Prog(b,s,f1 Uf2)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progbsp rdfs:label "Prog(b,s,p)"@en,
        "Prog(b,s,¬p)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progfalses_ rdfs:label "Prog(false,s, $)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-programs rdfs:label "programs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-progressing_the_reward-normal_reward_function_specification rdfs:label "progressing the reward-normal reward function specification"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progression_algorithms rdfs:label "progression algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-progression_correctly_computes_non-markovian_reward_functions rdfs:label "progression correctly computes non-Markovian reward functions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-progression_method rdfs:label "progression method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progression_of_predecessor_reward_specifications rdfs:label "progression of predecessor reward specifications"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progression_technique rdfs:label "progression technique"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-progtrues_ rdfs:label "Prog(true,s, $)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-project rdfs:label "Project"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-properties_of_state_sequences rdfs:label "properties of state sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-property_1 rdfs:label "Property 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-property_3 rdfs:label "property (3)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-proportion_reachable rdfs:label "proportion reachable"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-proportion_reachable_parameter rdfs:label "Proportion Reachable parameter"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-proposals rdfs:label "proposals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposition_1 rdfs:label "Proposition 1"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-proposition_p rdfs:label "proposition p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-propositional_logic rdfs:label "propositional logic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-propositional_planning rdfs:label "Propositional planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-propositions_pq_and_temporal_variables_t1t2t3 rdfs:label "propositions p,q and temporal variables t1,t2,t3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-propplan_planner rdfs:label "PropPlan planner"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-prs1as2__0 rdfs:label "Pr(s1,a,s2) > 0"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-prsas rdfs:label "Pr(s,a,s′**)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-prv2_heads rdfs:label "prv^2 heads"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prv_heads rdfs:label "prv heads"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prvin rdfs:label "prvIn"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prvout rdfs:label "prvOut"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-psychology rdfs:label "Psychology"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-ptsub rdfs:label "PTSub"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-publications rdfs:label "publications"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-pup rdfs:label "(¬pU(p∧$))"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-purely_markovian_rewards rdfs:label "purely Markovian rewards"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-q__p rdfs:label "q ∧ ⊖⊖p"@en,
        "¬(q ∧ ⊖⊖p)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-q_up__q__q__ rdfs:label "¬q U((¬p ∧ ¬q) ∨ (q ∧ $))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-qualitative_research rdfs:label "Qualitative Research"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-quality rdfs:label "quality"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-quality_of_the_policy rdfs:label "quality of the policy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-quantifiers rdfs:label "quantifiers"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quantitative_time rdfs:label "quantitative time"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quantum_computing rdfs:label "Quantum Computing"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-r%09ext%CE%B3i-1igtriangleup rdfs:label "$R(	ext{Γ}(i-1);igtriangleup)$"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-r%09extprime rdfs:label "$R^{	ext{prime}}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r%CE%B31i_ rdfs:label "R(Γ1(i); ∆)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r%CE%B31i__1 rdfs:label "R(Γ1(i − 1))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r%CE%B32j_ rdfs:label "R(Γ2(j); ∆)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r%CE%B32j__1 rdfs:label "R(Γ2(j − 1))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r%CE%B3i__r%CE%B3i_for_all_i rdfs:label "R([Γ(i)]) = R(Γ(i)) for all i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r%CF%860 rdfs:label "Rφ0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r-tire rdfs:label "r-tire"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r_%0Aphi%0Agammai%0A rdfs:label """R_{
\\phi}(
\\Gamma(i)
)"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r_%CF%86%CE%B3i rdfs:label "R_{φ}(Γ(i))"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-r_units rdfs:label "r units"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-radiologists rdfs:label "Radiologists"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rajeev_gor%C3%A9 rdfs:label "Rajeev Goré"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-random_action rdfs:label "random action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_decision_diagram rdfs:label "random decision diagram"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_domains rdfs:label "random domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-random_domains_of_size_n rdfs:label "Random domains of size n"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-random_generation_of_the_domain_dynamics rdfs:label "random generation of the domain dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_problem rdfs:label "random problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_problem_domains rdfs:label "Random problem domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-random_proposition rdfs:label "random proposition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_reward_specification rdfs:label "random reward specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_walks rdfs:label "random walks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-rasconi_r rdfs:label "Rasconi, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-rate_k rdfs:label "Rate K"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-reachability rdfs:label "reachability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachability_analysis rdfs:label "reachability analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachability_of_the_conditions_tracked rdfs:label "reachability of the conditions tracked"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachable rdfs:label "reachable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachable_e-state_space rdfs:label "reachable e-state space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachable_states rdfs:label "reachable states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachable_states_in_the_nmrdp rdfs:label "reachable states in the NMRDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reached rdfs:label "reached"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reactive_planning rdfs:label "reactive planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-real rdfs:label "real"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-real-time_dynamic_programming rdfs:label "real-time dynamic programming"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-real-time_dynamic_programming_rtdp rdfs:label "Real-time dynamic programming (RTDP)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-real-time_heuristic_search rdfs:label "Real-time heuristic search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-real-valued_rewards rdfs:label "real-valued rewards"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-real_value_r rdfs:label "real value r"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reasoning rdfs:label "reasoning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reasoning_model rdfs:label "reasoning model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recent_work rdfs:label "recent work"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-recovery_goals rdfs:label "recovery goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recursively rdfs:label "recursively"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-reference_implementation rdfs:label "reference implementation"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-reg rdfs:label "Reg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regf1__f2s__regf1s__regf2s rdfs:label "Reg(f1 ∧ f2,s) = Reg(f1,s) ∧ Reg(f2,s)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-regf1_s_f2s__regf2s__regf1s__f1_s_f2 rdfs:label "Reg(f1 S f2,s) = Reg(f2,s) ∨ (Reg(f1,s) ∧ (f1 S f2))"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-regfs__f rdfs:label "Reg(⊖f,s) = f"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-regfs__regfs rdfs:label "Reg(¬f,s) = ¬Reg(f,s)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-regps___iff_p__s_and__otherwise rdfs:label "Reg(p,s) = ⊤ iff p ∈ s and ⊥ otherwise"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-regression_algorithms rdfs:label "regression algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-regression_and_progression_of_temporal_formulae rdfs:label "regression and progression of temporal formulae"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-reinforcement_learning rdfs:label "Reinforcement Learning"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-related_and_future_work rdfs:label "related and future work"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-related_research rdfs:label "related research"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-related_work rdfs:label "related work"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-relationship rdfs:label "relationship"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relative_performance rdfs:label "relative performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-relative_performance_of_the_methods rdfs:label "relative performance of the methods"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-relative_success rdfs:label "relative success"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-relevance_of_rewards rdfs:label "relevance of rewards"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-remaining_time rdfs:label "remaining time"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-rep rdfs:label "rep."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-repeat_g rdfs:label "repeat g"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-repeatedly_visiting_all_rooms_in_the_ward_in_a_given_order rdfs:label "repeatedly visiting all rooms in the ward in a given order"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-report_solving_time rdfs:label "report solving time"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-representation rdfs:label "representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-requirement_about_the_last_state_%CE%B3i_of_a_sequence_%CE%B3i rdfs:label "requirement about the last state Γi of a sequence Γ(i**)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-research_concept_x rdfs:label "Research Concept X"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_field_a rdfs:label "Research Field A"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_field_b rdfs:label "Research Field B"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_group_a rdfs:label "Research Group A"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-research_in_ai rdfs:label "Research in AI"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-research_method_x rdfs:label "Research Method X"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-research_methodology rdfs:label "Research Methodology"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_on_ai_in_healthcare rdfs:label "Research on AI in healthcare"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_on_x rdfs:label "Research on X"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_outputs rdfs:label "research outputs"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-researcher rdfs:label "Researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-researcher_g rdfs:label "Researcher G"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-researchers rdfs:label "researchers"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-researchgate rdfs:label "ResearchGate"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-resolution_of_the_tradeoff rdfs:label "resolution of the tradeoff"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-restricted_dynamic_analysis_of_the_reward_formulae rdfs:label "restricted dynamic analysis of the reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-restriction rdfs:label "restriction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-restrictions rdfs:label "restrictions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-result_ rdfs:label "result ⊥"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-result_unavailable rdfs:label "result unavailable"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-resulting_policy_and_value_functions rdfs:label "resulting policy and value functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rew%CE%B30f0 rdfs:label "Rew(Γ0,f0)"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-rew%CE%B3_if rdfs:label "Rew(Γ_{i},f)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-reward-abnormal_formulae rdfs:label "reward-abnormal formulae"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward-based rdfs:label "reward-based"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward-determinacy rdfs:label "reward-determinacy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward-normal_ones rdfs:label "reward-normal ones"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward-stability rdfs:label "reward-stability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward-stable rdfs:label "reward-stable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_and_value_functions rdfs:label "reward and value functions"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-reward_condition rdfs:label "reward condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward_formula_progresses_to_ rdfs:label "reward formula progresses to ⊥**"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward_function_specification_%CF%86 rdfs:label "reward function specification φ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_function_specification_language rdfs:label "reward function specification language"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_function_specifications rdfs:label "reward function specifications"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_functions rdfs:label "reward functions"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_history rdfs:label "reward history"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-reward_models rdfs:label "reward models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-reward_n rdfs:label "reward ⊖n¬⊖⊤"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward_normal rdfs:label "reward normal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward_now rdfs:label "reward now"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_of_125 rdfs:label "reward of 12.5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_of_52 rdfs:label "reward of 5.2"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_of_73 rdfs:label "reward of 7.3"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_r rdfs:label "reward r"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_r%CE%B3i rdfs:label "reward R(Γ(i))"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_scheme rdfs:label "reward scheme"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward_schemes rdfs:label "reward schemes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_specification_functions rdfs:label "reward specification functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_specifications_containing_multiple_reward_elements rdfs:label "reward specifications containing multiple reward elements"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_specified_using_formulae rdfs:label "reward specified using formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_structure rdfs:label "Reward structure"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-reward_types_inducing_a_small_mdp rdfs:label "reward types inducing a small MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_values rdfs:label "reward values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_version rdfs:label "reward version"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewardbased_problems rdfs:label "rewardbased problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewarded rdfs:label "rewarded"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-rewarded_k_steps_later rdfs:label "rewarded k steps later"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-rewarded_now rdfs:label "rewarded now"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewardindeterminate rdfs:label "rewardindeterminate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewarding_behaviors rdfs:label "Rewarding behaviors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewarding_behaviours rdfs:label "rewarding behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewarding_the_behaviours_described_in_%CF%86 rdfs:label "rewarding the behaviours described in φ"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-rewardnormal rdfs:label "rewardnormal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-rewards_achievements_of_p rdfs:label "rewards achievements of ¬p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewards_all_achievements_of_the_goal_p rdfs:label "rewards all achievements of the goal p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewards_and_dynamics rdfs:label "rewards and dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ri rdfs:label "ri"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ris_for_which_that_sequence_is_a_model_of_fi rdfs:label "ri's for which that sequence is a model of fi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-robot rdfs:label "robot"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-ron_van_der_meyden rdfs:label "Ron van der Meyden"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-root_of_this_decision_diagram rdfs:label "root of this decision diagram"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rprog rdfs:label "RProg"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rs rdfs:label "R(s)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rtdp rdfs:label "RTDP"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-rtdp_envelope rdfs:label "RTDP envelope"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-run-time rdfs:label "Run-time"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-run-times rdfs:label "run-times"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-run_time_gains rdfs:label "run time gains"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-runs_in_which_the_goal_was_reached rdfs:label "runs in which the goal was reached"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-runs_out_of_memory rdfs:label "runs out of memory"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-runtime rdfs:label "runtime"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-s%CF%89 rdfs:label "Sω"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s1as2 rdfs:label "(s'1,a',s'2)"@en,
        "(s1,a',s2)"@en,
        "(s1,a,s2)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_1_and_s_2 rdfs:label "s ′1 and s ′2"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-s_2 rdfs:label "s ′2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_3 rdfs:label "s ′3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_7_s rdfs:label "S ′7→ S"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s__0 rdfs:label "s ′ 0"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-s__2_fltl_ir_2 rdfs:label "S × 2 $**FLTL** ×IR 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_to_a rdfs:label "S ∗to A"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_to_s_via_a rdfs:label "s to s' via a"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-saggase_a rdfs:label "Saggase, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-same rdfs:label "same"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-same_strategy rdfs:label "same strategy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sample_paths rdfs:label "sample paths"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sampling-based_policy_evaluation_process rdfs:label "sampling-based policy evaluation process"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-schneider rdfs:label "Schneider"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-schneider_m rdfs:label "Schneider, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-schuster_k rdfs:label "Schuster, K."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-scientist rdfs:label "Scientist"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-scientist_l rdfs:label "Scientist L"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-scopelliti_m rdfs:label "Scopelliti, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-search_algorithm rdfs:label "search algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-search_control rdfs:label "Search control"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-search_control-knowledge rdfs:label "search control-knowledge"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-search_problems rdfs:label "search problems"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-search_space rdfs:label "search space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-searching rdfs:label "searching"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-second_experiment rdfs:label "second experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-section_3 rdfs:label "Section 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_32 rdfs:label "Section 3.2"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-section_33 rdfs:label "Section 3.3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_36 rdfs:label "Section 3.6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_4 rdfs:label "Section 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_8 rdfs:label "Section 8"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-sections_5_and_6 rdfs:label "Sections 5 and 6"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-semantic_equivalence rdfs:label "semantic equivalence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-semantics rdfs:label "semantics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-semantics_of_non-markovian_rewards rdfs:label "semantics of non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-semi-positive_ltl rdfs:label "Semi-positive LTL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sensible rdfs:label "sensible"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-seq rdfs:label "seq"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-sequence_%CE%B3i rdfs:label "sequence Γ(i**)"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-sequence_h%CF%860%CF%861i rdfs:label "sequence hφ0,φ1,...i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_hs0i rdfs:label "sequence hs0i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_in_s_ rdfs:label "sequence in S ∗"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_leading_to_e-state rdfs:label "sequence leading to e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_of_states rdfs:label "sequence of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_prefixes_%CE%B3i__des0 rdfs:label "sequence prefixes Γ(i) ∈ De(s0)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequences rdfs:label "sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-service rdfs:label "service"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set6_%CF%86 rdfs:label "set6 φ"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-set_%CF%880 rdfs:label "set Ψ0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_%CF%88__subf_of_subformulae_of_the_reward_formulae_in_f rdfs:label "set Ψ ⊆ Sub(F**) of subformulae of the reward formulae in F"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_ls_of_subformulae rdfs:label "set l(s) of subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_actions rdfs:label "set of actions"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-set_of_all_subformulae_in_subf rdfs:label "set of all subformulae in Sub(F)"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-set_of_behaviours rdfs:label "set of behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_finite_sequences_ending_in_a_state_where_g_is_true_for_the_first_time_in_the_sequence rdfs:label "set of finite sequences ending in a state where g is true for the first time in the sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_finite_state_sequences_having_at_least_one_state_in_which_p_holds rdfs:label "set of finite state sequences having at least one state in which p holds"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-set_of_negations rdfs:label "set of negations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_reward-normal_formulae rdfs:label "set of reward-normal formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_reward_formulae rdfs:label "set of reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_reward_formulae_fi rdfs:label "set of reward formulae fi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_state_sequences rdfs:label "set of state sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_pi_to_true rdfs:label "set pi to true"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-set_t_of_temporal_variables rdfs:label "set T of temporal variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sets_labelling_the_respective_e-states rdfs:label "sets labelling the respective e-states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sets_of_actions_a_and_a rdfs:label "sets of actions A and A'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shoaff rdfs:label "Shoaff"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-shoaff_w rdfs:label "Shoaff, W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-show-domainrb rdfs:label "show-domain.rb"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-significance_in_research rdfs:label "significance in research"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-similar_approach_to_pltlstr rdfs:label "similar approach to pltlstr"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-simmons rdfs:label "Simmons"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-simmons_r rdfs:label "Simmons, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-simple_admissible_heuristic rdfs:label "simple admissible heuristic"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-simple_heuristic rdfs:label "Simple Heuristic"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-since_q_last_did rdfs:label "since q last did"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-singh rdfs:label "Singh"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-singh_s rdfs:label "Singh, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-situated_control_rules rdfs:label "Situated control rules"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-size rdfs:label "size"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-size_and_effectiveness rdfs:label "size and effectiveness"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-size_increase rdfs:label "size increase"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-size_of_the_generated_mdp rdfs:label "size of the generated MDP"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-size_of_the_mdp rdfs:label "size of the MDP"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-size_of_the_minimal_equivalent_mdp rdfs:label "size of the minimal equivalent MDP"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-size_of_the_minimal_equivalent_mdp_increase rdfs:label "size of the minimal equivalent MDP increase"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-skvortsova_o rdfs:label "Skvortsova, O."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-slaney rdfs:label "Slaney"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-slaney__thiebaux_2001 rdfs:label "Slaney & Thi´ebaux, 2001"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-small_enough rdfs:label "small enough"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-small_equivalent_mdp rdfs:label "small equivalent MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-small_values_of_n rdfs:label "small values of n"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-social_networking_site rdfs:label "social networking site"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-social_sciences rdfs:label "Social Sciences"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-software_development rdfs:label "Software Development"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-software_tool_b rdfs:label "Software Tool B"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-solution_algorithms rdfs:label "solution algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-solving_first-order_mdps rdfs:label "Solving First-Order MDPs"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-some rdfs:label "some"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-some_arbitrary_floor rdfs:label "some arbitrary floor"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-some_effects_to_each_action rdfs:label "some effects to each action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-some_point rdfs:label "some point"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-somenzi_f rdfs:label "Somenzi, F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-sophisticated_near-optimal_strategies rdfs:label "sophisticated near-optimal strategies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sophisticated_translation rdfs:label "sophisticated translation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-space rdfs:label "space"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-spaces rdfs:label "spaces"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-special_requirements rdfs:label "special requirements"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-specification_of_actions_initial_states_rewards_and_search_control-knowledge rdfs:label "specification of actions, initial states, rewards, and search control-knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-specification_of_reusable_search_control_knowledge rdfs:label "specification of reusable search control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-specified_number_of_timesteps rdfs:label "specified number of timesteps"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-spltl rdfs:label "sPltl"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-spudd-expon_states rdfs:label "spudd-expon states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spudd_algorithm rdfs:label "SPUDD algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-spudd_system rdfs:label "SPUDD system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-ss0aprr rdfs:label "(S,s0,A,Pr,R)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sse rdfs:label "SSE"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-starred rdfs:label "starred"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-start_e-state rdfs:label "start e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-start_state rdfs:label "start state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-start_state_of_m rdfs:label "start state of M"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-stat rdfs:label "Stat"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-state-based_algorithms rdfs:label "state-based algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_anytime_heuristic_search rdfs:label "state-based anytime heuristic search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_anytime_solution_methods rdfs:label "state-based anytime solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_flat_representations rdfs:label "state-based (flat) representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_heuristic_search_methods rdfs:label "state-based heuristic search methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_mdp_representations rdfs:label "state-based MDP representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_processing_variants rdfs:label "state-based processing variants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_solution_method rdfs:label "state-based solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_value_and_policy_iteration rdfs:label "state-based value and policy iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_value_or_policy_iteration rdfs:label "state-based value or policy iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state_itself rdfs:label "state itself"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-state_of_d rdfs:label "state of D"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-state_of_index_i_in_%CE%B3 rdfs:label "state of index i in Γ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_of_m rdfs:label "state of M"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-state_of_the_art_optimal_classical_planners rdfs:label "state of the art optimal classical planners"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-state_satisfying_p rdfs:label "state satisfying p"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-state_sequence rdfs:label "state sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_sequence_%CE%B3 rdfs:label "state sequence Γ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_sequence_%CE%B3i rdfs:label "state sequence Γ(i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_sequences rdfs:label "state sequences"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-state_variables rdfs:label "state variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-statebased_pltl_approaches rdfs:label "statebased PLTL approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-states_in_the_sequence rdfs:label "states in the sequence"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-static rdfs:label "static"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-static_analysis rdfs:label "static analysis"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-static_propositions rdfs:label "static propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-step_1 rdfs:label "Step 1"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-steps rdfs:label "steps"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-still_holds rdfs:label "still holds"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-stochastic_actions rdfs:label "stochastic actions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stochastic_domains rdfs:label "stochastic domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-stochastic_dynamic_programming rdfs:label "Stochastic dynamic programming"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-stochastic_model rdfs:label "stochastic model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-stochastic_planning_using_decision_diagrams rdfs:label "stochastic planning using decision diagrams"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-stochastic_variants rdfs:label "stochastic variants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stove rdfs:label "stove"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-strengths_and_weaknesses rdfs:label "strengths and weaknesses"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-strictly_positive_reward rdfs:label "strictly positive reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-structural_assumptions rdfs:label "Structural assumptions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structure_in_the_transition_model rdfs:label "structure in the transition model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-structure_parameter rdfs:label "Structure parameter"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-structured_algorithms rdfs:label "structured algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structured_approaches rdfs:label "structured approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structured_decision-theoretic_exploration_problems rdfs:label "structured decision-theoretic exploration problems"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-structured_form_of_preprocessing rdfs:label "structured form of preprocessing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structured_mdp rdfs:label "structured MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-structured_mdp_representations rdfs:label "structured MDP representations"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-structured_policy_iteration rdfs:label "structured policy iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structured_reachability_analysis_and_structured_pi rdfs:label "structured reachability analysis and structured PI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structured_representation rdfs:label "structured representation"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-structured_representations rdfs:label "structured representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-studies rdfs:label "Studies"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-study_b rdfs:label "Study B"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-study_y rdfs:label "Study Y"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-subformula_set_%CF%88 rdfs:label "subformula set Ψ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subformulae_%CF%88__subf__%CF%88__reg%CF%88s rdfs:label "subformulae {ψ' ∈ Sub(F) | Ψ |= Reg(ψ',s')"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subformulae_in_%CF%88 rdfs:label "subformulae in Ψ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subformulae_in_subf rdfs:label "subformulae in Sub(F)"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-suboptimal_policies rdfs:label "suboptimal policies"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-success_probabilities_and_rewards rdfs:label "success probabilities and rewards"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-successor_e-states rdfs:label "successor e-states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-successor_s rdfs:label "successor s"@en,
        "successor s'"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-successor_state rdfs:label "successor state"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-sufficient_information rdfs:label "sufficient information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sufficient_to_determine_the_current_truth_of_all_reward_formulae_in_f rdfs:label "sufficient to determine the current truth of all reward formulae in F"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-sum_frinphirmidgammaiin_b_f rdfs:label "\\sum_{(f:r)\\in\\phi}\\{r\\mid\\Gamma(i)\\in B_{f}\\}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-supervised rdfs:label "supervised"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-supervisedpi rdfs:label "SupervisedPi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-supervision rdfs:label "supervision"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-supervisor_pj rdfs:label "Supervisor Pj"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-symbolic rdfs:label "Symbolic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-symbolic_generalization rdfs:label "Symbolic generalization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-symbolic_heuristic_policy_iteration_algorithms rdfs:label "Symbolic heuristic policy iteration algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-symbolic_implementation rdfs:label "symbolic implementation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-symbolic_laosearch rdfs:label "Symbolic LAO∗search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-symbolic_mdp rdfs:label "symbolic MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-symbolic_model-checking rdfs:label "symbolic model-checking"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-symbolic_state_representations rdfs:label "symbolic state representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-symbolic_versions_of_methods rdfs:label "symbolic versions of methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-syntactic_constructions rdfs:label "syntactic constructions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-syntactic_restrictions rdfs:label "syntactic restrictions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-syntactically_recognisable rdfs:label "syntactically recognisable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-syntax_of_the_formulae rdfs:label "syntax of the formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-system_dynamics rdfs:label "system dynamics"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-system_for_decision-theoretic_planning_with_non-markovian_rewards rdfs:label "system for decision-theoretic planning with non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-systematic rdfs:label "systematic"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-systematically_underperforming rdfs:label "systematically underperforming"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-systems_dynamics rdfs:label "system's dynamics"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-t%CE%B3i_a_j rdfs:label "T([Γ(i)], a, [∆(j)])"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-t%CE%B3iaj rdfs:label "T(Γ(i),a,∆[j])"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-t%CE%B3iax rdfs:label "T([Γ(i)],a,X)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-t1 rdfs:label "t1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t2 rdfs:label "t2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t3 rdfs:label "t3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t_%CE%B3iax rdfs:label "T ([Γ(i)],a,X)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t_1 rdfs:label "t_{1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t_2 rdfs:label "t_{2}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-t_3 rdfs:label "t_{3}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_3_results_for_goal-based_problems rdfs:label "Table 3: Results for Goal-Based Problems"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-table_4 rdfs:label "Table 4"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-tables_3_and_4 rdfs:label "Tables 3 and 4"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-tech rdfs:label "Tech"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tech_companies rdfs:label "Tech Companies"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-techniques rdfs:label "techniques"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-technology rdfs:label "Technology"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-technology_b rdfs:label "Technology B"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-technology_n rdfs:label "Technology N"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-teichteil-k%C3%B6nigsbuch_f rdfs:label "Teichteil-Königsbuch, F."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-temperature rdfs:label "temperature"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-temporal_formulae rdfs:label "temporal formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_goal rdfs:label "temporal goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_logic_formalisms rdfs:label "temporal logic formalisms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_planning rdfs:label "temporal planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporally_extended rdfs:label "temporally extended"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-termination_condition rdfs:label "termination condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-textual rdfs:label "textual"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-that rdfs:label "that"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-that_progresses_hf0f1i rdfs:label "that progresses hf0,f1,...i"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-that_scale rdfs:label "that scale"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-that_under_weak_assumptions_rewards_are_correctly_allocated_by_progression rdfs:label "that under weak assumptions, rewards are correctly allocated by progression"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_attribution_of_rewards rdfs:label "the attribution of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_australian_governments_backing_australias_ability_initiative rdfs:label "the Australian Government's Backing Australia's Ability initiative"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_australian_national_university rdfs:label "The Australian National University"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-the_australian_research_council rdfs:label "the Australian Research Council"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-the_behaviour_we_want_to_reward_has_just_happened_or_the_reward_is_received_now rdfs:label "The behaviour we want to reward has just happened or The reward is received now"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_case rdfs:label "the case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_colored_goal_specification rdfs:label "the colored goal specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_current_reward rdfs:label "the current reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_dessert rdfs:label "the dessert"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_discount_factor_controlling_the_contribution_of_distant_rewards rdfs:label "the discount factor controlling the contribution of distant rewards"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_domain_modeller rdfs:label "the domain modeller"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-the_dynamics_and_for_the_rewards rdfs:label "the dynamics and for the rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_elderly rdfs:label "the elderly"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_elevator_control_domain rdfs:label "the elevator control domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-the_envelope_of_policy_%CF%80 rdfs:label "the envelope of policy π"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_fastest rdfs:label "the fastest"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_fastest_and_slowest_methods rdfs:label "the fastest and slowest methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-the_ff_heuristic rdfs:label "the ff heuristic"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-the_formula_f__pup__ rdfs:label "the formula f = ¬pU(p ∧ $)"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-the_four_conditions_of_definition_1 rdfs:label "the four conditions of Definition 1"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_full_structure_of_the_reward_function rdfs:label "the full structure of the reward function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_generated_adds rdfs:label "the generated ADDs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-the_goal rdfs:label "the goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_initial_state_s0_under_the_policy rdfs:label "the initial state s0 under the policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_known_problems rdfs:label "the known problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_last_row rdfs:label "the last row"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_last_state rdfs:label "the last state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_minimal_equivalent_mdp rdfs:label "the minimal equivalent MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-the_movie rdfs:label "the movie"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_non-colored_blocks_world rdfs:label "the non-colored blocks world"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-the_number_of_distinctions rdfs:label "the number of distinctions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_output_of_a_summation rdfs:label "the output of a summation"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_pddl_description rdfs:label "the PDDL description"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_planner rdfs:label "the planner"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-the_planner_attempted_the_problem_but_was_never_able_to_achieve_the_goal rdfs:label "the planner attempted the problem but was never able to achieve the goal"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_prefix_%CE%B3i__1 rdfs:label "the prefix Γ(i − 1)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_previous_state rdfs:label "the previous state"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_probabilistic_version_of_blocks_and_box_world rdfs:label "the probabilistic version of blocks and box world"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_proofs_of_the_theorems rdfs:label "the proofs of the theorems"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_proportion_of_the_entire_2n_state_space_that_is_reachable_from_the_start_state rdfs:label "the proportion of the entire 2n state space that is reachable from the start state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_reasons_why_the_ff_heuristic_works_well_for_traditional_planning_benchmarks rdfs:label "the reasons why the ff heuristic works well for traditional planning benchmarks"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_set_of_all_finite_sequences_ending_with_a_state_containing_p rdfs:label "the set of all finite sequences ending with a state containing p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_set_of_states rdfs:label "the set of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_shortest_time_in_the_future rdfs:label "the shortest time in the future"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_state_of_the_art rdfs:label "the state of the art"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_structure_as_fltl rdfs:label "the structure as fltl"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-the_structured_approach rdfs:label "the structured approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-the_sum_of_the_lengths_of_the_formulae_in_f rdfs:label "the sum of the lengths of the formulae in F"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-the_table rdfs:label "the table"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_tradeoff_between_quality_and_cost rdfs:label "the tradeoff between quality and cost"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_trigger rdfs:label "the trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_two_others rdfs:label "the two others"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_usual_simplification_for_sentential_constants__and_ rdfs:label "the usual simplification for sentential constants ⊥ and ⊤"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-their_kind rdfs:label "their kind"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-their_probabilities rdfs:label "their probabilities"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-them rdfs:label "them"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-then rdfs:label "then"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-theorem rdfs:label "theorem"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-theorem_2 rdfs:label "Theorem 2"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-theorem_3 rdfs:label "Theorem 3"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-theoretical_analyses rdfs:label "theoretical analyses"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-theoretical_analysis rdfs:label "theoretical analysis"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-theoretical_computer_science rdfs:label "Theoretical Computer Science"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-these_approaches rdfs:label "these approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-these_problems rdfs:label "these problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-thi%C3%A9baux rdfs:label "Thiébaux"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-thi%C3%A9baux_et_al_1995 rdfs:label "Thiébaux et al., 1995"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-thiebaux_et_al_1995 rdfs:label "Thi´ebaux et al., 1995"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-thiebaux_kabanza__slaney rdfs:label "Thi´ebaux, Kabanza, & Slaney"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-this_effect rdfs:label "this effect"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-this_framework rdfs:label "this framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-this_paper rdfs:label "this paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-this_sum rdfs:label "this sum"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-those_presented_here rdfs:label "those presented here"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-those_problems rdfs:label "those problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_approaches rdfs:label "three approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_cities_closest_to_the_departure_city rdfs:label "three cities closest to the departure city"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-threshold rdfs:label "threshold"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-tilt_action rdfs:label "tilt action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-time_performance_problems rdfs:label "time performance problems"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-timing_and_memory_usage rdfs:label "timing and memory usage"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-tire rdfs:label "tire"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tire-r rdfs:label "tire-r"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-tire_world_problem rdfs:label "tire world problem"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-to_be_different rdfs:label "to be different"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-to_make_f_true rdfs:label "to make f true"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-tool_b rdfs:label "Tool B"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-tool_c rdfs:label "Tool C"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-tool_z rdfs:label "Tool Z"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-top_s_p_s_q_r rdfs:label "(top S (p S (q∨⊙ r)))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-total_reward rdfs:label "total reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-tower_of_hanoi_problem rdfs:label "tower of hanoi problem"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-traditional_dynamic_programming_algorithms rdfs:label "traditional dynamic programming algorithms"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-traditional_dynamic_programming_methods rdfs:label "traditional dynamic programming methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-traditional_methods rdfs:label "traditional methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-traditional_planning_benchmarks_such_as_blocks_world_and_logistics rdfs:label "traditional planning benchmarks such as blocks world and logistics"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-training_data rdfs:label "Training Data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-trajectories rdfs:label "trajectories"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transition_function rdfs:label "transition function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transition_model rdfs:label "transition model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-transition_models rdfs:label "transition models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-transition_probabilities rdfs:label "transition probabilities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transition_probability rdfs:label "transition probability"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-transition_relation rdfs:label "transition relation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transitions rdfs:label "transitions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-translation_into_adds rdfs:label "translation into ADDs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-traveling_direct rdfs:label "traveling direct"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-travelling_in_a_single_direction rdfs:label "travelling in a single direction"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-treatment_of_non-markovian_rewards rdfs:label "treatment of non-Markovian rewards"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-trees rdfs:label "trees"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-trends rdfs:label "trends"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-trigger_condition_c rdfs:label "trigger condition c"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-trigger_is_unreachable rdfs:label "trigger is unreachable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-triggering_condition rdfs:label "triggering condition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triple_1 rdfs:label "triple 1"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-triple_15 rdfs:label "triple 15"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triple_2 rdfs:label "triple 2"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-triple_6 rdfs:label "triple 6"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-triple_7 rdfs:label "triple 7"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-triple_8 rdfs:label "triple 8"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-triple_9 rdfs:label "triple 9"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-triples rdfs:label "triples"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triples_hs%CF%86ci rdfs:label "triples hs,φ,ci"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trivial rdfs:label "trivial"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-true_of_the_paths_leading_to_the_e-state rdfs:label "true of the paths leading to the e-state"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-truly_minimal_mdp rdfs:label "truly minimal MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-truth_value_of_f1f2 rdfs:label "truth value of f1∨f2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-try-maintain_p rdfs:label "try-maintain p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-try-reach_p rdfs:label "try-reach p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-turn-off_action rdfs:label "turn-off action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-turn-on-pi rdfs:label "turn-on-pi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two rdfs:label "two"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-two_cases rdfs:label "two cases"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-two_iterations_through_the_reward_formula rdfs:label "two iterations through the reward formula"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-two_types rdfs:label "two types"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_unknown_problems rdfs:label "two unknown problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-type_of_representations rdfs:label "type of representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-type_of_reward rdfs:label "type of reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-type_of_rewards rdfs:label "type of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-type_syntax_and_length_of_the_temporal_reward_formula rdfs:label "type, syntax, and length of the temporal reward formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-u_weak_until rdfs:label "U (weak until)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uai rdfs:label "UAI"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uci_machine_learning_repository rdfs:label "UCI Machine Learning Repository"@en ;
    askg-onto:entityType "Database"@en .

askg-data:Entity-unachievable_goal rdfs:label "Unachievable Goal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-unachievable_trigger rdfs:label "Unachievable Trigger"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-unattainable rdfs:label "unattainable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-uncertainty_and_incomplete_information rdfs:label "Uncertainty and Incomplete Information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uncertainty_and_structure_parameters rdfs:label "uncertainty and structure parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uncertainty_in_artificial_intelligence_uai rdfs:label "Uncertainty in Artificial Intelligence (UAI)"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-uncertainty_parameter rdfs:label "Uncertainty parameter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-undefined rdfs:label "undefined"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uninformed_lao rdfs:label "Uninformed LAO*"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-uninterpreted_past_operator rdfs:label "uninterpreted past operator"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-union rdfs:label "union"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unionf1f2 rdfs:label "union[f1,f2]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unique_element_x_of_e rdfs:label "unique element X of E"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-universite_de_sherbrooke rdfs:label "Universit´e de Sherbrooke"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-university_of_california rdfs:label "University of California"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-university_of_xyz rdfs:label "University of XYZ"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-university_x rdfs:label "University X"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-unknown_concept rdfs:label "unknown concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unknown_goal-based_domains rdfs:label "unknown goal-based domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-unknown_problems rdfs:label "unknown problems"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-unnatural_allocations_of_rewards rdfs:label "unnatural allocations of rewards"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-unpromising_sequential_plans rdfs:label "unpromising sequential plans"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unreachable rdfs:label "unreachable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-unreachable_states rdfs:label "unreachable states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unrestricted_negation rdfs:label "unrestricted negation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unrewarding_goal rdfs:label "Unrewarding Goal"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-unrewarding_trigger rdfs:label "Unrewarding Trigger"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-until rdfs:label "'until'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-useful_operators rdfs:label "useful operators"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-useful_result rdfs:label "useful result"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-user rdfs:label "user"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-usually_negative_reward rdfs:label "(usually negative) reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-utility_functions rdfs:label "Utility functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-v%CF%80 rdfs:label "Vπ"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-v%CF%80s0 rdfs:label "Vπ(s0)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-v%CF%80s__0 rdfs:label "Vπ′(s ′ 0)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-valit099_00001 rdfs:label "valIt(0.99, 0.0001)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-value rdfs:label "value"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-values_of_n rdfs:label "values of n"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-valuetodot rdfs:label "valueToDot"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-vardi rdfs:label "Vardi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-variables_which_are_irrelevant rdfs:label "variables which are irrelevant"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-variant rdfs:label "variant"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variants rdfs:label "variants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-various_approaches rdfs:label "various approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-various_trajectories_in_the_optimal_policy rdfs:label "various trajectories in the optimal policy"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-version_of_ff_replanning_upon_failure rdfs:label "version of ff replanning upon failure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vi%CE%B2_%C7%AB rdfs:label "VI(β, ǫ)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-violation rdfs:label "violation"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-vip_and_conflicting_group_services rdfs:label "VIP and conflicting group services"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visualizing_graphs rdfs:label "visualizing graphs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vol rdfs:label "Vol."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-we rdfs:label "We"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-weak rdfs:label "weak"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weak_temporally_extended_goals rdfs:label "weak temporally extended goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-weissmann rdfs:label "Weissmann"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-what_must_have_been_true_previously_for_f_to_be_true_now rdfs:label "what must have been true previously for f to be true now"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-whatever_that_is rdfs:label "whatever that is"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-whelan_g rdfs:label "Whelan, G."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-when rdfs:label "when"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-when_a_formula_holds rdfs:label "when a formula holds"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-whether_a_particular_prefix_needs_to_be_rewarded rdfs:label "whether a particular prefix needs to be rewarded"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-whether_p_was_true_or_not rdfs:label "whether p was true or not"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-which_no_passenger_is_waiting rdfs:label "which no passenger is waiting"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-wj_wk rdfs:label "Wj Wk"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-wolper rdfs:label "Wolper"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-wolper_p rdfs:label "Wolper, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-workshop rdfs:label "Workshop"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-world rdfs:label "world"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-worst_case_behaviour rdfs:label "worst case behaviour"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-x__x__x rdfs:label "{¬x | x ∈ X}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_to_y rdfs:label "X to Y"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-y rdfs:label "Y"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-yes_and_no rdfs:label "yes and no"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-yoon_s rdfs:label "Yoon, S."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-younes rdfs:label "Younes"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-younes__littman rdfs:label "Younes & Littman"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-younes__simmons_2004 rdfs:label "Younes & Simmons, 2004"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-younes_et_al rdfs:label "Younes et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-younes_littman_weissmann__asmuth rdfs:label "Younes, Littman, Weissmann, & Asmuth"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-zeno rdfs:label "zeno"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-zeno_travel_domain_problem rdfs:label "zeno travel domain problem"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-zhao_j rdfs:label "Zhao, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zuck_l rdfs:label "Zuck, L."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Paper-c253584c3f1ff2a2-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "Decision-Theoretic Planning With Non-Markovian Rewards"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-1-Paragraph-11 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Sylvie Thi´ebaux **Sylvie.Thiebaux@anu.edu.au** Charles Gretton **Charles.Gretton@anu.edu.au** John Slaney **John.Slaney@anu.edu.au** David Price **David.Price@anu.edu.au** National ICT Australia & The Australian National University Canberra, ACT 0200, Australia Froduald Kabanza **kabanza@usherbrooke.ca** D´epartement d'Informatique Universit´e de Sherbrooke Sherbrooke, Qu´ebec J1K 2R1, Canada"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-1-Paragraph-11-Sentence-111 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Sylvie Thi´ebaux **Sylvie.Thiebaux@anu.edu.au** Charles Gretton **Charles.Gretton@anu.edu.au** John Slaney **John.Slaney@anu.edu.au** David Price **David.Price@anu.edu.au** National ICT Australia & The Australian National University Canberra, ACT 0200, Australia Froduald Kabanza **kabanza@usherbrooke.ca** D´epartement d'Informatique Universit´e de Sherbrooke Sherbrooke, Qu´ebec J1K 2R1, Canada"@en ;
    askg-onto:inSentence "Sylvie Thi´ebaux **Sylvie.Thiebaux@anu.edu.au** Charles Gretton **Charles.Gretton@anu.edu.au** John Slaney **John.Slaney@anu.edu.au** David Price **David.Price@anu.edu.au** National ICT Australia & The Australian National University Canberra, ACT 0200, Australia Froduald Kabanza **kabanza@usherbrooke.ca** D´epartement d'Informatique Universit´e de Sherbrooke Sherbrooke, Qu´ebec J1K 2R1, Canada"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-charles_gretton,
        askg-data:Entity-david_price,
        askg-data:Entity-departement_dinformatique_universite_de_sherbrooke,
        askg-data:Entity-froduald_kabanza,
        askg-data:Entity-john_slaney,
        askg-data:Entity-national_ict_australia,
        askg-data:Entity-sylvie_thiebaux,
        askg-data:Entity-the_australian_national_university,
        askg-data:Entity-universite_de_sherbrooke .

askg-data:Paper-c253584c3f1ff2a2-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "2. Background"@en ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "2.1 Mdps, Nmrdps, Equivalence"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We start with some notation and definitions. Given a finite set S **of states, we write** S ∗for the set of finite sequences of states over S**, and** S ω**for the set of possibly infinite** state sequences. Where 'Γ' stands for a possibly infinite state sequence in S ω and i **is a** natural number, by 'Γi' we mean the state of index i in Γ, by 'Γ(i**)' we mean the prefix** hΓ0,... , Γii ∈ S ∗ of Γ. Γ; Γ′ **denotes the concatenation of Γ** ∈ S ∗ **and Γ**′ ∈ S ω."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1112,
        askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1113,
        askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1114,
        askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1115 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We start with some notation and definitions."@en ;
    askg-onto:inSentence "We start with some notation and definitions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-definitions,
        askg-data:Entity-notation .

askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given a finite set S **of states, we write** S ∗for the set of finite sequences of states over S**, and** S ω**for the set of possibly infinite** state sequences."@en ;
    askg-onto:inSentence "Given a finite set S **of states, we write** S ∗for the set of finite sequences of states over S**, and** S ω**for the set of possibly infinite** state sequences."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finite_sequences_of_states_over_s,
        askg-data:Entity-possibly_infinite_state_sequences,
        askg-data:Entity-s,
        askg-data:Entity-s%CF%89,
        askg-data:Entity-states .

askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Where 'Γ' stands for a possibly infinite state sequence in S ω and i **is a** natural number, by 'Γi' we mean the state of index i in Γ, by 'Γ(i**)' we mean the prefix** hΓ0,..."@en ;
    askg-onto:inSentence "Where 'Γ' stands for a possibly infinite state sequence in S ω and i **is a** natural number, by 'Γi' we mean the state of index i in Γ, by 'Γ(i**)' we mean the prefix** hΓ0,..."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-%CE%B3i,
        askg-data:Entity-i,
        askg-data:Entity-natural_number,
        askg-data:Entity-possibly_infinite_state_sequence,
        askg-data:Entity-prefix_h%CE%B30,
        askg-data:Entity-state_of_index_i_in_%CE%B3 .

askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text ", Γii ∈ S ∗ of Γ."@en ;
    askg-onto:inSentence ", Γii ∈ S ∗ of Γ."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3ii,
        askg-data:Entity-s_ .

askg-data:Paper-c253584c3f1ff2a2-Section-11-Paragraph-111-Sentence-1115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Γ; Γ′ **denotes the concatenation of Γ** ∈ S ∗ **and Γ**′ ∈ S ω."@en ;
    askg-onto:inSentence "Γ; Γ′ **denotes the concatenation of Γ** ∈ S ∗ **and Γ**′ ∈ S ω."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3 .

askg-data:Paper-c253584c3f1ff2a2-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "2.1.1 Mdps"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-121,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-122,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-123,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-124,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-125,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-127,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-128 ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-121 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "A Markov decision process of the type we consider is a 5-tuple hS,s0,A,Pr,Ri**, where** S is a finite set of fully observable states, s0 ∈ S is the initial state, A **is a finite set of actions** (A(s) denotes the subset of actions applicable in s ∈ S), {Pr(s,a, •) | s ∈ S,a ∈ A(s)} **is a** family of probability distributions over S, such that Pr(s,a,s′**) is the probability of being** in state s ′ after performing action a in state s, and R : S 7→ **IR is a reward function such** that R(s) is the immediate reward for being in state s**. It is well known that such an MDP** can be compactly represented using dynamic Bayesian networks (Dean & Kanazawa, 1989; Boutilier et al., 1999) or probabilistic extensions of traditional planning languages (see e.g., Kushmerick, Hanks, & Weld, 1995; Thi´ebaux et al., 1995; Younes & Littman, 2004)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-121-Sentence-1211,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-121-Sentence-1212 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-121-Sentence-1211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A Markov decision process of the type we consider is a 5-tuple hS,s0,A,Pr,Ri**, where** S is a finite set of fully observable states, s0 ∈ S is the initial state, A **is a finite set of actions** (A(s) denotes the subset of actions applicable in s ∈ S), {Pr(s,a, •) | s ∈ S,a ∈ A(s)} **is a** family of probability distributions over S, such that Pr(s,a,s′**) is the probability of being** in state s ′ after performing action a in state s, and R : S 7→ **IR is a reward function such** that R(s) is the immediate reward for being in state s**."@en ;
    askg-onto:inSentence "A Markov decision process of the type we consider is a 5-tuple hS,s0,A,Pr,Ri**, where** S is a finite set of fully observable states, s0 ∈ S is the initial state, A **is a finite set of actions** (A(s) denotes the subset of actions applicable in s ∈ S), {Pr(s,a, •) | s ∈ S,a ∈ A(s)} **is a** family of probability distributions over S, such that Pr(s,a,s′**) is the probability of being** in state s ′ after performing action a in state s, and R : S 7→ **IR is a reward function such** that R(s) is the immediate reward for being in state s**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5-tuple,
        askg-data:Entity-a,
        askg-data:Entity-family_of_probability_distributions,
        askg-data:Entity-finite_set_of_actions,
        askg-data:Entity-finite_set_of_fully_observable_states,
        askg-data:Entity-immediate_reward_for_being_in_state_s,
        askg-data:Entity-initial_state,
        askg-data:Entity-markov_decision_process,
        askg-data:Entity-pr,
        askg-data:Entity-r,
        askg-data:Entity-reward_function,
        askg-data:Entity-rs,
        askg-data:Entity-s,
        askg-data:Entity-s0 .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-121-Sentence-1212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It is well known that such an MDP** can be compactly represented using dynamic Bayesian networks (Dean & Kanazawa, 1989; Boutilier et al., 1999) or probabilistic extensions of traditional planning languages (see e.g., Kushmerick, Hanks, & Weld, 1995; Thi´ebaux et al., 1995; Younes & Littman, 2004)."@en ;
    askg-onto:inSentence "It is well known that such an MDP** can be compactly represented using dynamic Bayesian networks (Dean & Kanazawa, 1989; Boutilier et al., 1999) or probabilistic extensions of traditional planning languages (see e.g., Kushmerick, Hanks, & Weld, 1995; Thi´ebaux et al., 1995; Younes & Littman, 2004)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-boutilier_et_al_1999,
        askg-data:Entity-dean__kanazawa_1989,
        askg-data:Entity-dynamic_bayesian_networks,
        askg-data:Entity-kushmerick_hanks__weld_1995,
        askg-data:Entity-mdp,
        askg-data:Entity-probabilistic_extensions_of_traditional_planning_languages,
        askg-data:Entity-thi%C3%A9baux_et_al_1995,
        askg-data:Entity-younes__littman_2004 .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-122 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "A stationary policy for an MDP is a function π : S 7→ A, such that π(s) ∈ A(s**) is** the action to be executed in state s. The value Vπ of the policy at s0**, which we seek to** maximise, is the sum of the expected future rewards over an infinite horizon, discounted by how far into the future they occur:"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-122-Sentence-1221,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-122-Sentence-1222 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-122-Sentence-1221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A stationary policy for an MDP is a function π : S 7→ A, such that π(s) ∈ A(s**) is** the action to be executed in state s."@en ;
    askg-onto:inSentence "A stationary policy for an MDP is a function π : S 7→ A, such that π(s) ∈ A(s**) is** the action to be executed in state s."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%80,
        askg-data:Entity-%CF%80s,
        askg-data:Entity-a,
        askg-data:Entity-as,
        askg-data:Entity-condition,
        askg-data:Entity-function,
        askg-data:Entity-mdp,
        askg-data:Entity-s,
        askg-data:Entity-set_of_actions,
        askg-data:Entity-set_of_states,
        askg-data:Entity-state_s,
        askg-data:Entity-stationary_policy .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-122-Sentence-1222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The value Vπ of the policy at s0**, which we seek to** maximise, is the sum of the expected future rewards over an infinite horizon, discounted by how far into the future they occur:"@en ;
    askg-onto:inSentence "The value Vπ of the policy at s0**, which we seek to** maximise, is the sum of the expected future rewards over an infinite horizon, discounted by how far into the future they occur:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expected_future_rewards,
        askg-data:Entity-how_far_into_the_future_they_occur,
        askg-data:Entity-policy,
        askg-data:Entity-v%CF%80 .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-123 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$V_{\\pi}(s_{0})=\\operatorname*{lim}_{n\\to\\infty}\\;\\mathsf{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma_{i})\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-123-Sentence-1231 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-123-Sentence-1231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$V_{\\pi}(s_{0})=\\operatorname*{lim}_{n\\to\\infty}\\;\\mathsf{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma_{i})\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:inSentence "$$V_{\\pi}(s_{0})=\\operatorname*{lim}_{n\\to\\infty}\\;\\mathsf{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma_{i})\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-operatornamelim_ntoinftymathsfeleftsum_i0nbetairgamma_imidpigamma_0s_0right,
        askg-data:Entity-v_%0Apis_0 .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-124 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "where 0 ≤ β < **1 is the discount factor controlling the contribution of distant rewards.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-124-Sentence-1241 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-124-Sentence-1241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where 0 ≤ β < **1 is the discount factor controlling the contribution of distant rewards.**"@en ;
    askg-onto:inSentence "where 0 ≤ β < **1 is the discount factor controlling the contribution of distant rewards.**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B2,
        askg-data:Entity-the_discount_factor_controlling_the_contribution_of_distant_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-125 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![5_image_0.png](5_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-125-Sentence-1251 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-125-Sentence-1251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![5_image_0.png](5_image_0.png)"@en ;
    askg-onto:inSentence "![5_image_0.png](5_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_science,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning,
        askg-data:Entity-imagenet,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-organization,
        askg-data:Entity-research_paper,
        askg-data:Entity-stanford_university,
        askg-data:Entity-support_vector_machines .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "In the initial state s0, p **is false and two actions are** possible: a causes a transition to s1 **with probability** 0.1, and no change with probability 0.9, while for b the transition probabilities are 0.5. In state s1, p **is true,** and actions c and d (\"stay\" and \"go\") lead to s1 and s0 respectively with probability 1. A reward is received the first time p **is true, but not** subsequently. That is, the rewarded state sequences are: hs0, s1i"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1261,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1262,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1263,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1264 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the initial state s0, p **is false and two actions are** possible: a causes a transition to s1 **with probability** 0.1, and no change with probability 0.9, while for b the transition probabilities are 0.5."@en ;
    askg-onto:inSentence "In the initial state s0, p **is false and two actions are** possible: a causes a transition to s1 **with probability** 0.1, and no change with probability 0.9, while for b the transition probabilities are 0.5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-01,
        askg-data:Entity-05,
        askg-data:Entity-09,
        askg-data:Entity-false,
        askg-data:Entity-s0 .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In state s1, p **is true,** and actions c and d (\"stay\" and \"go\") lead to s1 and s0 respectively with probability 1."@en ;
    askg-onto:inSentence "In state s1, p **is true,** and actions c and d (\"stay\" and \"go\") lead to s1 and s0 respectively with probability 1."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions_c_and_d,
        askg-data:Entity-s0,
        askg-data:Entity-s1,
        askg-data:Entity-state_s1 .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1263 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A reward is received the first time p **is true, but not** subsequently."@en ;
    askg-onto:inSentence "A reward is received the first time p **is true, but not** subsequently."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_time_p_is_true,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-126-Sentence-1264 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "That is, the rewarded state sequences are: hs0, s1i"@en ;
    askg-onto:inSentence "That is, the rewarded state sequences are: hs0, s1i"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hs0,
        askg-data:Entity-s1i .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-127 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$\\langle\\,s_0,\\,s_0,\\,s_1\\,\\rangle\\\\ \\langle\\,s_0,\\,s_0,\\,s_0,\\,s_1\\,\\rangle\\\\$ 4. hs0, s0, s0, s0, s1i **etc.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-127-Sentence-1271,
        askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-127-Sentence-1272 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-127-Sentence-1271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\langle\\,s_0,\\,s_0,\\,s_1\\,\\rangle\\\\ \\langle\\,s_0,\\,s_0,\\,s_0,\\,s_1\\,\\rangle\\\\$ 4."@en ;
    askg-onto:inSentence "$\\langle\\,s_0,\\,s_0,\\,s_1\\,\\rangle\\\\ \\langle\\,s_0,\\,s_0,\\,s_0,\\,s_1\\,\\rangle\\\\$ 4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s_0,
        askg-data:Entity-s_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-127-Sentence-1272 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "hs0, s0, s0, s0, s1i **etc.**"@en ;
    askg-onto:inSentence "hs0, s0, s0, s0, s1i **etc.**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hs0,
        askg-data:Entity-s0,
        askg-data:Entity-s1i .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-128 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Figure 1: A Simple NMRDP"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-128-Sentence-1281 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-12-Paragraph-128-Sentence-1281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 1: A Simple NMRDP"@en ;
    askg-onto:inSentence "Figure 1: A Simple NMRDP"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "2.1.2 Nmrdps"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131,
        askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-132,
        askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-133 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "A decision process with non-Markovian rewards is identical **to an MDP except that the** domain of the reward function is S ∗**. The idea is that if the process has passed through** state sequence Γ(i) up to stage i, then the reward R(Γ(i)) is received at stage i**. Figure 1** gives an example. Like the reward function, a policy for an NMRDP depends on history, and is a mapping from S ∗to A. As before, the value of policy π **is the expectation of the** discounted cumulative reward over an infinite horizon:"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1312,
        askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1313,
        askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1314,
        askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1315 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A decision process with non-Markovian rewards is identical **to an MDP except that the** domain of the reward function is S ∗**."@en ;
    askg-onto:inSentence "A decision process with non-Markovian rewards is identical **to an MDP except that the** domain of the reward function is S ∗**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_process,
        askg-data:Entity-mdp,
        askg-data:Entity-reward_function,
        askg-data:Entity-s_ .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The idea is that if the process has passed through** state sequence Γ(i) up to stage i, then the reward R(Γ(i)) is received at stage i**."@en ;
    askg-onto:inSentence "The idea is that if the process has passed through** state sequence Γ(i) up to stage i, then the reward R(Γ(i)) is received at stage i**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-process,
        askg-data:Entity-reward_r%CE%B3i,
        askg-data:Entity-stage_i,
        askg-data:Entity-state_sequence_%CE%B3i .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Figure 1** gives an example."@en ;
    askg-onto:inSentence "Figure 1** gives an example."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_example,
        askg-data:Entity-figure_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Like the reward function, a policy for an NMRDP depends on history, and is a mapping from S ∗to A."@en ;
    askg-onto:inSentence "Like the reward function, a policy for an NMRDP depends on history, and is a mapping from S ∗to A."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-history,
        askg-data:Entity-nmrdp,
        askg-data:Entity-policy,
        askg-data:Entity-s_to_a .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-131-Sentence-1315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "As before, the value of policy π **is the expectation of the** discounted cumulative reward over an infinite horizon:"@en ;
    askg-onto:inSentence "As before, the value of policy π **is the expectation of the** discounted cumulative reward over an infinite horizon:"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discounted_cumulative_reward,
        askg-data:Entity-infinite_horizon,
        askg-data:Entity-policy_%CF%80 .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-132 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$V_{\\pi}(s_{0})=\\operatorname*{lim}_{n\\to\\infty}\\mathsf{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma(i))\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-132-Sentence-1321 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-132-Sentence-1321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$V_{\\pi}(s_{0})=\\operatorname*{lim}_{n\\to\\infty}\\mathsf{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma(i))\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:inSentence "$$V_{\\pi}(s_{0})=\\operatorname*{lim}_{n\\to\\infty}\\mathsf{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma(i))\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-v_%0Apis_0 .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-133 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "For a decision process D = hS,s0,A,Pr,Ri and a state s ∈ S, we let De(s**) stand for** the set of state sequences rooted at s that are feasible under the actions in D**, that is:** De(s) = {Γ ∈ S ω| Γ0 = s and ∀i ∃a ∈ A(Γi) Pr(Γi,a, Γi+1) > 0}**. Note that the definition** of De(s) does not depend on R **and therefore applies to both MDPs and NMRDPs.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-133-Sentence-1331,
        askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-133-Sentence-1332 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-133-Sentence-1331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For a decision process D = hS,s0,A,Pr,Ri and a state s ∈ S, we let De(s**) stand for** the set of state sequences rooted at s that are feasible under the actions in D**, that is:** De(s) = {Γ ∈ S ω| Γ0 = s and ∀i ∃a ∈ A(Γi) Pr(Γi,a, Γi+1) > 0}**."@en ;
    askg-onto:inSentence "For a decision process D = hS,s0,A,Pr,Ri and a state s ∈ S, we let De(s**) stand for** the set of state sequences rooted at s that are feasible under the actions in D**, that is:** De(s) = {Γ ∈ S ω| Γ0 = s and ∀i ∃a ∈ A(Γi) Pr(Γi,a, Γi+1) > 0}**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions_in_d,
        askg-data:Entity-decision_process_d,
        askg-data:Entity-des,
        askg-data:Entity-hss0aprri,
        askg-data:Entity-set_of_state_sequences,
        askg-data:Entity-state_s .

askg-data:Paper-c253584c3f1ff2a2-Section-13-Paragraph-133-Sentence-1332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that the definition** of De(s) does not depend on R **and therefore applies to both MDPs and NMRDPs.**"@en ;
    askg-onto:inSentence "Note that the definition** of De(s) does not depend on R **and therefore applies to both MDPs and NMRDPs.**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-des,
        askg-data:Entity-mdps,
        askg-data:Entity-nmrdps,
        askg-data:Entity-r .

askg-data:Paper-c253584c3f1ff2a2-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "2.1.3 Equivalence"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-142,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-144,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-145,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-146,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-147,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The clever algorithms developed to solve MDPs cannot be directly applied to NMRDPs. One way of dealing with this problem is to translate the NMRDP **into an equivalent MDP** with an expanded state space (Bacchus et al., 1996). The expanded states in this MDP (e-states**, for short) augment the states of the NMRDP by encoding additional information** sufficient to make the reward history-independent. For instance, if we only want to reward the very first achievement of goal g **in an NMRDP, the states of an equivalent MDP would** carry one extra bit of information recording whether g **has already been true. An e-state can** be seen as labelled by a state of the NMRDP (via the function τ **in Definition 1 below) and** by history information. The dynamics of NMRDPs being Markovian, the actions and their probabilistic effects in the MDP are exactly those of the NMRDP. The following definition, adapted from that given by Bacchus et al. (1996), makes this concept of equivalent MDP precise. Figure 2 gives an example."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1411,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1412,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1413,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1414,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1415,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1416,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1417,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1418,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1419 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The clever algorithms developed to solve MDPs cannot be directly applied to NMRDPs."@en ;
    askg-onto:inSentence "The clever algorithms developed to solve MDPs cannot be directly applied to NMRDPs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-mdps,
        askg-data:Entity-nmrdps .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "One way of dealing with this problem is to translate the NMRDP **into an equivalent MDP** with an expanded state space (Bacchus et al., 1996)."@en ;
    askg-onto:inSentence "One way of dealing with this problem is to translate the NMRDP **into an equivalent MDP** with an expanded state space (Bacchus et al., 1996)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The expanded states in this MDP (e-states**, for short) augment the states of the NMRDP by encoding additional information** sufficient to make the reward history-independent."@en ;
    askg-onto:inSentence "The expanded states in this MDP (e-states**, for short) augment the states of the NMRDP by encoding additional information** sufficient to make the reward history-independent."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-reward_history .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For instance, if we only want to reward the very first achievement of goal g **in an NMRDP, the states of an equivalent MDP would** carry one extra bit of information recording whether g **has already been true."@en ;
    askg-onto:inSentence "For instance, if we only want to reward the very first achievement of goal g **in an NMRDP, the states of an equivalent MDP would** carry one extra bit of information recording whether g **has already been true."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "An e-state can** be seen as labelled by a state of the NMRDP (via the function τ **in Definition 1 below) and** by history information."@en ;
    askg-onto:inSentence "An e-state can** be seen as labelled by a state of the NMRDP (via the function τ **in Definition 1 below) and** by history information."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-history_information,
        askg-data:Entity-state_of_the_nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The dynamics of NMRDPs being Markovian, the actions and their probabilistic effects in the MDP are exactly those of the NMRDP."@en ;
    askg-onto:inSentence "The dynamics of NMRDPs being Markovian, the actions and their probabilistic effects in the MDP are exactly those of the NMRDP."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions,
        askg-data:Entity-markovian,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-nmrdps,
        askg-data:Entity-probabilistic_effects .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1417 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The following definition, adapted from that given by Bacchus et al."@en ;
    askg-onto:inSentence "The following definition, adapted from that given by Bacchus et al."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-definition .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1418 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "(1996), makes this concept of equivalent MDP precise."@en ;
    askg-onto:inSentence "(1996), makes this concept of equivalent MDP precise."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-141-Sentence-1419 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Figure 2 gives an example."@en ;
    askg-onto:inSentence "Figure 2 gives an example."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-example .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-142 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-142-Sentence-1421 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-142-Sentence-1421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:inSentence "![6_image_0.png](6_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-dataset_x,
        askg-data:Entity-deep_learning_techniques,
        askg-data:Entity-machine_learning_model,
        askg-data:Entity-model_a,
        askg-data:Entity-patients_with_condition_y,
        askg-data:Entity-research_group_a,
        askg-data:Entity-research_paper,
        askg-data:Entity-software_tool_b,
        askg-data:Entity-university_of_xyz .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 2: An MDP Equivalent to the NMRDP in Figure 1. τ (s ′0) = τ (s ′2) = s0. τ (s ′1) = τ (s ′3) = s1**. The initial state is** s ′0**. State** s ′1**is rewarded; the other states are not.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1431,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1432,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1433,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1434,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1435 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 2: An MDP Equivalent to the NMRDP in Figure 1."@en ;
    askg-onto:inSentence "Figure 2: An MDP Equivalent to the NMRDP in Figure 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "τ (s ′0) = τ (s ′2) = s0."@en ;
    askg-onto:inSentence "τ (s ′0) = τ (s ′2) = s0."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s0,
        askg-data:Entity-s_0,
        askg-data:Entity-s_2 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "τ (s ′1) = τ (s ′3) = s1**."@en ;
    askg-onto:inSentence "τ (s ′1) = τ (s ′3) = s1**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s1,
        askg-data:Entity-s_1,
        askg-data:Entity-s_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The initial state is** s ′0**."@en ;
    askg-onto:inSentence "The initial state is** s ′0**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_state,
        askg-data:Entity-s_0 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-143-Sentence-1435 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "State** s ′1**is rewarded; the other states are not.**"@en ;
    askg-onto:inSentence "State** s ′1**is rewarded; the other states are not.**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-other_states,
        askg-data:Entity-state_s1 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-144 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Definition 1 MDP D′=hS ′,s′0 ,A′,Pr′,R′i is equivalent to NMRDP D = hS,s0,A,Pr,Ri if there exists a mapping τ : S ′7→ S **such that:**1 1. τ (s ′ 0) = s0."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-144-Sentence-1441,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-144-Sentence-1442 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-144-Sentence-1441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Definition 1 MDP D′=hS ′,s′0 ,A′,Pr′,R′i is equivalent to NMRDP D = hS,s0,A,Pr,Ri if there exists a mapping τ : S ′7→ S **such that:**1 1."@en ;
    askg-onto:inSentence "Definition 1 MDP D′=hS ′,s′0 ,A′,Pr′,R′i is equivalent to NMRDP D = hS,s0,A,Pr,Ri if there exists a mapping τ : S ′7→ S **such that:**1 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mapping_%CF%84,
        askg-data:Entity-mdp_d,
        askg-data:Entity-nmrdp_d,
        askg-data:Entity-s_7_s .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-144-Sentence-1442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "τ (s ′ 0) = s0."@en ;
    askg-onto:inSentence "τ (s ′ 0) = s0."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s0,
        askg-data:Entity-s__0 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-145 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "2. For all s ′ ∈ S ′, A′(s ′) = A(τ (s ′))."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-145-Sentence-1451,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-145-Sentence-1452 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-145-Sentence-1451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2."@en ;
    askg-onto:inSentence "2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-145-Sentence-1452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For all s ′ ∈ S ′, A′(s ′) = A(τ (s ′))."@en ;
    askg-onto:inSentence "For all s ′ ∈ S ′, A′(s ′) = A(τ (s ′))."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%84s,
        askg-data:Entity-a,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-146 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "3. For all s1,s2 ∈ S, if there is a ∈ A(s1) such that Pr(s1,a,s2) > 0**, then for all** s ′1 ∈ S ′ such that τ (s ′1) = s1**, there exists a unique** s ′2 ∈ S ′, τ (s ′2) = s2**, such that for all** a ′ ∈ A′(s ′1), Pr′(s ′1,a′,s′2**)=Pr(**s1,a′,s2)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-146-Sentence-1461,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-146-Sentence-1462 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-146-Sentence-1461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3."@en ;
    askg-onto:inSentence "3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-triple_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-146-Sentence-1462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For all s1,s2 ∈ S, if there is a ∈ A(s1) such that Pr(s1,a,s2) > 0**, then for all** s ′1 ∈ S ′ such that τ (s ′1) = s1**, there exists a unique** s ′2 ∈ S ′, τ (s ′2) = s2**, such that for all** a ′ ∈ A′(s ′1), Pr′(s ′1,a′,s′2**)=Pr(**s1,a′,s2)."@en ;
    askg-onto:inSentence "For all s1,s2 ∈ S, if there is a ∈ A(s1) such that Pr(s1,a,s2) > 0**, then for all** s ′1 ∈ S ′ such that τ (s ′1) = s1**, there exists a unique** s ′2 ∈ S ′, τ (s ′2) = s2**, such that for all** a ′ ∈ A′(s ′1), Pr′(s ′1,a′,s′2**)=Pr(**s1,a′,s2)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-s1,
        askg-data:Entity-s1as2,
        askg-data:Entity-s2 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-147 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "4. For any feasible state sequence Γ ∈ De(s0) and Γ ′ ∈ De′(s ′0) such that τ (Γ′i) = Γifor all i, we have: R′(Γ′i) = R(Γ(i)) **for all** i."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-147-Sentence-1471,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-147-Sentence-1472 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-147-Sentence-1471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4."@en ;
    askg-onto:inSentence "4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_concept,
        askg-data:Entity-triple_4 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-147-Sentence-1472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For any feasible state sequence Γ ∈ De(s0) and Γ ′ ∈ De′(s ′0) such that τ (Γ′i) = Γifor all i, we have: R′(Γ′i) = R(Γ(i)) **for all** i."@en ;
    askg-onto:inSentence "For any feasible state sequence Γ ∈ De(s0) and Γ ′ ∈ De′(s ′0) such that τ (Γ′i) = Γifor all i, we have: R′(Γ′i) = R(Γ(i)) **for all** i."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CF%84_%CE%B3i,
        askg-data:Entity-des0,
        askg-data:Entity-des_0,
        askg-data:Entity-feasible_state_sequence,
        askg-data:Entity-r%CE%B3i .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Items 1–3 ensure that there is a bijection between feasible state sequences in the NMRDP and feasible e-state sequences in the MDP. Therefore, a stationary policy for the MDP can be reinterpreted as a non-stationary policy for the NMRDP. Furthermore, item 4 ensures that the two policies have identical values, and that consequently, solving an NMRDP optimally reduces to producing an equivalent MDP and solving it optimally (Bacchus et al., 1996): Proposition 1 Let D be an NMRDP, D′ **an equivalent MDP for it, and** π ′ **a policy for** D′. Let π be the function defined on the sequence prefixes Γ(i) ∈ De(s0) by π(Γ(i**)) =** π ′(Γ′i), where for all j ≤ i τ (Γ′j ) = Γj . Then π is a policy for D such that Vπ(s0) = Vπ′(s ′ 0)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1481,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1482,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1483,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1484,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1485 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Items 1–3 ensure that there is a bijection between feasible state sequences in the NMRDP and feasible e-state sequences in the MDP."@en ;
    askg-onto:inSentence "Items 1–3 ensure that there is a bijection between feasible state sequences in the NMRDP and feasible e-state sequences in the MDP."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1482 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Therefore, a stationary policy for the MDP can be reinterpreted as a non-stationary policy for the NMRDP."@en ;
    askg-onto:inSentence "Therefore, a stationary policy for the MDP can be reinterpreted as a non-stationary policy for the NMRDP."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-non-stationary_policy,
        askg-data:Entity-stationary_policy .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1483 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, item 4 ensures that the two policies have identical values, and that consequently, solving an NMRDP optimally reduces to producing an equivalent MDP and solving it optimally (Bacchus et al., 1996): Proposition 1 Let D be an NMRDP, D′ **an equivalent MDP for it, and** π ′ **a policy for** D′."@en ;
    askg-onto:inSentence "Furthermore, item 4 ensures that the two policies have identical values, and that consequently, solving an NMRDP optimally reduces to producing an equivalent MDP and solving it optimally (Bacchus et al., 1996): Proposition 1 Let D be an NMRDP, D′ **an equivalent MDP for it, and** π ′ **a policy for** D′."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al_1996,
        askg-data:Entity-d,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-proposition_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1484 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Let π be the function defined on the sequence prefixes Γ(i) ∈ De(s0) by π(Γ(i**)) =** π ′(Γ′i), where for all j ≤ i τ (Γ′j ) = Γj ."@en ;
    askg-onto:inSentence "Let π be the function defined on the sequence prefixes Γ(i) ∈ De(s0) by π(Γ(i**)) =** π ′(Γ′i), where for all j ≤ i τ (Γ′j ) = Γj ."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3j,
        askg-data:Entity-sequence_prefixes_%CE%B3i__des0 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-148-Sentence-1485 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Then π is a policy for D such that Vπ(s0) = Vπ′(s ′ 0)."@en ;
    askg-onto:inSentence "Then π is a policy for D such that Vπ(s0) = Vπ′(s ′ 0)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%80,
        askg-data:Entity-d,
        askg-data:Entity-v%CF%80s0,
        askg-data:Entity-v%CF%80s__0 .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "1. Technically, the definition allows the sets of actions A and A ′**to be different, but any action in which** they differ must be inapplicable in reachable states in the NMRDP and in all e-states in the equivalent MDP. For all practical purposes, A and A ′**can be seen as identical.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149-Sentence-1491,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149-Sentence-1492,
        askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149-Sentence-1493 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149-Sentence-1491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1."@en ;
    askg-onto:inSentence "1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-company,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-model,
        askg-data:Entity-research_field,
        askg-data:Entity-researcher,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149-Sentence-1492 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Technically, the definition allows the sets of actions A and A ′**to be different, but any action in which** they differ must be inapplicable in reachable states in the NMRDP and in all e-states in the equivalent MDP."@en ;
    askg-onto:inSentence "Technically, the definition allows the sets of actions A and A ′**to be different, but any action in which** they differ must be inapplicable in reachable states in the NMRDP and in all e-states in the equivalent MDP."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions,
        askg-data:Entity-all_e-states_in_the_equivalent_mdp,
        askg-data:Entity-reachable_states_in_the_nmrdp,
        askg-data:Entity-sets_of_actions_a_and_a,
        askg-data:Entity-to_be_different .

askg-data:Paper-c253584c3f1ff2a2-Section-14-Paragraph-149-Sentence-1493 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For all practical purposes, A and A ′**can be seen as identical.**"@en ;
    askg-onto:inSentence "For all practical purposes, A and A ′**can be seen as identical.**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-a_ .

askg-data:Paper-c253584c3f1ff2a2-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "2.2 Existing Approaches"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-151,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-153 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Both existing approaches to NMRDPs (Bacchus et al., 1996, 1997) use a temporal logic of the past (PLTL) to compactly represent non-Markovian rewards and exploit this compact representation to translate the NMRDP into an MDP amenable to off-the-shelf solution methods. However, they target different classes of MDP representations and solution methods, and consequently, adopt different styles of translations."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-151-Sentence-1511,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-151-Sentence-1512 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Both existing approaches to NMRDPs (Bacchus et al., 1996, 1997) use a temporal logic of the past (PLTL) to compactly represent non-Markovian rewards and exploit this compact representation to translate the NMRDP into an MDP amenable to off-the-shelf solution methods."@en ;
    askg-onto:inSentence "Both existing approaches to NMRDPs (Bacchus et al., 1996, 1997) use a temporal logic of the past (PLTL) to compactly represent non-Markovian rewards and exploit this compact representation to translate the NMRDP into an MDP amenable to off-the-shelf solution methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996_1997,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdps,
        askg-data:Entity-pltl,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-151-Sentence-1512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, they target different classes of MDP representations and solution methods, and consequently, adopt different styles of translations."@en ;
    askg-onto:inSentence "However, they target different classes of MDP representations and solution methods, and consequently, adopt different styles of translations."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_representations,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Bacchus et al. (1996) target state-based MDP representations. The equivalent MDP is first generated entirely - this involves the enumeration of all e-states and all transitions between them. Then, it is solved using traditional dynamic programming methods such as value or policy iteration. Because these methods are extremely sensitive to the number of states, attention is paid to producing a minimal equivalent **MDP (with the least number of** states). A first simple translation which we call pltlsim **produces a large MDP which can** be post-processed for minimisation before being solved. Another, which we call **pltlmin**, directly results in a minimal MDP, but relies on an expensive **pre-processing phase.** The second approach (Bacchus et al., 1997), which we call pltlstr**, targets structured** MDP representations: the transition model, policies, reward and value functions are represented in a compact form, e.g. as trees or algebraic decision **diagrams (ADDs) (Hoey et al.,** 1999; Boutilier et al., 2000). For instance, the probability of a given proposition (state variable) being true after the execution of an action is specified by a tree whose internal nodes are labelled with the state variables on whose previous values the given variable depends, whose arcs are labelled by the possible previous values (⊤ or ⊥**) of these variables,** and whose leaves are labelled with probabilities. The translation amounts to augmenting the structured MDP with new temporal **variables tracking the relevant properties of state** sequences, together with the compact representation of (1) **their dynamics, e.g. as trees over** the previous values of relevant variables, and (2) of the non-Markovian reward function in terms of the variables' current values. Then, structured solution methods such as structured policy iteration or the SPUDD algorithm are run on the resulting structured MDP. Neither the translation nor the solution methods explicitly enumerates the states."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1521,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15210,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15211,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15212,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15213,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1522,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1523,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1524,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1525,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1526,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1527,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1528,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1529 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Bacchus et al."@en ;
    askg-onto:inSentence "Bacchus et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bacchus_et_al .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "The translation amounts to augmenting the structured MDP with new temporal **variables tracking the relevant properties of state** sequences, together with the compact representation of (1) **their dynamics, e.g."@en ;
    askg-onto:inSentence "The translation amounts to augmenting the structured MDP with new temporal **variables tracking the relevant properties of state** sequences, together with the compact representation of (1) **their dynamics, e.g."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-properties_of_state_sequences,
        askg-data:Entity-temporal_variables .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15211 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "as trees over** the previous values of relevant variables, and (2) of the non-Markovian reward function in terms of the variables' current values."@en ;
    askg-onto:inSentence "as trees over** the previous values of relevant variables, and (2) of the non-Markovian reward function in terms of the variables' current values."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function,
        askg-data:Entity-non-markovian_reward_function .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15212 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Then, structured solution methods such as structured policy iteration or the SPUDD algorithm are run on the resulting structured MDP."@en ;
    askg-onto:inSentence "Then, structured solution methods such as structured policy iteration or the SPUDD algorithm are run on the resulting structured MDP."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-spudd_algorithm,
        askg-data:Entity-structured_mdp,
        askg-data:Entity-structured_policy_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-15213 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Neither the translation nor the solution methods explicitly enumerates the states."@en ;
    askg-onto:inSentence "Neither the translation nor the solution methods explicitly enumerates the states."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-solution_methods,
        askg-data:Entity-states,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1996) target state-based MDP representations."@en ;
    askg-onto:inSentence "(1996) target state-based MDP representations."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996,
        askg-data:Entity-state-based_mdp_representations .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The equivalent MDP is first generated entirely - this involves the enumeration of all e-states and all transitions between them."@en ;
    askg-onto:inSentence "The equivalent MDP is first generated entirely - this involves the enumeration of all e-states and all transitions between them."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-mdp,
        askg-data:Entity-transitions .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Then, it is solved using traditional dynamic programming methods such as value or policy iteration."@en ;
    askg-onto:inSentence "Then, it is solved using traditional dynamic programming methods such as value or policy iteration."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-traditional_dynamic_programming_methods,
        askg-data:Entity-value_or_policy_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Because these methods are extremely sensitive to the number of states, attention is paid to producing a minimal equivalent **MDP (with the least number of** states)."@en ;
    askg-onto:inSentence "Because these methods are extremely sensitive to the number of states, attention is paid to producing a minimal equivalent **MDP (with the least number of** states)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-model .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1526 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "A first simple translation which we call pltlsim **produces a large MDP which can** be post-processed for minimisation before being solved."@en ;
    askg-onto:inSentence "A first simple translation which we call pltlsim **produces a large MDP which can** be post-processed for minimisation before being solved."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-large_mdp,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1527 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Another, which we call **pltlmin**, directly results in a minimal MDP, but relies on an expensive **pre-processing phase.** The second approach (Bacchus et al., 1997), which we call pltlstr**, targets structured** MDP representations: the transition model, policies, reward and value functions are represented in a compact form, e.g."@en ;
    askg-onto:inSentence "Another, which we call **pltlmin**, directly results in a minimal MDP, but relies on an expensive **pre-processing phase.** The second approach (Bacchus et al., 1997), which we call pltlstr**, targets structured** MDP representations: the transition model, policies, reward and value functions are represented in a compact form, e.g."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compact_form,
        askg-data:Entity-minimal_mdp,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-policies,
        askg-data:Entity-pre-processing_phase,
        askg-data:Entity-reward_and_value_functions,
        askg-data:Entity-structured_mdp_representations,
        askg-data:Entity-transition_model .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1528 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "as trees or algebraic decision **diagrams (ADDs) (Hoey et al.,** 1999; Boutilier et al., 2000)."@en ;
    askg-onto:inSentence "as trees or algebraic decision **diagrams (ADDs) (Hoey et al.,** 1999; Boutilier et al., 2000)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1999,
        askg-data:Entity-2000,
        askg-data:Entity-algebraic_decision_diagrams,
        askg-data:Entity-boutilier_et_al,
        askg-data:Entity-hoey_et_al,
        askg-data:Entity-trees .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-152-Sentence-1529 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "For instance, the probability of a given proposition (state variable) being true after the execution of an action is specified by a tree whose internal nodes are labelled with the state variables on whose previous values the given variable depends, whose arcs are labelled by the possible previous values (⊤ or ⊥**) of these variables,** and whose leaves are labelled with probabilities."@en ;
    askg-onto:inSentence "For instance, the probability of a given proposition (state variable) being true after the execution of an action is specified by a tree whose internal nodes are labelled with the state variables on whose previous values the given variable depends, whose arcs are labelled by the possible previous values (⊤ or ⊥**) of these variables,** and whose leaves are labelled with probabilities."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_tree,
        askg-data:Entity-arcs,
        askg-data:Entity-internal_nodes,
        askg-data:Entity-leaves,
        askg-data:Entity-previous_values,
        askg-data:Entity-probabilities,
        askg-data:Entity-proposition,
        askg-data:Entity-state_variables .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-153 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "We now review these approaches in some detail. The reader is referred to the respective papers for additional information."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-153-Sentence-1531,
        askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-153-Sentence-1532 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-153-Sentence-1531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We now review these approaches in some detail."@en ;
    askg-onto:inSentence "We now review these approaches in some detail."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-these_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-15-Paragraph-153-Sentence-1532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The reader is referred to the respective papers for additional information."@en ;
    askg-onto:inSentence "The reader is referred to the respective papers for additional information."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-papers,
        askg-data:Entity-reader .

askg-data:Paper-c253584c3f1ff2a2-Section-16 a askg-onto:Section ;
    rdfs:label "Section 16"@en ;
    domo:Text "2.2.1 Representing Rewards With Pltl"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161 ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The syntax of PLTL, the language chosen to represent rewarding behaviours, is that of propositional logic, augmented with the operators ⊖ (previously) and S (since) (see Emerson, 1990). Whereas a classical propositional logic formula denotes a set of states (a subset of S), a PLTL formula denotes a set of finite sequences **of states (a subset of** S ∗**). A formula** without temporal modality expresses a property that must be **true of the current state, i.e.,** the last state of the finite sequence. ⊖f specifies that f **holds in the previous state (the** state one before the last). f1 S f2, requires f2 to have been true at some point in the sequence, and, unless that point is the present, f1 **to have held ever since. More formally, the** modelling relation |= stating whether a formula f holds of a finite sequence Γ(i**) is defined** recursively as follows: - Γ(i) |= p iff p ∈ Γi, for p ∈ P**, the set of atomic propositions** - Γ(i) |= ¬f **iff Γ(**i) 6|= f - Γ(i) |= f1 ∧ f2 iff Γ(i) |= f1 **and Γ(**i) |= f2 - Γ(i) |= ⊖f iff i > **0 and Γ(**i − 1) |= f - Γ(i) |= f1 S f2 iff ∃j ≤ i, Γ(j) |= f2 and ∀**k,j < k** ≤ i, Γ(k) |= f1 From S, one can define the useful operators ♦- f ≡ ⊤ S f meaning that f **has been true at** some point, and ⊟f ≡ ¬♦- ¬f meaning that f has always been true. E.g, g ∧ ¬⊖ ♦- g **denotes** the set of finite sequences ending in a state where g **is true for the first time in the sequence.** Other useful abbreviation are ⊖k(k times ago), for k iterations of the ⊖ modality, ♦- kf for ∨ k i=1 ⊖i f (f was true at some of the k last steps), and ⊟kf for ∧ k i=1 ⊖i f (f **was true at all** the k **last steps).** Non-Markovian reward functions are described with a set of pairs (fi: ri**) where** fiis a PLTL reward formula and ri**is a real, with the semantics that the reward assigned to a** sequence in S ∗is the sum of the ri's for which that sequence is a model of fi**. Below, we let** F denote the set of reward formulae fi**in the description of the reward function. Bacchus** et al. (1996) give a list of behaviours which it might be useful to reward, together with their expression in PLTL. For instance, where f is an atemporal formula, (f : r**) rewards** with r units the achievement of f **whenever it happens. This is a Markovian reward. In** contrast (♦- f : r) rewards every state following (and including) the achievement of f**, while** (f ∧¬⊖♦- f : r) only rewards the first occurrence of f. (f ∧⊟k¬f : r**) rewards the occurrence** of f at most once every k steps. (⊖n¬ ⊖ ⊥ : r**) rewards the** n th **state, independently of** its properties. (⊖2f1 ∧ ⊖f2 ∧ f3 : r) rewards the occurrence of f1 **immediately followed by** f2 and then f3. In reactive planning, so-called response **formulae which describe that the** achievement of f is triggered by a condition (or command) c **are particularly useful. These** can be written as (f ∧ ♦- c : r) if every state in which f **is true following the first issue of** the command is to be rewarded. Alternatively, they can be written as (f ∧ ⊖(¬f S c) : r**) if** only the first occurrence of f **is to be rewarded after each command. It is common to only** reward the achievement f within k **steps of the trigger; we write for example (**f ∧ ♦- kc : r) to reward all such states in which f **holds.** From a theoretical point of view, it is known (Lichtenstein, **Pnueli, & Zuck, 1985) that** the behaviours representable in PLTL are exactly those corresponding to star-free regular languages. Non star-free behaviours such as (pp)∗ **(reward an even number of states all** containing p**) are therefore not representable. Nor, of course, are non-regular behaviours** such as p nq n**(e.g. reward taking equal numbers of steps to the left and right). We shall not** speculate here on how severe a restriction this is for the purposes of planning."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1611,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16110,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16111,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16112,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16113,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16114,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16115,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16116,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16117,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16118,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16119,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1612,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16120,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16121,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16122,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16123,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16124,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1613,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1614,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1615,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1616,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1617,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1618,
        askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1619 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The syntax of PLTL, the language chosen to represent rewarding behaviours, is that of propositional logic, augmented with the operators ⊖ (previously) and S (since) (see Emerson, 1990)."@en ;
    askg-onto:inSentence "The syntax of PLTL, the language chosen to represent rewarding behaviours, is that of propositional logic, augmented with the operators ⊖ (previously) and S (since) (see Emerson, 1990)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1990,
        askg-data:Entity-emerson,
        askg-data:Entity-operators__and_s,
        askg-data:Entity-pltl,
        askg-data:Entity-propositional_logic .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(1996) give a list of behaviours which it might be useful to reward, together with their expression in PLTL."@en ;
    askg-onto:inSentence "(1996) give a list of behaviours which it might be useful to reward, together with their expression in PLTL."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-expression_in_pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "For instance, where f is an atemporal formula, (f : r**) rewards** with r units the achievement of f **whenever it happens."@en ;
    askg-onto:inSentence "For instance, where f is an atemporal formula, (f : r**) rewards** with r units the achievement of f **whenever it happens."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-r_units .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "This is a Markovian reward."@en ;
    askg-onto:inSentence "This is a Markovian reward."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-markovian_reward,
        askg-data:Entity-model .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "In** contrast (♦- f : r) rewards every state following (and including) the achievement of f**, while** (f ∧¬⊖♦- f : r) only rewards the first occurrence of f."@en ;
    askg-onto:inSentence "In** contrast (♦- f : r) rewards every state following (and including) the achievement of f**, while** (f ∧¬⊖♦- f : r) only rewards the first occurrence of f."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievement_of_f,
        askg-data:Entity-f_-_f__r,
        askg-data:Entity-first_occurrence_of_f,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "(f ∧⊟k¬f : r**) rewards the occurrence** of f at most once every k steps."@en ;
    askg-onto:inSentence "(f ∧⊟k¬f : r**) rewards the occurrence** of f at most once every k steps."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-k_steps .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "(⊖n¬ ⊖ ⊥ : r**) rewards the** n th **state, independently of** its properties."@en ;
    askg-onto:inSentence "(⊖n¬ ⊖ ⊥ : r**) rewards the** n th **state, independently of** its properties."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n__,
        askg-data:Entity-n_th_state .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "(⊖2f1 ∧ ⊖f2 ∧ f3 : r) rewards the occurrence of f1 **immediately followed by** f2 and then f3."@en ;
    askg-onto:inSentence "(⊖2f1 ∧ ⊖f2 ∧ f3 : r) rewards the occurrence of f1 **immediately followed by** f2 and then f3."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2f1,
        askg-data:Entity-f2,
        askg-data:Entity-f3 .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16117 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "In reactive planning, so-called response **formulae which describe that the** achievement of f is triggered by a condition (or command) c **are particularly useful."@en ;
    askg-onto:inSentence "In reactive planning, so-called response **formulae which describe that the** achievement of f is triggered by a condition (or command) c **are particularly useful."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievement_of_f,
        askg-data:Entity-command,
        askg-data:Entity-condition_c,
        askg-data:Entity-reactive_planning .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16118 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "These** can be written as (f ∧ ♦- c : r) if every state in which f **is true following the first issue of** the command is to be rewarded."@en ;
    askg-onto:inSentence "These** can be written as (f ∧ ♦- c : r) if every state in which f **is true following the first issue of** the command is to be rewarded."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-command,
        askg-data:Entity-every_state,
        askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16119 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Alternatively, they can be written as (f ∧ ⊖(¬f S c) : r**) if** only the first occurrence of f **is to be rewarded after each command."@en ;
    askg-onto:inSentence "Alternatively, they can be written as (f ∧ ⊖(¬f S c) : r**) if** only the first occurrence of f **is to be rewarded after each command."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Whereas a classical propositional logic formula denotes a set of states (a subset of S), a PLTL formula denotes a set of finite sequences **of states (a subset of** S ∗**)."@en ;
    askg-onto:inSentence "Whereas a classical propositional logic formula denotes a set of states (a subset of S), a PLTL formula denotes a set of finite sequences **of states (a subset of** S ∗**)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classical_propositional_logic_formula,
        askg-data:Entity-pltl_formula,
        askg-data:Entity-set_of_finite_sequences_of_states,
        askg-data:Entity-set_of_states .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16120 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "It is common to only** reward the achievement f within k **steps of the trigger; we write for example (**f ∧ ♦- kc : r) to reward all such states in which f **holds.** From a theoretical point of view, it is known (Lichtenstein, **Pnueli, & Zuck, 1985) that** the behaviours representable in PLTL are exactly those corresponding to star-free regular languages."@en ;
    askg-onto:inSentence "It is common to only** reward the achievement f within k **steps of the trigger; we write for example (**f ∧ ♦- kc : r) to reward all such states in which f **holds.** From a theoretical point of view, it is known (Lichtenstein, **Pnueli, & Zuck, 1985) that** the behaviours representable in PLTL are exactly those corresponding to star-free regular languages."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lichtenstein,
        askg-data:Entity-pltl,
        askg-data:Entity-pnueli__zuck_1985,
        askg-data:Entity-star-free_regular_languages .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16121 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Non star-free behaviours such as (pp)∗ **(reward an even number of states all** containing p**) are therefore not representable."@en ;
    askg-onto:inSentence "Non star-free behaviours such as (pp)∗ **(reward an even number of states all** containing p**) are therefore not representable."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non_star-free_behaviours,
        askg-data:Entity-pp_reward_an_even_number_of_states_all_containing_p .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16122 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Nor, of course, are non-regular behaviours** such as p nq n**(e.g."@en ;
    askg-onto:inSentence "Nor, of course, are non-regular behaviours** such as p nq n**(e.g."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-regular_behaviours,
        askg-data:Entity-p_nq_n .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16123 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "reward taking equal numbers of steps to the left and right)."@en ;
    askg-onto:inSentence "reward taking equal numbers of steps to the left and right)."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward,
        askg-data:Entity-steps .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-16124 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "We shall not** speculate here on how severe a restriction this is for the purposes of planning."@en ;
    askg-onto:inSentence "We shall not** speculate here on how severe a restriction this is for the purposes of planning."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planning,
        askg-data:Entity-restriction .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A formula** without temporal modality expresses a property that must be **true of the current state, i.e.,** the last state of the finite sequence."@en ;
    askg-onto:inSentence "A formula** without temporal modality expresses a property that must be **true of the current state, i.e.,** the last state of the finite sequence."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_state,
        askg-data:Entity-finite_sequence,
        askg-data:Entity-formula,
        askg-data:Entity-last_state,
        askg-data:Entity-property .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "⊖f specifies that f **holds in the previous state (the** state one before the last)."@en ;
    askg-onto:inSentence "⊖f specifies that f **holds in the previous state (the** state one before the last)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-the_previous_state .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "f1 S f2, requires f2 to have been true at some point in the sequence, and, unless that point is the present, f1 **to have held ever since."@en ;
    askg-onto:inSentence "f1 S f2, requires f2 to have been true at some point in the sequence, and, unless that point is the present, f1 **to have held ever since."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f1,
        askg-data:Entity-f2 .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1616 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "More formally, the** modelling relation |= stating whether a formula f holds of a finite sequence Γ(i**) is defined** recursively as follows: - Γ(i) |= p iff p ∈ Γi, for p ∈ P**, the set of atomic propositions** - Γ(i) |= ¬f **iff Γ(**i) 6|= f - Γ(i) |= f1 ∧ f2 iff Γ(i) |= f1 **and Γ(**i) |= f2 - Γ(i) |= ⊖f iff i > **0 and Γ(**i − 1) |= f - Γ(i) |= f1 S f2 iff ∃j ≤ i, Γ(j) |= f2 and ∀**k,j < k** ≤ i, Γ(k) |= f1 From S, one can define the useful operators ♦- f ≡ ⊤ S f meaning that f **has been true at** some point, and ⊟f ≡ ¬♦- ¬f meaning that f has always been true."@en ;
    askg-onto:inSentence "More formally, the** modelling relation |= stating whether a formula f holds of a finite sequence Γ(i**) is defined** recursively as follows: - Γ(i) |= p iff p ∈ Γi, for p ∈ P**, the set of atomic propositions** - Γ(i) |= ¬f **iff Γ(**i) 6|= f - Γ(i) |= f1 ∧ f2 iff Γ(i) |= f1 **and Γ(**i) |= f2 - Γ(i) |= ⊖f iff i > **0 and Γ(**i − 1) |= f - Γ(i) |= f1 S f2 iff ∃j ≤ i, Γ(j) |= f2 and ∀**k,j < k** ≤ i, Γ(k) |= f1 From S, one can define the useful operators ♦- f ≡ ⊤ S f meaning that f **has been true at** some point, and ⊟f ≡ ¬♦- ¬f meaning that f has always been true."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CE%B3i__1,
        askg-data:Entity--_f,
        askg-data:Entity-0,
        askg-data:Entity-f,
        askg-data:Entity-f1__f2,
        askg-data:Entity-f1_s_f2,
        askg-data:Entity-formula_f,
        askg-data:Entity-i,
        askg-data:Entity-modelling_relation,
        askg-data:Entity-p,
        askg-data:Entity-recursively,
        askg-data:Entity-s,
        askg-data:Entity-some_point,
        askg-data:Entity-useful_operators .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1617 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "E.g, g ∧ ¬⊖ ♦- g **denotes** the set of finite sequences ending in a state where g **is true for the first time in the sequence.** Other useful abbreviation are ⊖k(k times ago), for k iterations of the ⊖ modality, ♦- kf for ∨ k i=1 ⊖i f (f was true at some of the k last steps), and ⊟kf for ∧ k i=1 ⊖i f (f **was true at all** the k **last steps).** Non-Markovian reward functions are described with a set of pairs (fi: ri**) where** fiis a PLTL reward formula and ri**is a real, with the semantics that the reward assigned to a** sequence in S ∗is the sum of the ri's for which that sequence is a model of fi**."@en ;
    askg-onto:inSentence "E.g, g ∧ ¬⊖ ♦- g **denotes** the set of finite sequences ending in a state where g **is true for the first time in the sequence.** Other useful abbreviation are ⊖k(k times ago), for k iterations of the ⊖ modality, ♦- kf for ∨ k i=1 ⊖i f (f was true at some of the k last steps), and ⊟kf for ∧ k i=1 ⊖i f (f **was true at all** the k **last steps).** Non-Markovian reward functions are described with a set of pairs (fi: ri**) where** fiis a PLTL reward formula and ri**is a real, with the semantics that the reward assigned to a** sequence in S ∗is the sum of the ri's for which that sequence is a model of fi**."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity--,
        askg-data:Entity-a_set_of_pairs_fi_ri,
        askg-data:Entity-fi,
        askg-data:Entity-g,
        askg-data:Entity-k_iterations_of_the__modality,
        askg-data:Entity-kf_for__k_i1_i_f,
        askg-data:Entity-kk_times_ago,
        askg-data:Entity-non-markovian_reward_functions,
        askg-data:Entity-pltl_reward_formula,
        askg-data:Entity-real,
        askg-data:Entity-reward,
        askg-data:Entity-ri,
        askg-data:Entity-ris_for_which_that_sequence_is_a_model_of_fi,
        askg-data:Entity-sequence_in_s_,
        askg-data:Entity-set_of_finite_sequences_ending_in_a_state_where_g_is_true_for_the_first_time_in_the_sequence .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1618 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Below, we let** F denote the set of reward formulae fi**in the description of the reward function."@en ;
    askg-onto:inSentence "Below, we let** F denote the set of reward formulae fi**in the description of the reward function."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-set_of_reward_formulae_fi .

askg-data:Paper-c253584c3f1ff2a2-Section-16-Paragraph-161-Sentence-1619 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Bacchus** et al."@en ;
    askg-onto:inSentence "Bacchus** et al."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus,
        askg-data:Entity-et_al .

askg-data:Paper-c253584c3f1ff2a2-Section-17 a askg-onto:Section ;
    rdfs:label "Section 17"@en ;
    domo:Text "2.2.2 Principles Behind The Translations"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-172,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173 ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "All three translations into an MDP (pltlsim, pltlmin, and pltlstr) rely on the equivalence f1 S f2 ≡ f2 ∨ (f1 ∧ ⊖(f1 S f2**)), with which we can decompose temporal modalities** into a requirement about the last state Γi of a sequence Γ(i**), and a requirement about the** prefix Γ(i − 1) of the sequence. More precisely, given state s and a formula f, one can compute in2 O(||f||) a new formula Reg(f,s) called the regression of f through s**. Regression** has the property that, for i > 0, f is true of a finite sequence Γ(i) ending with Γi = s iff Reg(f,s) is true of the prefix Γ(i − 1). That is, Reg(f,s**) represents what must have been** true previously for f **to be true now. Reg is defined as follows:** - Reg(p,s) = ⊤ iff p ∈ s and ⊥ otherwise, for p ∈ P - Reg(¬f,s) = ¬Reg(f,s) - Reg(f1 ∧ f2,s) = Reg(f1,s) ∧ **Reg(**f2,s) - Reg(⊖f,s) = f - Reg(f1 S f2,s) = Reg(f2,s) ∨ **(Reg(**f1,s) ∧ (f1 S f2)) For instance, take a state s in which p holds and q does not, and take f = (⊖¬q) ∧ (p S q), meaning that q **must have been false 1 step ago, but that it must have held at some point** in the past and that p must have held since q last did. Reg(f,s) = ¬q ∧ (p S q**), that is,** for f to hold now, then at the previous stage, q had to be false and the p S q **requirement** still had to hold. When p and q are both false in s, then Reg(f,s) = ⊥**, indicating that** f cannot be satisfied, regardless of what came earlier in the sequence."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1711,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1712,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1713,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1714,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1715,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1716,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1717 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "All three translations into an MDP (pltlsim, pltlmin, and pltlstr) rely on the equivalence f1 S f2 ≡ f2 ∨ (f1 ∧ ⊖(f1 S f2**)), with which we can decompose temporal modalities** into a requirement about the last state Γi of a sequence Γ(i**), and a requirement about the** prefix Γ(i − 1) of the sequence."@en ;
    askg-onto:inSentence "All three translations into an MDP (pltlsim, pltlmin, and pltlstr) rely on the equivalence f1 S f2 ≡ f2 ∨ (f1 ∧ ⊖(f1 S f2**)), with which we can decompose temporal modalities** into a requirement about the last state Γi of a sequence Γ(i**), and a requirement about the** prefix Γ(i − 1) of the sequence."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equivalence_f1_s_f2__f2__f1__f1_s_f2,
        askg-data:Entity-last_state_%CE%B3i,
        askg-data:Entity-mdp,
        askg-data:Entity-prefix_%CE%B3i__1,
        askg-data:Entity-requirement_about_the_last_state_%CE%B3i_of_a_sequence_%CE%B3i,
        askg-data:Entity-sequence,
        askg-data:Entity-sequence_%CE%B3i,
        askg-data:Entity-temporal_modalities .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "More precisely, given state s and a formula f, one can compute in2 O(||f||) a new formula Reg(f,s) called the regression of f through s**."@en ;
    askg-onto:inSentence "More precisely, given state s and a formula f, one can compute in2 O(||f||) a new formula Reg(f,s) called the regression of f through s**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula_f,
        askg-data:Entity-regfs,
        askg-data:Entity-state_s .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Regression** has the property that, for i > 0, f is true of a finite sequence Γ(i) ending with Γi = s iff Reg(f,s) is true of the prefix Γ(i − 1)."@en ;
    askg-onto:inSentence "Regression** has the property that, for i > 0, f is true of a finite sequence Γ(i) ending with Γi = s iff Reg(f,s) is true of the prefix Γ(i − 1)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CE%B3i__s,
        askg-data:Entity-f_is_true_of_a_finite_sequence_%CE%B3i,
        askg-data:Entity-regfs,
        askg-data:Entity-regression,
        askg-data:Entity-the_prefix_%CE%B3i__1 .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "That is, Reg(f,s**) represents what must have been** true previously for f **to be true now."@en ;
    askg-onto:inSentence "That is, Reg(f,s**) represents what must have been** true previously for f **to be true now."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-regfs,
        askg-data:Entity-what_must_have_been_true_previously_for_f_to_be_true_now .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Reg is defined as follows:** - Reg(p,s) = ⊤ iff p ∈ s and ⊥ otherwise, for p ∈ P - Reg(¬f,s) = ¬Reg(f,s) - Reg(f1 ∧ f2,s) = Reg(f1,s) ∧ **Reg(**f2,s) - Reg(⊖f,s) = f - Reg(f1 S f2,s) = Reg(f2,s) ∨ **(Reg(**f1,s) ∧ (f1 S f2)) For instance, take a state s in which p holds and q does not, and take f = (⊖¬q) ∧ (p S q), meaning that q **must have been false 1 step ago, but that it must have held at some point** in the past and that p must have held since q last did."@en ;
    askg-onto:inSentence "Reg is defined as follows:** - Reg(p,s) = ⊤ iff p ∈ s and ⊥ otherwise, for p ∈ P - Reg(¬f,s) = ¬Reg(f,s) - Reg(f1 ∧ f2,s) = Reg(f1,s) ∧ **Reg(**f2,s) - Reg(⊖f,s) = f - Reg(f1 S f2,s) = Reg(f2,s) ∨ **(Reg(**f1,s) ∧ (f1 S f2)) For instance, take a state s in which p holds and q does not, and take f = (⊖¬q) ∧ (p S q), meaning that q **must have been false 1 step ago, but that it must have held at some point** in the past and that p must have held since q last did."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-false_1_step_ago,
        askg-data:Entity-p,
        askg-data:Entity-p_holds_and_q_does_not,
        askg-data:Entity-q,
        askg-data:Entity-q__p_s_q,
        askg-data:Entity-reg,
        askg-data:Entity-regf1__f2s__regf1s__regf2s,
        askg-data:Entity-regf1_s_f2s__regf2s__regf1s__f1_s_f2,
        askg-data:Entity-regfs__f,
        askg-data:Entity-regfs__regfs,
        askg-data:Entity-regps___iff_p__s_and__otherwise,
        askg-data:Entity-s,
        askg-data:Entity-since_q_last_did .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1716 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Reg(f,s) = ¬q ∧ (p S q**), that is,** for f to hold now, then at the previous stage, q had to be false and the p S q **requirement** still had to hold."@en ;
    askg-onto:inSentence "Reg(f,s) = ¬q ∧ (p S q**), that is,** for f to hold now, then at the previous stage, q had to be false and the p S q **requirement** still had to hold."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-p_s_q,
        askg-data:Entity-q__p_s_q,
        askg-data:Entity-regfs,
        askg-data:Entity-still_holds .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-171-Sentence-1717 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "When p and q are both false in s, then Reg(f,s) = ⊥**, indicating that** f cannot be satisfied, regardless of what came earlier in the sequence."@en ;
    askg-onto:inSentence "When p and q are both false in s, then Reg(f,s) = ⊥**, indicating that** f cannot be satisfied, regardless of what came earlier in the sequence."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f_cannot_be_satisfied,
        askg-data:Entity-regfs .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-172 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For notational convenience, where X is a set of formulae we write X for X∪{¬x | x ∈ X}."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-172-Sentence-1721 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-172-Sentence-1721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For notational convenience, where X is a set of formulae we write X for X∪{¬x | x ∈ X}."@en ;
    askg-onto:inSentence "For notational convenience, where X is a set of formulae we write X for X∪{¬x | x ∈ X}."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-x,
        askg-data:Entity-x__x__x .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Now the translations exploit the PLTL representation of rewards as follows. Each expanded state (e-state) in the generated MDP can be seen as labelled with a set Ψ ⊆ Sub(F**) of** subformulae of the reward formulae in F **(and their negations). The subformulae in Ψ must** be (1) true of the paths leading to the e-state, and (2) sufficient to determine the current truth of all reward formulae in F**, as this is needed to compute the current reward. Ideally** the Ψs should also be (3) small enough to enable just that, i.e. they should not contain subformulae which draw history distinctions that are irrelevant to determining the reward at one point or another. Note however that in the worst-case, **the number of distinctions** needed, even in the minimal equivalent MDP, may be exponential in ||F||**. This happens for** instance with the formula ⊖kf, which requires k **additional bits of information memorising** the truth of f over the last k **steps.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1731,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1732,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1733,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1734,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1735,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1736,
        askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1737 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Now the translations exploit the PLTL representation of rewards as follows."@en ;
    askg-onto:inSentence "Now the translations exploit the PLTL representation of rewards as follows."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_representation_of_rewards,
        askg-data:Entity-translations .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Each expanded state (e-state) in the generated MDP can be seen as labelled with a set Ψ ⊆ Sub(F**) of** subformulae of the reward formulae in F **(and their negations)."@en ;
    askg-onto:inSentence "Each expanded state (e-state) in the generated MDP can be seen as labelled with a set Ψ ⊆ Sub(F**) of** subformulae of the reward formulae in F **(and their negations)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expanded_state_e-state,
        askg-data:Entity-set_%CF%88__subf_of_subformulae_of_the_reward_formulae_in_f .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The subformulae in Ψ must** be (1) true of the paths leading to the e-state, and (2) sufficient to determine the current truth of all reward formulae in F**, as this is needed to compute the current reward."@en ;
    askg-onto:inSentence "The subformulae in Ψ must** be (1) true of the paths leading to the e-state, and (2) sufficient to determine the current truth of all reward formulae in F**, as this is needed to compute the current reward."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward_formulae_in_f,
        askg-data:Entity-subformulae_in_%CF%88,
        askg-data:Entity-sufficient_to_determine_the_current_truth_of_all_reward_formulae_in_f,
        askg-data:Entity-the_current_reward,
        askg-data:Entity-true_of_the_paths_leading_to_the_e-state .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Ideally** the Ψs should also be (3) small enough to enable just that, i.e."@en ;
    askg-onto:inSentence "Ideally** the Ψs should also be (3) small enough to enable just that, i.e."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%88s,
        askg-data:Entity-small_enough .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1735 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "they should not contain subformulae which draw history distinctions that are irrelevant to determining the reward at one point or another."@en ;
    askg-onto:inSentence "they should not contain subformulae which draw history distinctions that are irrelevant to determining the reward at one point or another."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-history_distinctions,
        askg-data:Entity-subformulae .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1736 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Note however that in the worst-case, **the number of distinctions** needed, even in the minimal equivalent MDP, may be exponential in ||F||**."@en ;
    askg-onto:inSentence "Note however that in the worst-case, **the number of distinctions** needed, even in the minimal equivalent MDP, may be exponential in ||F||**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-the_minimal_equivalent_mdp,
        askg-data:Entity-the_number_of_distinctions .

askg-data:Paper-c253584c3f1ff2a2-Section-17-Paragraph-173-Sentence-1737 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "This happens for** instance with the formula ⊖kf, which requires k **additional bits of information memorising** the truth of f over the last k **steps.**"@en ;
    askg-onto:inSentence "This happens for** instance with the formula ⊖kf, which requires k **additional bits of information memorising** the truth of f over the last k **steps.**"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_bits_of_information_memorising_the_truth_of_f_over_the_last_k_steps,
        askg-data:Entity-formula_kf .

askg-data:Paper-c253584c3f1ff2a2-Section-18 a askg-onto:Section ;
    rdfs:label "Section 18"@en ;
    domo:Text "2.2.3 Pltlsim"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-183,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-184,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-187 ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "For the choice of the Ψs, Bacchus et al. (1996) consider two cases. In the simple case, which we call pltlsim**, an MDP obeying properties (1) and (2) is produced by simply labelling** each e-state with the set of all subformulae in Sub(F**) which are true of the sequence leading** to that e-state. This MDP is generated forward, starting from the initial e-state labelled with s0 and with the set Ψ0 ⊆ Sub(F**) of all subformulae which are true of the sequence** hs0i. The successors of any e-state labelled by NMRDP state s **and subformula set Ψ are** generated as follows: each of them is labelled by a successor s ′ of s **in the NMRDP and by** the set of subformulae {ψ ′ ∈ Sub(F) | Ψ |**= Reg(**ψ ′,s′)}."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1811,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1812,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1813,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1814,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1815 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For the choice of the Ψs, Bacchus et al."@en ;
    askg-onto:inSentence "For the choice of the Ψs, Bacchus et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%88s,
        askg-data:Entity-bacchus_et_al .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1996) consider two cases."@en ;
    askg-onto:inSentence "(1996) consider two cases."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-two_cases .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In the simple case, which we call pltlsim**, an MDP obeying properties (1) and (2) is produced by simply labelling** each e-state with the set of all subformulae in Sub(F**) which are true of the sequence leading** to that e-state."@en ;
    askg-onto:inSentence "In the simple case, which we call pltlsim**, an MDP obeying properties (1) and (2) is produced by simply labelling** each e-state with the set of all subformulae in Sub(F**) which are true of the sequence leading** to that e-state."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-mdp,
        askg-data:Entity-pltlsim,
        askg-data:Entity-sequence_leading_to_e-state,
        askg-data:Entity-set_of_all_subformulae_in_subf,
        askg-data:Entity-subformulae_in_subf .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This MDP is generated forward, starting from the initial e-state labelled with s0 and with the set Ψ0 ⊆ Sub(F**) of all subformulae which are true of the sequence** hs0i."@en ;
    askg-onto:inSentence "This MDP is generated forward, starting from the initial e-state labelled with s0 and with the set Ψ0 ⊆ Sub(F**) of all subformulae which are true of the sequence** hs0i."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_subformulae,
        askg-data:Entity-initial_e-state,
        askg-data:Entity-mdp,
        askg-data:Entity-s0,
        askg-data:Entity-sequence_hs0i,
        askg-data:Entity-set_%CF%880,
        askg-data:Entity-subf,
        askg-data:Entity-subformulae .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-181-Sentence-1815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The successors of any e-state labelled by NMRDP state s **and subformula set Ψ are** generated as follows: each of them is labelled by a successor s ′ of s **in the NMRDP and by** the set of subformulae {ψ ′ ∈ Sub(F) | Ψ |**= Reg(**ψ ′,s′)}."@en ;
    askg-onto:inSentence "The successors of any e-state labelled by NMRDP state s **and subformula set Ψ are** generated as follows: each of them is labelled by a successor s ′ of s **in the NMRDP and by** the set of subformulae {ψ ′ ∈ Sub(F) | Ψ |**= Reg(**ψ ′,s′)}."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdp,
        askg-data:Entity-state_s,
        askg-data:Entity-subformula_set_%CF%88,
        askg-data:Entity-subformulae_%CF%88__subf__%CF%88__reg%CF%88s,
        askg-data:Entity-successor_s .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For instance, consider the NMRDP shown in Figure 3. The set F = {q∧⊖⊖p} **consists of** a single reward formula. The set Sub(F**) consists of all subformulae of this reward formula,**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182-Sentence-1821,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182-Sentence-1822,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182-Sentence-1823 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182-Sentence-1821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For instance, consider the NMRDP shown in Figure 3."@en ;
    askg-onto:inSentence "For instance, consider the NMRDP shown in Figure 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_3,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182-Sentence-1822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The set F = {q∧⊖⊖p} **consists of** a single reward formula."@en ;
    askg-onto:inSentence "The set F = {q∧⊖⊖p} **consists of** a single reward formula."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_single_reward_formula,
        askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-182-Sentence-1823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The set Sub(F**) consists of all subformulae of this reward formula,**"@en ;
    askg-onto:inSentence "The set Sub(F**) consists of all subformulae of this reward formula,**"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_subformulae_of_this_reward_formula,
        askg-data:Entity-subf .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-183 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "2. The size ||f|| of a reward formula is measured as its length and the size ||F|| **of a set of reward formulae** F **is measured as the sum of the lengths of the formulae in** F."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-183-Sentence-1831,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-183-Sentence-1832 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-183-Sentence-1831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2."@en ;
    askg-onto:inSentence "2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-field,
        askg-data:Entity-research,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-183-Sentence-1832 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The size ||f|| of a reward formula is measured as its length and the size ||F|| **of a set of reward formulae** F **is measured as the sum of the lengths of the formulae in** F."@en ;
    askg-onto:inSentence "The size ||f|| of a reward formula is measured as its length and the size ||F|| **of a set of reward formulae** F **is measured as the sum of the lengths of the formulae in** F."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-its_length,
        askg-data:Entity-reward_formula,
        askg-data:Entity-set_of_reward_formulae,
        askg-data:Entity-the_sum_of_the_lengths_of_the_formulae_in_f .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-184 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![10_image_0.png](10_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-184-Sentence-1841 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-184-Sentence-1841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![10_image_0.png](10_image_0.png)"@en ;
    askg-onto:inSentence "![10_image_0.png](10_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_science,
        askg-data:Entity-computer_vision,
        askg-data:Entity-deep_learning,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "In the initial state, both p and q **are false.** When p is false, action a **independently sets** p and q **to true with probability 0.8. When** both p and q are false, action b sets q **to true** with probability 0.8. Both actions have"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185-Sentence-1851,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185-Sentence-1852,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185-Sentence-1853 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185-Sentence-1851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the initial state, both p and q **are false.** When p is false, action a **independently sets** p and q **to true with probability 0.8."@en ;
    askg-onto:inSentence "In the initial state, both p and q **are false.** When p is false, action a **independently sets** p and q **to true with probability 0.8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-08,
        askg-data:Entity-false,
        askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-true .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185-Sentence-1852 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "When** both p and q are false, action b sets q **to true** with probability 0.8."@en ;
    askg-onto:inSentence "When** both p and q are false, action b sets q **to true** with probability 0.8."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-185-Sentence-1853 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Both actions have"@en ;
    askg-onto:inSentence "Both actions have"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "no effect otherwise. A reward is obtained whenever q ∧ ⊖ ⊖ p**. The optimal policy** is to apply b until q **gets produced, making** sure to avoid the state on the left-hand side, then to apply a until p **gets produced, and** then to apply a or b **indifferently forever.** Figure 3: Another Simple NMRDP"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186-Sentence-1861,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186-Sentence-1862,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186-Sentence-1863 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186-Sentence-1861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "no effect otherwise."@en ;
    askg-onto:inSentence "no effect otherwise."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-no_effect .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186-Sentence-1862 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A reward is obtained whenever q ∧ ⊖ ⊖ p**."@en ;
    askg-onto:inSentence "A reward is obtained whenever q ∧ ⊖ ⊖ p**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-186-Sentence-1863 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The optimal policy** is to apply b until q **gets produced, making** sure to avoid the state on the left-hand side, then to apply a until p **gets produced, and** then to apply a or b **indifferently forever.** Figure 3: Another Simple NMRDP"@en ;
    askg-onto:inSentence "The optimal policy** is to apply b until q **gets produced, making** sure to avoid the state on the left-hand side, then to apply a until p **gets produced, and** then to apply a or b **indifferently forever.** Figure 3: Another Simple NMRDP"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-another_simple_nmrdp,
        askg-data:Entity-apply_a,
        askg-data:Entity-apply_a_or_b,
        askg-data:Entity-b_until_q_gets_produced,
        askg-data:Entity-figure_3,
        askg-data:Entity-indifferently_forever,
        askg-data:Entity-optimal_policy,
        askg-data:Entity-p_gets_produced .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-187 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "and their negations, that is Sub(F) = {**p,q,** ⊖p, ⊖ ⊖ p,q ∧ ⊖ ⊖ p,¬p,¬q,¬ ⊖ p,¬ ⊖ ⊖p,¬(q ∧ ⊖ ⊖ p)}. The equivalent MDP produced by pltlsim **is shown in Figure 4.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-187-Sentence-1871,
        askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-187-Sentence-1872 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-187-Sentence-1871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and their negations, that is Sub(F) = {**p,q,** ⊖p, ⊖ ⊖ p,q ∧ ⊖ ⊖ p,¬p,¬q,¬ ⊖ p,¬ ⊖ ⊖p,¬(q ∧ ⊖ ⊖ p)}."@en ;
    askg-onto:inSentence "and their negations, that is Sub(F) = {**p,q,** ⊖p, ⊖ ⊖ p,q ∧ ⊖ ⊖ p,¬p,¬q,¬ ⊖ p,¬ ⊖ ⊖p,¬(q ∧ ⊖ ⊖ p)}."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-set_of_negations,
        askg-data:Entity-subf .

askg-data:Paper-c253584c3f1ff2a2-Section-18-Paragraph-187-Sentence-1872 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The equivalent MDP produced by pltlsim **is shown in Figure 4.**"@en ;
    askg-onto:inSentence "The equivalent MDP produced by pltlsim **is shown in Figure 4.**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-19 a askg-onto:Section ;
    rdfs:label "Section 19"@en ;
    domo:Text "2.2.4 Pltlmin"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193 ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Unfortunately, the MDPs produced by pltlsim **are far from minimal. Although they could** be postprocessed for minimisation before invoking the MDP solution method, the above expansion may still constitute a serious bottleneck. Therefore, Bacchus et al. (1996) consider a more complex two-phase translation, which we call pltlmin**, capable of producing an** MDP also satisfying property (3). Here, a preprocessing phase iterates over all states in S, and computes, for each state s, a set l(s) of subformulae, where the function l **is the** solution of the fixpoint equation l(s) = F ∪ {**Reg(**ψ ′,s′) | ψ ′ ∈ l(s ′),s′**is a successor of** s}."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1911,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1912,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1913,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1914,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1915 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Unfortunately, the MDPs produced by pltlsim **are far from minimal."@en ;
    askg-onto:inSentence "Unfortunately, the MDPs produced by pltlsim **are far from minimal."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdps,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Although they could** be postprocessed for minimisation before invoking the MDP solution method, the above expansion may still constitute a serious bottleneck."@en ;
    askg-onto:inSentence "Although they could** be postprocessed for minimisation before invoking the MDP solution method, the above expansion may still constitute a serious bottleneck."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_solution_method,
        askg-data:Entity-postprocessed_for_minimisation .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Therefore, Bacchus et al."@en ;
    askg-onto:inSentence "Therefore, Bacchus et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(1996) consider a more complex two-phase translation, which we call pltlmin**, capable of producing an** MDP also satisfying property (3)."@en ;
    askg-onto:inSentence "(1996) consider a more complex two-phase translation, which we call pltlmin**, capable of producing an** MDP also satisfying property (3)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-pltlmin,
        askg-data:Entity-property_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-191-Sentence-1915 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Here, a preprocessing phase iterates over all states in S, and computes, for each state s, a set l(s) of subformulae, where the function l **is the** solution of the fixpoint equation l(s) = F ∪ {**Reg(**ψ ′,s′) | ψ ′ ∈ l(s ′),s′**is a successor of** s}."@en ;
    askg-onto:inSentence "Here, a preprocessing phase iterates over all states in S, and computes, for each state s, a set l(s) of subformulae, where the function l **is the** solution of the fixpoint equation l(s) = F ∪ {**Reg(**ψ ′,s′) | ψ ′ ∈ l(s ′),s′**is a successor of** s}."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_states_in_s,
        askg-data:Entity-preprocessing_phase,
        askg-data:Entity-set_ls_of_subformulae,
        askg-data:Entity-state_s .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Only subformulae in l(s**) will be candidates for inclusion in the sets labelling the respective** e-states labelled with s**. That is, the subsequent expansion phase will be as above, but taking** Ψ0 ⊆ l(s0**) and** ψ ′ ⊆ l(s ′) instead of Ψ0 ⊆ Sub(F**) and** ψ ′ ⊆ Sub(F**). As the subformulae in** l(s**) are exactly those that are relevant to the way feasible execution sequences starting from** e-states labelled with s **are rewarded, this leads the expansion phase to produce a minimal** equivalent MDP."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192-Sentence-1921,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192-Sentence-1922,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192-Sentence-1923 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192-Sentence-1921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Only subformulae in l(s**) will be candidates for inclusion in the sets labelling the respective** e-states labelled with s**."@en ;
    askg-onto:inSentence "Only subformulae in l(s**) will be candidates for inclusion in the sets labelling the respective** e-states labelled with s**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-sets_labelling_the_respective_e-states,
        askg-data:Entity-subformulae .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192-Sentence-1922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "That is, the subsequent expansion phase will be as above, but taking** Ψ0 ⊆ l(s0**) and** ψ ′ ⊆ l(s ′) instead of Ψ0 ⊆ Sub(F**) and** ψ ′ ⊆ Sub(F**)."@en ;
    askg-onto:inSentence "That is, the subsequent expansion phase will be as above, but taking** Ψ0 ⊆ l(s0**) and** ψ ′ ⊆ l(s ′) instead of Ψ0 ⊆ Sub(F**) and** ψ ′ ⊆ Sub(F**)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%880,
        askg-data:Entity-%CF%88_,
        askg-data:Entity-ls0,
        askg-data:Entity-ls_ .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-192-Sentence-1923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As the subformulae in** l(s**) are exactly those that are relevant to the way feasible execution sequences starting from** e-states labelled with s **are rewarded, this leads the expansion phase to produce a minimal** equivalent MDP."@en ;
    askg-onto:inSentence "As the subformulae in** l(s**) are exactly those that are relevant to the way feasible execution sequences starting from** e-states labelled with s **are rewarded, this leads the expansion phase to produce a minimal** equivalent MDP."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-ls,
        askg-data:Entity-minimal_equivalent_mdp,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 5 shows the equivalent MDP produced by pltlmin **for the NMRDP example in** Figure 3, together with the function l **from which the labels are built. Observe how this** MDP is smaller than the pltlsim **MDP: once we reach the state on the left-hand side in** which p is true and q **is false, there is no point in tracking the values of subformulae, because** q **cannot become true and so the reward formula cannot either. This is reflected by the fact** that l({p}**) only contains the reward formula.** In the worst case, computing l **requires a space, and a number of iterations through** S, exponential in ||F||**. Hence the question arises of whether the gain during the expansion** phase is worth the extra complexity of the preprocessing phase. This is one of the questions our experimental analysis in Section 5 will try to answer."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1931,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1932,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1933,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1934,
        askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1935 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 5 shows the equivalent MDP produced by pltlmin **for the NMRDP example in** Figure 3, together with the function l **from which the labels are built."@en ;
    askg-onto:inSentence "Figure 5 shows the equivalent MDP produced by pltlmin **for the NMRDP example in** Figure 3, together with the function l **from which the labels are built."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-labels,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp_example,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Observe how this** MDP is smaller than the pltlsim **MDP: once we reach the state on the left-hand side in** which p is true and q **is false, there is no point in tracking the values of subformulae, because** q **cannot become true and so the reward formula cannot either."@en ;
    askg-onto:inSentence "Observe how this** MDP is smaller than the pltlsim **MDP: once we reach the state on the left-hand side in** which p is true and q **is false, there is no point in tracking the values of subformulae, because** q **cannot become true and so the reward formula cannot either."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-pltlsim_mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1933 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This is reflected by the fact** that l({p}**) only contains the reward formula.** In the worst case, computing l **requires a space, and a number of iterations through** S, exponential in ||F||**."@en ;
    askg-onto:inSentence "This is reflected by the fact** that l({p}**) only contains the reward formula.** In the worst case, computing l **requires a space, and a number of iterations through** S, exponential in ||F||**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-number_of_iterations,
        askg-data:Entity-reward_formula,
        askg-data:Entity-s,
        askg-data:Entity-space .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1934 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Hence the question arises of whether the gain during the expansion** phase is worth the extra complexity of the preprocessing phase."@en ;
    askg-onto:inSentence "Hence the question arises of whether the gain during the expansion** phase is worth the extra complexity of the preprocessing phase."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expansion_phase,
        askg-data:Entity-preprocessing_phase .

askg-data:Paper-c253584c3f1ff2a2-Section-19-Paragraph-193-Sentence-1935 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This is one of the questions our experimental analysis in Section 5 will try to answer."@en ;
    askg-onto:inSentence "This is one of the questions our experimental analysis in Section 5 will try to answer."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experimental_analysis,
        askg-data:Entity-section_5 .

askg-data:Paper-c253584c3f1ff2a2-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "Abstract"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "A decision process in which rewards depend on history rather than merely on the current state is called a decision process with non-Markovian rewards (NMRDP). In decisiontheoretic planning, where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states, NMRDPs form a more natural model than the commonly adopted fully Markovian decision process (MDP) model. While the more tractable solution methods developed for MDPs do not directly apply in the presence of non-Markovian rewards, a number of solution methods for NMRDPs have been proposed in the literature. These all exploit a compact specification of the non-Markovian reward function in temporal logic, to automatically translate the NMRDP into an equivalent MDP which is solved using efficient MDP solution methods. This paper presents nmrdpp**(Non-Markovian Reward Decision Process Planner), a software platform for the** development and experimentation of methods for decision-theoretic planning with non- Markovian rewards. The current version of nmrdpp **implements, under a single interface,** a family of methods based on existing as well as new approaches which we describe in detail. These include dynamic programming, heuristic search, and structured methods. Using nmrdpp**, we compare the methods and identify certain problem features that affect their** performance. nmrdpp**'s treatment of non-Markovian rewards is inspired by the treatment** of domain-specific search control knowledge in the TLPlan planner, which it incorporates as a special case. In the First International Probabilistic Planning Competition, **nmrdpp** was able to compete and perform well in both the domain-independent and hand-coded tracks, using search control knowledge in the latter."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-211,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-2110,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-212,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-213,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-214,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-215,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-216,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-217,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-218,
        askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-219 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A decision process in which rewards depend on history rather than merely on the current state is called a decision process with non-Markovian rewards (NMRDP)."@en ;
    askg-onto:inSentence "A decision process in which rewards depend on history rather than merely on the current state is called a decision process with non-Markovian rewards (NMRDP)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_process,
        askg-data:Entity-decision_process_with_non-markovian_rewards_nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-2110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "In the First International Probabilistic Planning Competition, **nmrdpp** was able to compete and perform well in both the domain-independent and hand-coded tracks, using search control knowledge in the latter."@en ;
    askg-onto:inSentence "In the First International Probabilistic Planning Competition, **nmrdpp** was able to compete and perform well in both the domain-independent and hand-coded tracks, using search control knowledge in the latter."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-independent_track,
        askg-data:Entity-hand-coded_track,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-search_control_knowledge .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In decisiontheoretic planning, where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states, NMRDPs form a more natural model than the commonly adopted fully Markovian decision process (MDP) model."@en ;
    askg-onto:inSentence "In decisiontheoretic planning, where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states, NMRDPs form a more natural model than the commonly adopted fully Markovian decision process (MDP) model."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decisiontheoretic_planning,
        askg-data:Entity-execution_sequences,
        askg-data:Entity-fully_markovian_decision_process,
        askg-data:Entity-model,
        askg-data:Entity-nmrdps,
        askg-data:Entity-property .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While the more tractable solution methods developed for MDPs do not directly apply in the presence of non-Markovian rewards, a number of solution methods for NMRDPs have been proposed in the literature."@en ;
    askg-onto:inSentence "While the more tractable solution methods developed for MDPs do not directly apply in the presence of non-Markovian rewards, a number of solution methods for NMRDPs have been proposed in the literature."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdps,
        askg-data:Entity-nmrdps,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These all exploit a compact specification of the non-Markovian reward function in temporal logic, to automatically translate the NMRDP into an equivalent MDP which is solved using efficient MDP solution methods."@en ;
    askg-onto:inSentence "These all exploit a compact specification of the non-Markovian reward function in temporal logic, to automatically translate the NMRDP into an equivalent MDP which is solved using efficient MDP solution methods."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-mdp_solution_methods,
        askg-data:Entity-nmrdp,
        askg-data:Entity-non-markovian_reward_function,
        askg-data:Entity-temporal_logic .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This paper presents nmrdpp**(Non-Markovian Reward Decision Process Planner), a software platform for the** development and experimentation of methods for decision-theoretic planning with non- Markovian rewards."@en ;
    askg-onto:inSentence "This paper presents nmrdpp**(Non-Markovian Reward Decision Process Planner), a software platform for the** development and experimentation of methods for decision-theoretic planning with non- Markovian rewards."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-development_and_experimentation_of_methods_for_decision-theoretic_planning_with_non-markovian_rewards,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-software_platform .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The current version of nmrdpp **implements, under a single interface,** a family of methods based on existing as well as new approaches which we describe in detail."@en ;
    askg-onto:inSentence "The current version of nmrdpp **implements, under a single interface,** a family of methods based on existing as well as new approaches which we describe in detail."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_family_of_methods,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "These include dynamic programming, heuristic search, and structured methods."@en ;
    askg-onto:inSentence "These include dynamic programming, heuristic search, and structured methods."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_programming,
        askg-data:Entity-heuristic_search,
        askg-data:Entity-method,
        askg-data:Entity-structured_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-218 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Using nmrdpp**, we compare the methods and identify certain problem features that affect their** performance."@en ;
    askg-onto:inSentence "Using nmrdpp**, we compare the methods and identify certain problem features that affect their** performance."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-performance,
        askg-data:Entity-problem_features .

askg-data:Paper-c253584c3f1ff2a2-Section-2-Paragraph-21-Sentence-219 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "nmrdpp**'s treatment of non-Markovian rewards is inspired by the treatment** of domain-specific search control knowledge in the TLPlan planner, which it incorporates as a special case."@en ;
    askg-onto:inSentence "nmrdpp**'s treatment of non-Markovian rewards is inspired by the treatment** of domain-specific search control knowledge in the TLPlan planner, which it incorporates as a special case."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-specific_search_control_knowledge,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-tlplan .

askg-data:Paper-c253584c3f1ff2a2-Section-20 a askg-onto:Section ;
    rdfs:label "Section 20"@en ;
    domo:Text "2.2.5 Pltlstr"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-201,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2010,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2011,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2012,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2013,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2014,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2015,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2016,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2017,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2018,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2019,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-202,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2021,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-203,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-204,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-205,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-206,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-207,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-208,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-209 ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-201 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The pltlstr translation can be seen as a symbolic version of pltlsim**. The set** T of added temporal variables contains the purely temporal subformulae PTSub(F**) of the reward** formulae in F, to which the ⊖ **modality is prepended (unless already there):** T = {⊖ψ | ψ ∈"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-201-Sentence-2011,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-201-Sentence-2012 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-201-Sentence-2011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The pltlstr translation can be seen as a symbolic version of pltlsim**."@en ;
    askg-onto:inSentence "The pltlstr translation can be seen as a symbolic version of pltlsim**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstr_translation .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-201-Sentence-2012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The set** T of added temporal variables contains the purely temporal subformulae PTSub(F**) of the reward** formulae in F, to which the ⊖ **modality is prepended (unless already there):** T = {⊖ψ | ψ ∈"@en ;
    askg-onto:inSentence "The set** T of added temporal variables contains the purely temporal subformulae PTSub(F**) of the reward** formulae in F, to which the ⊖ **modality is prepended (unless already there):** T = {⊖ψ | ψ ∈"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-_modality,
        askg-data:Entity-ptsubf,
        askg-data:Entity-reward_formulae_in_f,
        askg-data:Entity-t .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2010 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "PTSub(F),ψ 6= ⊖ψ ′} ∪ {⊖ψ | ⊖ψ ∈ PTSub(F)}**. By repeatedly applying the equivalence** f1 S f2 ≡ f2 ∨ (f1 ∧ ⊖(f1 S f2)) to any subformula in PTSub(F**), we can express its current** value, and hence that of reward formulae, as a function of the **current values of formulae** in T **and state variables, as required by the compact representation of the transition and** reward models."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2010-Sentence-20101,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2010-Sentence-20102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2010-Sentence-20101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "PTSub(F),ψ 6= ⊖ψ ′} ∪ {⊖ψ | ⊖ψ ∈ PTSub(F)}**."@en ;
    askg-onto:inSentence "PTSub(F),ψ 6= ⊖ψ ′} ∪ {⊖ψ | ⊖ψ ∈ PTSub(F)}**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%88,
        askg-data:Entity-mathematical_expression,
        askg-data:Entity-mathematical_symbol,
        askg-data:Entity-ptsubf .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2010-Sentence-20102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "By repeatedly applying the equivalence** f1 S f2 ≡ f2 ∨ (f1 ∧ ⊖(f1 S f2)) to any subformula in PTSub(F**), we can express its current** value, and hence that of reward formulae, as a function of the **current values of formulae** in T **and state variables, as required by the compact representation of the transition and** reward models."@en ;
    askg-onto:inSentence "By repeatedly applying the equivalence** f1 S f2 ≡ f2 ∨ (f1 ∧ ⊖(f1 S f2)) to any subformula in PTSub(F**), we can express its current** value, and hence that of reward formulae, as a function of the **current values of formulae** in T **and state variables, as required by the compact representation of the transition and** reward models."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compact_representation,
        askg-data:Entity-current_values_of_formulae,
        askg-data:Entity-f,
        askg-data:Entity-f1_s_f2,
        askg-data:Entity-f2__f1__f1_s_f2,
        askg-data:Entity-ptsubf,
        askg-data:Entity-reward_formulae,
        askg-data:Entity-reward_models,
        askg-data:Entity-t,
        askg-data:Entity-transition_models .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2011 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "For our NMRDP example in Figure 3, the set of purely temporal variables is PTSub(F) = {⊖p, ⊖ ⊖ p}, and T is identical to PTSub(F**). Figure 6 shows some of the ADDs forming** part of the symbolic MDP produced by pltlstr**: the ADDs describing the dynamics of** the temporal variables, i.e., the ADDs describing the effects of the actions a and b **on their** respective values, and the ADD describing the reward."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2011-Sentence-20111,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2011-Sentence-20112 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2011-Sentence-20111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For our NMRDP example in Figure 3, the set of purely temporal variables is PTSub(F) = {⊖p, ⊖ ⊖ p}, and T is identical to PTSub(F**)."@en ;
    askg-onto:inSentence "For our NMRDP example in Figure 3, the set of purely temporal variables is PTSub(F) = {⊖p, ⊖ ⊖ p}, and T is identical to PTSub(F**)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p___p,
        askg-data:Entity-ptsubf,
        askg-data:Entity-t .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2011-Sentence-20112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Figure 6 shows some of the ADDs forming** part of the symbolic MDP produced by pltlstr**: the ADDs describing the dynamics of** the temporal variables, i.e., the ADDs describing the effects of the actions a and b **on their** respective values, and the ADD describing the reward."@en ;
    askg-onto:inSentence "Figure 6 shows some of the ADDs forming** part of the symbolic MDP produced by pltlstr**: the ADDs describing the dynamics of** the temporal variables, i.e., the ADDs describing the effects of the actions a and b **on their** respective values, and the ADD describing the reward."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-add,
        askg-data:Entity-adds,
        askg-data:Entity-dynamics_of_temporal_variables,
        askg-data:Entity-effects_of_actions_a_and_b,
        askg-data:Entity-pltlstr,
        askg-data:Entity-reward,
        askg-data:Entity-symbolic_mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2012 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "As a more complex illustration, consider this example (Bacchus et al., 1997) in which"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2012-Sentence-20121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2012-Sentence-20121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As a more complex illustration, consider this example (Bacchus et al., 1997) in which"@en ;
    askg-onto:inSentence "As a more complex illustration, consider this example (Bacchus et al., 1997) in which"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1997,
        askg-data:Entity-bacchus_et_al .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2013 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "$$F=\\{\\diamond(p\\,\\mathsf{S}\\ (q\\vee\\ominus r))\\}\\equiv\\{\\mathsf{T}\\,\\mathsf{S}\\ (p\\,\\mathsf{S}\\ (q\\vee\\ominus r))\\}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2013-Sentence-20131 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2013-Sentence-20131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$F=\\{\\diamond(p\\,\\mathsf{S}\\ (q\\vee\\ominus r))\\}\\equiv\\{\\mathsf{T}\\,\\mathsf{S}\\ (p\\,\\mathsf{S}\\ (q\\vee\\ominus r))\\}$$"@en ;
    askg-onto:inSentence "$$F=\\{\\diamond(p\\,\\mathsf{S}\\ (q\\vee\\ominus r))\\}\\equiv\\{\\mathsf{T}\\,\\mathsf{S}\\ (p\\,\\mathsf{S}\\ (q\\vee\\ominus r))\\}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-t .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2014 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "We have that"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2014-Sentence-20141 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2014-Sentence-20141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We have that"@en ;
    askg-onto:inSentence "We have that"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-that,
        askg-data:Entity-we .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2015 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "$$\\mathrm{{PTSub}}(F)=\\{\\top\\;\\mathsf{S}\\;\\;(p\\;\\mathsf{S}\\;\\;(q\\vee\\ominus r)),p\\;\\mathsf{S}\\;\\;(q\\vee\\ominus r),\\ominus r\\}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2015-Sentence-20151 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2015-Sentence-20151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathrm{{PTSub}}(F)=\\{\\top\\;\\mathsf{S}\\;\\;(p\\;\\mathsf{S}\\;\\;(q\\vee\\ominus r)),p\\;\\mathsf{S}\\;\\;(q\\vee\\ominus r),\\ominus r\\}$$"@en ;
    askg-onto:inSentence "$$\\mathrm{{PTSub}}(F)=\\{\\top\\;\\mathsf{S}\\;\\;(p\\;\\mathsf{S}\\;\\;(q\\vee\\ominus r)),p\\;\\mathsf{S}\\;\\;(q\\vee\\ominus r),\\ominus r\\}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-ptsub .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2016 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "and so the set of temporal variables used is"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2016-Sentence-20161 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2016-Sentence-20161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and so the set of temporal variables used is"@en ;
    askg-onto:inSentence "and so the set of temporal variables used is"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-set,
        askg-data:Entity-temporal_variables .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2017 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "$$T=\\{t_{1}:\\odot(\\top\\,\\mathsf{S}\\,\\,\\,(p\\,\\mathsf{S}\\,(q\\vee\\odot r))),t_{2}:\\odot(p\\,\\mathsf{S}\\,\\,\\,(q\\vee\\odot r)),t3:\\odot r\\}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2017-Sentence-20171 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2017-Sentence-20171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$T=\\{t_{1}:\\odot(\\top\\,\\mathsf{S}\\,\\,\\,(p\\,\\mathsf{S}\\,(q\\vee\\odot r))),t_{2}:\\odot(p\\,\\mathsf{S}\\,\\,\\,(q\\vee\\odot r)),t3:\\odot r\\}$$"@en ;
    askg-onto:inSentence "$$T=\\{t_{1}:\\odot(\\top\\,\\mathsf{S}\\,\\,\\,(p\\,\\mathsf{S}\\,(q\\vee\\odot r))),t_{2}:\\odot(p\\,\\mathsf{S}\\,\\,\\,(q\\vee\\odot r)),t3:\\odot r\\}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-_r,
        askg-data:Entity-p_s_q_r,
        askg-data:Entity-t,
        askg-data:Entity-t1,
        askg-data:Entity-t2,
        askg-data:Entity-t3,
        askg-data:Entity-top_s_p_s_q_r .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2018 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "Using the equivalences, the reward can be decomposed and expressed by means of the propositions p,q and the temporal variables t1,t2,t3 **as follows:**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2018-Sentence-20181 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2018-Sentence-20181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Using the equivalences, the reward can be decomposed and expressed by means of the propositions p,q and the temporal variables t1,t2,t3 **as follows:**"@en ;
    askg-onto:inSentence "Using the equivalences, the reward can be decomposed and expressed by means of the propositions p,q and the temporal variables t1,t2,t3 **as follows:**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-propositions_pq_and_temporal_variables_t1t2t3,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2019 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "$$\\begin{array}{r l}{\\top\\,\\mathsf{S}\\ \\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)}&{{}\\equiv}\\\\ {\\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\vee\\ominus\\left(\\top\\,\\mathsf{S}\\ \\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\right)}&{{}\\equiv}\\\\ {\\left(q\\vee\\ominus r\\right)\\vee\\left(p\\wedge\\ominus\\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\right)\\lor t_{1}}&{{}\\equiv}\\\\ {\\left(q\\lor t_{3}\\right)\\vee\\left(p\\wedge t_{2}\\right)\\lor t_{1}}&{{}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2019-Sentence-20191 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2019-Sentence-20191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{r l}{\\top\\,\\mathsf{S}\\ \\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)}&{{}\\equiv}\\\\ {\\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\vee\\ominus\\left(\\top\\,\\mathsf{S}\\ \\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\right)}&{{}\\equiv}\\\\ {\\left(q\\vee\\ominus r\\right)\\vee\\left(p\\wedge\\ominus\\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\right)\\lor t_{1}}&{{}\\equiv}\\\\ {\\left(q\\lor t_{3}\\right)\\vee\\left(p\\wedge t_{2}\\right)\\lor t_{1}}&{{}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{r l}{\\top\\,\\mathsf{S}\\ \\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)}&{{}\\equiv}\\\\ {\\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\vee\\ominus\\left(\\top\\,\\mathsf{S}\\ \\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\right)}&{{}\\equiv}\\\\ {\\left(q\\vee\\ominus r\\right)\\vee\\left(p\\wedge\\ominus\\left(p\\,\\mathsf{S}\\ \\left(q\\vee\\ominus r\\right)\\right)\\right)\\lor t_{1}}&{{}\\equiv}\\\\ {\\left(q\\lor t_{3}\\right)\\vee\\left(p\\wedge t_{2}\\right)\\lor t_{1}}&{{}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-r,
        askg-data:Entity-s,
        askg-data:Entity-t_1,
        askg-data:Entity-t_2,
        askg-data:Entity-t_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-202 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![11_image_0.png](11_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-202-Sentence-2021 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-202-Sentence-2021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![11_image_0.png](11_image_0.png)"@en ;
    askg-onto:inSentence "![11_image_0.png](11_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-big_data,
        askg-data:Entity-data_science,
        askg-data:Entity-healthcare,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-predictive_analytics,
        askg-data:Entity-research_area,
        askg-data:Entity-statistical_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "As with pltlsim, the underlying MDP produced by pltlstr **is far from minimal - the** encoded history features do not even vary from one state to the next. However, size is not as problematic as with state-based approaches, because **structured solution methods do** not enumerate states and are able to dynamically ignore some **of the variables that become** irrelevant during policy construction. For instance, when **solving the MDP, they may be** able to determine that some temporal variables have become irrelevant because the situation they track, although possible in principle, is too costly to **be realised under a good policy.** This dynamic analysis of rewards contrast with pltlmin's static **analysis (Bacchus et al.,** 1996) which must encode enough history to determine the reward at all reachable future states under any policy."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020-Sentence-20201,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020-Sentence-20202,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020-Sentence-20203 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020-Sentence-20201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As with pltlsim, the underlying MDP produced by pltlstr **is far from minimal - the** encoded history features do not even vary from one state to the next."@en ;
    askg-onto:inSentence "As with pltlsim, the underlying MDP produced by pltlstr **is far from minimal - the** encoded history features do not even vary from one state to the next."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoded_history_features,
        askg-data:Entity-mdp,
        askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020-Sentence-20202 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, size is not as problematic as with state-based approaches, because **structured solution methods do** not enumerate states and are able to dynamically ignore some **of the variables that become** irrelevant during policy construction."@en ;
    askg-onto:inSentence "However, size is not as problematic as with state-based approaches, because **structured solution methods do** not enumerate states and are able to dynamically ignore some **of the variables that become** irrelevant during policy construction."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-states,
        askg-data:Entity-structured_solution_methods,
        askg-data:Entity-variables .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2020-Sentence-20203 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For instance, when **solving the MDP, they may be** able to determine that some temporal variables have become irrelevant because the situation they track, although possible in principle, is too costly to **be realised under a good policy.** This dynamic analysis of rewards contrast with pltlmin's static **analysis (Bacchus et al.,** 1996) which must encode enough history to determine the reward at all reachable future states under any policy."@en ;
    askg-onto:inSentence "For instance, when **solving the MDP, they may be** able to determine that some temporal variables have become irrelevant because the situation they track, although possible in principle, is too costly to **be realised under a good policy.** This dynamic analysis of rewards contrast with pltlmin's static **analysis (Bacchus et al.,** 1996) which must encode enough history to determine the reward at all reachable future states under any policy."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-dynamic_analysis_of_rewards,
        askg-data:Entity-future_states,
        askg-data:Entity-history,
        askg-data:Entity-mdp,
        askg-data:Entity-reward,
        askg-data:Entity-static_analysis,
        askg-data:Entity-temporal_variables .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2021 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 21"@en ;
    domo:Text "One question that arises is that of the circumstances under which this analysis of irrelevance by structured solution methods, especially the dynamic aspects, is really effective. This is another question our experimental analysis will try **to address.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2021-Sentence-20211,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2021-Sentence-20212 ;
    askg-onto:index "21"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2021-Sentence-20211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "One question that arises is that of the circumstances under which this analysis of irrelevance by structured solution methods, especially the dynamic aspects, is really effective."@en ;
    askg-onto:inSentence "One question that arises is that of the circumstances under which this analysis of irrelevance by structured solution methods, especially the dynamic aspects, is really effective."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis_of_irrelevance,
        askg-data:Entity-dynamic_aspects,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-2021-Sentence-20212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This is another question our experimental analysis will try **to address.**"@en ;
    askg-onto:inSentence "This is another question our experimental analysis will try **to address.**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experimental_analysis,
        askg-data:Entity-question .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-203 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The following subformulae in Sub(F**) label** the e-states: f1 : p f2 : q f3 : ⊖p f4 : ⊖ ⊖ p f5 : q ∧ ⊖ ⊖ p f6 : ¬p f7 : ¬q f8 : ¬ ⊖ p f9 : ¬ ⊖ ⊖p f10 : ¬(q ∧ ⊖ ⊖ p)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-203-Sentence-2031 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-203-Sentence-2031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The following subformulae in Sub(F**) label** the e-states: f1 : p f2 : q f3 : ⊖p f4 : ⊖ ⊖ p f5 : q ∧ ⊖ ⊖ p f6 : ¬p f7 : ¬q f8 : ¬ ⊖ p f9 : ¬ ⊖ ⊖p f10 : ¬(q ∧ ⊖ ⊖ p)"@en ;
    askg-onto:inSentence "The following subformulae in Sub(F**) label** the e-states: f1 : p f2 : q f3 : ⊖p f4 : ⊖ ⊖ p f5 : q ∧ ⊖ ⊖ p f6 : ¬p f7 : ¬q f8 : ¬ ⊖ p f9 : ¬ ⊖ ⊖p f10 : ¬(q ∧ ⊖ ⊖ p)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-f1,
        askg-data:Entity-f10,
        askg-data:Entity-f2,
        askg-data:Entity-f3,
        askg-data:Entity-f4,
        askg-data:Entity-f5,
        askg-data:Entity-f6,
        askg-data:Entity-f7,
        askg-data:Entity-f8,
        askg-data:Entity-f9,
        askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-q__p,
        askg-data:Entity-subf .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-204 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Figure 4: Equivalent MDP Produced by **pltlsim**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-204-Sentence-2041 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-204-Sentence-2041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 4: Equivalent MDP Produced by **pltlsim**"@en ;
    askg-onto:inSentence "Figure 4: Equivalent MDP Produced by **pltlsim**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equivalent_mdp,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-205 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![11_image_1.png](11_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-205-Sentence-2051 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-205-Sentence-2051 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![11_image_1.png](11_image_1.png)"@en ;
    askg-onto:inSentence "![11_image_1.png](11_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai_tools,
        askg-data:Entity-algorithm,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-company,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning,
        askg-data:Entity-experiment,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-person,
        askg-data:Entity-quantum_computing,
        askg-data:Entity-research_field,
        askg-data:Entity-research_paper,
        askg-data:Entity-university .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-206 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "The function l **is given by:** l({}) = {q ∧ ⊖ ⊖ p, ⊖p, p} l({p}) = {q ∧ ⊖ ⊖ p} l({q}) = {q ∧ ⊖ ⊖ p, ⊖p, p} l({p, q}) = {q ∧ ⊖ ⊖ p, ⊖p,p} The following formulae label the e-states: f1 : q ∧ ⊖ ⊖ p f2 : ⊖p f3 : p f4 : ¬(q ∧ ⊖ ⊖ p) f5 : ¬ ⊖ p f6 : ¬p"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-206-Sentence-2061 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-206-Sentence-2061 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The function l **is given by:** l({}) = {q ∧ ⊖ ⊖ p, ⊖p, p} l({p}) = {q ∧ ⊖ ⊖ p} l({q}) = {q ∧ ⊖ ⊖ p, ⊖p, p} l({p, q}) = {q ∧ ⊖ ⊖ p, ⊖p,p} The following formulae label the e-states: f1 : q ∧ ⊖ ⊖ p f2 : ⊖p f3 : p f4 : ¬(q ∧ ⊖ ⊖ p) f5 : ¬ ⊖ p f6 : ¬p"@en ;
    askg-onto:inSentence "The function l **is given by:** l({}) = {q ∧ ⊖ ⊖ p, ⊖p, p} l({p}) = {q ∧ ⊖ ⊖ p} l({q}) = {q ∧ ⊖ ⊖ p, ⊖p, p} l({p, q}) = {q ∧ ⊖ ⊖ p, ⊖p,p} The following formulae label the e-states: f1 : q ∧ ⊖ ⊖ p f2 : ⊖p f3 : p f4 : ¬(q ∧ ⊖ ⊖ p) f5 : ¬ ⊖ p f6 : ¬p"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-207 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Figure 5: Equivalent MDP Produced by **pltlmin**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-207-Sentence-2071 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-207-Sentence-2071 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 5: Equivalent MDP Produced by **pltlmin**"@en ;
    askg-onto:inSentence "Figure 5: Equivalent MDP Produced by **pltlmin**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equivalent_mdp,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-208 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-208-Sentence-2081 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-208-Sentence-2081 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:inSentence "![12_image_0.png](12_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-data_science,
        askg-data:Entity-deep_learning,
        askg-data:Entity-healthcare,
        askg-data:Entity-healthcare_technology,
        askg-data:Entity-machine_learning,
        askg-data:Entity-mathematics,
        askg-data:Entity-medical_imaging,
        askg-data:Entity-predictive_analytics,
        askg-data:Entity-research_on_ai,
        askg-data:Entity-statistics .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-209 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Figure 6: ADDs Produced by pltlstr**. prv (previously) stands for** ⊖"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-209-Sentence-2091,
        askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-209-Sentence-2092 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-209-Sentence-2091 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 6: ADDs Produced by pltlstr**."@en ;
    askg-onto:inSentence "Figure 6: ADDs Produced by pltlstr**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adds,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-20-Paragraph-209-Sentence-2092 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "prv (previously) stands for** ⊖"@en ;
    askg-onto:inSentence "prv (previously) stands for** ⊖"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-prv .

askg-data:Paper-c253584c3f1ff2a2-Section-21 a askg-onto:Section ;
    rdfs:label "Section 21"@en ;
    domo:Text "3. Fltl**: A Forward-Looking Approach**"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211 ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "As noted in Section 1 above, the two key issues facing approaches to NMRDPs are how to specify the reward functions compactly and how to exploit **this compact representation** to automatically translate an NMRDP into an equivalent MDP amenable to the chosen solution method. Accordingly, our goals are to provide a reward function specification language and a translation that are adapted to anytime state-based solution methods. After a brief reminder of the relevant features of these methods, we consider these two goals in turn. We describe the syntax and semantics of the language, the notion of formula progression for the language which will form the basis of our **translation, the translation** itself, its properties, and its embedding into the solution **method. We call our approach** fltl. We finish the section with a discussion of the features that distinguish fltl **from** existing approaches."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2111,
        askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2112,
        askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2113,
        askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2114,
        askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2115,
        askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2116 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As noted in Section 1 above, the two key issues facing approaches to NMRDPs are how to specify the reward functions compactly and how to exploit **this compact representation** to automatically translate an NMRDP into an equivalent MDP amenable to the chosen solution method."@en ;
    askg-onto:inSentence "As noted in Section 1 above, the two key issues facing approaches to NMRDPs are how to specify the reward functions compactly and how to exploit **this compact representation** to automatically translate an NMRDP into an equivalent MDP amenable to the chosen solution method."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compact_representation,
        askg-data:Entity-issues,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdps,
        askg-data:Entity-reward_functions,
        askg-data:Entity-solution_method .

askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Accordingly, our goals are to provide a reward function specification language and a translation that are adapted to anytime state-based solution methods."@en ;
    askg-onto:inSentence "Accordingly, our goals are to provide a reward function specification language and a translation that are adapted to anytime state-based solution methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-language,
        askg-data:Entity-method,
        askg-data:Entity-reward_function_specification_language,
        askg-data:Entity-state-based_solution_methods,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "After a brief reminder of the relevant features of these methods, we consider these two goals in turn."@en ;
    askg-onto:inSentence "After a brief reminder of the relevant features of these methods, we consider these two goals in turn."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goals,
        askg-data:Entity-methods .

askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We describe the syntax and semantics of the language, the notion of formula progression for the language which will form the basis of our **translation, the translation** itself, its properties, and its embedding into the solution **method."@en ;
    askg-onto:inSentence "We describe the syntax and semantics of the language, the notion of formula progression for the language which will form the basis of our **translation, the translation** itself, its properties, and its embedding into the solution **method."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-properties,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We call our approach** fltl."@en ;
    askg-onto:inSentence "We call our approach** fltl."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-21-Paragraph-211-Sentence-2116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We finish the section with a discussion of the features that distinguish fltl **from** existing approaches."@en ;
    askg-onto:inSentence "We finish the section with a discussion of the features that distinguish fltl **from** existing approaches."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-existing_approaches,
        askg-data:Entity-fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-22 a askg-onto:Section ;
    rdfs:label "Section 22"@en ;
    domo:Text "3.1 Anytime State-Based Solution Methods"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-221,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-224 ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-221 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The main drawback of traditional dynamic programming algorithms such as policy iteration (Howard, 1960) is that they explicitly enumerate all states **that are reachable from** s0 in the entire MDP. There has been interest in other state-based **solution methods, which may** produce incomplete policies, but only enumerate a fraction **of the states that policy iteration** requires."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-221-Sentence-2211,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-221-Sentence-2212 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-221-Sentence-2211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The main drawback of traditional dynamic programming algorithms such as policy iteration (Howard, 1960) is that they explicitly enumerate all states **that are reachable from** s0 in the entire MDP."@en ;
    askg-onto:inSentence "The main drawback of traditional dynamic programming algorithms such as policy iteration (Howard, 1960) is that they explicitly enumerate all states **that are reachable from** s0 in the entire MDP."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-explicitly_enumerate_all_states_reachable_from_s0_in_the_entire_mdp,
        askg-data:Entity-howard_1960,
        askg-data:Entity-initial_state_in_mdp,
        askg-data:Entity-markov_decision_process,
        askg-data:Entity-mdp,
        askg-data:Entity-policy_iteration,
        askg-data:Entity-s0,
        askg-data:Entity-traditional_dynamic_programming_algorithms .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-221-Sentence-2212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "There has been interest in other state-based **solution methods, which may** produce incomplete policies, but only enumerate a fraction **of the states that policy iteration** requires."@en ;
    askg-onto:inSentence "There has been interest in other state-based **solution methods, which may** produce incomplete policies, but only enumerate a fraction **of the states that policy iteration** requires."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-incomplete_policies,
        askg-data:Entity-policy_iteration,
        askg-data:Entity-solution_methods,
        askg-data:Entity-states .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Let E(π) denote the envelope of policy π**, that is the set of states that are reachable** (with a non-zero probability) from the initial state s0 under the policy. If π **is defined** at all s ∈ E(π), we say that the policy is complete**, and that it is incomplete otherwise.** The set of states in E(π) at which π is undefined is called the fringe **of the policy. The** fringe states are taken to be absorbing, and their value is heuristic. A common feature of anytime state-based algorithms is that they perform a forward search, starting from s0 and repeatedly expanding the envelope of the current policy one **step forward by adding one or** more fringe states. When provided with admissible heuristic values for the fringe states, they eventually converge to the optimal policy without necessarily needing to explore the entire state space. In fact, since planning operators are used to compactly represent the state space, they may not even need to construct **more than a small subset of the MDP** before returning the optimal policy. When interrupted before convergence, they return a possibly incomplete but often useful policy."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2221,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2222,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2223,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2224,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2225,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2226,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2227 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Let E(π) denote the envelope of policy π**, that is the set of states that are reachable** (with a non-zero probability) from the initial state s0 under the policy."@en ;
    askg-onto:inSentence "Let E(π) denote the envelope of policy π**, that is the set of states that are reachable** (with a non-zero probability) from the initial state s0 under the policy."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e%CF%80,
        askg-data:Entity-the_envelope_of_policy_%CF%80,
        askg-data:Entity-the_initial_state_s0_under_the_policy,
        askg-data:Entity-the_set_of_states .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "If π **is defined** at all s ∈ E(π), we say that the policy is complete**, and that it is incomplete otherwise.** The set of states in E(π) at which π is undefined is called the fringe **of the policy."@en ;
    askg-onto:inSentence "If π **is defined** at all s ∈ E(π), we say that the policy is complete**, and that it is incomplete otherwise.** The set of states in E(π) at which π is undefined is called the fringe **of the policy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e%CF%80,
        askg-data:Entity-fringe,
        askg-data:Entity-policy,
        askg-data:Entity-states .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The** fringe states are taken to be absorbing, and their value is heuristic."@en ;
    askg-onto:inSentence "The** fringe states are taken to be absorbing, and their value is heuristic."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-absorbing,
        askg-data:Entity-fringe_states,
        askg-data:Entity-heuristic,
        askg-data:Entity-value .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "A common feature of anytime state-based algorithms is that they perform a forward search, starting from s0 and repeatedly expanding the envelope of the current policy one **step forward by adding one or** more fringe states."@en ;
    askg-onto:inSentence "A common feature of anytime state-based algorithms is that they perform a forward search, starting from s0 and repeatedly expanding the envelope of the current policy one **step forward by adding one or** more fringe states."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_state-based_algorithms,
        askg-data:Entity-current_policy,
        askg-data:Entity-envelope,
        askg-data:Entity-forward_search,
        askg-data:Entity-fringe_states .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "When provided with admissible heuristic values for the fringe states, they eventually converge to the optimal policy without necessarily needing to explore the entire state space."@en ;
    askg-onto:inSentence "When provided with admissible heuristic values for the fringe states, they eventually converge to the optimal policy without necessarily needing to explore the entire state space."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-admissible_heuristic_values,
        askg-data:Entity-entire_state_space,
        askg-data:Entity-fringe_states,
        askg-data:Entity-optimal_policy .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In fact, since planning operators are used to compactly represent the state space, they may not even need to construct **more than a small subset of the MDP** before returning the optimal policy."@en ;
    askg-onto:inSentence "In fact, since planning operators are used to compactly represent the state space, they may not even need to construct **more than a small subset of the MDP** before returning the optimal policy."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-optimal_policy,
        askg-data:Entity-planning_operators,
        askg-data:Entity-state_space .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-222-Sentence-2227 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "When interrupted before convergence, they return a possibly incomplete but often useful policy."@en ;
    askg-onto:inSentence "When interrupted before convergence, they return a possibly incomplete but often useful policy."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-policy,
        askg-data:Entity-possibly_incomplete_but_often_useful .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "These methods include the envelope expansion algorithm (Dean et al., 1995), which deploys policy iteration on judiciously chosen larger and larger envelopes, using each successive policy to seed the calculation of the next. The more recent LAO∗ **algorithm (Hansen** & Zilberstein, 2001) which combines dynamic programming with heuristic search can be viewed as a clever implementation of a particular case of the **envelope expansion algorithm,** where fringe states are given admissible heuristic values, **where policy iteration is run up to** convergence between envelope expansions, and where the clever implementation only runs policy iteration on the states whose optimal value can actually be affected when a new fringe state is added to the envelope. Another example is a backtracking forward search in the space of (possibly incomplete) policies rooted at s0 (Thi´ebaux et al., 1995), which is performed until interrupted, at which point the best policy found so far is returned. Real-time dynamic programming (RTDP) (Barto et al., 1995) is another popular anytime algorithm which is to MDPs what learning real-time A∗**(Korf, 1990) is to deterministic domains, and** which has asymptotic convergence guarantees. The RTDP envelope is made up of sample paths which are visited with a frequency determined by the current greedy policy and the transition probabilities in the domain. RTDP can be run on-line, off-line for a given number of steps or until interrupted. A variant called LRTDP (Bonet **& Geffner, 2003) incorporates** mechanisms that focus the search on states whose value has not yet converged, resulting in convergence speed up and finite time convergence guarantees."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2231,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2232,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2233,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2234,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2235,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2236,
        askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2237 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "These methods include the envelope expansion algorithm (Dean et al., 1995), which deploys policy iteration on judiciously chosen larger and larger envelopes, using each successive policy to seed the calculation of the next."@en ;
    askg-onto:inSentence "These methods include the envelope expansion algorithm (Dean et al., 1995), which deploys policy iteration on judiciously chosen larger and larger envelopes, using each successive policy to seed the calculation of the next."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-dean_et_al,
        askg-data:Entity-envelope_expansion_algorithm,
        askg-data:Entity-method,
        askg-data:Entity-policy_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The more recent LAO∗ **algorithm (Hansen** & Zilberstein, 2001) which combines dynamic programming with heuristic search can be viewed as a clever implementation of a particular case of the **envelope expansion algorithm,** where fringe states are given admissible heuristic values, **where policy iteration is run up to** convergence between envelope expansions, and where the clever implementation only runs policy iteration on the states whose optimal value can actually be affected when a new fringe state is added to the envelope."@en ;
    askg-onto:inSentence "The more recent LAO∗ **algorithm (Hansen** & Zilberstein, 2001) which combines dynamic programming with heuristic search can be viewed as a clever implementation of a particular case of the **envelope expansion algorithm,** where fringe states are given admissible heuristic values, **where policy iteration is run up to** convergence between envelope expansions, and where the clever implementation only runs policy iteration on the states whose optimal value can actually be affected when a new fringe state is added to the envelope."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence,
        askg-data:Entity-dynamic_programming,
        askg-data:Entity-envelope_expansion_algorithm,
        askg-data:Entity-fringe_states,
        askg-data:Entity-heuristic_search,
        askg-data:Entity-lao_algorithm,
        askg-data:Entity-policy_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Another example is a backtracking forward search in the space of (possibly incomplete) policies rooted at s0 (Thi´ebaux et al., 1995), which is performed until interrupted, at which point the best policy found so far is returned."@en ;
    askg-onto:inSentence "Another example is a backtracking forward search in the space of (possibly incomplete) policies rooted at s0 (Thi´ebaux et al., 1995), which is performed until interrupted, at which point the best policy found so far is returned."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backtracking_forward_search,
        askg-data:Entity-method,
        askg-data:Entity-paper,
        askg-data:Entity-policies,
        askg-data:Entity-s0,
        askg-data:Entity-thiebaux_et_al_1995 .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2234 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Real-time dynamic programming (RTDP) (Barto et al., 1995) is another popular anytime algorithm which is to MDPs what learning real-time A∗**(Korf, 1990) is to deterministic domains, and** which has asymptotic convergence guarantees."@en ;
    askg-onto:inSentence "Real-time dynamic programming (RTDP) (Barto et al., 1995) is another popular anytime algorithm which is to MDPs what learning real-time A∗**(Korf, 1990) is to deterministic domains, and** which has asymptotic convergence guarantees."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_algorithm,
        askg-data:Entity-asymptotic_convergence_guarantees,
        askg-data:Entity-deterministic_domains,
        askg-data:Entity-learning_real-time_a,
        askg-data:Entity-mdps,
        askg-data:Entity-real-time_dynamic_programming_rtdp .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2235 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The RTDP envelope is made up of sample paths which are visited with a frequency determined by the current greedy policy and the transition probabilities in the domain."@en ;
    askg-onto:inSentence "The RTDP envelope is made up of sample paths which are visited with a frequency determined by the current greedy policy and the transition probabilities in the domain."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain,
        askg-data:Entity-frequency,
        askg-data:Entity-greedy_policy,
        askg-data:Entity-rtdp_envelope,
        askg-data:Entity-sample_paths,
        askg-data:Entity-transition_probabilities .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2236 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "RTDP can be run on-line, off-line for a given number of steps or until interrupted."@en ;
    askg-onto:inSentence "RTDP can be run on-line, off-line for a given number of steps or until interrupted."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-on-line_off-line,
        askg-data:Entity-rtdp .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-223-Sentence-2237 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "A variant called LRTDP (Bonet **& Geffner, 2003) incorporates** mechanisms that focus the search on states whose value has not yet converged, resulting in convergence speed up and finite time convergence guarantees."@en ;
    askg-onto:inSentence "A variant called LRTDP (Bonet **& Geffner, 2003) incorporates** mechanisms that focus the search on states whose value has not yet converged, resulting in convergence speed up and finite time convergence guarantees."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bonet__geffner_2003,
        askg-data:Entity-convergence_speed_up,
        askg-data:Entity-finite_time_convergence_guarantees,
        askg-data:Entity-lrtdp,
        askg-data:Entity-mechanisms .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-224 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "The fltl **translation we are about to present targets these anytime algorithms, although** it could also be used with more traditional methods such as value and policy iteration."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-224-Sentence-2241 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-22-Paragraph-224-Sentence-2241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The fltl **translation we are about to present targets these anytime algorithms, although** it could also be used with more traditional methods such as value and policy iteration."@en ;
    askg-onto:inSentence "The fltl **translation we are about to present targets these anytime algorithms, although** it could also be used with more traditional methods such as value and policy iteration."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_algorithms,
        askg-data:Entity-fltl_translation,
        askg-data:Entity-policy_iteration,
        askg-data:Entity-traditional_methods,
        askg-data:Entity-value_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-23 a askg-onto:Section ;
    rdfs:label "Section 23"@en ;
    domo:Text "3.2 Language And Semantics"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-232,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-233,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236 ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Compactly representing non-Markovian reward functions reduces to compactly representing the behaviours of interest, where by behaviour **we mean a set of finite sequences of states** (a subset of S ∗), e.g. the {hs0,s1i,hs0,s0,s1i,hs0,s0,s0,s1i...} **in Figure 1. Recall that the** reward is issued at the end of any prefix Γ(i**) in that set. Once behaviours are compactly** represented, it is straightforward to represent non-Markovian reward functions as mappings from behaviours to real numbers - we shall defer looking at this until Section 3.6."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2311,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2312,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2313,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2314 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Compactly representing non-Markovian reward functions reduces to compactly representing the behaviours of interest, where by behaviour **we mean a set of finite sequences of states** (a subset of S ∗), e.g."@en ;
    askg-onto:inSentence "Compactly representing non-Markovian reward functions reduces to compactly representing the behaviours of interest, where by behaviour **we mean a set of finite sequences of states** (a subset of S ∗), e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviour,
        askg-data:Entity-behaviours_of_interest,
        askg-data:Entity-non-markovian_reward_functions,
        askg-data:Entity-set_of_finite_sequences_of_states .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "the {hs0,s1i,hs0,s0,s1i,hs0,s0,s0,s1i...} **in Figure 1."@en ;
    askg-onto:inSentence "the {hs0,s1i,hs0,s0,s1i,hs0,s0,s0,s1i...} **in Figure 1."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Recall that the** reward is issued at the end of any prefix Γ(i**) in that set."@en ;
    askg-onto:inSentence "Recall that the** reward is issued at the end of any prefix Γ(i**) in that set."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-prefix_%CE%B3i,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-231-Sentence-2314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Once behaviours are compactly** represented, it is straightforward to represent non-Markovian reward functions as mappings from behaviours to real numbers - we shall defer looking at this until Section 3.6."@en ;
    askg-onto:inSentence "Once behaviours are compactly** represented, it is straightforward to represent non-Markovian reward functions as mappings from behaviours to real numbers - we shall defer looking at this until Section 3.6."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-non-markovian_reward_functions .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-232 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "To represent behaviours compactly, we adopt a version of future linear temporal logic (FLTL) (see Emerson, 1990), augmented with a propositional **constant '$', intended to be** read 'The behaviour we want to reward has just happened' or 'The reward is received now'. The language $FLTL begins with a set of basic propositions P **giving rise to literals:**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-232-Sentence-2321,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-232-Sentence-2322 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-232-Sentence-2321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To represent behaviours compactly, we adopt a version of future linear temporal logic (FLTL) (see Emerson, 1990), augmented with a propositional **constant '$', intended to be** read 'The behaviour we want to reward has just happened' or 'The reward is received now'."@en ;
    askg-onto:inSentence "To represent behaviours compactly, we adopt a version of future linear temporal logic (FLTL) (see Emerson, 1990), augmented with a propositional **constant '$', intended to be** read 'The behaviour we want to reward has just happened' or 'The reward is received now'."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-future_linear_temporal_logic_fltl,
        askg-data:Entity-temporal_logic,
        askg-data:Entity-the_behaviour_we_want_to_reward_has_just_happened_or_the_reward_is_received_now .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-232-Sentence-2322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The language $FLTL begins with a set of basic propositions P **giving rise to literals:**"@en ;
    askg-onto:inSentence "The language $FLTL begins with a set of basic propositions P **giving rise to literals:**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_set_of_basic_propositions_p,
        askg-data:Entity-basic_propositions_p,
        askg-data:Entity-fltl,
        askg-data:Entity-literals .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-233 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$${\\mathcal{L}}::={\\mathcal{P}}\\mid\\neg{\\mathcal{P}}\\mid\\top\\mid\\bot\\mid\\$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-233-Sentence-2331 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-233-Sentence-2331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\mathcal{L}}::={\\mathcal{P}}\\mid\\neg{\\mathcal{P}}\\mid\\top\\mid\\bot\\mid\\$$"@en ;
    askg-onto:inSentence "$${\\mathcal{L}}::={\\mathcal{P}}\\mid\\neg{\\mathcal{P}}\\mid\\top\\mid\\bot\\mid\\$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0A%0A%09extl%0A,
        askg-data:Entity-%0A%0A%09extp%0A .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "where ⊤ and ⊥ stand for 'true' and 'false', respectively. The connectives are classical ∧ and ∨, and the temporal modalities (next) and U (weak **until), giving formulae:** F ::= L | F ∧ F | F ∨ F | **F | F** U F Our 'until' is weak: f1 Uf2 means f1 will be true from now on until f2 **is, if ever. Unlike** the more commonly used strong 'until', this does not imply that f2 **will eventually be true.** It allows us to define the useful operator (always): f ≡ f U⊥ (f **will always be true** from now on). We also adopt the notations kf for k iterations of the **modality (f will** be true in exactly k steps), ♦kf for Wk i=1 if (f will be true within the next k **steps), and** kf for Vk i=1 if (f will be true throughout the next k **steps).** Although negation officially occurs only in literals, i.e., the formulae are in negation normal form (NNF), we allow ourselves to write formulae involving it in the usual way, provided that they have an equivalent in NNF. Not every formula has such an equivalent, because there is no such literal as ¬**$ and because eventualities ('f will be true some time')** are not expressible. These restrictions are deliberate. If **we were to use our notation and** logic to theorise **about the allocation of rewards, we would indeed need the means to say** when rewards are not received or to express features such as liveness ('always, there will be a reward eventually'), but in fact we are using them only as a mechanism for ensuring that rewards are given where they should be, and for this restricted purpose eventualities and the negated dollar are not needed. In fact, including them would create technical difficulties in relating formulae to the behaviours they represent."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2341,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2342,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2343,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2344,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2345,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2346,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2347,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2348 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where ⊤ and ⊥ stand for 'true' and 'false', respectively."@en ;
    askg-onto:inSentence "where ⊤ and ⊥ stand for 'true' and 'false', respectively."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-false,
        askg-data:Entity-true .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The connectives are classical ∧ and ∨, and the temporal modalities (next) and U (weak **until), giving formulae:** F ::= L | F ∧ F | F ∨ F | **F | F** U F Our 'until' is weak: f1 Uf2 means f1 will be true from now on until f2 **is, if ever."@en ;
    askg-onto:inSentence "The connectives are classical ∧ and ∨, and the temporal modalities (next) and U (weak **until), giving formulae:** F ::= L | F ∧ F | F ∨ F | **F | F** U F Our 'until' is weak: f1 Uf2 means f1 will be true from now on until f2 **is, if ever."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classical__and_,
        askg-data:Entity-connectives,
        askg-data:Entity-f1,
        askg-data:Entity-f2,
        askg-data:Entity-f__l__f__f__f__f__f__f_u_f,
        askg-data:Entity-formulae,
        askg-data:Entity-next,
        askg-data:Entity-temporal_modalities,
        askg-data:Entity-u_weak_until,
        askg-data:Entity-until,
        askg-data:Entity-weak .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Unlike** the more commonly used strong 'until', this does not imply that f2 **will eventually be true.** It allows us to define the useful operator (always): f ≡ f U⊥ (f **will always be true** from now on)."@en ;
    askg-onto:inSentence "Unlike** the more commonly used strong 'until', this does not imply that f2 **will eventually be true.** It allows us to define the useful operator (always): f ≡ f U⊥ (f **will always be true** from now on)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-f2,
        askg-data:Entity-f_u,
        askg-data:Entity-operator_always .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2344 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We also adopt the notations kf for k iterations of the **modality (f will** be true in exactly k steps), ♦kf for Wk i=1 if (f will be true within the next k **steps), and** kf for Vk i=1 if (f will be true throughout the next k **steps).** Although negation officially occurs only in literals, i.e., the formulae are in negation normal form (NNF), we allow ourselves to write formulae involving it in the usual way, provided that they have an equivalent in NNF."@en ;
    askg-onto:inSentence "We also adopt the notations kf for k iterations of the **modality (f will** be true in exactly k steps), ♦kf for Wk i=1 if (f will be true within the next k **steps), and** kf for Vk i=1 if (f will be true throughout the next k **steps).** Although negation officially occurs only in literals, i.e., the formulae are in negation normal form (NNF), we allow ourselves to write formulae involving it in the usual way, provided that they have an equivalent in NNF."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-literals,
        askg-data:Entity-negation,
        askg-data:Entity-negation_normal_form_nnf,
        askg-data:Entity-nnf .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2345 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Not every formula has such an equivalent, because there is no such literal as ¬**$ and because eventualities ('f will be true some time')** are not expressible."@en ;
    askg-onto:inSentence "Not every formula has such an equivalent, because there is no such literal as ¬**$ and because eventualities ('f will be true some time')** are not expressible."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-eventualities .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2346 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "These restrictions are deliberate."@en ;
    askg-onto:inSentence "These restrictions are deliberate."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deliberate,
        askg-data:Entity-restrictions .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2347 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "If **we were to use our notation and** logic to theorise **about the allocation of rewards, we would indeed need the means to say** when rewards are not received or to express features such as liveness ('always, there will be a reward eventually'), but in fact we are using them only as a mechanism for ensuring that rewards are given where they should be, and for this restricted purpose eventualities and the negated dollar are not needed."@en ;
    askg-onto:inSentence "If **we were to use our notation and** logic to theorise **about the allocation of rewards, we would indeed need the means to say** when rewards are not received or to express features such as liveness ('always, there will be a reward eventually'), but in fact we are using them only as a mechanism for ensuring that rewards are given where they should be, and for this restricted purpose eventualities and the negated dollar are not needed."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eventualities,
        askg-data:Entity-liveness,
        askg-data:Entity-mechanism,
        askg-data:Entity-negated_dollar,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-234-Sentence-2348 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In fact, including them would create technical difficulties in relating formulae to the behaviours they represent."@en ;
    askg-onto:inSentence "In fact, including them would create technical difficulties in relating formulae to the behaviours they represent."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "The semantics of this language is similar to that of FLTL, with an important difference: because the interpretation of the constant $ depends on the behaviour B **we want to reward** (whatever that is), the modelling relation |= must be indexed by B**. We therefore write** (Γ,i)|=B f to mean that formula f holds at the i**-th stage of an arbitrary sequence Γ** ∈ S ω, relative to behaviour B. Defining |=B**is the first step in our description of the semantics:** (Γ,i)|=B $ iff Γ(i) ∈ B (Γ,i)|=B ⊤ (Γ,i) 6|=B ⊥ (Γ,i)|=B p, for p ∈ P**, iff** p ∈ Γi (Γ,i)|=B ¬p, for p ∈ P**, iff** p 6∈ Γi (Γ,i)|=B f1 ∧ f2 **iff (Γ**,i)|=B f1 **and (Γ**,i)|=B f2 (Γ,i)|=B f1 ∨ f2 **iff (Γ**,i)|=B f1 **or (Γ**,i)|=B f2 (Γ,i)|=B f iff (Γ,i **+ 1)**|=B f (Γ,i)|=B f1 Uf2 iff ∀k ≥ i if (∀j,i ≤ j ≤ k (Γ,j) 6|=B f2**) then (Γ**,k)|=B f1 Note that except for subscript B **and for the first rule, this is just the standard FLTL** semantics, and that therefore $-free formulae keep their FLTL meaning. As with FLTL, we say Γ |=B f **iff (Γ**, 0)|=B f**, and** |=B f **iff Γ** |=B f **for all Γ** ∈ S ω."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2351,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2352,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2353,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2354 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The semantics of this language is similar to that of FLTL, with an important difference: because the interpretation of the constant $ depends on the behaviour B **we want to reward** (whatever that is), the modelling relation |= must be indexed by B**."@en ;
    askg-onto:inSentence "The semantics of this language is similar to that of FLTL, with an important difference: because the interpretation of the constant $ depends on the behaviour B **we want to reward** (whatever that is), the modelling relation |= must be indexed by B**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-behaviour_b,
        askg-data:Entity-constant_,
        askg-data:Entity-fltl,
        askg-data:Entity-modelling_relation,
        askg-data:Entity-semantics,
        askg-data:Entity-whatever_that_is .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We therefore write** (Γ,i)|=B f to mean that formula f holds at the i**-th stage of an arbitrary sequence Γ** ∈ S ω, relative to behaviour B."@en ;
    askg-onto:inSentence "We therefore write** (Γ,i)|=B f to mean that formula f holds at the i**-th stage of an arbitrary sequence Γ** ∈ S ω, relative to behaviour B."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-i-th_stage,
        askg-data:Entity-s_%CF%89 .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2353 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Defining |=B**is the first step in our description of the semantics:** (Γ,i)|=B $ iff Γ(i) ∈ B (Γ,i)|=B ⊤ (Γ,i) 6|=B ⊥ (Γ,i)|=B p, for p ∈ P**, iff** p ∈ Γi (Γ,i)|=B ¬p, for p ∈ P**, iff** p 6∈ Γi (Γ,i)|=B f1 ∧ f2 **iff (Γ**,i)|=B f1 **and (Γ**,i)|=B f2 (Γ,i)|=B f1 ∨ f2 **iff (Γ**,i)|=B f1 **or (Γ**,i)|=B f2 (Γ,i)|=B f iff (Γ,i **+ 1)**|=B f (Γ,i)|=B f1 Uf2 iff ∀k ≥ i if (∀j,i ≤ j ≤ k (Γ,j) 6|=B f2**) then (Γ**,k)|=B f1 Note that except for subscript B **and for the first rule, this is just the standard FLTL** semantics, and that therefore $-free formulae keep their FLTL meaning."@en ;
    askg-onto:inSentence "Defining |=B**is the first step in our description of the semantics:** (Γ,i)|=B $ iff Γ(i) ∈ B (Γ,i)|=B ⊤ (Γ,i) 6|=B ⊥ (Γ,i)|=B p, for p ∈ P**, iff** p ∈ Γi (Γ,i)|=B ¬p, for p ∈ P**, iff** p 6∈ Γi (Γ,i)|=B f1 ∧ f2 **iff (Γ**,i)|=B f1 **and (Γ**,i)|=B f2 (Γ,i)|=B f1 ∨ f2 **iff (Γ**,i)|=B f1 **or (Γ**,i)|=B f2 (Γ,i)|=B f iff (Γ,i **+ 1)**|=B f (Γ,i)|=B f1 Uf2 iff ∀k ≥ i if (∀j,i ≤ j ≤ k (Γ,j) 6|=B f2**) then (Γ**,k)|=B f1 Note that except for subscript B **and for the first rule, this is just the standard FLTL** semantics, and that therefore $-free formulae keep their FLTL meaning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-meaning .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-235-Sentence-2354 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As with FLTL, we say Γ |=B f **iff (Γ**, 0)|=B f**, and** |=B f **iff Γ** |=B f **for all Γ** ∈ S ω."@en ;
    askg-onto:inSentence "As with FLTL, we say Γ |=B f **iff (Γ**, 0)|=B f**, and** |=B f **iff Γ** |=B f **for all Γ** ∈ S ω."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-f,
        askg-data:Entity-s_%CF%89 .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "The modelling relation |=B**can be seen as specifying when a formula holds, on which** reading it takes B as input. Our next and final step is to use the |=B**relation to define,** for a formula f, the behaviour Bf that it represents, and for this we must rather **assume** that f holds, and then solve for B. For instance, let f be (p → **$), i.e., we get rewarded** every time p is true. We would like Bf **to be the set of all finite sequences ending with a** state containing p. For an arbitrary f, we take Bf to be the set of prefixes that have **to be** rewarded if f **is to hold in all sequences:**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2361,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2362,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2363,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2364,
        askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2365 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The modelling relation |=B**can be seen as specifying when a formula holds, on which** reading it takes B as input."@en ;
    askg-onto:inSentence "The modelling relation |=B**can be seen as specifying when a formula holds, on which** reading it takes B as input."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-formula,
        askg-data:Entity-modelling_relation,
        askg-data:Entity-when_a_formula_holds .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Our next and final step is to use the |=B**relation to define,** for a formula f, the behaviour Bf that it represents, and for this we must rather **assume** that f holds, and then solve for B."@en ;
    askg-onto:inSentence "Our next and final step is to use the |=B**relation to define,** for a formula f, the behaviour Bf that it represents, and for this we must rather **assume** that f holds, and then solve for B."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviour_bf,
        askg-data:Entity-formula_f .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2363 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For instance, let f be (p → **$), i.e., we get rewarded** every time p is true."@en ;
    askg-onto:inSentence "For instance, let f be (p → **$), i.e., we get rewarded** every time p is true."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2364 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We would like Bf **to be the set of all finite sequences ending with a** state containing p."@en ;
    askg-onto:inSentence "We would like Bf **to be the set of all finite sequences ending with a** state containing p."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bf,
        askg-data:Entity-the_set_of_all_finite_sequences_ending_with_a_state_containing_p .

askg-data:Paper-c253584c3f1ff2a2-Section-23-Paragraph-236-Sentence-2365 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For an arbitrary f, we take Bf to be the set of prefixes that have **to be** rewarded if f **is to hold in all sequences:**"@en ;
    askg-onto:inSentence "For an arbitrary f, we take Bf to be the set of prefixes that have **to be** rewarded if f **is to hold in all sequences:**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_sequences,
        askg-data:Entity-f,
        askg-data:Entity-if_f,
        askg-data:Entity-prefixes .

askg-data:Paper-c253584c3f1ff2a2-Section-24 a askg-onto:Section ;
    rdfs:label "Section 24"@en ;
    domo:Text "Definition 2 Bf ≡T{B | |=B F}"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241 ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To understand Definition 2, recall that B **contains prefixes at the end of which we get** a reward and $ evaluates to true. Since f **is supposed to describe the way rewards will** be received in an arbitrary sequence, we are interested in behaviours B **which make $** true in such a way as to make f **hold without imposing constraints on the evolution of** the world. However, there may be many behaviours with this property, so we take their intersection,3ensuring that Bf **will only reward a prefix if it has to because that prefix is in** every behaviour satisfying f**. In all but pathological cases (see Section 3.4), this makes** Bf coincide with the (set-inclusion) minimal behaviour B **such that** |=B f**. The reason for this** 'stingy' semantics, making rewards minimal, is that f **does not actually say that rewards** are allocated to more prefixes than are required for its truth. For instance, (p → $) **says** only that a reward is given every time p **is true, even though a more generous distribution** of rewards would be consistent **with it.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2411,
        askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2412,
        askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2413,
        askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2414,
        askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2415,
        askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2416 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To understand Definition 2, recall that B **contains prefixes at the end of which we get** a reward and $ evaluates to true."@en ;
    askg-onto:inSentence "To understand Definition 2, recall that B **contains prefixes at the end of which we get** a reward and $ evaluates to true."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-prefixes,
        askg-data:Entity-reward,
        askg-data:Entity-true .

askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Since f **is supposed to describe the way rewards will** be received in an arbitrary sequence, we are interested in behaviours B **which make $** true in such a way as to make f **hold without imposing constraints on the evolution of** the world."@en ;
    askg-onto:inSentence "Since f **is supposed to describe the way rewards will** be received in an arbitrary sequence, we are interested in behaviours B **which make $** true in such a way as to make f **hold without imposing constraints on the evolution of** the world."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-behaviours_b,
        askg-data:Entity-f,
        askg-data:Entity-world .

askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, there may be many behaviours with this property, so we take their intersection,3ensuring that Bf **will only reward a prefix if it has to because that prefix is in** every behaviour satisfying f**."@en ;
    askg-onto:inSentence "However, there may be many behaviours with this property, so we take their intersection,3ensuring that Bf **will only reward a prefix if it has to because that prefix is in** every behaviour satisfying f**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_prefix,
        askg-data:Entity-bf,
        askg-data:Entity-every_behaviour_satisfying_f,
        askg-data:Entity-prefix .

askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In all but pathological cases (see Section 3.4), this makes** Bf coincide with the (set-inclusion) minimal behaviour B **such that** |=B f**."@en ;
    askg-onto:inSentence "In all but pathological cases (see Section 3.4), this makes** Bf coincide with the (set-inclusion) minimal behaviour B **such that** |=B f**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b,
        askg-data:Entity-bf .

askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The reason for this** 'stingy' semantics, making rewards minimal, is that f **does not actually say that rewards** are allocated to more prefixes than are required for its truth."@en ;
    askg-onto:inSentence "The reason for this** 'stingy' semantics, making rewards minimal, is that f **does not actually say that rewards** are allocated to more prefixes than are required for its truth."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-prefixes,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-24-Paragraph-241-Sentence-2416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "For instance, (p → $) **says** only that a reward is given every time p **is true, even though a more generous distribution** of rewards would be consistent **with it.**"@en ;
    askg-onto:inSentence "For instance, (p → $) **says** only that a reward is given every time p **is true, even though a more generous distribution** of rewards would be consistent **with it.**"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-every_time_p_is_true,
        askg-data:Entity-more_generous_distribution,
        askg-data:Entity-p,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-25 a askg-onto:Section ;
    rdfs:label "Section 25"@en ;
    domo:Text "3.3 Examples"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-251,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-254,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-255 ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-251 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "It is intuitively clear that many behaviours can be specified **by means of $FLTL formulae.** While there is no simple way in general to translate between past and future tense expressions,4 **all of the examples used to illustrate PLTL in Section 2.2 above are expressible** naturally in $FLTL, as follows."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-251-Sentence-2511 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-251-Sentence-2511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "It is intuitively clear that many behaviours can be specified **by means of $FLTL formulae.** While there is no simple way in general to translate between past and future tense expressions,4 **all of the examples used to illustrate PLTL in Section 2.2 above are expressible** naturally in $FLTL, as follows."@en ;
    askg-onto:inSentence "It is intuitively clear that many behaviours can be specified **by means of $FLTL formulae.** While there is no simple way in general to translate between past and future tense expressions,4 **all of the examples used to illustrate PLTL in Section 2.2 above are expressible** naturally in $FLTL, as follows."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-examples,
        askg-data:Entity-fltl_formulae,
        askg-data:Entity-pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The classical goal formula g saying that a goal p **is rewarded whenever it happens is** easily expressed: (p → $). As already noted, Bg **is the set of finite sequences of states such** that p holds in the last state. If we only care that p **is achieved once and get rewarded at** each state from then on, we write (p → **$). The behaviour that this formula represents** is the set of finite state sequences having at least one state in which p **holds. By contrast,** the formula ¬pU(p ∧ $) stipulates only that the first occurrence of p **is rewarded (i.e. it** specifies the behaviour in Figure 1). To reward the occurrence of p **at most once every** k steps, we write ((k+1p ∧ k¬p) → k+1$)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2521,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2522,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2523,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2524,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2525,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2526,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2527 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The classical goal formula g saying that a goal p **is rewarded whenever it happens is** easily expressed: (p → $)."@en ;
    askg-onto:inSentence "The classical goal formula g saying that a goal p **is rewarded whenever it happens is** easily expressed: (p → $)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-goal_p .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As already noted, Bg **is the set of finite sequences of states such** that p holds in the last state."@en ;
    askg-onto:inSentence "As already noted, Bg **is the set of finite sequences of states such** that p holds in the last state."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bg,
        askg-data:Entity-finite_sequences_of_states,
        askg-data:Entity-p,
        askg-data:Entity-the_last_state .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "If we only care that p **is achieved once and get rewarded at** each state from then on, we write (p → **$)."@en ;
    askg-onto:inSentence "If we only care that p **is achieved once and get rewarded at** each state from then on, we write (p → **$)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-p .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The behaviour that this formula represents** is the set of finite state sequences having at least one state in which p **holds."@en ;
    askg-onto:inSentence "The behaviour that this formula represents** is the set of finite state sequences having at least one state in which p **holds."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finite_state_sequences,
        askg-data:Entity-set_of_finite_state_sequences_having_at_least_one_state_in_which_p_holds .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "By contrast,** the formula ¬pU(p ∧ $) stipulates only that the first occurrence of p **is rewarded (i.e."@en ;
    askg-onto:inSentence "By contrast,** the formula ¬pU(p ∧ $) stipulates only that the first occurrence of p **is rewarded (i.e."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_occurrence_of_p,
        askg-data:Entity-formula_pup__ .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2526 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "it** specifies the behaviour in Figure 1)."@en ;
    askg-onto:inSentence "it** specifies the behaviour in Figure 1)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviour .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-252-Sentence-2527 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "To reward the occurrence of p **at most once every** k steps, we write ((k+1p ∧ k¬p) → k+1$)."@en ;
    askg-onto:inSentence "To reward the occurrence of p **at most once every** k steps, we write ((k+1p ∧ k¬p) → k+1$)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k_steps .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "For response formulae, where the achievement of p **is triggered by the command** c, we write (c → (p → $)) to reward every state in which p **is true following the first** issue of the command. To reward only the first occurrence p **after each command, we write** (c → (¬pU(p∧**$))). As for bounded variants for which we only reward goal achievement** within k steps of the trigger command, we write for example (c → k(p → **$)) to reward** all such states in which p **holds.** It is also worth noting how to express simple behaviours involving past tense operators."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253-Sentence-2531,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253-Sentence-2532,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253-Sentence-2533 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253-Sentence-2531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For response formulae, where the achievement of p **is triggered by the command** c, we write (c → (p → $)) to reward every state in which p **is true following the first** issue of the command."@en ;
    askg-onto:inSentence "For response formulae, where the achievement of p **is triggered by the command** c, we write (c → (p → $)) to reward every state in which p **is true following the first** issue of the command."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-p .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253-Sentence-2532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To reward only the first occurrence p **after each command, we write** (c → (¬pU(p∧**$)))."@en ;
    askg-onto:inSentence "To reward only the first occurrence p **after each command, we write** (c → (¬pU(p∧**$)))."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-pup .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-253-Sentence-2533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As for bounded variants for which we only reward goal achievement** within k steps of the trigger command, we write for example (c → k(p → **$)) to reward** all such states in which p **holds.** It is also worth noting how to express simple behaviours involving past tense operators."@en ;
    askg-onto:inSentence "As for bounded variants for which we only reward goal achievement** within k steps of the trigger command, we write for example (c → k(p → **$)) to reward** all such states in which p **holds.** It is also worth noting how to express simple behaviours involving past tense operators."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bounded_variants,
        askg-data:Entity-goal_achievement,
        askg-data:Entity-p,
        askg-data:Entity-states .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-254 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "To stipulate a reward if p has always been true, we write $U¬p**. To say that we are rewarded** if p has been true since q was, we write (q → ($U¬p))."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-254-Sentence-2541,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-254-Sentence-2542 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-254-Sentence-2541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To stipulate a reward if p has always been true, we write $U¬p**."@en ;
    askg-onto:inSentence "To stipulate a reward if p has always been true, we write $U¬p**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward_condition,
        askg-data:Entity-up .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-254-Sentence-2542 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To say that we are rewarded** if p has been true since q was, we write (q → ($U¬p))."@en ;
    askg-onto:inSentence "To say that we are rewarded** if p has been true since q was, we write (q → ($U¬p))."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-up .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-255 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Finally, we often find it useful to reward the holding of p until the occurrence of q**. The** neatest expression for this is ¬q U((¬p ∧ ¬q) ∨ (q ∧ **$)).**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-255-Sentence-2551,
        askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-255-Sentence-2552 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-255-Sentence-2551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Finally, we often find it useful to reward the holding of p until the occurrence of q**."@en ;
    askg-onto:inSentence "Finally, we often find it useful to reward the holding of p until the occurrence of q**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p,
        askg-data:Entity-q .

askg-data:Paper-c253584c3f1ff2a2-Section-25-Paragraph-255-Sentence-2552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The** neatest expression for this is ¬q U((¬p ∧ ¬q) ∨ (q ∧ **$)).**"@en ;
    askg-onto:inSentence "The** neatest expression for this is ¬q U((¬p ∧ ¬q) ∨ (q ∧ **$)).**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-q_up__q__q__ .

askg-data:Paper-c253584c3f1ff2a2-Section-26 a askg-onto:Section ;
    rdfs:label "Section 26"@en ;
    domo:Text "3.4 Reward Normality"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264 ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "$FLTL is therefore quite expressive. Unfortunately, it is rather too **expressive, in that it** contains formulae which describe \"unnatural\" allocations **of rewards. For instance, they** may make rewards depend on future behaviours rather than on the past, or they may"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261-Sentence-2611,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261-Sentence-2612,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261-Sentence-2613 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261-Sentence-2611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$FLTL is therefore quite expressive."@en ;
    askg-onto:inSentence "$FLTL is therefore quite expressive."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expressive,
        askg-data:Entity-fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261-Sentence-2612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Unfortunately, it is rather too **expressive, in that it** contains formulae which describe \"unnatural\" allocations **of rewards."@en ;
    askg-onto:inSentence "Unfortunately, it is rather too **expressive, in that it** contains formulae which describe \"unnatural\" allocations **of rewards."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-unnatural_allocations_of_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-261-Sentence-2613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For instance, they** may make rewards depend on future behaviours rather than on the past, or they may"@en ;
    askg-onto:inSentence "For instance, they** may make rewards depend on future behaviours rather than on the past, or they may"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_behaviours,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "3. If there is no B **such that** |=B f, which is the case for any $-free f **which is not a logical theorem, then** Bf is T∅ **– i.e.** S ∗**following normal set-theoretic conventions. This limiting case does no harm, since** $-free formulae do not describe the attribution of rewards."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262-Sentence-2621,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262-Sentence-2622,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262-Sentence-2623 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262-Sentence-2621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3."@en ;
    askg-onto:inSentence "3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-research,
        askg-data:Entity-study,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262-Sentence-2622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "If there is no B **such that** |=B f, which is the case for any $-free f **which is not a logical theorem, then** Bf is T∅ **– i.e.** S ∗**following normal set-theoretic conventions."@en ;
    askg-onto:inSentence "If there is no B **such that** |=B f, which is the case for any $-free f **which is not a logical theorem, then** Bf is T∅ **– i.e.** S ∗**following normal set-theoretic conventions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bf,
        askg-data:Entity-t .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-262-Sentence-2623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This limiting case does no harm, since** $-free formulae do not describe the attribution of rewards."@en ;
    askg-onto:inSentence "This limiting case does no harm, since** $-free formulae do not describe the attribution of rewards."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity--free_formulae,
        askg-data:Entity-the_attribution_of_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "4. It is an open question whether the set of representable behaviours is the same for $FLTL as for PLTL, that is star-free regular languages. Even if the behaviours **were the same, there is little hope that a** practical translation from one to the other exists. leave open a choice as to which of several behaviours is to be rewarded.5 **An example of** dependence on the future is p → $, which stipulates a reward now if p **is going to hold** next. We call such formula reward-unstable. What a reward-stable f **amounts to is that** whether a particular prefix needs to be rewarded in order to make f **true does not depend** on the future of the sequence. An example of an open choice of which behavior to reward is (p → $) ∨ (¬p → $) which says we should either **reward all achievements of the goal** p or reward achievements of ¬p but does not determine which. We call such formula rewardindeterminate. What a reward-determinate f **amounts to is that the set of behaviours** modelling f, i.e. {B | |=B f}, has a unique minimum. If it does not, Bf **is insufficient (too** small) to make f **true.** In investigating $FLTL (Slaney, 2005), we examine the notions of reward-stability and reward-determinacy in depth, and motivate the claim that formulae that are both rewardstable and reward-determinate - we call them reward-normal **– are precisely those that** capture the notion of \"no funny business\". This is the intuition that we ask the reader to note, as it will be needed in the rest of the paper. Just for reference then, we define: Definition 3 f is reward-normal **iff for every** Γ ∈ S ω **and every** B ⊆ S ∗, Γ |=B f **iff for** every i, if Γ(i) ∈ Bf **then** Γ(i) ∈ B."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2631,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26310,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26311,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26312,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26313,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2632,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2633,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2634,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2635,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2636,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2637,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2638,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2639 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4."@en ;
    askg-onto:inSentence "4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-finding,
        askg-data:Entity-research,
        askg-data:Entity-study,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "{B | |=B f}, has a unique minimum."@en ;
    askg-onto:inSentence "{B | |=B f}, has a unique minimum."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_unique_minimum,
        askg-data:Entity-b .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "If it does not, Bf **is insufficient (too** small) to make f **true.** In investigating $FLTL (Slaney, 2005), we examine the notions of reward-stability and reward-determinacy in depth, and motivate the claim that formulae that are both rewardstable and reward-determinate - we call them reward-normal **– are precisely those that** capture the notion of \"no funny business\"."@en ;
    askg-onto:inSentence "If it does not, Bf **is insufficient (too** small) to make f **true.** In investigating $FLTL (Slaney, 2005), we examine the notions of reward-stability and reward-determinacy in depth, and motivate the claim that formulae that are both rewardstable and reward-determinate - we call them reward-normal **– are precisely those that** capture the notion of \"no funny business\"."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-no_funny_business,
        askg-data:Entity-reward-determinacy,
        askg-data:Entity-reward-normal,
        askg-data:Entity-reward-stability .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "This is the intuition that we ask the reader to note, as it will be needed in the rest of the paper."@en ;
    askg-onto:inSentence "This is the intuition that we ask the reader to note, as it will be needed in the rest of the paper."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-intuition,
        askg-data:Entity-reader .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-26313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Just for reference then, we define: Definition 3 f is reward-normal **iff for every** Γ ∈ S ω **and every** B ⊆ S ∗, Γ |=B f **iff for** every i, if Γ(i) ∈ Bf **then** Γ(i) ∈ B."@en ;
    askg-onto:inSentence "Just for reference then, we define: Definition 3 f is reward-normal **iff for every** Γ ∈ S ω **and every** B ⊆ S ∗, Γ |=B f **iff for** every i, if Γ(i) ∈ Bf **then** Γ(i) ∈ B."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-%CE%B3_b_f,
        askg-data:Entity-%CE%B3i,
        askg-data:Entity-b,
        askg-data:Entity-bf,
        askg-data:Entity-f,
        askg-data:Entity-s_,
        askg-data:Entity-s_%CF%89 .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It is an open question whether the set of representable behaviours is the same for $FLTL as for PLTL, that is star-free regular languages."@en ;
    askg-onto:inSentence "It is an open question whether the set of representable behaviours is the same for $FLTL as for PLTL, that is star-free regular languages."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-pltl,
        askg-data:Entity-star-free_regular_languages .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Even if the behaviours **were the same, there is little hope that a** practical translation from one to the other exists."@en ;
    askg-onto:inSentence "Even if the behaviours **were the same, there is little hope that a** practical translation from one to the other exists."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-hope,
        askg-data:Entity-practical_translation .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "leave open a choice as to which of several behaviours is to be rewarded.5 **An example of** dependence on the future is p → $, which stipulates a reward now if p **is going to hold** next."@en ;
    askg-onto:inSentence "leave open a choice as to which of several behaviours is to be rewarded.5 **An example of** dependence on the future is p → $, which stipulates a reward now if p **is going to hold** next."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dependence_on_the_future,
        askg-data:Entity-p__,
        askg-data:Entity-p_is_going_to_hold_next,
        askg-data:Entity-reward_now .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2635 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We call such formula reward-unstable."@en ;
    askg-onto:inSentence "We call such formula reward-unstable."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula,
        askg-data:Entity-reward-unstable .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2636 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "What a reward-stable f **amounts to is that** whether a particular prefix needs to be rewarded in order to make f **true does not depend** on the future of the sequence."@en ;
    askg-onto:inSentence "What a reward-stable f **amounts to is that** whether a particular prefix needs to be rewarded in order to make f **true does not depend** on the future of the sequence."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_of_the_sequence,
        askg-data:Entity-particular_prefix,
        askg-data:Entity-reward-stable,
        askg-data:Entity-rewarded,
        askg-data:Entity-to_make_f_true,
        askg-data:Entity-whether_a_particular_prefix_needs_to_be_rewarded .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2637 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "An example of an open choice of which behavior to reward is (p → $) ∨ (¬p → $) which says we should either **reward all achievements of the goal** p or reward achievements of ¬p but does not determine which."@en ;
    askg-onto:inSentence "An example of an open choice of which behavior to reward is (p → $) ∨ (¬p → $) which says we should either **reward all achievements of the goal** p or reward achievements of ¬p but does not determine which."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievements_of_p,
        askg-data:Entity-achievements_of_the_goal_p,
        askg-data:Entity-rewards_achievements_of_p,
        askg-data:Entity-rewards_all_achievements_of_the_goal_p .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2638 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We call such formula rewardindeterminate."@en ;
    askg-onto:inSentence "We call such formula rewardindeterminate."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula,
        askg-data:Entity-rewardindeterminate .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-263-Sentence-2639 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "What a reward-determinate f **amounts to is that the set of behaviours** modelling f, i.e."@en ;
    askg-onto:inSentence "What a reward-determinate f **amounts to is that the set of behaviours** modelling f, i.e."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-set_of_behaviours .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "The property of reward-normality is decidable (Slaney, 2005). In Appendix A we give some simple syntactic constructions guaranteed to result in reward-normal formulae. While reward-abnormal formulae may be interesting, for present purposes we restrict attention to reward-normal ones. Indeed, we stipulate as part of our method that only reward-normal formulae should be used to represent behaviours. Naturally, all formulae in Section 3.3 are normal."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2641,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2642,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2643,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2644,
        askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2645 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The property of reward-normality is decidable (Slaney, 2005)."@en ;
    askg-onto:inSentence "The property of reward-normality is decidable (Slaney, 2005)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward-normality,
        askg-data:Entity-slaney_2005 .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In Appendix A we give some simple syntactic constructions guaranteed to result in reward-normal formulae."@en ;
    askg-onto:inSentence "In Appendix A we give some simple syntactic constructions guaranteed to result in reward-normal formulae."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward-normal_formulae,
        askg-data:Entity-syntactic_constructions .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2643 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While reward-abnormal formulae may be interesting, for present purposes we restrict attention to reward-normal ones."@en ;
    askg-onto:inSentence "While reward-abnormal formulae may be interesting, for present purposes we restrict attention to reward-normal ones."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward-abnormal_formulae,
        askg-data:Entity-reward-normal_ones .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2644 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Indeed, we stipulate as part of our method that only reward-normal formulae should be used to represent behaviours."@en ;
    askg-onto:inSentence "Indeed, we stipulate as part of our method that only reward-normal formulae should be used to represent behaviours."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-reward-normal_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-26-Paragraph-264-Sentence-2645 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Naturally, all formulae in Section 3.3 are normal."@en ;
    askg-onto:inSentence "Naturally, all formulae in Section 3.3 are normal."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-section_33 .

askg-data:Paper-c253584c3f1ff2a2-Section-27 a askg-onto:Section ;
    rdfs:label "Section 27"@en ;
    domo:Text "3.5 $Fltl Formula Progression"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-274,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-278,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279 ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Having defined a language to represent behaviours to be rewarded, we now turn to the problem of computing, given a reward formula, a minimum allocation of rewards to states actually encountered in an execution sequence, in such a way **as to satisfy the formula.** Because we ultimately wish to use anytime solution methods which generate state sequences incrementally via forward search, this computation is best **done on the fly, while the sequence** is being generated. We therefore devise an incremental algorithm based on a model-checking technique normally used to check whether a state sequence is **a model of an FLTL formula** (Bacchus & Kabanza, 1998). This technique is known as formula progression **because it** 'progresses' or 'pushes' the formula through the sequence."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271-Sentence-2711,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271-Sentence-2712,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271-Sentence-2713 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271-Sentence-2711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Having defined a language to represent behaviours to be rewarded, we now turn to the problem of computing, given a reward formula, a minimum allocation of rewards to states actually encountered in an execution sequence, in such a way **as to satisfy the formula.** Because we ultimately wish to use anytime solution methods which generate state sequences incrementally via forward search, this computation is best **done on the fly, while the sequence** is being generated."@en ;
    askg-onto:inSentence "Having defined a language to represent behaviours to be rewarded, we now turn to the problem of computing, given a reward formula, a minimum allocation of rewards to states actually encountered in an execution sequence, in such a way **as to satisfy the formula.** Because we ultimately wish to use anytime solution methods which generate state sequences incrementally via forward search, this computation is best **done on the fly, while the sequence** is being generated."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_solution_methods,
        askg-data:Entity-forward_search,
        askg-data:Entity-minimum_allocation_of_rewards,
        askg-data:Entity-reward_formula,
        askg-data:Entity-state_sequences .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271-Sentence-2712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We therefore devise an incremental algorithm based on a model-checking technique normally used to check whether a state sequence is **a model of an FLTL formula** (Bacchus & Kabanza, 1998)."@en ;
    askg-onto:inSentence "We therefore devise an incremental algorithm based on a model-checking technique normally used to check whether a state sequence is **a model of an FLTL formula** (Bacchus & Kabanza, 1998)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1998,
        askg-data:Entity-bacchus__kabanza,
        askg-data:Entity-fltl_formula,
        askg-data:Entity-incremental_algorithm,
        askg-data:Entity-model-checking_technique,
        askg-data:Entity-state_sequence .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-271-Sentence-2713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This technique is known as formula progression **because it** 'progresses' or 'pushes' the formula through the sequence."@en ;
    askg-onto:inSentence "This technique is known as formula progression **because it** 'progresses' or 'pushes' the formula through the sequence."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula_progression .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Our progression technique is shown in Algorithm 1. In essence, it computes the modelling relation |=B**given in Section 3.2. However,unlike the definition of** |=B , it is designed to be useful when states in the sequence become available one **at a time, in that it defers the** evaluation of the part of the formula that refers to the future to the point where the next state becomes available. Let s be a state, say Γi**, the last state of the sequence prefix Γ(**i)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2721,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2722,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2723,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2724 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our progression technique is shown in Algorithm 1."@en ;
    askg-onto:inSentence "Our progression technique is shown in Algorithm 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm_1,
        askg-data:Entity-progression_technique .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In essence, it computes the modelling relation |=B**given in Section 3.2."@en ;
    askg-onto:inSentence "In essence, it computes the modelling relation |=B**given in Section 3.2."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-modelling_relation,
        askg-data:Entity-section_32 .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However,unlike the definition of** |=B , it is designed to be useful when states in the sequence become available one **at a time, in that it defers the** evaluation of the part of the formula that refers to the future to the point where the next state becomes available."@en ;
    askg-onto:inSentence "However,unlike the definition of** |=B , it is designed to be useful when states in the sequence become available one **at a time, in that it defers the** evaluation of the part of the formula that refers to the future to the point where the next state becomes available."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-definition,
        askg-data:Entity-evaluation,
        askg-data:Entity-future,
        askg-data:Entity-next_state,
        askg-data:Entity-point,
        askg-data:Entity-states_in_the_sequence .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-272-Sentence-2724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Let s be a state, say Γi**, the last state of the sequence prefix Γ(**i)"@en ;
    askg-onto:inSentence "Let s be a state, say Γi**, the last state of the sequence prefix Γ(**i)"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-state .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "5. These difficulties are inherent in the use of linear-time formalisms in contexts where the principle of directionality must be enforced. They are shared for instance by formalisms developed for reasoning about actions such as the Event Calculus and LTL action theories (see e.g., Calvanese, De Giacomo, & Vardi, 2002). that has been generated so far, and let b be a boolean true iff Γ(i**) is in the behaviour** B to be rewarded. Let the $FLTL formula f **describe the allocation of rewards over all possible** futures. Then the progression of f through s given b, written Prog(b,s,f**), is a new formula** which will describe the allocation of rewards over all possible futures of the next **state, given** that we have just passed through s**. Crucially, the function Prog is Markovian, depending** only on the current state and the single boolean value b**. Note that Prog is computable in** linear time in the length of f**, and that for $-free formulae, it collapses to FLTL formula** progression (Bacchus & Kabanza, 1998), regardless of the value of b**. We assume that Prog** incorporates the usual simplification for sentential constants ⊥ and ⊤: f ∧ ⊥ **simplifies to** ⊥, f ∧ ⊤ simplifies to f**, etc.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2731,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2732,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2733,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2734,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2735,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2736,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2737,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2738,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2739 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "5."@en ;
    askg-onto:inSentence "5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-section_5,
        askg-data:Entity-triple_4,
        askg-data:Entity-triple_5 .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These difficulties are inherent in the use of linear-time formalisms in contexts where the principle of directionality must be enforced."@en ;
    askg-onto:inSentence "These difficulties are inherent in the use of linear-time formalisms in contexts where the principle of directionality must be enforced."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-contexts_where_the_principle_of_directionality_must_be_enforced,
        askg-data:Entity-linear-time_formalisms .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "They are shared for instance by formalisms developed for reasoning about actions such as the Event Calculus and LTL action theories (see e.g., Calvanese, De Giacomo, & Vardi, 2002)."@en ;
    askg-onto:inSentence "They are shared for instance by formalisms developed for reasoning about actions such as the Event Calculus and LTL action theories (see e.g., Calvanese, De Giacomo, & Vardi, 2002)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-calvanese_de_giacomo__vardi_2002,
        askg-data:Entity-event_calculus,
        askg-data:Entity-ltl_action_theories,
        askg-data:Entity-paper,
        askg-data:Entity-theory .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "that has been generated so far, and let b be a boolean true iff Γ(i**) is in the behaviour** B to be rewarded."@en ;
    askg-onto:inSentence "that has been generated so far, and let b be a boolean true iff Γ(i**) is in the behaviour** B to be rewarded."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-behaviour_b .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2735 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Let the $FLTL formula f **describe the allocation of rewards over all possible** futures."@en ;
    askg-onto:inSentence "Let the $FLTL formula f **describe the allocation of rewards over all possible** futures."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-allocation_of_rewards,
        askg-data:Entity-fltl_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2736 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Then the progression of f through s given b, written Prog(b,s,f**), is a new formula** which will describe the allocation of rewards over all possible futures of the next **state, given** that we have just passed through s**."@en ;
    askg-onto:inSentence "Then the progression of f through s given b, written Prog(b,s,f**), is a new formula** which will describe the allocation of rewards over all possible futures of the next **state, given** that we have just passed through s**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-allocation_of_rewards,
        askg-data:Entity-progbsf .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2737 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Crucially, the function Prog is Markovian, depending** only on the current state and the single boolean value b**."@en ;
    askg-onto:inSentence "Crucially, the function Prog is Markovian, depending** only on the current state and the single boolean value b**."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-boolean_value_b,
        askg-data:Entity-current_state,
        askg-data:Entity-prog .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2738 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Note that Prog is computable in** linear time in the length of f**, and that for $-free formulae, it collapses to FLTL formula** progression (Bacchus & Kabanza, 1998), regardless of the value of b**."@en ;
    askg-onto:inSentence "Note that Prog is computable in** linear time in the length of f**, and that for $-free formulae, it collapses to FLTL formula** progression (Bacchus & Kabanza, 1998), regardless of the value of b**."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity--free_formulae,
        askg-data:Entity-1998,
        askg-data:Entity-bacchus__kabanza,
        askg-data:Entity-fltl_formula_progression,
        askg-data:Entity-linear_time_in_the_length_of_f,
        askg-data:Entity-prog .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-273-Sentence-2739 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "We assume that Prog** incorporates the usual simplification for sentential constants ⊥ and ⊤: f ∧ ⊥ **simplifies to** ⊥, f ∧ ⊤ simplifies to f**, etc.**"@en ;
    askg-onto:inSentence "We assume that Prog** incorporates the usual simplification for sentential constants ⊥ and ⊤: f ∧ ⊥ **simplifies to** ⊥, f ∧ ⊤ simplifies to f**, etc.**"^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-f,
        askg-data:Entity-f__,
        askg-data:Entity-prog,
        askg-data:Entity-the_usual_simplification_for_sentential_constants__and_ .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-274 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "| Algorithm 1 | $FLTL Progression | | |-------------------|---------------------|---------------------------------------| | Prog(true,s, $) | = | ⊤ | | Prog(false,s, $) | = | ⊥ | | Prog(b,s, ⊤) | = | ⊤ | | Prog(b,s, ⊥) | = | ⊥ | | Prog(b,s,p) | = | ⊤ iff p ∈ s and ⊥ otherwise | | Prog(b,s,¬p) | = | ⊤ iff p 6∈ s and ⊥ otherwise | | ∧ Prog(b,s,f1 f2) | = | ∧ Prog(b,s,f1) Prog(b,s,f2) | | ∨ Prog(b,s,f1 f2) | = | ∨ Prog(b,s,f1) Prog(b,s,f2) | | Prog(b,s, f) | = | f | | Prog(b,s,f1 Uf2) | = | Prog(b,s,f2) ∨(Prog(b,s,f1) ∧ f1 Uf2) | | Rew(s,f) | = | true iff Prog(false,s,f) = ⊥ | | $Prog(s,f) | = | Prog(Rew(s,f),s,f) |"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-274-Sentence-2741 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-274-Sentence-2741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Algorithm 1 | $FLTL Progression | | |-------------------|---------------------|---------------------------------------| | Prog(true,s, $) | = | ⊤ | | Prog(false,s, $) | = | ⊥ | | Prog(b,s, ⊤) | = | ⊤ | | Prog(b,s, ⊥) | = | ⊥ | | Prog(b,s,p) | = | ⊤ iff p ∈ s and ⊥ otherwise | | Prog(b,s,¬p) | = | ⊤ iff p 6∈ s and ⊥ otherwise | | ∧ Prog(b,s,f1 f2) | = | ∧ Prog(b,s,f1) Prog(b,s,f2) | | ∨ Prog(b,s,f1 f2) | = | ∨ Prog(b,s,f1) Prog(b,s,f2) | | Prog(b,s, f) | = | f | | Prog(b,s,f1 Uf2) | = | Prog(b,s,f2) ∨(Prog(b,s,f1) ∧ f1 Uf2) | | Rew(s,f) | = | true iff Prog(false,s,f) = ⊥ | | $Prog(s,f) | = | Prog(Rew(s,f),s,f) |"@en ;
    askg-onto:inSentence "| Algorithm 1 | $FLTL Progression | | |-------------------|---------------------|---------------------------------------| | Prog(true,s, $) | = | ⊤ | | Prog(false,s, $) | = | ⊥ | | Prog(b,s, ⊤) | = | ⊤ | | Prog(b,s, ⊥) | = | ⊥ | | Prog(b,s,p) | = | ⊤ iff p ∈ s and ⊥ otherwise | | Prog(b,s,¬p) | = | ⊤ iff p 6∈ s and ⊥ otherwise | | ∧ Prog(b,s,f1 f2) | = | ∧ Prog(b,s,f1) Prog(b,s,f2) | | ∨ Prog(b,s,f1 f2) | = | ∨ Prog(b,s,f1) Prog(b,s,f2) | | Prog(b,s, f) | = | f | | Prog(b,s,f1 Uf2) | = | Prog(b,s,f2) ∨(Prog(b,s,f1) ∧ f1 Uf2) | | Rew(s,f) | = | true iff Prog(false,s,f) = ⊥ | | $Prog(s,f) | = | Prog(Rew(s,f),s,f) |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm_1,
        askg-data:Entity-fltl_progression,
        askg-data:Entity-progbs_,
        askg-data:Entity-progbsf1_f2,
        askg-data:Entity-progbsf1_uf2,
        askg-data:Entity-progbsp,
        askg-data:Entity-progfalses_,
        askg-data:Entity-progsf,
        askg-data:Entity-progtrues_,
        askg-data:Entity-rewsf .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "The fundamental property of Prog is the following. Where b ⇔ (Γ(i) ∈ B): Property 1 (Γ,i)|=B f iff (Γ,i **+ 1)**|=B Prog(b, Γi,f) Proof: **See Appendix B.** Like |=B , the function Prog seems to require B (or at least b**) as input, but of course** when progression is applied in practice we only have f **and one new state at a time of Γ,** and what we really want to do is compute the appropriate B**, namely that represented by** f**. So, similarly as in Section 3.2, we now turn to the second step, which is to use Prog to** decide on the fly whether a newly generated sequence prefix Γ(i) is in Bf **and so should** be allocated a reward. This is the purpose of the functions $Prog and Rew, also given in Algorithm 1. Given Γ and f**, the function $Prog in Algorithm 1 defines an infinite sequence** of formulae hf0,f1,...i **in the obvious way:**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2751,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2752,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2753,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2754,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2755 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The fundamental property of Prog is the following."@en ;
    askg-onto:inSentence "The fundamental property of Prog is the following."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-prog,
        askg-data:Entity-the_following .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2752 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Where b ⇔ (Γ(i) ∈ B): Property 1 (Γ,i)|=B f iff (Γ,i **+ 1)**|=B Prog(b, Γi,f) Proof: **See Appendix B.** Like |=B , the function Prog seems to require B (or at least b**) as input, but of course** when progression is applied in practice we only have f **and one new state at a time of Γ,** and what we really want to do is compute the appropriate B**, namely that represented by** f**."@en ;
    askg-onto:inSentence "Where b ⇔ (Γ(i) ∈ B): Property 1 (Γ,i)|=B f iff (Γ,i **+ 1)**|=B Prog(b, Γi,f) Proof: **See Appendix B.** Like |=B , the function Prog seems to require B (or at least b**) as input, but of course** when progression is applied in practice we only have f **and one new state at a time of Γ,** and what we really want to do is compute the appropriate B**, namely that represented by** f**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-%CE%B3i__b,
        askg-data:Entity-b,
        askg-data:Entity-f,
        askg-data:Entity-state .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2753 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "So, similarly as in Section 3.2, we now turn to the second step, which is to use Prog to** decide on the fly whether a newly generated sequence prefix Γ(i) is in Bf **and so should** be allocated a reward."@en ;
    askg-onto:inSentence "So, similarly as in Section 3.2, we now turn to the second step, which is to use Prog to** decide on the fly whether a newly generated sequence prefix Γ(i) is in Bf **and so should** be allocated a reward."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bf,
        askg-data:Entity-prog .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2754 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This is the purpose of the functions $Prog and Rew, also given in Algorithm 1."@en ;
    askg-onto:inSentence "This is the purpose of the functions $Prog and Rew, also given in Algorithm 1."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm_1,
        askg-data:Entity-prog,
        askg-data:Entity-rew .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-275-Sentence-2755 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Given Γ and f**, the function $Prog in Algorithm 1 defines an infinite sequence** of formulae hf0,f1,...i **in the obvious way:**"@en ;
    askg-onto:inSentence "Given Γ and f**, the function $Prog in Algorithm 1 defines an infinite sequence** of formulae hf0,f1,...i **in the obvious way:**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm_1,
        askg-data:Entity-infinite_sequence_of_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$${\\boldsymbol{\\theta}}=f$$ $\\operatorname{\\mathcal{Q}\\!\\!\\!\\sigma}(\\Gamma_i,\\ f_i)$ f0 = f fi+1 **= $Prog(Γ**i,fi) To decide whether a prefix Γ(i**) of Γ is to be rewarded, Rew first tries progressing the** formula fi through Γi **with the boolean flag set to 'false'. If that gives a consistent result,** we need not reward the prefix and we continue without rewarding Γ(i**), but if the result is** ⊥ then we know that Γ(i) must be rewarded in order for Γ to satisfy f**. In that case, to** obtain fi+1 we must progress fi through Γi **again, this time with the boolean flag set to the** value 'true'. To sum up, the behaviour corresponding to f is {Γ(i)|**Rew(Γ**i,fi)}."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2761,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2762,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2763,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2764 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\boldsymbol{\\theta}}=f$$ $\\operatorname{\\mathcal{Q}\\!\\!\\!\\sigma}(\\Gamma_i,\\ f_i)$ f0 = f fi+1 **= $Prog(Γ**i,fi) To decide whether a prefix Γ(i**) of Γ is to be rewarded, Rew first tries progressing the** formula fi through Γi **with the boolean flag set to 'false'."@en ;
    askg-onto:inSentence "$${\\boldsymbol{\\theta}}=f$$ $\\operatorname{\\mathcal{Q}\\!\\!\\!\\sigma}(\\Gamma_i,\\ f_i)$ f0 = f fi+1 **= $Prog(Γ**i,fi) To decide whether a prefix Γ(i**) of Γ is to be rewarded, Rew first tries progressing the** formula fi through Γi **with the boolean flag set to 'false'."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-f,
        askg-data:Entity-f0,
        askg-data:Entity-false,
        askg-data:Entity-fi1,
        askg-data:Entity-formula_fi,
        askg-data:Entity-prefix_%CE%B3i,
        askg-data:Entity-prog,
        askg-data:Entity-rew .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2762 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "If that gives a consistent result,** we need not reward the prefix and we continue without rewarding Γ(i**), but if the result is** ⊥ then we know that Γ(i) must be rewarded in order for Γ to satisfy f**."@en ;
    askg-onto:inSentence "If that gives a consistent result,** we need not reward the prefix and we continue without rewarding Γ(i**), but if the result is** ⊥ then we know that Γ(i) must be rewarded in order for Γ to satisfy f**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-%CE%B3i,
        askg-data:Entity-f,
        askg-data:Entity-result_ .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2763 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In that case, to** obtain fi+1 we must progress fi through Γi **again, this time with the boolean flag set to the** value 'true'."@en ;
    askg-onto:inSentence "In that case, to** obtain fi+1 we must progress fi through Γi **again, this time with the boolean flag set to the** value 'true'."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-boolean_flag,
        askg-data:Entity-fi .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-276-Sentence-2764 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To sum up, the behaviour corresponding to f is {Γ(i)|**Rew(Γ**i,fi)}."@en ;
    askg-onto:inSentence "To sum up, the behaviour corresponding to f is {Γ(i)|**Rew(Γ**i,fi)}."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-rew%CE%B3ifi .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "To illustrate the behaviour of $FLTL progression, consider **the formula** f = ¬pU(p ∧ $) stating that a reward will be received the first time p is true. Let s **be a state in which** p holds, then Prog(false,s,f) = ⊥ ∨ (⊥ ∧ ¬pU(p ∧ $)) ≡ ⊥**. Therefore, since the formula has** progressed to ⊥, Rew(s,f) is true and a reward is received. $Prog(s,f) = Prog(true,s,f) = ⊤ ∨(⊥ ∧ ¬pU(p∧$)) ≡ ⊤**, so the reward formula fades away and will not affect subsequent** progression steps. If, on the other hand, p is false in s, then Prog(false,s,f) = ⊥ ∨ (⊤ ∧ ¬pU(p∧$)) ≡ ¬pU(p∧$)). Therefore, since the formula has not progressed to ⊥, Rew(s,f) is false and no reward is received. $Prog(s,f) = Prog(false,s,f) = ¬pU(p∧**$), so the reward** formula persists as is for subsequent progression steps."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2771,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2772,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2773,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2774,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2775,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2776,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2777 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To illustrate the behaviour of $FLTL progression, consider **the formula** f = ¬pU(p ∧ $) stating that a reward will be received the first time p is true."@en ;
    askg-onto:inSentence "To illustrate the behaviour of $FLTL progression, consider **the formula** f = ¬pU(p ∧ $) stating that a reward will be received the first time p is true."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_progression,
        askg-data:Entity-the_formula_f__pup__ .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2772 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let s **be a state in which** p holds, then Prog(false,s,f) = ⊥ ∨ (⊥ ∧ ¬pU(p ∧ $)) ≡ ⊥**."@en ;
    askg-onto:inSentence "Let s **be a state in which** p holds, then Prog(false,s,f) = ⊥ ∨ (⊥ ∧ ¬pU(p ∧ $)) ≡ ⊥**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-p_holds,
        askg-data:Entity-progfalsesf .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2773 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Therefore, since the formula has** progressed to ⊥, Rew(s,f) is true and a reward is received."@en ;
    askg-onto:inSentence "Therefore, since the formula has** progressed to ⊥, Rew(s,f) is true and a reward is received."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-formula,
        askg-data:Entity-reward,
        askg-data:Entity-rewsf .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2774 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "$Prog(s,f) = Prog(true,s,f) = ⊤ ∨(⊥ ∧ ¬pU(p∧$)) ≡ ⊤**, so the reward formula fades away and will not affect subsequent** progression steps."@en ;
    askg-onto:inSentence "$Prog(s,f) = Prog(true,s,f) = ⊤ ∨(⊥ ∧ ¬pU(p∧$)) ≡ ⊤**, so the reward formula fades away and will not affect subsequent** progression steps."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-progsf,
        askg-data:Entity-reward_formula,
        askg-data:Entity-subsequent_progression_steps .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2775 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "If, on the other hand, p is false in s, then Prog(false,s,f) = ⊥ ∨ (⊤ ∧ ¬pU(p∧$)) ≡ ¬pU(p∧$))."@en ;
    askg-onto:inSentence "If, on the other hand, p is false in s, then Prog(false,s,f) = ⊥ ∨ (⊤ ∧ ¬pU(p∧$)) ≡ ¬pU(p∧$))."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition,
        askg-data:Entity-p,
        askg-data:Entity-prog,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2776 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Therefore, since the formula has not progressed to ⊥, Rew(s,f) is false and no reward is received."@en ;
    askg-onto:inSentence "Therefore, since the formula has not progressed to ⊥, Rew(s,f) is false and no reward is received."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-false,
        askg-data:Entity-no_reward,
        askg-data:Entity-rewsf .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-277-Sentence-2777 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "$Prog(s,f) = Prog(false,s,f) = ¬pU(p∧**$), so the reward** formula persists as is for subsequent progression steps."@en ;
    askg-onto:inSentence "$Prog(s,f) = Prog(false,s,f) = ¬pU(p∧**$), so the reward** formula persists as is for subsequent progression steps."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-progfalsesf,
        askg-data:Entity-progsf,
        askg-data:Entity-reward_formula,
        askg-data:Entity-subsequent_progression_steps .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-278 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "The following theorem states that under weak assumptions, rewards are correctly allocated by progression: Theorem 1 Let f be reward-normal, and let hf0,f1,...i **be the result of progressing it** through the successive states of a sequence Γ using the function $Prog**. Then, provided no** fiis ⊥, for all i Rew(Γi,fi) iff Γ(i) ∈ Bf ."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-278-Sentence-2781,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-278-Sentence-2782 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-278-Sentence-2781 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The following theorem states that under weak assumptions, rewards are correctly allocated by progression: Theorem 1 Let f be reward-normal, and let hf0,f1,...i **be the result of progressing it** through the successive states of a sequence Γ using the function $Prog**."@en ;
    askg-onto:inSentence "The following theorem states that under weak assumptions, rewards are correctly allocated by progression: Theorem 1 Let f be reward-normal, and let hf0,f1,...i **be the result of progressing it** through the successive states of a sequence Γ using the function $Prog**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-hf0f1i,
        askg-data:Entity-it_through_the_successive_states_of_a_sequence_%CE%B3,
        askg-data:Entity-reward-normal,
        askg-data:Entity-that_progresses_hf0f1i,
        askg-data:Entity-that_under_weak_assumptions_rewards_are_correctly_allocated_by_progression,
        askg-data:Entity-theorem_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-278-Sentence-2782 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Then, provided no** fiis ⊥, for all i Rew(Γi,fi) iff Γ(i) ∈ Bf ."@en ;
    askg-onto:inSentence "Then, provided no** fiis ⊥, for all i Rew(Γi,fi) iff Γ(i) ∈ Bf ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i__bf,
        askg-data:Entity-rew%CE%B3ifi .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Proof: **See Appendix B** The premise of the theorem is that f never progresses to ⊥. Indeed if fi = ⊥ **for some** i, it means that even rewarding Γ(i) does not suffice to make f **true, so something must** have gone wrong: at some earlier stage, the boolean Rew was made false where it should have been made true. The usual explanation is that the original f **was not reward-normal.** For instance p → $, which is reward unstable, progresses to ⊥ **in the next state if p is** true there: regardless of Γ0, f0 = p → $ = ¬p ∨ $, Rew(Γ0,f0**) = false, and** f1 = ¬p, so if p ∈ Γ1 then f2 = ⊥**. However, other (admittedly bizarre) possibilities exist: for** example, although p → $ is reward-unstable, its substitution instance ⊤ → **$, which** also progresses to ⊥ **in a few steps, is logically equivalent to $ and is reward-normal.** If the progression method were to deliver the correct minimal behaviour in all cases (even in all reward-normal cases) it would have to backtrack **on the choice of values for the** boolean flags. In the interest of efficiency, we choose not to allow backtracking. Instead, our algorithm raises an exception whenever a reward formula progresses to ⊥**, and informs** the user of the sequence which caused the problem. The onus is **thus placed on the domain** modeller to select sensible reward formulae so as to avoid possible progression to ⊥**. It** should be noted that in the worst case, detecting reward-normality cannot be easier than the decision problem for $FLTL so it is not to be expected that **there will be a simple** syntactic criterion for reward-normality. In practice, however, commonsense precautions such as avoiding making rewards depend explicitly on future **tense expressions suffice to** keep things normal in all routine cases. For a generous class **of syntactically recognisable** reward-normal formulae, see Appendix A."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2791,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-27910,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2792,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2793,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2794,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2795,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2796,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2797,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2798,
        askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2799 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2791 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof: **See Appendix B** The premise of the theorem is that f never progresses to ⊥."@en ;
    askg-onto:inSentence "Proof: **See Appendix B** The premise of the theorem is that f never progresses to ⊥."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f_never_progresses_to_,
        askg-data:Entity-theorem .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-27910 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "For a generous class **of syntactically recognisable** reward-normal formulae, see Appendix A."@en ;
    askg-onto:inSentence "For a generous class **of syntactically recognisable** reward-normal formulae, see Appendix A."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward-normal_formulae,
        askg-data:Entity-syntactically_recognisable .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2792 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Indeed if fi = ⊥ **for some** i, it means that even rewarding Γ(i) does not suffice to make f **true, so something must** have gone wrong: at some earlier stage, the boolean Rew was made false where it should have been made true."@en ;
    askg-onto:inSentence "Indeed if fi = ⊥ **for some** i, it means that even rewarding Γ(i) does not suffice to make f **true, so something must** have gone wrong: at some earlier stage, the boolean Rew was made false where it should have been made true."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-false,
        askg-data:Entity-rew,
        askg-data:Entity-true .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2793 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The usual explanation is that the original f **was not reward-normal.** For instance p → $, which is reward unstable, progresses to ⊥ **in the next state if p is** true there: regardless of Γ0, f0 = p → $ = ¬p ∨ $, Rew(Γ0,f0**) = false, and** f1 = ¬p, so if p ∈ Γ1 then f2 = ⊥**."@en ;
    askg-onto:inSentence "The usual explanation is that the original f **was not reward-normal.** For instance p → $, which is reward unstable, progresses to ⊥ **in the next state if p is** true there: regardless of Γ0, f0 = p → $ = ¬p ∨ $, Rew(Γ0,f0**) = false, and** f1 = ¬p, so if p ∈ Γ1 then f2 = ⊥**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B31,
        askg-data:Entity-f,
        askg-data:Entity-f0,
        askg-data:Entity-f1,
        askg-data:Entity-f2,
        askg-data:Entity-false,
        askg-data:Entity-not_reward-normal,
        askg-data:Entity-p,
        askg-data:Entity-p__,
        askg-data:Entity-rew%CE%B30f0 .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2794 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, other (admittedly bizarre) possibilities exist: for** example, although p → $ is reward-unstable, its substitution instance ⊤ → **$, which** also progresses to ⊥ **in a few steps, is logically equivalent to $ and is reward-normal.** If the progression method were to deliver the correct minimal behaviour in all cases (even in all reward-normal cases) it would have to backtrack **on the choice of values for the** boolean flags."@en ;
    askg-onto:inSentence "However, other (admittedly bizarre) possibilities exist: for** example, although p → $ is reward-unstable, its substitution instance ⊤ → **$, which** also progresses to ⊥ **in a few steps, is logically equivalent to $ and is reward-normal.** If the progression method were to deliver the correct minimal behaviour in all cases (even in all reward-normal cases) it would have to backtrack **on the choice of values for the** boolean flags."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-__,
        askg-data:Entity-boolean_flags,
        askg-data:Entity-correct_minimal_behaviour,
        askg-data:Entity-logically_equivalent_to_,
        askg-data:Entity-p__,
        askg-data:Entity-progression_method,
        askg-data:Entity-reward-unstable .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2795 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In the interest of efficiency, we choose not to allow backtracking."@en ;
    askg-onto:inSentence "In the interest of efficiency, we choose not to allow backtracking."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backtracking,
        askg-data:Entity-efficiency .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2796 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Instead, our algorithm raises an exception whenever a reward formula progresses to ⊥**, and informs** the user of the sequence which caused the problem."@en ;
    askg-onto:inSentence "Instead, our algorithm raises an exception whenever a reward formula progresses to ⊥**, and informs** the user of the sequence which caused the problem."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-reward_formula_progresses_to_,
        askg-data:Entity-sequence,
        askg-data:Entity-user .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2797 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The onus is **thus placed on the domain** modeller to select sensible reward formulae so as to avoid possible progression to ⊥**."@en ;
    askg-onto:inSentence "The onus is **thus placed on the domain** modeller to select sensible reward formulae so as to avoid possible progression to ⊥**."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain,
        askg-data:Entity-modeller,
        askg-data:Entity-reward_formulae,
        askg-data:Entity-sensible .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2798 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "It** should be noted that in the worst case, detecting reward-normality cannot be easier than the decision problem for $FLTL so it is not to be expected that **there will be a simple** syntactic criterion for reward-normality."@en ;
    askg-onto:inSentence "It** should be noted that in the worst case, detecting reward-normality cannot be easier than the decision problem for $FLTL so it is not to be expected that **there will be a simple** syntactic criterion for reward-normality."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_problem_for_fltl,
        askg-data:Entity-reward-normality .

askg-data:Paper-c253584c3f1ff2a2-Section-27-Paragraph-279-Sentence-2799 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In practice, however, commonsense precautions such as avoiding making rewards depend explicitly on future **tense expressions suffice to** keep things normal in all routine cases."@en ;
    askg-onto:inSentence "In practice, however, commonsense precautions such as avoiding making rewards depend explicitly on future **tense expressions suffice to** keep things normal in all routine cases."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-commonsense_precautions,
        askg-data:Entity-keep_things_normal .

askg-data:Paper-c253584c3f1ff2a2-Section-28 a askg-onto:Section ;
    rdfs:label "Section 28"@en ;
    domo:Text "3.6 Reward Functions"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-282,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-283,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-284,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-285,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-287,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-288 ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "With the language defined so far, we are able to compactly represent behaviours. The extension to a non-Markovian reward function is straightforward. We represent such a function by a set6 φ ⊆ $FLTL × **IR of formulae associated with real valued rewards. We** call φ a reward function specification. Where formula f **is associated with reward** r in φ, we write '(f : r) ∈ φ'. The rewards are assumed to be independent and additive, so **that** the reward function Rφ represented by φ **is given by:**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2811,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2812,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2813,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2814,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2815,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2816 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "With the language defined so far, we are able to compactly represent behaviours."@en ;
    askg-onto:inSentence "With the language defined so far, we are able to compactly represent behaviours."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-language .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The extension to a non-Markovian reward function is straightforward."@en ;
    askg-onto:inSentence "The extension to a non-Markovian reward function is straightforward."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-markovian_reward_function,
        askg-data:Entity-reward_function .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We represent such a function by a set6 φ ⊆ $FLTL × **IR of formulae associated with real valued rewards."@en ;
    askg-onto:inSentence "We represent such a function by a set6 φ ⊆ $FLTL × **IR of formulae associated with real valued rewards."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl__ir,
        askg-data:Entity-set6_%CF%86 .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We** call φ a reward function specification."@en ;
    askg-onto:inSentence "We** call φ a reward function specification."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-reward_function_specification .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Where formula f **is associated with reward** r in φ, we write '(f : r) ∈ φ'."@en ;
    askg-onto:inSentence "Where formula f **is associated with reward** r in φ, we write '(f : r) ∈ φ'."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-formula_f,
        askg-data:Entity-reward_r .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-281-Sentence-2816 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The rewards are assumed to be independent and additive, so **that** the reward function Rφ represented by φ **is given by:**"@en ;
    askg-onto:inSentence "The rewards are assumed to be independent and additive, so **that** the reward function Rφ represented by φ **is given by:**"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86 .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-282 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "**Definition 4**: $R_{\\phi}(\\Gamma(i))=\\sum_{(f:r)\\in\\phi}\\{r\\mid\\Gamma(i)\\in B_{f}\\}$. E.g, if φ is {¬pU(p ∧ $) : 5.2, (q → $) : 7.3}**, we get a reward of 5.2 the first time that** p holds, a reward of 7.3 from the first time that q holds onwards, a reward of 12.**5 when both** conditions are met, and 0 otherwise."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-282-Sentence-2821,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-282-Sentence-2822 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-282-Sentence-2821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "**Definition 4**: $R_{\\phi}(\\Gamma(i))=\\sum_{(f:r)\\in\\phi}\\{r\\mid\\Gamma(i)\\in B_{f}\\}$."@en ;
    askg-onto:inSentence "**Definition 4**: $R_{\\phi}(\\Gamma(i))=\\sum_{(f:r)\\in\\phi}\\{r\\mid\\Gamma(i)\\in B_{f}\\}$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-r_%0Aphi%0Agammai%0A,
        askg-data:Entity-sum_frinphirmidgammaiin_b_f .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-282-Sentence-2822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "E.g, if φ is {¬pU(p ∧ $) : 5.2, (q → $) : 7.3}**, we get a reward of 5.2 the first time that** p holds, a reward of 7.3 from the first time that q holds onwards, a reward of 12.**5 when both** conditions are met, and 0 otherwise."@en ;
    askg-onto:inSentence "E.g, if φ is {¬pU(p ∧ $) : 5.2, (q → $) : 7.3}**, we get a reward of 5.2 the first time that** p holds, a reward of 7.3 from the first time that q holds onwards, a reward of 12.**5 when both** conditions are met, and 0 otherwise."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-both_conditions,
        askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-reward_of_125,
        askg-data:Entity-reward_of_52,
        askg-data:Entity-reward_of_73 .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-283 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Again, we can progress a reward function specification φ **to compute the reward at** all stages i of Γ. As before, progression defines a sequence hφ0,φ1,...i **of reward function** specifications, with φi+1 = RProg(Γi,φi**), where RProg is the function that applies Prog to** all formulae in a reward function specification:"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-283-Sentence-2831,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-283-Sentence-2832 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-283-Sentence-2831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Again, we can progress a reward function specification φ **to compute the reward at** all stages i of Γ."@en ;
    askg-onto:inSentence "Again, we can progress a reward function specification φ **to compute the reward at** all stages i of Γ."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_stages_i_of_%CE%B3,
        askg-data:Entity-reward_function_specification_%CF%86 .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-283-Sentence-2832 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As before, progression defines a sequence hφ0,φ1,...i **of reward function** specifications, with φi+1 = RProg(Γi,φi**), where RProg is the function that applies Prog to** all formulae in a reward function specification:"@en ;
    askg-onto:inSentence "As before, progression defines a sequence hφ0,φ1,...i **of reward function** specifications, with φi+1 = RProg(Γi,φi**), where RProg is the function that applies Prog to** all formulae in a reward function specification:"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-prog,
        askg-data:Entity-reward_function,
        askg-data:Entity-reward_function_specification,
        askg-data:Entity-sequence_h%CF%860%CF%861i .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-284 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$\\operatorname{RProg}(s,\\phi)=\\{(\\operatorname{Prog}(s,f):r)\\mid(f:r)\\in\\phi\\}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-284-Sentence-2841 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-284-Sentence-2841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\operatorname{RProg}(s,\\phi)=\\{(\\operatorname{Prog}(s,f):r)\\mid(f:r)\\in\\phi\\}$$"@en ;
    askg-onto:inSentence "$$\\operatorname{RProg}(s,\\phi)=\\{(\\operatorname{Prog}(s,f):r)\\mid(f:r)\\in\\phi\\}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-phi,
        askg-data:Entity-prog,
        askg-data:Entity-r,
        askg-data:Entity-rprog,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-285 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Then, the total reward received at stage i **is simply the sum of the real-valued rewards** granted by the progression function to the behaviours represented by the formulae in φi:"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-285-Sentence-2851 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-285-Sentence-2851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Then, the total reward received at stage i **is simply the sum of the real-valued rewards** granted by the progression function to the behaviours represented by the formulae in φi:"@en ;
    askg-onto:inSentence "Then, the total reward received at stage i **is simply the sum of the real-valued rewards** granted by the progression function to the behaviours represented by the formulae in φi:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-formulae_in_%CF%86i,
        askg-data:Entity-real-valued_rewards,
        askg-data:Entity-stage_i,
        askg-data:Entity-total_reward .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$\\sum_{(f:r)\\in\\phi_{i}}\\{r\\mid\\mathrm{{New}}(\\Gamma_{i},f)\\}$$ $\\boxed{\\text{L}}$. By proceeding that way, we get the expected analog of Theorem **1, which states progression** correctly computes non-Markovian reward functions: Theorem 2 Let φ be a reward-normal7reward function specification, and let hφ0,φ1 ...i be the result of progressing it through the successive states of a sequence Γ **using the function** RProg. Then, provided (⊥:r)6∈φifor any i**, then** X (f:r)∈φi"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286-Sentence-2861,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286-Sentence-2862,
        askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286-Sentence-2863 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286-Sentence-2861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\sum_{(f:r)\\in\\phi_{i}}\\{r\\mid\\mathrm{{New}}(\\Gamma_{i},f)\\}$$ $\\boxed{\\text{L}}$."@en ;
    askg-onto:inSentence "$$\\sum_{(f:r)\\in\\phi_{i}}\\{r\\mid\\mathrm{{New}}(\\Gamma_{i},f)\\}$$ $\\boxed{\\text{L}}$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extl,
        askg-data:Entity-new,
        askg-data:Entity-research_methods,
        askg-data:Entity-the_output_of_a_summation .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286-Sentence-2862 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "By proceeding that way, we get the expected analog of Theorem **1, which states progression** correctly computes non-Markovian reward functions: Theorem 2 Let φ be a reward-normal7reward function specification, and let hφ0,φ1 ...i be the result of progressing it through the successive states of a sequence Γ **using the function** RProg."@en ;
    askg-onto:inSentence "By proceeding that way, we get the expected analog of Theorem **1, which states progression** correctly computes non-Markovian reward functions: Theorem 2 Let φ be a reward-normal7reward function specification, and let hφ0,φ1 ...i be the result of progressing it through the successive states of a sequence Γ **using the function** RProg."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86_be_a_reward-normal_reward_function_specification,
        askg-data:Entity-h%CF%860%CF%861_i,
        askg-data:Entity-progressing_it_through_the_successive_states_of_a_sequence_%CE%B3,
        askg-data:Entity-progressing_the_reward-normal_reward_function_specification,
        askg-data:Entity-progression_correctly_computes_non-markovian_reward_functions,
        askg-data:Entity-theorem_1,
        askg-data:Entity-theorem_2 .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-286-Sentence-2863 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Then, provided (⊥:r)6∈φifor any i**, then** X (f:r)∈φi"@en ;
    askg-onto:inSentence "Then, provided (⊥:r)6∈φifor any i**, then** X (f:r)∈φi"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86i,
        askg-data:Entity-x .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-287 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$\\begin{array}{l}{{\\{r\\mid\\mathrm{{Rew}(\\Gamma_{i},f)\\}=R_{\\phi}(\\Gamma(i)).}}}\\\\ {{\\delta_{i}}}\\end{array}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-287-Sentence-2871 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-287-Sentence-2871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{{\\{r\\mid\\mathrm{{Rew}(\\Gamma_{i},f)\\}=R_{\\phi}(\\Gamma(i)).}}}\\\\ {{\\delta_{i}}}\\end{array}$$"@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{{\\{r\\mid\\mathrm{{Rew}(\\Gamma_{i},f)\\}=R_{\\phi}(\\Gamma(i)).}}}\\\\ {{\\delta_{i}}}\\end{array}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-parameter,
        askg-data:Entity-r_%CF%86%CE%B3i,
        askg-data:Entity-rew%CE%B3_if .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-288 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Proof: **Immediate from Theorem 1.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-288-Sentence-2881 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-28-Paragraph-288-Sentence-2881 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof: **Immediate from Theorem 1.**"@en ;
    askg-onto:inSentence "Proof: **Immediate from Theorem 1.**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proof,
        askg-data:Entity-theorem_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-29 a askg-onto:Section ;
    rdfs:label "Section 29"@en ;
    domo:Text "3.7 Translation Into Mdp"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2910,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2911,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2912,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2913,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-292,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-294,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-295,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299 ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We now exploit the compact representation of a non-Markovian reward function as a reward function specification to translate an NMRDP into an equivalent MDP amenable to statebased anytime solution methods. Recall from Section 2 that each e-state in the MDP is labelled by a state of the NMRDP and by history information sufficient to determine the immediate reward. In the case of a compact representation as **a reward function specification** φ0, this additional information can be summarised by the progression of φ0 **through the** sequence of states passed through. So an e-state will be of the form hs,φi**, where** s ∈ S is"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2911,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2912,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2913,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2914 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We now exploit the compact representation of a non-Markovian reward function as a reward function specification to translate an NMRDP into an equivalent MDP amenable to statebased anytime solution methods."@en ;
    askg-onto:inSentence "We now exploit the compact representation of a non-Markovian reward function as a reward function specification to translate an NMRDP into an equivalent MDP amenable to statebased anytime solution methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-non-markovian_reward_function,
        askg-data:Entity-reward_function_specification,
        askg-data:Entity-state-based_anytime_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Recall from Section 2 that each e-state in the MDP is labelled by a state of the NMRDP and by history information sufficient to determine the immediate reward."@en ;
    askg-onto:inSentence "Recall from Section 2 that each e-state in the MDP is labelled by a state of the NMRDP and by history information sufficient to determine the immediate reward."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-history_information,
        askg-data:Entity-immediate_reward,
        askg-data:Entity-state_of_the_nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In the case of a compact representation as **a reward function specification** φ0, this additional information can be summarised by the progression of φ0 **through the** sequence of states passed through."@en ;
    askg-onto:inSentence "In the case of a compact representation as **a reward function specification** φ0, this additional information can be summarised by the progression of φ0 **through the** sequence of states passed through."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%860,
        askg-data:Entity-reward_function_specification,
        askg-data:Entity-sequence_of_states .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-291-Sentence-2914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "So an e-state will be of the form hs,φi**, where** s ∈ S is"@en ;
    askg-onto:inSentence "So an e-state will be of the form hs,φi**, where** s ∈ S is"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-hs%CF%86i .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2910 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "![22_image_0.png](22_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2910-Sentence-29101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2910-Sentence-29101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![22_image_0.png](22_image_0.png)"@en ;
    askg-onto:inSentence "![22_image_0.png](22_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-business_analytics,
        askg-data:Entity-computer_science,
        askg-data:Entity-data_analysis,
        askg-data:Entity-machine_learning,
        askg-data:Entity-mathematics,
        askg-data:Entity-predictive_modeling,
        askg-data:Entity-research_field,
        askg-data:Entity-statistical_methods,
        askg-data:Entity-statistics .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2911 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "The following formulae label the e-states: f1 : ((p ∧ q) → $) f2 : q → $ f3 : q → $"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2911-Sentence-29111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2911-Sentence-29111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The following formulae label the e-states: f1 : ((p ∧ q) → $) f2 : q → $ f3 : q → $"@en ;
    askg-onto:inSentence "The following formulae label the e-states: f1 : ((p ∧ q) → $) f2 : q → $ f3 : q → $"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2912 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "Figure 7: Equivalent MDP Produced by **fltl**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2912-Sentence-29121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2912-Sentence-29121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 7: Equivalent MDP Produced by **fltl**"@en ;
    askg-onto:inSentence "Figure 7: Equivalent MDP Produced by **fltl**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equivalent_mdp,
        askg-data:Entity-fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2913 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "shows the relevant formulae labelling the e-states, obtained by progression of this reward formula. Note that without progressing one step ahead, there would be 3 e-states with state {p} on the left-hand side, labelled with {f1}, {f1,f2}, and {f1,f2,f3}**, respectively.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2913-Sentence-29131,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2913-Sentence-29132 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2913-Sentence-29131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "shows the relevant formulae labelling the e-states, obtained by progression of this reward formula."@en ;
    askg-onto:inSentence "shows the relevant formulae labelling the e-states, obtained by progression of this reward formula."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-2913-Sentence-29132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that without progressing one step ahead, there would be 3 e-states with state {p} on the left-hand side, labelled with {f1}, {f1,f2}, and {f1,f2,f3}**, respectively.**"@en ;
    askg-onto:inSentence "Note that without progressing one step ahead, there would be 3 e-states with state {p} on the left-hand side, labelled with {f1}, {f1,f2}, and {f1,f2,f3}**, respectively.**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-f1,
        askg-data:Entity-f1f2,
        askg-data:Entity-f1f2f3 .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-292 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "6. Strictly speaking, a multiset, but for convenience we represent it as a set, with the rewards for multiple occurrences of the same formula in the multiset summed."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-292-Sentence-2921,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-292-Sentence-2922 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-292-Sentence-2921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "6."@en ;
    askg-onto:inSentence "6."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-field,
        askg-data:Entity-knowledge_graph,
        askg-data:Entity-model,
        askg-data:Entity-research,
        askg-data:Entity-triple,
        askg-data:Entity-triples .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-292-Sentence-2922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Strictly speaking, a multiset, but for convenience we represent it as a set, with the rewards for multiple occurrences of the same formula in the multiset summed."@en ;
    askg-onto:inSentence "Strictly speaking, a multiset, but for convenience we represent it as a set, with the rewards for multiple occurrences of the same formula in the multiset summed."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-multiset,
        askg-data:Entity-set .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "7. We extend the definition of reward-normality to reward specification functions in the obvious way, by requiring that all reward formulae involved be reward normal. a state, and φ ⊆ $FLTL × **IR is a reward function specification (obtained by progression).** Two e-states hs,φi and ht,ψi are equal if s = t**, the immediate rewards are the same, and** the results of progressing φ and ψ through s **are semantically equivalent.**8 Definition 5 Let D = hS,s0,A,Pr,Ri be an NMRDP, and φ0 be a reward function specification representing R **(i.e.,** Rφ0 = R, see Definition 4). We translate D **into the MDP** D′ = hS ′,s′0,A′,Pr′,R′i **defined as follows:** 1. S ′ ⊆ S × 2 $**FLTL** ×IR 2. s ′0 = hs0,φ0i"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2931,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2932,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2933,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2934,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2935,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2936 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "7."@en ;
    askg-onto:inSentence "7."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-research,
        askg-data:Entity-research_field,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We extend the definition of reward-normality to reward specification functions in the obvious way, by requiring that all reward formulae involved be reward normal."@en ;
    askg-onto:inSentence "We extend the definition of reward-normality to reward specification functions in the obvious way, by requiring that all reward formulae involved be reward normal."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward-normality,
        askg-data:Entity-reward_formulae,
        askg-data:Entity-reward_normal,
        askg-data:Entity-reward_specification_functions .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2933 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "a state, and φ ⊆ $FLTL × **IR is a reward function specification (obtained by progression).** Two e-states hs,φi and ht,ψi are equal if s = t**, the immediate rewards are the same, and** the results of progressing φ and ψ through s **are semantically equivalent.**8 Definition 5 Let D = hS,s0,A,Pr,Ri be an NMRDP, and φ0 be a reward function specification representing R **(i.e.,** Rφ0 = R, see Definition 4)."@en ;
    askg-onto:inSentence "a state, and φ ⊆ $FLTL × **IR is a reward function specification (obtained by progression).** Two e-states hs,φi and ht,ψi are equal if s = t**, the immediate rewards are the same, and** the results of progressing φ and ψ through s **are semantically equivalent.**8 Definition 5 Let D = hS,s0,A,Pr,Ri be an NMRDP, and φ0 be a reward function specification representing R **(i.e.,** Rφ0 = R, see Definition 4)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%860,
        askg-data:Entity-%CF%86__fltl__ir,
        askg-data:Entity-d,
        askg-data:Entity-nmrdp,
        askg-data:Entity-r,
        askg-data:Entity-r%CF%860,
        askg-data:Entity-reward_function_specification .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2934 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We translate D **into the MDP** D′ = hS ′,s′0,A′,Pr′,R′i **defined as follows:** 1."@en ;
    askg-onto:inSentence "We translate D **into the MDP** D′ = hS ′,s′0,A′,Pr′,R′i **defined as follows:** 1."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-mdp_d__hs_s0aprri .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2935 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "S ′ ⊆ S × 2 $**FLTL** ×IR 2."@en ;
    askg-onto:inSentence "S ′ ⊆ S × 2 $**FLTL** ×IR 2."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s_,
        askg-data:Entity-s__2_fltl_ir_2 .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-293-Sentence-2936 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "s ′0 = hs0,φ0i"@en ;
    askg-onto:inSentence "s ′0 = hs0,φ0i"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hs0%CF%860i,
        askg-data:Entity-s_0 .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-294 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$${A}(s)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-294-Sentence-2941 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-294-Sentence-2941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${A}(s)$$"@en ;
    askg-onto:inSentence "$${A}(s)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-as,
        askg-data:Entity-model .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-295 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "3. A′(hs,φi) = A(s) Pr(**s,a,s**′) if φ"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-295-Sentence-2951,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-295-Sentence-2952 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-295-Sentence-2951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3."@en ;
    askg-onto:inSentence "3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-triple,
        askg-data:Entity-triple_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-295-Sentence-2952 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A′(hs,φi) = A(s) Pr(**s,a,s**′) if φ"@en ;
    askg-onto:inSentence "A′(hs,φi) = A(s) Pr(**s,a,s**′) if φ"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ahs%CF%86i,
        askg-data:Entity-as_prsas .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$\\begin{array}{l}{{i f\\,\\phi^{\\prime}=\\mathrm{RProg}(s,\\phi)}}\\\\ {{o t h e r w i s e}}\\end{array}$$ 0 **otherwise** _4. If $a\\in A^{\\prime}(\\langle s,\\phi\\rangle)$, then $\\Pr^{\\prime}(\\langle s,\\phi\\rangle,a,\\langle s^{\\prime},\\phi^{\\prime}\\rangle)=\\left\\{\\begin{array}{l}\\Pr(s,a)\\\\ 0\\end{array}\\right.$ If $a\\notin A^{\\prime}(\\langle s,\\phi\\rangle)$, then $\\Pr^{\\prime}(\\langle s,\\phi\\rangle,a,\\bullet)$ is undefined_ _5. $R^{\\prime}(\\langle s,\\phi\\rangle)=\\sum_{(f:r)\\in\\phi}\\{r\\mid\\mbox{\\rm New}(s,f)\\}$_ 6. For all s ′ ∈ S ′, s ′is reachable under A′**from** s ′0."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2961,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2962,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2963,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2964 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2961 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\begin{array}{l}{{i f\\,\\phi^{\\prime}=\\mathrm{RProg}(s,\\phi)}}\\\\ {{o t h e r w i s e}}\\end{array}$$ 0 **otherwise** _4."@en ;
    askg-onto:inSentence "$$\\begin{array}{l}{{i f\\,\\phi^{\\prime}=\\mathrm{RProg}(s,\\phi)}}\\\\ {{o t h e r w i s e}}\\end{array}$$ 0 **otherwise** _4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition,
        askg-data:Entity-otherwise .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2962 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "If $a\\in A^{\\prime}(\\langle s,\\phi\\rangle)$, then $\\Pr^{\\prime}(\\langle s,\\phi\\rangle,a,\\langle s^{\\prime},\\phi^{\\prime}\\rangle)=\\left\\{\\begin{array}{l}\\Pr(s,a)\\\\ 0\\end{array}\\right.$ If $a\\notin A^{\\prime}(\\langle s,\\phi\\rangle)$, then $\\Pr^{\\prime}(\\langle s,\\phi\\rangle,a,\\bullet)$ is undefined_ _5."@en ;
    askg-onto:inSentence "If $a\\in A^{\\prime}(\\langle s,\\phi\\rangle)$, then $\\Pr^{\\prime}(\\langle s,\\phi\\rangle,a,\\langle s^{\\prime},\\phi^{\\prime}\\rangle)=\\left\\{\\begin{array}{l}\\Pr(s,a)\\\\ 0\\end{array}\\right.$ If $a\\notin A^{\\prime}(\\langle s,\\phi\\rangle)$, then $\\Pr^{\\prime}(\\langle s,\\phi\\rangle,a,\\bullet)$ is undefined_ _5."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09extprsa,
        askg-data:Entity-%09extprulletoldsymbolsoldsymbol%09ext%CF%86aoldsymbolsulletoldsymbol%09ext%CF%86ullet,
        askg-data:Entity-%09extprulletoldsymbolsoldsymbol%09ext%CF%86aullet,
        askg-data:Entity-a,
        askg-data:Entity-aulletoldsymbolsoldsymbol%09ext%CF%86,
        askg-data:Entity-undefined .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2963 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "$R^{\\prime}(\\langle s,\\phi\\rangle)=\\sum_{(f:r)\\in\\phi}\\{r\\mid\\mbox{\\rm New}(s,f)\\}$_ 6."@en ;
    askg-onto:inSentence "$R^{\\prime}(\\langle s,\\phi\\rangle)=\\sum_{(f:r)\\in\\phi}\\{r\\mid\\mbox{\\rm New}(s,f)\\}$_ 6."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Aeginpmatrixs%09extphi%09ext_%09extbf_%09ext_sum_of__fr_%09ext_in__%09extphi%09ext_such_that__%09extnewsf,
        askg-data:Entity-r%09extprime .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-296-Sentence-2964 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For all s ′ ∈ S ′, s ′is reachable under A′**from** s ′0."@en ;
    askg-onto:inSentence "For all s ′ ∈ S ′, s ′is reachable under A′**from** s ′0."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-afrom_s_0,
        askg-data:Entity-s_ .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Item 1 says that the e-states are labelled by a state and a reward function specification. Item 2 says that the initial e-state is labelled with the initial state and with the original reward function specification. Item 3 says that an action is applicable in an e-state if it is applicable in the state labelling it. Item 4 explains how successor e-states and their probabilities are computed. Given an action a applicable in an e-state hs,φi**, each successor e-state will** be labelled by a successor state s ′ of s via a **in the NMRDP and by the progression of** φ through s. The probability of that e-state is Pr(s,a,s′**) as in the NMRDP. Note that the** cost of computing Pr′**is linear in that of computing Pr and in the sum of the lengths of the** formulae in φ**. Item 5 has been motivated before (see Section 3.6). Finally, since items 1–5** leave open the choice of many MDPs differing only in the unreachable states they contain, item 6 excludes all such irrelevant extensions. It is easy to **show that this translation leads** to an equivalent MDP, as defined in Definition 1. Obviously, the function τ **required for** Definition1 is given by τ (hs,φi) = s**, and then the proof is a matter of checking conditions.** In our practical implementation, the labelling is one step ahead of that in the definition: we label the initial e-state with RProg(s0,φ0) and compute the current reward and the current reward specification label by progression of predecessor reward specifications through the current state rather than through the predecessor states. As will be apparent below, this has the potential to reduce the number of states in the generated MDP."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2971,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-29710,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-29711,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-29712,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2972,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2973,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2974,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2975,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2976,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2977,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2978,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2979 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2971 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Item 1 says that the e-states are labelled by a state and a reward function specification."@en ;
    askg-onto:inSentence "Item 1 says that the e-states are labelled by a state and a reward function specification."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_state_and_a_reward_function_specification,
        askg-data:Entity-e-states .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-29710 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "It is easy to **show that this translation leads** to an equivalent MDP, as defined in Definition 1."@en ;
    askg-onto:inSentence "It is easy to **show that this translation leads** to an equivalent MDP, as defined in Definition 1."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-29711 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Obviously, the function τ **required for** Definition1 is given by τ (hs,φi) = s**, and then the proof is a matter of checking conditions.** In our practical implementation, the labelling is one step ahead of that in the definition: we label the initial e-state with RProg(s0,φ0) and compute the current reward and the current reward specification label by progression of predecessor reward specifications through the current state rather than through the predecessor states."@en ;
    askg-onto:inSentence "Obviously, the function τ **required for** Definition1 is given by τ (hs,φi) = s**, and then the proof is a matter of checking conditions.** In our practical implementation, the labelling is one step ahead of that in the definition: we label the initial e-state with RProg(s0,φ0) and compute the current reward and the current reward specification label by progression of predecessor reward specifications through the current state rather than through the predecessor states."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_reward,
        askg-data:Entity-current_reward_specification_label,
        askg-data:Entity-definition1,
        askg-data:Entity-e-state,
        askg-data:Entity-function_%CF%84,
        askg-data:Entity-progression_of_predecessor_reward_specifications .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-29712 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "As will be apparent below, this has the potential to reduce the number of states in the generated MDP."@en ;
    askg-onto:inSentence "As will be apparent below, this has the potential to reduce the number of states in the generated MDP."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generated_mdp,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2972 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Item 2 says that the initial e-state is labelled with the initial state and with the original reward function specification."@en ;
    askg-onto:inSentence "Item 2 says that the initial e-state is labelled with the initial state and with the original reward function specification."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_e-state,
        askg-data:Entity-initial_state,
        askg-data:Entity-original_reward_function_specification .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2973 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Item 3 says that an action is applicable in an e-state if it is applicable in the state labelling it."@en ;
    askg-onto:inSentence "Item 3 says that an action is applicable in an e-state if it is applicable in the state labelling it."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action,
        askg-data:Entity-e-state,
        askg-data:Entity-state .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2974 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Item 4 explains how successor e-states and their probabilities are computed."@en ;
    askg-onto:inSentence "Item 4 explains how successor e-states and their probabilities are computed."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-probabilities,
        askg-data:Entity-successor_e-states .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2975 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Given an action a applicable in an e-state hs,φi**, each successor e-state will** be labelled by a successor state s ′ of s via a **in the NMRDP and by the progression of** φ through s."@en ;
    askg-onto:inSentence "Given an action a applicable in an e-state hs,φi**, each successor e-state will** be labelled by a successor state s ′ of s via a **in the NMRDP and by the progression of** φ through s."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-action,
        askg-data:Entity-e-state,
        askg-data:Entity-nmrdp,
        askg-data:Entity-s,
        askg-data:Entity-successor_state .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2976 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The probability of that e-state is Pr(s,a,s′**) as in the NMRDP."@en ;
    askg-onto:inSentence "The probability of that e-state is Pr(s,a,s′**) as in the NMRDP."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-nmrdp,
        askg-data:Entity-prsas .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2977 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Note that the** cost of computing Pr′**is linear in that of computing Pr and in the sum of the lengths of the** formulae in φ**."@en ;
    askg-onto:inSentence "Note that the** cost of computing Pr′**is linear in that of computing Pr and in the sum of the lengths of the** formulae in φ**."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-formulae,
        askg-data:Entity-pr .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2978 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Item 5 has been motivated before (see Section 3.6)."@en ;
    askg-onto:inSentence "Item 5 has been motivated before (see Section 3.6)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-item_5,
        askg-data:Entity-section_36 .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-297-Sentence-2979 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Finally, since items 1–5** leave open the choice of many MDPs differing only in the unreachable states they contain, item 6 excludes all such irrelevant extensions."@en ;
    askg-onto:inSentence "Finally, since items 1–5** leave open the choice of many MDPs differing only in the unreachable states they contain, item 6 excludes all such irrelevant extensions."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-irrelevant_extensions,
        askg-data:Entity-item_6 .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Figure 7 shows the equivalent MDP produced for the $FLTL version of our NMRDP example in Figure 3. Recall that for this example, the PLTL reward formula was q ∧ ⊖ ⊖ p. In $FLTL, the allocation of rewards is described by ((p ∧ q) → **$). The figure also**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2981,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2982,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2983,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2984 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2981 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 7 shows the equivalent MDP produced for the $FLTL version of our NMRDP example in Figure 3."@en ;
    askg-onto:inSentence "Figure 7 shows the equivalent MDP produced for the $FLTL version of our NMRDP example in Figure 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_version_of_nmrdp_example,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2982 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Recall that for this example, the PLTL reward formula was q ∧ ⊖ ⊖ p."@en ;
    askg-onto:inSentence "Recall that for this example, the PLTL reward formula was q ∧ ⊖ ⊖ p."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_reward_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2983 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In $FLTL, the allocation of rewards is described by ((p ∧ q) → **$)."@en ;
    askg-onto:inSentence "In $FLTL, the allocation of rewards is described by ((p ∧ q) → **$)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-p__q__ .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-298-Sentence-2984 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The figure also**"@en ;
    askg-onto:inSentence "The figure also**"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "8. Care is needed over the notion of 'semantic equivalence'. **Because rewards are additive, determining** equivalence may involve arithmetic as well as theorem proving. For example, the reward function specification {(p → $ : 3), (q → $ : 2)} is equivalent to {((p∧q) → $ : 5), ((p∧ ¬q) → $ : 3), ((¬p∧q) → **$ : 2)**} although there is no one-one correspondence between the formulae in the two sets."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2991,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2992,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2993,
        askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2994 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2991 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "8."@en ;
    askg-onto:inSentence "8."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-research_field,
        askg-data:Entity-study,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2992 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Care is needed over the notion of 'semantic equivalence'."@en ;
    askg-onto:inSentence "Care is needed over the notion of 'semantic equivalence'."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-care,
        askg-data:Entity-semantic_equivalence .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2993 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "**Because rewards are additive, determining** equivalence may involve arithmetic as well as theorem proving."@en ;
    askg-onto:inSentence "**Because rewards are additive, determining** equivalence may involve arithmetic as well as theorem proving."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additive,
        askg-data:Entity-arithmetic,
        askg-data:Entity-equivalence,
        askg-data:Entity-rewards,
        askg-data:Entity-theorem_proving .

askg-data:Paper-c253584c3f1ff2a2-Section-29-Paragraph-299-Sentence-2994 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For example, the reward function specification {(p → $ : 3), (q → $ : 2)} is equivalent to {((p∧q) → $ : 5), ((p∧ ¬q) → $ : 3), ((¬p∧q) → **$ : 2)**} although there is no one-one correspondence between the formulae in the two sets."@en ;
    askg-onto:inSentence "For example, the reward function specification {(p → $ : 3), (q → $ : 2)} is equivalent to {((p∧q) → $ : 5), ((p∧ ¬q) → $ : 3), ((¬p∧q) → **$ : 2)**} although there is no one-one correspondence between the formulae in the two sets."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae_in_the_two_sets,
        askg-data:Entity-reward_function_specification .

askg-data:Paper-c253584c3f1ff2a2-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "1. Introduction"@en ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30 a askg-onto:Section ;
    rdfs:label "Section 30"@en ;
    domo:Text "3.8 Blind Minimality"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3010,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3011,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3012,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3013,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-304,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-305,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-306,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-308,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-309 ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The size of the MDP obtained, i.e. the number of e-states it contains is a key issue for us, as it has to be amenable to state-based solution methods. **Ideally, we would like the** MDP to be of minimal size. However, we do not know of a method building the **minimal** equivalent MDP incrementally, adding parts as required by the solution method. And since in the worst case even the minimal equivalent MDP can be larger than the NMRDP by a factor exponential in the length of the reward formulae (Bacchus et al., 1996), constructing it entirely would nullify the interest of anytime solution methods."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3011,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3012,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3013,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3014,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3015 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The size of the MDP obtained, i.e."@en ;
    askg-onto:inSentence "The size of the MDP obtained, i.e."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-size .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "the number of e-states it contains is a key issue for us, as it has to be amenable to state-based solution methods."@en ;
    askg-onto:inSentence "the number of e-states it contains is a key issue for us, as it has to be amenable to state-based solution methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-state-based_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "**Ideally, we would like the** MDP to be of minimal size."@en ;
    askg-onto:inSentence "**Ideally, we would like the** MDP to be of minimal size."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-minimal_size .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, we do not know of a method building the **minimal** equivalent MDP incrementally, adding parts as required by the solution method."@en ;
    askg-onto:inSentence "However, we do not know of a method building the **minimal** equivalent MDP incrementally, adding parts as required by the solution method."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-minimal_equivalent_mdp,
        askg-data:Entity-solution_method .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-301-Sentence-3015 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "And since in the worst case even the minimal equivalent MDP can be larger than the NMRDP by a factor exponential in the length of the reward formulae (Bacchus et al., 1996), constructing it entirely would nullify the interest of anytime solution methods."@en ;
    askg-onto:inSentence "And since in the worst case even the minimal equivalent MDP can be larger than the NMRDP by a factor exponential in the length of the reward formulae (Bacchus et al., 1996), constructing it entirely would nullify the interest of anytime solution methods."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-bacchus_et_al_1996,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3010 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Proof: **See Appendix B.** Blind minimality is similar, except that, since there is no looking ahead, no distinction can be drawn between feasible trajectories and others in the future of s: Definition 7 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3010-Sentence-30101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3010-Sentence-30101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof: **See Appendix B.** Blind minimality is similar, except that, since there is no looking ahead, no distinction can be drawn between feasible trajectories and others in the future of s: Definition 7 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."@en ;
    askg-onto:inSentence "Proof: **See Appendix B.** Blind minimality is similar, except that, since there is no looking ahead, no distinction can be drawn between feasible trajectories and others in the future of s: Definition 7 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-mdp_d,
        askg-data:Entity-s_ .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3011 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "D′is blind minimal **iff every e-state in** S ′**is reachable and** S ′contains no two distinct estates s ′1and s ′2 **with** τ (s ′1) = τ (s ′2) and ρ(s ′1) = ρ(s ′2)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3011-Sentence-30111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3011-Sentence-30111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "D′is blind minimal **iff every e-state in** S ′**is reachable and** S ′contains no two distinct estates s ′1and s ′2 **with** τ (s ′1) = τ (s ′2) and ρ(s ′1) = ρ(s ′2)."@en ;
    askg-onto:inSentence "D′is blind minimal **iff every e-state in** S ′**is reachable and** S ′contains no two distinct estates s ′1and s ′2 **with** τ (s ′1) = τ (s ′2) and ρ(s ′1) = ρ(s ′2)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%81s_1,
        askg-data:Entity-%CF%81s_2,
        askg-data:Entity-%CF%84_s_1,
        askg-data:Entity-%CF%84_s_2,
        askg-data:Entity-dis_blind_minimal,
        askg-data:Entity-every_e-state_in_s__is_reachable,
        askg-data:Entity-no_two_distinct_estates_s_1_and_s_2,
        askg-data:Entity-s_ .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3012 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "$\\square$ Theorem 4 Let D′be the translation of D as in Definition 5. D′**is a blind minimal** equivalent MDP for D."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3012-Sentence-30121,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3012-Sentence-30122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3012-Sentence-30121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\square$ Theorem 4 Let D′be the translation of D as in Definition 5."@en ;
    askg-onto:inSentence "$\\square$ Theorem 4 Let D′be the translation of D as in Definition 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3012-Sentence-30122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "D′**is a blind minimal** equivalent MDP for D."@en ;
    askg-onto:inSentence "D′**is a blind minimal** equivalent MDP for D."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimal_equivalent_mdp,
        askg-data:Entity-d,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3013 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "Proof: **See Appendix B.** The size difference between the blind-minimal and minimal MDPs will depend on the precise interaction between rewards and dynamics for the problem at hand, making theoretical analyses difficult and experimental results rather anecdotal. However, our experiments in Section 5 and 6 will show that from a computation time point of view, it is often preferable to work with the blind-minimal MDP than to invest in the overhead of computing the truly minimal one."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3013-Sentence-30131,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3013-Sentence-30132 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3013-Sentence-30131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof: **See Appendix B.** The size difference between the blind-minimal and minimal MDPs will depend on the precise interaction between rewards and dynamics for the problem at hand, making theoretical analyses difficult and experimental results rather anecdotal."@en ;
    askg-onto:inSentence "Proof: **See Appendix B.** The size difference between the blind-minimal and minimal MDPs will depend on the precise interaction between rewards and dynamics for the problem at hand, making theoretical analyses difficult and experimental results rather anecdotal."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anecdotal,
        askg-data:Entity-blind-minimal_mdps,
        askg-data:Entity-difficult,
        askg-data:Entity-experimental_results,
        askg-data:Entity-interaction,
        askg-data:Entity-minimal_mdps,
        askg-data:Entity-rewards_and_dynamics,
        askg-data:Entity-theoretical_analyses .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3013-Sentence-30132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, our experiments in Section 5 and 6 will show that from a computation time point of view, it is often preferable to work with the blind-minimal MDP than to invest in the overhead of computing the truly minimal one."@en ;
    askg-onto:inSentence "However, our experiments in Section 5 and 6 will show that from a computation time point of view, it is often preferable to work with the blind-minimal MDP than to invest in the overhead of computing the truly minimal one."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind-minimal_mdp,
        askg-data:Entity-truly_minimal_mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "Finally, recall that syntactically different but semantically equivalent reward function specifications define the same e-state. Therefore, neither minimality nor blind minimality can be achieved in general without an equivalence check at least as complex as theorem proving for LTL. In pratical implementations, we avoid theorem proving in favour of embedding (fast) formula simplification in our progression and regression algorithms. This means that in principle we only approximate minimality and blind minimality, but this appears to be enough for practical purposes."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30141,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30142,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30143,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30144 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Finally, recall that syntactically different but semantically equivalent reward function specifications define the same e-state."@en ;
    askg-onto:inSentence "Finally, recall that syntactically different but semantically equivalent reward function specifications define the same e-state."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-reward_function_specifications .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Therefore, neither minimality nor blind minimality can be achieved in general without an equivalence check at least as complex as theorem proving for LTL."@en ;
    askg-onto:inSentence "Therefore, neither minimality nor blind minimality can be achieved in general without an equivalence check at least as complex as theorem proving for LTL."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-equivalence_check,
        askg-data:Entity-ltl,
        askg-data:Entity-minimality,
        askg-data:Entity-theorem_proving .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In pratical implementations, we avoid theorem proving in favour of embedding (fast) formula simplification in our progression and regression algorithms."@en ;
    askg-onto:inSentence "In pratical implementations, we avoid theorem proving in favour of embedding (fast) formula simplification in our progression and regression algorithms."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-embedding_formula_simplification,
        askg-data:Entity-progression_algorithms,
        askg-data:Entity-regression_algorithms,
        askg-data:Entity-theorem_proving .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-3014-Sentence-30144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This means that in principle we only approximate minimality and blind minimality, but this appears to be enough for practical purposes."@en ;
    askg-onto:inSentence "This means that in principle we only approximate minimality and blind minimality, but this appears to be enough for practical purposes."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-concept,
        askg-data:Entity-minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "However, as we now explain, Definition 5 leads to an equivalent MDP exhibiting a relaxed notion of minimality, and which is amenable to incremental construction. By inspection, we may observe that wherever an e-state hs,φi **has a successor** hs ′,φ′i via action a**, this** means that in order to succeed in rewarding the behaviours described in φ **by means of** execution sequences that start by going from s to s ′ via a**, it is necessary that the future** starting with s ′**succeeds in rewarding the behaviours described in** φ ′. If hs,φi **is in the** minimal equivalent MDP, and if there really are such execution sequences succeeding in rewarding the behaviours described in φ**, then** hs ′,φ′i **must also be in the minimal MDP.** That is, construction by progression can only introduce e-states which are a priori **needed.** Note that an e-state that is a priori needed may not really **be needed: there may in fact** be no execution sequence using the available actions that exhibits a given behaviour. For instance, consider the response formula (p → (kq → k**$)), i.e., every time trigger** p is true, we will be rewarded k steps later provided q **is true then. Obviously, whether** p is true at some stage affects the way future states should be rewarded. However, if the transition relation happens to have the property that k steps from a state satisfying p**, no** state satisfying q can be reached, then a posteriori p **is irrelevant, and there was no need to** label e-states differently according to whether p **was true or not - observe an occurrence of** this in the example in Figure 7, and how this leads fltl **to produce an extra state at the** bottom left of the Figure. To detect such cases, we would have **to look perhaps quite deep** into feasible futures, which we cannot do while constructing the e-states on the fly. Hence the relaxed notion which we call blind minimality **does not always coincide with absolute** minimality."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3021,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3022,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3023,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3024,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3025,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3026,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3027,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3028 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "However, as we now explain, Definition 5 leads to an equivalent MDP exhibiting a relaxed notion of minimality, and which is amenable to incremental construction."@en ;
    askg-onto:inSentence "However, as we now explain, Definition 5 leads to an equivalent MDP exhibiting a relaxed notion of minimality, and which is amenable to incremental construction."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-definition_5,
        askg-data:Entity-incremental_construction,
        askg-data:Entity-mdp,
        askg-data:Entity-notion_of_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "By inspection, we may observe that wherever an e-state hs,φi **has a successor** hs ′,φ′i via action a**, this** means that in order to succeed in rewarding the behaviours described in φ **by means of** execution sequences that start by going from s to s ′ via a**, it is necessary that the future** starting with s ′**succeeds in rewarding the behaviours described in** φ ′."@en ;
    askg-onto:inSentence "By inspection, we may observe that wherever an e-state hs,φi **has a successor** hs ′,φ′i via action a**, this** means that in order to succeed in rewarding the behaviours described in φ **by means of** execution sequences that start by going from s to s ′ via a**, it is necessary that the future** starting with s ′**succeeds in rewarding the behaviours described in** φ ′."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-e-state_hs%CF%86i,
        askg-data:Entity-execution_sequences,
        askg-data:Entity-future_starting_with_s,
        askg-data:Entity-s_to_s_via_a .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "If hs,φi **is in the** minimal equivalent MDP, and if there really are such execution sequences succeeding in rewarding the behaviours described in φ**, then** hs ′,φ′i **must also be in the minimal MDP.** That is, construction by progression can only introduce e-states which are a priori **needed.** Note that an e-state that is a priori needed may not really **be needed: there may in fact** be no execution sequence using the available actions that exhibits a given behaviour."@en ;
    askg-onto:inSentence "If hs,φi **is in the** minimal equivalent MDP, and if there really are such execution sequences succeeding in rewarding the behaviours described in φ**, then** hs ′,φ′i **must also be in the minimal MDP.** That is, construction by progression can only introduce e-states which are a priori **needed.** Note that an e-state that is a priori needed may not really **be needed: there may in fact** be no execution sequence using the available actions that exhibits a given behaviour."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-execution_sequence,
        askg-data:Entity-execution_sequences,
        askg-data:Entity-given_behaviour,
        askg-data:Entity-hs%CF%86i,
        askg-data:Entity-minimal_equivalent_mdp,
        askg-data:Entity-minimal_mdp,
        askg-data:Entity-rewarding_the_behaviours_described_in_%CF%86 .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For instance, consider the response formula (p → (kq → k**$)), i.e., every time trigger** p is true, we will be rewarded k steps later provided q **is true then."@en ;
    askg-onto:inSentence "For instance, consider the response formula (p → (kq → k**$)), i.e., every time trigger** p is true, we will be rewarded k steps later provided q **is true then."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-q,
        askg-data:Entity-rewarded_k_steps_later,
        askg-data:Entity-then,
        askg-data:Entity-trigger .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Obviously, whether** p is true at some stage affects the way future states should be rewarded."@en ;
    askg-onto:inSentence "Obviously, whether** p is true at some stage affects the way future states should be rewarded."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_states,
        askg-data:Entity-p .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3026 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "However, if the transition relation happens to have the property that k steps from a state satisfying p**, no** state satisfying q can be reached, then a posteriori p **is irrelevant, and there was no need to** label e-states differently according to whether p **was true or not - observe an occurrence of** this in the example in Figure 7, and how this leads fltl **to produce an extra state at the** bottom left of the Figure."@en ;
    askg-onto:inSentence "However, if the transition relation happens to have the property that k steps from a state satisfying p**, no** state satisfying q can be reached, then a posteriori p **is irrelevant, and there was no need to** label e-states differently according to whether p **was true or not - observe an occurrence of** this in the example in Figure 7, and how this leads fltl **to produce an extra state at the** bottom left of the Figure."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-extra_state_at_the_bottom_left_of_the_figure,
        askg-data:Entity-fltl,
        askg-data:Entity-k_steps_from_a_state_satisfying_p,
        askg-data:Entity-no_state_satisfying_q,
        askg-data:Entity-p,
        askg-data:Entity-posteriori_p,
        askg-data:Entity-state_satisfying_p,
        askg-data:Entity-transition_relation,
        askg-data:Entity-whether_p_was_true_or_not .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3027 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "To detect such cases, we would have **to look perhaps quite deep** into feasible futures, which we cannot do while constructing the e-states on the fly."@en ;
    askg-onto:inSentence "To detect such cases, we would have **to look perhaps quite deep** into feasible futures, which we cannot do while constructing the e-states on the fly."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-feasible_futures .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-302-Sentence-3028 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Hence the relaxed notion which we call blind minimality **does not always coincide with absolute** minimality."@en ;
    askg-onto:inSentence "Hence the relaxed notion which we call blind minimality **does not always coincide with absolute** minimality."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-absolute_minimality,
        askg-data:Entity-blind_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "We now formalise the difference between true and blind minimality. For this purpose, it is convenient to define some functions ρ and µ mapping e-states e **to functions from** S ∗ to IR intuitively assigning rewards to sequences in the NMRDP starting from τ (e**). Recall** from Definition 1 that τ **maps each e-state of the MDP to the underlying NMRDP state.** Definition 6 Let D **be an NMRDP. Let** S ′**be the set of e-states in an equivalent MDP** D′ for D. Let e **be any reachable e-state in** S ′**. Let** Γ ′(i) **be a sequence of e-states in** Df′(s ′0) such that Γ ′(i) = e. Let Γ(i) be the corresponding sequence in De(s0) **obtained under** τ in the sense that, for each j ≤ i, Γ(j) = τ (Γ′j)**. Then for any** ∆ ∈ S ∗**, we define**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3031,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3032,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3033,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3034,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3035,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3036,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3037,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3038 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3031 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We now formalise the difference between true and blind minimality."@en ;
    askg-onto:inSentence "We now formalise the difference between true and blind minimality."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-concept,
        askg-data:Entity-true_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3032 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For this purpose, it is convenient to define some functions ρ and µ mapping e-states e **to functions from** S ∗ to IR intuitively assigning rewards to sequences in the NMRDP starting from τ (e**)."@en ;
    askg-onto:inSentence "For this purpose, it is convenient to define some functions ρ and µ mapping e-states e **to functions from** S ∗ to IR intuitively assigning rewards to sequences in the NMRDP starting from τ (e**)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%84,
        askg-data:Entity-e-states,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3033 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Recall** from Definition 1 that τ **maps each e-state of the MDP to the underlying NMRDP state.** Definition 6 Let D **be an NMRDP."@en ;
    askg-onto:inSentence "Recall** from Definition 1 that τ **maps each e-state of the MDP to the underlying NMRDP state.** Definition 6 Let D **be an NMRDP."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-nmrdp_state .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3034 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Let** S ′**be the set of e-states in an equivalent MDP** D′ for D."@en ;
    askg-onto:inSentence "Let** S ′**be the set of e-states in an equivalent MDP** D′ for D."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-e-states,
        askg-data:Entity-mdp,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3035 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Let e **be any reachable e-state in** S ′**."@en ;
    askg-onto:inSentence "Let e **be any reachable e-state in** S ′**."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3036 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Let** Γ ′(i) **be a sequence of e-states in** Df′(s ′0) such that Γ ′(i) = e."@en ;
    askg-onto:inSentence "Let** Γ ′(i) **be a sequence of e-states in** Df′(s ′0) such that Γ ′(i) = e."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3_i,
        askg-data:Entity-dfs_0,
        askg-data:Entity-e-states .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3037 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Let Γ(i) be the corresponding sequence in De(s0) **obtained under** τ in the sense that, for each j ≤ i, Γ(j) = τ (Γ′j)**."@en ;
    askg-onto:inSentence "Let Γ(i) be the corresponding sequence in De(s0) **obtained under** τ in the sense that, for each j ≤ i, Γ(j) = τ (Γ′j)**."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CE%B3j,
        askg-data:Entity-%CF%84,
        askg-data:Entity-des0,
        askg-data:Entity-i .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-303-Sentence-3038 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Then for any** ∆ ∈ S ∗**, we define**"@en ;
    askg-onto:inSentence "Then for any** ∆ ∈ S ∗**, we define**"^^xsd:string ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-304 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$\\rho(e):\\Delta\\mapsto{\\left\\{\\begin{array}{l l}{R(\\Gamma(i-1);\\Delta)}&{{\\mathrm{if~}}\\Delta_{0}=\\Gamma_{i}}\\\\ {0}&{{\\mathrm{otherwise}}}\\end{array}\\right.}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-304-Sentence-3041 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-304-Sentence-3041 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\rho(e):\\Delta\\mapsto{\\left\\{\\begin{array}{l l}{R(\\Gamma(i-1);\\Delta)}&{{\\mathrm{if~}}\\Delta_{0}=\\Gamma_{i}}\\\\ {0}&{{\\mathrm{otherwise}}}\\end{array}\\right.}$$"@en ;
    askg-onto:inSentence "$$\\rho(e):\\Delta\\mapsto{\\left\\{\\begin{array}{l l}{R(\\Gamma(i-1);\\Delta)}&{{\\mathrm{if~}}\\Delta_{0}=\\Gamma_{i}}\\\\ {0}&{{\\mathrm{otherwise}}}\\end{array}\\right.}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Dhoe,
        askg-data:Entity-igtriangleup,
        askg-data:Entity-igtriangleup_0%09ext%CE%B3_i,
        askg-data:Entity-r%09ext%CE%B3i-1igtriangleup .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-305 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "and"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-305-Sentence-3051 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-305-Sentence-3051 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "and"@en ;
    askg-onto:inSentence "and"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-institution,
        askg-data:Entity-journal,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-person,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-306 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$\\mu(e):\\Delta\\mapsto\\left\\{\\begin{array}{l l}{{R(\\Gamma(i-1);\\Delta)}}&{{\\mathrm{if~}\\Delta\\in\\tilde{D}(\\Gamma_{i})}}\\\\ {{0}}&{{\\mathrm{otherwise}}}\\end{array}\\right.$$"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-306-Sentence-3061 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-306-Sentence-3061 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mu(e):\\Delta\\mapsto\\left\\{\\begin{array}{l l}{{R(\\Gamma(i-1);\\Delta)}}&{{\\mathrm{if~}\\Delta\\in\\tilde{D}(\\Gamma_{i})}}\\\\ {{0}}&{{\\mathrm{otherwise}}}\\end{array}\\right.$$"@en ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "For any unreachable e-state e, we define both ρ(e)(∆) and µ(e)(∆) **to be 0 for all** ∆. Note carefully the difference between ρ and µ**. The former describes the rewards assigned** to all continuations of a given state sequence, while the latter confines rewards to **feasible** continuations. Note also that ρ and µ **are well-defined despite the indeterminacy in the** choice of Γ′(i**), since by clause 4 of Definition 1, all such choices lead to the same values for** R."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3071,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3072,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3073,
        askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3074 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3071 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For any unreachable e-state e, we define both ρ(e)(∆) and µ(e)(∆) **to be 0 for all** ∆."@en ;
    askg-onto:inSentence "For any unreachable e-state e, we define both ρ(e)(∆) and µ(e)(∆) **to be 0 for all** ∆."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-0,
        askg-data:Entity-e-state .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3072 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note carefully the difference between ρ and µ**."@en ;
    askg-onto:inSentence "Note carefully the difference between ρ and µ**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C2%B5,
        askg-data:Entity-%CF%81 .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3073 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The former describes the rewards assigned** to all continuations of a given state sequence, while the latter confines rewards to **feasible** continuations."@en ;
    askg-onto:inSentence "The former describes the rewards assigned** to all continuations of a given state sequence, while the latter confines rewards to **feasible** continuations."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-continuations_of_a_given_state_sequence,
        askg-data:Entity-feasible_continuations,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-307-Sentence-3074 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Note also that ρ and µ **are well-defined despite the indeterminacy in the** choice of Γ′(i**), since by clause 4 of Definition 1, all such choices lead to the same values for** R."@en ;
    askg-onto:inSentence "Note also that ρ and µ **are well-defined despite the indeterminacy in the** choice of Γ′(i**), since by clause 4 of Definition 1, all such choices lead to the same values for** R."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CF%81,
        askg-data:Entity-all_such_choices,
        askg-data:Entity-r .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-308 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Theorem 3 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-308-Sentence-3081 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-308-Sentence-3081 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Theorem 3 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."@en ;
    askg-onto:inSentence "Theorem 3 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-e-states,
        askg-data:Entity-mdp_d,
        askg-data:Entity-s,
        askg-data:Entity-ss0aprr .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-309 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "D′**is minimal iff every e-state in** S ′**is reachable and** S ′**contains no two distinct e-states** s ′1 and s ′2 **with** τ (s ′1) = τ (s ′2) and µ(s ′1) = µ(s ′2)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-309-Sentence-3091 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-30-Paragraph-309-Sentence-3091 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "D′**is minimal iff every e-state in** S ′**is reachable and** S ′**contains no two distinct e-states** s ′1 and s ′2 **with** τ (s ′1) = τ (s ′2) and µ(s ′1) = µ(s ′2)."@en ;
    askg-onto:inSentence "D′**is minimal iff every e-state in** S ′**is reachable and** S ′**contains no two distinct e-states** s ′1 and s ′2 **with** τ (s ′1) = τ (s ′2) and µ(s ′1) = µ(s ′2)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C2%B5s_1,
        askg-data:Entity-%C2%B5s_2,
        askg-data:Entity-%CF%84_s_1,
        askg-data:Entity-%CF%84_s_2,
        askg-data:Entity-d,
        askg-data:Entity-every_e-state_in_s__is_reachable,
        askg-data:Entity-s_,
        askg-data:Entity-s_1_and_s_2 .

askg-data:Paper-c253584c3f1ff2a2-Section-31 a askg-onto:Section ;
    rdfs:label "Section 31"@en ;
    domo:Text "3.9 Embedded Solution/Construction"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314 ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Blind minimality is essentially the best achievable with anytime state-based solution methods which typically extend their envelope one step forward without looking deeper into the future. Our translation into a blind-minimal MDP can be trivially embedded in any of these solution methods. This results in an 'on-line construction' of the MDP: the method entirely drives the construction of those parts of the MDP which it feels the need to explore, and leave the others implicit. If time is short, a suboptimal or even incomplete policy may be returned, but only a fraction of the state and expanded state **spaces might be constructed.** Note that the solution method should raise an exception as soon as one of the reward formulae progresses to ⊥, i.e., as soon as an expanded state hs,φi **is built such that (**⊥ : r) ∈ φ, since this acts as a detector of unsuitable reward function specifications."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3111,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3112,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3113,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3114 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Blind minimality is essentially the best achievable with anytime state-based solution methods which typically extend their envelope one step forward without looking deeper into the future."@en ;
    askg-onto:inSentence "Blind minimality is essentially the best achievable with anytime state-based solution methods which typically extend their envelope one step forward without looking deeper into the future."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_state-based_solution_methods,
        askg-data:Entity-blind_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Our translation into a blind-minimal MDP can be trivially embedded in any of these solution methods."@en ;
    askg-onto:inSentence "Our translation into a blind-minimal MDP can be trivially embedded in any of these solution methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind-minimal_mdp,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This results in an 'on-line construction' of the MDP: the method entirely drives the construction of those parts of the MDP which it feels the need to explore, and leave the others implicit."@en ;
    askg-onto:inSentence "This results in an 'on-line construction' of the MDP: the method entirely drives the construction of those parts of the MDP which it feels the need to explore, and leave the others implicit."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-method .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-311-Sentence-3114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "If time is short, a suboptimal or even incomplete policy may be returned, but only a fraction of the state and expanded state **spaces might be constructed.** Note that the solution method should raise an exception as soon as one of the reward formulae progresses to ⊥, i.e., as soon as an expanded state hs,φi **is built such that (**⊥ : r) ∈ φ, since this acts as a detector of unsuitable reward function specifications."@en ;
    askg-onto:inSentence "If time is short, a suboptimal or even incomplete policy may be returned, but only a fraction of the state and expanded state **spaces might be constructed.** Note that the solution method should raise an exception as soon as one of the reward formulae progresses to ⊥, i.e., as soon as an expanded state hs,φi **is built such that (**⊥ : r) ∈ φ, since this acts as a detector of unsuitable reward function specifications."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-__r,
        askg-data:Entity-expanded_state_hs%CF%86i,
        askg-data:Entity-reward_formulae,
        askg-data:Entity-spaces,
        askg-data:Entity-state .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "To the extent enabled by blind minimality, our approach allows for a dynamic analysis of the reward formulae, much as in pltlstr **(Bacchus et al., 1997). Indeed, only the execution** sequences feasible under a particular policy actually explored by the solution method contribute to the analysis of rewards for that policy. Specifically, the reward formulae generated by progression for a given policy are determined by the prefixes of the execution sequences feasible under this policy. This dynamic analysis is particularly useful, since relevance of reward formulae to particular policies (e.g. the optimal policy) cannot be detected a priori."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3121,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3122,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3123,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3124,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3125 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To the extent enabled by blind minimality, our approach allows for a dynamic analysis of the reward formulae, much as in pltlstr **(Bacchus et al., 1997)."@en ;
    askg-onto:inSentence "To the extent enabled by blind minimality, our approach allows for a dynamic analysis of the reward formulae, much as in pltlstr **(Bacchus et al., 1997)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1997,
        askg-data:Entity-approach,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-dynamic_analysis_of_the_reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Indeed, only the execution** sequences feasible under a particular policy actually explored by the solution method contribute to the analysis of rewards for that policy."@en ;
    askg-onto:inSentence "Indeed, only the execution** sequences feasible under a particular policy actually explored by the solution method contribute to the analysis of rewards for that policy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis_of_rewards,
        askg-data:Entity-execution_sequences,
        askg-data:Entity-policy,
        askg-data:Entity-solution_method .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Specifically, the reward formulae generated by progression for a given policy are determined by the prefixes of the execution sequences feasible under this policy."@en ;
    askg-onto:inSentence "Specifically, the reward formulae generated by progression for a given policy are determined by the prefixes of the execution sequences feasible under this policy."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-execution_sequences,
        askg-data:Entity-policy,
        askg-data:Entity-progression,
        askg-data:Entity-reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This dynamic analysis is particularly useful, since relevance of reward formulae to particular policies (e.g."@en ;
    askg-onto:inSentence "This dynamic analysis is particularly useful, since relevance of reward formulae to particular policies (e.g."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_analysis,
        askg-data:Entity-policies,
        askg-data:Entity-reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-312-Sentence-3125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "the optimal policy) cannot be detected a priori."@en ;
    askg-onto:inSentence "the optimal policy) cannot be detected a priori."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_priori,
        askg-data:Entity-optimal_policy .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The forward-chaining planner TLPlan (Bacchus & Kabanza, 2000) introduced the idea of using FLTL to specify domain-specific search control knowledge **and formula progression** to prune unpromising sequential plans (plans violating this knowledge) from deterministic search spaces. This has been shown to provide enormous time gains, leading TLPlan to win the 2002 planning competition hand-tailored track. Because our approach is based on progression, it provides an elegant way to exploit search **control knowledge, yet in the** context of decision-theoretic planning. Here this results **in a dramatic reduction of the** fraction of the MDP to be constructed and explored, and therefore in substantially better policies by the deadline."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3131,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3132,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3133,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3134 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The forward-chaining planner TLPlan (Bacchus & Kabanza, 2000) introduced the idea of using FLTL to specify domain-specific search control knowledge **and formula progression** to prune unpromising sequential plans (plans violating this knowledge) from deterministic search spaces."@en ;
    askg-onto:inSentence "The forward-chaining planner TLPlan (Bacchus & Kabanza, 2000) introduced the idea of using FLTL to specify domain-specific search control knowledge **and formula progression** to prune unpromising sequential plans (plans violating this knowledge) from deterministic search spaces."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deterministic_search_spaces,
        askg-data:Entity-domain-specific_search_control_knowledge,
        askg-data:Entity-fltl,
        askg-data:Entity-tlplan,
        askg-data:Entity-unpromising_sequential_plans .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This has been shown to provide enormous time gains, leading TLPlan to win the 2002 planning competition hand-tailored track."@en ;
    askg-onto:inSentence "This has been shown to provide enormous time gains, leading TLPlan to win the 2002 planning competition hand-tailored track."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-tlplan .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Because our approach is based on progression, it provides an elegant way to exploit search **control knowledge, yet in the** context of decision-theoretic planning."@en ;
    askg-onto:inSentence "Because our approach is based on progression, it provides an elegant way to exploit search **control knowledge, yet in the** context of decision-theoretic planning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-search_control_knowledge .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-313-Sentence-3134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Here this results **in a dramatic reduction of the** fraction of the MDP to be constructed and explored, and therefore in substantially better policies by the deadline."@en ;
    askg-onto:inSentence "Here this results **in a dramatic reduction of the** fraction of the MDP to be constructed and explored, and therefore in substantially better policies by the deadline."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deadline,
        askg-data:Entity-fraction,
        askg-data:Entity-mdp,
        askg-data:Entity-policies .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "We achieve this as follows. We specify, via a $-free formula c0**, properties which we know** must be verified by paths feasible under promising **policies. Then we simply progress** c0 alongside the reward function specification, making e-states triples hs,φ,ci where c **is a $-free** formula obtained by progression. To prevent the solution method from applying an action that leads to the control knowledge being violated, the action applicability condition (item 3 in Definition 5) becomes: a ∈ A′(hs,φ,ci) iff a ∈ A(s) and c 6= ⊥ **(the other changes are** straightforward). For instance, the effect of the control knowledge formula (p → q**) is to** remove from consideration any feasible path in which p is not followed by q**. This is detected** as soon as violation occurs, when the formula progresses to ⊥**. Although this paper focuses** on non-Markovian rewards rather than dynamics, it should be **noted that $-free formulae** can also be used to express non-Markovian constraints on the **system's dynamics, which** can be incorporated in our approach exactly as we do for the control knowledge."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3141,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3142,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3143,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3144,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3145,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3146,
        askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3147 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We achieve this as follows."@en ;
    askg-onto:inSentence "We achieve this as follows."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-as_follows,
        askg-data:Entity-this .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We specify, via a $-free formula c0**, properties which we know** must be verified by paths feasible under promising **policies."@en ;
    askg-onto:inSentence "We specify, via a $-free formula c0**, properties which we know** must be verified by paths feasible under promising **policies."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula_c0,
        askg-data:Entity-paths,
        askg-data:Entity-policies,
        askg-data:Entity-properties .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Then we simply progress** c0 alongside the reward function specification, making e-states triples hs,φ,ci where c **is a $-free** formula obtained by progression."@en ;
    askg-onto:inSentence "Then we simply progress** c0 alongside the reward function specification, making e-states triples hs,φ,ci where c **is a $-free** formula obtained by progression."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity--free_formula,
        askg-data:Entity-c,
        askg-data:Entity-c0,
        askg-data:Entity-e-states,
        askg-data:Entity-reward_function_specification,
        askg-data:Entity-triples_hs%CF%86ci .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To prevent the solution method from applying an action that leads to the control knowledge being violated, the action applicability condition (item 3 in Definition 5) becomes: a ∈ A′(hs,φ,ci) iff a ∈ A(s) and c 6= ⊥ **(the other changes are** straightforward)."@en ;
    askg-onto:inSentence "To prevent the solution method from applying an action that leads to the control knowledge being violated, the action applicability condition (item 3 in Definition 5) becomes: a ∈ A′(hs,φ,ci) iff a ∈ A(s) and c 6= ⊥ **(the other changes are** straightforward)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_applicability_condition,
        askg-data:Entity-condition,
        askg-data:Entity-control_knowledge,
        askg-data:Entity-knowledge,
        askg-data:Entity-method,
        askg-data:Entity-solution_method .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3145 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For instance, the effect of the control knowledge formula (p → q**) is to** remove from consideration any feasible path in which p is not followed by q**."@en ;
    askg-onto:inSentence "For instance, the effect of the control knowledge formula (p → q**) is to** remove from consideration any feasible path in which p is not followed by q**."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control_knowledge_formula,
        askg-data:Entity-formula_p__q,
        askg-data:Entity-p,
        askg-data:Entity-q .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3146 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This is detected** as soon as violation occurs, when the formula progresses to ⊥**."@en ;
    askg-onto:inSentence "This is detected** as soon as violation occurs, when the formula progresses to ⊥**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-violation .

askg-data:Paper-c253584c3f1ff2a2-Section-31-Paragraph-314-Sentence-3147 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Although this paper focuses** on non-Markovian rewards rather than dynamics, it should be **noted that $-free formulae** can also be used to express non-Markovian constraints on the **system's dynamics, which** can be incorporated in our approach exactly as we do for the control knowledge."@en ;
    askg-onto:inSentence "Although this paper focuses** on non-Markovian rewards rather than dynamics, it should be **noted that $-free formulae** can also be used to express non-Markovian constraints on the **system's dynamics, which** can be incorporated in our approach exactly as we do for the control knowledge."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity--free_formulae,
        askg-data:Entity-control_knowledge,
        askg-data:Entity-non-markovian_constraints,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-our_approach,
        askg-data:Entity-systems_dynamics .

askg-data:Paper-c253584c3f1ff2a2-Section-32 a askg-onto:Section ;
    rdfs:label "Section 32"@en ;
    domo:Text "3.10 Discussion"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323 ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Existing approaches (Bacchus et al., 1996, 1997) advocate the use of PLTL over a finite past to specify non-Markovian rewards. In the PLTL style of specification, we describe the past conditions under which we get rewarded now, while with $FLTL we describe the conditions on the present and future under which future states will be rewarded. While the behaviours and rewards may be the same in each scheme, the naturalness of thinking in one style or the other depends on the case. Letting the kids have a **strawberry dessert because** they have been good all day fits naturally into a past-oriented account of rewards, whereas promising that they may watch a movie if they tidy their room (indeed, making sense of the whole notion of promising) goes more naturally with $FLTL. One advantage of the PLTL formulation is that it trivially enforces the principle that present rewards do not depend on future states. In $FLTL, this responsibility is placed on **the domain modeller. The best** we can offer is an exception mechanism to recognise mistakes when their effects appear, or syntactic restrictions. On the other hand, the greater expressive power of $FLTL opens the possibility of considering a richer class of decision processes, e.g. with uncertainty as to which rewards are received (the dessert or the movie) and when (some time next week, before it rains)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3211,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3212,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3213,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3214,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3215,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3216,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3217,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3218,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3219 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Existing approaches (Bacchus et al., 1996, 1997) advocate the use of PLTL over a finite past to specify non-Markovian rewards."@en ;
    askg-onto:inSentence "Existing approaches (Bacchus et al., 1996, 1997) advocate the use of PLTL over a finite past to specify non-Markovian rewards."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996_1997,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-existing_approaches,
        askg-data:Entity-pltl_over_a_finite_past .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the PLTL style of specification, we describe the past conditions under which we get rewarded now, while with $FLTL we describe the conditions on the present and future under which future states will be rewarded."@en ;
    askg-onto:inSentence "In the PLTL style of specification, we describe the past conditions under which we get rewarded now, while with $FLTL we describe the conditions on the present and future under which future states will be rewarded."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conditions,
        askg-data:Entity-fltl,
        askg-data:Entity-future_states,
        askg-data:Entity-past_conditions,
        askg-data:Entity-pltl,
        askg-data:Entity-rewarded_now,
        askg-data:Entity-specification .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While the behaviours and rewards may be the same in each scheme, the naturalness of thinking in one style or the other depends on the case."@en ;
    askg-onto:inSentence "While the behaviours and rewards may be the same in each scheme, the naturalness of thinking in one style or the other depends on the case."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-each_scheme,
        askg-data:Entity-naturalness,
        askg-data:Entity-the_case .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Letting the kids have a **strawberry dessert because** they have been good all day fits naturally into a past-oriented account of rewards, whereas promising that they may watch a movie if they tidy their room (indeed, making sense of the whole notion of promising) goes more naturally with $FLTL."@en ;
    askg-onto:inSentence "Letting the kids have a **strawberry dessert because** they have been good all day fits naturally into a past-oriented account of rewards, whereas promising that they may watch a movie if they tidy their room (indeed, making sense of the whole notion of promising) goes more naturally with $FLTL."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kids,
        askg-data:Entity-past-oriented_account_of_rewards,
        askg-data:Entity-they .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "One advantage of the PLTL formulation is that it trivially enforces the principle that present rewards do not depend on future states."@en ;
    askg-onto:inSentence "One advantage of the PLTL formulation is that it trivially enforces the principle that present rewards do not depend on future states."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_formulation,
        askg-data:Entity-principle_that_present_rewards_do_not_depend_on_future_states .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In $FLTL, this responsibility is placed on **the domain modeller."@en ;
    askg-onto:inSentence "In $FLTL, this responsibility is placed on **the domain modeller."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain,
        askg-data:Entity-fltl,
        askg-data:Entity-the_domain_modeller .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The best** we can offer is an exception mechanism to recognise mistakes when their effects appear, or syntactic restrictions."@en ;
    askg-onto:inSentence "The best** we can offer is an exception mechanism to recognise mistakes when their effects appear, or syntactic restrictions."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effects,
        askg-data:Entity-exception_mechanism,
        askg-data:Entity-mistakes,
        askg-data:Entity-syntactic_restrictions .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3218 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "On the other hand, the greater expressive power of $FLTL opens the possibility of considering a richer class of decision processes, e.g."@en ;
    askg-onto:inSentence "On the other hand, the greater expressive power of $FLTL opens the possibility of considering a richer class of decision processes, e.g."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_richer_class_of_decision_processes,
        askg-data:Entity-fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-321-Sentence-3219 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "with uncertainty as to which rewards are received (the dessert or the movie) and when (some time next week, before it rains)."@en ;
    askg-onto:inSentence "with uncertainty as to which rewards are received (the dessert or the movie) and when (some time next week, before it rains)."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-it_rains,
        askg-data:Entity-next_week,
        askg-data:Entity-rewards,
        askg-data:Entity-the_dessert,
        askg-data:Entity-the_movie,
        askg-data:Entity-time .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "At any rate, we believe that $FLTL is better suited than PLTL to solving NMRDPs using anytime state-based solution methods. While the pltlsim translation could be easily embedded in such a solution method, it loses the structure of the original formulae when considering subformulae individually. Consequently, the expanded state space easily becomes exponentially bigger than the blind-minimal one. This is problematic with the solution methods we consider, because size severely affects **their performance in solution** quality. The pre-processing phase of pltlmin **uses PLTL formula regression to find sets** of subformulae as potential labels for possible predecessor states, so that the subsequent generation phase builds an MDP representing all and only the histories which make a difference to the way actually feasible execution sequences should be rewarded. Not only does this recover the structure of the original formula, but in the best case, the MDP produced is exponentially smaller than the blind-minimal one. However, the prohibitive cost of the pre-processing phase makes it unsuitable for anytime solution methods. We do not consider that any method based on PLTL and regression will achieve a meaningful relaxed notion of minimality without a costly pre-processing phase. fltl **is an approach based on** $FLTL and progression which does precisely that, letting the solution method resolve the tradeoff between quality and cost in a principled way intermediate between the two extreme suggestions above."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3221,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3222,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3223,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3224,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3225,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3226,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3227,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3228,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3229 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "At any rate, we believe that $FLTL is better suited than PLTL to solving NMRDPs using anytime state-based solution methods."@en ;
    askg-onto:inSentence "At any rate, we believe that $FLTL is better suited than PLTL to solving NMRDPs using anytime state-based solution methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_state-based_solution_methods,
        askg-data:Entity-fltl,
        askg-data:Entity-nmrdps,
        askg-data:Entity-pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While the pltlsim translation could be easily embedded in such a solution method, it loses the structure of the original formulae when considering subformulae individually."@en ;
    askg-onto:inSentence "While the pltlsim translation could be easily embedded in such a solution method, it loses the structure of the original formulae when considering subformulae individually."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlsim_translation,
        askg-data:Entity-solution_method .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Consequently, the expanded state space easily becomes exponentially bigger than the blind-minimal one."@en ;
    askg-onto:inSentence "Consequently, the expanded state space easily becomes exponentially bigger than the blind-minimal one."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind-minimal,
        askg-data:Entity-expansion,
        askg-data:Entity-state_space .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This is problematic with the solution methods we consider, because size severely affects **their performance in solution** quality."@en ;
    askg-onto:inSentence "This is problematic with the solution methods we consider, because size severely affects **their performance in solution** quality."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-performance_in_solution_quality,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The pre-processing phase of pltlmin **uses PLTL formula regression to find sets** of subformulae as potential labels for possible predecessor states, so that the subsequent generation phase builds an MDP representing all and only the histories which make a difference to the way actually feasible execution sequences should be rewarded."@en ;
    askg-onto:inSentence "The pre-processing phase of pltlmin **uses PLTL formula regression to find sets** of subformulae as potential labels for possible predecessor states, so that the subsequent generation phase builds an MDP representing all and only the histories which make a difference to the way actually feasible execution sequences should be rewarded."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-execution_sequences,
        askg-data:Entity-generation_phase,
        askg-data:Entity-histories,
        askg-data:Entity-mdp,
        askg-data:Entity-pltl_formula_regression,
        askg-data:Entity-pltlmin,
        askg-data:Entity-possible_predecessor_states,
        askg-data:Entity-subformulae .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Not only does this recover the structure of the original formula, but in the best case, the MDP produced is exponentially smaller than the blind-minimal one."@en ;
    askg-onto:inSentence "Not only does this recover the structure of the original formula, but in the best case, the MDP produced is exponentially smaller than the blind-minimal one."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind-minimal_one,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3227 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "However, the prohibitive cost of the pre-processing phase makes it unsuitable for anytime solution methods."@en ;
    askg-onto:inSentence "However, the prohibitive cost of the pre-processing phase makes it unsuitable for anytime solution methods."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_solution_methods,
        askg-data:Entity-pre-processing_phase .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3228 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We do not consider that any method based on PLTL and regression will achieve a meaningful relaxed notion of minimality without a costly pre-processing phase."@en ;
    askg-onto:inSentence "We do not consider that any method based on PLTL and regression will achieve a meaningful relaxed notion of minimality without a costly pre-processing phase."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl,
        askg-data:Entity-regression .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-322-Sentence-3229 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "fltl **is an approach based on** $FLTL and progression which does precisely that, letting the solution method resolve the tradeoff between quality and cost in a principled way intermediate between the two extreme suggestions above."@en ;
    askg-onto:inSentence "fltl **is an approach based on** $FLTL and progression which does precisely that, letting the solution method resolve the tradeoff between quality and cost in a principled way intermediate between the two extreme suggestions above."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-the_tradeoff_between_quality_and_cost .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The structured representation and solution methods targeted by Bacchus et al. (1997) differ from the anytime state-based solution methods fltl **primarily aims at, in particular** in that they do not require explicit state enumeration at all. Here, non-minimality is not as problematic as with the state-based approaches. In virtue of the size of the MDP produced, the pltlstr translation is, as pltlsim**, clearly unsuitable to anytime state-based methods.**9 In another sense, too, fltl **represents a middle way, combining the advantages conferred by** state-based and structured approaches, e.g. by pltlmin on one side, and pltlstr **on the** other. From the former fltl **inherits a meaningful notion of minimality. As with the latter,** approximate solution methods can be used and can perform a restricted dynamic analysis of the reward formulae. In particular, formula progression enables even state-based methods to exploit some of the structure in '$FLTL space'. However, the gap between blind and true minimality indicates that progression alone is insufficient to always fully exploit that structure. There is a hope that pltlstr **is able to take advantage of the full structure of** the reward function, but also a possibility that it will fail **to exploit even as much structure** as fltl**, as efficiently. An empirical comparison of the three approaches is needed to answer** this question and identify the domain features favoring one **over the other.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3231,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-32310,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-32311,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3232,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3233,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3234,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3235,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3236,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3237,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3238,
        askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3239 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The structured representation and solution methods targeted by Bacchus et al."@en ;
    askg-onto:inSentence "The structured representation and solution methods targeted by Bacchus et al."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-solution_methods,
        askg-data:Entity-structured_representation .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-32310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "There is a hope that pltlstr **is able to take advantage of the full structure of** the reward function, but also a possibility that it will fail **to exploit even as much structure** as fltl**, as efficiently."@en ;
    askg-onto:inSentence "There is a hope that pltlstr **is able to take advantage of the full structure of** the reward function, but also a possibility that it will fail **to exploit even as much structure** as fltl**, as efficiently."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-the_full_structure_of_the_reward_function,
        askg-data:Entity-the_structure_as_fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-32311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "An empirical comparison of the three approaches is needed to answer** this question and identify the domain features favoring one **over the other.**"@en ;
    askg-onto:inSentence "An empirical comparison of the three approaches is needed to answer** this question and identify the domain features favoring one **over the other.**"^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain_features,
        askg-data:Entity-three_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1997) differ from the anytime state-based solution methods fltl **primarily aims at, in particular** in that they do not require explicit state enumeration at all."@en ;
    askg-onto:inSentence "(1997) differ from the anytime state-based solution methods fltl **primarily aims at, in particular** in that they do not require explicit state enumeration at all."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_state-based_solution_methods,
        askg-data:Entity-explicit_state_enumeration .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Here, non-minimality is not as problematic as with the state-based approaches."@en ;
    askg-onto:inSentence "Here, non-minimality is not as problematic as with the state-based approaches."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-minimality,
        askg-data:Entity-state-based_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3234 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In virtue of the size of the MDP produced, the pltlstr translation is, as pltlsim**, clearly unsuitable to anytime state-based methods.**9 In another sense, too, fltl **represents a middle way, combining the advantages conferred by** state-based and structured approaches, e.g."@en ;
    askg-onto:inSentence "In virtue of the size of the MDP produced, the pltlstr translation is, as pltlsim**, clearly unsuitable to anytime state-based methods.**9 In another sense, too, fltl **represents a middle way, combining the advantages conferred by** state-based and structured approaches, e.g."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_state-based_methods,
        askg-data:Entity-fltl,
        askg-data:Entity-middle_way,
        askg-data:Entity-pltlstr_translation,
        askg-data:Entity-state-based_approaches,
        askg-data:Entity-structured_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3235 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "by pltlmin on one side, and pltlstr **on the** other."@en ;
    askg-onto:inSentence "by pltlmin on one side, and pltlstr **on the** other."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3236 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "From the former fltl **inherits a meaningful notion of minimality."@en ;
    askg-onto:inSentence "From the former fltl **inherits a meaningful notion of minimality."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-meaningful_notion_of_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3237 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "As with the latter,** approximate solution methods can be used and can perform a restricted dynamic analysis of the reward formulae."@en ;
    askg-onto:inSentence "As with the latter,** approximate solution methods can be used and can perform a restricted dynamic analysis of the reward formulae."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approximate_solution_methods,
        askg-data:Entity-restricted_dynamic_analysis_of_the_reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3238 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In particular, formula progression enables even state-based methods to exploit some of the structure in '$FLTL space'."@en ;
    askg-onto:inSentence "In particular, formula progression enables even state-based methods to exploit some of the structure in '$FLTL space'."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_space,
        askg-data:Entity-formula_progression,
        askg-data:Entity-state-based_methods,
        askg-data:Entity-structure .

askg-data:Paper-c253584c3f1ff2a2-Section-32-Paragraph-323-Sentence-3239 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "However, the gap between blind and true minimality indicates that progression alone is insufficient to always fully exploit that structure."@en ;
    askg-onto:inSentence "However, the gap between blind and true minimality indicates that progression alone is insufficient to always fully exploit that structure."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-gap,
        askg-data:Entity-progression,
        askg-data:Entity-true_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-33 a askg-onto:Section ;
    rdfs:label "Section 33"@en ;
    domo:Text "4. Nmrdpp"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331 ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The first step towards a decent comparison of the different approaches is to have a framework that includes them all. The Non-Markovian Reward Decision Process Planner, **nmrdpp**, is a platform for the development and experimentation of approaches to NMRDPs. it provides an implementation of the approaches we have described in a common framework, within a single system, and with a common input language. nmrdpp **is available on-line,** see http://rsise.anu.edu.au/~charlesg/nmrdpp**. It is worth noting that Bacchus et al.** (1996, 1997) do not report any implementation of their approaches."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3311,
        askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3312,
        askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3313,
        askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3314,
        askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3315 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The first step towards a decent comparison of the different approaches is to have a framework that includes them all."@en ;
    askg-onto:inSentence "The first step towards a decent comparison of the different approaches is to have a framework that includes them all."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_approaches,
        askg-data:Entity-framework .

askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The Non-Markovian Reward Decision Process Planner, **nmrdpp**, is a platform for the development and experimentation of approaches to NMRDPs."@en ;
    askg-onto:inSentence "The Non-Markovian Reward Decision Process Planner, **nmrdpp**, is a platform for the development and experimentation of approaches to NMRDPs."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-markovian_reward_decision_process_planner,
        askg-data:Entity-platform_for_the_development_and_experimentation_of_approaches_to_nmrdps .

askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "it provides an implementation of the approaches we have described in a common framework, within a single system, and with a common input language."@en ;
    askg-onto:inSentence "it provides an implementation of the approaches we have described in a common framework, within a single system, and with a common input language."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-implementation .

askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "nmrdpp **is available on-line,** see http://rsise.anu.edu.au/~charlesg/nmrdpp**."@en ;
    askg-onto:inSentence "nmrdpp **is available on-line,** see http://rsise.anu.edu.au/~charlesg/nmrdpp**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-httprsiseanueduaucharlesgnmrdpp,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-33-Paragraph-331-Sentence-3315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "It is worth noting that Bacchus et al.** (1996, 1997) do not report any implementation of their approaches."@en ;
    askg-onto:inSentence "It is worth noting that Bacchus et al.** (1996, 1997) do not report any implementation of their approaches."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-implementation_of_their_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-34 a askg-onto:Section ;
    rdfs:label "Section 34"@en ;
    domo:Text "4.1 Input Language"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343 ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The input language enables the specification of actions, initial states, rewards, and search control-knowledge. The format for the action specification **is essentially the same as in the** SPUDD system (Hoey et al., 1999). The reward specification is **one or more formulae, each** associated with a name and a real number. These formulae are in either PLTL or $FLTL. Control knowledge is given in the same language as that chosen for the reward. Control knowledge formulae will have to be verified by any sequence of **states feasible under the** generated policies. Initial states are simply specified as part of the control knowledge or as explicit assignments to propositions."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3411,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3412,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3413,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3414,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3415,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3416,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3417 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The input language enables the specification of actions, initial states, rewards, and search control-knowledge."@en ;
    askg-onto:inSentence "The input language enables the specification of actions, initial states, rewards, and search control-knowledge."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_language,
        askg-data:Entity-specification_of_actions_initial_states_rewards_and_search_control-knowledge .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The format for the action specification **is essentially the same as in the** SPUDD system (Hoey et al., 1999)."@en ;
    askg-onto:inSentence "The format for the action specification **is essentially the same as in the** SPUDD system (Hoey et al., 1999)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1999,
        askg-data:Entity-action_specification,
        askg-data:Entity-hoey_et_al,
        askg-data:Entity-spudd_system .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The reward specification is **one or more formulae, each** associated with a name and a real number."@en ;
    askg-onto:inSentence "The reward specification is **one or more formulae, each** associated with a name and a real number."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_name,
        askg-data:Entity-a_real_number,
        askg-data:Entity-formulae,
        askg-data:Entity-one_or_more_formulae,
        askg-data:Entity-reward_specification .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These formulae are in either PLTL or $FLTL."@en ;
    askg-onto:inSentence "These formulae are in either PLTL or $FLTL."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-formulae,
        askg-data:Entity-pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Control knowledge is given in the same language as that chosen for the reward."@en ;
    askg-onto:inSentence "Control knowledge is given in the same language as that chosen for the reward."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control_knowledge,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Control knowledge formulae will have to be verified by any sequence of **states feasible under the** generated policies."@en ;
    askg-onto:inSentence "Control knowledge formulae will have to be verified by any sequence of **states feasible under the** generated policies."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_sequence_of_states_feasible_under_the_generated_policies,
        askg-data:Entity-control_knowledge_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-341-Sentence-3417 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Initial states are simply specified as part of the control knowledge or as explicit assignments to propositions."@en ;
    askg-onto:inSentence "Initial states are simply specified as part of the control knowledge or as explicit assignments to propositions."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_states,
        askg-data:Entity-part_of_the_control_knowledge,
        askg-data:Entity-propositions .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "9. It would be interesting, on the other hand, to use pltlstr **in conjunction with symbolic versions of such** methods, e.g. Symbolic LAO* (Feng & Hansen, 2002) or Symbolic RTDP (Feng, Hansen, & Zilberstein, 2003). action flip heads (0.5) endaction action tilt heads (heads (0.9) (0.1)) endaction heads = ff [first, 5.0]? heads and ~prv (pdi heads) [seq, 1.0]? (prv^2 heads) and (prv heads) and ~heads Figure 8: Input for the Coin Example. prv (previously) stands for ⊖ and pdi **(past diamond) stands for** ♦- ."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3421,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3422,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3423,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3424,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3425,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3426,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3427 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "9."@en ;
    askg-onto:inSentence "9."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-abstract,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It would be interesting, on the other hand, to use pltlstr **in conjunction with symbolic versions of such** methods, e.g."@en ;
    askg-onto:inSentence "It would be interesting, on the other hand, to use pltlstr **in conjunction with symbolic versions of such** methods, e.g."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-symbolic_versions_of_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Symbolic LAO* (Feng & Hansen, 2002) or Symbolic RTDP (Feng, Hansen, & Zilberstein, 2003)."@en ;
    askg-onto:inSentence "Symbolic LAO* (Feng & Hansen, 2002) or Symbolic RTDP (Feng, Hansen, & Zilberstein, 2003)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feng__hansen_2002,
        askg-data:Entity-feng_hansen__zilberstein_2003,
        askg-data:Entity-model,
        askg-data:Entity-paper,
        askg-data:Entity-symbolic_lao,
        askg-data:Entity-symbolic_rtdp .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "action flip heads (0.5) endaction action tilt heads (heads (0.9) (0.1)) endaction heads = ff [first, 5.0]?"@en ;
    askg-onto:inSentence "action flip heads (0.5) endaction action tilt heads (heads (0.9) (0.1)) endaction heads = ff [first, 5.0]?"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_flip,
        askg-data:Entity-action_tilt,
        askg-data:Entity-ff_first_50,
        askg-data:Entity-heads .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "heads and ~prv (pdi heads) [seq, 1.0]?"@en ;
    askg-onto:inSentence "heads and ~prv (pdi heads) [seq, 1.0]?"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10,
        askg-data:Entity-heads,
        askg-data:Entity-pdi_heads,
        askg-data:Entity-seq .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "(prv^2 heads) and (prv heads) and ~heads Figure 8: Input for the Coin Example."@en ;
    askg-onto:inSentence "(prv^2 heads) and (prv heads) and ~heads Figure 8: Input for the Coin Example."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coin_example,
        askg-data:Entity-prv2_heads,
        askg-data:Entity-prv_heads .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-342-Sentence-3427 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "prv (previously) stands for ⊖ and pdi **(past diamond) stands for** ♦- ."@en ;
    askg-onto:inSentence "prv (previously) stands for ⊖ and pdi **(past diamond) stands for** ♦- ."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pdi,
        askg-data:Entity-prv .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "For instance, consider a simple example consisting of a coin **showing either heads or** tails (¬**heads). There are two actions that can be performed. The flip action changes the** coin to show heads or tails with a 50% probability. The tilt action changes it with 10% probability, otherwise leaving it as it is. The initial state is tails. We get a reward of 5.0 for the very first head (this is written heads ∧ ¬ ⊖ ♦- **heads in PLTL) and a reward of 1.0 each** time we achieve the sequence heads, heads, tails (⊖2heads ∧ ⊖heads ∧ ¬**heads in PLTL). In** our input language, this NMRDP is described as shown in Figure 8."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3431,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3432,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3433,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3434,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3435,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3436,
        askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3437 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For instance, consider a simple example consisting of a coin **showing either heads or** tails (¬**heads)."@en ;
    askg-onto:inSentence "For instance, consider a simple example consisting of a coin **showing either heads or** tails (¬**heads)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coin,
        askg-data:Entity-heads,
        askg-data:Entity-tails .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "There are two actions that can be performed."@en ;
    askg-onto:inSentence "There are two actions that can be performed."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions,
        askg-data:Entity-two .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The flip action changes the** coin to show heads or tails with a 50% probability."@en ;
    askg-onto:inSentence "The flip action changes the** coin to show heads or tails with a 50% probability."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-50,
        askg-data:Entity-coin,
        askg-data:Entity-heads_or_tails,
        askg-data:Entity-probability .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The tilt action changes it with 10% probability, otherwise leaving it as it is."@en ;
    askg-onto:inSentence "The tilt action changes it with 10% probability, otherwise leaving it as it is."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10_probability,
        askg-data:Entity-tilt_action .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3435 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The initial state is tails."@en ;
    askg-onto:inSentence "The initial state is tails."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_state,
        askg-data:Entity-tails .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3436 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We get a reward of 5.0 for the very first head (this is written heads ∧ ¬ ⊖ ♦- **heads in PLTL) and a reward of 1.0 each** time we achieve the sequence heads, heads, tails (⊖2heads ∧ ⊖heads ∧ ¬**heads in PLTL)."@en ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-34-Paragraph-343-Sentence-3437 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In** our input language, this NMRDP is described as shown in Figure 8."@en ;
    askg-onto:inSentence "In** our input language, this NMRDP is described as shown in Figure 8."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_8,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-35 a askg-onto:Section ;
    rdfs:label "Section 35"@en ;
    domo:Text "4.2 Common Framework"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-351,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3510,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3511,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-354,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-355,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-356,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-357,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-358,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-359 ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-351 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The common framework underlying nmrdpp **takes advantage of the fact that NMRDP** solution methods can, in general, be divided into the distinct phases of preprocessing, expansion, and solving. The first two are optional."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-351-Sentence-3511,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-351-Sentence-3512 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-351-Sentence-3511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The common framework underlying nmrdpp **takes advantage of the fact that NMRDP** solution methods can, in general, be divided into the distinct phases of preprocessing, expansion, and solving."@en ;
    askg-onto:inSentence "The common framework underlying nmrdpp **takes advantage of the fact that NMRDP** solution methods can, in general, be divided into the distinct phases of preprocessing, expansion, and solving."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-distinct_phases,
        askg-data:Entity-nmrdp_solution_methods,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-preprocessing_expansion_and_solving .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-351-Sentence-3512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The first two are optional."@en ;
    askg-onto:inSentence "The first two are optional."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_two,
        askg-data:Entity-optional .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3510 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "> iterationCount **report number of iterations** 1277 > getPolicy **output policy (textual)** ..."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3510-Sentence-35101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3510-Sentence-35101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "> iterationCount **report number of iterations** 1277 > getPolicy **output policy (textual)** ..."@en ;
    askg-onto:inSentence "> iterationCount **report number of iterations** 1277 > getPolicy **output policy (textual)** ..."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1277,
        askg-data:Entity-getpolicy,
        askg-data:Entity-iterationcount,
        askg-data:Entity-textual .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3511 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "> displayDot(valueToDot) **display ADD of value function** > expand **completely expand MDP** > valIt(0.99, 0.0001) solve MDP with VI(**β, ǫ**) Figure 9: Sample Session"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3511-Sentence-35111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-3511-Sentence-35111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "> displayDot(valueToDot) **display ADD of value function** > expand **completely expand MDP** > valIt(0.99, 0.0001) solve MDP with VI(**β, ǫ**) Figure 9: Sample Session"@en ;
    askg-onto:inSentence "> displayDot(valueToDot) **display ADD of value function** > expand **completely expand MDP** > valIt(0.99, 0.0001) solve MDP with VI(**β, ǫ**) Figure 9: Sample Session"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-display_add_of_value_function,
        askg-data:Entity-expand,
        askg-data:Entity-function,
        askg-data:Entity-mdp,
        askg-data:Entity-valit099_00001,
        askg-data:Entity-valuetodot,
        askg-data:Entity-vi%CE%B2_%C7%AB .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For pltlsim, preprocessing simply computes the set Sub(F**) of subformulae of the reward** formulae. For pltlmin, it also includes computing the labels l(s) for each state s**. For** pltlstr, preprocessing involves computing the set T **of temporal variables as well as the** ADDs for their dynamics and for the rewards. fltl **does not require any preprocessing.** Expansion **is the optional generation of the entire equivalent MDP prior to solving.** Whether or not off-line expansion is sensible depends on the MDP solution method used. If state-based value or policy iteration is used, then the MDP needs to be expanded anyway. If, on the other hand, an anytime search algorithm or structured method is used, it is definitely a bad idea. In our experiments, we often used expansion solely for the purpose of measuring the size of the generated MDP."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3521,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3522,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3523,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3524,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3525,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3526,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3527 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For pltlsim, preprocessing simply computes the set Sub(F**) of subformulae of the reward** formulae."@en ;
    askg-onto:inSentence "For pltlsim, preprocessing simply computes the set Sub(F**) of subformulae of the reward** formulae."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula,
        askg-data:Entity-pltlsim,
        askg-data:Entity-reward_formulae,
        askg-data:Entity-set_of_subformulae,
        askg-data:Entity-subf,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For pltlmin, it also includes computing the labels l(s) for each state s**."@en ;
    askg-onto:inSentence "For pltlmin, it also includes computing the labels l(s) for each state s**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computing_the_labels_ls_for_each_state_s,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For** pltlstr, preprocessing involves computing the set T **of temporal variables as well as the** ADDs for their dynamics and for the rewards."@en ;
    askg-onto:inSentence "For** pltlstr, preprocessing involves computing the set T **of temporal variables as well as the** ADDs for their dynamics and for the rewards."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-set_t_of_temporal_variables,
        askg-data:Entity-the_dynamics_and_for_the_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "fltl **does not require any preprocessing.** Expansion **is the optional generation of the entire equivalent MDP prior to solving.** Whether or not off-line expansion is sensible depends on the MDP solution method used."@en ;
    askg-onto:inSentence "fltl **does not require any preprocessing.** Expansion **is the optional generation of the entire equivalent MDP prior to solving.** Whether or not off-line expansion is sensible depends on the MDP solution method used."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equivalent_mdp,
        askg-data:Entity-expansion,
        askg-data:Entity-fltl,
        askg-data:Entity-mdp_solution_method,
        askg-data:Entity-off-line_expansion,
        askg-data:Entity-preprocessing .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "If state-based value or policy iteration is used, then the MDP needs to be expanded anyway."@en ;
    askg-onto:inSentence "If state-based value or policy iteration is used, then the MDP needs to be expanded anyway."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anyway,
        askg-data:Entity-mdp,
        askg-data:Entity-state-based_value_or_policy_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3526 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "If, on the other hand, an anytime search algorithm or structured method is used, it is definitely a bad idea."@en ;
    askg-onto:inSentence "If, on the other hand, an anytime search algorithm or structured method is used, it is definitely a bad idea."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_search_algorithm,
        askg-data:Entity-method,
        askg-data:Entity-search_algorithm,
        askg-data:Entity-structured_method .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-352-Sentence-3527 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In our experiments, we often used expansion solely for the purpose of measuring the size of the generated MDP."@en ;
    askg-onto:inSentence "In our experiments, we often used expansion solely for the purpose of measuring the size of the generated MDP."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expansion,
        askg-data:Entity-experiments,
        askg-data:Entity-mdp,
        askg-data:Entity-measuring_the_size_of_the_generated_mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Solving the MDP can be done using a number of methods. Currently, nmrdpp **provides** implementations of classical dynamic programming methods, namely state-based value and policy iteration (Howard, 1960), of heuristic search methods: state-based LAO* (Hansen & Zilberstein, 2001) using either value or policy iteration as a subroutine, and of one structured method, namely SPUDD (Hoey et al., 1999). Prime candidates for future developments are (L)RTDP (Bonet & Geffner, 2003), symbolic LAO* (Feng & Hansen, 2002), and symbolic RTDP (Feng et al., 2003)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353-Sentence-3531,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353-Sentence-3532,
        askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353-Sentence-3533 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353-Sentence-3531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Solving the MDP can be done using a number of methods."@en ;
    askg-onto:inSentence "Solving the MDP can be done using a number of methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-methods .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353-Sentence-3532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Currently, nmrdpp **provides** implementations of classical dynamic programming methods, namely state-based value and policy iteration (Howard, 1960), of heuristic search methods: state-based LAO* (Hansen & Zilberstein, 2001) using either value or policy iteration as a subroutine, and of one structured method, namely SPUDD (Hoey et al., 1999)."@en ;
    askg-onto:inSentence "Currently, nmrdpp **provides** implementations of classical dynamic programming methods, namely state-based value and policy iteration (Howard, 1960), of heuristic search methods: state-based LAO* (Hansen & Zilberstein, 2001) using either value or policy iteration as a subroutine, and of one structured method, namely SPUDD (Hoey et al., 1999)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_programming,
        askg-data:Entity-heuristic_search_methods,
        askg-data:Entity-implementations_of_classical_dynamic_programming_methods,
        askg-data:Entity-lao,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-spudd,
        askg-data:Entity-state-based_value_and_policy_iteration,
        askg-data:Entity-structured_method,
        askg-data:Entity-value_or_policy_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-353-Sentence-3533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Prime candidates for future developments are (L)RTDP (Bonet & Geffner, 2003), symbolic LAO* (Feng & Hansen, 2002), and symbolic RTDP (Feng et al., 2003)."@en ;
    askg-onto:inSentence "Prime candidates for future developments are (L)RTDP (Bonet & Geffner, 2003), symbolic LAO* (Feng & Hansen, 2002), and symbolic RTDP (Feng et al., 2003)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-bonet__geffner_2003,
        askg-data:Entity-feng__hansen_2002,
        askg-data:Entity-feng_et_al_2003,
        askg-data:Entity-lrtdp,
        askg-data:Entity-paper,
        askg-data:Entity-symbolic_lao,
        askg-data:Entity-symbolic_rtdp .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-354 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "> loadWorld('coin') **load coin NMRDP** > preprocess('sPltl') pltlstr **preprocessing** > startCPUtimer > spudd(0.99, 0.0001) solve MDP with SPUDD(**β, ǫ**) > stopCPUtimer > readCPUtimer **report solving time** 1.22000 > iterationCount **report number of iterations** 1277"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-354-Sentence-3541 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-354-Sentence-3541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "> loadWorld('coin') **load coin NMRDP** > preprocess('sPltl') pltlstr **preprocessing** > startCPUtimer > spudd(0.99, 0.0001) solve MDP with SPUDD(**β, ǫ**) > stopCPUtimer > readCPUtimer **report solving time** 1.22000 > iterationCount **report number of iterations** 1277"@en ;
    askg-onto:inSentence "> loadWorld('coin') **load coin NMRDP** > preprocess('sPltl') pltlstr **preprocessing** > startCPUtimer > spudd(0.99, 0.0001) solve MDP with SPUDD(**β, ǫ**) > stopCPUtimer > readCPUtimer **report solving time** 1.22000 > iterationCount **report number of iterations** 1277"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-122000,
        askg-data:Entity-1277,
        askg-data:Entity-coin,
        askg-data:Entity-iterationcount,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-pltlstr,
        askg-data:Entity-report_solving_time,
        askg-data:Entity-spltl,
        askg-data:Entity-spudd .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-355 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![28_image_0.png](28_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-355-Sentence-3551 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-355-Sentence-3551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![28_image_0.png](28_image_0.png)"@en ;
    askg-onto:inSentence "![28_image_0.png](28_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-clinical_trials,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-covid-19,
        askg-data:Entity-data_science,
        askg-data:Entity-deep_learning,
        askg-data:Entity-disease,
        askg-data:Entity-healthcare,
        askg-data:Entity-kaggle,
        askg-data:Entity-machine_learning,
        askg-data:Entity-medical_imaging,
        askg-data:Entity-medical_research,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-pytorch,
        askg-data:Entity-software,
        askg-data:Entity-tensorflow .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-356 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "> displayDot(policyToDot) **display policy**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-356-Sentence-3561 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-356-Sentence-3561 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "> displayDot(policyToDot) **display policy**"@en ;
    askg-onto:inSentence "> displayDot(policyToDot) **display policy**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-policy,
        askg-data:Entity-policytodot .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-357 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "![28_image_1.png](28_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-357-Sentence-3571 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-357-Sentence-3571 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![28_image_1.png](28_image_1.png)"@en ;
    askg-onto:inSentence "![28_image_1.png](28_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_vision,
        askg-data:Entity-deep_learning,
        askg-data:Entity-google,
        askg-data:Entity-image_recognition,
        askg-data:Entity-machine_learning,
        askg-data:Entity-machine_learning_framework,
        askg-data:Entity-neural_networks,
        askg-data:Entity-tech_companies,
        askg-data:Entity-tensorflow .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-358 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "> preprocess('mPltl') pltlmin **preprocessing** > domainStateSize **report MDP size** 6 > printDomain (\"\") | 'show-domain.rb' **display postcript rendering of MDP**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-358-Sentence-3581 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-358-Sentence-3581 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "> preprocess('mPltl') pltlmin **preprocessing** > domainStateSize **report MDP size** 6 > printDomain (\"\") | 'show-domain.rb' **display postcript rendering of MDP**"@en ;
    askg-onto:inSentence "> preprocess('mPltl') pltlmin **preprocessing** > domainStateSize **report MDP size** 6 > printDomain (\"\") | 'show-domain.rb' **display postcript rendering of MDP**"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6,
        askg-data:Entity-domainstatesize,
        askg-data:Entity-mpltl,
        askg-data:Entity-pltlmin,
        askg-data:Entity-postcript_rendering_of_mdp,
        askg-data:Entity-show-domainrb .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-359 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "![28_image_2.png](28_image_2.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-359-Sentence-3591 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-35-Paragraph-359-Sentence-3591 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![28_image_2.png](28_image_2.png)"@en ;
    askg-onto:inSentence "![28_image_2.png](28_image_2.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-biological_research,
        askg-data:Entity-crispr,
        askg-data:Entity-crispr-cas9,
        askg-data:Entity-gene_editing,
        askg-data:Entity-genetic_analysis,
        askg-data:Entity-genetic_engineering,
        askg-data:Entity-genetic_research,
        askg-data:Entity-genetics,
        askg-data:Entity-genome_sequencing,
        askg-data:Entity-journal_of_genetic_engineering__biotechnology,
        askg-data:Entity-mendelian_genetics,
        askg-data:Entity-nature .

askg-data:Paper-c253584c3f1ff2a2-Section-36 a askg-onto:Section ;
    rdfs:label "Section 36"@en ;
    domo:Text "4.3 Approaches Covered"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362 ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Altogether, the various types of preprocessing, the choice **of whether to expand, and the** MDP solution methods, give rise to quite a number of NMRDP approaches, including, but not limited to those previously mentioned (see e.g. pltlstr(a) below). Not all combinations are possible. E.g., state-based processing variants **are incompatible with structured** solution methods (the converse is possible in principle, however). Also, there is at present no structured form of preprocessing for $FLTL formulae."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3611,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3612,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3613,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3614,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3615 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Altogether, the various types of preprocessing, the choice **of whether to expand, and the** MDP solution methods, give rise to quite a number of NMRDP approaches, including, but not limited to those previously mentioned (see e.g."@en ;
    askg-onto:inSentence "Altogether, the various types of preprocessing, the choice **of whether to expand, and the** MDP solution methods, give rise to quite a number of NMRDP approaches, including, but not limited to those previously mentioned (see e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_solution_methods,
        askg-data:Entity-nmrdp_approaches,
        askg-data:Entity-preprocessing .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "pltlstr(a) below)."@en ;
    askg-onto:inSentence "pltlstr(a) below)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstra,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Not all combinations are possible."@en ;
    askg-onto:inSentence "Not all combinations are possible."^^xsd:string ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "E.g., state-based processing variants **are incompatible with structured** solution methods (the converse is possible in principle, however)."@en ;
    askg-onto:inSentence "E.g., state-based processing variants **are incompatible with structured** solution methods (the converse is possible in principle, however)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-state-based_processing_variants,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-361-Sentence-3615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Also, there is at present no structured form of preprocessing for $FLTL formulae."@en ;
    askg-onto:inSentence "Also, there is at present no structured form of preprocessing for $FLTL formulae."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_formulae,
        askg-data:Entity-structured_form_of_preprocessing .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "pltlstr(a) is an example of an interesting variant of pltlstr**, which we obtain by** considering additional preprocessing, whereby the state space is explored (without explicitly enumerating it) to produce a BDD representation of the e-states reachable from the start state. This is done by starting with a BDD representing the start e-state, and repeatedly applying each action. Non-zero probabilities are converted to ones and the result \"or-ed\" with the last result. When no action adds any reachable e-states to this BDD, we can be sure it represents the reachable e-state space. This is then used as additional control knowledge to restrict the search. It should be noted that without this phase pltlstr **makes** no assumptions about the start state, and thus is left at a possible disadvantage. Similar structured reachability analysis techniques have been used in the symbolic implementation of LAO* (Feng & Hansen, 2002). However, an important aspect of what we do here is that temporal variables are also included in the BDD."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3621,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3622,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3623,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3624,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3625,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3626,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3627,
        askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3628 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "pltlstr(a) is an example of an interesting variant of pltlstr**, which we obtain by** considering additional preprocessing, whereby the state space is explored (without explicitly enumerating it) to produce a BDD representation of the e-states reachable from the start state."@en ;
    askg-onto:inSentence "pltlstr(a) is an example of an interesting variant of pltlstr**, which we obtain by** considering additional preprocessing, whereby the state space is explored (without explicitly enumerating it) to produce a BDD representation of the e-states reachable from the start state."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bdd_representation,
        askg-data:Entity-e-states,
        askg-data:Entity-pltlstr,
        askg-data:Entity-pltlstra,
        askg-data:Entity-start_state,
        askg-data:Entity-state_space .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This is done by starting with a BDD representing the start e-state, and repeatedly applying each action."@en ;
    askg-onto:inSentence "This is done by starting with a BDD representing the start e-state, and repeatedly applying each action."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bdd,
        askg-data:Entity-start_e-state .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Non-zero probabilities are converted to ones and the result \"or-ed\" with the last result."@en ;
    askg-onto:inSentence "Non-zero probabilities are converted to ones and the result \"or-ed\" with the last result."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-last_result,
        askg-data:Entity-non-zero_probabilities,
        askg-data:Entity-ones,
        askg-data:Entity-result .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3624 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "When no action adds any reachable e-states to this BDD, we can be sure it represents the reachable e-state space."@en ;
    askg-onto:inSentence "When no action adds any reachable e-states to this BDD, we can be sure it represents the reachable e-state space."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bdd,
        askg-data:Entity-reachable_e-state_space .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3625 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This is then used as additional control knowledge to restrict the search."@en ;
    askg-onto:inSentence "This is then used as additional control knowledge to restrict the search."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control_knowledge,
        askg-data:Entity-search .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3626 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "It should be noted that without this phase pltlstr **makes** no assumptions about the start state, and thus is left at a possible disadvantage."@en ;
    askg-onto:inSentence "It should be noted that without this phase pltlstr **makes** no assumptions about the start state, and thus is left at a possible disadvantage."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-no_assumptions,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3627 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Similar structured reachability analysis techniques have been used in the symbolic implementation of LAO* (Feng & Hansen, 2002)."@en ;
    askg-onto:inSentence "Similar structured reachability analysis techniques have been used in the symbolic implementation of LAO* (Feng & Hansen, 2002)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feng__hansen_2002,
        askg-data:Entity-lao,
        askg-data:Entity-symbolic_implementation .

askg-data:Paper-c253584c3f1ff2a2-Section-36-Paragraph-362-Sentence-3628 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "However, an important aspect of what we do here is that temporal variables are also included in the BDD."@en ;
    askg-onto:inSentence "However, an important aspect of what we do here is that temporal variables are also included in the BDD."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bdd,
        askg-data:Entity-temporal_variables .

askg-data:Paper-c253584c3f1ff2a2-Section-37 a askg-onto:Section ;
    rdfs:label "Section 37"@en ;
    domo:Text "4.4 The Nmrdpp **System**"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371 ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "nmrdpp is controlled by a command language, which is read either from a file or interactively. The command language provides commands for the different phases (preprocessing, expansion, solution) of the methods, commands to inspect the resulting policy and value functions, e.g. with rendering via DOT (AT&T Labs-Research, 2000), as well as supporting commands for timing and memory usage. A sample session, where the coin NMRDP is successively solved with pltlstr and pltlmin **is shown in Figure 9.** nmrdpp is implemented in C++, and makes use of a number of supporting **libraries.** In particular, it relies heavily on the CUDD package for manipulating ADDs (Somenzi, 2001): action specification trees are converted into and stored as ADDs by the system, and moreover the structured algorithms rely heavily on CUDD **for ADD computations.** The state-based algorithms make use of the MTL - Matrix Template Library for matrix operations. MTL takes advantage of modern processor features such as MMX and SSE and provides efficient sparse matrix operations. We believe that our implementations of MDP solution methods are comparable with the state of the art. For instance, we found that our implementation of SPUDD is comparable in performance (within a factor of 2) to the reference implementation (Hoey et al., 1999). On the other hand, we believe that data structures used for regression and progression of temporal **formulae could be optimised.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3711,
        askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3712,
        askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3713,
        askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3714,
        askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3715,
        askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3716,
        askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3717,
        askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3718 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "nmrdpp is controlled by a command language, which is read either from a file or interactively."@en ;
    askg-onto:inSentence "nmrdpp is controlled by a command language, which is read either from a file or interactively."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-command_language,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The command language provides commands for the different phases (preprocessing, expansion, solution) of the methods, commands to inspect the resulting policy and value functions, e.g."@en ;
    askg-onto:inSentence "The command language provides commands for the different phases (preprocessing, expansion, solution) of the methods, commands to inspect the resulting policy and value functions, e.g."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-command_language,
        askg-data:Entity-different_phases,
        askg-data:Entity-resulting_policy_and_value_functions .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "with rendering via DOT (AT&T Labs-Research, 2000), as well as supporting commands for timing and memory usage."@en ;
    askg-onto:inSentence "with rendering via DOT (AT&T Labs-Research, 2000), as well as supporting commands for timing and memory usage."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-att_labs-research,
        askg-data:Entity-dot,
        askg-data:Entity-timing_and_memory_usage .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "A sample session, where the coin NMRDP is successively solved with pltlstr and pltlmin **is shown in Figure 9.** nmrdpp is implemented in C++, and makes use of a number of supporting **libraries.** In particular, it relies heavily on the CUDD package for manipulating ADDs (Somenzi, 2001): action specification trees are converted into and stored as ADDs by the system, and moreover the structured algorithms rely heavily on CUDD **for ADD computations.** The state-based algorithms make use of the MTL - Matrix Template Library for matrix operations."@en ;
    askg-onto:inSentence "A sample session, where the coin NMRDP is successively solved with pltlstr and pltlmin **is shown in Figure 9.** nmrdpp is implemented in C++, and makes use of a number of supporting **libraries.** In particular, it relies heavily on the CUDD package for manipulating ADDs (Somenzi, 2001): action specification trees are converted into and stored as ADDs by the system, and moreover the structured algorithms rely heavily on CUDD **for ADD computations.** The state-based algorithms make use of the MTL - Matrix Template Library for matrix operations."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_specification_trees,
        askg-data:Entity-adds,
        askg-data:Entity-c,
        askg-data:Entity-cudd,
        askg-data:Entity-libraries,
        askg-data:Entity-manipulating_adds,
        askg-data:Entity-matrix_operations,
        askg-data:Entity-mtl,
        askg-data:Entity-nmrdp,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-state-based_algorithms,
        askg-data:Entity-structured_algorithms .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "MTL takes advantage of modern processor features such as MMX and SSE and provides efficient sparse matrix operations."@en ;
    askg-onto:inSentence "MTL takes advantage of modern processor features such as MMX and SSE and provides efficient sparse matrix operations."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-efficient_sparse_matrix_operations,
        askg-data:Entity-mmx,
        askg-data:Entity-modern_processor_features,
        askg-data:Entity-mtl,
        askg-data:Entity-sse .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3716 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "We believe that our implementations of MDP solution methods are comparable with the state of the art."@en ;
    askg-onto:inSentence "We believe that our implementations of MDP solution methods are comparable with the state of the art."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_solution_methods,
        askg-data:Entity-the_state_of_the_art .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3717 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "For instance, we found that our implementation of SPUDD is comparable in performance (within a factor of 2) to the reference implementation (Hoey et al., 1999)."@en ;
    askg-onto:inSentence "For instance, we found that our implementation of SPUDD is comparable in performance (within a factor of 2) to the reference implementation (Hoey et al., 1999)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hoey_et_al_1999,
        askg-data:Entity-reference_implementation,
        askg-data:Entity-spudd .

askg-data:Paper-c253584c3f1ff2a2-Section-37-Paragraph-371-Sentence-3718 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "On the other hand, we believe that data structures used for regression and progression of temporal **formulae could be optimised.**"@en ;
    askg-onto:inSentence "On the other hand, we believe that data structures used for regression and progression of temporal **formulae could be optimised.**"^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_structures,
        askg-data:Entity-optimised,
        askg-data:Entity-regression_and_progression_of_temporal_formulae,
        askg-data:Entity-temporal_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-38 a askg-onto:Section ;
    rdfs:label "Section 38"@en ;
    domo:Text "5. Experimental Analysis"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-382,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-384 ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We are faced with three substantially different approaches that are not easy to compare, as their performance will depend on domain features as varied as the structure in the transition model, the type, syntax, and length of the temporal reward formula, the presence of rewards unreachable or irrelevant to the optimal policy, **the availability of good heuristics** and control-knowledge, etc, and on the interactions between these factors. In this section, we report an experimental investigation into the influence of some of these factors and try to answer the questions raised previously:10 1. is the dynamics of the domain the predominant factor affecting performance? 2. is the type of reward a major factor? 3. is the syntax used to describe rewards a major factor? 4. is there an overall best method?"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3811,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3812,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3813,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3814,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3815,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3816,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3817,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3818,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3819 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We are faced with three substantially different approaches that are not easy to compare, as their performance will depend on domain features as varied as the structure in the transition model, the type, syntax, and length of the temporal reward formula, the presence of rewards unreachable or irrelevant to the optimal policy, **the availability of good heuristics** and control-knowledge, etc, and on the interactions between these factors."@en ;
    askg-onto:inSentence "We are faced with three substantially different approaches that are not easy to compare, as their performance will depend on domain features as varied as the structure in the transition model, the type, syntax, and length of the temporal reward formula, the presence of rewards unreachable or irrelevant to the optimal policy, **the availability of good heuristics** and control-knowledge, etc, and on the interactions between these factors."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-availability_of_good_heuristics,
        askg-data:Entity-performance,
        askg-data:Entity-presence_of_rewards_unreachable_or_irrelevant_to_the_optimal_policy,
        askg-data:Entity-structure_in_the_transition_model,
        askg-data:Entity-type_syntax_and_length_of_the_temporal_reward_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In this section, we report an experimental investigation into the influence of some of these factors and try to answer the questions raised previously:10 1."@en ;
    askg-onto:inSentence "In this section, we report an experimental investigation into the influence of some of these factors and try to answer the questions raised previously:10 1."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experimental_investigation,
        askg-data:Entity-influence_of_factors .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "is the dynamics of the domain the predominant factor affecting performance?"@en ;
    askg-onto:inSentence "is the dynamics of the domain the predominant factor affecting performance?"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamics_of_the_domain,
        askg-data:Entity-performance .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "2."@en ;
    askg-onto:inSentence "2."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-person,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-research_group,
        askg-data:Entity-study,
        askg-data:Entity-system,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "is the type of reward a major factor?"@en ;
    askg-onto:inSentence "is the type of reward a major factor?"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-factor,
        askg-data:Entity-type_of_reward .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3816 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "3."@en ;
    askg-onto:inSentence "3."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3817 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "is the syntax used to describe rewards a major factor?"@en ;
    askg-onto:inSentence "is the syntax used to describe rewards a major factor?"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rewards,
        askg-data:Entity-syntax .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3818 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "4."@en ;
    askg-onto:inSentence "4."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning_paper,
        askg-data:Entity-github,
        askg-data:Entity-imagenet,
        askg-data:Entity-john_doe,
        askg-data:Entity-machine_learning,
        askg-data:Entity-model,
        askg-data:Entity-random_forest,
        askg-data:Entity-software_development .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-381-Sentence-3819 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "is there an overall best method?"@en ;
    askg-onto:inSentence "is there an overall best method?"^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-overall_best_method .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-382 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "5. is there an overall worst method?"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-382-Sentence-3821,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-382-Sentence-3822 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-382-Sentence-3821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "5."@en ;
    askg-onto:inSentence "5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-analyze,
        askg-data:Entity-author,
        askg-data:Entity-data,
        askg-data:Entity-dataset,
        askg-data:Entity-field,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-paper,
        askg-data:Entity-person,
        askg-data:Entity-publication,
        askg-data:Entity-research,
        askg-data:Entity-study,
        askg-data:Entity-tool,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-382-Sentence-3822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "is there an overall worst method?"@en ;
    askg-onto:inSentence "is there an overall worst method?"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-overall_worst_method .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "6. does the preprocessing phase of pltlmin pay, compared to **pltlsim**? 7. does the simplicity of the fltl **translation compensate for blind-minimality, or does** the benefit of true minimality outweigh the cost of pltlmin **preprocessing?** 8. are the dynamic analyses of rewards in pltlstr and fltl **effective?** 9. is one of these analyses more powerful, or are they rather complementary?"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3831,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3832,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3833,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3834,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3835,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3836 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "6."@en ;
    askg-onto:inSentence "6."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3832 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "does the preprocessing phase of pltlmin pay, compared to **pltlsim**?"@en ;
    askg-onto:inSentence "does the preprocessing phase of pltlmin pay, compared to **pltlsim**?"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3833 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "7."@en ;
    askg-onto:inSentence "7."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-triple_1,
        askg-data:Entity-triple_2,
        askg-data:Entity-triple_3,
        askg-data:Entity-triple_4,
        askg-data:Entity-triple_5,
        askg-data:Entity-triple_6,
        askg-data:Entity-triple_7,
        askg-data:Entity-triple_8,
        askg-data:Entity-triple_9,
        askg-data:Entity-university_x .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3834 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "does the simplicity of the fltl **translation compensate for blind-minimality, or does** the benefit of true minimality outweigh the cost of pltlmin **preprocessing?** 8."@en ;
    askg-onto:inSentence "does the simplicity of the fltl **translation compensate for blind-minimality, or does** the benefit of true minimality outweigh the cost of pltlmin **preprocessing?** 8."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind-minimality,
        askg-data:Entity-fltl_translation,
        askg-data:Entity-pltlmin_preprocessing,
        askg-data:Entity-true_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3835 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "are the dynamic analyses of rewards in pltlstr and fltl **effective?** 9."@en ;
    askg-onto:inSentence "are the dynamic analyses of rewards in pltlstr and fltl **effective?** 9."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_analyses_of_rewards,
        askg-data:Entity-effective .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-383-Sentence-3836 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "is one of these analyses more powerful, or are they rather complementary?"@en ;
    askg-onto:inSentence "is one of these analyses more powerful, or are they rather complementary?"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analyses,
        askg-data:Entity-complementary .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-384 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "In some cases but not all, we were able to identify systematic **patterns. The results in this** section were obtained using a Pentium4 2.6GHz GNU/Linux 2.4.20 machine with 500MB of ram."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-384-Sentence-3841,
        askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-384-Sentence-3842 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-384-Sentence-3841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In some cases but not all, we were able to identify systematic **patterns."@en ;
    askg-onto:inSentence "In some cases but not all, we were able to identify systematic **patterns."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-patterns,
        askg-data:Entity-systematic .

askg-data:Paper-c253584c3f1ff2a2-Section-38-Paragraph-384-Sentence-3842 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The results in this** section were obtained using a Pentium4 2.6GHz GNU/Linux 2.4.20 machine with 500MB of ram."@en ;
    askg-onto:inSentence "The results in this** section were obtained using a Pentium4 2.6GHz GNU/Linux 2.4.20 machine with 500MB of ram."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-500mb_of_ram,
        askg-data:Entity-condition,
        askg-data:Entity-gnulinux_2420,
        askg-data:Entity-operating_system,
        askg-data:Entity-pentium4_26ghz,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-39 a askg-onto:Section ;
    rdfs:label "Section 39"@en ;
    domo:Text "5.1 Preliminary Remarks"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393 ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Clearly, fltl and pltlstr(a) have great potential for exploiting domain-specific heuristics and control-knowledge; pltlmin **less so. To avoid obscuring the results, we therefore** refrained from incorporating these features in the experiments. When running LAO*, the heuristic value of a state was the crudest possible (the sum of all reward values in the problem). Performance results should be interpreted in this light - they do not necessarily reflect the practical abilities of the methods that are able to exploit these features."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3911,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3912,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3913,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3914 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Clearly, fltl and pltlstr(a) have great potential for exploiting domain-specific heuristics and control-knowledge; pltlmin **less so."@en ;
    askg-onto:inSentence "Clearly, fltl and pltlstr(a) have great potential for exploiting domain-specific heuristics and control-knowledge; pltlmin **less so."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control-knowledge,
        askg-data:Entity-domain-specific_heuristics,
        askg-data:Entity-fltl,
        askg-data:Entity-less,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstra .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To avoid obscuring the results, we therefore** refrained from incorporating these features in the experiments."@en ;
    askg-onto:inSentence "To avoid obscuring the results, we therefore** refrained from incorporating these features in the experiments."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-features .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "When running LAO*, the heuristic value of a state was the crudest possible (the sum of all reward values in the problem)."@en ;
    askg-onto:inSentence "When running LAO*, the heuristic value of a state was the crudest possible (the sum of all reward values in the problem)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition,
        askg-data:Entity-heuristic_value,
        askg-data:Entity-lao,
        askg-data:Entity-metric,
        askg-data:Entity-reward_values,
        askg-data:Entity-state,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-391-Sentence-3914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Performance results should be interpreted in this light - they do not necessarily reflect the practical abilities of the methods that are able to exploit these features."@en ;
    askg-onto:inSentence "Performance results should be interpreted in this light - they do not necessarily reflect the practical abilities of the methods that are able to exploit these features."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-performance_results,
        askg-data:Entity-practical_abilities_of_the_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We begin with some general observations. One question raised above was whether the gain during the PLTL expansion phase is worth the expensive preprocessing performed by pltlmin, i.e. whether pltlmin typically outperforms pltlsim**. We can definitively answer** this question: up to pathological exceptions, preprocessing pays. We found that expansion was the bottleneck, and that post-hoc minimisation of the MDP produced by pltlsim did not help much. pltlsim **is therefore of little or no practical interest, and we decided not to** report results on its performance, as it is often an order of magnitude worse than that of pltlmin. Unsurprisingly, we also found that pltlstr **would typically scale to larger state** spaces, inevitably leading it to outperform state-based methods. However, this effect is not uniform: structured solution methods sometimes impose excessive memory requirements which makes them uncompetitive in certain cases, for example where ⊖nf**, for large** n, features as a reward formula."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3921,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3922,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3923,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3924,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3925,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3926,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3927,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3928 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We begin with some general observations."@en ;
    askg-onto:inSentence "We begin with some general observations."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-general_observations,
        askg-data:Entity-some .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "One question raised above was whether the gain during the PLTL expansion phase is worth the expensive preprocessing performed by pltlmin, i.e."@en ;
    askg-onto:inSentence "One question raised above was whether the gain during the PLTL expansion phase is worth the expensive preprocessing performed by pltlmin, i.e."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expensive_preprocessing,
        askg-data:Entity-pltl_expansion_phase,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "whether pltlmin typically outperforms pltlsim**."@en ;
    askg-onto:inSentence "whether pltlmin typically outperforms pltlsim**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3924 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We can definitively answer** this question: up to pathological exceptions, preprocessing pays."@en ;
    askg-onto:inSentence "We can definitively answer** this question: up to pathological exceptions, preprocessing pays."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-preprocessing,
        askg-data:Entity-question .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3925 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We found that expansion was the bottleneck, and that post-hoc minimisation of the MDP produced by pltlsim did not help much."@en ;
    askg-onto:inSentence "We found that expansion was the bottleneck, and that post-hoc minimisation of the MDP produced by pltlsim did not help much."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expansion,
        askg-data:Entity-mdp,
        askg-data:Entity-pltlsim,
        askg-data:Entity-post-hoc_minimisation_of_the_mdp,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3926 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "pltlsim **is therefore of little or no practical interest, and we decided not to** report results on its performance, as it is often an order of magnitude worse than that of pltlmin."@en ;
    askg-onto:inSentence "pltlsim **is therefore of little or no practical interest, and we decided not to** report results on its performance, as it is often an order of magnitude worse than that of pltlmin."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-performance,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3927 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Unsurprisingly, we also found that pltlstr **would typically scale to larger state** spaces, inevitably leading it to outperform state-based methods."@en ;
    askg-onto:inSentence "Unsurprisingly, we also found that pltlstr **would typically scale to larger state** spaces, inevitably leading it to outperform state-based methods."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-larger_state_spaces,
        askg-data:Entity-pltlstr,
        askg-data:Entity-state-based_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-392-Sentence-3928 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "However, this effect is not uniform: structured solution methods sometimes impose excessive memory requirements which makes them uncompetitive in certain cases, for example where ⊖nf**, for large** n, features as a reward formula."@en ;
    askg-onto:inSentence "However, this effect is not uniform: structured solution methods sometimes impose excessive memory requirements which makes them uncompetitive in certain cases, for example where ⊖nf**, for large** n, features as a reward formula."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-excessive_memory_requirements,
        askg-data:Entity-nf,
        askg-data:Entity-reward_formula,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "10. Here is an executive summary of the answers for the executive reader. 1. no, 2. yes, 3. yes, 4. **pltlstr** and fltl, 5. pltlsim**, 6. yes, 7. yes and no, respectively, 8. yes, 9. no and yes, respectively.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3931,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-39310,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-39311,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-39312,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3932,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3933,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3934,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3935,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3936,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3937,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3938,
        askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3939 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "10."@en ;
    askg-onto:inSentence "10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-study,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-39310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "yes and no, respectively, 8."@en ;
    askg-onto:inSentence "yes and no, respectively, 8."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8,
        askg-data:Entity-yes_and_no .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-39311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "yes, 9."@en ;
    askg-onto:inSentence "yes, 9."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-9,
        askg-data:Entity-yes .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-39312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "no and yes, respectively.**"@en ;
    askg-onto:inSentence "no and yes, respectively.**"^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-no,
        askg-data:Entity-yes .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here is an executive summary of the answers for the executive reader."@en ;
    askg-onto:inSentence "Here is an executive summary of the answers for the executive reader."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-executive_summary .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3933 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "1."@en ;
    askg-onto:inSentence "1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-research_field,
        askg-data:Entity-research_group,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-tool,
        askg-data:Entity-triple,
        askg-data:Entity-university .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3934 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "no, 2."@en ;
    askg-onto:inSentence "no, 2."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2,
        askg-data:Entity-no .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3935 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "yes, 3."@en ;
    askg-onto:inSentence "yes, 3."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3,
        askg-data:Entity-yes .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3936 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "yes, 4."@en ;
    askg-onto:inSentence "yes, 4."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4,
        askg-data:Entity-yes .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3937 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "**pltlstr** and fltl, 5."@en ;
    askg-onto:inSentence "**pltlstr** and fltl, 5."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3938 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "pltlsim**, 6."@en ;
    askg-onto:inSentence "pltlsim**, 6."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6,
        askg-data:Entity-pltlsim .

askg-data:Paper-c253584c3f1ff2a2-Section-39-Paragraph-393-Sentence-3939 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "yes, 7."@en ;
    askg-onto:inSentence "yes, 7."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-7,
        askg-data:Entity-a_number .

askg-data:Paper-c253584c3f1ff2a2-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "1.1 The Problem"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-42,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Markov decision processes (MDPs) are now widely accepted as **the preferred model for** decision-theoretic planning problems (Boutilier, Dean, & **Hanks, 1999). The fundamental** assumption behind the MDP formulation is that not only the system dynamics but also the reward function are Markovian**. Therefore, all information needed to determine the reward** at a given state must be encoded in the state itself."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41-Sentence-413 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Markov decision processes (MDPs) are now widely accepted as **the preferred model for** decision-theoretic planning problems (Boutilier, Dean, & **Hanks, 1999)."@en ;
    askg-onto:inSentence "Markov decision processes (MDPs) are now widely accepted as **the preferred model for** decision-theoretic planning problems (Boutilier, Dean, & **Hanks, 1999)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1999,
        askg-data:Entity-boutilier_dean__hanks,
        askg-data:Entity-decision-theoretic_planning_problems,
        askg-data:Entity-markov_decision_processes_mdps .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The fundamental** assumption behind the MDP formulation is that not only the system dynamics but also the reward function are Markovian**."@en ;
    askg-onto:inSentence "The fundamental** assumption behind the MDP formulation is that not only the system dynamics but also the reward function are Markovian**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-markovian,
        askg-data:Entity-mdp_formulation,
        askg-data:Entity-reward_function,
        askg-data:Entity-system_dynamics .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Therefore, all information needed to determine the reward** at a given state must be encoded in the state itself."@en ;
    askg-onto:inSentence "Therefore, all information needed to determine the reward** at a given state must be encoded in the state itself."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-information,
        askg-data:Entity-reward,
        askg-data:Entity-state,
        askg-data:Entity-state_itself .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "This requirement is not always easy to meet for planning problems, as many desirable behaviours are naturally expressed as properties of execution sequences (see e.g., Drummond, 1989; Haddawy & Hanks, 1992; Bacchus & Kabanza, 1998; Pistore & Traverso, 2001). Typical cases include rewards for the maintenance of **some property, for the periodic** achievement of some goal, for the achievement of a goal within a given number of steps of the request being made, or even simply for the very first achievement of a goal which becomes irrelevant afterwards."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-42-Sentence-421,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-42-Sentence-422 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This requirement is not always easy to meet for planning problems, as many desirable behaviours are naturally expressed as properties of execution sequences (see e.g., Drummond, 1989; Haddawy & Hanks, 1992; Bacchus & Kabanza, 1998; Pistore & Traverso, 2001)."@en ;
    askg-onto:inSentence "This requirement is not always easy to meet for planning problems, as many desirable behaviours are naturally expressed as properties of execution sequences (see e.g., Drummond, 1989; Haddawy & Hanks, 1992; Bacchus & Kabanza, 1998; Pistore & Traverso, 2001)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1989,
        askg-data:Entity-1992,
        askg-data:Entity-1998,
        askg-data:Entity-2001,
        askg-data:Entity-bacchus__kabanza,
        askg-data:Entity-drummond,
        askg-data:Entity-haddawy__hanks,
        askg-data:Entity-pistore__traverso .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-42-Sentence-422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Typical cases include rewards for the maintenance of **some property, for the periodic** achievement of some goal, for the achievement of a goal within a given number of steps of the request being made, or even simply for the very first achievement of a goal which becomes irrelevant afterwards."@en ;
    askg-onto:inSentence "Typical cases include rewards for the maintenance of **some property, for the periodic** achievement of some goal, for the achievement of a goal within a given number of steps of the request being made, or even simply for the very first achievement of a goal which becomes irrelevant afterwards."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievement_of_a_goal_within_a_given_number_of_steps,
        askg-data:Entity-first_achievement_of_a_goal,
        askg-data:Entity-maintenance_of_some_property,
        askg-data:Entity-periodic_achievement_of_some_goal,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "For instance, consider a health care robot which assists ederly or disabled people by achieving simple goals such as reminding them to do important tasks (e.g. taking a pill), entertaining them, checking or transporting objects for them (e.g. checking the stove's temperature or bringing coffee), escorting them, or searching (e.g. for glasses or for the nurse) (Cesta et al., 2003). In this domain, we might want to reward the robot for making sure a given patient takes his pill exactly once every 8 hours **(and penalise it if it fails** to prevent the patient from doing this more than once within this time frame!), we may reward it for repeatedly visiting all rooms in the ward in a given order and reporting any problem it detects, it may also receive a reward once for each **patient's request answered** within the appropriate time-frame, etc. Another example is **the elevator control domain** (Koehler & Schuster, 2000), in which an elevator must get passengers from their origin to their destination as efficiently as possible, while attempting to satisfying a range of other conditions such as providing priority services to critical **customers. In this domain, some** trajectories of the elevator are more desirable than others, which makes it natural to encode the problem by assigning rewards to those trajectories."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-431,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-432,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-433,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-434,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-435,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-436,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-437 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For instance, consider a health care robot which assists ederly or disabled people by achieving simple goals such as reminding them to do important tasks (e.g."@en ;
    askg-onto:inSentence "For instance, consider a health care robot which assists ederly or disabled people by achieving simple goals such as reminding them to do important tasks (e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elderly_or_disabled_people,
        askg-data:Entity-health_care_robot .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "taking a pill), entertaining them, checking or transporting objects for them (e.g."@en ;
    askg-onto:inSentence "taking a pill), entertaining them, checking or transporting objects for them (e.g."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "checking the stove's temperature or bringing coffee), escorting them, or searching (e.g."@en ;
    askg-onto:inSentence "checking the stove's temperature or bringing coffee), escorting them, or searching (e.g."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-beverage,
        askg-data:Entity-coffee,
        askg-data:Entity-searching,
        askg-data:Entity-stove,
        askg-data:Entity-temperature .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "for glasses or for the nurse) (Cesta et al., 2003)."@en ;
    askg-onto:inSentence "for glasses or for the nurse) (Cesta et al., 2003)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2003,
        askg-data:Entity-cesta_et_al .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-435 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In this domain, we might want to reward the robot for making sure a given patient takes his pill exactly once every 8 hours **(and penalise it if it fails** to prevent the patient from doing this more than once within this time frame!), we may reward it for repeatedly visiting all rooms in the ward in a given order and reporting any problem it detects, it may also receive a reward once for each **patient's request answered** within the appropriate time-frame, etc."@en ;
    askg-onto:inSentence "In this domain, we might want to reward the robot for making sure a given patient takes his pill exactly once every 8 hours **(and penalise it if it fails** to prevent the patient from doing this more than once within this time frame!), we may reward it for repeatedly visiting all rooms in the ward in a given order and reporting any problem it detects, it may also receive a reward once for each **patient's request answered** within the appropriate time-frame, etc."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_problem_it_detects,
        askg-data:Entity-each_patients_request_answered_within_the_appropriate_time-frame,
        askg-data:Entity-failing_to_prevent_the_patient_from_taking_the_pill_more_than_once_within_this_time_frame,
        askg-data:Entity-making_sure_a_given_patient_takes_his_pill_exactly_once_every_8_hours,
        askg-data:Entity-repeatedly_visiting_all_rooms_in_the_ward_in_a_given_order,
        askg-data:Entity-robot .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-436 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Another example is **the elevator control domain** (Koehler & Schuster, 2000), in which an elevator must get passengers from their origin to their destination as efficiently as possible, while attempting to satisfying a range of other conditions such as providing priority services to critical **customers."@en ;
    askg-onto:inSentence "Another example is **the elevator control domain** (Koehler & Schuster, 2000), in which an elevator must get passengers from their origin to their destination as efficiently as possible, while attempting to satisfying a range of other conditions such as providing priority services to critical **customers."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-customers,
        askg-data:Entity-domain,
        askg-data:Entity-person,
        askg-data:Entity-the_elevator_control_domain .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-43-Sentence-437 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In this domain, some** trajectories of the elevator are more desirable than others, which makes it natural to encode the problem by assigning rewards to those trajectories."@en ;
    askg-onto:inSentence "In this domain, some** trajectories of the elevator are more desirable than others, which makes it natural to encode the problem by assigning rewards to those trajectories."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-assigning_rewards,
        askg-data:Entity-others,
        askg-data:Entity-problem,
        askg-data:Entity-trajectories .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "A decision process in which rewards depend on the sequence of **states passed through** rather than merely on the current state is called a decision process with **non-Markovian** rewards **(NMRDP) (Bacchus, Boutilier, & Grove, 1996). A difficulty with NMRDPs is that** the most efficient MDP solution methods do not directly apply to them. The traditional way to circumvent this problem is to formulate the NMRDP as an equivalent MDP, whose states result from augmenting those of the original NMRDP with extra information capturing enough history to make the reward Markovian. Hand crafting such an MDP can however be very difficult in general. This is exacerbated by the fact that the size of the MDP impacts the effectiveness of many solution methods. Therefore, there has been interest in automating the translation into an MDP, starting from a natural specification of non- Markovian rewards and of the system's dynamics (Bacchus et al., 1996; Bacchus, Boutilier, & Grove, 1997). This is the problem we focus on."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-441,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-442,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-443,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-444,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-445,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-446,
        askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-447 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A decision process in which rewards depend on the sequence of **states passed through** rather than merely on the current state is called a decision process with **non-Markovian** rewards **(NMRDP) (Bacchus, Boutilier, & Grove, 1996)."@en ;
    askg-onto:inSentence "A decision process in which rewards depend on the sequence of **states passed through** rather than merely on the current state is called a decision process with **non-Markovian** rewards **(NMRDP) (Bacchus, Boutilier, & Grove, 1996)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996,
        askg-data:Entity-bacchus_boutilier__grove,
        askg-data:Entity-decision_process_with_non-markovian_rewards,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A difficulty with NMRDPs is that** the most efficient MDP solution methods do not directly apply to them."@en ;
    askg-onto:inSentence "A difficulty with NMRDPs is that** the most efficient MDP solution methods do not directly apply to them."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-most_efficient_mdp_solution_methods,
        askg-data:Entity-nmrdps .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The traditional way to circumvent this problem is to formulate the NMRDP as an equivalent MDP, whose states result from augmenting those of the original NMRDP with extra information capturing enough history to make the reward Markovian."@en ;
    askg-onto:inSentence "The traditional way to circumvent this problem is to formulate the NMRDP as an equivalent MDP, whose states result from augmenting those of the original NMRDP with extra information capturing enough history to make the reward Markovian."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-444 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Hand crafting such an MDP can however be very difficult in general."@en ;
    askg-onto:inSentence "Hand crafting such an MDP can however be very difficult in general."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-model .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-445 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This is exacerbated by the fact that the size of the MDP impacts the effectiveness of many solution methods."@en ;
    askg-onto:inSentence "This is exacerbated by the fact that the size of the MDP impacts the effectiveness of many solution methods."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effectiveness_of_many_solution_methods,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-446 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Therefore, there has been interest in automating the translation into an MDP, starting from a natural specification of non- Markovian rewards and of the system's dynamics (Bacchus et al., 1996; Bacchus, Boutilier, & Grove, 1997)."@en ;
    askg-onto:inSentence "Therefore, there has been interest in automating the translation into an MDP, starting from a natural specification of non- Markovian rewards and of the system's dynamics (Bacchus et al., 1996; Bacchus, Boutilier, & Grove, 1997)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996,
        askg-data:Entity-1997,
        askg-data:Entity-bacchus,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-boutilier,
        askg-data:Entity-grove,
        askg-data:Entity-mdp,
        askg-data:Entity-natural_specification_of_non-markovian_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-4-Paragraph-44-Sentence-447 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "This is the problem we focus on."@en ;
    askg-onto:inSentence "This is the problem we focus on."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-problem,
        askg-data:Entity-this .

askg-data:Paper-c253584c3f1ff2a2-Section-40 a askg-onto:Section ;
    rdfs:label "Section 40"@en ;
    domo:Text "5.2 Domains"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402 ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Experiments were performed on four hand-coded domains (propositions + dynamics) and on random domains. Each hand-coded domain has n propositions pi**, and a dynamics** which makes every state possible and eventually reachable from the initial state in which all propositions are false. The first two such domains, spudd-linear and **spudd-expon** were discussed by Hoey et al. (1999); the two others are our own."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4011,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4012,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4013,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4014 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Experiments were performed on four hand-coded domains (propositions + dynamics) and on random domains."@en ;
    askg-onto:inSentence "Experiments were performed on four hand-coded domains (propositions + dynamics) and on random domains."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-four_hand-coded_domains,
        askg-data:Entity-random_domains .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Each hand-coded domain has n propositions pi**, and a dynamics** which makes every state possible and eventually reachable from the initial state in which all propositions are false."@en ;
    askg-onto:inSentence "Each hand-coded domain has n propositions pi**, and a dynamics** which makes every state possible and eventually reachable from the initial state in which all propositions are false."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_propositions_are_false,
        askg-data:Entity-dynamics,
        askg-data:Entity-every_state,
        askg-data:Entity-hand-coded_domain,
        askg-data:Entity-initial_state,
        askg-data:Entity-n_propositions .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The first two such domains, spudd-linear and **spudd-expon** were discussed by Hoey et al."@en ;
    askg-onto:inSentence "The first two such domains, spudd-linear and **spudd-expon** were discussed by Hoey et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hoey_et_al,
        askg-data:Entity-spudd-expon,
        askg-data:Entity-spudd-linear .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-401-Sentence-4014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(1999); the two others are our own."@en ;
    askg-onto:inSentence "(1999); the two others are our own."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_own,
        askg-data:Entity-the_two_others .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The intention of spudd-linear **was to take advantage of the best case behaviour of** SPUDD. For each proposition pi, it has an action ai which sets pi **to true and all propositions** pj , 1 ≤ j < i to false. spudd-expon**, was used by Hoey et al. (1999) to demonstrate the** worst case behaviour of SPUDD. For each proposition pi, it has an action ai **which sets** pi to true only when all propositions pj , 1 ≤ j < i are true (and sets pi **to false otherwise), and** sets the latter propositions to false. The third domain, called on/off**, has one \"turn-on\"** and one \"turn-off\" action per proposition. The \"turn-on-pi**\" action only probabilistically** succeeds in setting pi to true when pi **was false. The turn-off action is similar. The fourth** domain, called complete**, is a fully connected reflexive domain. For each proposition** pi there is an action ai which sets pi to true with probability i/(n**+ 1) (and to false otherwise)** and pj , j 6= i to true or false with probability 0.5. Note that ai **can cause a transition to** any of the 2n**states.** Random domains of size n also involve n **propositions. The method for generating their** dynamics is detailed in appendix C. Let us just summarise by saying that we are able to generate random dynamics exhibiting a given degree of \"structure\" and a given degree of uncertainty. Lack of structure essentially measures the bushiness of the internal part of the ADDs representing the actions, and uncertainty measures the bushiness of their leaves."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4021,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40210,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40211,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40212,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40213,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40214,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4022,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4023,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4024,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4025,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4026,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4027,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4028,
        askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4029 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The intention of spudd-linear **was to take advantage of the best case behaviour of** SPUDD."@en ;
    askg-onto:inSentence "The intention of spudd-linear **was to take advantage of the best case behaviour of** SPUDD."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-spudd,
        askg-data:Entity-spudd-linear .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "For each proposition** pi there is an action ai which sets pi to true with probability i/(n**+ 1) (and to false otherwise)** and pj , j 6= i to true or false with probability 0.5."@en ;
    askg-onto:inSentence "For each proposition** pi there is an action ai which sets pi to true with probability i/(n**+ 1) (and to false otherwise)** and pj , j 6= i to true or false with probability 0.5."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-05,
        askg-data:Entity-action,
        askg-data:Entity-false,
        askg-data:Entity-pj,
        askg-data:Entity-probability,
        askg-data:Entity-proposition .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40211 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Note that ai **can cause a transition to** any of the 2n**states.** Random domains of size n also involve n **propositions."@en ;
    askg-onto:inSentence "Note that ai **can cause a transition to** any of the 2n**states.** Random domains of size n also involve n **propositions."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2n_states,
        askg-data:Entity-ai,
        askg-data:Entity-random_domains_of_size_n .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40212 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "The method for generating their** dynamics is detailed in appendix C."@en ;
    askg-onto:inSentence "The method for generating their** dynamics is detailed in appendix C."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamics,
        askg-data:Entity-method .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40213 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Let us just summarise by saying that we are able to generate random dynamics exhibiting a given degree of \"structure\" and a given degree of uncertainty."@en ;
    askg-onto:inSentence "Let us just summarise by saying that we are able to generate random dynamics exhibiting a given degree of \"structure\" and a given degree of uncertainty."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamics,
        askg-data:Entity-structure,
        askg-data:Entity-uncertainty .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-40214 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Lack of structure essentially measures the bushiness of the internal part of the ADDs representing the actions, and uncertainty measures the bushiness of their leaves."@en ;
    askg-onto:inSentence "Lack of structure essentially measures the bushiness of the internal part of the ADDs representing the actions, and uncertainty measures the bushiness of their leaves."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bushiness_of_the_internal_part_of_the_adds,
        askg-data:Entity-bushiness_of_their_leaves,
        askg-data:Entity-lack_of_structure,
        askg-data:Entity-uncertainty .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For each proposition pi, it has an action ai which sets pi **to true and all propositions** pj , 1 ≤ j < i to false."@en ;
    askg-onto:inSentence "For each proposition pi, it has an action ai which sets pi **to true and all propositions** pj , 1 ≤ j < i to false."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_ai,
        askg-data:Entity-proposition_pi,
        askg-data:Entity-proposition_pj .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "spudd-expon**, was used by Hoey et al."@en ;
    askg-onto:inSentence "spudd-expon**, was used by Hoey et al."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hoey_et_al,
        askg-data:Entity-spudd-expon .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(1999) to demonstrate the** worst case behaviour of SPUDD."@en ;
    askg-onto:inSentence "(1999) to demonstrate the** worst case behaviour of SPUDD."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-spudd,
        askg-data:Entity-worst_case_behaviour .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For each proposition pi, it has an action ai **which sets** pi to true only when all propositions pj , 1 ≤ j < i are true (and sets pi **to false otherwise), and** sets the latter propositions to false."@en ;
    askg-onto:inSentence "For each proposition pi, it has an action ai **which sets** pi to true only when all propositions pj , 1 ≤ j < i are true (and sets pi **to false otherwise), and** sets the latter propositions to false."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_ai,
        askg-data:Entity-false,
        askg-data:Entity-proposition_pi,
        askg-data:Entity-proposition_pj,
        askg-data:Entity-propositions,
        askg-data:Entity-true .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4026 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The third domain, called on/off**, has one \"turn-on\"** and one \"turn-off\" action per proposition."@en ;
    askg-onto:inSentence "The third domain, called on/off**, has one \"turn-on\"** and one \"turn-off\" action per proposition."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-onoff .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4027 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The \"turn-on-pi**\" action only probabilistically** succeeds in setting pi to true when pi **was false."@en ;
    askg-onto:inSentence "The \"turn-on-pi**\" action only probabilistically** succeeds in setting pi to true when pi **was false."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-false,
        askg-data:Entity-pi,
        askg-data:Entity-set_pi_to_true,
        askg-data:Entity-turn-on-pi .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4028 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "The turn-off action is similar."@en ;
    askg-onto:inSentence "The turn-off action is similar."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-turn-off_action .

askg-data:Paper-c253584c3f1ff2a2-Section-40-Paragraph-402-Sentence-4029 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "The fourth** domain, called complete**, is a fully connected reflexive domain."@en ;
    askg-onto:inSentence "The fourth** domain, called complete**, is a fully connected reflexive domain."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complete,
        askg-data:Entity-fully_connected_reflexive_domain .

askg-data:Paper-c253584c3f1ff2a2-Section-41 a askg-onto:Section ;
    rdfs:label "Section 41"@en ;
    domo:Text "5.3 Influence Of Dynamics"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-412,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-414,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-415,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-416,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-417,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-418,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-419 ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The interaction between dynamics and reward certainly affects the performance of the different approaches, though not so strikingly as other factors such as the reward type (see below). We found that under the same reward scheme, varying the degree of structure or uncertainty did not generally change the relative success of the different approaches. For instance, Figures 10 and 11 show the average run time of the methods as a function of the degree of structure, resp. degree of uncertainty, for random problems of size n **= 6 and** reward ⊖n¬⊖⊤ (the state encountered at stage n **is rewarded, regardless of its properties**11)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4111,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4112,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4113,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4114 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The interaction between dynamics and reward certainly affects the performance of the different approaches, though not so strikingly as other factors such as the reward type (see below)."@en ;
    askg-onto:inSentence "The interaction between dynamics and reward certainly affects the performance of the different approaches, though not so strikingly as other factors such as the reward type (see below)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamics,
        askg-data:Entity-performance,
        askg-data:Entity-reward,
        askg-data:Entity-reward_type .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We found that under the same reward scheme, varying the degree of structure or uncertainty did not generally change the relative success of the different approaches."@en ;
    askg-onto:inSentence "We found that under the same reward scheme, varying the degree of structure or uncertainty did not generally change the relative success of the different approaches."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-degree_of_structure_or_uncertainty,
        askg-data:Entity-relative_success,
        askg-data:Entity-reward_scheme .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For instance, Figures 10 and 11 show the average run time of the methods as a function of the degree of structure, resp."@en ;
    askg-onto:inSentence "For instance, Figures 10 and 11 show the average run time of the methods as a function of the degree of structure, resp."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_run_time_of_the_methods,
        askg-data:Entity-degree_of_structure .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-411-Sentence-4114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "degree of uncertainty, for random problems of size n **= 6 and** reward ⊖n¬⊖⊤ (the state encountered at stage n **is rewarded, regardless of its properties**11)."@en ;
    askg-onto:inSentence "degree of uncertainty, for random problems of size n **= 6 and** reward ⊖n¬⊖⊤ (the state encountered at stage n **is rewarded, regardless of its properties**11)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-degree_of_uncertainty,
        askg-data:Entity-n__6,
        askg-data:Entity-random_problems,
        askg-data:Entity-reward_n .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-412 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Run-time increases slightly with both degrees, but there is **no significant change in relative** performance. These are typical of the graphs we obtain for other rewards."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-412-Sentence-4121,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-412-Sentence-4122 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-412-Sentence-4121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Run-time increases slightly with both degrees, but there is **no significant change in relative** performance."@en ;
    askg-onto:inSentence "Run-time increases slightly with both degrees, but there is **no significant change in relative** performance."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-relative_performance,
        askg-data:Entity-run-time .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-412-Sentence-4122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These are typical of the graphs we obtain for other rewards."@en ;
    askg-onto:inSentence "These are typical of the graphs we obtain for other rewards."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-graphs,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Clearly, counterexamples to this observation exist. These **are most notable in cases of** extreme dynamics, for instance with the spudd-expon **domain. Although for small values** of n, such as n = 6, pltlstr **approaches are faster than the others in handling the reward** ⊖n¬⊖⊤ **for virtually any type of dynamics we encountered, they perform very poorly with** that reward on spudd-expon**. This is explained by the fact that only a small fraction of** spudd-expon states are reachable in the first n steps. After n steps, fltl **immediately** recognises that reward is of no consequence, because the formula has progressed to ⊤."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4131,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4132,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4133,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4134,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4135 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Clearly, counterexamples to this observation exist."@en ;
    askg-onto:inSentence "Clearly, counterexamples to this observation exist."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-counterexamples,
        askg-data:Entity-observation .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These **are most notable in cases of** extreme dynamics, for instance with the spudd-expon **domain."@en ;
    askg-onto:inSentence "These **are most notable in cases of** extreme dynamics, for instance with the spudd-expon **domain."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain,
        askg-data:Entity-spudd-expon .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Although for small values** of n, such as n = 6, pltlstr **approaches are faster than the others in handling the reward** ⊖n¬⊖⊤ **for virtually any type of dynamics we encountered, they perform very poorly with** that reward on spudd-expon**."@en ;
    askg-onto:inSentence "Although for small values** of n, such as n = 6, pltlstr **approaches are faster than the others in handling the reward** ⊖n¬⊖⊤ **for virtually any type of dynamics we encountered, they perform very poorly with** that reward on spudd-expon**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-others,
        askg-data:Entity-pltlstr,
        askg-data:Entity-reward,
        askg-data:Entity-spudd-expon .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This is explained by the fact that only a small fraction of** spudd-expon states are reachable in the first n steps."@en ;
    askg-onto:inSentence "This is explained by the fact that only a small fraction of** spudd-expon states are reachable in the first n steps."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_n_steps,
        askg-data:Entity-spudd-expon_states .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-413-Sentence-4135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "After n steps, fltl **immediately** recognises that reward is of no consequence, because the formula has progressed to ⊤."@en ;
    askg-onto:inSentence "After n steps, fltl **immediately** recognises that reward is of no consequence, because the formula has progressed to ⊤."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-fltl,
        askg-data:Entity-formula,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-414 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "pltlmin discovers this fact only after expensive preprocessing. pltlstr**, on the other** hand, remains concerned by the prospect of reward, just as pltlsim **would.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-414-Sentence-4141,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-414-Sentence-4142 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-414-Sentence-4141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "pltlmin discovers this fact only after expensive preprocessing."@en ;
    askg-onto:inSentence "pltlmin discovers this fact only after expensive preprocessing."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fact,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-414-Sentence-4142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "pltlstr**, on the other** hand, remains concerned by the prospect of reward, just as pltlsim **would.**"@en ;
    askg-onto:inSentence "pltlstr**, on the other** hand, remains concerned by the prospect of reward, just as pltlsim **would.**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstr,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-415 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "11. n**$ in $FLTL**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-415-Sentence-4151,
        askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-415-Sentence-4152 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-415-Sentence-4151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "11."@en ;
    askg-onto:inSentence "11."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-finding,
        askg-data:Entity-model,
        askg-data:Entity-result,
        askg-data:Entity-tool,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-415-Sentence-4152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "n**$ in $FLTL**"@en ;
    askg-onto:inSentence "n**$ in $FLTL**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-_in_fltl,
        askg-data:Entity-fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-416 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![32_image_0.png](32_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-416-Sentence-4161 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-416-Sentence-4161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![32_image_0.png](32_image_0.png)"@en ;
    askg-onto:inSentence "![32_image_0.png](32_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-impact_factor,
        askg-data:Entity-publications,
        askg-data:Entity-research_outputs,
        askg-data:Entity-researchers,
        askg-data:Entity-researchgate,
        askg-data:Entity-social_networking_site .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-417 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Figure 10: Changing the Degree of Structure"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-417-Sentence-4171 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-417-Sentence-4171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 10: Changing the Degree of Structure"@en ;
    askg-onto:inSentence "Figure 10: Changing the Degree of Structure"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-changing,
        askg-data:Entity-degree_of_structure .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-418 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "![32_image_1.png](32_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-418-Sentence-4181 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-418-Sentence-4181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![32_image_1.png](32_image_1.png)"@en ;
    askg-onto:inSentence "![32_image_1.png](32_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company_alpha,
        askg-data:Entity-dataset_z,
        askg-data:Entity-method_x,
        askg-data:Entity-method_y,
        askg-data:Entity-paper_y,
        askg-data:Entity-person_x,
        askg-data:Entity-research_field_a,
        askg-data:Entity-research_field_b,
        askg-data:Entity-technology_b,
        askg-data:Entity-tool_c .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-419 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Figure 11: Changing the Degree of Uncertainty"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-419-Sentence-4191 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-41-Paragraph-419-Sentence-4191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 11: Changing the Degree of Uncertainty"@en ;
    askg-onto:inSentence "Figure 11: Changing the Degree of Uncertainty"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-degree_of_uncertainty,
        askg-data:Entity-uncertainty .

askg-data:Paper-c253584c3f1ff2a2-Section-42 a askg-onto:Section ;
    rdfs:label "Section 42"@en ;
    domo:Text "5.4 Influence Of Reward Types"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-423,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-424,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-425,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-426,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428 ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The type of reward appears to have a stronger influence on performance than dynamics. This is unsurprising, as the reward type significantly affects the size of the generated MDP: certain rewards only make the size of the minimal equivalent **MDP increase by a constant** number of states or a constant factor, while others make it increase by a factor exponential in the length of the formula. Table 1 illustrates this. The third column reports the size of the minimal equivalent MDP induced by the formulae on the left hand side.12 A legitimate question is whether there is a direct correlation between size increase and (in)appropriateness of the different methods. For instance, we might expect the state-based methods to do particularly well in conjunction with reward types inducing a small MDP and"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4211,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4212,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4213,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4214,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4215 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The type of reward appears to have a stronger influence on performance than dynamics."@en ;
    askg-onto:inSentence "The type of reward appears to have a stronger influence on performance than dynamics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-performance,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This is unsurprising, as the reward type significantly affects the size of the generated MDP: certain rewards only make the size of the minimal equivalent **MDP increase by a constant** number of states or a constant factor, while others make it increase by a factor exponential in the length of the formula."@en ;
    askg-onto:inSentence "This is unsurprising, as the reward type significantly affects the size of the generated MDP: certain rewards only make the size of the minimal equivalent **MDP increase by a constant** number of states or a constant factor, while others make it increase by a factor exponential in the length of the formula."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constant_factor,
        askg-data:Entity-constant_number_of_states,
        askg-data:Entity-factor_exponential_in_the_length_of_the_formula,
        askg-data:Entity-reward_type,
        askg-data:Entity-rewards,
        askg-data:Entity-size_of_the_generated_mdp,
        askg-data:Entity-size_of_the_minimal_equivalent_mdp,
        askg-data:Entity-size_of_the_minimal_equivalent_mdp_increase .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Table 1 illustrates this."@en ;
    askg-onto:inSentence "Table 1 illustrates this."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_1,
        askg-data:Entity-this .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The third column reports the size of the minimal equivalent MDP induced by the formulae on the left hand side.12 A legitimate question is whether there is a direct correlation between size increase and (in)appropriateness of the different methods."@en ;
    askg-onto:inSentence "The third column reports the size of the minimal equivalent MDP induced by the formulae on the left hand side.12 A legitimate question is whether there is a direct correlation between size increase and (in)appropriateness of the different methods."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_methods,
        askg-data:Entity-formulae,
        askg-data:Entity-inappropriateness,
        askg-data:Entity-minimal_equivalent_mdp,
        askg-data:Entity-size_increase .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-421-Sentence-4215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For instance, we might expect the state-based methods to do particularly well in conjunction with reward types inducing a small MDP and"@en ;
    askg-onto:inSentence "For instance, we might expect the state-based methods to do particularly well in conjunction with reward types inducing a small MDP and"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward_types_inducing_a_small_mdp,
        askg-data:Entity-state-based_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "12. The figures are not necessarily valid for non-completely **connected NMRDPs. Unfortunately, even for** completely connected domains, there does not appear to be a much cheaper way to determine the MDP size than to generate it and count states."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422-Sentence-4221,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422-Sentence-4222,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422-Sentence-4223 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422-Sentence-4221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "12."@en ;
    askg-onto:inSentence "12."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-12,
        askg-data:Entity-numerical_value .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422-Sentence-4222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The figures are not necessarily valid for non-completely **connected NMRDPs."@en ;
    askg-onto:inSentence "The figures are not necessarily valid for non-completely **connected NMRDPs."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdps,
        askg-data:Entity-non-completely_connected .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-422-Sentence-4223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Unfortunately, even for** completely connected domains, there does not appear to be a much cheaper way to determine the MDP size than to generate it and count states."@en ;
    askg-onto:inSentence "Unfortunately, even for** completely connected domains, there does not appear to be a much cheaper way to determine the MDP size than to generate it and count states."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_size,
        askg-data:Entity-states .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-423 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "| type | formula | | | | | size | fastest | slowest | |----------------------------------|------------------|--------|---------|------------|---------|-------------------|------------|-----------| | first time all pis | n (∧ i=1pi) | ∧ | (¬ | n ⊖ ♦\\- ∧ | i=1 pi) | O(1)\\|\\|S\\|\\| | pltlstr(a) | pltlmin | | pis in sequence from start state | n (∧ i=1 ⊖i pi) | | ∧ ⊖n¬ | ⊖ | ⊤ | O(n)\\|\\|S\\|\\| | fltl | pltlstr | | two consecutive pis | n−1 ∨ i=1 (⊖pi | | ∧ pi+1) | | | O(n k )\\|\\|S\\|\\| | pltlstr | fltl | | all pis n times ago | n ⊖n ∧ | i=1 pi | | | | O(2n)\\|\\|S\\|\\| | pltlstr | pltlmin |"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-423-Sentence-4231 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-423-Sentence-4231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| type | formula | | | | | size | fastest | slowest | |----------------------------------|------------------|--------|---------|------------|---------|-------------------|------------|-----------| | first time all pis | n (∧ i=1pi) | ∧ | (¬ | n ⊖ ♦\\- ∧ | i=1 pi) | O(1)\\|\\|S\\|\\| | pltlstr(a) | pltlmin | | pis in sequence from start state | n (∧ i=1 ⊖i pi) | | ∧ ⊖n¬ | ⊖ | ⊤ | O(n)\\|\\|S\\|\\| | fltl | pltlstr | | two consecutive pis | n−1 ∨ i=1 (⊖pi | | ∧ pi+1) | | | O(n k )\\|\\|S\\|\\| | pltlstr | fltl | | all pis n times ago | n ⊖n ∧ | i=1 pi | | | | O(2n)\\|\\|S\\|\\| | pltlstr | pltlmin |"@en ;
    askg-onto:inSentence "| type | formula | | | | | size | fastest | slowest | |----------------------------------|------------------|--------|---------|------------|---------|-------------------|------------|-----------| | first time all pis | n (∧ i=1pi) | ∧ | (¬ | n ⊖ ♦\\- ∧ | i=1 pi) | O(1)\\|\\|S\\|\\| | pltlstr(a) | pltlmin | | pis in sequence from start state | n (∧ i=1 ⊖i pi) | | ∧ ⊖n¬ | ⊖ | ⊤ | O(n)\\|\\|S\\|\\| | fltl | pltlstr | | two consecutive pis | n−1 ∨ i=1 (⊖pi | | ∧ pi+1) | | | O(n k )\\|\\|S\\|\\| | pltlstr | fltl | | all pis n times ago | n ⊖n ∧ | i=1 pi | | | | O(2n)\\|\\|S\\|\\| | pltlstr | pltlmin |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-424 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Table 1: Influence of Reward Type on MDP Size and Method Performance"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-424-Sentence-4241 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-424-Sentence-4241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 1: Influence of Reward Type on MDP Size and Method Performance"@en ;
    askg-onto:inSentence "Table 1: Influence of Reward Type on MDP Size and Method Performance"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_size,
        askg-data:Entity-method_performance,
        askg-data:Entity-reward_type .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-425 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![33_image_0.png](33_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-425-Sentence-4251 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-425-Sentence-4251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![33_image_0.png](33_image_0.png)"@en ;
    askg-onto:inSentence "![33_image_0.png](33_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-diagnostic_reports,
        askg-data:Entity-healthcare_system,
        askg-data:Entity-hospitals,
        askg-data:Entity-image_analysis,
        askg-data:Entity-machine_learning,
        askg-data:Entity-medical_images,
        askg-data:Entity-medical_imaging,
        askg-data:Entity-mri,
        askg-data:Entity-radiologists .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-426 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Figure 12: Changing the Syntax"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-426-Sentence-4261 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-426-Sentence-4261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 12: Changing the Syntax"@en ;
    askg-onto:inSentence "Figure 12: Changing the Syntax"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-changing_the_syntax,
        askg-data:Entity-figure_12 .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "otherwise badly in comparison with structured methods. Interestingly, this is not always the case. For instance, in Table 1 whose last two columns report the fastest and slowest methods over the range of hand-coded domains where 1 ≤ n ≤ **12, the first row contradicts** that expectation. Moreover, although pltlstr **is fastest in the last row, for larger values** of n **(not represented in the table), it aborts through lack of memory, unlike the other** methods."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4271,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4272,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4273,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4274 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "otherwise badly in comparison with structured methods."@en ;
    askg-onto:inSentence "otherwise badly in comparison with structured methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-badly,
        askg-data:Entity-structured_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4272 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Interestingly, this is not always the case."@en ;
    askg-onto:inSentence "Interestingly, this is not always the case."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4273 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For instance, in Table 1 whose last two columns report the fastest and slowest methods over the range of hand-coded domains where 1 ≤ n ≤ **12, the first row contradicts** that expectation."@en ;
    askg-onto:inSentence "For instance, in Table 1 whose last two columns report the fastest and slowest methods over the range of hand-coded domains where 1 ≤ n ≤ **12, the first row contradicts** that expectation."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expectation,
        askg-data:Entity-table_1,
        askg-data:Entity-the_fastest_and_slowest_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-427-Sentence-4274 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover, although pltlstr **is fastest in the last row, for larger values** of n **(not represented in the table), it aborts through lack of memory, unlike the other** methods."@en ;
    askg-onto:inSentence "Moreover, although pltlstr **is fastest in the last row, for larger values** of n **(not represented in the table), it aborts through lack of memory, unlike the other** methods."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-not_represented_in_the_table,
        askg-data:Entity-pltlstr,
        askg-data:Entity-the_last_row,
        askg-data:Entity-values_of_n .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "The most obvious observations arising out of these experiments is that pltlstr **is nearly** always the fastest - until it runs out of memory. Perhaps the most interesting results are those in the second row, which expose the inability of methods based on PLTL to deal with rewards specified as long sequences of events. In converting the reward formula to a set of subformulae, they lose information about the order of events, which then has to be recovered laboriously by reasoning. $FLTL progression in contrast takes the events one at a time, preserving the relevant structure at each step. Further experimentation led us to observe that all PLTL based algorithms perform poorly where reward is specified using formulae of the form ⊖kf, ♦- kf, and ⊟kf (f has been true k **steps ago, within the last** k steps, or at all of the last k **steps).**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4281,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4282,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4283,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4284,
        askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4285 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The most obvious observations arising out of these experiments is that pltlstr **is nearly** always the fastest - until it runs out of memory."@en ;
    askg-onto:inSentence "The most obvious observations arising out of these experiments is that pltlstr **is nearly** always the fastest - until it runs out of memory."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-runs_out_of_memory .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4282 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Perhaps the most interesting results are those in the second row, which expose the inability of methods based on PLTL to deal with rewards specified as long sequences of events."@en ;
    askg-onto:inSentence "Perhaps the most interesting results are those in the second row, which expose the inability of methods based on PLTL to deal with rewards specified as long sequences of events."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inability_to_deal_with_rewards_specified_as_long_sequences_of_events,
        askg-data:Entity-methods_based_on_pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4283 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In converting the reward formula to a set of subformulae, they lose information about the order of events, which then has to be recovered laboriously by reasoning."@en ;
    askg-onto:inSentence "In converting the reward formula to a set of subformulae, they lose information about the order of events, which then has to be recovered laboriously by reasoning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-information,
        askg-data:Entity-order_of_events,
        askg-data:Entity-reasoning,
        askg-data:Entity-reward_formula,
        askg-data:Entity-set_of_subformulae,
        askg-data:Entity-they .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4284 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "$FLTL progression in contrast takes the events one at a time, preserving the relevant structure at each step."@en ;
    askg-onto:inSentence "$FLTL progression in contrast takes the events one at a time, preserving the relevant structure at each step."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-events,
        askg-data:Entity-fltl_progression .

askg-data:Paper-c253584c3f1ff2a2-Section-42-Paragraph-428-Sentence-4285 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Further experimentation led us to observe that all PLTL based algorithms perform poorly where reward is specified using formulae of the form ⊖kf, ♦- kf, and ⊟kf (f has been true k **steps ago, within the last** k steps, or at all of the last k **steps).**"@en ;
    askg-onto:inSentence "Further experimentation led us to observe that all PLTL based algorithms perform poorly where reward is specified using formulae of the form ⊖kf, ♦- kf, and ⊟kf (f has been true k **steps ago, within the last** k steps, or at all of the last k **steps).**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_based_algorithms,
        askg-data:Entity-reward_specified_using_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-43 a askg-onto:Section ;
    rdfs:label "Section 43"@en ;
    domo:Text "5.5 Influence Of Syntax"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-432,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-433,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-434,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-435,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436 ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Unsurprisingly, we find that the syntax used to express rewards, which affects the length of the formula, has a major influence on the run time. A typical **example of this effect is** captured in Figure 12. This graph demonstrates how re-expressing **prvOut** ≡ ⊖n(∧ n i=1pi)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431-Sentence-4311,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431-Sentence-4312,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431-Sentence-4313 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431-Sentence-4311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Unsurprisingly, we find that the syntax used to express rewards, which affects the length of the formula, has a major influence on the run time."@en ;
    askg-onto:inSentence "Unsurprisingly, we find that the syntax used to express rewards, which affects the length of the formula, has a major influence on the run time."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-run_time,
        askg-data:Entity-syntax .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431-Sentence-4312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A typical **example of this effect is** captured in Figure 12."@en ;
    askg-onto:inSentence "A typical **example of this effect is** captured in Figure 12."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_12,
        askg-data:Entity-this_effect .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-431-Sentence-4313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This graph demonstrates how re-expressing **prvOut** ≡ ⊖n(∧ n i=1pi)"@en ;
    askg-onto:inSentence "This graph demonstrates how re-expressing **prvOut** ≡ ⊖n(∧ n i=1pi)"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n_n_i1pi,
        askg-data:Entity-prvout .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-432 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "![34_image_0.png](34_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-432-Sentence-4321 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-432-Sentence-4321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![34_image_0.png](34_image_0.png)"@en ;
    askg-onto:inSentence "![34_image_0.png](34_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-research_concept .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-433 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 13: Effect of Multiple Rewards on MDP size"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-433-Sentence-4331 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-433-Sentence-4331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 13: Effect of Multiple Rewards on MDP size"@en ;
    askg-onto:inSentence "Figure 13: Effect of Multiple Rewards on MDP size"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_size,
        askg-data:Entity-multiple_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-434 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![34_image_1.png](34_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-434-Sentence-4341 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-434-Sentence-4341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![34_image_1.png](34_image_1.png)"@en ;
    askg-onto:inSentence "![34_image_1.png](34_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithms,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-data_science,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning_techniques,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_networks,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-research_paper,
        askg-data:Entity-statistical_methods,
        askg-data:Entity-studies .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-435 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Figure 14: Effect of Multiple Rewards on Run Time"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-435-Sentence-4351 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-435-Sentence-4351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 14: Effect of Multiple Rewards on Run Time"@en ;
    askg-onto:inSentence "Figure 14: Effect of Multiple Rewards on Run Time"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-multiple_rewards,
        askg-data:Entity-run_time .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "as prvIn ≡ ∧n i=1 ⊖n pi, thereby creating n **times more temporal subformulae, alters the** running time of all PLTL methods. fltl **is affected too as $FLTL progression requires two** iterations through the reward formula. The graph represents the averages of the running times over all the methods, for the complete **domain.** Our most serious concern in relation to the PLTL approaches is their handling of reward specifications containing multiple reward elements. Most notably we found that **pltlmin** does not necessarily produce the minimal equivalent MDP in this situation. To demonstrate, we consider the set of reward formulae {f1,f2,... ,fn}**, each associated with the** same real value r**. Given this, PLTL approaches will distinguish unnecessarily between past** behaviours which lead to identical future rewards. This may **occur when the reward at an** e-state is determined by the truth value of f1∨f2**. This formula does not necessarily require** e-states that distinguish between the cases in which {f1 ≡ ⊤,f2 ≡ ⊥} and {f1 ≡ ⊥,f2 **≡ ⊤}** hold; however, given the above specification, pltlmin **makes this distinction. For example,** taking fi = ⊖pi, Figure 13 shows that fltl **leads to an MDP whose size is at most 3 times** that of the NMRDP. In contrast, the relative size of the MDP produced by **pltlmin** is linear in n**, the number of rewards and propositions. These results are obtained with all** hand-coded domains except spudd-expon**. Figure 14 shows the run-times as a function** of n for complete. fltl dominates and is only overtaken by pltlstr**(A) for large values** of n**, when the MDP becomes too large for explicit exploration to be practical. To obtain** the minimal equivalent MDP using pltlmin**, a bloated reward specification of the form** {(⊖ ∨ n i=1 (pi ∧ n j=1,j6=i ¬pj ) : r)**,... ,**(⊖ ∧ n i=1 pi: n ∗ r)} **is necessary, which, by virtue of its** exponential length, is not an adequate solution."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4361,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43610,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43611,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43612,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43613,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43614,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43615,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43616,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4362,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4363,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4364,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4365,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4366,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4367,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4368,
        askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4369 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "as prvIn ≡ ∧n i=1 ⊖n pi, thereby creating n **times more temporal subformulae, alters the** running time of all PLTL methods."@en ;
    askg-onto:inSentence "as prvIn ≡ ∧n i=1 ⊖n pi, thereby creating n **times more temporal subformulae, alters the** running time of all PLTL methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_methods,
        askg-data:Entity-prvin .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43610 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "For example,** taking fi = ⊖pi, Figure 13 shows that fltl **leads to an MDP whose size is at most 3 times** that of the NMRDP."@en ;
    askg-onto:inSentence "For example,** taking fi = ⊖pi, Figure 13 shows that fltl **leads to an MDP whose size is at most 3 times** that of the NMRDP."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_times_that_of_the_nmrdp,
        askg-data:Entity-fltl,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43611 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "In contrast, the relative size of the MDP produced by **pltlmin** is linear in n**, the number of rewards and propositions."@en ;
    askg-onto:inSentence "In contrast, the relative size of the MDP produced by **pltlmin** is linear in n**, the number of rewards and propositions."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-linear_in_n,
        askg-data:Entity-mdp,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43612 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "These results are obtained with all** hand-coded domains except spudd-expon**."@en ;
    askg-onto:inSentence "These results are obtained with all** hand-coded domains except spudd-expon**."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hand-coded_domains,
        askg-data:Entity-spudd-expon .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43613 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Figure 14 shows the run-times as a function** of n for complete."@en ;
    askg-onto:inSentence "Figure 14 shows the run-times as a function** of n for complete."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_14,
        askg-data:Entity-run-times .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43614 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "fltl dominates and is only overtaken by pltlstr**(A) for large values** of n**, when the MDP becomes too large for explicit exploration to be practical."@en ;
    askg-onto:inSentence "fltl dominates and is only overtaken by pltlstr**(A) for large values** of n**, when the MDP becomes too large for explicit exploration to be practical."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-mdp,
        askg-data:Entity-n,
        askg-data:Entity-pltlstra .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43615 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "To obtain** the minimal equivalent MDP using pltlmin**, a bloated reward specification of the form** {(⊖ ∨ n i=1 (pi ∧ n j=1,j6=i ¬pj ) : r)**,..."@en ;
    askg-onto:inSentence "To obtain** the minimal equivalent MDP using pltlmin**, a bloated reward specification of the form** {(⊖ ∨ n i=1 (pi ∧ n j=1,j6=i ¬pj ) : r)**,..."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-43616 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text ",**(⊖ ∧ n i=1 pi: n ∗ r)} **is necessary, which, by virtue of its** exponential length, is not an adequate solution."@en ;
    askg-onto:inSentence ",**(⊖ ∧ n i=1 pi: n ∗ r)} **is necessary, which, by virtue of its** exponential length, is not an adequate solution."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-__n_i1_pi_n__r,
        askg-data:Entity-solution .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "fltl **is affected too as $FLTL progression requires two** iterations through the reward formula."@en ;
    askg-onto:inSentence "fltl **is affected too as $FLTL progression requires two** iterations through the reward formula."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_progression,
        askg-data:Entity-two_iterations_through_the_reward_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4363 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The graph represents the averages of the running times over all the methods, for the complete **domain.** Our most serious concern in relation to the PLTL approaches is their handling of reward specifications containing multiple reward elements."@en ;
    askg-onto:inSentence "The graph represents the averages of the running times over all the methods, for the complete **domain.** Our most serious concern in relation to the PLTL approaches is their handling of reward specifications containing multiple reward elements."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averages_of_the_running_times,
        askg-data:Entity-domain,
        askg-data:Entity-pltl_approaches,
        askg-data:Entity-reward_specifications_containing_multiple_reward_elements .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4364 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Most notably we found that **pltlmin** does not necessarily produce the minimal equivalent MDP in this situation."@en ;
    askg-onto:inSentence "Most notably we found that **pltlmin** does not necessarily produce the minimal equivalent MDP in this situation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-minimal_equivalent_mdp,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4365 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To demonstrate, we consider the set of reward formulae {f1,f2,..."@en ;
    askg-onto:inSentence "To demonstrate, we consider the set of reward formulae {f1,f2,..."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f1f2,
        askg-data:Entity-reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4366 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text ",fn}**, each associated with the** same real value r**."@en ;
    askg-onto:inSentence ",fn}**, each associated with the** same real value r**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-real_value_r,
        askg-data:Entity-same .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4367 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Given this, PLTL approaches will distinguish unnecessarily between past** behaviours which lead to identical future rewards."@en ;
    askg-onto:inSentence "Given this, PLTL approaches will distinguish unnecessarily between past** behaviours which lead to identical future rewards."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-identical_future_rewards,
        askg-data:Entity-past_behaviours,
        askg-data:Entity-pltl_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4368 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "This may **occur when the reward at an** e-state is determined by the truth value of f1∨f2**."@en ;
    askg-onto:inSentence "This may **occur when the reward at an** e-state is determined by the truth value of f1∨f2**."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-truth_value_of_f1f2 .

askg-data:Paper-c253584c3f1ff2a2-Section-43-Paragraph-436-Sentence-4369 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "This formula does not necessarily require** e-states that distinguish between the cases in which {f1 ≡ ⊤,f2 ≡ ⊥} and {f1 ≡ ⊥,f2 **≡ ⊤}** hold; however, given the above specification, pltlmin **makes this distinction."@en ;
    askg-onto:inSentence "This formula does not necessarily require** e-states that distinguish between the cases in which {f1 ≡ ⊤,f2 ≡ ⊥} and {f1 ≡ ⊥,f2 **≡ ⊤}** hold; however, given the above specification, pltlmin **makes this distinction."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-pltlmin .

askg-data:Paper-c253584c3f1ff2a2-Section-44 a askg-onto:Section ;
    rdfs:label "Section 44"@en ;
    domo:Text "5.6 Influence Of Reachability"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441 ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "All approaches claim to have some ability to ignore variables which are irrelevant because the condition they track is unreachable:13 pltlmin **detects them through preprocessing,** pltlstr exploits the ability of structured solution methods to ignore them, and fltl ignores them when progression never exposes them. However, given that the mechanisms for avoiding irrelevance are so different, we expect corresponding differences in their effects. On experimental investigation, we found that the differences in performance are best illustrated by looking at response formulae, which assert that if a trigger condition c **is reached** then a reward will be received upon achievement of the goal g in, resp. within, k **steps.** In PLTL, this is written g ∧ ⊖kc, resp. g ∧ ♦- kc, and in $FLTL, (c → k(g → **$)), resp.** (c → k(g → $)) When the goal **is unreachable, PLTL approaches perform well. As it is always false, the** goal g **does not lead to behavioural distinctions. On the other hand, while constructing the** MDP, fltl considers the successive progressions of kg **without being able to detect that it** is unreachable until it actually fails to happen. This is exactly what the blindness of blind minimality amounts to. Figure 15 illustrates the difference **in performance as a function of** the number n of propositions involved in the spudd-linear **domain, when the reward is of** the form g ∧ ⊖nc, with g **unreachable.** fltl shines when the trigger is unreachable. Since c **never happens, the formula will** always progress to itself, and the goal, however complicated, is never tracked in the generated MDP. In this situation PLTL approaches still consider ⊖kc **and its subformulae, only** to discover, after expensive preprocessing for pltlmin, after reachability analysis for pltlstr(a), and never for pltlstr**, that these are irrelevant. This is illustrated in Figure 16,** again with spudd-linear and a reward of the form g ∧ ⊖nc, with c **unreachable.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4411,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-44110,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-44111,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-44112,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4412,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4413,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4414,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4415,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4416,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4417,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4418,
        askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4419 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "All approaches claim to have some ability to ignore variables which are irrelevant because the condition they track is unreachable:13 pltlmin **detects them through preprocessing,** pltlstr exploits the ability of structured solution methods to ignore them, and fltl ignores them when progression never exposes them."@en ;
    askg-onto:inSentence "All approaches claim to have some ability to ignore variables which are irrelevant because the condition they track is unreachable:13 pltlmin **detects them through preprocessing,** pltlstr exploits the ability of structured solution methods to ignore them, and fltl ignores them when progression never exposes them."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-structured_solution_methods,
        askg-data:Entity-variables_which_are_irrelevant .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-44110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Since c **never happens, the formula will** always progress to itself, and the goal, however complicated, is never tracked in the generated MDP."@en ;
    askg-onto:inSentence "Since c **never happens, the formula will** always progress to itself, and the goal, however complicated, is never tracked in the generated MDP."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-44111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "In this situation PLTL approaches still consider ⊖kc **and its subformulae, only** to discover, after expensive preprocessing for pltlmin, after reachability analysis for pltlstr(a), and never for pltlstr**, that these are irrelevant."@en ;
    askg-onto:inSentence "In this situation PLTL approaches still consider ⊖kc **and its subformulae, only** to discover, after expensive preprocessing for pltlmin, after reachability analysis for pltlstr(a), and never for pltlstr**, that these are irrelevant."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-pltlstra,
        askg-data:Entity-subformulae .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-44112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "This is illustrated in Figure 16,** again with spudd-linear and a reward of the form g ∧ ⊖nc, with c **unreachable.**"@en ;
    askg-onto:inSentence "This is illustrated in Figure 16,** again with spudd-linear and a reward of the form g ∧ ⊖nc, with c **unreachable.**"^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g__nc,
        askg-data:Entity-model,
        askg-data:Entity-reward_structure,
        askg-data:Entity-spudd-linear .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, given that the mechanisms for avoiding irrelevance are so different, we expect corresponding differences in their effects."@en ;
    askg-onto:inSentence "However, given that the mechanisms for avoiding irrelevance are so different, we expect corresponding differences in their effects."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differences,
        askg-data:Entity-effects,
        askg-data:Entity-irrelevance,
        askg-data:Entity-mechanisms .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "On experimental investigation, we found that the differences in performance are best illustrated by looking at response formulae, which assert that if a trigger condition c **is reached** then a reward will be received upon achievement of the goal g in, resp."@en ;
    askg-onto:inSentence "On experimental investigation, we found that the differences in performance are best illustrated by looking at response formulae, which assert that if a trigger condition c **is reached** then a reward will be received upon achievement of the goal g in, resp."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal_g,
        askg-data:Entity-reward,
        askg-data:Entity-trigger_condition_c .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "within, k **steps.** In PLTL, this is written g ∧ ⊖kc, resp."@en ;
    askg-onto:inSentence "within, k **steps.** In PLTL, this is written g ∧ ⊖kc, resp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g__kc,
        askg-data:Entity-model,
        askg-data:Entity-pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "g ∧ ♦- kc, and in $FLTL, (c → k(g → **$)), resp.** (c → k(g → $)) When the goal **is unreachable, PLTL approaches perform well."@en ;
    askg-onto:inSentence "g ∧ ♦- kc, and in $FLTL, (c → k(g → **$)), resp.** (c → k(g → $)) When the goal **is unreachable, PLTL approaches perform well."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-perform_well,
        askg-data:Entity-pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "As it is always false, the** goal g **does not lead to behavioural distinctions."@en ;
    askg-onto:inSentence "As it is always false, the** goal g **does not lead to behavioural distinctions."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behavioural_distinctions,
        askg-data:Entity-goal_g .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4417 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "On the other hand, while constructing the** MDP, fltl considers the successive progressions of kg **without being able to detect that it** is unreachable until it actually fails to happen."@en ;
    askg-onto:inSentence "On the other hand, while constructing the** MDP, fltl considers the successive progressions of kg **without being able to detect that it** is unreachable until it actually fails to happen."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kg,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4418 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "This is exactly what the blindness of blind minimality amounts to."@en ;
    askg-onto:inSentence "This is exactly what the blindness of blind minimality amounts to."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-blindness .

askg-data:Paper-c253584c3f1ff2a2-Section-44-Paragraph-441-Sentence-4419 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Figure 15 illustrates the difference **in performance as a function of** the number n of propositions involved in the spudd-linear **domain, when the reward is of** the form g ∧ ⊖nc, with g **unreachable.** fltl shines when the trigger is unreachable."@en ;
    askg-onto:inSentence "Figure 15 illustrates the difference **in performance as a function of** the number n of propositions involved in the spudd-linear **domain, when the reward is of** the form g ∧ ⊖nc, with g **unreachable.** fltl shines when the trigger is unreachable."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-g,
        askg-data:Entity-g__nc,
        askg-data:Entity-number_n_of_propositions,
        askg-data:Entity-reward,
        askg-data:Entity-spudd-linear,
        askg-data:Entity-trigger_is_unreachable,
        askg-data:Entity-unreachable .

askg-data:Paper-c253584c3f1ff2a2-Section-45 a askg-onto:Section ;
    rdfs:label "Section 45"@en ;
    domo:Text "5.7 Dynamic Irrelevance"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4510,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4511,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4512,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-453,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-454,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-455,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-456,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-458,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-459 ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Earlier we claimed that one advantage of pltlstr and fltl over pltlmin and **pltlsim** is that the former perform a dynamic analysis of rewards capable of detecting irrelevance of variables to particular policies, e.g. to the optimal policy. Our experiments confirm this claim. However, as for reachability, whether the goal or the triggering condition in a response formula becomes irrelevant plays an important role in determining whether a"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4511,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4512,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4513,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4514 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Earlier we claimed that one advantage of pltlstr and fltl over pltlmin and **pltlsim** is that the former perform a dynamic analysis of rewards capable of detecting irrelevance of variables to particular policies, e.g."@en ;
    askg-onto:inSentence "Earlier we claimed that one advantage of pltlstr and fltl over pltlmin and **pltlsim** is that the former perform a dynamic analysis of rewards capable of detecting irrelevance of variables to particular policies, e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-detecting_irrelevance_of_variables,
        askg-data:Entity-dynamic_analysis_of_rewards,
        askg-data:Entity-fltl,
        askg-data:Entity-particular_policies,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-variables .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "to the optimal policy."@en ;
    askg-onto:inSentence "to the optimal policy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimal_policy,
        askg-data:Entity-policy .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our experiments confirm this claim."@en ;
    askg-onto:inSentence "Our experiments confirm this claim."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-claim,
        askg-data:Entity-experiments .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-451-Sentence-4514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, as for reachability, whether the goal or the triggering condition in a response formula becomes irrelevant plays an important role in determining whether a"@en ;
    askg-onto:inSentence "However, as for reachability, whether the goal or the triggering condition in a response formula becomes irrelevant plays an important role in determining whether a"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal,
        askg-data:Entity-reachability,
        askg-data:Entity-response_formula,
        askg-data:Entity-triggering_condition .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4510 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "![37_image_1.png](37_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4510-Sentence-45101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4510-Sentence-45101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![37_image_1.png](37_image_1.png)"@en ;
    askg-onto:inSentence "![37_image_1.png](37_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai,
        askg-data:Entity-article_on_ai_research,
        askg-data:Entity-computer_vision,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-covid-19,
        askg-data:Entity-crispr,
        askg-data:Entity-deep_learning,
        askg-data:Entity-disease,
        askg-data:Entity-gene_editing,
        askg-data:Entity-image_classification,
        askg-data:Entity-john_doe,
        askg-data:Entity-journal_of_ai,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-research_on_ai,
        askg-data:Entity-software,
        askg-data:Entity-tensorflow,
        askg-data:Entity-university_of_california .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4511 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Figure 18: Response Formula with Unrewarding Trigger"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4511-Sentence-45111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4511-Sentence-45111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 18: Response Formula with Unrewarding Trigger"@en ;
    askg-onto:inSentence "Figure 18: Response Formula with Unrewarding Trigger"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-response_formula,
        askg-data:Entity-unrewarding_trigger .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4512 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "up either and performs consistently badly. Note that in both figures, pltlstr **progressively** takes longer to compute as r **increases because value iteration requires additional iterations** to converge."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4512-Sentence-45121,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4512-Sentence-45122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4512-Sentence-45121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "up either and performs consistently badly."@en ;
    askg-onto:inSentence "up either and performs consistently badly."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-badly,
        askg-data:Entity-none .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-4512-Sentence-45122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that in both figures, pltlstr **progressively** takes longer to compute as r **increases because value iteration requires additional iterations** to converge."@en ;
    askg-onto:inSentence "Note that in both figures, pltlstr **progressively** takes longer to compute as r **increases because value iteration requires additional iterations** to converge."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-converge,
        askg-data:Entity-pltlstr,
        askg-data:Entity-value_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "13. Here we sometimes speak of conditions and goals being 'reachable' or 'achievable' rather than 'feasible', although they may be temporally extended. This is to keep in line with conventional vocabulary as in the phrase 'reachability analysis'."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452-Sentence-4521,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452-Sentence-4522,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452-Sentence-4523 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452-Sentence-4521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "13."@en ;
    askg-onto:inSentence "13."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-imagenet,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-neural_networks,
        askg-data:Entity-random_forest,
        askg-data:Entity-research_field,
        askg-data:Entity-tensorflow,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452-Sentence-4522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Here we sometimes speak of conditions and goals being 'reachable' or 'achievable' rather than 'feasible', although they may be temporally extended."@en ;
    askg-onto:inSentence "Here we sometimes speak of conditions and goals being 'reachable' or 'achievable' rather than 'feasible', although they may be temporally extended."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievable,
        askg-data:Entity-conditions,
        askg-data:Entity-feasible,
        askg-data:Entity-goals,
        askg-data:Entity-reachable,
        askg-data:Entity-temporally_extended .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-452-Sentence-4523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This is to keep in line with conventional vocabulary as in the phrase 'reachability analysis'."@en ;
    askg-onto:inSentence "This is to keep in line with conventional vocabulary as in the phrase 'reachability analysis'."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-reachability_analysis .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-453 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![36_image_0.png](36_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-453-Sentence-4531 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-453-Sentence-4531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![36_image_0.png](36_image_0.png)"@en ;
    askg-onto:inSentence "![36_image_0.png](36_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-computer_vision,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-deep_learning,
        askg-data:Entity-image_recognition,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-pytorch,
        askg-data:Entity-support_vector_machines,
        askg-data:Entity-tensorflow .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-454 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Figure 15: Response Formula with Unachievable Goal"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-454-Sentence-4541 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-454-Sentence-4541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 15: Response Formula with Unachievable Goal"@en ;
    askg-onto:inSentence "Figure 15: Response Formula with Unachievable Goal"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-response_formula,
        askg-data:Entity-unachievable_goal .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-455 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![36_image_1.png](36_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-455-Sentence-4551 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-455-Sentence-4551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![36_image_1.png](36_image_1.png)"@en ;
    askg-onto:inSentence "![36_image_1.png](36_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-deep_learning,
        askg-data:Entity-image_recognition,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-pytorch,
        askg-data:Entity-reinforcement_learning,
        askg-data:Entity-software,
        askg-data:Entity-tensorflow .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-456 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Figure 16: Response Formula with Unachievable Trigger"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-456-Sentence-4561 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-456-Sentence-4561 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 16: Response Formula with Unachievable Trigger"@en ;
    askg-onto:inSentence "Figure 16: Response Formula with Unachievable Trigger"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-response_formula,
        askg-data:Entity-unachievable_trigger .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "pltlstr or fltl approach should be taken: pltlstr **is able to dynamically ignore the goal,** while fltl **is able to dynamically ignore the trigger.** This is illustrated in Figures 17 and 18. In both figures, the domain considered is on/off with n = 6 propositions, the response formula is g ∧ ⊖nc **as before, here with both** g and c **achievable. This response formula is assigned a fixed reward. To study the effect of** dynamic irrelevance of the goal, in Figure 17, achievement of ¬g **is rewarded by the value** r (i.e. we have (¬g : r**) in PLTL). In Figure 18, on the other hand, we study the effect of** dynamic irrelevance of the trigger and achievement of ¬c is rewarded by the value r**. Both** figures show the runtime of the methods as r **increases.** Achieving the goal, resp. the trigger, is made less attractive as r **increases up to the** point where the response formula becomes irrelevant under the optimal policy. When this happens, the run-time of pltlstr resp. fltl**, exhibits an abrupt but durable improvement.** The figures show that fltl is able to pick up irrelevance of the trigger, while pltlstr **is able** to exploit irrelevance of the goal. As expected, pltlmin **whose analysis is static does not pick**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4571,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-45710,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-45711,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4572,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4573,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4574,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4575,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4576,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4577,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4578,
        askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4579 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4571 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "pltlstr or fltl approach should be taken: pltlstr **is able to dynamically ignore the goal,** while fltl **is able to dynamically ignore the trigger.** This is illustrated in Figures 17 and 18."@en ;
    askg-onto:inSentence "pltlstr or fltl approach should be taken: pltlstr **is able to dynamically ignore the goal,** while fltl **is able to dynamically ignore the trigger.** This is illustrated in Figures 17 and 18."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-pltlstr,
        askg-data:Entity-the_goal,
        askg-data:Entity-the_trigger .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-45710 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "fltl**, exhibits an abrupt but durable improvement.** The figures show that fltl is able to pick up irrelevance of the trigger, while pltlstr **is able** to exploit irrelevance of the goal."@en ;
    askg-onto:inSentence "fltl**, exhibits an abrupt but durable improvement.** The figures show that fltl is able to pick up irrelevance of the trigger, while pltlstr **is able** to exploit irrelevance of the goal."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-improvement,
        askg-data:Entity-irrelevance_of_the_goal,
        askg-data:Entity-irrelevance_of_the_trigger,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-45711 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "As expected, pltlmin **whose analysis is static does not pick**"@en ;
    askg-onto:inSentence "As expected, pltlmin **whose analysis is static does not pick**"^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-static .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4572 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In both figures, the domain considered is on/off with n = 6 propositions, the response formula is g ∧ ⊖nc **as before, here with both** g and c **achievable."@en ;
    askg-onto:inSentence "In both figures, the domain considered is on/off with n = 6 propositions, the response formula is g ∧ ⊖nc **as before, here with both** g and c **achievable."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievable,
        askg-data:Entity-c,
        askg-data:Entity-domain,
        askg-data:Entity-g,
        askg-data:Entity-n__6,
        askg-data:Entity-onoff,
        askg-data:Entity-propositions,
        askg-data:Entity-response_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4573 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This response formula is assigned a fixed reward."@en ;
    askg-onto:inSentence "This response formula is assigned a fixed reward."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fixed_reward,
        askg-data:Entity-response_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4574 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To study the effect of** dynamic irrelevance of the goal, in Figure 17, achievement of ¬g **is rewarded by the value** r (i.e."@en ;
    askg-onto:inSentence "To study the effect of** dynamic irrelevance of the goal, in Figure 17, achievement of ¬g **is rewarded by the value** r (i.e."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_irrelevance_of_the_goal,
        askg-data:Entity-g,
        askg-data:Entity-value_r .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4575 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "we have (¬g : r**) in PLTL)."@en ;
    askg-onto:inSentence "we have (¬g : r**) in PLTL)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4576 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In Figure 18, on the other hand, we study the effect of** dynamic irrelevance of the trigger and achievement of ¬c is rewarded by the value r**."@en ;
    askg-onto:inSentence "In Figure 18, on the other hand, we study the effect of** dynamic irrelevance of the trigger and achievement of ¬c is rewarded by the value r**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievement_of_c,
        askg-data:Entity-dynamic_irrelevance,
        askg-data:Entity-value_r .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4577 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Both** figures show the runtime of the methods as r **increases.** Achieving the goal, resp."@en ;
    askg-onto:inSentence "Both** figures show the runtime of the methods as r **increases.** Achieving the goal, resp."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal,
        askg-data:Entity-methods,
        askg-data:Entity-r,
        askg-data:Entity-resp,
        askg-data:Entity-runtime .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4578 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "the trigger, is made less attractive as r **increases up to the** point where the response formula becomes irrelevant under the optimal policy."@en ;
    askg-onto:inSentence "the trigger, is made less attractive as r **increases up to the** point where the response formula becomes irrelevant under the optimal policy."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimal_policy,
        askg-data:Entity-r,
        askg-data:Entity-response_formula,
        askg-data:Entity-trigger .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-457-Sentence-4579 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "When this happens, the run-time of pltlstr resp."@en ;
    askg-onto:inSentence "When this happens, the run-time of pltlstr resp."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-resp .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-458 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "![37_image_0.png](37_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-458-Sentence-4581 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-458-Sentence-4581 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![37_image_0.png](37_image_0.png)"@en ;
    askg-onto:inSentence "![37_image_0.png](37_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset_c,
        askg-data:Entity-domain_o,
        askg-data:Entity-experiment_h,
        askg-data:Entity-finding_e,
        askg-data:Entity-gene_m,
        askg-data:Entity-method_i,
        askg-data:Entity-metric_j,
        askg-data:Entity-organization_y,
        askg-data:Entity-paper_g,
        askg-data:Entity-person_a,
        askg-data:Entity-rate_k,
        askg-data:Entity-research_concept_x,
        askg-data:Entity-research_field_d,
        askg-data:Entity-scientist_l,
        askg-data:Entity-study_b,
        askg-data:Entity-technology_n,
        askg-data:Entity-tool_z,
        askg-data:Entity-university_f .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-459 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Figure 17: Response Formula with Unrewarding Goal"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-459-Sentence-4591 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-45-Paragraph-459-Sentence-4591 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 17: Response Formula with Unrewarding Goal"@en ;
    askg-onto:inSentence "Figure 17: Response Formula with Unrewarding Goal"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-response_formula,
        askg-data:Entity-unrewarding_goal .

askg-data:Paper-c253584c3f1ff2a2-Section-46 a askg-onto:Section ;
    rdfs:label "Section 46"@en ;
    domo:Text "5.8 Summary"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461 ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In our experiments with artificial domains, we found pltlstr and fltl preferable to statebased PLTL approaches in most cases. If one insists on using the latter, we strongly recommend preprocessing. fltl **is the technique of choice when the reward requires tracking** a long sequence of events or when the desired behaviour is composed of many elements with identical rewards. For response formulae, we advise the use of pltlstr **if the probability of** reaching the goal is low or achieving the goal is very costly, **and conversely, we advise the** use of fltl **if the probability of reaching the triggering condition is low or if reaching it is** very costly. In all cases, attention should be paid to the syntax of the reward formulae and in particular to minimising its length. Indeed, as could be expected, we found the syntax of the formulae and the type of non-Markovian reward they encode to be a predominant factor in determining the difficulty of the problem, much more **so than the features of the** Markovian dynamics of the domain."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4611,
        askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4612,
        askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4613,
        askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4614,
        askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4615,
        askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4616 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In our experiments with artificial domains, we found pltlstr and fltl preferable to statebased PLTL approaches in most cases."@en ;
    askg-onto:inSentence "In our experiments with artificial domains, we found pltlstr and fltl preferable to statebased PLTL approaches in most cases."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-pltlstr,
        askg-data:Entity-statebased_pltl_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "If one insists on using the latter, we strongly recommend preprocessing."@en ;
    askg-onto:inSentence "If one insists on using the latter, we strongly recommend preprocessing."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-latter,
        askg-data:Entity-preprocessing .

askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "fltl **is the technique of choice when the reward requires tracking** a long sequence of events or when the desired behaviour is composed of many elements with identical rewards."@en ;
    askg-onto:inSentence "fltl **is the technique of choice when the reward requires tracking** a long sequence of events or when the desired behaviour is composed of many elements with identical rewards."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_long_sequence_of_events_or_when_the_desired_behaviour_is_composed_of_many_elements_with_identical_rewards,
        askg-data:Entity-fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For response formulae, we advise the use of pltlstr **if the probability of** reaching the goal is low or achieving the goal is very costly, **and conversely, we advise the** use of fltl **if the probability of reaching the triggering condition is low or if reaching it is** very costly."@en ;
    askg-onto:inSentence "For response formulae, we advise the use of pltlstr **if the probability of** reaching the goal is low or achieving the goal is very costly, **and conversely, we advise the** use of fltl **if the probability of reaching the triggering condition is low or if reaching it is** very costly."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-low_probability_of_reaching_the_goal,
        askg-data:Entity-low_probability_of_reaching_the_triggering_condition,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In all cases, attention should be paid to the syntax of the reward formulae and in particular to minimising its length."@en ;
    askg-onto:inSentence "In all cases, attention should be paid to the syntax of the reward formulae and in particular to minimising its length."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attention,
        askg-data:Entity-length,
        askg-data:Entity-reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-46-Paragraph-461-Sentence-4616 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Indeed, as could be expected, we found the syntax of the formulae and the type of non-Markovian reward they encode to be a predominant factor in determining the difficulty of the problem, much more **so than the features of the** Markovian dynamics of the domain."@en ;
    askg-onto:inSentence "Indeed, as could be expected, we found the syntax of the formulae and the type of non-Markovian reward they encode to be a predominant factor in determining the difficulty of the problem, much more **so than the features of the** Markovian dynamics of the domain."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-difficulty_of_the_problem,
        askg-data:Entity-domain,
        askg-data:Entity-markovian_dynamics,
        askg-data:Entity-non-markovian_reward,
        askg-data:Entity-syntax_of_the_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-47 a askg-onto:Section ;
    rdfs:label "Section 47"@en ;
    domo:Text "6. A Concrete Example"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4710,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4711,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4712,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4714,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4715,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4716,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4717,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4720,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4721,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4722,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4723,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-473,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-476,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-477,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-478,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-479 ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Our experiments have so far focused on artificial problems and have aimed at characterising the strengths and weaknesses of the various approaches. We now look at a concrete example in order to give a sense of the size of more interesting problems that these techniques can solve. Our example is derived from the Miconic elevator classical planning benchmark (Koehler & Schuster, 2000). An elevator must get a number of passengers from their **origin** floor to their destination. Initially, the elevator is at **some arbitrary floor and no passenger** is served nor has boarded **the elevator. In our version of the problem, there is one single** action which causes the elevator to service **a given floor, with the effect that the unserved** passengers whose origin is the serviced floor board the elevator, while the boarded passengers whose destination is the serviced floor unboard and become served. The task is to plan the elevator movement so that all passengers are eventually served.14 There are two variants of Miconic. In the 'simple' variant, a **reward is received each** time a passenger becomes served. In the 'hard' variant, the elevator also attempts to provide a range of priority services to passengers with special requirements: many passengers will prefer travelling in a single direction (either up or down) to their destination, certain passengers might be offered non-stop travel to their destination, and finally, passengers with disabilities or young children should be supervised inside the elevator by some other passenger (the supervisor) assigned to them. Here we omit the VIP and conflicting group services present in the original hard Miconic problem, as the reward formulae for those do not create additional difficulties."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4711,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-47110,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4712,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4713,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4714,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4715,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4716,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4717,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4718,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4719 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our experiments have so far focused on artificial problems and have aimed at characterising the strengths and weaknesses of the various approaches."@en ;
    askg-onto:inSentence "Our experiments have so far focused on artificial problems and have aimed at characterising the strengths and weaknesses of the various approaches."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-artificial_problems,
        askg-data:Entity-experiments,
        askg-data:Entity-strengths_and_weaknesses .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-47110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Here we omit the VIP and conflicting group services present in the original hard Miconic problem, as the reward formulae for those do not create additional difficulties."@en ;
    askg-onto:inSentence "Here we omit the VIP and conflicting group services present in the original hard Miconic problem, as the reward formulae for those do not create additional difficulties."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-miconic_problem,
        askg-data:Entity-vip_and_conflicting_group_services .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We now look at a concrete example in order to give a sense of the size of more interesting problems that these techniques can solve."@en ;
    askg-onto:inSentence "We now look at a concrete example in order to give a sense of the size of more interesting problems that these techniques can solve."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-problems,
        askg-data:Entity-techniques .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our example is derived from the Miconic elevator classical planning benchmark (Koehler & Schuster, 2000)."@en ;
    askg-onto:inSentence "Our example is derived from the Miconic elevator classical planning benchmark (Koehler & Schuster, 2000)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-koehler__schuster_2000,
        askg-data:Entity-miconic_elevator_classical_planning_benchmark .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "An elevator must get a number of passengers from their **origin** floor to their destination."@en ;
    askg-onto:inSentence "An elevator must get a number of passengers from their **origin** floor to their destination."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-destination,
        askg-data:Entity-elevator,
        askg-data:Entity-origin_floor,
        askg-data:Entity-passengers .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Initially, the elevator is at **some arbitrary floor and no passenger** is served nor has boarded **the elevator."@en ;
    askg-onto:inSentence "Initially, the elevator is at **some arbitrary floor and no passenger** is served nor has boarded **the elevator."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elevator,
        askg-data:Entity-passenger,
        askg-data:Entity-some_arbitrary_floor .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4716 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In our version of the problem, there is one single** action which causes the elevator to service **a given floor, with the effect that the unserved** passengers whose origin is the serviced floor board the elevator, while the boarded passengers whose destination is the serviced floor unboard and become served."@en ;
    askg-onto:inSentence "In our version of the problem, there is one single** action which causes the elevator to service **a given floor, with the effect that the unserved** passengers whose origin is the serviced floor board the elevator, while the boarded passengers whose destination is the serviced floor unboard and become served."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elevator,
        askg-data:Entity-floor,
        askg-data:Entity-passengers .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4717 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The task is to plan the elevator movement so that all passengers are eventually served.14 There are two variants of Miconic."@en ;
    askg-onto:inSentence "The task is to plan the elevator movement so that all passengers are eventually served.14 There are two variants of Miconic."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elevator_movement_planning,
        askg-data:Entity-miconic .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4718 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In the 'simple' variant, a **reward is received each** time a passenger becomes served."@en ;
    askg-onto:inSentence "In the 'simple' variant, a **reward is received each** time a passenger becomes served."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-passenger,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-471-Sentence-4719 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In the 'hard' variant, the elevator also attempts to provide a range of priority services to passengers with special requirements: many passengers will prefer travelling in a single direction (either up or down) to their destination, certain passengers might be offered non-stop travel to their destination, and finally, passengers with disabilities or young children should be supervised inside the elevator by some other passenger (the supervisor) assigned to them."@en ;
    askg-onto:inSentence "In the 'hard' variant, the elevator also attempts to provide a range of priority services to passengers with special requirements: many passengers will prefer travelling in a single direction (either up or down) to their destination, certain passengers might be offered non-stop travel to their destination, and finally, passengers with disabilities or young children should be supervised inside the elevator by some other passenger (the supervisor) assigned to them."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elevator,
        askg-data:Entity-non-stop_travel,
        askg-data:Entity-passengers,
        askg-data:Entity-passengers_with_disabilities_or_young_children,
        askg-data:Entity-special_requirements,
        askg-data:Entity-supervisor,
        askg-data:Entity-travelling_in_a_single_direction .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4710 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "![40_image_1.png](40_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4710-Sentence-47101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4710-Sentence-47101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![40_image_1.png](40_image_1.png)"@en ;
    askg-onto:inSentence "![40_image_1.png](40_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-data_collection,
        askg-data:Entity-interviews,
        askg-data:Entity-psychology,
        askg-data:Entity-qualitative_research,
        askg-data:Entity-research_methodology,
        askg-data:Entity-research_methods,
        askg-data:Entity-social_sciences .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4711 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "![40_image_2.png](40_image_2.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4711-Sentence-47111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4711-Sentence-47111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![40_image_2.png](40_image_2.png)"@en ;
    askg-onto:inSentence "![40_image_2.png](40_image_2.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-40_image_2png,
        askg-data:Entity-image .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4712 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "Figure 20: Simple Miconic - Number of Expanded States"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4712-Sentence-47121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4712-Sentence-47121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 20: Simple Miconic - Number of Expanded States"@en ;
    askg-onto:inSentence "Figure 20: Simple Miconic - Number of Expanded States"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-miconic,
        askg-data:Entity-model,
        askg-data:Entity-number_of_expanded_states,
        askg-data:Entity-simple_miconic .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "formulae relevant to the passengers that still need to be served, the other formulae having progressed to ⊤. The gain in number of expanded states materialises into run **time gains,** resulting in fltl **eventually taking the lead.** Our second experiment illustrates the benefits of using an even extremely simple admissible heuristic in conjunction with fltl**. Our heuristic is applicable to discounted stochastic** shortest path problems, and discounts rewards by the shortest time in the future in which they are possible. Here it simply amounts to assigning a fringe state to a value of 50 times the number of still unserved passengers (discounted once), **and results in avoiding floors at** which no passenger is waiting and which are not the destination of a boarded passenger. Figures 21 and 22 compare the run time and number of states expanded by fltl **when used** in conjunction with value iteration (valIt) to when it is used in conjunction with an LAO*"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47131,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47132,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47133,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47134,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47135 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "formulae relevant to the passengers that still need to be served, the other formulae having progressed to ⊤."@en ;
    askg-onto:inSentence "formulae relevant to the passengers that still need to be served, the other formulae having progressed to ⊤."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-passengers .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The gain in number of expanded states materialises into run **time gains,** resulting in fltl **eventually taking the lead.** Our second experiment illustrates the benefits of using an even extremely simple admissible heuristic in conjunction with fltl**."@en ;
    askg-onto:inSentence "The gain in number of expanded states materialises into run **time gains,** resulting in fltl **eventually taking the lead.** Our second experiment illustrates the benefits of using an even extremely simple admissible heuristic in conjunction with fltl**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-run_time_gains,
        askg-data:Entity-second_experiment,
        askg-data:Entity-simple_admissible_heuristic .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our heuristic is applicable to discounted stochastic** shortest path problems, and discounts rewards by the shortest time in the future in which they are possible."@en ;
    askg-onto:inSentence "Our heuristic is applicable to discounted stochastic** shortest path problems, and discounts rewards by the shortest time in the future in which they are possible."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-discounted_stochastic_shortest_path_problems,
        askg-data:Entity-discounts_rewards,
        askg-data:Entity-heuristic,
        askg-data:Entity-the_shortest_time_in_the_future .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Here it simply amounts to assigning a fringe state to a value of 50 times the number of still unserved passengers (discounted once), **and results in avoiding floors at** which no passenger is waiting and which are not the destination of a boarded passenger."@en ;
    askg-onto:inSentence "Here it simply amounts to assigning a fringe state to a value of 50 times the number of still unserved passengers (discounted once), **and results in avoiding floors at** which no passenger is waiting and which are not the destination of a boarded passenger."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-passengers,
        askg-data:Entity-which_no_passenger_is_waiting .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4713-Sentence-47135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Figures 21 and 22 compare the run time and number of states expanded by fltl **when used** in conjunction with value iteration (valIt) to when it is used in conjunction with an LAO*"@en ;
    askg-onto:inSentence "Figures 21 and 22 compare the run time and number of states expanded by fltl **when used** in conjunction with value iteration (valIt) to when it is used in conjunction with an LAO*"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-lao,
        askg-data:Entity-value_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4714 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "![41_image_0.png](41_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4714-Sentence-47141 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4714-Sentence-47141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![41_image_0.png](41_image_0.png)"@en ;
    askg-onto:inSentence "![41_image_0.png](41_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4715 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Figure 21: Effect of a Simple Heuristic on Run Time"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4715-Sentence-47151 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4715-Sentence-47151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 21: Effect of a Simple Heuristic on Run Time"@en ;
    askg-onto:inSentence "Figure 21: Effect of a Simple Heuristic on Run Time"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristic,
        askg-data:Entity-run_time .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4716 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "![41_image_1.png](41_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4716-Sentence-47161 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4716-Sentence-47161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![41_image_1.png](41_image_1.png)"@en ;
    askg-onto:inSentence "![41_image_1.png](41_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article_on_neural_networks,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-bert,
        askg-data:Entity-computer_science,
        askg-data:Entity-covid-19,
        askg-data:Entity-data_science,
        askg-data:Entity-deep_learning,
        askg-data:Entity-disease,
        askg-data:Entity-graph_neural_networks,
        askg-data:Entity-john_doe,
        askg-data:Entity-machine_learning,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-neural_networks,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-stanford_university,
        askg-data:Entity-tensorflow .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4717 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "Figure 22: Effect of a Simple Heuristic on the Number of Expanded States"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4717-Sentence-47171 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4717-Sentence-47171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 22: Effect of a Simple Heuristic on the Number of Expanded States"@en ;
    askg-onto:inSentence "Figure 22: Effect of a Simple Heuristic on the Number of Expanded States"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-number_of_expanded_states,
        askg-data:Entity-simple_heuristic .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "search informed by the above heuristic (LAO(h)). Uninformed LAO* (LAO*(u), i.e. LAO* with a heuristic of 50 ∗ n **at each node) is also included as a reference point to show the** overhead induced by heuristic search. As can be seen from the **graphs, the heuristic search** generates significantly fewer states and this eventually pays in terms of run time."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47181,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47182,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47183,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47184 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "search informed by the above heuristic (LAO(h))."@en ;
    askg-onto:inSentence "search informed by the above heuristic (LAO(h))."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristic,
        askg-data:Entity-laoh .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Uninformed LAO* (LAO*(u), i.e."@en ;
    askg-onto:inSentence "Uninformed LAO* (LAO*(u), i.e."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-uninformed_lao .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "LAO* with a heuristic of 50 ∗ n **at each node) is also included as a reference point to show the** overhead induced by heuristic search."@en ;
    askg-onto:inSentence "LAO* with a heuristic of 50 ∗ n **at each node) is also included as a reference point to show the** overhead induced by heuristic search."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristic_search,
        askg-data:Entity-lao .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4718-Sentence-47184 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As can be seen from the **graphs, the heuristic search** generates significantly fewer states and this eventually pays in terms of run time."@en ;
    askg-onto:inSentence "As can be seen from the **graphs, the heuristic search** generates significantly fewer states and this eventually pays in terms of run time."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fewer_states,
        askg-data:Entity-heuristic_search .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "In our final experiment, we considered the hard variant, giving a reward of 50 as before for service (1), a reward of 2 for non-stop travel (2), a reward of 5 for appropriate supervision (3), and a reward of 10 for direct travel (2). Regardless of the number n **of floors and** passengers, problems only feature a single non-stop traveller, a third of passengers require supervision, and only half the passengers care about traveling direct. CPU time and number of states expanded are shown in Figures 23 and 24, respectively. As in the simple case, pltlsim and pltlstr quickly run out of memory. Formulae of type (2) and (3) create too many additional variables to track for these approaches, and the problem does not seem"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47191,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47192,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47193,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47194,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47195 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In our final experiment, we considered the hard variant, giving a reward of 50 as before for service (1), a reward of 2 for non-stop travel (2), a reward of 5 for appropriate supervision (3), and a reward of 10 for direct travel (2)."@en ;
    askg-onto:inSentence "In our final experiment, we considered the hard variant, giving a reward of 50 as before for service (1), a reward of 2 for non-stop travel (2), a reward of 5 for appropriate supervision (3), and a reward of 10 for direct travel (2)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-10,
        askg-data:Entity-2,
        askg-data:Entity-5,
        askg-data:Entity-50,
        askg-data:Entity-appropriate_supervision,
        askg-data:Entity-direct_travel,
        askg-data:Entity-experiment,
        askg-data:Entity-final_experiment,
        askg-data:Entity-non-stop_travel,
        askg-data:Entity-service .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Regardless of the number n **of floors and** passengers, problems only feature a single non-stop traveller, a third of passengers require supervision, and only half the passengers care about traveling direct."@en ;
    askg-onto:inSentence "Regardless of the number n **of floors and** passengers, problems only feature a single non-stop traveller, a third of passengers require supervision, and only half the passengers care about traveling direct."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-passengers,
        askg-data:Entity-supervision,
        askg-data:Entity-traveling_direct .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47193 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "CPU time and number of states expanded are shown in Figures 23 and 24, respectively."@en ;
    askg-onto:inSentence "CPU time and number of states expanded are shown in Figures 23 and 24, respectively."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cpu_time,
        askg-data:Entity-number_of_states_expanded .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47194 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As in the simple case, pltlsim and pltlstr quickly run out of memory."@en ;
    askg-onto:inSentence "As in the simple case, pltlsim and pltlstr quickly run out of memory."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-memory,
        askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstr .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4719-Sentence-47195 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Formulae of type (2) and (3) create too many additional variables to track for these approaches, and the problem does not seem"@en ;
    askg-onto:inSentence "Formulae of type (2) and (3) create too many additional variables to track for these approaches, and the problem does not seem"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_variables,
        askg-data:Entity-formulae_of_type_2_and_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Our formulation of the problem makes use of the same propositions as the PDDL description of Miconic used in the 2000 International Planning Competition: dynamic propositions record the floor the elevator is currently at and whether passengers are served or boarded, and static propositions record the origin and destination floors of passengers, as well as the categories (non-stop, direct-travel, supervisor, supervised) the passengers fall in. However, our formulation differs from the PDDL description in two interesting ways. Firstly, since we use rewards instead of goals, we are able to find a preferred solution even **when all** goals cannot simultaneously be satisfied. Secondly, because priority services are naturally described in terms of non-Markovian rewards, we are able to use the same action description for both the simple and hard versions, whereas the PDDL description of hard miconic requires additional actions (up, down) and complex preconditions to monitor the satisfaction of priority service constraints. The reward schemes for Miconic can be encapsulated through four different types of reward formula."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4721,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4722,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4723,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4724,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4725 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our formulation of the problem makes use of the same propositions as the PDDL description of Miconic used in the 2000 International Planning Competition: dynamic propositions record the floor the elevator is currently at and whether passengers are served or boarded, and static propositions record the origin and destination floors of passengers, as well as the categories (non-stop, direct-travel, supervisor, supervised) the passengers fall in."@en ;
    askg-onto:inSentence "Our formulation of the problem makes use of the same propositions as the PDDL description of Miconic used in the 2000 International Planning Competition: dynamic propositions record the floor the elevator is currently at and whether passengers are served or boarded, and static propositions record the origin and destination floors of passengers, as well as the categories (non-stop, direct-travel, supervisor, supervised) the passengers fall in."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-categories,
        askg-data:Entity-direct-travel,
        askg-data:Entity-dynamic_propositions,
        askg-data:Entity-floor,
        askg-data:Entity-miconic,
        askg-data:Entity-non-stop,
        askg-data:Entity-origin_and_destination_floors,
        askg-data:Entity-passengers,
        askg-data:Entity-passengers_served_or_boarded,
        askg-data:Entity-pddl,
        askg-data:Entity-static_propositions,
        askg-data:Entity-supervised,
        askg-data:Entity-supervisor .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, our formulation differs from the PDDL description in two interesting ways."@en ;
    askg-onto:inSentence "However, our formulation differs from the PDDL description in two interesting ways."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_formulation,
        askg-data:Entity-the_pddl_description .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Firstly, since we use rewards instead of goals, we are able to find a preferred solution even **when all** goals cannot simultaneously be satisfied."@en ;
    askg-onto:inSentence "Firstly, since we use rewards instead of goals, we are able to find a preferred solution even **when all** goals cannot simultaneously be satisfied."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goals,
        askg-data:Entity-goals_cannot_simultaneously_be_satisfied,
        askg-data:Entity-rewards,
        askg-data:Entity-solution .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Secondly, because priority services are naturally described in terms of non-Markovian rewards, we are able to use the same action description for both the simple and hard versions, whereas the PDDL description of hard miconic requires additional actions (up, down) and complex preconditions to monitor the satisfaction of priority service constraints."@en ;
    askg-onto:inSentence "Secondly, because priority services are naturally described in terms of non-Markovian rewards, we are able to use the same action description for both the simple and hard versions, whereas the PDDL description of hard miconic requires additional actions (up, down) and complex preconditions to monitor the satisfaction of priority service constraints."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_actions_up_down,
        askg-data:Entity-complex_preconditions,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-pddl_description_of_hard_miconic,
        askg-data:Entity-priority_service_constraints,
        askg-data:Entity-priority_services .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-472-Sentence-4725 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The reward schemes for Miconic can be encapsulated through four different types of reward formula."@en ;
    askg-onto:inSentence "The reward schemes for Miconic can be encapsulated through four different types of reward formula."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-miconic,
        askg-data:Entity-reward_schemes .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4720 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "![42_image_0.png](42_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4720-Sentence-47201 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4720-Sentence-47201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![42_image_0.png](42_image_0.png)"@en ;
    askg-onto:inSentence "![42_image_0.png](42_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company,
        askg-data:Entity-deep_learning,
        askg-data:Entity-domain,
        askg-data:Entity-health_informatics,
        askg-data:Entity-ibm_watson,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-openai,
        askg-data:Entity-research_field,
        askg-data:Entity-research_on_ai_in_healthcare,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4721 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 21"@en ;
    domo:Text "Figure 23: Hard Miconic - Run Time"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4721-Sentence-47211 ;
    askg-onto:index "21"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4721-Sentence-47211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 23: Hard Miconic - Run Time"@en ;
    askg-onto:inSentence "Figure 23: Hard Miconic - Run Time"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hard_miconic,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4722 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 22"@en ;
    domo:Text "![42_image_1.png](42_image_1.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4722-Sentence-47221 ;
    askg-onto:index "22"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4722-Sentence-47221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![42_image_1.png](42_image_1.png)"@en ;
    askg-onto:inSentence "![42_image_1.png](42_image_1.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-classification_problems,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-data_augmentation,
        askg-data:Entity-datasets,
        askg-data:Entity-deep_learning,
        askg-data:Entity-image_classification,
        askg-data:Entity-image_recognition,
        askg-data:Entity-imagenet,
        askg-data:Entity-machine_learning,
        askg-data:Entity-openai,
        askg-data:Entity-pytorch,
        askg-data:Entity-support_vector_machines,
        askg-data:Entity-tensorflow,
        askg-data:Entity-uci_machine_learning_repository .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4723 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 23"@en ;
    domo:Text "Figure 24: Hard Miconic - Number of Expanded States"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4723-Sentence-47231 ;
    askg-onto:index "23"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4723-Sentence-47231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 24: Hard Miconic - Number of Expanded States"@en ;
    askg-onto:inSentence "Figure 24: Hard Miconic - Number of Expanded States"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hard_miconic,
        askg-data:Entity-model,
        askg-data:Entity-number_of_expanded_states .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 24"@en ;
    domo:Text "to exhibit enough structure to help pltlstr. fltl **remains the fastest. Here, this does** not seem to be so much due to the size of the generated MDP which **is just slightly below** that of the pltlmin **MDP, but rather to the overhead incurred by minimisation. Another** observation arising from this experiment is that only very small instances can be handled in comparison to the classical planning version of the problem solved by state of the art optimal classical planners. For example, at the 2000 International Planning Competition, the PropPlan planner (Fourman, 2000) optimally solved instances of hard **Miconic with** 20 passengers and 40 floors in about 1000 seconds on a much less **powerful machine.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47241,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47242,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47243,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47244,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47245 ;
    askg-onto:index "24"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "to exhibit enough structure to help pltlstr."@en ;
    askg-onto:inSentence "to exhibit enough structure to help pltlstr."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-structure .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "fltl **remains the fastest."@en ;
    askg-onto:inSentence "fltl **remains the fastest."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-the_fastest .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47243 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Here, this does** not seem to be so much due to the size of the generated MDP which **is just slightly below** that of the pltlmin **MDP, but rather to the overhead incurred by minimisation."@en ;
    askg-onto:inSentence "Here, this does** not seem to be so much due to the size of the generated MDP which **is just slightly below** that of the pltlmin **MDP, but rather to the overhead incurred by minimisation."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-minimisation,
        askg-data:Entity-overhead,
        askg-data:Entity-pltlmin_mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47244 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Another** observation arising from this experiment is that only very small instances can be handled in comparison to the classical planning version of the problem solved by state of the art optimal classical planners."@en ;
    askg-onto:inSentence "Another** observation arising from this experiment is that only very small instances can be handled in comparison to the classical planning version of the problem solved by state of the art optimal classical planners."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classical_planning_version,
        askg-data:Entity-experiment,
        askg-data:Entity-observation,
        askg-data:Entity-state_of_the_art_optimal_classical_planners .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-4724-Sentence-47245 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For example, at the 2000 International Planning Competition, the PropPlan planner (Fourman, 2000) optimally solved instances of hard **Miconic with** 20 passengers and 40 floors in about 1000 seconds on a much less **powerful machine.**"@en ;
    askg-onto:inSentence "For example, at the 2000 International Planning Competition, the PropPlan planner (Fourman, 2000) optimally solved instances of hard **Miconic with** 20 passengers and 40 floors in about 1000 seconds on a much less **powerful machine.**"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-20_passengers,
        askg-data:Entity-40_floors,
        askg-data:Entity-miconic,
        askg-data:Entity-much_less_powerful_machine,
        askg-data:Entity-propplan_planner .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-473 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "1. In the simple variant, a reward is received the first time each passenger Pi**is served:**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-473-Sentence-4731,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-473-Sentence-4732 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-473-Sentence-4731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1."@en ;
    askg-onto:inSentence "1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company,
        askg-data:Entity-dataset,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-paper,
        askg-data:Entity-person,
        askg-data:Entity-research_field,
        askg-data:Entity-system,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-473-Sentence-4732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the simple variant, a reward is received the first time each passenger Pi**is served:**"@en ;
    askg-onto:inSentence "In the simple variant, a reward is received the first time each passenger Pi**is served:**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-passenger,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "14. We have experimented with stochastic variants of Miconic where passengers have some small probability of desembarking at the wrong floor. However, we find it more useful to present results for the deterministic version since it is closer to the Miconic deterministic planning benchmark and since, as we have shown before, rewards have a far more crucial impact than dynamics **on the relative performance of the methods.** PLTL: **ServedP**i ∧ ⊖ ⊟ ¬**ServedP**i $FLTL: ¬ServedPi U(**ServedP**i ∧ $) 2. Next, a reward is received each time a non-stop passenger Pi**is served in one step** after boarding the elevator: PLTL: **NonStopP**i ∧ ⊖ ⊖ ¬**BoardedP**i ∧ ⊖ ⊖ ¬ServedPi ∧ **ServedP**i $FLTL: ((NonStopPi ∧ ¬BoardedPi ∧ ¬ServedPi ∧ **ServedP**i) → $) 3. Then, a reward is received each time a supervised passenger Pi**is served while having** been accompanied at all times inside the elevator by his supervisor15 Pj : PLTL: SupervisedPi ∧ SupervisorPjPi ∧ **ServedP**i∧ ⊖ ⊟ ¬ServedPi ∧ ⊟(BoardedPi → **BoardedP**j ) $FLTL: ¬ServedPi U((BoardedPi ∧ SupervisedPi ∧ ¬(BoardedPj ∧ **SupervisorP**jPi)∧ ¬ServedPi) ∨ (ServededPi ∧ $)) 4. Finally, reward is received each time a direct travel passenger Pi**is served while having** travelled only in one direction since boarding, e.g., in the **case of going up:** PLTL: DirectPi ∧ ServedPi ∧ ⊖¬**ServedP**i∧ ((Wj Wk>j (AtFloork ∧ ⊖AtFloorj )) S (BoardedPi ∧ ⊖¬**BoardedP**i)) $FLTL: ((DirectPi ∧ BoardedPi) → (¬**ServedP**i U((¬(Wj Wk>i AtFloorj ∧ **AtFloor**k)∧ ¬ServedPi) ∨ (servedPi ∧ **$))))** and similarly in the case of going down."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4741,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4742,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4743,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4744,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4745,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4746 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "14."@en ;
    askg-onto:inSentence "14."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ai_solutions,
        askg-data:Entity-algorithm,
        askg-data:Entity-company,
        askg-data:Entity-data_analysis,
        askg-data:Entity-data_science,
        askg-data:Entity-data_visualization,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-hypothesis,
        askg-data:Entity-machine_learning_techniques,
        askg-data:Entity-method,
        askg-data:Entity-paper,
        askg-data:Entity-predictive_modeling,
        askg-data:Entity-research_field,
        askg-data:Entity-research_in_ai,
        askg-data:Entity-tool,
        askg-data:Entity-training_data,
        askg-data:Entity-university .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4742 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We have experimented with stochastic variants of Miconic where passengers have some small probability of desembarking at the wrong floor."@en ;
    askg-onto:inSentence "We have experimented with stochastic variants of Miconic where passengers have some small probability of desembarking at the wrong floor."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-disembarking_at_the_wrong_floor,
        askg-data:Entity-miconic,
        askg-data:Entity-passengers,
        askg-data:Entity-stochastic_variants .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4743 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "However, we find it more useful to present results for the deterministic version since it is closer to the Miconic deterministic planning benchmark and since, as we have shown before, rewards have a far more crucial impact than dynamics **on the relative performance of the methods.** PLTL: **ServedP**i ∧ ⊖ ⊟ ¬**ServedP**i $FLTL: ¬ServedPi U(**ServedP**i ∧ $) 2."@en ;
    askg-onto:inSentence "However, we find it more useful to present results for the deterministic version since it is closer to the Miconic deterministic planning benchmark and since, as we have shown before, rewards have a far more crucial impact than dynamics **on the relative performance of the methods.** PLTL: **ServedP**i ∧ ⊖ ⊟ ¬**ServedP**i $FLTL: ¬ServedPi U(**ServedP**i ∧ $) 2."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deterministic_version,
        askg-data:Entity-miconic_deterministic_planning_benchmark,
        askg-data:Entity-relative_performance_of_the_methods,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4744 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Next, a reward is received each time a non-stop passenger Pi**is served in one step** after boarding the elevator: PLTL: **NonStopP**i ∧ ⊖ ⊖ ¬**BoardedP**i ∧ ⊖ ⊖ ¬ServedPi ∧ **ServedP**i $FLTL: ((NonStopPi ∧ ¬BoardedPi ∧ ¬ServedPi ∧ **ServedP**i) → $) 3."@en ;
    askg-onto:inSentence "Next, a reward is received each time a non-stop passenger Pi**is served in one step** after boarding the elevator: PLTL: **NonStopP**i ∧ ⊖ ⊖ ¬**BoardedP**i ∧ ⊖ ⊖ ¬ServedPi ∧ **ServedP**i $FLTL: ((NonStopPi ∧ ¬BoardedPi ∧ ¬ServedPi ∧ **ServedP**i) → $) 3."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-boardedp,
        askg-data:Entity-nonstopp,
        askg-data:Entity-passenger,
        askg-data:Entity-reward,
        askg-data:Entity-servedp,
        askg-data:Entity-servedpi .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4745 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Then, a reward is received each time a supervised passenger Pi**is served while having** been accompanied at all times inside the elevator by his supervisor15 Pj : PLTL: SupervisedPi ∧ SupervisorPjPi ∧ **ServedP**i∧ ⊖ ⊟ ¬ServedPi ∧ ⊟(BoardedPi → **BoardedP**j ) $FLTL: ¬ServedPi U((BoardedPi ∧ SupervisedPi ∧ ¬(BoardedPj ∧ **SupervisorP**jPi)∧ ¬ServedPi) ∨ (ServededPi ∧ $)) 4."@en ;
    askg-onto:inSentence "Then, a reward is received each time a supervised passenger Pi**is served while having** been accompanied at all times inside the elevator by his supervisor15 Pj : PLTL: SupervisedPi ∧ SupervisorPjPi ∧ **ServedP**i∧ ⊖ ⊟ ¬ServedPi ∧ ⊟(BoardedPi → **BoardedP**j ) $FLTL: ¬ServedPi U((BoardedPi ∧ SupervisedPi ∧ ¬(BoardedPj ∧ **SupervisorP**jPi)∧ ¬ServedPi) ∨ (ServededPi ∧ $)) 4."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-passenger_pi,
        askg-data:Entity-supervisor_pj .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-474-Sentence-4746 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Finally, reward is received each time a direct travel passenger Pi**is served while having** travelled only in one direction since boarding, e.g., in the **case of going up:** PLTL: DirectPi ∧ ServedPi ∧ ⊖¬**ServedP**i∧ ((Wj Wk>j (AtFloork ∧ ⊖AtFloorj )) S (BoardedPi ∧ ⊖¬**BoardedP**i)) $FLTL: ((DirectPi ∧ BoardedPi) → (¬**ServedP**i U((¬(Wj Wk>i AtFloorj ∧ **AtFloor**k)∧ ¬ServedPi) ∨ (servedPi ∧ **$))))** and similarly in the case of going down."@en ;
    askg-onto:inSentence "Finally, reward is received each time a direct travel passenger Pi**is served while having** travelled only in one direction since boarding, e.g., in the **case of going up:** PLTL: DirectPi ∧ ServedPi ∧ ⊖¬**ServedP**i∧ ((Wj Wk>j (AtFloork ∧ ⊖AtFloorj )) S (BoardedPi ∧ ⊖¬**BoardedP**i)) $FLTL: ((DirectPi ∧ BoardedPi) → (¬**ServedP**i U((¬(Wj Wk>i AtFloorj ∧ **AtFloor**k)∧ ¬ServedPi) ∨ (servedPi ∧ **$))))** and similarly in the case of going down."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-atfloorj,
        askg-data:Entity-atfloork,
        askg-data:Entity-boardedp,
        askg-data:Entity-boardedpi,
        askg-data:Entity-directpi,
        askg-data:Entity-fltl,
        askg-data:Entity-j,
        askg-data:Entity-one_direction,
        askg-data:Entity-pi,
        askg-data:Entity-pltl,
        askg-data:Entity-servedp,
        askg-data:Entity-servedpi,
        askg-data:Entity-wj_wk .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Experiments in this section were run on a Dual Pentium4 3.4GHz GNU/Linux 2.6.11 machine with 1GB of ram. We first experimented with the simple **variant, giving a reward** of 50 each time a passenger is first served. Figure 19 shows the **CPU time taken by the** various approaches to solve random problems with an increasing number n **of floors and** passengers, and Figure 20 shows the number of states expanded when doing so. Each data point corresponds to just one random problem. To be fair with **the structured approach, we** ran pltlstr(a) which is able to exploit reachability from the start state. A **first observation** is that although pltlstr(a) does best for small values of n**, it quickly runs out of memory.** pltlstr(a) and pltlsim **both need to track formulae of the form** ⊖ ⊟ ¬ServedPi **while** pltlsim **does not, and we conjecture that this is why they run out of memory earlier. A** second observation is that attempts at PLTL minimisation do **not pay very much here.** While pltlmin has reduced memory because it tracks fewer subformulae, the **size of the** MDP it produces is identical to the size of the pltlsim **MDP and larger than that of the** fltl **MDP. This size increase is due to the fact that PLTL approaches label differently** e-states in which the same passengers are served, depending **on who has just become served** (for those passengers, the reward formula is true at the e-state). In contrast, our **fltl** implementation with progression one step ahead labels all these e-states with the reward"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4751,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4752,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4753,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4754,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4755,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4756,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4757,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4758,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4759 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Experiments in this section were run on a Dual Pentium4 3.4GHz GNU/Linux 2.6.11 machine with 1GB of ram."@en ;
    askg-onto:inSentence "Experiments in this section were run on a Dual Pentium4 3.4GHz GNU/Linux 2.6.11 machine with 1GB of ram."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1gb_of_ram,
        askg-data:Entity-dual_pentium4_34ghz,
        askg-data:Entity-equipment,
        askg-data:Entity-gnulinux_2611,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4752 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We first experimented with the simple **variant, giving a reward** of 50 each time a passenger is first served."@en ;
    askg-onto:inSentence "We first experimented with the simple **variant, giving a reward** of 50 each time a passenger is first served."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-50_each_time_a_passenger_is_first_served,
        askg-data:Entity-variant .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4753 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Figure 19 shows the **CPU time taken by the** various approaches to solve random problems with an increasing number n **of floors and** passengers, and Figure 20 shows the number of states expanded when doing so."@en ;
    askg-onto:inSentence "Figure 19 shows the **CPU time taken by the** various approaches to solve random problems with an increasing number n **of floors and** passengers, and Figure 20 shows the number of states expanded when doing so."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cpu_time,
        askg-data:Entity-number_n_of_floors_and_passengers,
        askg-data:Entity-number_of_states_expanded,
        askg-data:Entity-random_problems,
        askg-data:Entity-various_approaches .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4754 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Each data point corresponds to just one random problem."@en ;
    askg-onto:inSentence "Each data point corresponds to just one random problem."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_point,
        askg-data:Entity-random_problem .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4755 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To be fair with **the structured approach, we** ran pltlstr(a) which is able to exploit reachability from the start state."@en ;
    askg-onto:inSentence "To be fair with **the structured approach, we** ran pltlstr(a) which is able to exploit reachability from the start state."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstra,
        askg-data:Entity-the_structured_approach .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4756 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "A **first observation** is that although pltlstr(a) does best for small values of n**, it quickly runs out of memory.** pltlstr(a) and pltlsim **both need to track formulae of the form** ⊖ ⊟ ¬ServedPi **while** pltlsim **does not, and we conjecture that this is why they run out of memory earlier."@en ;
    askg-onto:inSentence "A **first observation** is that although pltlstr(a) does best for small values of n**, it quickly runs out of memory.** pltlstr(a) and pltlsim **both need to track formulae of the form** ⊖ ⊟ ¬ServedPi **while** pltlsim **does not, and we conjecture that this is why they run out of memory earlier."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae_of_the_form___servedpi,
        askg-data:Entity-memory,
        askg-data:Entity-memory_earlier,
        askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstra,
        askg-data:Entity-pltlstra_and_pltlsim,
        askg-data:Entity-small_values_of_n .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4757 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "A** second observation is that attempts at PLTL minimisation do **not pay very much here.** While pltlmin has reduced memory because it tracks fewer subformulae, the **size of the** MDP it produces is identical to the size of the pltlsim **MDP and larger than that of the** fltl **MDP."@en ;
    askg-onto:inSentence "A** second observation is that attempts at PLTL minimisation do **not pay very much here.** While pltlmin has reduced memory because it tracks fewer subformulae, the **size of the** MDP it produces is identical to the size of the pltlsim **MDP and larger than that of the** fltl **MDP."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_mdp,
        askg-data:Entity-mdp,
        askg-data:Entity-memory,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlsim_mdp,
        askg-data:Entity-subformulae .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4758 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "This size increase is due to the fact that PLTL approaches label differently** e-states in which the same passengers are served, depending **on who has just become served** (for those passengers, the reward formula is true at the e-state)."@en ;
    askg-onto:inSentence "This size increase is due to the fact that PLTL approaches label differently** e-states in which the same passengers are served, depending **on who has just become served** (for those passengers, the reward formula is true at the e-state)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-e-states,
        askg-data:Entity-passengers,
        askg-data:Entity-pltl_approaches,
        askg-data:Entity-reward_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-475-Sentence-4759 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In contrast, our **fltl** implementation with progression one step ahead labels all these e-states with the reward"@en ;
    askg-onto:inSentence "In contrast, our **fltl** implementation with progression one step ahead labels all these e-states with the reward"^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-fltl,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-476 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "15. To understand the $FLTL formula, observe that we get a reward iff (BoardedPi ∧ SupervisedPi) → (BoardedPj∧SupervisorPjPi**) holds until** ServedPi **becomes true, and recall that the formula** ¬q U ((¬p∧ ¬q) ∨ (q ∧ $)) rewards the holding of p **until the occurrence of** q."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-476-Sentence-4761,
        askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-476-Sentence-4762 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-476-Sentence-4761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "15."@en ;
    askg-onto:inSentence "15."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-15,
        askg-data:Entity-triple_15 .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-476-Sentence-4762 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To understand the $FLTL formula, observe that we get a reward iff (BoardedPi ∧ SupervisedPi) → (BoardedPj∧SupervisorPjPi**) holds until** ServedPi **becomes true, and recall that the formula** ¬q U ((¬p∧ ¬q) ∨ (q ∧ $)) rewards the holding of p **until the occurrence of** q."@en ;
    askg-onto:inSentence "To understand the $FLTL formula, observe that we get a reward iff (BoardedPi ∧ SupervisedPi) → (BoardedPj∧SupervisorPjPi**) holds until** ServedPi **becomes true, and recall that the formula** ¬q U ((¬p∧ ¬q) ∨ (q ∧ $)) rewards the holding of p **until the occurrence of** q."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-boardedpi,
        askg-data:Entity-fltl_formula,
        askg-data:Entity-formula,
        askg-data:Entity-p,
        askg-data:Entity-q,
        askg-data:Entity-reward,
        askg-data:Entity-servedpi,
        askg-data:Entity-supervisedpi .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-477 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "![40_image_0.png](40_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-477-Sentence-4771 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-477-Sentence-4771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![40_image_0.png](40_image_0.png)"@en ;
    askg-onto:inSentence "![40_image_0.png](40_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept_e,
        askg-data:Entity-data_points,
        askg-data:Entity-dataset_z,
        askg-data:Entity-experiment_c,
        askg-data:Entity-paper_1,
        askg-data:Entity-person_a,
        askg-data:Entity-research_field_d,
        askg-data:Entity-research_method_x,
        askg-data:Entity-researcher_g,
        askg-data:Entity-study_y,
        askg-data:Entity-tool_b,
        askg-data:Entity-university_f .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-478 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Figure 19: Simple Miconic - Run Time"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-478-Sentence-4781 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-478-Sentence-4781 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 19: Simple Miconic - Run Time"@en ;
    askg-onto:inSentence "Figure 19: Simple Miconic - Run Time"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-simple_miconic,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-479 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "e c ount/ (2^n ) Stat"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-479-Sentence-4791 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-47-Paragraph-479-Sentence-4791 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "e c ount/ (2^n ) Stat"@en ;
    askg-onto:inSentence "e c ount/ (2^n ) Stat"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-metric,
        askg-data:Entity-stat .

askg-data:Paper-c253584c3f1ff2a2-Section-48 a askg-onto:Section ;
    rdfs:label "Section 48"@en ;
    domo:Text "7. Nmrdpp **In The Probabilistic Planning Competition**"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4813,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4814,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4815,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4816,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4822,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4823,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-483,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-486,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-487,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489 ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We now report on the behaviour of nmrdpp in the probabilistic track of the 4th International Planning Competition (IPC-4). Since the competition did not feature non-Markovian rewards, our original motivation in taking part was to further compare the solution methods implemented in nmrdpp in a Markovian **setting. This objective largely underestimated the** challenges raised by merely getting a planner ready for a competition, especially when that competition is the first of its kind. In the end, we decided that successfully preparing nmrdpp to attempt all problems in the competition using one **solution method (and possibly** search control knowledge), would be an honorable result."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4811,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4812,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4813,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4814 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We now report on the behaviour of nmrdpp in the probabilistic track of the 4th International Planning Competition (IPC-4)."@en ;
    askg-onto:inSentence "We now report on the behaviour of nmrdpp in the probabilistic track of the 4th International Planning Competition (IPC-4)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Since the competition did not feature non-Markovian rewards, our original motivation in taking part was to further compare the solution methods implemented in nmrdpp in a Markovian **setting."@en ;
    askg-onto:inSentence "Since the competition did not feature non-Markovian rewards, our original motivation in taking part was to further compare the solution methods implemented in nmrdpp in a Markovian **setting."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-competition,
        askg-data:Entity-markovian_setting,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This objective largely underestimated the** challenges raised by merely getting a planner ready for a competition, especially when that competition is the first of its kind."@en ;
    askg-onto:inSentence "This objective largely underestimated the** challenges raised by merely getting a planner ready for a competition, especially when that competition is the first of its kind."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planner .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-481-Sentence-4814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In the end, we decided that successfully preparing nmrdpp to attempt all problems in the competition using one **solution method (and possibly** search control knowledge), would be an honorable result."@en ;
    askg-onto:inSentence "In the end, we decided that successfully preparing nmrdpp to attempt all problems in the competition using one **solution method (and possibly** search control knowledge), would be an honorable result."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-problems,
        askg-data:Entity-solution_method .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "We decided to enroll nmrdpp **in a control-knowledge mode and in a domain-independent** mode. The only difference between the two modes is that the first uses FLTL search control knowledge written for the known domains as additional input. Our main concern in writing the control knowledge was to achieve a reasonable **compromise between the size** and effectiveness of the formulae. For the blocks world domain, in which the two actions pickup-from and putdown-to had a 25% chance of dropping the block onto the table, the control knowledge we used encoded a variant of the well-known GN1 near-optimal strategy for deterministic blocks world planning (Slaney & Thi´ebaux, 2001): whenever possible, try putting a clear block in its goal position, otherwise put **an arbitrary clear block on** the table. Because blocks get dropped on the table whenever an action fails, and because the success probabilities and rewards are identical across **actions, optimal policies for the** problem are essentially made up of optimal sequences of actions for the deterministic blocks world and there was little need for a more sophisticated strategy.17 **In the colored blocks** world domain, where several blocks can share the same color and the goal only refers to the color of the blocks, the control knowledge selected an arbitrary goal state of the non-colored blocks world consistent with the colored goal specification, and then used the same strategy as for the non-colored blocks world. The performance of this **strategy depends entirely on** the goal-state selected and can therefore be arbitrarily bad."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48101,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48102,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48103,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48104,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48105,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48106 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We decided to enroll nmrdpp **in a control-knowledge mode and in a domain-independent** mode."@en ;
    askg-onto:inSentence "We decided to enroll nmrdpp **in a control-knowledge mode and in a domain-independent** mode."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control-knowledge_mode,
        askg-data:Entity-domain-independent_mode,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The only difference between the two modes is that the first uses FLTL search control knowledge written for the known domains as additional input."@en ;
    askg-onto:inSentence "The only difference between the two modes is that the first uses FLTL search control knowledge written for the known domains as additional input."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_search_control_knowledge,
        askg-data:Entity-input .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48103 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our main concern in writing the control knowledge was to achieve a reasonable **compromise between the size** and effectiveness of the formulae."@en ;
    askg-onto:inSentence "Our main concern in writing the control knowledge was to achieve a reasonable **compromise between the size** and effectiveness of the formulae."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compromise,
        askg-data:Entity-size_and_effectiveness .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48104 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For the blocks world domain, in which the two actions pickup-from and putdown-to had a 25% chance of dropping the block onto the table, the control knowledge we used encoded a variant of the well-known GN1 near-optimal strategy for deterministic blocks world planning (Slaney & Thi´ebaux, 2001): whenever possible, try putting a clear block in its goal position, otherwise put **an arbitrary clear block on** the table."@en ;
    askg-onto:inSentence "For the blocks world domain, in which the two actions pickup-from and putdown-to had a 25% chance of dropping the block onto the table, the control knowledge we used encoded a variant of the well-known GN1 near-optimal strategy for deterministic blocks world planning (Slaney & Thi´ebaux, 2001): whenever possible, try putting a clear block in its goal position, otherwise put **an arbitrary clear block on** the table."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blocks_world_domain,
        askg-data:Entity-domain,
        askg-data:Entity-gn1_near-optimal_strategy,
        askg-data:Entity-paper,
        askg-data:Entity-slaney__thiebaux_2001,
        askg-data:Entity-strategy .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48105 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Because blocks get dropped on the table whenever an action fails, and because the success probabilities and rewards are identical across **actions, optimal policies for the** problem are essentially made up of optimal sequences of actions for the deterministic blocks world and there was little need for a more sophisticated strategy.17 **In the colored blocks** world domain, where several blocks can share the same color and the goal only refers to the color of the blocks, the control knowledge selected an arbitrary goal state of the non-colored blocks world consistent with the colored goal specification, and then used the same strategy as for the non-colored blocks world."@en ;
    askg-onto:inSentence "Because blocks get dropped on the table whenever an action fails, and because the success probabilities and rewards are identical across **actions, optimal policies for the** problem are essentially made up of optimal sequences of actions for the deterministic blocks world and there was little need for a more sophisticated strategy.17 **In the colored blocks** world domain, where several blocks can share the same color and the goal only refers to the color of the blocks, the control knowledge selected an arbitrary goal state of the non-colored blocks world consistent with the colored goal specification, and then used the same strategy as for the non-colored blocks world."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions,
        askg-data:Entity-an_arbitrary_goal_state,
        askg-data:Entity-blocks,
        askg-data:Entity-blocks_world,
        askg-data:Entity-control_knowledge,
        askg-data:Entity-domain,
        askg-data:Entity-optimal_policies,
        askg-data:Entity-optimal_sequences_of_actions,
        askg-data:Entity-same_strategy,
        askg-data:Entity-success_probabilities_and_rewards,
        askg-data:Entity-the_colored_goal_specification,
        askg-data:Entity-the_non-colored_blocks_world,
        askg-data:Entity-the_table .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4810-Sentence-48106 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The performance of this **strategy depends entirely on** the goal-state selected and can therefore be arbitrarily bad."@en ;
    askg-onto:inSentence "The performance of this **strategy depends entirely on** the goal-state selected and can therefore be arbitrarily bad."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal-state_selected,
        askg-data:Entity-strategy .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Logistics problems from IPC-2 distinguish between airports and other locations within a city; trucks can drive between any two locations in a city and planes can fly between any two airports. In contrast, the box world only features cities, some of which have an airport, some of which are only accessible by truck. A priori, the map of the truck and plane connections is arbitrary. The goal is to get packages from their city of origin to their city of destination. Moving by truck has a 20% chance of resulting in reaching one of the three cities closest to the departure city rather than the intended one. The size of the box world search space turned out to be quite challenging for nmrdpp**. Therefore, when writing** search control knowledge, we gave up any optimality consideration and favored maximal pruning. We were helped by the fact that the box world generator produces problems with the following structure. Cities are divided into clusters, **all of which are composed of at** least one airport city. Furthermore each cluster has at least one hamiltonian circuit which trucks can follow. The control knowledge we used forced all planes but one, and all trucks but one in each cluster to be idle. In each cluster, the truck allowed to move could only attempt driving along the chosen hamiltonian circuit, picking up and dropping parcels as it went."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48111,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-481110,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-481111,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-481112,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48112,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48113,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48114,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48115,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48116,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48117,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48118,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48119 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Logistics problems from IPC-2 distinguish between airports and other locations within a city; trucks can drive between any two locations in a city and planes can fly between any two airports."@en ;
    askg-onto:inSentence "Logistics problems from IPC-2 distinguish between airports and other locations within a city; trucks can drive between any two locations in a city and planes can fly between any two airports."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-airports_and_other_locations_within_a_city,
        askg-data:Entity-any_two_airports,
        askg-data:Entity-any_two_locations_in_a_city,
        askg-data:Entity-logistics_problems_from_ipc-2,
        askg-data:Entity-planes,
        askg-data:Entity-trucks .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-481110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Furthermore each cluster has at least one hamiltonian circuit which trucks can follow."@en ;
    askg-onto:inSentence "Furthermore each cluster has at least one hamiltonian circuit which trucks can follow."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cluster,
        askg-data:Entity-hamiltonian_circuit,
        askg-data:Entity-trucks .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-481111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "The control knowledge we used forced all planes but one, and all trucks but one in each cluster to be idle."@en ;
    askg-onto:inSentence "The control knowledge we used forced all planes but one, and all trucks but one in each cluster to be idle."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-idle,
        askg-data:Entity-planes,
        askg-data:Entity-trucks .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-481112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "In each cluster, the truck allowed to move could only attempt driving along the chosen hamiltonian circuit, picking up and dropping parcels as it went."@en ;
    askg-onto:inSentence "In each cluster, the truck allowed to move could only attempt driving along the chosen hamiltonian circuit, picking up and dropping parcels as it went."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hamiltonian_circuit,
        askg-data:Entity-truck .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In contrast, the box world only features cities, some of which have an airport, some of which are only accessible by truck."@en ;
    askg-onto:inSentence "In contrast, the box world only features cities, some of which have an airport, some of which are only accessible by truck."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-airport,
        askg-data:Entity-box_world,
        askg-data:Entity-cities,
        askg-data:Entity-truck .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A priori, the map of the truck and plane connections is arbitrary."@en ;
    askg-onto:inSentence "A priori, the map of the truck and plane connections is arbitrary."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arbitrary,
        askg-data:Entity-map_of_the_truck_and_plane_connections .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The goal is to get packages from their city of origin to their city of destination."@en ;
    askg-onto:inSentence "The goal is to get packages from their city of origin to their city of destination."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-city_of_destination,
        askg-data:Entity-city_of_origin,
        askg-data:Entity-packages .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Moving by truck has a 20% chance of resulting in reaching one of the three cities closest to the departure city rather than the intended one."@en ;
    askg-onto:inSentence "Moving by truck has a 20% chance of resulting in reaching one of the three cities closest to the departure city rather than the intended one."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-20,
        askg-data:Entity-chance,
        askg-data:Entity-intended_one,
        askg-data:Entity-three_cities_closest_to_the_departure_city,
        askg-data:Entity-truck .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The size of the box world search space turned out to be quite challenging for nmrdpp**."@en ;
    askg-onto:inSentence "The size of the box world search space turned out to be quite challenging for nmrdpp**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-box_world_search_space,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48117 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Therefore, when writing** search control knowledge, we gave up any optimality consideration and favored maximal pruning."@en ;
    askg-onto:inSentence "Therefore, when writing** search control knowledge, we gave up any optimality consideration and favored maximal pruning."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-condition,
        askg-data:Entity-maximal_pruning,
        askg-data:Entity-method,
        askg-data:Entity-optimality_consideration,
        askg-data:Entity-search_control_knowledge .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48118 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We were helped by the fact that the box world generator produces problems with the following structure."@en ;
    askg-onto:inSentence "We were helped by the fact that the box world generator produces problems with the following structure."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-box_world_generator,
        askg-data:Entity-problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4811-Sentence-48119 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Cities are divided into clusters, **all of which are composed of at** least one airport city."@en ;
    askg-onto:inSentence "Cities are divided into clusters, **all of which are composed of at** least one airport city."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-airport_city,
        askg-data:Entity-cities,
        askg-data:Entity-clusters .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "The planners participating in the competition are shown in Table 2. Planners E, G2, J1, and J2 are domain-specific: either they are tuned for blocks and box worlds, or they use domain-specific search control knowledge, or learn from examples. The other participating planners are domain-independent."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812-Sentence-48121,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812-Sentence-48122,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812-Sentence-48123 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812-Sentence-48121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The planners participating in the competition are shown in Table 2."@en ;
    askg-onto:inSentence "The planners participating in the competition are shown in Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-competition,
        askg-data:Entity-planners .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812-Sentence-48122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Planners E, G2, J1, and J2 are domain-specific: either they are tuned for blocks and box worlds, or they use domain-specific search control knowledge, or learn from examples."@en ;
    askg-onto:inSentence "Planners E, G2, J1, and J2 are domain-specific: either they are tuned for blocks and box worlds, or they use domain-specific search control knowledge, or learn from examples."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blocks_and_box_worlds,
        askg-data:Entity-domain-specific,
        askg-data:Entity-domain-specific_search_control_knowledge,
        askg-data:Entity-examples,
        askg-data:Entity-planners_e_g2_j1_and_j2 .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4812-Sentence-48123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The other participating planners are domain-independent."@en ;
    askg-onto:inSentence "The other participating planners are domain-independent."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-independent,
        askg-data:Entity-planners .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4813 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "17. More sophisticated near-optimal strategies for deterministic blocks world exist (see Slaney & Thi´ebaux, 2001), but are much more complex to encode and might have caused time performance problems."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4813-Sentence-48131,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4813-Sentence-48132 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4813-Sentence-48131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "17."@en ;
    askg-onto:inSentence "17."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-17,
        askg-data:Entity-a_position .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4813-Sentence-48132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "More sophisticated near-optimal strategies for deterministic blocks world exist (see Slaney & Thi´ebaux, 2001), but are much more complex to encode and might have caused time performance problems."@en ;
    askg-onto:inSentence "More sophisticated near-optimal strategies for deterministic blocks world exist (see Slaney & Thi´ebaux, 2001), but are much more complex to encode and might have caused time performance problems."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2001,
        askg-data:Entity-complex_to_encode,
        askg-data:Entity-deterministic_blocks_world,
        askg-data:Entity-sophisticated_near-optimal_strategies,
        askg-data:Entity-strategy,
        askg-data:Entity-time_performance_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4814 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "| Part. | Description | Reference | |---------|------------------------------------------------------|------------------------------------------| | C | symbolic LAO* | (Feng & Hansen, 2002) | | E* | first\\-order heuristic search in the fluent calculus | (Karabaev & Skvortsova, 2005) | | G1 | nmrdpp without control knowledge | this paper | | G2* | nmrdpp with control knowledge | this paper | | J1* | interpreter of hand written classy policies | (Fern et al., 2004) | | J2* | learns classy policies from random walks | (Fern et al., 2004) | | J3 | version of ff replanning upon failure | (Hoffmann & Nebel, 2001) | | P | mgpt: lrtdp with automatically extracted heuristics | (Bonet & Geffner, 2005) | | Q | ProbaProp: conformant probabilistic planner | (Onder et al., 2006) | | R | structured reachability analysis and structured PI | (Teichteil\\-K¨onigsbuch & Fabiani, 2005) |"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4814-Sentence-48141,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4814-Sentence-48142 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4814-Sentence-48141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Part."@en ;
    askg-onto:inSentence "| Part."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-part,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4814-Sentence-48142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "| Description | Reference | |---------|------------------------------------------------------|------------------------------------------| | C | symbolic LAO* | (Feng & Hansen, 2002) | | E* | first\\-order heuristic search in the fluent calculus | (Karabaev & Skvortsova, 2005) | | G1 | nmrdpp without control knowledge | this paper | | G2* | nmrdpp with control knowledge | this paper | | J1* | interpreter of hand written classy policies | (Fern et al., 2004) | | J2* | learns classy policies from random walks | (Fern et al., 2004) | | J3 | version of ff replanning upon failure | (Hoffmann & Nebel, 2001) | | P | mgpt: lrtdp with automatically extracted heuristics | (Bonet & Geffner, 2005) | | Q | ProbaProp: conformant probabilistic planner | (Onder et al., 2006) | | R | structured reachability analysis and structured PI | (Teichteil\\-K¨onigsbuch & Fabiani, 2005) |"@en ;
    askg-onto:inSentence "| Description | Reference | |---------|------------------------------------------------------|------------------------------------------| | C | symbolic LAO* | (Feng & Hansen, 2002) | | E* | first\\-order heuristic search in the fluent calculus | (Karabaev & Skvortsova, 2005) | | G1 | nmrdpp without control knowledge | this paper | | G2* | nmrdpp with control knowledge | this paper | | J1* | interpreter of hand written classy policies | (Fern et al., 2004) | | J2* | learns classy policies from random walks | (Fern et al., 2004) | | J3 | version of ff replanning upon failure | (Hoffmann & Nebel, 2001) | | P | mgpt: lrtdp with automatically extracted heuristics | (Bonet & Geffner, 2005) | | Q | ProbaProp: conformant probabilistic planner | (Onder et al., 2006) | | R | structured reachability analysis and structured PI | (Teichteil\\-K¨onigsbuch & Fabiani, 2005) |"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first-order_heuristic_search_in_the_fluent_calculus,
        askg-data:Entity-interpreter_of_hand_written_classy_policies,
        askg-data:Entity-learns_classy_policies_from_random_walks,
        askg-data:Entity-mgpt_lrtdp_with_automatically_extracted_heuristics,
        askg-data:Entity-nmrdpp_with_control_knowledge,
        askg-data:Entity-nmrdpp_without_control_knowledge,
        askg-data:Entity-paper,
        askg-data:Entity-probaprop_conformant_probabilistic_planner,
        askg-data:Entity-structured_reachability_analysis_and_structured_pi,
        askg-data:Entity-symbolic_lao,
        askg-data:Entity-version_of_ff_replanning_upon_failure .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4815 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "| dom | | bw\\-c\\-nr | | bw\\-nc\\-nr | bx\\-nr | | expl\\-bw | hanoise | zeno | tire\\-nr | | |-------|---------|-------------|-----|--------------|--------------|-----|------------|-----------|------------|------------|-------| | prob | 5 | 8 | 11 | 8 | 5\\-10 10\\-10 | | 11 | 5\\-3 | 1\\-2\\-3\\-7 | 30\\-4 | total | | G2* | 100 100 | | 100 | 100 | 100 | 100 | | | | | 600 | | J1* | 100 | 100 | 100 | 100 | 100 | 100 | | | | | 600 | | J2* | 100 | 100 | 100 | 100 | 100 | 67 | | | | | 567 | | E* | 100 | 100 | 100 | 100 | | | | | | | 400 | | J3 | 100 | 100 | 100 | 100 | 100 | 100 | 9 | - | - | 23 | 632 | | G1 | | | | | | | - | 50 | 100 | 30 | 180 | | R | | | | 3 | | | | 57 | 90 | 30 | 177 | | P | | | | | | | | | 100 | 53 | 153 | | C | | | | | | | | | 100 | ? | ≥ 100 | | Q | | | | | | | | | 3 | 23 | 26 |"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4815-Sentence-48151,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4815-Sentence-48152 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4815-Sentence-48151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| dom | | bw\\-c\\-nr | | bw\\-nc\\-nr | bx\\-nr | | expl\\-bw | hanoise | zeno | tire\\-nr | | |-------|---------|-------------|-----|--------------|--------------|-----|------------|-----------|------------|------------|-------| | prob | 5 | 8 | 11 | 8 | 5\\-10 10\\-10 | | 11 | 5\\-3 | 1\\-2\\-3\\-7 | 30\\-4 | total | | G2* | 100 100 | | 100 | 100 | 100 | 100 | | | | | 600 | | J1* | 100 | 100 | 100 | 100 | 100 | 100 | | | | | 600 | | J2* | 100 | 100 | 100 | 100 | 100 | 67 | | | | | 567 | | E* | 100 | 100 | 100 | 100 | | | | | | | 400 | | J3 | 100 | 100 | 100 | 100 | 100 | 100 | 9 | - | - | 23 | 632 | | G1 | | | | | | | - | 50 | 100 | 30 | 180 | | R | | | | 3 | | | | 57 | 90 | 30 | 177 | | P | | | | | | | | | 100 | 53 | 153 | | C | | | | | | | | | 100 | ?"@en ;
    askg-onto:inSentence "| dom | | bw\\-c\\-nr | | bw\\-nc\\-nr | bx\\-nr | | expl\\-bw | hanoise | zeno | tire\\-nr | | |-------|---------|-------------|-----|--------------|--------------|-----|------------|-----------|------------|------------|-------| | prob | 5 | 8 | 11 | 8 | 5\\-10 10\\-10 | | 11 | 5\\-3 | 1\\-2\\-3\\-7 | 30\\-4 | total | | G2* | 100 100 | | 100 | 100 | 100 | 100 | | | | | 600 | | J1* | 100 | 100 | 100 | 100 | 100 | 100 | | | | | 600 | | J2* | 100 | 100 | 100 | 100 | 100 | 67 | | | | | 567 | | E* | 100 | 100 | 100 | 100 | | | | | | | 400 | | J3 | 100 | 100 | 100 | 100 | 100 | 100 | 9 | - | - | 23 | 632 | | G1 | | | | | | | - | 50 | 100 | 30 | 180 | | R | | | | 3 | | | | 57 | 90 | 30 | 177 | | P | | | | | | | | | 100 | 53 | 153 | | C | | | | | | | | | 100 | ?"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-100,
        askg-data:Entity-153,
        askg-data:Entity-177,
        askg-data:Entity-180,
        askg-data:Entity-400,
        askg-data:Entity-567,
        askg-data:Entity-600,
        askg-data:Entity-632,
        askg-data:Entity-c,
        askg-data:Entity-e,
        askg-data:Entity-g1,
        askg-data:Entity-g2,
        askg-data:Entity-j1,
        askg-data:Entity-j2,
        askg-data:Entity-j3,
        askg-data:Entity-p,
        askg-data:Entity-r .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4815-Sentence-48152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "| ≥ 100 | | Q | | | | | | | | | 3 | 23 | 26 |"@en ;
    askg-onto:inSentence "| ≥ 100 | | Q | | | | | | | | | 3 | 23 | 26 |"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-100,
        askg-data:Entity-q .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4816 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "| dom | bw\\-c\\-r | | | | | | bw\\-nc\\-r | | | bx\\-r | | | file | tire\\-r | | |-------|------------|-----|-----|-----|-----|-------------------------|-------------|-----|-----|---------------------|-----|-----|--------|-----------|-------| | prob | 5 | 8 | 11 | 5 | 8 | 11 | 15 | 18 | 21 | 5\\-10 10\\-10 10\\-15 | | | 30\\-4 | 30\\-4 | total | | J1* | 497 | 487 | 481 | 494 | 489 | 480 | 470 | 462 | 458 | 419 | 317 | 129 | | | 5183 | | G2* | 495 486 | | 480 | | | 495 490 480 468 352 286 | | | | 438 | 376 | - | | | 4846 | | E* | 496 | 492 | 486 | 495 | 490 | | | | | | | | | | 2459 | | J2* | 497 | 486 | 482 | 495 | 490 | 480 | 468 | - | 455 | 376 | - | - | | | 4229 | | J3 | 496 | 487 | 482 | 494 | 490 | 481 | - | - | 459 | 425 | 346 | 279 | 36 | - | 4475 | | P | | | | 494 | 488 | 466 | 397 | | | 184 | - | | 58 | - | 2087 | | C | | | | 495 | | | | | | | | | | ? | ≥ 495 | | G1 | | | | 495 | | | | | | | | | - | - | 495 | | R | | | | 494 | | | | | | | | | | | 494 | | Q | | | | 180 | | | | | | | | | | 11 | 191 |"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4816-Sentence-48161,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4816-Sentence-48162 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4816-Sentence-48161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| dom | bw\\-c\\-r | | | | | | bw\\-nc\\-r | | | bx\\-r | | | file | tire\\-r | | |-------|------------|-----|-----|-----|-----|-------------------------|-------------|-----|-----|---------------------|-----|-----|--------|-----------|-------| | prob | 5 | 8 | 11 | 5 | 8 | 11 | 15 | 18 | 21 | 5\\-10 10\\-10 10\\-15 | | | 30\\-4 | 30\\-4 | total | | J1* | 497 | 487 | 481 | 494 | 489 | 480 | 470 | 462 | 458 | 419 | 317 | 129 | | | 5183 | | G2* | 495 486 | | 480 | | | 495 490 480 468 352 286 | | | | 438 | 376 | - | | | 4846 | | E* | 496 | 492 | 486 | 495 | 490 | | | | | | | | | | 2459 | | J2* | 497 | 486 | 482 | 495 | 490 | 480 | 468 | - | 455 | 376 | - | - | | | 4229 | | J3 | 496 | 487 | 482 | 494 | 490 | 481 | - | - | 459 | 425 | 346 | 279 | 36 | - | 4475 | | P | | | | 494 | 488 | 466 | 397 | | | 184 | - | | 58 | - | 2087 | | C | | | | 495 | | | | | | | | | | ?"@en ;
    askg-onto:inSentence "| dom | bw\\-c\\-r | | | | | | bw\\-nc\\-r | | | bx\\-r | | | file | tire\\-r | | |-------|------------|-----|-----|-----|-----|-------------------------|-------------|-----|-----|---------------------|-----|-----|--------|-----------|-------| | prob | 5 | 8 | 11 | 5 | 8 | 11 | 15 | 18 | 21 | 5\\-10 10\\-10 10\\-15 | | | 30\\-4 | 30\\-4 | total | | J1* | 497 | 487 | 481 | 494 | 489 | 480 | 470 | 462 | 458 | 419 | 317 | 129 | | | 5183 | | G2* | 495 486 | | 480 | | | 495 490 480 468 352 286 | | | | 438 | 376 | - | | | 4846 | | E* | 496 | 492 | 486 | 495 | 490 | | | | | | | | | | 2459 | | J2* | 497 | 486 | 482 | 495 | 490 | 480 | 468 | - | 455 | 376 | - | - | | | 4229 | | J3 | 496 | 487 | 482 | 494 | 490 | 481 | - | - | 459 | 425 | 346 | 279 | 36 | - | 4475 | | P | | | | 494 | 488 | 466 | 397 | | | 184 | - | | 58 | - | 2087 | | C | | | | 495 | | | | | | | | | | ?"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2087,
        askg-data:Entity-2459,
        askg-data:Entity-4229,
        askg-data:Entity-4475,
        askg-data:Entity-4846,
        askg-data:Entity-495,
        askg-data:Entity-5183,
        askg-data:Entity-c,
        askg-data:Entity-e,
        askg-data:Entity-g2,
        askg-data:Entity-j1,
        askg-data:Entity-j2,
        askg-data:Entity-j3,
        askg-data:Entity-p .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4816-Sentence-48162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "| ≥ 495 | | G1 | | | | 495 | | | | | | | | | - | - | 495 | | R | | | | 494 | | | | | | | | | | | 494 | | Q | | | | 180 | | | | | | | | | | 11 | 191 |"@en ;
    askg-onto:inSentence "| ≥ 495 | | G1 | | | | 495 | | | | | | | | | - | - | 495 | | R | | | | 494 | | | | | | | | | | | 494 | | Q | | | | 180 | | | | | | | | | | 11 | 191 |"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11,
        askg-data:Entity-180,
        askg-data:Entity-191,
        askg-data:Entity-494,
        askg-data:Entity-495,
        askg-data:Entity-g1,
        askg-data:Entity-q,
        askg-data:Entity-r .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "Table 2: Competition Participants. Domain-specific planners are starred Table 3: Results for Goal-Based Problems. Domain-specific planners are starred. Entries are the percentage of runs in which the goal was reached. A blank indicates that the planner was unable to attempt the problem. A - indicates that the planner attempted the problem but was never able to achieve the goal. **A ? indicates that** the result is unavailable (due to a bug in the evaluation software, a couple of the results initially announced were found to be invalid)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48171,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48172,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48173,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48174,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48175,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48176,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48177,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48178 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 2: Competition Participants."@en ;
    askg-onto:inSentence "Table 2: Competition Participants."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-competition_participants,
        askg-data:Entity-participants_in_a_competition .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48172 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Domain-specific planners are starred Table 3: Results for Goal-Based Problems."@en ;
    askg-onto:inSentence "Domain-specific planners are starred Table 3: Results for Goal-Based Problems."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-specific_planners,
        askg-data:Entity-table_3_results_for_goal-based_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48173 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Domain-specific planners are starred."@en ;
    askg-onto:inSentence "Domain-specific planners are starred."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-specific_planners,
        askg-data:Entity-starred .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48174 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Entries are the percentage of runs in which the goal was reached."@en ;
    askg-onto:inSentence "Entries are the percentage of runs in which the goal was reached."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-entries,
        askg-data:Entity-runs_in_which_the_goal_was_reached .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48175 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "A blank indicates that the planner was unable to attempt the problem."@en ;
    askg-onto:inSentence "A blank indicates that the planner was unable to attempt the problem."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planner,
        askg-data:Entity-problem .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48176 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "A - indicates that the planner attempted the problem but was never able to achieve the goal."@en ;
    askg-onto:inSentence "A - indicates that the planner attempted the problem but was never able to achieve the goal."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-the_planner_attempted_the_problem_but_was_never_able_to_achieve_the_goal .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48177 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "**A ?"@en ;
    askg-onto:inSentence "**A ?"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-a .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4817-Sentence-48178 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "indicates that** the result is unavailable (due to a bug in the evaluation software, a couple of the results initially announced were found to be invalid)."@en ;
    askg-onto:inSentence "indicates that** the result is unavailable (due to a bug in the evaluation software, a couple of the results initially announced were found to be invalid)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evaluation_software,
        askg-data:Entity-result_unavailable .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "Table 4: Results for Reward-Based Problems. Domain-specific planners are starred. Entries are the average reward achieved over the 30 runs. A blank indicates that the planner was unable to attempt the problem. A - indicates that **the planner** attempted the problem but did not achieve a strictly positive reward. A ? indicates that the result is unavailable."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48181,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48182,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48183,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48184,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48185,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48186,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48187 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 4: Results for Reward-Based Problems."@en ;
    askg-onto:inSentence "Table 4: Results for Reward-Based Problems."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward-based_problems,
        askg-data:Entity-table_4 .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Domain-specific planners are starred."@en ;
    askg-onto:inSentence "Domain-specific planners are starred."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-specific_planners .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Entries are the average reward achieved over the 30 runs."@en ;
    askg-onto:inSentence "Entries are the average reward achieved over the 30 runs."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_reward,
        askg-data:Entity-entries .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48184 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "A blank indicates that the planner was unable to attempt the problem."@en ;
    askg-onto:inSentence "A blank indicates that the planner was unable to attempt the problem."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planner,
        askg-data:Entity-the_problem .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48185 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "A - indicates that **the planner** attempted the problem but did not achieve a strictly positive reward."@en ;
    askg-onto:inSentence "A - indicates that **the planner** attempted the problem but did not achieve a strictly positive reward."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-the_planner,
        askg-data:Entity-the_problem .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48186 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "A ?"@en ;
    askg-onto:inSentence "A ?"^^xsd:string ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4818-Sentence-48187 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "indicates that the result is unavailable."@en ;
    askg-onto:inSentence "indicates that the result is unavailable."^^xsd:string ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "Tables 3 and 4 show the results of the competition, which we extracted from the competition overview paper (Younes, Littman, Weissmann, & Asmuth, 2005) and from the competition web site http://www.cs.rutgers.edu/~mlittman/topics/ipc04-pt/**. The** first of those tables concerns goal-based problems and the second the reward-based problems. The entries in the tables represent the goal-achievement percentage or average reward achieved by the various planner versions (left-column) on the various problems (top two rows). Planners in the top part of the tables are domain-specific. Problems from the known domains lie on the left-hand side of the tables. The colored blocks world problems are bw-c-nr **(goal-based version) and** bw-c-r **(reward version) with 5, 8, and 11 blocks. The** non-colored blocks world problems are bw-nc-nr **(goal-based version) with 8 blocks, and** bwnc-r **(reward-based version) with 5, 8, 11, 15, 18, and 21 blocks. The box world problems** are bx-nr **(goal-based) and** bx-r (reward-based), with 5 or 10 cities and 10 or 15 boxes. Problems from the unknown domains lie on the right hand side of the **tables. They comprise:** expl-bw, an exploding version of the 11 block blocks world problem in **which putting down** a block may destroy the object it is put on, zeno**, a probabilistic variant of a zeno travel** domain problem from the IPC-3 with 1 plane, 2 persons, 3 cities and 7 fuel levels, hanoise, a probabilistic variant of the tower of hanoi problem with 5 disks and 3 rods, file**, a problem** of putting 30 files in 5 randomly chosen folders, and tire**, a variant a the tire world problem** with 30 cities and spare tires at 4 of them, where the tire may go flat while driving."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48191,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-481910,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48192,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48193,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48194,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48195,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48196,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48197,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48198,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48199 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Tables 3 and 4 show the results of the competition, which we extracted from the competition overview paper (Younes, Littman, Weissmann, & Asmuth, 2005) and from the competition web site http://www.cs.rutgers.edu/~mlittman/topics/ipc04-pt/**."@en ;
    askg-onto:inSentence "Tables 3 and 4 show the results of the competition, which we extracted from the competition overview paper (Younes, Littman, Weissmann, & Asmuth, 2005) and from the competition web site http://www.cs.rutgers.edu/~mlittman/topics/ipc04-pt/**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-competition_overview_paper,
        askg-data:Entity-tables_3_and_4,
        askg-data:Entity-younes_littman_weissmann__asmuth .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-481910 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "They comprise:** expl-bw, an exploding version of the 11 block blocks world problem in **which putting down** a block may destroy the object it is put on, zeno**, a probabilistic variant of a zeno travel** domain problem from the IPC-3 with 1 plane, 2 persons, 3 cities and 7 fuel levels, hanoise, a probabilistic variant of the tower of hanoi problem with 5 disks and 3 rods, file**, a problem** of putting 30 files in 5 randomly chosen folders, and tire**, a variant a the tire world problem** with 30 cities and spare tires at 4 of them, where the tire may go flat while driving."@en ;
    askg-onto:inSentence "They comprise:** expl-bw, an exploding version of the 11 block blocks world problem in **which putting down** a block may destroy the object it is put on, zeno**, a probabilistic variant of a zeno travel** domain problem from the IPC-3 with 1 plane, 2 persons, 3 cities and 7 fuel levels, hanoise, a probabilistic variant of the tower of hanoi problem with 5 disks and 3 rods, file**, a problem** of putting 30 files in 5 randomly chosen folders, and tire**, a variant a the tire world problem** with 30 cities and spare tires at 4 of them, where the tire may go flat while driving."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11_block_blocks_world_problem,
        askg-data:Entity-expl-bw,
        askg-data:Entity-file,
        askg-data:Entity-hanoise,
        askg-data:Entity-ipc-3,
        askg-data:Entity-tire,
        askg-data:Entity-tire_world_problem,
        askg-data:Entity-tower_of_hanoi_problem,
        askg-data:Entity-zeno,
        askg-data:Entity-zeno_travel_domain_problem .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The** first of those tables concerns goal-based problems and the second the reward-based problems."@en ;
    askg-onto:inSentence "The** first of those tables concerns goal-based problems and the second the reward-based problems."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal-based_problems,
        askg-data:Entity-reward-based_problems,
        askg-data:Entity-tables .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48193 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The entries in the tables represent the goal-achievement percentage or average reward achieved by the various planner versions (left-column) on the various problems (top two rows)."@en ;
    askg-onto:inSentence "The entries in the tables represent the goal-achievement percentage or average reward achieved by the various planner versions (left-column) on the various problems (top two rows)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_reward,
        askg-data:Entity-goal-achievement_percentage,
        askg-data:Entity-planner_versions,
        askg-data:Entity-problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48194 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Planners in the top part of the tables are domain-specific."@en ;
    askg-onto:inSentence "Planners in the top part of the tables are domain-specific."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-specific,
        askg-data:Entity-planners .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48195 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Problems from the known domains lie on the left-hand side of the tables."@en ;
    askg-onto:inSentence "Problems from the known domains lie on the left-hand side of the tables."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domains,
        askg-data:Entity-left-hand_side_of_the_tables .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48196 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The colored blocks world problems are bw-c-nr **(goal-based version) and** bw-c-r **(reward version) with 5, 8, and 11 blocks."@en ;
    askg-onto:inSentence "The colored blocks world problems are bw-c-nr **(goal-based version) and** bw-c-r **(reward version) with 5, 8, and 11 blocks."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bw-c-nr,
        askg-data:Entity-bw-c-r,
        askg-data:Entity-goal-based_version,
        askg-data:Entity-reward_version .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48197 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The** non-colored blocks world problems are bw-nc-nr **(goal-based version) with 8 blocks, and** bwnc-r **(reward-based version) with 5, 8, 11, 15, 18, and 21 blocks."@en ;
    askg-onto:inSentence "The** non-colored blocks world problems are bw-nc-nr **(goal-based version) with 8 blocks, and** bwnc-r **(reward-based version) with 5, 8, 11, 15, 18, and 21 blocks."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_8_11_15_18_and_21_blocks,
        askg-data:Entity-8_blocks,
        askg-data:Entity-bw-nc-nr,
        askg-data:Entity-bwnc-r,
        askg-data:Entity-non-colored_blocks_world_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48198 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "The box world problems** are bx-nr **(goal-based) and** bx-r (reward-based), with 5 or 10 cities and 10 or 15 boxes."@en ;
    askg-onto:inSentence "The box world problems** are bx-nr **(goal-based) and** bx-r (reward-based), with 5 or 10 cities and 10 or 15 boxes."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-box_world_problems,
        askg-data:Entity-goal-based,
        askg-data:Entity-reward-based .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4819-Sentence-48199 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Problems from the unknown domains lie on the right hand side of the **tables."@en ;
    askg-onto:inSentence "Problems from the unknown domains lie on the right hand side of the **tables."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-problems_from_the_unknown_domains,
        askg-data:Entity-tables .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The most crucial problem we encountered was the translation **of PPDDL (Younes &** Littman, 2004), the probabilistic variant of PDDL used as input language for the competition, into nmrdpp**'s ADD-based input language. While translating PPDDL into ADDs** is possible in theory, devising a translation which is practical enough for the need of the competition (small number of variables, small, quickly generated, and easily manipulable ADDs) is another matter. mtbdd**, the translator kindly made available to participants by** the competition organisers, was not always able to achieve the required efficiency. At other times, the translation was quick but nmrdpp was unable to use the generated ADDs efficiently. Consequently, we implemented a state-based translator on top of the PDDL parser as a backup, and opted for a state-based solution method since it did not rely on ADDs and could operate with both translators."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4821,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4822,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4823,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4824,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4825 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The most crucial problem we encountered was the translation **of PPDDL (Younes &** Littman, 2004), the probabilistic variant of PDDL used as input language for the competition, into nmrdpp**'s ADD-based input language."@en ;
    askg-onto:inSentence "The most crucial problem we encountered was the translation **of PPDDL (Younes &** Littman, 2004), the probabilistic variant of PDDL used as input language for the competition, into nmrdpp**'s ADD-based input language."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-pddl,
        askg-data:Entity-ppddl,
        askg-data:Entity-the_competition,
        askg-data:Entity-younes__littman,
        askg-data:Entity-younes__littman_2004 .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While translating PPDDL into ADDs** is possible in theory, devising a translation which is practical enough for the need of the competition (small number of variables, small, quickly generated, and easily manipulable ADDs) is another matter."@en ;
    askg-onto:inSentence "While translating PPDDL into ADDs** is possible in theory, devising a translation which is practical enough for the need of the competition (small number of variables, small, quickly generated, and easily manipulable ADDs) is another matter."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adds,
        askg-data:Entity-ppddl .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "mtbdd**, the translator kindly made available to participants by** the competition organisers, was not always able to achieve the required efficiency."@en ;
    askg-onto:inSentence "mtbdd**, the translator kindly made available to participants by** the competition organisers, was not always able to achieve the required efficiency."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-competition_organisers,
        askg-data:Entity-mtbdd,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4824 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "At other times, the translation was quick but nmrdpp was unable to use the generated ADDs efficiently."@en ;
    askg-onto:inSentence "At other times, the translation was quick but nmrdpp was unable to use the generated ADDs efficiently."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-the_generated_adds .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-482-Sentence-4825 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Consequently, we implemented a state-based translator on top of the PDDL parser as a backup, and opted for a state-based solution method since it did not rely on ADDs and could operate with both translators."@en ;
    askg-onto:inSentence "Consequently, we implemented a state-based translator on top of the PDDL parser as a backup, and opted for a state-based solution method since it did not rely on ADDs and could operate with both translators."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-pddl_parser,
        askg-data:Entity-state-based_solution_method,
        askg-data:Entity-state-based_translator,
        askg-data:Entity-system,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "Our planner nmrdpp in its G1 or G2 version, was able to attempt all problems, achieving a strictly positive reward in all but 4 of them. Not even ff **(J3), the competition overall** winner, was able to successfully attempt that many problems. nmrdpp performed particularly well on goal-based problems, achieving the goal in 100% of the runs except in expl-bw, hanoise**, and** tire-nr **(note that for these three problems, the goal achievement probability of** the optimal policy does not exceed 65%). No other planner outperformed nmrdpp **on that** scale. As pointed out before, ff **behaves well on the probabilistic version of blocks and box** world because the optimal policies are very close to those for the deterministic problem - Hoffmann (2002) analyses the reasons why the ff heuristic works well for traditional planning benchmarks such as blocks world and logistics. On the other hand, ff **is unable to** solve the unknown problems which have a different structure and require more substantial probabilistic reasoning, although these problems are easily solved by a number of participating planners. As expected, there is a large discrepancy between the version of **nmrdpp** allowed to use search control (G2) and the domain-independent version (G1). While the latter performs okay with the unknown goal-based domains, it is not able to solve any of the known ones. In fact, to except for ff**, none of the participating domain-independent** planners were able to solve these problems."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48201,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48202,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48203,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48204,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48205,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48206,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48207,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48208,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48209 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our planner nmrdpp in its G1 or G2 version, was able to attempt all problems, achieving a strictly positive reward in all but 4 of them."@en ;
    askg-onto:inSentence "Our planner nmrdpp in its G1 or G2 version, was able to attempt all problems, achieving a strictly positive reward in all but 4 of them."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-planner,
        askg-data:Entity-strictly_positive_reward .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48202 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Not even ff **(J3), the competition overall** winner, was able to successfully attempt that many problems."@en ;
    askg-onto:inSentence "Not even ff **(J3), the competition overall** winner, was able to successfully attempt that many problems."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-competition,
        askg-data:Entity-j3 .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48203 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "nmrdpp performed particularly well on goal-based problems, achieving the goal in 100% of the runs except in expl-bw, hanoise**, and** tire-nr **(note that for these three problems, the goal achievement probability of** the optimal policy does not exceed 65%)."@en ;
    askg-onto:inSentence "nmrdpp performed particularly well on goal-based problems, achieving the goal in 100% of the runs except in expl-bw, hanoise**, and** tire-nr **(note that for these three problems, the goal achievement probability of** the optimal policy does not exceed 65%)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-100_of_the_runs,
        askg-data:Entity-65,
        askg-data:Entity-goal-based_problems,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-optimal_policy .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48204 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "No other planner outperformed nmrdpp **on that** scale."@en ;
    askg-onto:inSentence "No other planner outperformed nmrdpp **on that** scale."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-that_scale .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48205 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "As pointed out before, ff **behaves well on the probabilistic version of blocks and box** world because the optimal policies are very close to those for the deterministic problem - Hoffmann (2002) analyses the reasons why the ff heuristic works well for traditional planning benchmarks such as blocks world and logistics."@en ;
    askg-onto:inSentence "As pointed out before, ff **behaves well on the probabilistic version of blocks and box** world because the optimal policies are very close to those for the deterministic problem - Hoffmann (2002) analyses the reasons why the ff heuristic works well for traditional planning benchmarks such as blocks world and logistics."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ff,
        askg-data:Entity-hoffmann_2002,
        askg-data:Entity-the_ff_heuristic,
        askg-data:Entity-the_probabilistic_version_of_blocks_and_box_world,
        askg-data:Entity-the_reasons_why_the_ff_heuristic_works_well_for_traditional_planning_benchmarks,
        askg-data:Entity-traditional_planning_benchmarks_such_as_blocks_world_and_logistics .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48206 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "On the other hand, ff **is unable to** solve the unknown problems which have a different structure and require more substantial probabilistic reasoning, although these problems are easily solved by a number of participating planners."@en ;
    askg-onto:inSentence "On the other hand, ff **is unable to** solve the unknown problems which have a different structure and require more substantial probabilistic reasoning, although these problems are easily solved by a number of participating planners."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ff,
        askg-data:Entity-more_substantial_probabilistic_reasoning,
        askg-data:Entity-participating_planners,
        askg-data:Entity-unknown_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48207 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "As expected, there is a large discrepancy between the version of **nmrdpp** allowed to use search control (G2) and the domain-independent version (G1)."@en ;
    askg-onto:inSentence "As expected, there is a large discrepancy between the version of **nmrdpp** allowed to use search control (G2) and the domain-independent version (G1)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-tool,
        askg-data:Entity-version .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48208 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "While the latter performs okay with the unknown goal-based domains, it is not able to solve any of the known ones."@en ;
    askg-onto:inSentence "While the latter performs okay with the unknown goal-based domains, it is not able to solve any of the known ones."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any,
        askg-data:Entity-known_ones,
        askg-data:Entity-okay,
        askg-data:Entity-unknown_goal-based_domains .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4820-Sentence-48209 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In fact, to except for ff**, none of the participating domain-independent** planners were able to solve these problems."@en ;
    askg-onto:inSentence "In fact, to except for ff**, none of the participating domain-independent** planners were able to solve these problems."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-independent_planners,
        askg-data:Entity-these_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 21"@en ;
    domo:Text "In the reward-based case, nmrdpp **with control knoweldge behaves well on the known** problems. Only the human-encoded policies (J1) performed better. Without control knowledge nmrdpp is unable to scale on those problems, while other participants such as ff and mgpt are. Furthermore nmrdpp **appears to perform poorly on the two unknown problems.** In both cases, this might be due to the fact that it fails to generate an optimal policy: suboptimal policies easily have a high negative score in these domains (see Younes et al., 2005)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48211,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48212,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48213,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48214 ;
    askg-onto:index "21"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the reward-based case, nmrdpp **with control knoweldge behaves well on the known** problems."@en ;
    askg-onto:inSentence "In the reward-based case, nmrdpp **with control knoweldge behaves well on the known** problems."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-the_known_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Only the human-encoded policies (J1) performed better."@en ;
    askg-onto:inSentence "Only the human-encoded policies (J1) performed better."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-human-encoded_policies,
        askg-data:Entity-j1 .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Without control knowledge nmrdpp is unable to scale on those problems, while other participants such as ff and mgpt are."@en ;
    askg-onto:inSentence "Without control knowledge nmrdpp is unable to scale on those problems, while other participants such as ff and mgpt are."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ff,
        askg-data:Entity-mgpt,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-those_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4821-Sentence-48214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Furthermore nmrdpp **appears to perform poorly on the two unknown problems.** In both cases, this might be due to the fact that it fails to generate an optimal policy: suboptimal policies easily have a high negative score in these domains (see Younes et al., 2005)."@en ;
    askg-onto:inSentence "Furthermore nmrdpp **appears to perform poorly on the two unknown problems.** In both cases, this might be due to the fact that it fails to generate an optimal policy: suboptimal policies easily have a high negative score in these domains (see Younes et al., 2005)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2005,
        askg-data:Entity-high_negative_score,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-optimal_policy,
        askg-data:Entity-suboptimal_policies,
        askg-data:Entity-two_unknown_problems,
        askg-data:Entity-younes_et_al .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4822 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 22"@en ;
    domo:Text "For r-tire, we know that nmrdpp **did indeed generate a suboptimal policy. Additionally, it** could be that nmrdpp **was unlucky with the sampling-based policy evaluation process: in** tire-r in particular, there was a high variance between the costs of **various trajectories in** the optimal policy."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4822-Sentence-48221,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4822-Sentence-48222 ;
    askg-onto:index "22"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4822-Sentence-48221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For r-tire, we know that nmrdpp **did indeed generate a suboptimal policy."@en ;
    askg-onto:inSentence "For r-tire, we know that nmrdpp **did indeed generate a suboptimal policy."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_suboptimal_policy,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-r-tire .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4822-Sentence-48222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Additionally, it** could be that nmrdpp **was unlucky with the sampling-based policy evaluation process: in** tire-r in particular, there was a high variance between the costs of **various trajectories in** the optimal policy."@en ;
    askg-onto:inSentence "Additionally, it** could be that nmrdpp **was unlucky with the sampling-based policy evaluation process: in** tire-r in particular, there was a high variance between the costs of **various trajectories in** the optimal policy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-sampling-based_policy_evaluation_process,
        askg-data:Entity-tire-r,
        askg-data:Entity-various_trajectories_in_the_optimal_policy .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4823 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 23"@en ;
    domo:Text "Alltogether, the competition results suggest that control knowledge is likely to be essential when solving larger problems (Markovian or not) with nmrdpp**, and that, as has** been observed with deterministic planners, approaches making use of control knowledge are quite powerful."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4823-Sentence-48231 ;
    askg-onto:index "23"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-4823-Sentence-48231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Alltogether, the competition results suggest that control knowledge is likely to be essential when solving larger problems (Markovian or not) with nmrdpp**, and that, as has** been observed with deterministic planners, approaches making use of control knowledge are quite powerful."@en ;
    askg-onto:inSentence "Alltogether, the competition results suggest that control knowledge is likely to be essential when solving larger problems (Markovian or not) with nmrdpp**, and that, as has** been observed with deterministic planners, approaches making use of control knowledge are quite powerful."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches_making_use_of_control_knowledge,
        askg-data:Entity-control_knowledge,
        askg-data:Entity-deterministic_planners,
        askg-data:Entity-larger_problems,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-483 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The version of nmrdpp **entered in the competition did the following:** 1. Attempt to get a translation into ADDs using mtbdd**, and if that proves infeasible,** abort it and rely on the state-based translator instead."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-483-Sentence-4831,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-483-Sentence-4832 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-483-Sentence-4831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The version of nmrdpp **entered in the competition did the following:** 1."@en ;
    askg-onto:inSentence "The version of nmrdpp **entered in the competition did the following:** 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-version .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-483-Sentence-4832 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Attempt to get a translation into ADDs using mtbdd**, and if that proves infeasible,** abort it and rely on the state-based translator instead."@en ;
    askg-onto:inSentence "Attempt to get a translation into ADDs using mtbdd**, and if that proves infeasible,** abort it and rely on the state-based translator instead."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-alternative,
        askg-data:Entity-mtbdd,
        askg-data:Entity-state-based_translator,
        askg-data:Entity-translation_into_adds .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "2. Run fltl **expansion of the state space, taking search control knowledge into account** when available. Break after 10mn if not complete."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484-Sentence-4841,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484-Sentence-4842,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484-Sentence-4843 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484-Sentence-4841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2."@en ;
    askg-onto:inSentence "2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484-Sentence-4842 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Run fltl **expansion of the state space, taking search control knowledge into account** when available."@en ;
    askg-onto:inSentence "Run fltl **expansion of the state space, taking search control knowledge into account** when available."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-search_control_knowledge,
        askg-data:Entity-state_space .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-484-Sentence-4843 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Break after 10mn if not complete."@en ;
    askg-onto:inSentence "Break after 10mn if not complete."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-not_complete .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "3. Run value iteration to convergence. Failing to achieve any useful result (e.g. because expansion was not complete enough to even reach a goal state), go back to step 2."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4851,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4852,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4853,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4854 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3."@en ;
    askg-onto:inSentence "3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finding,
        askg-data:Entity-model,
        askg-data:Entity-study,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4852 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Run value iteration to convergence."@en ;
    askg-onto:inSentence "Run value iteration to convergence."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition,
        askg-data:Entity-convergence,
        askg-data:Entity-method,
        askg-data:Entity-value_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4853 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Failing to achieve any useful result (e.g."@en ;
    askg-onto:inSentence "Failing to achieve any useful result (e.g."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-result,
        askg-data:Entity-useful_result .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-485-Sentence-4854 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "because expansion was not complete enough to even reach a goal state), go back to step 2."@en ;
    askg-onto:inSentence "because expansion was not complete enough to even reach a goal state), go back to step 2."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expansion,
        askg-data:Entity-goal_state .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-486 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "4. Run as many of the 30 trials as possible in the remaining time,16 following the generated policy where defined, and falling back on the non-deterministic search control policy when available."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-486-Sentence-4861,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-486-Sentence-4862 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-486-Sentence-4861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4."@en ;
    askg-onto:inSentence "4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finding,
        askg-data:Entity-model,
        askg-data:Entity-triple .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-486-Sentence-4862 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Run as many of the 30 trials as possible in the remaining time,16 following the generated policy where defined, and falling back on the non-deterministic search control policy when available."@en ;
    askg-onto:inSentence "Run as many of the 30 trials as possible in the remaining time,16 following the generated policy where defined, and falling back on the non-deterministic search control policy when available."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30_trials,
        askg-data:Entity-generated_policy,
        askg-data:Entity-non-deterministic_search_control_policy,
        askg-data:Entity-remaining_time .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-487 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "With Step 1 we were trying to maximise the instances in which the original ADD-based nmrdpp **version could be run intact. In Step 3, it was decided not to use LAO* because** when run with no good heuristic, it often incurs a significant **overhead compared to value** iteration."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-487-Sentence-4871,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-487-Sentence-4872 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-487-Sentence-4871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "With Step 1 we were trying to maximise the instances in which the original ADD-based nmrdpp **version could be run intact."@en ;
    askg-onto:inSentence "With Step 1 we were trying to maximise the instances in which the original ADD-based nmrdpp **version could be run intact."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-add-based_nmrdpp_version,
        askg-data:Entity-step_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-487-Sentence-4872 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In Step 3, it was decided not to use LAO* because** when run with no good heuristic, it often incurs a significant **overhead compared to value** iteration."@en ;
    askg-onto:inSentence "In Step 3, it was decided not to use LAO* because** when run with no good heuristic, it often incurs a significant **overhead compared to value** iteration."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lao,
        askg-data:Entity-overhead,
        askg-data:Entity-value_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "The problems featured in the competition can be classified into goal-based or rewardbased problems. In goal-based problems, a (positive) reward is only received when a goal state is reached. In reward-based problems, action performance may also incur a (usually negative) reward. Another orthogonal distinction can be made between problems from"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4881,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4882,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4883,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4884 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4881 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The problems featured in the competition can be classified into goal-based or rewardbased problems."@en ;
    askg-onto:inSentence "The problems featured in the competition can be classified into goal-based or rewardbased problems."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-competition,
        askg-data:Entity-goal-based_problems,
        askg-data:Entity-rewardbased_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4882 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In goal-based problems, a (positive) reward is only received when a goal state is reached."@en ;
    askg-onto:inSentence "In goal-based problems, a (positive) reward is only received when a goal state is reached."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal-based_problems,
        askg-data:Entity-goal_state,
        askg-data:Entity-reward,
        askg-data:Entity-state .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4883 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In reward-based problems, action performance may also incur a (usually negative) reward."@en ;
    askg-onto:inSentence "In reward-based problems, action performance may also incur a (usually negative) reward."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward-based_problems,
        askg-data:Entity-usually_negative_reward .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-488-Sentence-4884 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Another orthogonal distinction can be made between problems from"@en ;
    askg-onto:inSentence "Another orthogonal distinction can be made between problems from"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-distinction,
        askg-data:Entity-problems .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "16. On each given problem, planners had 15mn to run whatever computation they saw as appropriate (including parsing, pre-processing, and policy generation if **any), and execute 30 trial runs of the generated** policy from an initial state to a goal state. domains that were not communicated in advance to the participants and those from domains that were. The latter consisted of variants of blocks world and logistics (or box world) problems, and gave the participating planners an opportunity to exploit knowledge of the domain, much as in the hand-coded deterministic planning track."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4891,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4892,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4893,
        askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4894 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4891 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "16."@en ;
    askg-onto:inSentence "16."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-corpus,
        askg-data:Entity-dataset,
        askg-data:Entity-domain,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-model,
        askg-data:Entity-research_field,
        askg-data:Entity-software,
        askg-data:Entity-system,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4892 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "On each given problem, planners had 15mn to run whatever computation they saw as appropriate (including parsing, pre-processing, and policy generation if **any), and execute 30 trial runs of the generated** policy from an initial state to a goal state."@en ;
    askg-onto:inSentence "On each given problem, planners had 15mn to run whatever computation they saw as appropriate (including parsing, pre-processing, and policy generation if **any), and execute 30 trial runs of the generated** policy from an initial state to a goal state."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-15mn_to_run_whatever_computation_they_saw_as_appropriate,
        askg-data:Entity-30_trial_runs_of_the_generated_policy_from_an_initial_state_to_a_goal_state,
        askg-data:Entity-planners,
        askg-data:Entity-policy .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4893 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "domains that were not communicated in advance to the participants and those from domains that were."@en ;
    askg-onto:inSentence "domains that were not communicated in advance to the participants and those from domains that were."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domains,
        askg-data:Entity-participants .

askg-data:Paper-c253584c3f1ff2a2-Section-48-Paragraph-489-Sentence-4894 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The latter consisted of variants of blocks world and logistics (or box world) problems, and gave the participating planners an opportunity to exploit knowledge of the domain, much as in the hand-coded deterministic planning track."@en ;
    askg-onto:inSentence "The latter consisted of variants of blocks world and logistics (or box world) problems, and gave the participating planners an opportunity to exploit knowledge of the domain, much as in the hand-coded deterministic planning track."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blocks_world,
        askg-data:Entity-logistics_problems .

askg-data:Paper-c253584c3f1ff2a2-Section-49 a askg-onto:Section ;
    rdfs:label "Section 49"@en ;
    domo:Text "8. Conclusion, Related, And Future Work"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-497 ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this paper, we have examined the problem of solving decision processes with non- Markovian rewards. We have described existing approaches which exploit a compact representation of the reward function to automatically translate the NMRDP into an equivalent process amenable to MDP solution methods. The computational model underlying this framework can be traced back to work on the relationship between linear temporal logic and automata in the areas of automated verification and model-checking (Vardi, 2003; Wolper, 1987). While remaining in this framework, we have proposed a new representation of non-Markovian reward functions and a translation into MDPs aimed at making the best possible use of state-based anytime heuristic search as the solution method. Our representation extends future linear temporal logic to express rewards. Our translation has the effect of embedding model-checking in the solution method. It results in an MDP of the minimal size achievable without stepping outside the anytime framework, and consequently in better policies by the deadline. We have described nmrdpp**, a software platform that** implements such approaches under a common interface, and which proved a useful tool in their experimental analysis. Both the system and the analysis are the first of their kind. We were able to identify a number of general trends in the behaviours of the methods and to provide advice as to which are the best suited to certain circumstances. For obvious reasons, our analysis has focused on artificial domains. Additional work should examine a wider range of domains of more practical interest, to see what form these results take in that context. Ultimately, we would like our analysis to help nmrdpp **automatically select the** most appropriate method. Unfortunately, because of the difficulty of translating between PLTL and $FLTL, it is likely that nmrdpp **would still have to maintain both a PLTL and** a $FLTL version of the reward formulae."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4911,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49110,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49111,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49112,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49113,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49114,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4912,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4913,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4914,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4915,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4916,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4917,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4918,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4919 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this paper, we have examined the problem of solving decision processes with non- Markovian rewards."@en ;
    askg-onto:inSentence "In this paper, we have examined the problem of solving decision processes with non- Markovian rewards."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_processes,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-this_paper .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "We were able to identify a number of general trends in the behaviours of the methods and to provide advice as to which are the best suited to certain circumstances."@en ;
    askg-onto:inSentence "We were able to identify a number of general trends in the behaviours of the methods and to provide advice as to which are the best suited to certain circumstances."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-certain_circumstances,
        askg-data:Entity-methods .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "For obvious reasons, our analysis has focused on artificial domains."@en ;
    askg-onto:inSentence "For obvious reasons, our analysis has focused on artificial domains."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-artificial_domains .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Additional work should examine a wider range of domains of more practical interest, to see what form these results take in that context."@en ;
    askg-onto:inSentence "Additional work should examine a wider range of domains of more practical interest, to see what form these results take in that context."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_wider_range_of_domains,
        askg-data:Entity-additional_work .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Ultimately, we would like our analysis to help nmrdpp **automatically select the** most appropriate method."@en ;
    askg-onto:inSentence "Ultimately, we would like our analysis to help nmrdpp **automatically select the** most appropriate method."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-most_appropriate_method,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-49114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Unfortunately, because of the difficulty of translating between PLTL and $FLTL, it is likely that nmrdpp **would still have to maintain both a PLTL and** a $FLTL version of the reward formulae."@en ;
    askg-onto:inSentence "Unfortunately, because of the difficulty of translating between PLTL and $FLTL, it is likely that nmrdpp **would still have to maintain both a PLTL and** a $FLTL version of the reward formulae."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-pltl_and_fltl_version_of_the_reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We have described existing approaches which exploit a compact representation of the reward function to automatically translate the NMRDP into an equivalent process amenable to MDP solution methods."@en ;
    askg-onto:inSentence "We have described existing approaches which exploit a compact representation of the reward function to automatically translate the NMRDP into an equivalent process amenable to MDP solution methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compact_representation_of_the_reward_function,
        askg-data:Entity-existing_approaches,
        askg-data:Entity-mdp_solution_methods,
        askg-data:Entity-nmrdp .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The computational model underlying this framework can be traced back to work on the relationship between linear temporal logic and automata in the areas of automated verification and model-checking (Vardi, 2003; Wolper, 1987)."@en ;
    askg-onto:inSentence "The computational model underlying this framework can be traced back to work on the relationship between linear temporal logic and automata in the areas of automated verification and model-checking (Vardi, 2003; Wolper, 1987)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1987,
        askg-data:Entity-2003,
        askg-data:Entity-automata,
        askg-data:Entity-automated_verification,
        askg-data:Entity-computational_model,
        askg-data:Entity-framework,
        askg-data:Entity-linear_temporal_logic,
        askg-data:Entity-model-checking,
        askg-data:Entity-relationship,
        askg-data:Entity-vardi,
        askg-data:Entity-wolper .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "While remaining in this framework, we have proposed a new representation of non-Markovian reward functions and a translation into MDPs aimed at making the best possible use of state-based anytime heuristic search as the solution method."@en ;
    askg-onto:inSentence "While remaining in this framework, we have proposed a new representation of non-Markovian reward functions and a translation into MDPs aimed at making the best possible use of state-based anytime heuristic search as the solution method."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdps,
        askg-data:Entity-non-markovian_reward_functions,
        askg-data:Entity-state-based_anytime_heuristic_search .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4915 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Our representation extends future linear temporal logic to express rewards."@en ;
    askg-onto:inSentence "Our representation extends future linear temporal logic to express rewards."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_linear_temporal_logic,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4916 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Our translation has the effect of embedding model-checking in the solution method."@en ;
    askg-onto:inSentence "Our translation has the effect of embedding model-checking in the solution method."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model-checking,
        askg-data:Entity-solution_method,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4917 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "It results in an MDP of the minimal size achievable without stepping outside the anytime framework, and consequently in better policies by the deadline."@en ;
    askg-onto:inSentence "It results in an MDP of the minimal size achievable without stepping outside the anytime framework, and consequently in better policies by the deadline."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_framework,
        askg-data:Entity-better_policies,
        askg-data:Entity-deadline,
        askg-data:Entity-mdp,
        askg-data:Entity-minimal_size_achievable .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4918 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We have described nmrdpp**, a software platform that** implements such approaches under a common interface, and which proved a useful tool in their experimental analysis."@en ;
    askg-onto:inSentence "We have described nmrdpp**, a software platform that** implements such approaches under a common interface, and which proved a useful tool in their experimental analysis."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-experimental_analysis,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-software_platform .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-491-Sentence-4919 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Both the system and the analysis are the first of their kind."@en ;
    askg-onto:inSentence "Both the system and the analysis are the first of their kind."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-system,
        askg-data:Entity-their_kind .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "A detailed comparison of our approach to solving NMRDPs with existing methods (Bacchus et al., 1996, 1997) can be found in Sections 3.10 and 5. Two important aspects of future work would help take the comparison further. One is to settle the question of the appropriateness of our translation to structured solution methods. Symbolic implementations of the solution methods we consider, e.g. symbolic LAO* (Feng & **Hansen, 2002), as well as** formula progression in the context of symbolic state representations (Pistore & Traverso, 2001) could be investigated for that purpose. The other is to **take advantage of the greater** expressive power of $FLTL to consider a richer class of decision processes, for instance with uncertainty as to which rewards are received and when. Many extensions of the language are possible: adding eventualities, unrestricted negation, first-class reward propositions, quantitative time, etc. Of course, dealing with them via progression without backtracking is another matter."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4921,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4922,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4923,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4924,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4925,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4926,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4927,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4928 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A detailed comparison of our approach to solving NMRDPs with existing methods (Bacchus et al., 1996, 1997) can be found in Sections 3.10 and 5."@en ;
    askg-onto:inSentence "A detailed comparison of our approach to solving NMRDPs with existing methods (Bacchus et al., 1996, 1997) can be found in Sections 3.10 and 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996_1997,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-nmrdps,
        askg-data:Entity-our_approach .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4922 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Two important aspects of future work would help take the comparison further."@en ;
    askg-onto:inSentence "Two important aspects of future work would help take the comparison further."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-comparison,
        askg-data:Entity-future_work .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4923 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "One is to settle the question of the appropriateness of our translation to structured solution methods."@en ;
    askg-onto:inSentence "One is to settle the question of the appropriateness of our translation to structured solution methods."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-structured_solution_methods,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4924 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Symbolic implementations of the solution methods we consider, e.g."@en ;
    askg-onto:inSentence "Symbolic implementations of the solution methods we consider, e.g."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-solution_methods,
        askg-data:Entity-symbolic .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4925 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "symbolic LAO* (Feng & **Hansen, 2002), as well as** formula progression in the context of symbolic state representations (Pistore & Traverso, 2001) could be investigated for that purpose."@en ;
    askg-onto:inSentence "symbolic LAO* (Feng & **Hansen, 2002), as well as** formula progression in the context of symbolic state representations (Pistore & Traverso, 2001) could be investigated for that purpose."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-concept,
        askg-data:Entity-feng__hansen_2002,
        askg-data:Entity-formula_progression,
        askg-data:Entity-model,
        askg-data:Entity-pistore__traverso_2001,
        askg-data:Entity-research_field,
        askg-data:Entity-symbolic_lao,
        askg-data:Entity-symbolic_state_representations .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4926 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The other is to **take advantage of the greater** expressive power of $FLTL to consider a richer class of decision processes, for instance with uncertainty as to which rewards are received and when."@en ;
    askg-onto:inSentence "The other is to **take advantage of the greater** expressive power of $FLTL to consider a richer class of decision processes, for instance with uncertainty as to which rewards are received and when."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_richer_class,
        askg-data:Entity-decision_processes,
        askg-data:Entity-fltl,
        askg-data:Entity-greater_expressive_power,
        askg-data:Entity-rewards,
        askg-data:Entity-uncertainty,
        askg-data:Entity-when .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4927 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Many extensions of the language are possible: adding eventualities, unrestricted negation, first-class reward propositions, quantitative time, etc."@en ;
    askg-onto:inSentence "Many extensions of the language are possible: adding eventualities, unrestricted negation, first-class reward propositions, quantitative time, etc."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eventualities,
        askg-data:Entity-first-class_reward_propositions,
        askg-data:Entity-language,
        askg-data:Entity-quantitative_time,
        askg-data:Entity-unrestricted_negation .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-492-Sentence-4928 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Of course, dealing with them via progression without backtracking is another matter."@en ;
    askg-onto:inSentence "Of course, dealing with them via progression without backtracking is another matter."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backtracking,
        askg-data:Entity-dealing,
        askg-data:Entity-progression .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "We should investigate the precise relationship between our **line of work and recent work** on planning for temporally extended goals in non-deterministic domains. Of particular interest are 'weak' temporally extended goals such as those **expressible in the Eagle language** (Dal Lago et al., 2002), and temporally extended goals expressible in π**-CTL* (Baral &** Zhao, 2004). Eagle enables the expression of attempted reachability and maintenance goals of the form \"try-reach p\" and \"try-maintain p\", which add to the goals \"do-reach p**\" and** \"do-maintain p**\" already expressible in CTL. The idea is that the generated policy should** make every attempt at satisfying proposition p**. Furthermore, Eagle includes recovery goals** of the form \"g1 fail g2\", meaning that goal g2 must be achieved whenever goal g1 **fails, and** cyclic goals of the form \"repeat g\", meaning that g **should be achieved cyclically until it** fails. The semantics of these goals is given in terms of variants of B¨uchi tree automata with preferred transitions. Dal Lago et al. (2002) present a **planning algorithm based on** symbolic model-checking which generates policies achieving those goals. Baral and Zhao (2004) describe π**-CTL*, an alternative framework for expressing a subset of Eagle goals** and a variety of others. π**-CTL* is a variant of CTL* which allows for formulae involving** two types of path quantifiers: quantifiers tied to the paths feasible under the generated policy, as is usual, but also quantifiers more generally tied **to the paths feasible under any** of the domain actions. Baral and Zhao (2004) do not present any planning algorithm. It would be very interesting to know whether Eagle and π-CTL* goals can be encoded as non- Markovian rewards in our framework. An immediate consequence would be that **nmrdpp** could be used to plan for them. More generally, we would like to examine the respective merits of non-deterministic planning for temporally extended goals and decision-theoretic planning with non-Markovian rewards."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4931,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49310,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49311,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49312,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49313,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49314,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4932,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4933,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4934,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4935,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4936,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4937,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4938,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4939 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We should investigate the precise relationship between our **line of work and recent work** on planning for temporally extended goals in non-deterministic domains."@en ;
    askg-onto:inSentence "We should investigate the precise relationship between our **line of work and recent work** on planning for temporally extended goals in non-deterministic domains."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-line_of_work,
        askg-data:Entity-non-deterministic_domains,
        askg-data:Entity-planning_for_temporally_extended_goals,
        askg-data:Entity-recent_work .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "π**-CTL* is a variant of CTL* which allows for formulae involving** two types of path quantifiers: quantifiers tied to the paths feasible under the generated policy, as is usual, but also quantifiers more generally tied **to the paths feasible under any** of the domain actions."@en ;
    askg-onto:inSentence "π**-CTL* is a variant of CTL* which allows for formulae involving** two types of path quantifiers: quantifiers tied to the paths feasible under the generated policy, as is usual, but also quantifiers more generally tied **to the paths feasible under any** of the domain actions."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%80-ctl,
        askg-data:Entity-ctl,
        askg-data:Entity-path_quantifiers,
        askg-data:Entity-paths_feasible_under_any_of_the_domain_actions,
        askg-data:Entity-paths_feasible_under_the_generated_policy,
        askg-data:Entity-quantifiers,
        askg-data:Entity-two_types .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Baral and Zhao (2004) do not present any planning algorithm."@en ;
    askg-onto:inSentence "Baral and Zhao (2004) do not present any planning algorithm."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baral_and_zhao,
        askg-data:Entity-planning_algorithm .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "It would be very interesting to know whether Eagle and π-CTL* goals can be encoded as non- Markovian rewards in our framework."@en ;
    askg-onto:inSentence "It would be very interesting to know whether Eagle and π-CTL* goals can be encoded as non- Markovian rewards in our framework."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%80-ctl_goals,
        askg-data:Entity-eagle,
        askg-data:Entity-non-markovian_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "An immediate consequence would be that **nmrdpp** could be used to plan for them."@en ;
    askg-onto:inSentence "An immediate consequence would be that **nmrdpp** could be used to plan for them."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-them .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-49314 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "More generally, we would like to examine the respective merits of non-deterministic planning for temporally extended goals and decision-theoretic planning with non-Markovian rewards."@en ;
    askg-onto:inSentence "More generally, we would like to examine the respective merits of non-deterministic planning for temporally extended goals and decision-theoretic planning with non-Markovian rewards."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-non-deterministic_planning,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-temporally_extended_goals .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Of particular interest are 'weak' temporally extended goals such as those **expressible in the Eagle language** (Dal Lago et al., 2002), and temporally extended goals expressible in π**-CTL* (Baral &** Zhao, 2004)."@en ;
    askg-onto:inSentence "Of particular interest are 'weak' temporally extended goals such as those **expressible in the Eagle language** (Dal Lago et al., 2002), and temporally extended goals expressible in π**-CTL* (Baral &** Zhao, 2004)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%80-ctl,
        askg-data:Entity-baral__zhao_2004,
        askg-data:Entity-dal_lago_et_al_2002,
        askg-data:Entity-eagle_language,
        askg-data:Entity-temporally_extended_goals,
        askg-data:Entity-weak_temporally_extended_goals .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4933 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Eagle enables the expression of attempted reachability and maintenance goals of the form \"try-reach p\" and \"try-maintain p\", which add to the goals \"do-reach p**\" and** \"do-maintain p**\" already expressible in CTL."@en ;
    askg-onto:inSentence "Eagle enables the expression of attempted reachability and maintenance goals of the form \"try-reach p\" and \"try-maintain p\", which add to the goals \"do-reach p**\" and** \"do-maintain p**\" already expressible in CTL."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-do-maintain_p,
        askg-data:Entity-do-reach_p,
        askg-data:Entity-eagle,
        askg-data:Entity-expression_of_attempted_reachability_and_maintenance_goals,
        askg-data:Entity-try-maintain_p,
        askg-data:Entity-try-reach_p .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4934 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The idea is that the generated policy should** make every attempt at satisfying proposition p**."@en ;
    askg-onto:inSentence "The idea is that the generated policy should** make every attempt at satisfying proposition p**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-policy,
        askg-data:Entity-proposition_p .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4935 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Furthermore, Eagle includes recovery goals** of the form \"g1 fail g2\", meaning that goal g2 must be achieved whenever goal g1 **fails, and** cyclic goals of the form \"repeat g\", meaning that g **should be achieved cyclically until it** fails."@en ;
    askg-onto:inSentence "Furthermore, Eagle includes recovery goals** of the form \"g1 fail g2\", meaning that goal g2 must be achieved whenever goal g1 **fails, and** cyclic goals of the form \"repeat g\", meaning that g **should be achieved cyclically until it** fails."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eagle,
        askg-data:Entity-fails,
        askg-data:Entity-g,
        askg-data:Entity-g1,
        askg-data:Entity-g1_fail_g2,
        askg-data:Entity-g2,
        askg-data:Entity-recovery_goals,
        askg-data:Entity-repeat_g .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4936 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The semantics of these goals is given in terms of variants of B¨uchi tree automata with preferred transitions."@en ;
    askg-onto:inSentence "The semantics of these goals is given in terms of variants of B¨uchi tree automata with preferred transitions."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b%C3%BCchi_tree_automata,
        askg-data:Entity-variants .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4937 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Dal Lago et al."@en ;
    askg-onto:inSentence "Dal Lago et al."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-dal_lago_et_al .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4938 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "(2002) present a **planning algorithm based on** symbolic model-checking which generates policies achieving those goals."@en ;
    askg-onto:inSentence "(2002) present a **planning algorithm based on** symbolic model-checking which generates policies achieving those goals."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planning_algorithm,
        askg-data:Entity-policies,
        askg-data:Entity-symbolic_model-checking .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-493-Sentence-4939 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Baral and Zhao (2004) describe π**-CTL*, an alternative framework for expressing a subset of Eagle goals** and a variety of others."@en ;
    askg-onto:inSentence "Baral and Zhao (2004) describe π**-CTL*, an alternative framework for expressing a subset of Eagle goals** and a variety of others."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%80-ctl,
        askg-data:Entity-baral_and_zhao,
        askg-data:Entity-eagle_goals .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "In the pure probabilistic setting (no rewards), recent related research includes work on planning and controller synthesis for probabilistic temporally extended goals expressible in probabilistic temporal logics such as CSL or PCTL (Younes & Simmons, 2004; Baier et al., 2004). These logics enable expressing statements about the probability of the policy satisfying a given temporal goal exceeding a given threshold. For **instance, Younes and Simmons** (2004) describe a very general probabilistic planning framework, involving concurrency, continuous time, and temporally extended goals, rich enough to **model generalised semi-Markov** processes. The solution algorithms are not directly comparable to those presented here."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4941,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4942,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4943,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4944 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In the pure probabilistic setting (no rewards), recent related research includes work on planning and controller synthesis for probabilistic temporally extended goals expressible in probabilistic temporal logics such as CSL or PCTL (Younes & Simmons, 2004; Baier et al., 2004)."@en ;
    askg-onto:inSentence "In the pure probabilistic setting (no rewards), recent related research includes work on planning and controller synthesis for probabilistic temporally extended goals expressible in probabilistic temporal logics such as CSL or PCTL (Younes & Simmons, 2004; Baier et al., 2004)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-baier_et_al_2004,
        askg-data:Entity-csl,
        askg-data:Entity-paper,
        askg-data:Entity-pctl,
        askg-data:Entity-planning_and_controller_synthesis,
        askg-data:Entity-probabilistic_temporal_logics,
        askg-data:Entity-related_research,
        askg-data:Entity-younes__simmons_2004 .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4942 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These logics enable expressing statements about the probability of the policy satisfying a given temporal goal exceeding a given threshold."@en ;
    askg-onto:inSentence "These logics enable expressing statements about the probability of the policy satisfying a given temporal goal exceeding a given threshold."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-policy,
        askg-data:Entity-temporal_goal,
        askg-data:Entity-threshold .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4943 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For **instance, Younes and Simmons** (2004) describe a very general probabilistic planning framework, involving concurrency, continuous time, and temporally extended goals, rich enough to **model generalised semi-Markov** processes."@en ;
    askg-onto:inSentence "For **instance, Younes and Simmons** (2004) describe a very general probabilistic planning framework, involving concurrency, continuous time, and temporally extended goals, rich enough to **model generalised semi-Markov** processes."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_very_general_probabilistic_planning_framework,
        askg-data:Entity-generalised_semi-markov_processes,
        askg-data:Entity-simmons,
        askg-data:Entity-younes .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-494-Sentence-4944 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The solution algorithms are not directly comparable to those presented here."@en ;
    askg-onto:inSentence "The solution algorithms are not directly comparable to those presented here."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-solution_algorithms,
        askg-data:Entity-those_presented_here .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Another exciting future work area is the investigation of temporal logic formalisms for specifying heuristic functions for NMRDPs or more generally for search problems with temporally extended goals. Good heuristics are important to some of the solution methods we are targeting, and surely their value ought to depend on history. The methods we have described could be applicable to the description and processing of such heuristics. Related to this is the problem of extending search control knowledge to fully **operate under the** presence of temporally extended goals, rewards, and stochastic actions. A first issue is that branching or probabilistic logics such as CTL or PCTL variants should be preferred to FLTL when describing search control knowledge, because when stochastic actions are involved, search control often needs to refer to some **of the possible futures and even to** their probabilities.18 **Another major problem is that the GOALP modality, which is the** key to the specification of reusable search control knowledge is interpreted with respect to"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4951,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4952,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4953,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4954,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4955 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Another exciting future work area is the investigation of temporal logic formalisms for specifying heuristic functions for NMRDPs or more generally for search problems with temporally extended goals."@en ;
    askg-onto:inSentence "Another exciting future work area is the investigation of temporal logic formalisms for specifying heuristic functions for NMRDPs or more generally for search problems with temporally extended goals."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristic_functions,
        askg-data:Entity-nmrdps,
        askg-data:Entity-search_problems,
        askg-data:Entity-temporal_logic_formalisms,
        askg-data:Entity-temporally_extended_goals .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4952 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Good heuristics are important to some of the solution methods we are targeting, and surely their value ought to depend on history."@en ;
    askg-onto:inSentence "Good heuristics are important to some of the solution methods we are targeting, and surely their value ought to depend on history."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-good_heuristics,
        askg-data:Entity-history,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4953 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The methods we have described could be applicable to the description and processing of such heuristics."@en ;
    askg-onto:inSentence "The methods we have described could be applicable to the description and processing of such heuristics."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-description_and_processing,
        askg-data:Entity-methods .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4954 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Related to this is the problem of extending search control knowledge to fully **operate under the** presence of temporally extended goals, rewards, and stochastic actions."@en ;
    askg-onto:inSentence "Related to this is the problem of extending search control knowledge to fully **operate under the** presence of temporally extended goals, rewards, and stochastic actions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rewards,
        askg-data:Entity-search_control_knowledge,
        askg-data:Entity-stochastic_actions,
        askg-data:Entity-temporally_extended_goals .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-495-Sentence-4955 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "A first issue is that branching or probabilistic logics such as CTL or PCTL variants should be preferred to FLTL when describing search control knowledge, because when stochastic actions are involved, search control often needs to refer to some **of the possible futures and even to** their probabilities.18 **Another major problem is that the GOALP modality, which is the** key to the specification of reusable search control knowledge is interpreted with respect to"@en ;
    askg-onto:inSentence "A first issue is that branching or probabilistic logics such as CTL or PCTL variants should be preferred to FLTL when describing search control knowledge, because when stochastic actions are involved, search control often needs to refer to some **of the possible futures and even to** their probabilities.18 **Another major problem is that the GOALP modality, which is the** key to the specification of reusable search control knowledge is interpreted with respect to"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-branching_or_probabilistic_logics,
        askg-data:Entity-ctl_or_pctl_variants,
        askg-data:Entity-fltl,
        askg-data:Entity-goalp_modality,
        askg-data:Entity-possible_futures,
        askg-data:Entity-search_control_knowledge,
        askg-data:Entity-specification_of_reusable_search_control_knowledge,
        askg-data:Entity-their_probabilities .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "18. We would not **argue, on the other hand, that CTL is necessary for representing non-Markovian** rewards. a fixed reachability goal19 **(Bacchus & Kabanza, 2000), and as such, is not applicable to** domains with temporally extended goals, let alone rewards. **Kabanza and Thi´ebaux (2005)** present a first approach to search control in the presence of temporally extended goals in deterministic domains, but much remains to be done for a system like nmrdpp **to be able** to support a meaningful extension of GOALP."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4961,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4962,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4963,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4964 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4961 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "18."@en ;
    askg-onto:inSentence "18."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-person,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-research_group,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-system,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4962 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We would not **argue, on the other hand, that CTL is necessary for representing non-Markovian** rewards."@en ;
    askg-onto:inSentence "We would not **argue, on the other hand, that CTL is necessary for representing non-Markovian** rewards."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ctl,
        askg-data:Entity-non-markovian_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4963 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "a fixed reachability goal19 **(Bacchus & Kabanza, 2000), and as such, is not applicable to** domains with temporally extended goals, let alone rewards."@en ;
    askg-onto:inSentence "a fixed reachability goal19 **(Bacchus & Kabanza, 2000), and as such, is not applicable to** domains with temporally extended goals, let alone rewards."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_fixed_reachability_goal,
        askg-data:Entity-bacchus__kabanza .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-496-Sentence-4964 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "**Kabanza and Thi´ebaux (2005)** present a first approach to search control in the presence of temporally extended goals in deterministic domains, but much remains to be done for a system like nmrdpp **to be able** to support a meaningful extension of GOALP."@en ;
    askg-onto:inSentence "**Kabanza and Thi´ebaux (2005)** present a first approach to search control in the presence of temporally extended goals in deterministic domains, but much remains to be done for a system like nmrdpp **to be able** to support a meaningful extension of GOALP."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_meaningful_extension,
        askg-data:Entity-a_meaningful_extension_of_goalp,
        askg-data:Entity-approach_to_search_control_in_the_presence_of_temporally_extended_goals,
        askg-data:Entity-goalp,
        askg-data:Entity-kabanza_and_thiebaux,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-497 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Finally, let us mention that related work in the area of databases uses a similar approach to pltlstr **to extend a database with auxiliary relations containing sufficient information** to check temporal integrity constraints (Chomicki, 1995). **The issues are somewhat different** from those raised by NMRDPs: as there is only ever one sequence of databases, what matters is more the size of these auxiliary relations than avoiding making redundant distinctions."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-497-Sentence-4971,
        askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-497-Sentence-4972 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-497-Sentence-4971 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Finally, let us mention that related work in the area of databases uses a similar approach to pltlstr **to extend a database with auxiliary relations containing sufficient information** to check temporal integrity constraints (Chomicki, 1995)."@en ;
    askg-onto:inSentence "Finally, let us mention that related work in the area of databases uses a similar approach to pltlstr **to extend a database with auxiliary relations containing sufficient information** to check temporal integrity constraints (Chomicki, 1995)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-auxiliary_relations,
        askg-data:Entity-chomicki,
        askg-data:Entity-databases,
        askg-data:Entity-related_work,
        askg-data:Entity-similar_approach_to_pltlstr,
        askg-data:Entity-sufficient_information,
        askg-data:Entity-temporal_integrity_constraints .

askg-data:Paper-c253584c3f1ff2a2-Section-49-Paragraph-497-Sentence-4972 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**The issues are somewhat different** from those raised by NMRDPs: as there is only ever one sequence of databases, what matters is more the size of these auxiliary relations than avoiding making redundant distinctions."@en ;
    askg-onto:inSentence "**The issues are somewhat different** from those raised by NMRDPs: as there is only ever one sequence of databases, what matters is more the size of these auxiliary relations than avoiding making redundant distinctions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-issues,
        askg-data:Entity-nmrdps .

askg-data:Paper-c253584c3f1ff2a2-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "1.2 Existing Approaches"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "When solving NMRDPs in this setting, the central issue is to define a non-Markovian reward specification language and a translation into an MDP adapted **to the class of MDP solution** methods and representations we would like to use for the type **of problems at hand. More** precisely, there is a tradeoff between the effort spent in the translation, e.g. in producing a small **equivalent MDP without many irrelevant history distinctions, and the effort required** to solve it. Appropriate resolution of this tradeoff depends **on the type of representations** and solution methods envisioned for the MDP. For instance, structured **representations and** solution methods which have some ability to ignore irrelevant information may cope with a crude translation, while state-based **(flat) representations and methods will require a more** sophisticated translation producing an MDP as small as feasible."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-511,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-512,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-513,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-514,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-515 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "When solving NMRDPs in this setting, the central issue is to define a non-Markovian reward specification language and a translation into an MDP adapted **to the class of MDP solution** methods and representations we would like to use for the type **of problems at hand."@en ;
    askg-onto:inSentence "When solving NMRDPs in this setting, the central issue is to define a non-Markovian reward specification language and a translation into an MDP adapted **to the class of MDP solution** methods and representations we would like to use for the type **of problems at hand."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-class_of_mdp_solution_methods,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdps,
        askg-data:Entity-non-markovian_reward_specification_language,
        askg-data:Entity-problems,
        askg-data:Entity-problems_at_hand,
        askg-data:Entity-representations .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "More** precisely, there is a tradeoff between the effort spent in the translation, e.g."@en ;
    askg-onto:inSentence "More** precisely, there is a tradeoff between the effort spent in the translation, e.g."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effort,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "in producing a small **equivalent MDP without many irrelevant history distinctions, and the effort required** to solve it."@en ;
    askg-onto:inSentence "in producing a small **equivalent MDP without many irrelevant history distinctions, and the effort required** to solve it."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effort,
        askg-data:Entity-mdp,
        askg-data:Entity-small_equivalent_mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Appropriate resolution of this tradeoff depends **on the type of representations** and solution methods envisioned for the MDP."@en ;
    askg-onto:inSentence "Appropriate resolution of this tradeoff depends **on the type of representations** and solution methods envisioned for the MDP."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-solution_methods,
        askg-data:Entity-type_of_representations .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-51-Sentence-515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For instance, structured **representations and** solution methods which have some ability to ignore irrelevant information may cope with a crude translation, while state-based **(flat) representations and methods will require a more** sophisticated translation producing an MDP as small as feasible."@en ;
    askg-onto:inSentence "For instance, structured **representations and** solution methods which have some ability to ignore irrelevant information may cope with a crude translation, while state-based **(flat) representations and methods will require a more** sophisticated translation producing an MDP as small as feasible."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-irrelevant_information,
        askg-data:Entity-mdp,
        askg-data:Entity-sophisticated_translation,
        askg-data:Entity-state-based_flat_representations,
        askg-data:Entity-structured_representations .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Both the two previous proposals within this line of research **rely on past linear temporal** logic (PLTL) formulae to specify the behaviours to be rewarded (Bacchus et al., 1996, 1997). A nice feature of PLTL is that it yields a straightforward semantics of non-Markovian rewards, and lends itself to a range of translations from the **crudest to the finest. The two** proposals adopt very different translations adapted to two very different types of solution methods and representations. The first (Bacchus et al., 1996) targets classical state-based solution methods such as policy iteration (Howard, 1960) which generate complete **policies** at the cost of enumerating all states in the entire MDP. Consequently, it adopts an expensive translation which attempts to produce a minimal **MDP. By contrast, the second translation** (Bacchus et al., 1997) is very efficient but crude, and targets **structured solution methods** and representations (see e.g., Hoey, St-Aubin, Hu, & Boutilier, 1999; Boutilier, Dearden, & Goldszmidt, 2000; Feng & Hansen, 2002), which do not require **explicit state enumeration.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-521,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-522,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-523,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-524,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-525,
        askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-526 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Both the two previous proposals within this line of research **rely on past linear temporal** logic (PLTL) formulae to specify the behaviours to be rewarded (Bacchus et al., 1996, 1997)."@en ;
    askg-onto:inSentence "Both the two previous proposals within this line of research **rely on past linear temporal** logic (PLTL) formulae to specify the behaviours to be rewarded (Bacchus et al., 1996, 1997)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996_1997,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-behaviours_to_be_rewarded,
        askg-data:Entity-past_linear_temporal_logic_pltl .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A nice feature of PLTL is that it yields a straightforward semantics of non-Markovian rewards, and lends itself to a range of translations from the **crudest to the finest."@en ;
    askg-onto:inSentence "A nice feature of PLTL is that it yields a straightforward semantics of non-Markovian rewards, and lends itself to a range of translations from the **crudest to the finest."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl,
        askg-data:Entity-semantics_of_non-markovian_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The two** proposals adopt very different translations adapted to two very different types of solution methods and representations."@en ;
    askg-onto:inSentence "The two** proposals adopt very different translations adapted to two very different types of solution methods and representations."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proposals,
        askg-data:Entity-representations,
        askg-data:Entity-solution_methods,
        askg-data:Entity-translations .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The first (Bacchus et al., 1996) targets classical state-based solution methods such as policy iteration (Howard, 1960) which generate complete **policies** at the cost of enumerating all states in the entire MDP."@en ;
    askg-onto:inSentence "The first (Bacchus et al., 1996) targets classical state-based solution methods such as policy iteration (Howard, 1960) which generate complete **policies** at the cost of enumerating all states in the entire MDP."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al_1996,
        askg-data:Entity-classical_state-based_solution_methods,
        askg-data:Entity-complete_policies,
        askg-data:Entity-howard_1960,
        askg-data:Entity-policy_iteration .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Consequently, it adopts an expensive translation which attempts to produce a minimal **MDP."@en ;
    askg-onto:inSentence "Consequently, it adopts an expensive translation which attempts to produce a minimal **MDP."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-model .

askg-data:Paper-c253584c3f1ff2a2-Section-5-Paragraph-52-Sentence-526 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "By contrast, the second translation** (Bacchus et al., 1997) is very efficient but crude, and targets **structured solution methods** and representations (see e.g., Hoey, St-Aubin, Hu, & Boutilier, 1999; Boutilier, Dearden, & Goldszmidt, 2000; Feng & Hansen, 2002), which do not require **explicit state enumeration.**"@en ;
    askg-onto:inSentence "By contrast, the second translation** (Bacchus et al., 1997) is very efficient but crude, and targets **structured solution methods** and representations (see e.g., Hoey, St-Aubin, Hu, & Boutilier, 1999; Boutilier, Dearden, & Goldszmidt, 2000; Feng & Hansen, 2002), which do not require **explicit state enumeration.**"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1997,
        askg-data:Entity-1999,
        askg-data:Entity-2000,
        askg-data:Entity-2002,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-boutilier_dearden__goldszmidt,
        askg-data:Entity-explicit_state_enumeration,
        askg-data:Entity-feng__hansen,
        askg-data:Entity-hoey_st-aubin_hu__boutilier,
        askg-data:Entity-representations,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-50 a askg-onto:Section ;
    rdfs:label "Section 50"@en ;
    domo:Text "Acknowledgements"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501 ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Many thanks to Fahiem Bacchus, Rajeev Gor´e, Marco Pistore, **Ron van der Meyden, Moshe** Vardi, and Lenore Zuck for useful discussions and comments, **as well as to the anonymous** reviewers and to David Smith for their thorough reading of the paper and their excellent suggestions. Sylvie Thi´ebaux, Charles Gretton, John Slaney, and David Price thank National ICT Australia for its support. NICTA is funded through the Australian Government's Backing Australia's Ability initiative, in part through the Australian Research Council. Froduald Kabanza is supported by the Canadian Natural Sciences **and Engineering Research** Council (NSERC)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5011,
        askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5012,
        askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5013,
        askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5014 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Many thanks to Fahiem Bacchus, Rajeev Gor´e, Marco Pistore, **Ron van der Meyden, Moshe** Vardi, and Lenore Zuck for useful discussions and comments, **as well as to the anonymous** reviewers and to David Smith for their thorough reading of the paper and their excellent suggestions."@en ;
    askg-onto:inSentence "Many thanks to Fahiem Bacchus, Rajeev Gor´e, Marco Pistore, **Ron van der Meyden, Moshe** Vardi, and Lenore Zuck for useful discussions and comments, **as well as to the anonymous** reviewers and to David Smith for their thorough reading of the paper and their excellent suggestions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anonymous_reviewers,
        askg-data:Entity-david_smith,
        askg-data:Entity-fahiem_bacchus,
        askg-data:Entity-lenore_zuck,
        askg-data:Entity-marco_pistore,
        askg-data:Entity-moshe_vardi,
        askg-data:Entity-rajeev_gor%C3%A9,
        askg-data:Entity-ron_van_der_meyden,
        askg-data:Entity-the_paper .

askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Sylvie Thi´ebaux, Charles Gretton, John Slaney, and David Price thank National ICT Australia for its support."@en ;
    askg-onto:inSentence "Sylvie Thi´ebaux, Charles Gretton, John Slaney, and David Price thank National ICT Australia for its support."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-charles_gretton,
        askg-data:Entity-david_price,
        askg-data:Entity-john_slaney,
        askg-data:Entity-national_ict_australia,
        askg-data:Entity-sylvie_thiebaux .

askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "NICTA is funded through the Australian Government's Backing Australia's Ability initiative, in part through the Australian Research Council."@en ;
    askg-onto:inSentence "NICTA is funded through the Australian Government's Backing Australia's Ability initiative, in part through the Australian Research Council."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nicta,
        askg-data:Entity-the_australian_governments_backing_australias_ability_initiative,
        askg-data:Entity-the_australian_research_council .

askg-data:Paper-c253584c3f1ff2a2-Section-50-Paragraph-501-Sentence-5014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Froduald Kabanza is supported by the Canadian Natural Sciences **and Engineering Research** Council (NSERC)."@en ;
    askg-onto:inSentence "Froduald Kabanza is supported by the Canadian Natural Sciences **and Engineering Research** Council (NSERC)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-canadian_natural_sciences_and_engineering_research_council_nserc,
        askg-data:Entity-froduald_kabanza .

askg-data:Paper-c253584c3f1ff2a2-Section-51 a askg-onto:Section ;
    rdfs:label "Section 51"@en ;
    domo:Text "Appendix A. A Class Of Reward-Normal Formulae"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-511,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-512,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515 ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-511 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The existing decision procedure (Slaney, 2005) for determining whether a formula is rewardnormal is guaranteed to terminate finitely, but involves the **construction and comparison of** automata and is rather intricate in practice. It is therefore useful to give a simple syntactic characterisation of a set of constructors for obtaining reward-normal formulae even though not all such formulae are so constructible."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-511-Sentence-5111,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-511-Sentence-5112 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-511-Sentence-5111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The existing decision procedure (Slaney, 2005) for determining whether a formula is rewardnormal is guaranteed to terminate finitely, but involves the **construction and comparison of** automata and is rather intricate in practice."@en ;
    askg-onto:inSentence "The existing decision procedure (Slaney, 2005) for determining whether a formula is rewardnormal is guaranteed to terminate finitely, but involves the **construction and comparison of** automata and is rather intricate in practice."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automata,
        askg-data:Entity-construction_and_comparison,
        askg-data:Entity-decision_procedure,
        askg-data:Entity-rewardnormal,
        askg-data:Entity-slaney_2005,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-511-Sentence-5112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It is therefore useful to give a simple syntactic characterisation of a set of constructors for obtaining reward-normal formulae even though not all such formulae are so constructible."@en ;
    askg-onto:inSentence "It is therefore useful to give a simple syntactic characterisation of a set of constructors for obtaining reward-normal formulae even though not all such formulae are so constructible."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constructors,
        askg-data:Entity-formulae,
        askg-data:Entity-reward-normal_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-512 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We say that a formula is material **iff it contains no $ and no temporal operators - that** is, the material formulae are the boolean combinations of atoms."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-512-Sentence-5121 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-512-Sentence-5121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We say that a formula is material **iff it contains no $ and no temporal operators - that** is, the material formulae are the boolean combinations of atoms."@en ;
    askg-onto:inSentence "We say that a formula is material **iff it contains no $ and no temporal operators - that** is, the material formulae are the boolean combinations of atoms."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-boolean_combinations_of_atoms,
        askg-data:Entity-material_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "We consider four operations on behaviours representable by **formulae of $FLTL. Firstly,** a behaviour may be delayed for a specified number of timesteps. Secondly, it may be made conditional on a material trigger. Thirdly, it may be started repeatedly until a material termination condition is met. Fourthly, two behaviours may **be combined to form their** union. These operations are easily realised syntactically **by corresponding operations on** formulae. Where m **is any material formula:**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5131,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5132,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5133,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5134,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5135,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5136,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5137 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We consider four operations on behaviours representable by **formulae of $FLTL."@en ;
    askg-onto:inSentence "We consider four operations on behaviours representable by **formulae of $FLTL."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-formulae_of_fltl .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Firstly,** a behaviour may be delayed for a specified number of timesteps."@en ;
    askg-onto:inSentence "Firstly,** a behaviour may be delayed for a specified number of timesteps."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviour,
        askg-data:Entity-specified_number_of_timesteps .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Secondly, it may be made conditional on a material trigger."@en ;
    askg-onto:inSentence "Secondly, it may be made conditional on a material trigger."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition,
        askg-data:Entity-material_trigger .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Thirdly, it may be started repeatedly until a material termination condition is met."@en ;
    askg-onto:inSentence "Thirdly, it may be started repeatedly until a material termination condition is met."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition,
        askg-data:Entity-termination_condition .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Fourthly, two behaviours may **be combined to form their** union."@en ;
    askg-onto:inSentence "Fourthly, two behaviours may **be combined to form their** union."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-union .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5136 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "These operations are easily realised syntactically **by corresponding operations on** formulae."@en ;
    askg-onto:inSentence "These operations are easily realised syntactically **by corresponding operations on** formulae."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-operations .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-513-Sentence-5137 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Where m **is any material formula:**"@en ;
    askg-onto:inSentence "Where m **is any material formula:**"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_material_formula,
        askg-data:Entity-m .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$\\begin{array}{ccc}\\sigma[f]&=&\\bigcirc f\\end{array}$ $\\begin{array}{ccc}\\text{ord}[m,f]&=&m\\to f\\\\ \\\\[-4mm]\\text{loop}[m,f]&=&f\\,\\text{U}\\,m\\\\ \\\\[-4mm]\\text{union}[f_1,f_2]&=&f_1\\wedge f_2\\end{array}$ GOALB(f) is true iff f is true. 19. Where f is an atemporal formula, GOALP(f) is true iff f **is true of all goal states.** We have shown (Slaney, 2005) that the set of reward-normal formulae is closed under delay, cond **(for any material** m), loop (for any material m**) and** union**, and also that the closure** of {$} **under these operations represents a class of behaviours closed under intersection and** concatenation as well as union."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514-Sentence-5141,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514-Sentence-5142,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514-Sentence-5143 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514-Sentence-5141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\begin{array}{ccc}\\sigma[f]&=&\\bigcirc f\\end{array}$ $\\begin{array}{ccc}\\text{ord}[m,f]&=&m\\to f\\\\ \\\\[-4mm]\\text{loop}[m,f]&=&f\\,\\text{U}\\,m\\\\ \\\\[-4mm]\\text{union}[f_1,f_2]&=&f_1\\wedge f_2\\end{array}$ GOALB(f) is true iff f is true."@en ;
    askg-onto:inSentence "$\\begin{array}{ccc}\\sigma[f]&=&\\bigcirc f\\end{array}$ $\\begin{array}{ccc}\\text{ord}[m,f]&=&m\\to f\\\\ \\\\[-4mm]\\text{loop}[m,f]&=&f\\,\\text{U}\\,m\\\\ \\\\[-4mm]\\text{union}[f_1,f_2]&=&f_1\\wedge f_2\\end{array}$ GOALB(f) is true iff f is true."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-f1__f2,
        askg-data:Entity-f_u_m,
        askg-data:Entity-goalbf,
        askg-data:Entity-loopmf,
        askg-data:Entity-m,
        askg-data:Entity-unionf1f2 .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514-Sentence-5142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "19."@en ;
    askg-onto:inSentence "19."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-19,
        askg-data:Entity-sequence .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-514-Sentence-5143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Where f is an atemporal formula, GOALP(f) is true iff f **is true of all goal states.** We have shown (Slaney, 2005) that the set of reward-normal formulae is closed under delay, cond **(for any material** m), loop (for any material m**) and** union**, and also that the closure** of {$} **under these operations represents a class of behaviours closed under intersection and** concatenation as well as union."@en ;
    askg-onto:inSentence "Where f is an atemporal formula, GOALP(f) is true iff f **is true of all goal states.** We have shown (Slaney, 2005) that the set of reward-normal formulae is closed under delay, cond **(for any material** m), loop (for any material m**) and** union**, and also that the closure** of {$} **under these operations represents a class of behaviours closed under intersection and** concatenation as well as union."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_class_of_behaviours,
        askg-data:Entity-all_goal_states,
        askg-data:Entity-class_of_behaviours,
        askg-data:Entity-closure_of_,
        askg-data:Entity-delay_cond_loop_union,
        askg-data:Entity-goalpf,
        askg-data:Entity-intersection_concatenation_union,
        askg-data:Entity-set_of_reward-normal_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Many familiar reward-normal formulae are obtainable from $ by applying the four operations. For example, (p → **$) is** loop[⊥, cond[p, **$]]. Sometimes a paraphrase is necessary.** For example, ((p∧q) → $) is not of the required form because of the **in the antecedent** of the conditional, but the equivalent (p → (q → **$)) is** loop[⊥, cond[p, delay[cond[q, **$]]]].** Other cases are not so easy. An example is the formula ¬pU(p∧**$) which stipulates a reward** the first time p **happens and which is not at all of the form suggested. To capture the same** behaviour using the above operations requires a formula like (p → $) ∧ ((p → $)Up)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5151,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5152,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5153,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5154,
        askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5155 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Many familiar reward-normal formulae are obtainable from $ by applying the four operations."@en ;
    askg-onto:inSentence "Many familiar reward-normal formulae are obtainable from $ by applying the four operations."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-reward-normal_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For example, (p → **$) is** loop[⊥, cond[p, **$]]."@en ;
    askg-onto:inSentence "For example, (p → **$) is** loop[⊥, cond[p, **$]]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condp_,
        askg-data:Entity-loop .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Sometimes a paraphrase is necessary.** For example, ((p∧q) → $) is not of the required form because of the **in the antecedent** of the conditional, but the equivalent (p → (q → **$)) is** loop[⊥, cond[p, delay[cond[q, **$]]]].** Other cases are not so easy."@en ;
    askg-onto:inSentence "Sometimes a paraphrase is necessary.** For example, ((p∧q) → $) is not of the required form because of the **in the antecedent** of the conditional, but the equivalent (p → (q → **$)) is** loop[⊥, cond[p, delay[cond[q, **$]]]].** Other cases are not so easy."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-conditional,
        askg-data:Entity-loop_condp_delaycondq_,
        askg-data:Entity-p,
        askg-data:Entity-q .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "An example is the formula ¬pU(p∧**$) which stipulates a reward** the first time p **happens and which is not at all of the form suggested."@en ;
    askg-onto:inSentence "An example is the formula ¬pU(p∧**$) which stipulates a reward** the first time p **happens and which is not at all of the form suggested."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula_pup,
        askg-data:Entity-reward .

askg-data:Paper-c253584c3f1ff2a2-Section-51-Paragraph-515-Sentence-5155 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "To capture the same** behaviour using the above operations requires a formula like (p → $) ∧ ((p → $)Up)."@en ;
    askg-onto:inSentence "To capture the same** behaviour using the above operations requires a formula like (p → $) ∧ ((p → $)Up)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula,
        askg-data:Entity-p__,
        askg-data:Entity-p__up .

askg-data:Paper-c253584c3f1ff2a2-Section-52 a askg-onto:Section ;
    rdfs:label "Section 52"@en ;
    domo:Text "Appendix B. Proofs Of Theorems"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-521,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5210,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5212,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5213,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5216,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5220,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5221,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-523,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-524,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-529 ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-521 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Property 1 Where b ⇔ (Γ(i) ∈ B**), (Γ**,i)|=B f iff (Γ,i **+ 1)**|=B Prog(b, Γi,f)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-521-Sentence-5211 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-521-Sentence-5211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Property 1 Where b ⇔ (Γ(i) ∈ B**), (Γ**,i)|=B f iff (Γ,i **+ 1)**|=B Prog(b, Γi,f)."@en ;
    askg-onto:inSentence "Property 1 Where b ⇔ (Γ(i) ∈ B**), (Γ**,i)|=B f iff (Γ,i **+ 1)**|=B Prog(b, Γi,f)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-%CE%B3i__1,
        askg-data:Entity-%CE%B3i__b,
        askg-data:Entity-b,
        askg-data:Entity-b_progb_%CE%B3if,
        askg-data:Entity-concept,
        askg-data:Entity-i,
        askg-data:Entity-property_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5210 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "D′**is minimal iff every e-state in** S ′**is reachable and** S ′**contains no two distinct e-states** s ′1 and s ′2 **with** τ (s ′1 ) = τ (s ′2 ) and µ(s ′1 ) = µ(s ′2 )."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5210-Sentence-52101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5210-Sentence-52101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "D′**is minimal iff every e-state in** S ′**is reachable and** S ′**contains no two distinct e-states** s ′1 and s ′2 **with** τ (s ′1 ) = τ (s ′2 ) and µ(s ′1 ) = µ(s ′2 )."@en ;
    askg-onto:inSentence "D′**is minimal iff every e-state in** S ′**is reachable and** S ′**contains no two distinct e-states** s ′1 and s ′2 **with** τ (s ′1 ) = τ (s ′2 ) and µ(s ′1 ) = µ(s ′2 )."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C2%B5s_1___%C2%B5s_2_,
        askg-data:Entity-%CF%84_s_1___%CF%84_s_2_,
        askg-data:Entity-d,
        askg-data:Entity-every_e-state_in_s__is_reachable,
        askg-data:Entity-no_two_distinct_e-states_s_1_and_s_2,
        askg-data:Entity-s_,
        askg-data:Entity-s_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Proof: Proof is by construction of the canonical equivalent MDP Dc**. Let the set of** finite prefixes of state sequences in De(s0**) be partitioned into equivalence classes, where** Γ1(i) ≡ Γ2(j) iff Γ1i = Γ2j **and for all ∆** ∈ S ∗such that Γ1(i); ∆ ∈ De(s0), R(Γ1(i**); ∆) =** R(Γ2(j); ∆). Let [Γ(i)] denote the equivalence class of Γ(i). Let E **be the set of these** equivalence classes. Let A be the function that takes each [Γ(i)] in E to A(Γi**). For each** Γ(i) and ∆(j) and for each a ∈ A([Γ(i)]), let T ([Γ(i)],a, [∆(j)]) be Pr(Γi,a,s) if [∆(j**)] =** [Γ(i);hsi]. Otherwise let T ([Γ(i)],a, [∆(j)]) = 0. Let R([Γ(i)]) be R(Γ(i**)). Then note the** following four facts: 1. Each of the functions A, T and R **is well-defined.** 2. Dc = hE, [hs0i], A, T , Ri is an equivalent MDP for D with τ ([Γ(i**)]) = Γ**i."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52111,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-521110,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-521111,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52112,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52113,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52114,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52115,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52116,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52117,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52118,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52119 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof: Proof is by construction of the canonical equivalent MDP Dc**."@en ;
    askg-onto:inSentence "Proof: Proof is by construction of the canonical equivalent MDP Dc**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_dc,
        askg-data:Entity-proof .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-521110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Each of the functions A, T and R **is well-defined.** 2."@en ;
    askg-onto:inSentence "Each of the functions A, T and R **is well-defined.** 2."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-functions_a,
        askg-data:Entity-functions_r,
        askg-data:Entity-functions_t .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-521111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Dc = hE, [hs0i], A, T , Ri is an equivalent MDP for D with τ ([Γ(i**)]) = Γ**i."@en ;
    askg-onto:inSentence "Dc = hE, [hs0i], A, T , Ri is an equivalent MDP for D with τ ([Γ(i**)]) = Γ**i."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CF%84_%CE%B3i,
        askg-data:Entity-d,
        askg-data:Entity-dc .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let the set of** finite prefixes of state sequences in De(s0**) be partitioned into equivalence classes, where** Γ1(i) ≡ Γ2(j) iff Γ1i = Γ2j **and for all ∆** ∈ S ∗such that Γ1(i); ∆ ∈ De(s0), R(Γ1(i**); ∆) =** R(Γ2(j); ∆)."@en ;
    askg-onto:inSentence "Let the set of** finite prefixes of state sequences in De(s0**) be partitioned into equivalence classes, where** Γ1(i) ≡ Γ2(j) iff Γ1i = Γ2j **and for all ∆** ∈ S ∗such that Γ1(i); ∆ ∈ De(s0), R(Γ1(i**); ∆) =** R(Γ2(j); ∆)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B31i,
        askg-data:Entity-%CE%B32j,
        askg-data:Entity-equivalence_classes,
        askg-data:Entity-finite_prefixes,
        askg-data:Entity-r%CE%B31i_,
        askg-data:Entity-r%CE%B32j_ .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Let [Γ(i)] denote the equivalence class of Γ(i)."@en ;
    askg-onto:inSentence "Let [Γ(i)] denote the equivalence class of Γ(i)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-equivalence_class_of_%CE%B3i .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Let E **be the set of these** equivalence classes."@en ;
    askg-onto:inSentence "Let E **be the set of these** equivalence classes."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e,
        askg-data:Entity-equivalence_classes .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52115 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Let A be the function that takes each [Γ(i)] in E to A(Γi**)."@en ;
    askg-onto:inSentence "Let A be the function that takes each [Γ(i)] in E to A(Γi**)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i_in_e_to_a%CE%B3i .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52116 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "For each** Γ(i) and ∆(j) and for each a ∈ A([Γ(i)]), let T ([Γ(i)],a, [∆(j)]) be Pr(Γi,a,s) if [∆(j**)] =** [Γ(i);hsi]."@en ;
    askg-onto:inSentence "For each** Γ(i) and ∆(j) and for each a ∈ A([Γ(i)]), let T ([Γ(i)],a, [∆(j)]) be Pr(Γi,a,s) if [∆(j**)] =** [Γ(i);hsi]."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-a%CE%B3i,
        askg-data:Entity-pr%CE%B3i_a_s,
        askg-data:Entity-t%CE%B3i_a_j .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52117 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Otherwise let T ([Γ(i)],a, [∆(j)]) = 0."@en ;
    askg-onto:inSentence "Otherwise let T ([Γ(i)],a, [∆(j)]) = 0."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0,
        askg-data:Entity-t .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52118 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Let R([Γ(i)]) be R(Γ(i**))."@en ;
    askg-onto:inSentence "Let R([Γ(i)]) be R(Γ(i**))."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-r%CE%B3i .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5211-Sentence-52119 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Then note the** following four facts: 1."@en ;
    askg-onto:inSentence "Then note the** following four facts: 1."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-four_facts,
        askg-data:Entity-the_following .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5212 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "3. For any equivalent MDP D′′ of D **there is a mapping from a subset of the states of** D′′ **onto** E."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5212-Sentence-52121,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5212-Sentence-52122 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5212-Sentence-52121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3."@en ;
    askg-onto:inSentence "3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-concept,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-paper,
        askg-data:Entity-research_field,
        askg-data:Entity-study .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5212-Sentence-52122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For any equivalent MDP D′′ of D **there is a mapping from a subset of the states of** D′′ **onto** E."@en ;
    askg-onto:inSentence "For any equivalent MDP D′′ of D **there is a mapping from a subset of the states of** D′′ **onto** E."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-e,
        askg-data:Entity-mdp_d .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5213 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "4. D′**satisfies the condition that every e-state in** S ′**is reachable and** S ′**contains no two** distinct e-states s ′1and s ′2 **with** τ (s ′1) = τ (s ′2**) and** µ(s ′1) = µ(s ′2) iff Dc**is isomorphic** to D′."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5213-Sentence-52131,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5213-Sentence-52132 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5213-Sentence-52131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4."@en ;
    askg-onto:inSentence "4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_concept,
        askg-data:Entity-triple_4 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5213-Sentence-52132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "D′**satisfies the condition that every e-state in** S ′**is reachable and** S ′**contains no two** distinct e-states s ′1and s ′2 **with** τ (s ′1) = τ (s ′2**) and** µ(s ′1) = µ(s ′2) iff Dc**is isomorphic** to D′."@en ;
    askg-onto:inSentence "D′**satisfies the condition that every e-state in** S ′**is reachable and** S ′**contains no two** distinct e-states s ′1and s ′2 **with** τ (s ′1) = τ (s ′2**) and** µ(s ′1) = µ(s ′2) iff Dc**is isomorphic** to D′."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C2%B5s1,
        askg-data:Entity-%C2%B5s2,
        askg-data:Entity-%CF%84s1,
        askg-data:Entity-%CF%84s2,
        askg-data:Entity-d,
        askg-data:Entity-dc,
        askg-data:Entity-distinct_e-states_s1_and_s2,
        askg-data:Entity-every_e-state_in_s_is_reachable,
        askg-data:Entity-s,
        askg-data:Entity-s1,
        askg-data:Entity-s2 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "What fact 1 above amounts to is that if Γ1(i) ≡ Γ2(j**) then it does not matter which of** the two sequences is used to define A, T and R **of their equivalence class. In the cases of** A and T this is simply that Γ1i = Γ2j . In the case of R**, it is the special case ∆ =** hΓ1ii of the equality of rewards over extensions."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214-Sentence-52141,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214-Sentence-52142,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214-Sentence-52143 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214-Sentence-52141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "What fact 1 above amounts to is that if Γ1(i) ≡ Γ2(j**) then it does not matter which of** the two sequences is used to define A, T and R **of their equivalence class."@en ;
    askg-onto:inSentence "What fact 1 above amounts to is that if Γ1(i) ≡ Γ2(j**) then it does not matter which of** the two sequences is used to define A, T and R **of their equivalence class."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B31i,
        askg-data:Entity-%CE%B32j,
        askg-data:Entity-a,
        askg-data:Entity-r,
        askg-data:Entity-t .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214-Sentence-52142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the cases of** A and T this is simply that Γ1i = Γ2j ."@en ;
    askg-onto:inSentence "In the cases of** A and T this is simply that Γ1i = Γ2j ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B31i,
        askg-data:Entity-%CE%B32j .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5214-Sentence-52143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In the case of R**, it is the special case ∆ =** hΓ1ii of the equality of rewards over extensions."@en ;
    askg-onto:inSentence "In the case of R**, it is the special case ∆ =** hΓ1ii of the equality of rewards over extensions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-__h%CE%B31ii,
        askg-data:Entity-r .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Fact 2 is a matter of checking that the four conditions of Definition 1 hold. Of these, conditions 1 (τ ([s0]) = s0) and 2 (A([Γ(i)]) = A(Γi**)) hold trivially by the construction.** Condition 4 says that for any feasible state sequence Γ ∈ De(s0), we have R([Γ(i)]) = R(Γ(i)) for all i**. This also is given in the construction. Condition 3 states:** For all s1,s2 ∈ S, if there is a ∈ A(s1) such that Pr(s1,a,s2) > **0, then for all** Γ(i) ∈ De(s0) such that Γi = s1, there exists a unique [∆(j)] ∈ E, ∆j = s2**, such** that for all a ∈ A([Γ(i)]), T ([Γ(i)],a, [∆[j]]) = Pr(s1**,a,s**2)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52151,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52152,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52153,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52154 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fact 2 is a matter of checking that the four conditions of Definition 1 hold."@en ;
    askg-onto:inSentence "Fact 2 is a matter of checking that the four conditions of Definition 1 hold."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fact_2,
        askg-data:Entity-the_four_conditions_of_definition_1 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Of these, conditions 1 (τ ([s0]) = s0) and 2 (A([Γ(i)]) = A(Γi**)) hold trivially by the construction.** Condition 4 says that for any feasible state sequence Γ ∈ De(s0), we have R([Γ(i)]) = R(Γ(i)) for all i**."@en ;
    askg-onto:inSentence "Of these, conditions 1 (τ ([s0]) = s0) and 2 (A([Γ(i)]) = A(Γi**)) hold trivially by the construction.** Condition 4 says that for any feasible state sequence Γ ∈ De(s0), we have R([Γ(i)]) = R(Γ(i)) for all i**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-condition_1,
        askg-data:Entity-condition_2,
        askg-data:Entity-condition_4,
        askg-data:Entity-des0,
        askg-data:Entity-r%CE%B3i__r%CE%B3i_for_all_i,
        askg-data:Entity-s0,
        askg-data:Entity-state_sequence_%CE%B3 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This also is given in the construction."@en ;
    askg-onto:inSentence "This also is given in the construction."^^xsd:string ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5215-Sentence-52154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Condition 3 states:** For all s1,s2 ∈ S, if there is a ∈ A(s1) such that Pr(s1,a,s2) > **0, then for all** Γ(i) ∈ De(s0) such that Γi = s1, there exists a unique [∆(j)] ∈ E, ∆j = s2**, such** that for all a ∈ A([Γ(i)]), T ([Γ(i)],a, [∆[j]]) = Pr(s1**,a,s**2)."@en ;
    askg-onto:inSentence "Condition 3 states:** For all s1,s2 ∈ S, if there is a ∈ A(s1) such that Pr(s1,a,s2) > **0, then for all** Γ(i) ∈ De(s0) such that Γi = s1, there exists a unique [∆(j)] ∈ E, ∆j = s2**, such** that for all a ∈ A([Γ(i)]), T ([Γ(i)],a, [∆[j]]) = Pr(s1**,a,s**2)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-a,
        askg-data:Entity-a%CE%B3i,
        askg-data:Entity-condition_3,
        askg-data:Entity-des0,
        askg-data:Entity-e,
        askg-data:Entity-j,
        askg-data:Entity-prs1as2,
        askg-data:Entity-prs1as2__0,
        askg-data:Entity-s1,
        askg-data:Entity-s2,
        askg-data:Entity-t%CE%B3iaj .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5216 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "Suppose Pr(s1,α,s2) > 0, Γ(i) ∈ De(s0) and Γi = s1. Then the required ∆(j**) is Γ(**i);hs2i, and of course A([Γ(i)]) = A(Γi**), so the required condition reads:** [Γ(i);hs2i] is the unique element X of E with τ (X) = s2 **such that for all** a ∈ A(Γi), T ([Γ(i)],a,X) = Pr(s1**,a,s**2)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5216-Sentence-52161,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5216-Sentence-52162 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5216-Sentence-52161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Suppose Pr(s1,α,s2) > 0, Γ(i) ∈ De(s0) and Γi = s1."@en ;
    askg-onto:inSentence "Suppose Pr(s1,α,s2) > 0, Γ(i) ∈ De(s0) and Γi = s1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-0,
        askg-data:Entity-des0,
        askg-data:Entity-prs1%CE%B1s2,
        askg-data:Entity-s1 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5216-Sentence-52162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Then the required ∆(j**) is Γ(**i);hs2i, and of course A([Γ(i)]) = A(Γi**), so the required condition reads:** [Γ(i);hs2i] is the unique element X of E with τ (X) = s2 **such that for all** a ∈ A(Γi), T ([Γ(i)],a,X) = Pr(s1**,a,s**2)."@en ;
    askg-onto:inSentence "Then the required ∆(j**) is Γ(**i);hs2i, and of course A([Γ(i)]) = A(Γi**), so the required condition reads:** [Γ(i);hs2i] is the unique element X of E with τ (X) = s2 **such that for all** a ∈ A(Γi), T ([Γ(i)],a,X) = Pr(s1**,a,s**2)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-a,
        askg-data:Entity-a%CE%B3i,
        askg-data:Entity-prs1as2,
        askg-data:Entity-s2,
        askg-data:Entity-t%CE%B3iax,
        askg-data:Entity-unique_element_x_of_e,
        askg-data:Entity-x .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "To establish existence, we need that if a ∈ A(Γi) then T ([Γ(i)],a, [Γ(i);hs2i]) = Pr(Γi**,a,s**2), which is immediate from the definition of T **above. To establish uniqueness, suppose that** τ (X) = s2 and T ([Γ(i)],a,X) = Pr(s1,a,s2) for all actions a ∈ A(Γi). Since Pr(s1**,α,s**2) > 0, the transition probability from [Γ(i)] to X **is nonzero for some action, so by the definition** of T , X **can only be [Γ(**i);hs2i]."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217-Sentence-52171,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217-Sentence-52172,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217-Sentence-52173 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217-Sentence-52171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To establish existence, we need that if a ∈ A(Γi) then T ([Γ(i)],a, [Γ(i);hs2i]) = Pr(Γi**,a,s**2), which is immediate from the definition of T **above."@en ;
    askg-onto:inSentence "To establish existence, we need that if a ∈ A(Γi) then T ([Γ(i)],a, [Γ(i);hs2i]) = Pr(Γi**,a,s**2), which is immediate from the definition of T **above."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a%CE%B3i .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217-Sentence-52172 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To establish uniqueness, suppose that** τ (X) = s2 and T ([Γ(i)],a,X) = Pr(s1,a,s2) for all actions a ∈ A(Γi)."@en ;
    askg-onto:inSentence "To establish uniqueness, suppose that** τ (X) = s2 and T ([Γ(i)],a,X) = Pr(s1,a,s2) for all actions a ∈ A(Γi)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%84_x,
        askg-data:Entity-prs1as2,
        askg-data:Entity-s2,
        askg-data:Entity-t_%CE%B3iax .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5217-Sentence-52173 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Since Pr(s1**,α,s**2) > 0, the transition probability from [Γ(i)] to X **is nonzero for some action, so by the definition** of T , X **can only be [Γ(**i);hs2i]."@en ;
    askg-onto:inSentence "Since Pr(s1**,α,s**2) > 0, the transition probability from [Γ(i)] to X **is nonzero for some action, so by the definition** of T , X **can only be [Γ(**i);hs2i]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CE%B3ihs2i,
        askg-data:Entity-0,
        askg-data:Entity-prs1%CE%B1s2,
        askg-data:Entity-transition_probability,
        askg-data:Entity-x .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "Fact 3 is readily observed. Let M be any equivalent MDP for D**. For any states** s1 and s2 of D, and any state X of M such that τ (X) = s1 **there is at most one state** Y of M with τ (Y ) = s2 such that some action a ∈ A(s1**) gives a nonzero probability of** transition from X to Y **. This follows from the uniqueness part of condition 3 of Definition 1** together with the fact that the transition function is a probability distribution (sums to 1). Therefore for any given finite state sequence Γ(i) there is at most one state of M **reached** from the start state of M by following Γ(i). Therefore M **induces an equivalence relation** ≈M on S ∗: Γ(i) ≈M ∆(j) iff they lead to the same state of M **(the sequences which are not** feasible in M may all be regarded as equivalent under ≈M). Each reachable state of M has associated with it a nonempty equivalence class of finite sequences of states of D**. Working** through the definitions, we may observe that ≈M is a sub-relation of ≡ **(if Γ(**i) ≈M ∆(j) then Γ(i) ≡ ∆(j)). Hence the function that takes the equivalence class under ≈M **of each** feasible sequence Γ(i) to [Γ(i)] induces a mapping h **(an epimorphism in fact) from the** reachable subset of states of M **onto** E."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52181,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52182,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52183,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52184,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52185,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52186,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52187,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52188,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52189 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Fact 3 is readily observed."@en ;
    askg-onto:inSentence "Fact 3 is readily observed."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fact_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let M be any equivalent MDP for D**."@en ;
    askg-onto:inSentence "Let M be any equivalent MDP for D**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-m,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For any states** s1 and s2 of D, and any state X of M such that τ (X) = s1 **there is at most one state** Y of M with τ (Y ) = s2 such that some action a ∈ A(s1**) gives a nonzero probability of** transition from X to Y **."@en ;
    askg-onto:inSentence "For any states** s1 and s2 of D, and any state X of M such that τ (X) = s1 **there is at most one state** Y of M with τ (Y ) = s2 such that some action a ∈ A(s1**) gives a nonzero probability of** transition from X to Y **."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-m,
        askg-data:Entity-s1,
        askg-data:Entity-s2,
        askg-data:Entity-x,
        askg-data:Entity-x_to_y,
        askg-data:Entity-y .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52184 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This follows from the uniqueness part of condition 3 of Definition 1** together with the fact that the transition function is a probability distribution (sums to 1)."@en ;
    askg-onto:inSentence "This follows from the uniqueness part of condition 3 of Definition 1** together with the fact that the transition function is a probability distribution (sums to 1)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-condition_3,
        askg-data:Entity-definition_1,
        askg-data:Entity-probability_distribution,
        askg-data:Entity-transition_function .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52185 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Therefore for any given finite state sequence Γ(i) there is at most one state of M **reached** from the start state of M by following Γ(i)."@en ;
    askg-onto:inSentence "Therefore for any given finite state sequence Γ(i) there is at most one state of M **reached** from the start state of M by following Γ(i)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finite_state_sequence_%CE%B3i,
        askg-data:Entity-start_state_of_m,
        askg-data:Entity-state_of_m .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52186 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Therefore M **induces an equivalence relation** ≈M on S ∗: Γ(i) ≈M ∆(j) iff they lead to the same state of M **(the sequences which are not** feasible in M may all be regarded as equivalent under ≈M)."@en ;
    askg-onto:inSentence "Therefore M **induces an equivalence relation** ≈M on S ∗: Γ(i) ≈M ∆(j) iff they lead to the same state of M **(the sequences which are not** feasible in M may all be regarded as equivalent under ≈M)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-j,
        askg-data:Entity-m,
        askg-data:Entity-sequences .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52187 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Each reachable state of M has associated with it a nonempty equivalence class of finite sequences of states of D**."@en ;
    askg-onto:inSentence "Each reachable state of M has associated with it a nonempty equivalence class of finite sequences of states of D**."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equivalence_class_of_finite_sequences_of_states_of_d,
        askg-data:Entity-m .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52188 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Working** through the definitions, we may observe that ≈M is a sub-relation of ≡ **(if Γ(**i) ≈M ∆(j) then Γ(i) ≡ ∆(j))."@en ;
    askg-onto:inSentence "Working** through the definitions, we may observe that ≈M is a sub-relation of ≡ **(if Γ(**i) ≈M ∆(j) then Γ(i) ≡ ∆(j))."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-m .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5218-Sentence-52189 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Hence the function that takes the equivalence class under ≈M **of each** feasible sequence Γ(i) to [Γ(i)] induces a mapping h **(an epimorphism in fact) from the** reachable subset of states of M **onto** E."@en ;
    askg-onto:inSentence "Hence the function that takes the equivalence class under ≈M **of each** feasible sequence Γ(i) to [Γ(i)] induces a mapping h **(an epimorphism in fact) from the** reachable subset of states of M **onto** E."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e,
        askg-data:Entity-m .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "To establish Fact 4, it must be shown that in the case of D′**the mapping can be** reversed, or that each equivalence class [Γ(i)] in Dc**corresponds to exactly one element of** D′. Suppose not (for contradiction). Then there exist sequences Γ1(i) and Γ2(j**) in** De(s0) such that Γ1(i) ≡ Γ2(j**) but on following the two sequences from** s ′0 **we arrive at two different** elements s ′1and s ′2of D′ **with** τ (s ′1) = Γ1i **= Γ2**j = τ (s ′2**) but with** µ(s ′1) 6= µ(s ′2**). Therefore** there exists a sequence ∆(k) ∈ De(s) such that R(Γ1(i − 1); ∆(k)) 6= R(Γ2(j − 1); ∆(k))."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52191,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52192,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52193,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52194 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To establish Fact 4, it must be shown that in the case of D′**the mapping can be** reversed, or that each equivalence class [Γ(i)] in Dc**corresponds to exactly one element of** D′."@en ;
    askg-onto:inSentence "To establish Fact 4, it must be shown that in the case of D′**the mapping can be** reversed, or that each equivalence class [Γ(i)] in Dc**corresponds to exactly one element of** D′."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-dc,
        askg-data:Entity-equivalence_class_%CE%B3i .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Suppose not (for contradiction)."@en ;
    askg-onto:inSentence "Suppose not (for contradiction)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52193 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Then there exist sequences Γ1(i) and Γ2(j**) in** De(s0) such that Γ1(i) ≡ Γ2(j**) but on following the two sequences from** s ′0 **we arrive at two different** elements s ′1and s ′2of D′ **with** τ (s ′1) = Γ1i **= Γ2**j = τ (s ′2**) but with** µ(s ′1) 6= µ(s ′2**)."@en ;
    askg-onto:inSentence "Then there exist sequences Γ1(i) and Γ2(j**) in** De(s0) such that Γ1(i) ≡ Γ2(j**) but on following the two sequences from** s ′0 **we arrive at two different** elements s ′1and s ′2of D′ **with** τ (s ′1) = Γ1i **= Γ2**j = τ (s ′2**) but with** µ(s ′1) 6= µ(s ′2**)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%C2%B5s1,
        askg-data:Entity-%C2%B5s2,
        askg-data:Entity-%CE%B31i,
        askg-data:Entity-%CE%B32j,
        askg-data:Entity-%CF%84s1,
        askg-data:Entity-%CF%84s2 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5219-Sentence-52194 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Therefore** there exists a sequence ∆(k) ∈ De(s) such that R(Γ1(i − 1); ∆(k)) 6= R(Γ2(j − 1); ∆(k))."@en ;
    askg-onto:inSentence "Therefore** there exists a sequence ∆(k) ∈ De(s) such that R(Γ1(i − 1); ∆(k)) 6= R(Γ2(j − 1); ∆(k))."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-r%CE%B31i__1,
        askg-data:Entity-r%CE%B32j__1 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Proof: Induction on the structure of f**. There are several base cases, all fairly trivial.** If f = ⊤ or f = ⊥ **there is nothing to prove, as these progress to themselves and hold** everywhere and nowhere respectively. If f = p then if f holds in Γi **then it progresses to** ⊤ which holds in Γi+1 while if f does not hold in Γi then it progresses to ⊥ **which does not** hold in Γi+1. The case f = ¬p is similar. In the last base case, f **= $. Then the following** are equivalent: (Γ,i)|=B f Γ(i) ∈ B b Prog(b, Γi,f) = ⊤ (Γ,i **+ 1)**|=B Prog(b, Γi,f) Induction case 1: f = g ∧ h**. The following are equivalent:** (Γ,i)|=B f (Γ,i)|=B g **and (Γ**,i)|=B h (Γ,i **+ 1)**|=B Prog(b, Γi,g) and (Γ,i **+ 1)**|=B Prog(b, Γi,h**) (by induction hypothesis)** (Γ,i **+ 1)**|=B Prog(b, Γi,g) ∧ **Prog(**b, Γi,h) (Γ,i **+ 1)**|=B Prog(b, Γi,f) Induction case 2: f = g ∨ h**. Analogous to case 1.** Induction case 3: f = g**. Trivial by inspection of the definitions.** Induction case 4: f = g Uh. Then f is logically equivalent to h ∨ (g ∧ (g Uh**) which by** cases 1, 2 and 3 holds at stage i of Γ for behaviour B iff Prog(b, Γi,f**) holds at stage i+1.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5221,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-52210,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5222,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5223,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5224,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5225,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5226,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5227,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5228,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5229 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof: Induction on the structure of f**."@en ;
    askg-onto:inSentence "Proof: Induction on the structure of f**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-proof .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-52210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Then f is logically equivalent to h ∨ (g ∧ (g Uh**) which by** cases 1, 2 and 3 holds at stage i of Γ for behaviour B iff Prog(b, Γi,f**) holds at stage i+1.**"@en ;
    askg-onto:inSentence "Then f is logically equivalent to h ∨ (g ∧ (g Uh**) which by** cases 1, 2 and 3 holds at stage i of Γ for behaviour B iff Prog(b, Γi,f**) holds at stage i+1.**"^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-h__g__g_uh,
        askg-data:Entity-i1,
        askg-data:Entity-progb_%CE%B3if .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "There are several base cases, all fairly trivial.** If f = ⊤ or f = ⊥ **there is nothing to prove, as these progress to themselves and hold** everywhere and nowhere respectively."@en ;
    askg-onto:inSentence "There are several base cases, all fairly trivial.** If f = ⊤ or f = ⊥ **there is nothing to prove, as these progress to themselves and hold** everywhere and nowhere respectively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "If f = p then if f holds in Γi **then it progresses to** ⊤ which holds in Γi+1 while if f does not hold in Γi then it progresses to ⊥ **which does not** hold in Γi+1."@en ;
    askg-onto:inSentence "If f = p then if f holds in Γi **then it progresses to** ⊤ which holds in Γi+1 while if f does not hold in Γi then it progresses to ⊥ **which does not** hold in Γi+1."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The case f = ¬p is similar."@en ;
    askg-onto:inSentence "The case f = ¬p is similar."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-p .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In the last base case, f **= $."@en ;
    askg-onto:inSentence "In the last base case, f **= $."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-base_case,
        askg-data:Entity-f__ .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Then the following** are equivalent: (Γ,i)|=B f Γ(i) ∈ B b Prog(b, Γi,f) = ⊤ (Γ,i **+ 1)**|=B Prog(b, Γi,f) Induction case 1: f = g ∧ h**."@en ;
    askg-onto:inSentence "Then the following** are equivalent: (Γ,i)|=B f Γ(i) ∈ B b Prog(b, Γi,f) = ⊤ (Γ,i **+ 1)**|=B Prog(b, Γi,f) Induction case 1: f = g ∧ h**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-_%CE%B3i__1,
        askg-data:Entity-b_f_%CE%B3i__b_b,
        askg-data:Entity-f,
        askg-data:Entity-g__h,
        askg-data:Entity-progb_%CE%B3if .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5227 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The following are equivalent:** (Γ,i)|=B f (Γ,i)|=B g **and (Γ**,i)|=B h (Γ,i **+ 1)**|=B Prog(b, Γi,g) and (Γ,i **+ 1)**|=B Prog(b, Γi,h**) (by induction hypothesis)** (Γ,i **+ 1)**|=B Prog(b, Γi,g) ∧ **Prog(**b, Γi,h) (Γ,i **+ 1)**|=B Prog(b, Γi,f) Induction case 2: f = g ∨ h**."@en ;
    askg-onto:inSentence "The following are equivalent:** (Γ,i)|=B f (Γ,i)|=B g **and (Γ**,i)|=B h (Γ,i **+ 1)**|=B Prog(b, Γi,g) and (Γ,i **+ 1)**|=B Prog(b, Γi,h**) (by induction hypothesis)** (Γ,i **+ 1)**|=B Prog(b, Γi,g) ∧ **Prog(**b, Γi,h) (Γ,i **+ 1)**|=B Prog(b, Γi,f) Induction case 2: f = g ∨ h**."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i,
        askg-data:Entity-%CE%B3i__1,
        askg-data:Entity-%CE%B3ib_f,
        askg-data:Entity-%CE%B3ib_g,
        askg-data:Entity-%CE%B3ib_h,
        askg-data:Entity-f__g__h,
        askg-data:Entity-induction_case_2,
        askg-data:Entity-progb_%CE%B3if,
        askg-data:Entity-progb_%CE%B3ig,
        askg-data:Entity-progb_%CE%B3ig__progb_%CE%B3ih,
        askg-data:Entity-progb_%CE%B3ih .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5228 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Analogous to case 1.** Induction case 3: f = g**."@en ;
    askg-onto:inSentence "Analogous to case 1.** Induction case 3: f = g**."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-induction_case_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-522-Sentence-5229 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Trivial by inspection of the definitions.** Induction case 4: f = g Uh."@en ;
    askg-onto:inSentence "Trivial by inspection of the definitions.** Induction case 4: f = g Uh."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-g_uh .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5220 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "But this contradicts the condition for Γ1(i) ≡ Γ2(j)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5220-Sentence-52201 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5220-Sentence-52201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "But this contradicts the condition for Γ1(i) ≡ Γ2(j)."@en ;
    askg-onto:inSentence "But this contradicts the condition for Γ1(i) ≡ Γ2(j)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B31i,
        askg-data:Entity-%CE%B32j .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5221 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 21"@en ;
    domo:Text "Theorem 3 follows immediately from facts 1–4."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5221-Sentence-52211 ;
    askg-onto:index "21"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5221-Sentence-52211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Theorem 3 follows immediately from facts 1–4."@en ;
    askg-onto:inSentence "Theorem 3 follows immediately from facts 1–4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-facts_14,
        askg-data:Entity-theorem_3 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 22"@en ;
    domo:Text "Theorem 4 Let D′be the translation of D as in Definition 5. D′**is a blind minimal** equivalent MDP for D. Proof: **Reachability of all the e-states is obvious, as they are constructed only when** reached. Each e-state is a pair hs,φi where s is a state of D and φ **is a reward function** specification. In fact, s = τ (hs,φi) and φ **determines a distribution of rewards over all** continuations of the sequences that reach hs,φi**. That is, for all ∆ in** S ∗**such that ∆**0 = s, the reward for ∆ is P(f:r)∈φ{r | ∆ ∈ Bf }. If D′**is not blind minimal, then there exist** distinct e-states hs,φi and hs,φ′i **for which this sum is the same for all ∆. But this makes** φ and φ ′**semantically equivalent, contradicting the supposition that they are distinct.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52221,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52222,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52223,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52224,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52225,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52226,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52227,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52228 ;
    askg-onto:index "22"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Theorem 4 Let D′be the translation of D as in Definition 5."@en ;
    askg-onto:inSentence "Theorem 4 Let D′be the translation of D as in Definition 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "D′**is a blind minimal** equivalent MDP for D."@en ;
    askg-onto:inSentence "D′**is a blind minimal** equivalent MDP for D."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimal_equivalent_mdp,
        askg-data:Entity-d,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Proof: **Reachability of all the e-states is obvious, as they are constructed only when** reached."@en ;
    askg-onto:inSentence "Proof: **Reachability of all the e-states is obvious, as they are constructed only when** reached."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-reached .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Each e-state is a pair hs,φi where s is a state of D and φ **is a reward function** specification."@en ;
    askg-onto:inSentence "Each e-state is a pair hs,φi where s is a state of D and φ **is a reward function** specification."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-e-state,
        askg-data:Entity-pair_hs%CF%86i,
        askg-data:Entity-reward_function_specification,
        askg-data:Entity-s,
        askg-data:Entity-state_of_d .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In fact, s = τ (hs,φi) and φ **determines a distribution of rewards over all** continuations of the sequences that reach hs,φi**."@en ;
    askg-onto:inSentence "In fact, s = τ (hs,φi) and φ **determines a distribution of rewards over all** continuations of the sequences that reach hs,φi**."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-continuations_of_the_sequences,
        askg-data:Entity-distribution_of_rewards,
        askg-data:Entity-hs%CF%86i,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "That is, for all ∆ in** S ∗**such that ∆**0 = s, the reward for ∆ is P(f:r)∈φ{r | ∆ ∈ Bf }."@en ;
    askg-onto:inSentence "That is, for all ∆ in** S ∗**such that ∆**0 = s, the reward for ∆ is P(f:r)∈φ{r | ∆ ∈ Bf }."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-0,
        askg-data:Entity-bf,
        askg-data:Entity-pfr%CF%86r____bf,
        askg-data:Entity-reward,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52227 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "If D′**is not blind minimal, then there exist** distinct e-states hs,φi and hs,φ′i **for which this sum is the same for all ∆."@en ;
    askg-onto:inSentence "If D′**is not blind minimal, then there exist** distinct e-states hs,φi and hs,φ′i **for which this sum is the same for all ∆."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_,
        askg-data:Entity-blind_minimal,
        askg-data:Entity-d,
        askg-data:Entity-e-states_hs%CF%86i,
        askg-data:Entity-this_sum .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-5222-Sentence-52228 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "But this makes** φ and φ ′**semantically equivalent, contradicting the supposition that they are distinct.**"@en ;
    askg-onto:inSentence "But this makes** φ and φ ′**semantically equivalent, contradicting the supposition that they are distinct.**"^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%86,
        askg-data:Entity-%CF%86_ .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-523 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Theorem 1 Let f be reward-normal, and let hf0,f1,...i **be the result of progressing it** through the successive states of a sequence Γ. Then, provided no fiis ⊥, for all i **Rew(Γ**i,fi) iff Γ(i) ∈ Bf ."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-523-Sentence-5231,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-523-Sentence-5232 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-523-Sentence-5231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Theorem 1 Let f be reward-normal, and let hf0,f1,...i **be the result of progressing it** through the successive states of a sequence Γ."@en ;
    askg-onto:inSentence "Theorem 1 Let f be reward-normal, and let hf0,f1,...i **be the result of progressing it** through the successive states of a sequence Γ."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-hf0f1i,
        askg-data:Entity-progressing_it_through_the_successive_states_of_a_sequence_%CE%B3,
        askg-data:Entity-reward-normal .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-523-Sentence-5232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Then, provided no fiis ⊥, for all i **Rew(Γ**i,fi) iff Γ(i) ∈ Bf ."@en ;
    askg-onto:inSentence "Then, provided no fiis ⊥, for all i **Rew(Γ**i,fi) iff Γ(i) ∈ Bf ."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3i__bf,
        askg-data:Entity-rew%CE%B3ifi .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-524 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Proof: First, by the definition of reward-normality, if f **is reward-normal then Γ** |=B f iff for all i, if Γ(i) ∈ Bf then Γ(i) ∈ B**. Next, if Γ** |=B f then progressing f **through Γ according** to B (that is, letting each bi be true iff Γ(i) ∈ B**) cannot lead to a contradiction because** by Property 1, progression is truth-preserving."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-524-Sentence-5241,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-524-Sentence-5242 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-524-Sentence-5241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Proof: First, by the definition of reward-normality, if f **is reward-normal then Γ** |=B f iff for all i, if Γ(i) ∈ Bf then Γ(i) ∈ B**."@en ;
    askg-onto:inSentence "Proof: First, by the definition of reward-normality, if f **is reward-normal then Γ** |=B f iff for all i, if Γ(i) ∈ Bf then Γ(i) ∈ B**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-%CE%B3i,
        askg-data:Entity-b,
        askg-data:Entity-bf,
        askg-data:Entity-reward-normal .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-524-Sentence-5242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Next, if Γ** |=B f then progressing f **through Γ according** to B (that is, letting each bi be true iff Γ(i) ∈ B**) cannot lead to a contradiction because** by Property 1, progression is truth-preserving."@en ;
    askg-onto:inSentence "Next, if Γ** |=B f then progressing f **through Γ according** to B (that is, letting each bi be true iff Γ(i) ∈ B**) cannot lead to a contradiction because** by Property 1, progression is truth-preserving."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "It remains, then, to show that if Γ 6|=B f then progressing f **through Γ according to** B must lead eventually to ⊥. The proof of this is by induction on the structure of f **and as** usual the base case in which f is a literal (an atom, a negated atom or ⊤, ⊥ **or $) is trivial.** Case f = g ∧ h**. Suppose Γ** 6|=B f**. Then either Γ** 6|=B g **or Γ** 6|=B h**, so by the induction** hypothesis either g or h progresses eventually to ⊥**, and hence so does their conjunction.** Case f = g ∨ h**. Suppose Γ** 6|=B f**. Then both Γ** 6|=B g **and Γ** 6|=B h**, so by the induction** hypothesis each of g and h progresses eventually to ⊥**. Suppose without loss of generality** that g does not progress to ⊥ before h does. Then at some point g **has progressed to some** formula g ′ and f **has progressed to** g ′ ∨ ⊥ **which simplifies to** g ′**. Since** g ′ **also progresses to** ⊥ **eventually, so does** f."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5251,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5252,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5253,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5254,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5255,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5256,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5257,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5258,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5259 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "It remains, then, to show that if Γ 6|=B f then progressing f **through Γ according to** B must lead eventually to ⊥."@en ;
    askg-onto:inSentence "It remains, then, to show that if Γ 6|=B f then progressing f **through Γ according to** B must lead eventually to ⊥."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B3,
        askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The proof of this is by induction on the structure of f **and as** usual the base case in which f is a literal (an atom, a negated atom or ⊤, ⊥ **or $) is trivial.** Case f = g ∧ h**."@en ;
    askg-onto:inSentence "The proof of this is by induction on the structure of f **and as** usual the base case in which f is a literal (an atom, a negated atom or ⊤, ⊥ **or $) is trivial.** Case f = g ∧ h**."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-base_case,
        askg-data:Entity-f,
        askg-data:Entity-g__h,
        askg-data:Entity-literal,
        askg-data:Entity-trivial .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5253 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Suppose Γ** 6|=B f**."@en ;
    askg-onto:inSentence "Suppose Γ** 6|=B f**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-b_f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5254 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Then either Γ** 6|=B g **or Γ** 6|=B h**, so by the induction** hypothesis either g or h progresses eventually to ⊥**, and hence so does their conjunction.** Case f = g ∨ h**."@en ;
    askg-onto:inSentence "Then either Γ** 6|=B g **or Γ** 6|=B h**, so by the induction** hypothesis either g or h progresses eventually to ⊥**, and hence so does their conjunction.** Case f = g ∨ h**."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B3,
        askg-data:Entity-f,
        askg-data:Entity-g,
        askg-data:Entity-g__h,
        askg-data:Entity-h .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5255 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Suppose Γ** 6|=B f**."@en ;
    askg-onto:inSentence "Suppose Γ** 6|=B f**."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5256 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Then both Γ** 6|=B g **and Γ** 6|=B h**, so by the induction** hypothesis each of g and h progresses eventually to ⊥**."@en ;
    askg-onto:inSentence "Then both Γ** 6|=B g **and Γ** 6|=B h**, so by the induction** hypothesis each of g and h progresses eventually to ⊥**."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B3_6b_g_,
        askg-data:Entity-%CE%B3_6b_h .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5257 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Suppose without loss of generality** that g does not progress to ⊥ before h does."@en ;
    askg-onto:inSentence "Suppose without loss of generality** that g does not progress to ⊥ before h does."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-g,
        askg-data:Entity-h .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5258 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Then at some point g **has progressed to some** formula g ′ and f **has progressed to** g ′ ∨ ⊥ **which simplifies to** g ′**."@en ;
    askg-onto:inSentence "Then at some point g **has progressed to some** formula g ′ and f **has progressed to** g ′ ∨ ⊥ **which simplifies to** g ′**."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-g,
        askg-data:Entity-g__ .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-525-Sentence-5259 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Since** g ′ **also progresses to** ⊥ **eventually, so does** f."@en ;
    askg-onto:inSentence "Since** g ′ **also progresses to** ⊥ **eventually, so does** f."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-f,
        askg-data:Entity-g .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Case f = g**. Suppose Γ** 6|=B f. Let Γ = Γ0; ∆ and let B′ = {γ|Γ0; γ ∈ B}**. Then** ∆ 6|=B′ g, so by the induction hypothesis g progressed through ∆ according to B′**eventually** reaches ⊥. But The progression of f through Γ according to B **is exactly the same after** the first step, so that too leads to ⊥."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5261,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5262,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5263,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5264,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5265 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Case f = g**."@en ;
    askg-onto:inSentence "Case f = g**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Suppose Γ** 6|=B f."@en ;
    askg-onto:inSentence "Suppose Γ** 6|=B f."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-b_f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5263 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Let Γ = Γ0; ∆ and let B′ = {γ|Γ0; γ ∈ B}**."@en ;
    askg-onto:inSentence "Let Γ = Γ0; ∆ and let B′ = {γ|Γ0; γ ∈ B}**."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-%CE%B3%CE%B30_%CE%B3__b,
        askg-data:Entity-%CE%B30_,
        askg-data:Entity-b .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5264 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Then** ∆ 6|=B′ g, so by the induction hypothesis g progressed through ∆ according to B′**eventually** reaches ⊥."@en ;
    askg-onto:inSentence "Then** ∆ 6|=B′ g, so by the induction hypothesis g progressed through ∆ according to B′**eventually** reaches ⊥."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-g .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-526-Sentence-5265 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "But The progression of f through Γ according to B **is exactly the same after** the first step, so that too leads to ⊥."@en ;
    askg-onto:inSentence "But The progression of f through Γ according to B **is exactly the same after** the first step, so that too leads to ⊥."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B3,
        askg-data:Entity-b,
        askg-data:Entity-f,
        askg-data:Entity-first_step .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Case f = g Uh**. Suppose Γ** 6|=B f. Then there is some j **such that (Γ**,j) 6|=B g **and for all** i ≤ j**, (Γ**,i) 6|=B h. We proceed by induction on j. In the base case j **= 0, and both Γ** 6|=B g and Γ 6|=B h whence by the main induction hypothesis both g and h **will eventually progress** to ⊥**. Thus** h∨(g ∧f ′) progresses eventually to ⊥ **for any** f ′**, and in particular for** f ′ = f, establishing the base case. For the induction case, suppose Γ |=B g **(and of course Γ** 6|=B h)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5271,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5272,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5273,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5274,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5275,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5276,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5277 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Case f = g Uh**."@en ;
    askg-onto:inSentence "Case f = g Uh**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-case_f__g_uh,
        askg-data:Entity-model .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5272 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Suppose Γ** 6|=B f."@en ;
    askg-onto:inSentence "Suppose Γ** 6|=B f."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-b_f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5273 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Then there is some j **such that (Γ**,j) 6|=B g **and for all** i ≤ j**, (Γ**,i) 6|=B h."@en ;
    askg-onto:inSentence "Then there is some j **such that (Γ**,j) 6|=B g **and for all** i ≤ j**, (Γ**,i) 6|=B h."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-b_g,
        askg-data:Entity-h .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5274 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We proceed by induction on j."@en ;
    askg-onto:inSentence "We proceed by induction on j."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-induction,
        askg-data:Entity-j .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5275 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In the base case j **= 0, and both Γ** 6|=B g and Γ 6|=B h whence by the main induction hypothesis both g and h **will eventually progress** to ⊥**."@en ;
    askg-onto:inSentence "In the base case j **= 0, and both Γ** 6|=B g and Γ 6|=B h whence by the main induction hypothesis both g and h **will eventually progress** to ⊥**."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B3 .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5276 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Thus** h∨(g ∧f ′) progresses eventually to ⊥ **for any** f ′**, and in particular for** f ′ = f, establishing the base case."@en ;
    askg-onto:inSentence "Thus** h∨(g ∧f ′) progresses eventually to ⊥ **for any** f ′**, and in particular for** f ′ = f, establishing the base case."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-f,
        askg-data:Entity-f_,
        askg-data:Entity-hg_f_ .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-527-Sentence-5277 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "For the induction case, suppose Γ |=B g **(and of course Γ** 6|=B h)."@en ;
    askg-onto:inSentence "For the induction case, suppose Γ |=B g **(and of course Γ** 6|=B h)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-g,
        askg-data:Entity-h .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Since f is equivalent to h∨(g ∧ f**) and Γ** 6|=B f, Γ 6|=B h **and Γ** |=B g**, clearly Γ** 6|=B f**. Where** ∆ and B′ are as in the previous case, therefore, ∆ 6|=B′ f **and the failure occurs at stage** j −1 of ∆. Therefore the hypothesis of the induction on j applies, and f **progressed through ∆** according to B′ goes eventually to ⊥, and so f progressed through Γ according to B **goes** similarly to ⊥."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528-Sentence-5281,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528-Sentence-5282,
        askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528-Sentence-5283 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528-Sentence-5281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Since f is equivalent to h∨(g ∧ f**) and Γ** 6|=B f, Γ 6|=B h **and Γ** |=B g**, clearly Γ** 6|=B f**."@en ;
    askg-onto:inSentence "Since f is equivalent to h∨(g ∧ f**) and Γ** 6|=B f, Γ 6|=B h **and Γ** |=B g**, clearly Γ** 6|=B f**."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B3,
        askg-data:Entity-b_f,
        askg-data:Entity-b_g,
        askg-data:Entity-b_h,
        askg-data:Entity-f,
        askg-data:Entity-hg__f .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528-Sentence-5282 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Where** ∆ and B′ are as in the previous case, therefore, ∆ 6|=B′ f **and the failure occurs at stage** j −1 of ∆."@en ;
    askg-onto:inSentence "Where** ∆ and B′ are as in the previous case, therefore, ∆ 6|=B′ f **and the failure occurs at stage** j −1 of ∆."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-b,
        askg-data:Entity-failure,
        askg-data:Entity-j_1_of_ .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-528-Sentence-5283 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Therefore the hypothesis of the induction on j applies, and f **progressed through ∆** according to B′ goes eventually to ⊥, and so f progressed through Γ according to B **goes** similarly to ⊥."@en ;
    askg-onto:inSentence "Therefore the hypothesis of the induction on j applies, and f **progressed through ∆** according to B′ goes eventually to ⊥, and so f progressed through Γ according to B **goes** similarly to ⊥."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-%CE%B3,
        askg-data:Entity-b,
        askg-data:Entity-f,
        askg-data:Entity-hypothesis,
        askg-data:Entity-induction .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-529 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Theorem 3 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-529-Sentence-5291 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-52-Paragraph-529-Sentence-5291 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Theorem 3 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."@en ;
    askg-onto:inSentence "Theorem 3 Let S ′be the set of e-states in an equivalent MDP D′for D = hS,s0,A,Pr,Ri."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-e-states,
        askg-data:Entity-hs_s0_a_pr_ri,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-53 a askg-onto:Section ;
    rdfs:label "Section 53"@en ;
    domo:Text "Appendix C. Random Problem Domains"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-531,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-533,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535 ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-531 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Random problem domains are produced by first creating a random action specification defining the domain dynamics. Some of the experiments we conducted20 **also involved** producing, in a second step, a random reward specification that had desired properties in relation to the generated dynamics."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-531-Sentence-5311,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-531-Sentence-5312 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-531-Sentence-5311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Random problem domains are produced by first creating a random action specification defining the domain dynamics."@en ;
    askg-onto:inSentence "Random problem domains are produced by first creating a random action specification defining the domain dynamics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_random_action_specification,
        askg-data:Entity-creating_a_random_action_specification,
        askg-data:Entity-random_problem_domains .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-531-Sentence-5312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Some of the experiments we conducted20 **also involved** producing, in a second step, a random reward specification that had desired properties in relation to the generated dynamics."@en ;
    askg-onto:inSentence "Some of the experiments we conducted20 **also involved** producing, in a second step, a random reward specification that had desired properties in relation to the generated dynamics."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-desired_properties,
        askg-data:Entity-experiments,
        askg-data:Entity-generated_dynamics,
        askg-data:Entity-random_reward_specification .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The random generation of the domain dynamics takes as parameters the number n of propositions in the domain and the number of actions to be produced, and starts by assigning some effects to each action such that each proposition is affected by exactly one action. For example, if we have 5 actions and 14 propositions, the first 4 actions may affect 3 propositions each, the 5th one only 2, and the affected propositions are all different. Once each action has some initial effects, we continue to add more effects one at a time, until a sufficient proportion of the state space is reachable - see \"proportion reachable\" parameter below. Each additional effect is generated by picking up a random action and a random proposition, and producing a random decision diagram according to the \"uncertainty\" and \"structure\" parameters below: The Uncertainty parameter is the probability of a non zero/one value as a leaf node. An uncertainty of 1 will result in all leaf nodes having random values from a uniform distribution. An uncertainty of 0 will result in all leaf nodes having values 0 or 1 with an equal probability."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5321,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5322,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5323,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5324,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5325,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5326 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The random generation of the domain dynamics takes as parameters the number n of propositions in the domain and the number of actions to be produced, and starts by assigning some effects to each action such that each proposition is affected by exactly one action."@en ;
    askg-onto:inSentence "The random generation of the domain dynamics takes as parameters the number n of propositions in the domain and the number of actions to be produced, and starts by assigning some effects to each action such that each proposition is affected by exactly one action."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-each_proposition,
        askg-data:Entity-exactly_one_action,
        askg-data:Entity-number_n_of_propositions_in_the_domain,
        askg-data:Entity-number_of_actions_to_be_produced,
        askg-data:Entity-random_generation_of_the_domain_dynamics,
        askg-data:Entity-some_effects_to_each_action .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For example, if we have 5 actions and 14 propositions, the first 4 actions may affect 3 propositions each, the 5th one only 2, and the affected propositions are all different."@en ;
    askg-onto:inSentence "For example, if we have 5 actions and 14 propositions, the first 4 actions may affect 3 propositions each, the 5th one only 2, and the affected propositions are all different."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5th_action,
        askg-data:Entity-actions,
        askg-data:Entity-propositions .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Once each action has some initial effects, we continue to add more effects one at a time, until a sufficient proportion of the state space is reachable - see \"proportion reachable\" parameter below."@en ;
    askg-onto:inSentence "Once each action has some initial effects, we continue to add more effects one at a time, until a sufficient proportion of the state space is reachable - see \"proportion reachable\" parameter below."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action,
        askg-data:Entity-effects,
        askg-data:Entity-proportion_reachable,
        askg-data:Entity-state_space .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Each additional effect is generated by picking up a random action and a random proposition, and producing a random decision diagram according to the \"uncertainty\" and \"structure\" parameters below: The Uncertainty parameter is the probability of a non zero/one value as a leaf node."@en ;
    askg-onto:inSentence "Each additional effect is generated by picking up a random action and a random proposition, and producing a random decision diagram according to the \"uncertainty\" and \"structure\" parameters below: The Uncertainty parameter is the probability of a non zero/one value as a leaf node."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_effect,
        askg-data:Entity-probability_of_a_non_zeroone_value_as_a_leaf_node,
        askg-data:Entity-random_action,
        askg-data:Entity-random_decision_diagram,
        askg-data:Entity-random_proposition,
        askg-data:Entity-uncertainty_and_structure_parameters,
        askg-data:Entity-uncertainty_parameter .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5325 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "An uncertainty of 1 will result in all leaf nodes having random values from a uniform distribution."@en ;
    askg-onto:inSentence "An uncertainty of 1 will result in all leaf nodes having random values from a uniform distribution."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_leaf_nodes_having_random_values_from_a_uniform_distribution,
        askg-data:Entity-uncertainty .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-532-Sentence-5326 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "An uncertainty of 0 will result in all leaf nodes having values 0 or 1 with an equal probability."@en ;
    askg-onto:inSentence "An uncertainty of 0 will result in all leaf nodes having values 0 or 1 with an equal probability."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-leaf_nodes_having_values_0_or_1_with_an_equal_probability,
        askg-data:Entity-uncertainty .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-533 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The Structure (or influence) parameter is the probability of **a decision diagram containing** a particular proposition. So an influence of 1 will result in all decision diagrams"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-533-Sentence-5331,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-533-Sentence-5332 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-533-Sentence-5331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The Structure (or influence) parameter is the probability of **a decision diagram containing** a particular proposition."@en ;
    askg-onto:inSentence "The Structure (or influence) parameter is the probability of **a decision diagram containing** a particular proposition."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_decision_diagram_containing_a_particular_proposition,
        askg-data:Entity-structure_parameter .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-533-Sentence-5332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "So an influence of 1 will result in all decision diagrams"@en ;
    askg-onto:inSentence "So an influence of 1 will result in all decision diagrams"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_diagrams,
        askg-data:Entity-influence .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "20. None of those are included in this paper, however. including all propositions (and very unlikely to have significant structure), while 0 will result in decision diagrams that do not depend on the values of propositions."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534-Sentence-5341,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534-Sentence-5342,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534-Sentence-5343 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534-Sentence-5341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "20."@en ;
    askg-onto:inSentence "20."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-20,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534-Sentence-5342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "None of those are included in this paper, however."@en ;
    askg-onto:inSentence "None of those are included in this paper, however."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-534-Sentence-5343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "including all propositions (and very unlikely to have significant structure), while 0 will result in decision diagrams that do not depend on the values of propositions."@en ;
    askg-onto:inSentence "including all propositions (and very unlikely to have significant structure), while 0 will result in decision diagrams that do not depend on the values of propositions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0,
        askg-data:Entity-decision_diagrams .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "The Proportion Reachable parameter is a lower bound on the proportion of the entire 2n state space that is reachable from the start state. The algorithm adds behaviour until this lower bound is reached. A value of 1 will result in the algorithm running until the actions are sufficient to allow the entire state space to be **reachable.** A reward specification can be produced with regard to the generated dynamics such that a specified number of the rewards are reachable and a specified **number are unreachable.** First, a decision diagram is produced to represent which states are reachable and which are not, given the domain dynamics. Next, a random path is taken from the root of this decision diagram to a true terminal if we are generating an attainable reward, or a false terminal if we are producing an unattainable reward. The propositions encountered on this path, both negated and not, form a conjunction that is the reward formula. This process is repeated until the desired number of reachable and unreachable rewards are obtained."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5351,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5352,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5353,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5354,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5355,
        askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5356 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The Proportion Reachable parameter is a lower bound on the proportion of the entire 2n state space that is reachable from the start state."@en ;
    askg-onto:inSentence "The Proportion Reachable parameter is a lower bound on the proportion of the entire 2n state space that is reachable from the start state."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proportion_reachable_parameter,
        askg-data:Entity-the_proportion_of_the_entire_2n_state_space_that_is_reachable_from_the_start_state .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The algorithm adds behaviour until this lower bound is reached."@en ;
    askg-onto:inSentence "The algorithm adds behaviour until this lower bound is reached."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-behaviour .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5353 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A value of 1 will result in the algorithm running until the actions are sufficient to allow the entire state space to be **reachable.** A reward specification can be produced with regard to the generated dynamics such that a specified number of the rewards are reachable and a specified **number are unreachable.** First, a decision diagram is produced to represent which states are reachable and which are not, given the domain dynamics."@en ;
    askg-onto:inSentence "A value of 1 will result in the algorithm running until the actions are sufficient to allow the entire state space to be **reachable.** A reward specification can be produced with regard to the generated dynamics such that a specified number of the rewards are reachable and a specified **number are unreachable.** First, a decision diagram is produced to represent which states are reachable and which are not, given the domain dynamics."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-decision_diagram,
        askg-data:Entity-dynamics,
        askg-data:Entity-reachable_states,
        askg-data:Entity-reward_specification,
        askg-data:Entity-state_space,
        askg-data:Entity-unreachable_states .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5354 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Next, a random path is taken from the root of this decision diagram to a true terminal if we are generating an attainable reward, or a false terminal if we are producing an unattainable reward."@en ;
    askg-onto:inSentence "Next, a random path is taken from the root of this decision diagram to a true terminal if we are generating an attainable reward, or a false terminal if we are producing an unattainable reward."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-attainable,
        askg-data:Entity-path,
        askg-data:Entity-reward,
        askg-data:Entity-root_of_this_decision_diagram,
        askg-data:Entity-unattainable .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5355 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The propositions encountered on this path, both negated and not, form a conjunction that is the reward formula."@en ;
    askg-onto:inSentence "The propositions encountered on this path, both negated and not, form a conjunction that is the reward formula."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conjunction,
        askg-data:Entity-propositions,
        askg-data:Entity-reward_formula .

askg-data:Paper-c253584c3f1ff2a2-Section-53-Paragraph-535-Sentence-5356 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This process is repeated until the desired number of reachable and unreachable rewards are obtained."@en ;
    askg-onto:inSentence "This process is repeated until the desired number of reachable and unreachable rewards are obtained."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-number_of_reachable_and_unreachable_rewards,
        askg-data:Entity-process .

askg-data:Paper-c253584c3f1ff2a2-Section-54 a askg-onto:Section ;
    rdfs:label "Section 54"@en ;
    domo:Text "References"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549 ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "AT&T Labs-Research (2000). Graphviz. Available from **http://www.research.att.com/** sw/tools/graphviz/."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541-Sentence-5411,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541-Sentence-5412,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541-Sentence-5413 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541-Sentence-5411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "AT&T Labs-Research (2000)."@en ;
    askg-onto:inSentence "AT&T Labs-Research (2000)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-att_labs-research,
        askg-data:Entity-organization .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541-Sentence-5412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Graphviz."@en ;
    askg-onto:inSentence "Graphviz."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-graphviz,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-541-Sentence-5413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Available from **http://www.research.att.com/** sw/tools/graphviz/."@en ;
    askg-onto:inSentence "Available from **http://www.research.att.com/** sw/tools/graphviz/."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-graphviz,
        askg-data:Entity-visualizing_graphs .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "In Proc. Conference on Uncertainty in Artificial Intelligence (UAI)**, pp. 209–216.** Fern, A., Yoon, S., & Givan, R. (2004). Learning domain-specific knowledge from random walks. In **Proc. International Conference on Automated Planning and Scheduling** (ICAPS)**, pp. 191–198.** Fourman, M. (2000). Propositional planning. In **Proc. AIPS Workshop on Model-Theoretic** Approaches to Planning**, pp. 10–17.** Gretton, C., Price, D., & Thi´ebaux, S. (2003a). Implementation and comparison of solution methods for decision processes with non-Markovian rewards. In **Proc. Conference on** Uncertainty in Artificial Intelligence (UAI)**, pp. 289–296.** Gretton, C., Price, D., & Thi´ebaux, S. (2003b). NMRDPP: a system for decision-theoretic planning with non-Markovian rewards. In **Proc. ICAPS Workshop on Planning under** Uncertainty and Incomplete Information**, pp. 48–56.** Haddawy, P., & Hanks, S. (1992). Representations for decision-theoretic planning: Utility functions and deadline goals. In **Proc. International Conference on the Principles of** Knowledge Representation and Reasoning (KR)**, pp. 71–82.** Hansen, E., & Zilberstein, S. (2001). LAO∗**: A heuristic search algorithm that finds solutions** with loops. Artificial Intelligence, 129**, 35–62.** Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C. (1999). SPUDD: stochastic planning using decision diagrams. In Proc. Conference on Uncertainty in Artificial Intelligence **(UAI)**, pp. 279–288."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54101,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541010,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541011,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541012,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541013,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541014,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541015,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541016,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541017,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541018,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541019,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54102,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541020,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541021,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541022,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541023,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541024,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541025,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541026,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541027,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541028,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541029,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54103,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541030,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541031,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541032,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541033,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541034,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541035,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541036,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54104,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54105,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54106,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54107,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54108,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54109 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541010 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Propositional planning."@en ;
    askg-onto:inSentence "Propositional planning."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planning,
        askg-data:Entity-propositional_planning .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541011 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541012 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "AIPS Workshop on Model-Theoretic** Approaches to Planning**, pp."@en ;
    askg-onto:inSentence "AIPS Workshop on Model-Theoretic** Approaches to Planning**, pp."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aips_workshop,
        askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-model-theoretic_approaches,
        askg-data:Entity-planning,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541013 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "10–17.** Gretton, C., Price, D., & Thi´ebaux, S."@en ;
    askg-onto:inSentence "10–17.** Gretton, C., Price, D., & Thi´ebaux, S."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-gretton_c,
        askg-data:Entity-price_d,
        askg-data:Entity-thiebaux_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541014 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "(2003a)."@en ;
    askg-onto:inSentence "(2003a)."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2003a,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541015 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Implementation and comparison of solution methods for decision processes with non-Markovian rewards."@en ;
    askg-onto:inSentence "Implementation and comparison of solution methods for decision processes with non-Markovian rewards."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_processes,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541016 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-proc .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541017 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Conference on** Uncertainty in Artificial Intelligence (UAI)**, pp."@en ;
    askg-onto:inSentence "Conference on** Uncertainty in Artificial Intelligence (UAI)**, pp."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-uncertainty_in_artificial_intelligence_uai .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541018 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "289–296.** Gretton, C., Price, D., & Thi´ebaux, S."@en ;
    askg-onto:inSentence "289–296.** Gretton, C., Price, D., & Thi´ebaux, S."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gretton_c,
        askg-data:Entity-paper,
        askg-data:Entity-price_d,
        askg-data:Entity-thiebaux_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541019 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "(2003b)."@en ;
    askg-onto:inSentence "(2003b)."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2003b,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Conference on Uncertainty in Artificial Intelligence (UAI)**, pp."@en ;
    askg-onto:inSentence "Conference on Uncertainty in Artificial Intelligence (UAI)**, pp."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference_on_uncertainty_in_artificial_intelligence_uai .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541020 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "NMRDPP: a system for decision-theoretic planning with non-Markovian rewards."@en ;
    askg-onto:inSentence "NMRDPP: a system for decision-theoretic planning with non-Markovian rewards."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-system_for_decision-theoretic_planning_with_non-markovian_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541021 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541022 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "ICAPS Workshop on Planning under** Uncertainty and Incomplete Information**, pp."@en ;
    askg-onto:inSentence "ICAPS Workshop on Planning under** Uncertainty and Incomplete Information**, pp."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-icaps_workshop,
        askg-data:Entity-planning,
        askg-data:Entity-research_field,
        askg-data:Entity-uncertainty_and_incomplete_information .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541023 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "48–56.** Haddawy, P., & Hanks, S."@en ;
    askg-onto:inSentence "48–56.** Haddawy, P., & Hanks, S."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-haddawy_p,
        askg-data:Entity-hanks_s,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541024 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "(1992)."@en ;
    askg-onto:inSentence "(1992)."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541025 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Representations for decision-theoretic planning: Utility functions and deadline goals."@en ;
    askg-onto:inSentence "Representations for decision-theoretic planning: Utility functions and deadline goals."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deadline_goals,
        askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-utility_functions .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541026 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541027 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "International Conference on the Principles of** Knowledge Representation and Reasoning (KR)**, pp."@en ;
    askg-onto:inSentence "International Conference on the Principles of** Knowledge Representation and Reasoning (KR)**, pp."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-knowledge_representation_and_reasoning_kr,
        askg-data:Entity-pp,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541028 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "71–82.** Hansen, E., & Zilberstein, S."@en ;
    askg-onto:inSentence "71–82.** Hansen, E., & Zilberstein, S."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hansen_e,
        askg-data:Entity-paper,
        askg-data:Entity-zilberstein_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541029 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "(2001)."@en ;
    askg-onto:inSentence "(2001)."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54103 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "209–216.** Fern, A., Yoon, S., & Givan, R."@en ;
    askg-onto:inSentence "209–216.** Fern, A., Yoon, S., & Givan, R."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fern_a,
        askg-data:Entity-givan_r,
        askg-data:Entity-paper,
        askg-data:Entity-yoon_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541030 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "LAO∗**: A heuristic search algorithm that finds solutions** with loops."@en ;
    askg-onto:inSentence "LAO∗**: A heuristic search algorithm that finds solutions** with loops."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristic_search_algorithm,
        askg-data:Entity-lao,
        askg-data:Entity-loops .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541031 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "Artificial Intelligence, 129**, 35–62.** Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C."@en ;
    askg-onto:inSentence "Artificial Intelligence, 129**, 35–62.** Hoey, J., St-Aubin, R., Hu, A., & Boutilier, C."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-hoey_j_st-aubin_r_hu_a__boutilier_c .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541032 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "(1999)."@en ;
    askg-onto:inSentence "(1999)."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1999,
        askg-data:Entity-research .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541033 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "SPUDD: stochastic planning using decision diagrams."@en ;
    askg-onto:inSentence "SPUDD: stochastic planning using decision diagrams."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-spudd,
        askg-data:Entity-stochastic_planning_using_decision_diagrams .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541034 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper,
        askg-data:Entity-proc .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541035 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Conference on Uncertainty in Artificial Intelligence **(UAI)**, pp."@en ;
    askg-onto:inSentence "Conference on Uncertainty in Artificial Intelligence **(UAI)**, pp."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference_on_uncertainty_in_artificial_intelligence .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-541036 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "279–288."@en ;
    askg-onto:inSentence "279–288."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54104 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2004)."@en ;
    askg-onto:inSentence "(2004)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54105 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Learning domain-specific knowledge from random walks."@en ;
    askg-onto:inSentence "Learning domain-specific knowledge from random walks."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning_domain-specific_knowledge,
        askg-data:Entity-random_walks .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54106 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54107 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "International Conference on Automated Planning and Scheduling** (ICAPS)**, pp."@en ;
    askg-onto:inSentence "International Conference on Automated Planning and Scheduling** (ICAPS)**, pp."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54108 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "191–198.** Fourman, M."@en ;
    askg-onto:inSentence "191–198.** Fourman, M."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-191198,
        askg-data:Entity-fourman_m .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5410-Sentence-54109 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "(2000)."@en ;
    askg-onto:inSentence "(2000)."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-year .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "Hoffmann, J. (2002). Local search topology in planning benchmarks: A theoretical analysis."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411-Sentence-54111,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411-Sentence-54112,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411-Sentence-54113 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411-Sentence-54111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Hoffmann, J."@en ;
    askg-onto:inSentence "Hoffmann, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-hoffmann_j .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411-Sentence-54112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2002)."@en ;
    askg-onto:inSentence "(2002)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5411-Sentence-54113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Local search topology in planning benchmarks: A theoretical analysis."@en ;
    askg-onto:inSentence "Local search topology in planning benchmarks: A theoretical analysis."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-local_search_topology,
        askg-data:Entity-planning_benchmarks,
        askg-data:Entity-research_field,
        askg-data:Entity-theoretical_analysis .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "In Proc. International Conference on AI Planning and Scheduling (AIPS)**, pp. 92–100.** Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast **plan generation through** heuristic search. Journal of Artificial Intelligence Research, 14**, 253–302.** Howard, R. (1960). Dynamic Programming and Markov Processes**. MIT Press, Cambridge,** MA."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54121,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54122,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54123,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54124,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54125,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54126,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54127,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54128,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54129 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "International Conference on AI Planning and Scheduling (AIPS)**, pp."@en ;
    askg-onto:inSentence "International Conference on AI Planning and Scheduling (AIPS)**, pp."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "92–100.** Hoffmann, J., & Nebel, B."@en ;
    askg-onto:inSentence "92–100.** Hoffmann, J., & Nebel, B."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-hoffmann_j,
        askg-data:Entity-nebel_b .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2001)."@en ;
    askg-onto:inSentence "(2001)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The FF planning system: Fast **plan generation through** heuristic search."@en ;
    askg-onto:inSentence "The FF planning system: Fast **plan generation through** heuristic search."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ff_planning_system,
        askg-data:Entity-heuristic_search .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54126 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Journal of Artificial Intelligence Research, 14**, 253–302.** Howard, R."@en ;
    askg-onto:inSentence "Journal of Artificial Intelligence Research, 14**, 253–302.** Howard, R."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-14,
        askg-data:Entity-253302,
        askg-data:Entity-howard_r,
        askg-data:Entity-journal_of_artificial_intelligence_research .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54127 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "(1960)."@en ;
    askg-onto:inSentence "(1960)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54128 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Dynamic Programming and Markov Processes**."@en ;
    askg-onto:inSentence "Dynamic Programming and Markov Processes**."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_programming,
        askg-data:Entity-markov_processes,
        askg-data:Entity-method,
        askg-data:Entity-theory .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5412-Sentence-54129 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "MIT Press, Cambridge,** MA."@en ;
    askg-onto:inSentence "MIT Press, Cambridge,** MA."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mit_press .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "Kabanza, F., & Thi´ebaux, S. (2005). Search control in planning for temporally extended goals. In **Proc. International Conference on Automated Planning and Scheduling** (ICAPS)**, pp. 130–139.** Karabaev, E., & Skvortsova, O. (2005). A Heuristic Search Algorithm for Solving First- Order MDPs. In Proc. Conference on Uncertainty in Artificial Intelligence **(UAI)**, pp. 292–299."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54131,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-541310,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-541311,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54132,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54133,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54134,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54135,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54136,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54137,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54138,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54139 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Kabanza, F., & Thi´ebaux, S."@en ;
    askg-onto:inSentence "Kabanza, F., & Thi´ebaux, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kabanza_f,
        askg-data:Entity-paper,
        askg-data:Entity-thiebaux_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-541310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Conference on Uncertainty in Artificial Intelligence **(UAI)**, pp."@en ;
    askg-onto:inSentence "Conference on Uncertainty in Artificial Intelligence **(UAI)**, pp."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-541311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "292–299."@en ;
    askg-onto:inSentence "292–299."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2005)."@en ;
    askg-onto:inSentence "(2005)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-significance_in_research .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Search control in planning for temporally extended goals."@en ;
    askg-onto:inSentence "Search control in planning for temporally extended goals."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planning_for_temporally_extended_goals,
        askg-data:Entity-search_control .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "International Conference on Automated Planning and Scheduling** (ICAPS)**, pp."@en ;
    askg-onto:inSentence "International Conference on Automated Planning and Scheduling** (ICAPS)**, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54136 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "130–139.** Karabaev, E., & Skvortsova, O."@en ;
    askg-onto:inSentence "130–139.** Karabaev, E., & Skvortsova, O."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-karabaev_e,
        askg-data:Entity-publication,
        askg-data:Entity-skvortsova_o .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54137 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "(2005)."@en ;
    askg-onto:inSentence "(2005)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54138 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "A Heuristic Search Algorithm for Solving First- Order MDPs."@en ;
    askg-onto:inSentence "A Heuristic Search Algorithm for Solving First- Order MDPs."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-first-order_mdps,
        askg-data:Entity-heuristic_search_algorithm,
        askg-data:Entity-mdp,
        askg-data:Entity-solving_first-order_mdps .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5413-Sentence-54139 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "Koehler, J., & Schuster, K. (2000). Elevator control as a planning problem. In **Proc.** International Conference on AI Planning and Scheduling (AIPS)**, pp. 331–338.** Korf, R. (1990). Real-time heuristic search. Artificial Intelligence, 42**, 189–211.** Kushmerick, N., Hanks, S., & Weld, D. (1995). An algorithm for probabilistic planning."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54141,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-541410,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54142,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54143,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54144,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54145,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54146,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54147,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54148,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54149 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Koehler, J., & Schuster, K."@en ;
    askg-onto:inSentence "Koehler, J., & Schuster, K."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-koehler_j,
        askg-data:Entity-paper,
        askg-data:Entity-schuster_k .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-541410 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "An algorithm for probabilistic planning."@en ;
    askg-onto:inSentence "An algorithm for probabilistic planning."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-probabilistic_planning .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2000)."@en ;
    askg-onto:inSentence "(2000)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Elevator control as a planning problem."@en ;
    askg-onto:inSentence "Elevator control as a planning problem."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elevator_control,
        askg-data:Entity-planning_problem .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54144 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In **Proc.** International Conference on AI Planning and Scheduling (AIPS)**, pp."@en ;
    askg-onto:inSentence "In **Proc.** International Conference on AI Planning and Scheduling (AIPS)**, pp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aips,
        askg-data:Entity-conference,
        askg-data:Entity-international_conference_on_ai_planning_and_scheduling .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54145 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "331–338.** Korf, R."@en ;
    askg-onto:inSentence "331–338.** Korf, R."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-331338,
        askg-data:Entity-korf_r .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54146 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "(1990)."@en ;
    askg-onto:inSentence "(1990)."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54147 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Real-time heuristic search."@en ;
    askg-onto:inSentence "Real-time heuristic search."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-real-time_heuristic_search .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54148 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Artificial Intelligence, 42**, 189–211.** Kushmerick, N., Hanks, S., & Weld, D."@en ;
    askg-onto:inSentence "Artificial Intelligence, 42**, 189–211.** Kushmerick, N., Hanks, S., & Weld, D."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-artificial_intelligence_42_189211,
        askg-data:Entity-kushmerick_n_hanks_s__weld_d .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5414-Sentence-54149 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "(1995)."@en ;
    askg-onto:inSentence "(1995)."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1995 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Artificial Intelligence, 76**, 239–286.** Lichtenstein, O., Pnueli, A., & Zuck, L. (1985). The glory of the past. In **Proc. Conference** on Logics of Programs**, pp. 196–218. LNCS, volume 193.** Onder, N., Whelan, G. C., & Li, L. (2006). Engineering a conformant probabilistic planner."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54151,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-541510,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54152,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54153,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54154,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54155,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54156,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54157,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54158,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54159 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Artificial Intelligence, 76**, 239–286.** Lichtenstein, O., Pnueli, A., & Zuck, L."@en ;
    askg-onto:inSentence "Artificial Intelligence, 76**, 239–286.** Lichtenstein, O., Pnueli, A., & Zuck, L."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-lichtenstein_o,
        askg-data:Entity-pnueli_a,
        askg-data:Entity-zuck_l .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-541510 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Engineering a conformant probabilistic planner."@en ;
    askg-onto:inSentence "Engineering a conformant probabilistic planner."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-probabilistic_planner,
        askg-data:Entity-system .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1985)."@en ;
    askg-onto:inSentence "(1985)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The glory of the past."@en ;
    askg-onto:inSentence "The glory of the past."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-glory .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54155 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Conference** on Logics of Programs**, pp."@en ;
    askg-onto:inSentence "Conference** on Logics of Programs**, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-logics_of_programs .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54156 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "196–218."@en ;
    askg-onto:inSentence "196–218."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54157 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "LNCS, volume 193.** Onder, N., Whelan, G."@en ;
    askg-onto:inSentence "LNCS, volume 193.** Onder, N., Whelan, G."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-193,
        askg-data:Entity-lncs,
        askg-data:Entity-lncs_volume_193,
        askg-data:Entity-onder_n,
        askg-data:Entity-whelan_g .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54158 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "C., & Li, L."@en ;
    askg-onto:inSentence "C., & Li, L."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-li_l .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5415-Sentence-54159 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "(2006)."@en ;
    askg-onto:inSentence "(2006)."^^xsd:string ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "Journal of Artificial Intelligence Research, 25**, 1–15.** Pistore, M., & Traverso, P. (2001). Planning as model-checking for extended goals in non-deterministic domains. In Proc. International Joint Conference on Artificial Intelligence (IJCAI-01)**, pp. 479–484.** Slaney, J. (2005). Semi-positive LTL with an uninterpreted past operator. **Logic Journal of** the IGPL, 13**, 211–229.** Slaney, J., & Thi´ebaux, S. (2001). Blocks world revisited. Artificial Intelligence, 125, 119–153."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54161,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-541610,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-541611,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-541612,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54162,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54163,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54164,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54165,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54166,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54167,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54168,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54169 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Journal of Artificial Intelligence Research, 25**, 1–15.** Pistore, M., & Traverso, P."@en ;
    askg-onto:inSentence "Journal of Artificial Intelligence Research, 25**, 1–15.** Pistore, M., & Traverso, P."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-journal_of_artificial_intelligence_research,
        askg-data:Entity-pistore_m,
        askg-data:Entity-traverso_p .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-541610 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(2001)."@en ;
    askg-onto:inSentence "(2001)."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2001 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-541611 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Blocks world revisited."@en ;
    askg-onto:inSentence "Blocks world revisited."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blocks_world,
        askg-data:Entity-concept .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-541612 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Artificial Intelligence, 125, 119–153."@en ;
    askg-onto:inSentence "Artificial Intelligence, 125, 119–153."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2001)."@en ;
    askg-onto:inSentence "(2001)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-study .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54163 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Planning as model-checking for extended goals in non-deterministic domains."@en ;
    askg-onto:inSentence "Planning as model-checking for extended goals in non-deterministic domains."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-extended_goals,
        askg-data:Entity-model-checking,
        askg-data:Entity-non-deterministic_domains,
        askg-data:Entity-planning .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54164 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54165 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "International Joint Conference on Artificial Intelligence (IJCAI-01)**, pp."@en ;
    askg-onto:inSentence "International Joint Conference on Artificial Intelligence (IJCAI-01)**, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-pp .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54166 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "479–484.** Slaney, J."@en ;
    askg-onto:inSentence "479–484.** Slaney, J."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-479484,
        askg-data:Entity-slaney_j .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54167 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "(2005)."@en ;
    askg-onto:inSentence "(2005)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2005 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54168 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Semi-positive LTL with an uninterpreted past operator."@en ;
    askg-onto:inSentence "Semi-positive LTL with an uninterpreted past operator."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-model,
        askg-data:Entity-semi-positive_ltl,
        askg-data:Entity-uninterpreted_past_operator .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5416-Sentence-54169 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "**Logic Journal of** the IGPL, 13**, 211–229.** Slaney, J., & Thi´ebaux, S."@en ;
    askg-onto:inSentence "**Logic Journal of** the IGPL, 13**, 211–229.** Slaney, J., & Thi´ebaux, S."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-logic_journal_of_the_igpl,
        askg-data:Entity-publication,
        askg-data:Entity-slaney_j,
        askg-data:Entity-thiebaux_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "Somenzi, F. (2001). CUDD: CU Decision Diagram Package. Available from ftp://vlsi.colorado.edu/pub/."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54171,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54172,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54173,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54174 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Somenzi, F."@en ;
    askg-onto:inSentence "Somenzi, F."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-somenzi_f .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54172 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2001)."@en ;
    askg-onto:inSentence "(2001)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54173 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "CUDD: CU Decision Diagram Package."@en ;
    askg-onto:inSentence "CUDD: CU Decision Diagram Package."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cu_decision_diagram_package,
        askg-data:Entity-cudd .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5417-Sentence-54174 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Available from ftp://vlsi.colorado.edu/pub/."@en ;
    askg-onto:inSentence "Available from ftp://vlsi.colorado.edu/pub/."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ftpvlsicoloradoedupub .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "Teichteil-K¨onigsbuch, F., & Fabiani, P. (2005). Symbolic heuristic policy iteration algorithms for structured decision-theoretic exploration problems. In Proc. ICAPS workshop on Planning under Uncertainty for Autonomous Systems."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54181,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54182,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54183,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54184,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54185 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Teichteil-K¨onigsbuch, F., & Fabiani, P."@en ;
    askg-onto:inSentence "Teichteil-K¨onigsbuch, F., & Fabiani, P."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fabiani_p,
        askg-data:Entity-paper,
        askg-data:Entity-teichteil-k%C3%B6nigsbuch_f .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2005)."@en ;
    askg-onto:inSentence "(2005)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54183 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Symbolic heuristic policy iteration algorithms for structured decision-theoretic exploration problems."@en ;
    askg-onto:inSentence "Symbolic heuristic policy iteration algorithms for structured decision-theoretic exploration problems."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-structured_decision-theoretic_exploration_problems,
        askg-data:Entity-symbolic_heuristic_policy_iteration_algorithms .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54184 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5418-Sentence-54185 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "ICAPS workshop on Planning under Uncertainty for Autonomous Systems."@en ;
    askg-onto:inSentence "ICAPS workshop on Planning under Uncertainty for Autonomous Systems."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-icaps_workshop,
        askg-data:Entity-planning_under_uncertainty_for_autonomous_systems .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "Thi´ebaux, S., Hertzberg, J., Shoaff, W., & Schneider, M. (1995). A stochastic model of actions and plans for anytime planning under uncertainty. **International Journal of** Intelligent Systems, 10**(2), 155–183.** Thi´ebaux, S., Kabanza, F., & Slaney, J. (2002a). Anytime state-based solution methods for decision processes with non-Markovian rewards. In **Proc. Conference on Uncertainty** in Artificial Intelligence (UAI)**, pp. 501–510.** Thi´ebaux, S., Kabanza, F., & Slaney, J. (2002b). A model-checking approach to decisiontheoretic planning with non-Markovian rewards. In Proc. ECAI Workshop on Model- Checking in Artificial Intelligence (MoChArt-02)**, pp. 101–108.** Vardi, M. (2003). Automated verification = graph, logic, and automata. In Proc. International Joint Conference on Artificial Intelligence (IJCAI)**, pp. 603–606. Invited** paper."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54191,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541910,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541911,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541912,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541913,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541914,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541915,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541916,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541917,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541918,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541919,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54192,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541920,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54193,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54194,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54195,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54196,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54197,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54198,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54199 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Thi´ebaux, S., Hertzberg, J., Shoaff, W., & Schneider, M."@en ;
    askg-onto:inSentence "Thi´ebaux, S., Hertzberg, J., Shoaff, W., & Schneider, M."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hertzberg_j,
        askg-data:Entity-paper,
        askg-data:Entity-schneider_m,
        askg-data:Entity-shoaff_w,
        askg-data:Entity-thiebaux_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541910 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(2002b)."@en ;
    askg-onto:inSentence "(2002b)."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002b,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541911 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "A model-checking approach to decisiontheoretic planning with non-Markovian rewards."@en ;
    askg-onto:inSentence "A model-checking approach to decisiontheoretic planning with non-Markovian rewards."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-model-checking_approach,
        askg-data:Entity-non-markovian_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541912 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541913 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "ECAI Workshop on Model- Checking in Artificial Intelligence (MoChArt-02)**, pp."@en ;
    askg-onto:inSentence "ECAI Workshop on Model- Checking in Artificial Intelligence (MoChArt-02)**, pp."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pp,
        askg-data:Entity-workshop .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541914 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "101–108.** Vardi, M."@en ;
    askg-onto:inSentence "101–108.** Vardi, M."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-vardi_m .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541915 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "(2003)."@en ;
    askg-onto:inSentence "(2003)."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541916 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Automated verification = graph, logic, and automata."@en ;
    askg-onto:inSentence "Automated verification = graph, logic, and automata."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automata,
        askg-data:Entity-automated_verification,
        askg-data:Entity-graph,
        askg-data:Entity-logic .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541917 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-proc .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541918 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "International Joint Conference on Artificial Intelligence (IJCAI)**, pp."@en ;
    askg-onto:inSentence "International Joint Conference on Artificial Intelligence (IJCAI)**, pp."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-international_joint_conference_on_artificial_intelligence_ijcai .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541919 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "603–606."@en ;
    askg-onto:inSentence "603–606."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-603606,
        askg-data:Entity-page_range .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1995)."@en ;
    askg-onto:inSentence "(1995)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-541920 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Invited** paper."@en ;
    askg-onto:inSentence "Invited** paper."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-invited_paper,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54193 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "A stochastic model of actions and plans for anytime planning under uncertainty."@en ;
    askg-onto:inSentence "A stochastic model of actions and plans for anytime planning under uncertainty."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_planning,
        askg-data:Entity-condition,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-stochastic_model,
        askg-data:Entity-uncertainty .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54194 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "**International Journal of** Intelligent Systems, 10**(2), 155–183.** Thi´ebaux, S., Kabanza, F., & Slaney, J."@en ;
    askg-onto:inSentence "**International Journal of** Intelligent Systems, 10**(2), 155–183.** Thi´ebaux, S., Kabanza, F., & Slaney, J."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-international_journal_of_intelligent_systems,
        askg-data:Entity-kabanza_f,
        askg-data:Entity-publication,
        askg-data:Entity-slaney_j,
        askg-data:Entity-thiebaux_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54195 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2002a)."@en ;
    askg-onto:inSentence "(2002a)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002a .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54196 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Anytime state-based solution methods for decision processes with non-Markovian rewards."@en ;
    askg-onto:inSentence "Anytime state-based solution methods for decision processes with non-Markovian rewards."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_processes_with_non-markovian_rewards,
        askg-data:Entity-state-based_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54197 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54198 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Conference on Uncertainty** in Artificial Intelligence (UAI)**, pp."@en ;
    askg-onto:inSentence "Conference on Uncertainty** in Artificial Intelligence (UAI)**, pp."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference_on_uncertainty_in_artificial_intelligence,
        askg-data:Entity-uai .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5419-Sentence-54199 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "501–510.** Thi´ebaux, S., Kabanza, F., & Slaney, J."@en ;
    askg-onto:inSentence "501–510.** Thi´ebaux, S., Kabanza, F., & Slaney, J."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kabanza_f,
        askg-data:Entity-paper,
        askg-data:Entity-slaney_j,
        askg-data:Entity-thiebaux_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Bacchus, F., Boutilier, C., & Grove, A. (1996). Rewarding behaviors. In **Proc. American** National Conference on Artificial Intelligence (AAAI)**, pp. 1160–1167.** Bacchus, F., Boutilier, C., & Grove, A. (1997). Structured solution methods for non- Markovian decision processes. In **Proc. American National Conference on Artificial** Intelligence (AAAI)**, pp. 112–117.** Bacchus, F., & Kabanza, F. (1998). Planning for temporally extended goals. **Annals of** Mathematics and Artificial Intelligence, 22**, 5–27.** Bacchus, F., & Kabanza, F. (2000). Using temporal logic to express search control knowledge for planning. Artificial Intelligence, 116**(1-2).** Baier, C., Gr¨oßer, M., Leucker, M., Bollig, B., & Ciesinski, F. (2004). Controller synthesis for probabilistic systems (extended abstract). In **Proc. IFIP International Conference** on Theoretical Computer Science (IFIP TCS)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5421,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54210,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54211,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54212,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54213,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54214,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54215,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54216,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54217,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54218,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54219,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5422,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54220,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54221,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5423,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5424,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5425,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5426,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5427,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5428,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5429 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Bacchus, F., Boutilier, C., & Grove, A."@en ;
    askg-onto:inSentence "Bacchus, F., Boutilier, C., & Grove, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bacchus_f,
        askg-data:Entity-boutilier_c,
        askg-data:Entity-grove_a .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "American National Conference on Artificial** Intelligence (AAAI)**, pp."@en ;
    askg-onto:inSentence "American National Conference on Artificial** Intelligence (AAAI)**, pp."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-aaai,
        askg-data:Entity-american_national_conference_on_artificial_intelligence,
        askg-data:Entity-conference .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54211 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "112–117.** Bacchus, F., & Kabanza, F."@en ;
    askg-onto:inSentence "112–117.** Bacchus, F., & Kabanza, F."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_f,
        askg-data:Entity-kabanza_f,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54212 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "(1998)."@en ;
    askg-onto:inSentence "(1998)."^^xsd:string ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54213 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Planning for temporally extended goals."@en ;
    askg-onto:inSentence "Planning for temporally extended goals."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-temporal_planning,
        askg-data:Entity-temporally_extended_goals .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54214 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "**Annals of** Mathematics and Artificial Intelligence, 22**, 5–27.** Bacchus, F., & Kabanza, F."@en ;
    askg-onto:inSentence "**Annals of** Mathematics and Artificial Intelligence, 22**, 5–27.** Bacchus, F., & Kabanza, F."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-annals_of_mathematics_and_artificial_intelligence,
        askg-data:Entity-author,
        askg-data:Entity-bacchus_f,
        askg-data:Entity-kabanza_f,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54215 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "(2000)."@en ;
    askg-onto:inSentence "(2000)."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2000,
        askg-data:Entity-year .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54216 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Using temporal logic to express search control knowledge for planning."@en ;
    askg-onto:inSentence "Using temporal logic to express search control knowledge for planning."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planning,
        askg-data:Entity-search_control_knowledge,
        askg-data:Entity-temporal_logic .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54217 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Artificial Intelligence, 116**(1-2).** Baier, C., Gr¨oßer, M., Leucker, M., Bollig, B., & Ciesinski, F."@en ;
    askg-onto:inSentence "Artificial Intelligence, 116**(1-2).** Baier, C., Gr¨oßer, M., Leucker, M., Bollig, B., & Ciesinski, F."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-baier_c,
        askg-data:Entity-bollig_b,
        askg-data:Entity-ciesinski_f,
        askg-data:Entity-gr%C3%B6%C3%9Fer_m,
        askg-data:Entity-leucker_m,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54218 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "(2004)."@en ;
    askg-onto:inSentence "(2004)."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54219 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Controller synthesis for probabilistic systems (extended abstract)."@en ;
    askg-onto:inSentence "Controller synthesis for probabilistic systems (extended abstract)."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-controller_synthesis,
        askg-data:Entity-controller_synthesis_for_probabilistic_systems,
        askg-data:Entity-domain,
        askg-data:Entity-method,
        askg-data:Entity-paper,
        askg-data:Entity-probabilistic_systems .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1996)."@en ;
    askg-onto:inSentence "(1996)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-unknown_concept .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54220 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-54221 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "IFIP International Conference** on Theoretical Computer Science (IFIP TCS)."@en ;
    askg-onto:inSentence "IFIP International Conference** on Theoretical Computer Science (IFIP TCS)."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ifip_international_conference,
        askg-data:Entity-theoretical_computer_science .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Rewarding behaviors."@en ;
    askg-onto:inSentence "Rewarding behaviors."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviors,
        askg-data:Entity-rewarding_behaviors .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "American** National Conference on Artificial Intelligence (AAAI)**, pp."@en ;
    askg-onto:inSentence "American** National Conference on Artificial Intelligence (AAAI)**, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-american_national_conference_on_artificial_intelligence_aaai,
        askg-data:Entity-conference .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "1160–1167.** Bacchus, F., Boutilier, C., & Grove, A."@en ;
    askg-onto:inSentence "1160–1167.** Bacchus, F., Boutilier, C., & Grove, A."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11601167,
        askg-data:Entity-bacchus_f,
        askg-data:Entity-boutilier_c,
        askg-data:Entity-grove_a .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5427 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "(1997)."@en ;
    askg-onto:inSentence "(1997)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1997 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5428 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Structured solution methods for non- Markovian decision processes."@en ;
    askg-onto:inSentence "Structured solution methods for non- Markovian decision processes."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-markovian_decision_processes,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-542-Sentence-5429 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "Wolper, P. (1987). On the relation of programs and computations to models of temporal logic. In Proc. Temporal Logic in Specification, LNCS 398**, pp. 75–123.** Younes, H. L. S., & Littman, M. (2004). PPDDL1.0: An extension to PDDL for expressing planning domains with probabilistic effects. Tech. rep. CMU-CS-04-167, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54201,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542010,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542011,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542012,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542013,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54202,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54203,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54204,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54205,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54206,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54207,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54208,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54209 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Wolper, P."@en ;
    askg-onto:inSentence "Wolper, P."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication,
        askg-data:Entity-wolper_p .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542010 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "PPDDL1.0: An extension to PDDL for expressing planning domains with probabilistic effects."@en ;
    askg-onto:inSentence "PPDDL1.0: An extension to PDDL for expressing planning domains with probabilistic effects."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pddl,
        askg-data:Entity-planning_domains_with_probabilistic_effects,
        askg-data:Entity-ppddl10 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542011 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Tech."@en ;
    askg-onto:inSentence "Tech."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-tech,
        askg-data:Entity-technology .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542012 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "rep."@en ;
    askg-onto:inSentence "rep."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-rep,
        askg-data:Entity-representation .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-542013 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "CMU-CS-04-167, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania."@en ;
    askg-onto:inSentence "CMU-CS-04-167, School of Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-carnegie_mellon_university .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54202 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1987)."@en ;
    askg-onto:inSentence "(1987)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54203 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "On the relation of programs and computations to models of temporal logic."@en ;
    askg-onto:inSentence "On the relation of programs and computations to models of temporal logic."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computations,
        askg-data:Entity-models_of_temporal_logic,
        askg-data:Entity-programs .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54204 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-proceedings .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54205 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Temporal Logic in Specification, LNCS 398**, pp."@en ;
    askg-onto:inSentence "Temporal Logic in Specification, LNCS 398**, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lncs_398,
        askg-data:Entity-publication,
        askg-data:Entity-specification,
        askg-data:Entity-temporal_logic .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54206 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "75–123.** Younes, H."@en ;
    askg-onto:inSentence "75–123.** Younes, H."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-75123,
        askg-data:Entity-younes_h .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54207 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l,
        askg-data:Entity-person .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54208 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "S., & Littman, M."@en ;
    askg-onto:inSentence "S., & Littman, M."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-littman_m,
        askg-data:Entity-paper,
        askg-data:Entity-s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5420-Sentence-54209 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "(2004)."@en ;
    askg-onto:inSentence "(2004)."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 21"@en ;
    domo:Text "Younes, H. L. S., Littman, M., Weissmann, D., & Asmuth, J. (2005). The first probabilistic track of the International Planning Competition. In **Journal of Artificial Intelligence** Research**, Vol. 24, pp. 851–887.** Younes, H., & Simmons, R. G. (2004). Policy generation for continuous-time stochastic domains with concurrency. In **Proc. International Conference on Automated Planning** and Scheduling (ICAPS)**, pp. 325–333.**"@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54211,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542110,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542111,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542112,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542113,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542114,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54212,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54213,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54214,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54215,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54216,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54217,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54218,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54219 ;
    askg-onto:index "21"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Younes, H."@en ;
    askg-onto:inSentence "Younes, H."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_on_x,
        askg-data:Entity-younes_h .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(2004)."@en ;
    askg-onto:inSentence "(2004)."^^xsd:string ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Policy generation for continuous-time stochastic domains with concurrency."@en ;
    askg-onto:inSentence "Policy generation for continuous-time stochastic domains with concurrency."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-concurrency,
        askg-data:Entity-continuous-time_stochastic_domains,
        askg-data:Entity-domain,
        askg-data:Entity-method,
        askg-data:Entity-policy_generation .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "International Conference on Automated Planning** and Scheduling (ICAPS)**, pp."@en ;
    askg-onto:inSentence "International Conference on Automated Planning** and Scheduling (ICAPS)**, pp."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-542114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "325–333.**"@en ;
    askg-onto:inSentence "325–333.**"^^xsd:string ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "L."@en ;
    askg-onto:inSentence "L."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l,
        askg-data:Entity-person .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "S., Littman, M., Weissmann, D., & Asmuth, J."@en ;
    askg-onto:inSentence "S., Littman, M., Weissmann, D., & Asmuth, J."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-asmuth,
        askg-data:Entity-littman,
        askg-data:Entity-paper,
        askg-data:Entity-s,
        askg-data:Entity-weissmann .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "(2005)."@en ;
    askg-onto:inSentence "(2005)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2005,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The first probabilistic track of the International Planning Competition."@en ;
    askg-onto:inSentence "The first probabilistic track of the International Planning Competition."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-international_planning_competition,
        askg-data:Entity-probabilistic_track .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In **Journal of Artificial Intelligence** Research**, Vol."@en ;
    askg-onto:inSentence "In **Journal of Artificial Intelligence** Research**, Vol."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-journal_of_artificial_intelligence_research,
        askg-data:Entity-publication,
        askg-data:Entity-vol .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "24, pp."@en ;
    askg-onto:inSentence "24, pp."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-24 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54218 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "851–887.** Younes, H., & Simmons, R."@en ;
    askg-onto:inSentence "851–887.** Younes, H., & Simmons, R."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-851887,
        askg-data:Entity-simmons_r,
        askg-data:Entity-younes_h .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-5421-Sentence-54219 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "G."@en ;
    askg-onto:inSentence "G."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-person .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Baral, C., & Zhao, J. (2004). Goal specification in presence of nondeterministic actions. In Proc. European Conference on Artificial Intelligence (ECAI)**, pp. 273–277.** Barto, A., Bardtke, S., & Singh, S. (1995). Learning to act using real-time dynamic programming. Artificial Intelligence, 72**, 81–138.** Bonet, B., & Geffner, H. (2003). Labeled RTDP: Improving the convergence of real-time dynamic programming. In **Proc. International Conference on Automated Planning** and Scheduling (ICAPS)**, pp. 12–21.** Bonet, B., & Geffner, H. (2005). mGPT: A probabilistic planner based on heuristic search."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5431,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54310,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54311,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54312,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54313,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54314,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54315,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54316,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5432,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5433,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5434,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5435,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5436,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5437,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5438,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5439 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Baral, C., & Zhao, J."@en ;
    askg-onto:inSentence "Baral, C., & Zhao, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-baral_c,
        askg-data:Entity-zhao_j .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(2003)."@en ;
    askg-onto:inSentence "(2003)."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Labeled RTDP: Improving the convergence of real-time dynamic programming."@en ;
    askg-onto:inSentence "Labeled RTDP: Improving the convergence of real-time dynamic programming."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convergence_of_real-time_dynamic_programming,
        askg-data:Entity-labeled_rtdp .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "International Conference on Automated Planning** and Scheduling (ICAPS)**, pp."@en ;
    askg-onto:inSentence "International Conference on Automated Planning** and Scheduling (ICAPS)**, pp."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-international_conference_on_automated_planning_and_scheduling .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54314 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "12–21.** Bonet, B., & Geffner, H."@en ;
    askg-onto:inSentence "12–21.** Bonet, B., & Geffner, H."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bonet_b,
        askg-data:Entity-geffner_h,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54315 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "(2005)."@en ;
    askg-onto:inSentence "(2005)."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-54316 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "mGPT: A probabilistic planner based on heuristic search."@en ;
    askg-onto:inSentence "mGPT: A probabilistic planner based on heuristic search."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristic_search,
        askg-data:Entity-mgpt,
        askg-data:Entity-probabilistic_planner .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2004)."@en ;
    askg-onto:inSentence "(2004)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Goal specification in presence of nondeterministic actions."@en ;
    askg-onto:inSentence "Goal specification in presence of nondeterministic actions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal_specification,
        askg-data:Entity-nondeterministic_actions .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5435 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "European Conference on Artificial Intelligence (ECAI)**, pp."@en ;
    askg-onto:inSentence "European Conference on Artificial Intelligence (ECAI)**, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference,
        askg-data:Entity-european_conference_on_artificial_intelligence_ecai,
        askg-data:Entity-pp .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5436 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "273–277.** Barto, A., Bardtke, S., & Singh, S."@en ;
    askg-onto:inSentence "273–277.** Barto, A., Bardtke, S., & Singh, S."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bardtke_s,
        askg-data:Entity-barto_a,
        askg-data:Entity-publication,
        askg-data:Entity-singh_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5437 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "(1995)."@en ;
    askg-onto:inSentence "(1995)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1995 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5438 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Learning to act using real-time dynamic programming."@en ;
    askg-onto:inSentence "Learning to act using real-time dynamic programming."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning,
        askg-data:Entity-real-time_dynamic_programming .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-543-Sentence-5439 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Artificial Intelligence, 72**, 81–138.** Bonet, B., & Geffner, H."@en ;
    askg-onto:inSentence "Artificial Intelligence, 72**, 81–138.** Bonet, B., & Geffner, H."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-author,
        askg-data:Entity-bonet_b,
        askg-data:Entity-geffner_h,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Journal of Artificial Intelligence Research, 24**, 933–944.** Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions and computational leverage. In **Journal of Artificial Intelligence Research**, Vol. 11, pp. 1–94."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5441,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5442,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5443,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5444,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5445,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5446 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Journal of Artificial Intelligence Research, 24**, 933–944.** Boutilier, C., Dean, T., & Hanks, S."@en ;
    askg-onto:inSentence "Journal of Artificial Intelligence Research, 24**, 933–944.** Boutilier, C., Dean, T., & Hanks, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-boutilier_c,
        askg-data:Entity-dean_t,
        askg-data:Entity-hanks_s,
        askg-data:Entity-journal_of_artificial_intelligence_research,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1999)."@en ;
    askg-onto:inSentence "(1999)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Decision-theoretic planning: Structural assumptions and computational leverage."@en ;
    askg-onto:inSentence "Decision-theoretic planning: Structural assumptions and computational leverage."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computational_leverage,
        askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-research_field,
        askg-data:Entity-structural_assumptions .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5444 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In **Journal of Artificial Intelligence Research**, Vol."@en ;
    askg-onto:inSentence "In **Journal of Artificial Intelligence Research**, Vol."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-journal_of_artificial_intelligence_research,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5445 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "11, pp."@en ;
    askg-onto:inSentence "11, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11,
        askg-data:Entity-pp .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-544-Sentence-5446 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "1–94."@en ;
    askg-onto:inSentence "1–94."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-194,
        askg-data:Entity-numbers .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programming with factored representations. Artificial Intelligence, 121**(1-2), 49–107.** Calvanese, D., De Giacomo, G., & Vardi, M. (2002). Reasoning about actions and planning in LTL action theories. In **Proc. International Conference on the Principles of** Knowledge Representation and Reasoning (KR)**, pp. 493–602.** Cesta, A., Bahadori, S., G, C., Grisetti, G., Giuliani, M., Loochi, L., Leone, G., Nardi, D., Oddi, A., Pecora, F., Rasconi, R., Saggase, A., & Scopelliti, M. (2003). The RoboCare project. Cognitive systems for the care of the elderly. In **Proc. International Conference** on Aging, Disability and Independence (ICADI)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5451,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54510,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54511,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54512,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54513,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54514,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5452,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5453,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5454,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5455,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5456,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5457,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5458,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5459 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Boutilier, C., Dearden, R., & Goldszmidt, M."@en ;
    askg-onto:inSentence "Boutilier, C., Dearden, R., & Goldszmidt, M."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-boutilier_c,
        askg-data:Entity-dearden_r,
        askg-data:Entity-goldszmidt_m,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54510 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "(2003)."@en ;
    askg-onto:inSentence "(2003)."^^xsd:string ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54511 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "The RoboCare project."@en ;
    askg-onto:inSentence "The RoboCare project."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-project .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54512 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Cognitive systems for the care of the elderly."@en ;
    askg-onto:inSentence "Cognitive systems for the care of the elderly."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cognitive_systems,
        askg-data:Entity-the_elderly .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54513 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-54514 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "International Conference** on Aging, Disability and Independence (ICADI)."@en ;
    askg-onto:inSentence "International Conference** on Aging, Disability and Independence (ICADI)."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2000)."@en ;
    askg-onto:inSentence "(2000)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2000 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5453 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Stochastic dynamic programming with factored representations."@en ;
    askg-onto:inSentence "Stochastic dynamic programming with factored representations."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-factored_representations,
        askg-data:Entity-stochastic_dynamic_programming .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5454 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Artificial Intelligence, 121**(1-2), 49–107.** Calvanese, D., De Giacomo, G., & Vardi, M."@en ;
    askg-onto:inSentence "Artificial Intelligence, 121**(1-2), 49–107.** Calvanese, D., De Giacomo, G., & Vardi, M."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1211-2_49107,
        askg-data:Entity-artificial_intelligence,
        askg-data:Entity-author,
        askg-data:Entity-calvanese_d,
        askg-data:Entity-de_giacomo_g,
        askg-data:Entity-research_field,
        askg-data:Entity-vardi_m .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5455 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2002)."@en ;
    askg-onto:inSentence "(2002)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5456 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Reasoning about actions and planning in LTL action theories."@en ;
    askg-onto:inSentence "Reasoning about actions and planning in LTL action theories."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions_and_planning,
        askg-data:Entity-ltl_action_theories .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5457 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper,
        askg-data:Entity-proc .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5458 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "International Conference on the Principles of** Knowledge Representation and Reasoning (KR)**, pp."@en ;
    askg-onto:inSentence "International Conference on the Principles of** Knowledge Representation and Reasoning (KR)**, pp."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-conference,
        askg-data:Entity-international_conference_on_the_principles_of_knowledge_representation_and_reasoning,
        askg-data:Entity-knowledge_representation_and_reasoning,
        askg-data:Entity-papers .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-545-Sentence-5459 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "493–602.** Cesta, A., Bahadori, S., G, C., Grisetti, G., Giuliani, M., Loochi, L., Leone, G., Nardi, D., Oddi, A., Pecora, F., Rasconi, R., Saggase, A., & Scopelliti, M."@en ;
    askg-onto:inSentence "493–602.** Cesta, A., Bahadori, S., G, C., Grisetti, G., Giuliani, M., Loochi, L., Leone, G., Nardi, D., Oddi, A., Pecora, F., Rasconi, R., Saggase, A., & Scopelliti, M."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bahadori_s,
        askg-data:Entity-cesta_a,
        askg-data:Entity-g_c,
        askg-data:Entity-giuliani_m,
        askg-data:Entity-grisetti_g,
        askg-data:Entity-leone_g,
        askg-data:Entity-loochi_l,
        askg-data:Entity-nardi_d,
        askg-data:Entity-oddi_a,
        askg-data:Entity-pecora_f,
        askg-data:Entity-publication,
        askg-data:Entity-rasconi_r,
        askg-data:Entity-saggase_a,
        askg-data:Entity-scopelliti_m .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Chomicki, J. (1995). Efficient checking of temporal integrity constraints using bounded history encoding. ACM Transactions on Database Systems, 20**(2), 149–186.** Dal Lago, U., Pistore, M., & Traverso, P. (2002). Planning with a language for extended goals. In Proc. American National Conference on Artificial Intelligence (AAAI)**, pp.** 447–454."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5461,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5462,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5463,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5464,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5465,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5466,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5467,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5468 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Chomicki, J."@en ;
    askg-onto:inSentence "Chomicki, J."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chomicki_j,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1995)."@en ;
    askg-onto:inSentence "(1995)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5463 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Efficient checking of temporal integrity constraints using bounded history encoding."@en ;
    askg-onto:inSentence "Efficient checking of temporal integrity constraints using bounded history encoding."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bounded_history_encoding,
        askg-data:Entity-temporal_integrity_constraints .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5464 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "ACM Transactions on Database Systems, 20**(2), 149–186.** Dal Lago, U., Pistore, M., & Traverso, P."@en ;
    askg-onto:inSentence "ACM Transactions on Database Systems, 20**(2), 149–186.** Dal Lago, U., Pistore, M., & Traverso, P."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-acm_transactions_on_database_systems,
        askg-data:Entity-dal_lago_u,
        askg-data:Entity-paper,
        askg-data:Entity-pistore_m,
        askg-data:Entity-traverso_p .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5465 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(2002)."@en ;
    askg-onto:inSentence "(2002)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5466 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Planning with a language for extended goals."@en ;
    askg-onto:inSentence "Planning with a language for extended goals."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-language_for_extended_goals,
        askg-data:Entity-planning .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5467 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-546-Sentence-5468 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "American National Conference on Artificial Intelligence (AAAI)**, pp.** 447–454."@en ;
    askg-onto:inSentence "American National Conference on Artificial Intelligence (AAAI)**, pp.** 447–454."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-american_national_conference_on_artificial_intelligence_aaai,
        askg-data:Entity-conference,
        askg-data:Entity-pp_447454 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A. (1995). Planning under time constraints in stochastic domains. Artificial Intelligence, 76**, 35–74.** Dean, T., & Kanazawa, K. (1989). A model for reasoning about persistance and causation."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5471,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5472,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5473,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5474,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5475,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5476 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A."@en ;
    askg-onto:inSentence "Dean, T., Kaelbling, L., Kirman, J., & Nicholson, A."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-dean_t,
        askg-data:Entity-kaelbling_l,
        askg-data:Entity-kirman_j,
        askg-data:Entity-nicholson_a .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1995)."@en ;
    askg-onto:inSentence "(1995)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Planning under time constraints in stochastic domains."@en ;
    askg-onto:inSentence "Planning under time constraints in stochastic domains."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planning,
        askg-data:Entity-stochastic_domains .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5474 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Artificial Intelligence, 76**, 35–74.** Dean, T., & Kanazawa, K."@en ;
    askg-onto:inSentence "Artificial Intelligence, 76**, 35–74.** Dean, T., & Kanazawa, K."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-dean_t,
        askg-data:Entity-kanazawa_k,
        askg-data:Entity-paper,
        askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5475 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "(1989)."@en ;
    askg-onto:inSentence "(1989)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-547-Sentence-5476 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "A model for reasoning about persistance and causation."@en ;
    askg-onto:inSentence "A model for reasoning about persistance and causation."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-reasoning_model .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Computational Intelligence, 5**, 142–150.** Drummond, M. (1989). Situated control rules. In **Proc. International Conference on the** Principles of Knowledge Representation and Reasoning (KR)**, pp. 103–113.** Emerson, E. A. (1990). Temporal and modal logic. In **Handbook of Theoretical Computer** Science**, Vol. B, pp. 997–1072. Elsevier and MIT Press.** Feng, Z., & Hansen, E. (2002). Symbolic LAO∗search for factored Markov decision processes. In Proc. American National Conference on Artificial Intelligence (AAAI)**, pp.** 455–460."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5481,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54810,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54811,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54812,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54813,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54814,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54815,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54816,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54817,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5482,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5483,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5484,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5485,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5486,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5487,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5488,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5489 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Computational Intelligence, 5**, 142–150.** Drummond, M."@en ;
    askg-onto:inSentence "Computational Intelligence, 5**, 142–150.** Drummond, M."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computational_intelligence,
        askg-data:Entity-drummond_m .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54810 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "In **Handbook of Theoretical Computer** Science**, Vol."@en ;
    askg-onto:inSentence "In **Handbook of Theoretical Computer** Science**, Vol."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-handbook_of_theoretical_computer_science,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54811 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "B, pp."@en ;
    askg-onto:inSentence "B, pp."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-b .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54812 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "997–1072."@en ;
    askg-onto:inSentence "997–1072."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-9971072,
        askg-data:Entity-period .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54813 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Elsevier and MIT Press.** Feng, Z., & Hansen, E."@en ;
    askg-onto:inSentence "Elsevier and MIT Press.** Feng, Z., & Hansen, E."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-elsevier,
        askg-data:Entity-feng_z,
        askg-data:Entity-hansen_e,
        askg-data:Entity-mit_press,
        askg-data:Entity-paper .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54814 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "(2002)."@en ;
    askg-onto:inSentence "(2002)."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-study .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54815 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Symbolic LAO∗search for factored Markov decision processes."@en ;
    askg-onto:inSentence "Symbolic LAO∗search for factored Markov decision processes."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-factored_markov_decision_processes,
        askg-data:Entity-symbolic_laosearch .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54816 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-54817 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "American National Conference on Artificial Intelligence (AAAI)**, pp.** 455–460."@en ;
    askg-onto:inSentence "American National Conference on Artificial Intelligence (AAAI)**, pp.** 455–460."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-american_national_conference_on_artificial_intelligence_aaai,
        askg-data:Entity-conference,
        askg-data:Entity-pp_455460 .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5482 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(1989)."@en ;
    askg-onto:inSentence "(1989)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research_field .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5483 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Situated control rules."@en ;
    askg-onto:inSentence "Situated control rules."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-situated_control_rules .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5484 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In **Proc."@en ;
    askg-onto:inSentence "In **Proc."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5485 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "International Conference on the** Principles of Knowledge Representation and Reasoning (KR)**, pp."@en ;
    askg-onto:inSentence "International Conference on the** Principles of Knowledge Representation and Reasoning (KR)**, pp."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5486 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "103–113.** Emerson, E."@en ;
    askg-onto:inSentence "103–113.** Emerson, E."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-emerson_e .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5487 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "A."@en ;
    askg-onto:inSentence "A."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiment,
        askg-data:Entity-method .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5488 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "(1990)."@en ;
    askg-onto:inSentence "(1990)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1990,
        askg-data:Entity-year .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-548-Sentence-5489 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Temporal and modal logic."@en ;
    askg-onto:inSentence "Temporal and modal logic."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-modal_logic,
        askg-data:Entity-temporal_logic .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Feng, Z., Hansen, E., & Zilberstein, S. (2003). Symbolic generalization for on-line planning."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549-Sentence-5491,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549-Sentence-5492,
        askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549-Sentence-5493 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549-Sentence-5491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Feng, Z., Hansen, E., & Zilberstein, S."@en ;
    askg-onto:inSentence "Feng, Z., Hansen, E., & Zilberstein, S."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-feng_z,
        askg-data:Entity-hansen_e,
        askg-data:Entity-zilberstein_s .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549-Sentence-5492 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(2003)."@en ;
    askg-onto:inSentence "(2003)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-research .

askg-data:Paper-c253584c3f1ff2a2-Section-54-Paragraph-549-Sentence-5493 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Symbolic generalization for on-line planning."@en ;
    askg-onto:inSentence "Symbolic generalization for on-line planning."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-on-line_planning,
        askg-data:Entity-symbolic_generalization .

askg-data:Paper-c253584c3f1ff2a2-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "1.3 A New Approach"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The first contribution of this paper is to provide a language and a translation adapted to another class of solution methods which have proven quite effective in dealing with large MDPs, namely anytime **state-based heuristic search methods such as LAO* (Hansen &** Zilberstein, 2001), LRTDP (Bonet & Geffner, 2003), and ancestors (Barto, Bardtke, & Singh, 1995; Dean, Kaelbling, Kirman, & Nicholson, 1995; Thi´ebaux, Hertzberg, Shoaff, & Schneider, 1995). These methods typically start with a compact representation of the MDP based on probabilistic planning operators, and search forward from an initial state, constructing new states by expanding the envelope of the policy as time permits. They may produce an approximate and even incomplete policy, but explicitly construct and explore only a fraction of the MDP. Neither of the two previous proposals is well-suited to such solution methods, the first because the cost of the translation (most of which is performed prior to the solution phase) annihilates the benefits of anytime algorithms, and the second because the size of the MDP obtained is an obstacle to the applicability of state-based methods. Since here both the cost of the translation and the size of the MDP it results in will severely impact on the quality of the policy obtainable by the deadline, we need an appropriate resolution of the tradeoff between the two."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-611,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-612,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-613,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-614,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-615 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The first contribution of this paper is to provide a language and a translation adapted to another class of solution methods which have proven quite effective in dealing with large MDPs, namely anytime **state-based heuristic search methods such as LAO* (Hansen &** Zilberstein, 2001), LRTDP (Bonet & Geffner, 2003), and ancestors (Barto, Bardtke, & Singh, 1995; Dean, Kaelbling, Kirman, & Nicholson, 1995; Thi´ebaux, Hertzberg, Shoaff, & Schneider, 1995)."@en ;
    askg-onto:inSentence "The first contribution of this paper is to provide a language and a translation adapted to another class of solution methods which have proven quite effective in dealing with large MDPs, namely anytime **state-based heuristic search methods such as LAO* (Hansen &** Zilberstein, 2001), LRTDP (Bonet & Geffner, 2003), and ancestors (Barto, Bardtke, & Singh, 1995; Dean, Kaelbling, Kirman, & Nicholson, 1995; Thi´ebaux, Hertzberg, Shoaff, & Schneider, 1995)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ancestors,
        askg-data:Entity-author_of_a_paper,
        askg-data:Entity-bardtke,
        askg-data:Entity-barto,
        askg-data:Entity-dean,
        askg-data:Entity-hertzberg,
        askg-data:Entity-kaelbling,
        askg-data:Entity-kirman,
        askg-data:Entity-lao,
        askg-data:Entity-lrtdp,
        askg-data:Entity-nicholson,
        askg-data:Entity-schneider,
        askg-data:Entity-shoaff,
        askg-data:Entity-singh,
        askg-data:Entity-solution_methods,
        askg-data:Entity-state-based_heuristic_search_methods,
        askg-data:Entity-thi%C3%A9baux .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These methods typically start with a compact representation of the MDP based on probabilistic planning operators, and search forward from an initial state, constructing new states by expanding the envelope of the policy as time permits."@en ;
    askg-onto:inSentence "These methods typically start with a compact representation of the MDP based on probabilistic planning operators, and search forward from an initial state, constructing new states by expanding the envelope of the policy as time permits."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_state,
        askg-data:Entity-mdp,
        askg-data:Entity-policy,
        askg-data:Entity-probabilistic_planning_operators,
        askg-data:Entity-search,
        askg-data:Entity-time .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "They may produce an approximate and even incomplete policy, but explicitly construct and explore only a fraction of the MDP."@en ;
    askg-onto:inSentence "They may produce an approximate and even incomplete policy, but explicitly construct and explore only a fraction of the MDP."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fraction,
        askg-data:Entity-mdp .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Neither of the two previous proposals is well-suited to such solution methods, the first because the cost of the translation (most of which is performed prior to the solution phase) annihilates the benefits of anytime algorithms, and the second because the size of the MDP obtained is an obstacle to the applicability of state-based methods."@en ;
    askg-onto:inSentence "Neither of the two previous proposals is well-suited to such solution methods, the first because the cost of the translation (most of which is performed prior to the solution phase) annihilates the benefits of anytime algorithms, and the second because the size of the MDP obtained is an obstacle to the applicability of state-based methods."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_algorithms,
        askg-data:Entity-applicability_of_state-based_methods,
        askg-data:Entity-mdp,
        askg-data:Entity-state-based_methods,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-61-Sentence-615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Since here both the cost of the translation and the size of the MDP it results in will severely impact on the quality of the policy obtainable by the deadline, we need an appropriate resolution of the tradeoff between the two."@en ;
    askg-onto:inSentence "Since here both the cost of the translation and the size of the MDP it results in will severely impact on the quality of the policy obtainable by the deadline, we need an appropriate resolution of the tradeoff between the two."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cost_of_the_translation,
        askg-data:Entity-quality,
        askg-data:Entity-quality_of_the_policy,
        askg-data:Entity-resolution_of_the_tradeoff,
        askg-data:Entity-size_of_the_mdp,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Our approach has the following main features. The translation is entirely embedded in the anytime solution method, to which full control is given as to which parts of the MDP will be explicitly constructed and explored. While the MDP obtained is not minimal, it is of the minimal size achievable without stepping outside of the anytime framework, i.e., without enumerating parts of the state space that the solution method would not necessarily explore. We formalise this relaxed notion of minimality, which we call **blind minimality** in reference to the fact that it does not require any lookahead (beyond the fringe). This is appropriate in the context of anytime state-based solution **methods, where we want the** minimal MDP achievable without expensive pre-processing."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-621,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-622,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-623,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-624,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-625 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our approach has the following main features."@en ;
    askg-onto:inSentence "Our approach has the following main features."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-main_features,
        askg-data:Entity-our_approach .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The translation is entirely embedded in the anytime solution method, to which full control is given as to which parts of the MDP will be explicitly constructed and explored."@en ;
    askg-onto:inSentence "The translation is entirely embedded in the anytime solution method, to which full control is given as to which parts of the MDP will be explicitly constructed and explored."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_solution_method,
        askg-data:Entity-mdp,
        askg-data:Entity-translation .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While the MDP obtained is not minimal, it is of the minimal size achievable without stepping outside of the anytime framework, i.e., without enumerating parts of the state space that the solution method would not necessarily explore."@en ;
    askg-onto:inSentence "While the MDP obtained is not minimal, it is of the minimal size achievable without stepping outside of the anytime framework, i.e., without enumerating parts of the state space that the solution method would not necessarily explore."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anytime_framework,
        askg-data:Entity-framework,
        askg-data:Entity-mdp,
        askg-data:Entity-model .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-624 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We formalise this relaxed notion of minimality, which we call **blind minimality** in reference to the fact that it does not require any lookahead (beyond the fringe)."@en ;
    askg-onto:inSentence "We formalise this relaxed notion of minimality, which we call **blind minimality** in reference to the fact that it does not require any lookahead (beyond the fringe)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-notion_of_minimality .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-62-Sentence-625 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This is appropriate in the context of anytime state-based solution **methods, where we want the** minimal MDP achievable without expensive pre-processing."@en ;
    askg-onto:inSentence "This is appropriate in the context of anytime state-based solution **methods, where we want the** minimal MDP achievable without expensive pre-processing."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-minimal_mdp_achievable_without_expensive_pre-processing,
        askg-data:Entity-state-based_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "When the rewarding behaviours are specified in PLTL, there does not appear to be a way of achieving a relaxed notion of minimality as powerful as blind minimality without a prohibitive translation. Therefore instead of PLTL, we adopt a variant of future **linear** temporal logic (FLTL) as our specification language, which we extend to handle rewards. While the language has a more complex semantics than PLTL, it enables a natural translation into a blind-minimal MDP by simple progression **of the reward formulae. Moreover,** search control knowledge expressed in FLTL (Bacchus & Kabanza, 2000) fits particularly nicely in this framework, and can be used to dramatically reduce the fraction of the search space explored by the solution method."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-631,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-632,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-633,
        askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-634 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "When the rewarding behaviours are specified in PLTL, there does not appear to be a way of achieving a relaxed notion of minimality as powerful as blind minimality without a prohibitive translation."@en ;
    askg-onto:inSentence "When the rewarding behaviours are specified in PLTL, there does not appear to be a way of achieving a relaxed notion of minimality as powerful as blind minimality without a prohibitive translation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-minimality,
        askg-data:Entity-pltl,
        askg-data:Entity-rewarding_behaviours .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Therefore instead of PLTL, we adopt a variant of future **linear** temporal logic (FLTL) as our specification language, which we extend to handle rewards."@en ;
    askg-onto:inSentence "Therefore instead of PLTL, we adopt a variant of future **linear** temporal logic (FLTL) as our specification language, which we extend to handle rewards."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-linear_temporal_logic,
        askg-data:Entity-rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While the language has a more complex semantics than PLTL, it enables a natural translation into a blind-minimal MDP by simple progression **of the reward formulae."@en ;
    askg-onto:inSentence "While the language has a more complex semantics than PLTL, it enables a natural translation into a blind-minimal MDP by simple progression **of the reward formulae."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind-minimal_mdp,
        askg-data:Entity-language,
        askg-data:Entity-pltl,
        askg-data:Entity-reward_formulae .

askg-data:Paper-c253584c3f1ff2a2-Section-6-Paragraph-63-Sentence-634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Moreover,** search control knowledge expressed in FLTL (Bacchus & Kabanza, 2000) fits particularly nicely in this framework, and can be used to dramatically reduce the fraction of the search space explored by the solution method."@en ;
    askg-onto:inSentence "Moreover,** search control knowledge expressed in FLTL (Bacchus & Kabanza, 2000) fits particularly nicely in this framework, and can be used to dramatically reduce the fraction of the search space explored by the solution method."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-search_control_knowledge,
        askg-data:Entity-search_space,
        askg-data:Entity-solution_method,
        askg-data:Entity-this_framework .

askg-data:Paper-c253584c3f1ff2a2-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "1.4 A New System"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72 ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Our second contribution is nmrdpp**, the first reported implementation of NMRDP solution** methods. nmrdpp is designed as a software platform for their development and experimentation under a common interface. Given a description of the actions in a domain, **nmrdpp** lets the user play with and compare various encoding styles for non-Markovian rewards and search control knowledge, various translations of the resulting NMRDP into MDP, and various MDP solution methods. While solving the problem, it **can be made to record a** range of statistics about the space and time behaviour of the **algorithms. It also supports** the graphical display of the MDPs and policies generated."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-711,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-712,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-713,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-714,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-715 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our second contribution is nmrdpp**, the first reported implementation of NMRDP solution** methods."@en ;
    askg-onto:inSentence "Our second contribution is nmrdpp**, the first reported implementation of NMRDP solution** methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdp_solution_methods,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "nmrdpp is designed as a software platform for their development and experimentation under a common interface."@en ;
    askg-onto:inSentence "nmrdpp is designed as a software platform for their development and experimentation under a common interface."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_software_platform,
        askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Given a description of the actions in a domain, **nmrdpp** lets the user play with and compare various encoding styles for non-Markovian rewards and search control knowledge, various translations of the resulting NMRDP into MDP, and various MDP solution methods."@en ;
    askg-onto:inSentence "Given a description of the actions in a domain, **nmrdpp** lets the user play with and compare various encoding styles for non-Markovian rewards and search control knowledge, various translations of the resulting NMRDP into MDP, and various MDP solution methods."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-mdp_solution_methods,
        askg-data:Entity-nmrdp,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-tool .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "While solving the problem, it **can be made to record a** range of statistics about the space and time behaviour of the **algorithms."@en ;
    askg-onto:inSentence "While solving the problem, it **can be made to record a** range of statistics about the space and time behaviour of the **algorithms."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_range_of_statistics_about_the_space_and_time_behaviour,
        askg-data:Entity-algorithms .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-71-Sentence-715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "It also supports** the graphical display of the MDPs and policies generated."@en ;
    askg-onto:inSentence "It also supports** the graphical display of the MDPs and policies generated."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-graphical_display,
        askg-data:Entity-mdps,
        askg-data:Entity-policies .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "While nmrdpp**'s primary interest is in the treatment of non-Markovian rewards, it is** also a competitive platform for decision-theoretic planning with purely Markovian rewards. In the First International Probabilistic Planning Competition, nmrdpp **was able to enrol** in both the domain-independent and hand-coded tracks, attempting all problems featuring in the contest. Thanks to its use of search control-knowledge, it scored a second place in the hand-coded track which featured probabilistic variants of blocks world and logistics problems. More surprisingly, it also scored second in the domain-independent subtrack consisting of all problems that were not **taken from the blocks world and logistic domains. Most** of these latter problems had not been released to the participants prior to the competition."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-721,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-722,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-723,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-724,
        askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-725 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "While nmrdpp**'s primary interest is in the treatment of non-Markovian rewards, it is** also a competitive platform for decision-theoretic planning with purely Markovian rewards."@en ;
    askg-onto:inSentence "While nmrdpp**'s primary interest is in the treatment of non-Markovian rewards, it is** also a competitive platform for decision-theoretic planning with purely Markovian rewards."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-platform,
        askg-data:Entity-purely_markovian_rewards,
        askg-data:Entity-treatment_of_non-markovian_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the First International Probabilistic Planning Competition, nmrdpp **was able to enrol** in both the domain-independent and hand-coded tracks, attempting all problems featuring in the contest."@en ;
    askg-onto:inSentence "In the First International Probabilistic Planning Competition, nmrdpp **was able to enrol** in both the domain-independent and hand-coded tracks, attempting all problems featuring in the contest."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Thanks to its use of search control-knowledge, it scored a second place in the hand-coded track which featured probabilistic variants of blocks world and logistics problems."@en ;
    askg-onto:inSentence "Thanks to its use of search control-knowledge, it scored a second place in the hand-coded track which featured probabilistic variants of blocks world and logistics problems."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hand-coded_track,
        askg-data:Entity-probabilistic_variants_of_blocks_world_and_logistics_problems,
        askg-data:Entity-search_control-knowledge .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "More surprisingly, it also scored second in the domain-independent subtrack consisting of all problems that were not **taken from the blocks world and logistic domains."@en ;
    askg-onto:inSentence "More surprisingly, it also scored second in the domain-independent subtrack consisting of all problems that were not **taken from the blocks world and logistic domains."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blocks_world_and_logistic_domains,
        askg-data:Entity-domain-independent_subtrack,
        askg-data:Entity-problems .

askg-data:Paper-c253584c3f1ff2a2-Section-7-Paragraph-72-Sentence-725 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Most** of these latter problems had not been released to the participants prior to the competition."@en ;
    askg-onto:inSentence "Most** of these latter problems had not been released to the participants prior to the competition."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-participants,
        askg-data:Entity-problems .

askg-data:Paper-c253584c3f1ff2a2-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "1.5 A New Experimental Analysis"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Our third contribution is an experimental analysis of the factors that affect the performance of NMRDP solution methods. Using nmrdpp**, we compared their behaviours under the** influence of parameters such as the structure and degree of uncertainty in the dynamics, the type of rewards and the syntax used to described them, reachability of the conditions tracked, and relevance of rewards to the optimal policy. We were able to identify a number of general trends in the behaviours of the methods and provide advice concerning which are best suited in certain circumstances. Our experiments also lead us to rule out one of the methods as systematically underperforming, and to identify issues with the claim of minimality made by one of the PLTL approaches."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-811,
        askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-812,
        askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-813,
        askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-814 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our third contribution is an experimental analysis of the factors that affect the performance of NMRDP solution methods."@en ;
    askg-onto:inSentence "Our third contribution is an experimental analysis of the factors that affect the performance of NMRDP solution methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-experimental_analysis,
        askg-data:Entity-factors,
        askg-data:Entity-nmrdp_solution_methods .

askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Using nmrdpp**, we compared their behaviours under the** influence of parameters such as the structure and degree of uncertainty in the dynamics, the type of rewards and the syntax used to described them, reachability of the conditions tracked, and relevance of rewards to the optimal policy."@en ;
    askg-onto:inSentence "Using nmrdpp**, we compared their behaviours under the** influence of parameters such as the structure and degree of uncertainty in the dynamics, the type of rewards and the syntax used to described them, reachability of the conditions tracked, and relevance of rewards to the optimal policy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-comparing_behaviours,
        askg-data:Entity-degree_of_uncertainty,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-optimal_policy,
        askg-data:Entity-parameters,
        askg-data:Entity-reachability_of_the_conditions_tracked,
        askg-data:Entity-relevance_of_rewards,
        askg-data:Entity-structure,
        askg-data:Entity-syntax,
        askg-data:Entity-type_of_rewards .

askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We were able to identify a number of general trends in the behaviours of the methods and provide advice concerning which are best suited in certain circumstances."@en ;
    askg-onto:inSentence "We were able to identify a number of general trends in the behaviours of the methods and provide advice concerning which are best suited in certain circumstances."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-trends .

askg-data:Paper-c253584c3f1ff2a2-Section-8-Paragraph-81-Sentence-814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our experiments also lead us to rule out one of the methods as systematically underperforming, and to identify issues with the claim of minimality made by one of the PLTL approaches."@en ;
    askg-onto:inSentence "Our experiments also lead us to rule out one of the methods as systematically underperforming, and to identify issues with the claim of minimality made by one of the PLTL approaches."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-claim_of_minimality,
        askg-data:Entity-one_of_the_methods,
        askg-data:Entity-one_of_the_pltl_approaches,
        askg-data:Entity-systematically_underperforming .

askg-data:Paper-c253584c3f1ff2a2-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "1.6 Organisation Of The Paper"@en ;
    askg-onto:hasParagraph askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The paper is organised as follows. Section 2 begins with background material on MDPs, NMRDPs, and existing approaches. Section 3 describes our new approach and Section 4 presents nmrdpp. Sections 5 and 6 report our experimental analysis of the various approaches. Section 7 explains how we used nmrdpp **in the competition. Section 8 concludes** with remarks about related and future work. Appendix B gives **the proofs of the theorems.** Most of the material presented is compiled from a series of recent conference and workshop papers (Thi´ebaux, Kabanza, & Slaney, 2002a, 2002b; Gretton, Price, & Thi´ebaux, 2003a, 2003b). Details of the logic we use to represent rewards may be found in our 2005 paper (Slaney, 2005)."@en ;
    askg-onto:hasSentence askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-911,
        askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-912,
        askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-913,
        askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-914,
        askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-915,
        askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-916,
        askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-917,
        askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-918 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The paper is organised as follows."@en ;
    askg-onto:inSentence "The paper is organised as follows."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-organized_structure,
        askg-data:Entity-the_paper .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Section 2 begins with background material on MDPs, NMRDPs, and existing approaches."@en ;
    askg-onto:inSentence "Section 2 begins with background material on MDPs, NMRDPs, and existing approaches."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_process,
        askg-data:Entity-existing_approaches,
        askg-data:Entity-mdps,
        askg-data:Entity-nmrdps .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Section 3 describes our new approach and Section 4 presents nmrdpp."@en ;
    askg-onto:inSentence "Section 3 describes our new approach and Section 4 presents nmrdpp."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-new_approach,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-section_3,
        askg-data:Entity-section_4 .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Sections 5 and 6 report our experimental analysis of the various approaches."@en ;
    askg-onto:inSentence "Sections 5 and 6 report our experimental analysis of the various approaches."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experimental_analysis,
        askg-data:Entity-sections_5_and_6 .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-915 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Section 7 explains how we used nmrdpp **in the competition."@en ;
    askg-onto:inSentence "Section 7 explains how we used nmrdpp **in the competition."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdpp,
        askg-data:Entity-the_competition .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-916 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Section 8 concludes** with remarks about related and future work."@en ;
    askg-onto:inSentence "Section 8 concludes** with remarks about related and future work."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-related_and_future_work,
        askg-data:Entity-section_8 .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-917 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Appendix B gives **the proofs of the theorems.** Most of the material presented is compiled from a series of recent conference and workshop papers (Thi´ebaux, Kabanza, & Slaney, 2002a, 2002b; Gretton, Price, & Thi´ebaux, 2003a, 2003b)."@en ;
    askg-onto:inSentence "Appendix B gives **the proofs of the theorems.** Most of the material presented is compiled from a series of recent conference and workshop papers (Thi´ebaux, Kabanza, & Slaney, 2002a, 2002b; Gretton, Price, & Thi´ebaux, 2003a, 2003b)."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appendix_b,
        askg-data:Entity-conference_and_workshop_papers,
        askg-data:Entity-gretton_price__thiebaux,
        askg-data:Entity-the_proofs_of_the_theorems,
        askg-data:Entity-thiebaux_kabanza__slaney .

askg-data:Paper-c253584c3f1ff2a2-Section-9-Paragraph-91-Sentence-918 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Details of the logic we use to represent rewards may be found in our 2005 paper (Slaney, 2005)."@en ;
    askg-onto:inSentence "Details of the logic we use to represent rewards may be found in our 2005 paper (Slaney, 2005)."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2005_paper,
        askg-data:Entity-slaney .

askg-data:Entity-%C2%B5s1 rdfs:label "µ(s'1)"@en,
        "µ(s′1)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%C2%B5s2 rdfs:label "µ(s'2)"@en,
        "µ(s′2)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CE%B3i__b rdfs:label "(Γ(i) ∈ B)"@en,
        "Γ(i) ∈ B**"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-%CE%B3i__bf rdfs:label "Γ(i) ∈ Bf"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B3j rdfs:label "Γ(j)"@en,
        "Γj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%80 rdfs:label "π"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%81 rdfs:label "ρ"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-%CF%84 rdfs:label "τ"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-%CF%84_%CE%B3i rdfs:label "τ ([Γ(i**)])"@en,
        "τ (Γ′i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%84_s_1 rdfs:label "τ (s ′1)"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-%CF%84_s_2 rdfs:label "τ (s ′2)"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-%CF%84s1 rdfs:label "τ(s'1)"@en,
        "τ(s′1)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CF%84s2 rdfs:label "τ(s'2)"@en,
        "τ(s′2)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CF%860 rdfs:label "φ0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%88s rdfs:label "Ψs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-05 rdfs:label "0.5"@en ;
    askg-onto:entityType "Metric"@en,
        "Rate"@en .

askg-data:Entity-10 rdfs:label "1.0"@en,
        "10"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-100 rdfs:label "100"@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-11 rdfs:label "11"@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-1277 rdfs:label "1277"@en ;
    askg-onto:entityType "Measure"@en,
        "Score"@en .

askg-data:Entity-180 rdfs:label "180"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-1990 rdfs:label "1990"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-1995 rdfs:label "1995"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2 rdfs:label "2"@en ;
    askg-onto:entityType "Metric"@en,
        "Score"@en .

askg-data:Entity-20 rdfs:label "20"@en,
        "20%"@en ;
    askg-onto:entityType "Concept"@en,
        "Rate"@en .

askg-data:Entity-2003 rdfs:label "2003"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-4 rdfs:label "4"@en ;
    askg-onto:entityType "Condition"@en,
        "Metric"@en .

askg-data:Entity-495 rdfs:label "495"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-50 rdfs:label "50"@en,
        "50%"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-6 rdfs:label "6"@en ;
    askg-onto:entityType "Measure"@en,
        "Score"@en .

askg-data:Entity-achievable rdfs:label "achievable"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-achievement_of_f rdfs:label "achievement of f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-action_ai rdfs:label "action ai"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ai rdfs:label "AI"@en,
        "ai"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-allocation_of_rewards rdfs:label "allocation of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anytime_algorithms rdfs:label "anytime algorithms"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-anytime_framework rdfs:label "anytime framework"@en ;
    askg-onto:entityType "Concept"@en,
        "Framework"@en .

askg-data:Entity-anytime_solution_methods rdfs:label "anytime solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-approach rdfs:label "approach"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-as rdfs:label "A(s)"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-att_labs-research rdfs:label "AT&T Labs-Research"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-automated_verification rdfs:label "Automated verification"@en,
        "automated verification"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-average_reward rdfs:label "average reward"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-b_g rdfs:label "B g"@en,
        "B g**"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-bacchus rdfs:label "Bacchus"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-backtracking rdfs:label "backtracking"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-badly rdfs:label "badly"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-baral_and_zhao rdfs:label "Baral and Zhao"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-base_case rdfs:label "base case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-behaviour_b rdfs:label "behaviour B"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-blind_minimal_equivalent_mdp rdfs:label "blind minimal equivalent MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-boardedp rdfs:label "BoardedP"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-boardedpi rdfs:label "BoardedPi"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-bonet__geffner_2003 rdfs:label "Bonet & Geffner, 2003"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bonet_b rdfs:label "Bonet, B."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-charles_gretton rdfs:label "Charles Gretton"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cities rdfs:label "Cities"@en,
        "cities"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-command rdfs:label "command"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-command_language rdfs:label "command language"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-compact_representation rdfs:label "compact representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-condition_3 rdfs:label "Condition 3"@en,
        "condition 3"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-conditions rdfs:label "conditions"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-conference_on_uncertainty_in_artificial_intelligence rdfs:label "Conference on Uncertainty in Artificial Intelligence"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-convergence rdfs:label "convergence"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-cpu_time rdfs:label "CPU time"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-crispr rdfs:label "CRISPR"@en ;
    askg-onto:entityType "Method"@en,
        "Tool"@en .

askg-data:Entity-ctl rdfs:label "CTL"@en,
        "CTL*"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cudd rdfs:label "CUDD"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-current_state rdfs:label "current state"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-data_analysis rdfs:label "Data Analysis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-dataset_z rdfs:label "Dataset Z"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-david_price rdfs:label "David Price"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-deadline rdfs:label "deadline"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-decision_diagrams rdfs:label "decision diagrams"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-deep_learning_techniques rdfs:label "Deep Learning Techniques"@en ;
    askg-onto:entityType "Finding"@en,
        "Method"@en .

askg-data:Entity-definition rdfs:label "definition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degree_of_structure rdfs:label "Degree of Structure"@en,
        "degree of structure"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-des rdfs:label "De(s)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain-specific rdfs:label "domain-specific"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-domains rdfs:label "Domains"@en,
        "domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-dynamic_analysis_of_rewards rdfs:label "dynamic analysis of rewards"@en ;
    askg-onto:entityType "Finding"@en,
        "Method"@en .

askg-data:Entity-e%CF%80 rdfs:label "E(π)"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-effort rdfs:label "effort"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-entries rdfs:label "Entries"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-envelope_expansion_algorithm rdfs:label "envelope expansion algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-equivalence_classes rdfs:label "equivalence classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-every_state rdfs:label "every state"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-examples rdfs:label "examples"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-explicit_state_enumeration rdfs:label "explicit state enumeration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f0 rdfs:label "f0"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-f1__f2 rdfs:label "f1 ∧ f2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f1_s_f2 rdfs:label "f1 S f2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f1f2 rdfs:label "{f1,f2,...}"@en,
        "{f1,f2}"@en ;
    askg-onto:entityType "Dataset"@en,
        "Finding"@en .

askg-data:Entity-f3 rdfs:label "f3"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-f__ rdfs:label "f = $"@en,
        "f ∧ ⊤"@en,
        "f ∧ ⊥"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-feng_z rdfs:label "Feng, Z."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-fi rdfs:label "fi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_1 rdfs:label "Figure 1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_12 rdfs:label "Figure 12"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_3 rdfs:label "Figure 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-floor rdfs:label "floor"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl_formulae rdfs:label "FLTL formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl_translation rdfs:label "fltl translation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-forward_search rdfs:label "forward search"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-fraction rdfs:label "fraction"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-froduald_kabanza rdfs:label "Froduald Kabanza"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-g__nc rdfs:label "g ∧ ⊖nc"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geffner_h rdfs:label "Geffner, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gene_editing rdfs:label "Gene Editing"@en,
        "Gene editing"@en,
        "gene editing"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-goal rdfs:label "goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal_g rdfs:label "goal g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal_state rdfs:label "goal state"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-graphviz rdfs:label "Graphviz"@en ;
    askg-onto:entityType "Software"@en,
        "Tool"@en .

askg-data:Entity-gretton_c rdfs:label "Gretton, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-grove_a rdfs:label "Grove, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hamiltonian_circuit rdfs:label "hamiltonian circuit"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hand-coded_track rdfs:label "hand-coded track"@en ;
    askg-onto:entityType "Research Field"@en,
        "System"@en .

askg-data:Entity-hanks_s rdfs:label "Hanks, S."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-hard_miconic rdfs:label "Hard Miconic"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-heuristic_search_algorithm rdfs:label "Heuristic Search Algorithm"@en,
        "heuristic search algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-hf0f1i rdfs:label "hf0,f1,...i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-history_information rdfs:label "history information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hoffmann_j rdfs:label "Hoffmann, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-howard_1960 rdfs:label "Howard, 1960"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-hs0 rdfs:label "hs0"@en ;
    askg-onto:entityType "Concept"@en,
        "Organization"@en .

askg-data:Entity-hypothesis rdfs:label "Hypothesis"@en,
        "hypothesis"@en ;
    askg-onto:entityType "Finding"@en,
        "Theory"@en .

askg-data:Entity-icaps_workshop rdfs:label "ICAPS Workshop"@en,
        "ICAPS workshop"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-image rdfs:label "Image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_classification rdfs:label "Image Classification"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-induction rdfs:label "induction"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-information rdfs:label "information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_e-state rdfs:label "initial e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-issues rdfs:label "issues"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-iterationcount rdfs:label "iterationCount"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-j2 rdfs:label "J2*"@en ;
    askg-onto:entityType "Metric"@en,
        "Paper"@en .

askg-data:Entity-john_slaney rdfs:label "John Slaney"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-k_steps rdfs:label "k steps"@en ;
    askg-onto:entityType "Condition"@en,
        "Metric"@en .

askg-data:Entity-l rdfs:label "L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-linear_temporal_logic rdfs:label "linear temporal logic"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-literals rdfs:label "literals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ltl_action_theories rdfs:label "LTL action theories"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-markov_decision_process rdfs:label "Markov Decision Process"@en,
        "Markov decision process"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-markovian rdfs:label "Markovian"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-mathematics rdfs:label "Mathematics"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-mdp_solution_method rdfs:label "MDP solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mechanisms rdfs:label "mechanisms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mgpt rdfs:label "mGPT"@en,
        "mgpt"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-minimal_mdp rdfs:label "minimal MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-mit_press rdfs:label "MIT Press"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-mtbdd rdfs:label "mtbdd"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-mtl rdfs:label "MTL"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-multiple_rewards rdfs:label "Multiple Rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n__6 rdfs:label "n = 6"@en ;
    askg-onto:entityType "Condition"@en,
        "Metric"@en .

askg-data:Entity-national_ict_australia rdfs:label "National ICT Australia"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-no rdfs:label "no"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-deterministic_domains rdfs:label "non-deterministic domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-non-stop_travel rdfs:label "non-stop travel"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-notion_of_minimality rdfs:label "notion of minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_states_expanded rdfs:label "number of states expanded"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-observation rdfs:label "observation"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-onoff rdfs:label "on/off"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-openai rdfs:label "OpenAI"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-others rdfs:label "others"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-overhead rdfs:label "overhead"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-papers rdfs:label "papers"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-participants rdfs:label "participants"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-person_a rdfs:label "Person A"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pi rdfs:label "Pi"@en,
        "pi"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-pistore_m rdfs:label "Pistore, M."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-planes rdfs:label "planes"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-planning_algorithm rdfs:label "planning algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-planning_for_temporally_extended_goals rdfs:label "planning for temporally extended goals"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-pltl_reward_formula rdfs:label "PLTL reward formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltlsim_mdp rdfs:label "pltlsim MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-pltlstr_translation rdfs:label "pltlstr translation"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-ppddl rdfs:label "PPDDL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pr rdfs:label "Pr"@en,
        "Pr′"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-pre-processing_phase rdfs:label "pre-processing phase"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-predictive_analytics rdfs:label "Predictive Analytics"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-predictive_modeling rdfs:label "Predictive Modeling"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-prefix_%CE%B3i rdfs:label "prefix Γ(i)"@en,
        "prefix Γ(i**)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-preprocessing_phase rdfs:label "preprocessing phase"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-price_d rdfs:label "Price, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-probabilistic_planner rdfs:label "probabilistic planner"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-probabilities rdfs:label "probabilities"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-probability rdfs:label "probability"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-process rdfs:label "process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-progfalsesf rdfs:label "Prog(false,s,f)"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-progressing_it_through_the_successive_states_of_a_sequence_%CE%B3 rdfs:label "progressing it through the successive states of a sequence Γ"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-properties rdfs:label "properties"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-property rdfs:label "Property"@en,
        "property"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-proposition rdfs:label "proposition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposition_pi rdfs:label "proposition pi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposition_pj rdfs:label "proposition pj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prs1%CE%B1s2 rdfs:label "Pr(s1**,α,s**2)"@en,
        "Pr(s1,α,s2)"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-prv rdfs:label "prv"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-q__p_s_q rdfs:label "(⊖¬q) ∧ (p S q)"@en,
        "¬q ∧ (p S q**)"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-question rdfs:label "question"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r%CE%B3i rdfs:label "R([Γ(i)])"@en,
        "R(Γ(i))"@en,
        "R(Γ(i**))"@en,
        "R′(Γ′i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_forest rdfs:label "Random Forest"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en .

askg-data:Entity-random_problems rdfs:label "random problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reader rdfs:label "reader"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-regression rdfs:label "Regression"@en,
        "regression"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-research_field_d rdfs:label "Research Field D"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-research_methods rdfs:label "Research Methods"@en,
        "research methods"@en ;
    askg-onto:entityType "Method"@en,
        "Research Field"@en .

askg-data:Entity-research_on_ai rdfs:label "Research on AI"@en ;
    askg-onto:entityType "Research Area"@en,
        "Research Field"@en .

askg-data:Entity-resp rdfs:label "resp"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-reward-unstable rdfs:label "reward-unstable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-reward_formulae_in_f rdfs:label "reward formulae in F"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_specification rdfs:label "reward specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s1i rdfs:label "s1i"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-search rdfs:label "search"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-section_5 rdfs:label "Section 5"@en,
        "section 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-servedp rdfs:label "ServedP"@en,
        "¬ServedP"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-set rdfs:label "set"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-set_of_finite_sequences_of_states rdfs:label "set of finite sequences of states"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-set_of_states rdfs:label "set of states"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-set_of_subformulae rdfs:label "Set of subformulae"@en,
        "set of subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simple_miconic rdfs:label "Simple Miconic"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-slaney_2005 rdfs:label "Slaney, 2005"@en ;
    askg-onto:entityType "Author"@en,
        "Paper"@en .

askg-data:Entity-software_platform rdfs:label "software platform"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-solution rdfs:label "solution"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-specification rdfs:label "Specification"@en,
        "specification"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-stage_i rdfs:label "stage i"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-stanford_university rdfs:label "Stanford University"@en ;
    askg-onto:entityType "Institution"@en,
        "University"@en .

askg-data:Entity-star-free_regular_languages rdfs:label "star-free regular languages"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-state-based_approaches rdfs:label "state-based approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_translator rdfs:label "state-based translator"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-state_of_the_nmrdp rdfs:label "state of the NMRDP"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-state_s1 rdfs:label "State s'1"@en,
        "state s1"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-stationary_policy rdfs:label "stationary policy"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-statistics rdfs:label "Statistics"@en ;
    askg-onto:entityType "Domain"@en,
        "Theory"@en .

askg-data:Entity-structured_method rdfs:label "structured method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structured_methods rdfs:label "structured methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-subsequent_progression_steps rdfs:label "subsequent progression steps"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-supervisor rdfs:label "supervisor"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-sylvie_thiebaux rdfs:label "Sylvie Thi´ebaux"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-symbolic_rtdp rdfs:label "Symbolic RTDP"@en,
        "symbolic RTDP"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Model"@en .

askg-data:Entity-table_1 rdfs:label "Table 1"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-tables rdfs:label "tables"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-tails rdfs:label "tails"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-temporal_integrity_constraints rdfs:label "temporal integrity constraints"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-temporal_modalities rdfs:label "temporal modalities"@en,
        "temporal modalities**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_competition rdfs:label "the competition"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-the_following rdfs:label "the following"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_paper rdfs:label "The paper"@en,
        "the paper"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-the_problem rdfs:label "the problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-they rdfs:label "they"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-time rdfs:label "time"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-translations rdfs:label "translations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-traverso_p rdfs:label "Traverso, P."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-trigger rdfs:label "trigger"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-triple_5 rdfs:label "triple 5"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-university_f rdfs:label "University F"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-up rdfs:label "($U¬p)"@en,
        "U¬p"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-v_%0Apis_0 rdfs:label """V_{
\\pi}(s_{0})"""@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-value_or_policy_iteration rdfs:label "value or policy iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-value_r rdfs:label "value r"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-vardi_m rdfs:label "Vardi, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-variables rdfs:label "variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-version rdfs:label "Version"@en,
        "version"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-younes__littman_2004 rdfs:label "Younes & Littman, 2004"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-zilberstein_s rdfs:label "Zilberstein, S."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-%CE%B3i__1 rdfs:label "(Γ,i + 1)"@en,
        "Γ(i − 1)"@en,
        "Γ,i **+ 1**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CF%80-ctl rdfs:label "π**-CTL*"@en,
        "π-CTL"@en ;
    askg-onto:entityType "Concept"@en,
        "Framework"@en .

askg-data:Entity--free_formulae rdfs:label "$-free formulae"@en,
        "-free formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1996 rdfs:label "(1996)"@en,
        "1996"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-1998 rdfs:label "1998"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2001 rdfs:label "2001"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2002 rdfs:label "(2002)"@en,
        "2002"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-2005 rdfs:label "2005"@en ;
    askg-onto:entityType "Concept"@en,
        "Paper"@en,
        "Publication"@en .

askg-data:Entity-algorithms rdfs:label "Algorithms"@en,
        "algorithms"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-american_national_conference_on_artificial_intelligence_aaai rdfs:label "American National Conference on Artificial Intelligence (AAAI)"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-anytime_state-based_solution_methods rdfs:label "anytime state-based solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-automata rdfs:label "automata"@en ;
    askg-onto:entityType "Domain"@en,
        "System"@en,
        "Theory"@en .

askg-data:Entity-bacchus_et_al_1996 rdfs:label "Bacchus et al., 1996"@en ;
    askg-onto:entityType "Paper"@en .

askg-data:Entity-bdd rdfs:label "BDD"@en ;
    askg-onto:entityType "Model"@en,
        "System"@en .

askg-data:Entity-blind-minimal_mdp rdfs:label "blind-minimal MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-blocks_world rdfs:label "Blocks world"@en,
        "blocks world"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-coin rdfs:label "coin"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-covid-19 rdfs:label "COVID-19"@en ;
    askg-onto:entityType "Concept"@en,
        "Disease"@en .

askg-data:Entity-data rdfs:label "Data"@en,
        "data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-dc rdfs:label "Dc"@en ;
    askg-onto:entityType "Dataset"@en,
        "Model"@en .

askg-data:Entity-dean_t rdfs:label "Dean, T."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-decision_process rdfs:label "Decision Process"@en,
        "decision process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_processes rdfs:label "decision processes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degree_of_uncertainty rdfs:label "Degree of Uncertainty"@en,
        "degree of uncertainty"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-disease rdfs:label "Disease"@en ;
    askg-onto:entityType "Concept"@en,
        "Disease"@en .

askg-data:Entity-domain-specific_planners rdfs:label "Domain-specific planners"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-domain-specific_search_control_knowledge rdfs:label "domain-specific search control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eagle rdfs:label "Eagle"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-effects rdfs:label "effects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eventualities rdfs:label "eventualities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-every_e-state_in_s__is_reachable rdfs:label "every e-state in S ′ is reachable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-ff rdfs:label "ff"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-field rdfs:label "Field"@en,
        "field"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-fltl_formula rdfs:label "FLTL formula"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Model"@en .

askg-data:Entity-formula_progression rdfs:label "formula progression"@en ;
    askg-onto:entityType "Concept"@en,
        "Technique"@en .

askg-data:Entity-framework rdfs:label "Framework"@en,
        "framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-function rdfs:label "Function"@en,
        "function"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-future_states rdfs:label "future states"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-g1 rdfs:label "G1"@en,
        "g1"@en ;
    askg-onto:entityType "Condition"@en,
        "Metric"@en .

askg-data:Entity-g2 rdfs:label "G2*"@en,
        "g2"@en ;
    askg-onto:entityType "Condition"@en,
        "Metric"@en,
        "Paper"@en .

askg-data:Entity-g__h rdfs:label "g ∧ h"@en,
        "g ∨ h"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goals rdfs:label "goals"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-hansen_e rdfs:label "Hansen, E."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-heads rdfs:label "heads"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-healthcare rdfs:label "Healthcare"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-history rdfs:label "history"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hs%CF%86i rdfs:label "hs,φi"@en,
        "hs,φi**"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-j1 rdfs:label "J1"@en,
        "J1*"@en ;
    askg-onto:entityType "Metric"@en,
        "Paper"@en .

askg-data:Entity-j3 rdfs:label "J3"@en ;
    askg-onto:entityType "Metric"@en,
        "Paper"@en,
        "Person"@en .

askg-data:Entity-john_doe rdfs:label "John Doe"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lrtdp rdfs:label "(L)RTDP"@en,
        "LRTDP"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-mdp_size rdfs:label "MDP Size"@en,
        "MDP size"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-medical_imaging rdfs:label "Medical Imaging"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-memory rdfs:label "memory"@en ;
    askg-onto:entityType "Condition"@en,
        "Metric"@en .

askg-data:Entity-minimality rdfs:label "minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-model-checking rdfs:label "Model-checking"@en,
        "model-checking"@en ;
    askg-onto:entityType "Method"@en,
        "Research Field"@en .

askg-data:Entity-nmrdp_solution_methods rdfs:label "NMRDP solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-number_of_expanded_states rdfs:label "Number of Expanded States"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-our_approach rdfs:label "Our approach"@en,
        "our approach"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-pddl rdfs:label "PDDL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_approaches rdfs:label "PLTL approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-prefixes rdfs:label "prefixes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-problem rdfs:label "problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-progb_%CE%B3if rdfs:label "Prog(b, Γi,f)"@en,
        "Prog(b, Γi,f**)"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-progression rdfs:label "progression"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-progsf rdfs:label "$Prog(s,f)"@en,
        "Prog(s,f)"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en .

askg-data:Entity-proof rdfs:label "Proof"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Theory"@en .

askg-data:Entity-prs1as2 rdfs:label "Pr(s1**,a,s**2)"@en,
        "Pr(s1,a,s2)"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-representations rdfs:label "representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_concept rdfs:label "Research Concept"@en,
        "research concept"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-result rdfs:label "result"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-rew rdfs:label "Rew"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Person"@en .

askg-data:Entity-rew%CE%B3ifi rdfs:label "Rew(Γi,fi)"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-reward-based_problems rdfs:label "Reward-Based Problems"@en,
        "reward-based problems"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-reward-normality rdfs:label "reward-normality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_type rdfs:label "Reward Type"@en,
        "reward type"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewsf rdfs:label "Rew(s,f)"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-run_time rdfs:label "Run Time"@en,
        "run time"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-s_%CF%89 rdfs:label "S ω"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-s_1 rdfs:label "s ′1"@en,
        "s_1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence rdfs:label "sequence"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Finding"@en .

askg-data:Entity-servedpi rdfs:label "ServedPi"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-statistical_methods rdfs:label "Statistical Methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-strategy rdfs:label "Strategy"@en,
        "strategy"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-support_vector_machines rdfs:label "Support Vector Machines"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en .

askg-data:Entity-syntax rdfs:label "syntax"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theorem_1 rdfs:label "Theorem 1"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-theorem_proving rdfs:label "theorem proving"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-this rdfs:label "this"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tlplan rdfs:label "TLPlan"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-triple_3 rdfs:label "triple 3"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Tool"@en .

askg-data:Entity-truck rdfs:label "truck"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-trucks rdfs:label "trucks"@en ;
    askg-onto:entityType "System"@en,
        "Tool"@en .

askg-data:Entity-true_minimality rdfs:label "true minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-year rdfs:label "Year"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-younes_h rdfs:label "Younes, H."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-1996_1997 rdfs:label "(1996, 1997)"@en,
        "1996, 1997"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-2000 rdfs:label "2000"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-a%CE%B3i rdfs:label "A([Γ(i)])"@en,
        "A(Γ(i))"@en,
        "A(Γi)"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Method"@en .

askg-data:Entity-action rdfs:label "action"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-adds rdfs:label "ADDs"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-algorithm_1 rdfs:label "Algorithm 1"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-analysis rdfs:label "analysis"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Study"@en .

askg-data:Entity-b_f rdfs:label "B f"@en,
        "B f**"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-bacchus__kabanza rdfs:label "Bacchus & Kabanza"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-bacchus_f rdfs:label "Bacchus, F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-behaviour rdfs:label "behaviour"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-boutilier_c rdfs:label "Boutilier, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-competition rdfs:label "competition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computer_science rdfs:label "Computer Science"@en ;
    askg-onto:entityType "Domain"@en,
        "Research Field"@en .

askg-data:Entity-dynamic_programming rdfs:label "Dynamic Programming"@en,
        "dynamic programming"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-elevator rdfs:label "elevator"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-equivalent_mdp rdfs:label "Equivalent MDP"@en,
        "equivalent MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-existing_approaches rdfs:label "Existing approaches"@en,
        "existing approaches"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-feng__hansen_2002 rdfs:label "Feng & Hansen, 2002"@en ;
    askg-onto:entityType "Author"@en,
        "Paper"@en .

askg-data:Entity-fltl_progression rdfs:label "$FLTL progression"@en,
        "FLTL Progression"@en,
        "FLTL progression"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-formula_f rdfs:label "formula f"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fringe_states rdfs:label "fringe states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal-based_problems rdfs:label "goal-based problems"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-h rdfs:label "h"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-heuristic rdfs:label "Heuristic"@en,
        "heuristic"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Method"@en .

askg-data:Entity-hoey_et_al rdfs:label "Hoey et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-i rdfs:label "i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_recognition rdfs:label "Image Recognition"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Research Field"@en .

askg-data:Entity-imagenet rdfs:label "ImageNet"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-j rdfs:label "j"@en,
        "∆(j)"@en,
        "∆j"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-language rdfs:label "language"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-mdp_d rdfs:label "MDP D"@en,
        "MDP D'"@en,
        "MDP D′"@en,
        "MDP D′′"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-modelling_relation rdfs:label "modelling relation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-markovian_reward_function rdfs:label "non-Markovian reward function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-markovian_reward_functions rdfs:label "Non-Markovian reward functions"@en,
        "non-Markovian reward functions"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-p__ rdfs:label "(p → $)"@en,
        "p → $"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-passenger rdfs:label "Passenger"@en,
        "passenger"@en ;
    askg-onto:entityType "Condition"@en,
        "Person"@en .

askg-data:Entity-planner rdfs:label "planner"@en ;
    askg-onto:entityType "Person"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-planners rdfs:label "Planners"@en,
        "planners"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en,
        "Research Group"@en .

askg-data:Entity-preprocessing rdfs:label "preprocessing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-ptsubf rdfs:label "PTSub(F)"@en,
        "PTSub(F**)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pytorch rdfs:label "PyTorch"@en ;
    askg-onto:entityType "Software"@en,
        "Tool"@en .

askg-data:Entity-research_group rdfs:label "Research Group"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-research_paper rdfs:label "Research Paper"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-reward-normal rdfs:label "reward-normal"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-s_0 rdfs:label "s ′0"@en,
        "s_0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-slaney_j rdfs:label "Slaney, J."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-spudd-linear rdfs:label "spudd-linear"@en ;
    askg-onto:entityType "Domain"@en,
        "Model"@en,
        "Tool"@en .

askg-data:Entity-state-based_methods rdfs:label "state-based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_solution_methods rdfs:label "state-based solution methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-structure rdfs:label "structure"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-symbolic_lao rdfs:label "Symbolic LAO*"@en,
        "symbolic LAO*"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Model"@en .

askg-data:Entity-temporal_variables rdfs:label "temporal variables"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-triple_4 rdfs:label "triple 4"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Research Field"@en,
        "Result"@en .

askg-data:Entity-yes rdfs:label "yes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%CE%B31i rdfs:label "Γ1(i)"@en,
        "Γ1i"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-%CE%B32j rdfs:label "Γ2(j)"@en,
        "Γ2(j**)"@en,
        "Γ2j"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-1997 rdfs:label "(1997)"@en,
        "1997"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-1999 rdfs:label "1999"@en ;
    askg-onto:entityType "Domain"@en,
        "Paper"@en,
        "Publication"@en .

askg-data:Entity-approaches rdfs:label "approaches"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-company rdfs:label "Company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-computer_vision rdfs:label "Computer Vision"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-des0 rdfs:label "De(s0)"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Domain"@en .

askg-data:Entity-dynamics rdfs:label "dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expansion rdfs:label "Expansion"@en,
        "expansion"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Method"@en .

askg-data:Entity-experimental_analysis rdfs:label "experimental analysis"@en ;
    askg-onto:entityType "Experiment"@en,
        "Finding"@en,
        "Study"@en .

askg-data:Entity-f1 rdfs:label "f1"@en,
        "{f1}"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Finding"@en .

askg-data:Entity-journal_of_artificial_intelligence_research rdfs:label "Journal of Artificial Intelligence Research"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-kabanza_f rdfs:label "Kabanza, F."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-mdp_solution_methods rdfs:label "MDP solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-metric rdfs:label "Metric"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-minimal_equivalent_mdp rdfs:label "minimal equivalent MDP"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-pp rdfs:label "pp"@en,
        "pp."@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-propositions rdfs:label "propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regfs rdfs:label "Reg(f,s)"@en,
        "Reg(f,s**)"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-reward-normal_formulae rdfs:label "reward-normal formulae"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-reward_function rdfs:label "reward function"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-spudd-expon rdfs:label "spudd-expon"@en ;
    askg-onto:entityType "Dataset"@en,
        "Domain"@en,
        "Tool"@en .

askg-data:Entity-state_s rdfs:label "state s"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-subf rdfs:label "Sub(F)"@en,
        "Sub(F**)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_logic rdfs:label "Temporal Logic"@en,
        "temporal logic"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-temporally_extended_goals rdfs:label "temporally extended goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-theory rdfs:label "Theory"@en,
        "theory"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-true rdfs:label "true"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-value_iteration rdfs:label "value iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-x rdfs:label "X"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Finding"@en .

askg-data:Entity-actions rdfs:label "actions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-control_knowledge rdfs:label "Control knowledge"@en,
        "control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolutional_neural_networks rdfs:label "Convolutional Neural Networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-data_science rdfs:label "Data Science"@en ;
    askg-onto:entityType "Domain"@en,
        "Research Area"@en,
        "Research Field"@en .

askg-data:Entity-e rdfs:label "E"@en,
        "E*"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Domain"@en,
        "Metric"@en,
        "Paper"@en .

askg-data:Entity-execution_sequences rdfs:label "execution sequences"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-experiments rdfs:label "Experiments"@en,
        "experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-f2 rdfs:label "f2"@en,
        "⊖f2"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Finding"@en .

askg-data:Entity-heuristic_search rdfs:label "heuristic search"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-initial_state rdfs:label "initial state"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-miconic rdfs:label "Miconic"@en ;
    askg-onto:entityType "Company"@en,
        "Concept"@en,
        "Model"@en,
        "System"@en .

askg-data:Entity-performance rdfs:label "performance"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-policy_iteration rdfs:label "policy iteration"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-research_area rdfs:label "Research Area"@en ;
    askg-onto:entityType "Research Area"@en,
        "Research Field"@en .

askg-data:Entity-s2 rdfs:label "s'2"@en,
        "s2"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Domain"@en .

askg-data:Entity-spudd rdfs:label "SPUDD"@en ;
    askg-onto:entityType "Method"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-state_space rdfs:label "state space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subformulae rdfs:label "subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-university rdfs:label "University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-0 rdfs:label "0"@en,
        "∆0"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en,
        "Score"@en .

askg-data:Entity-decision-theoretic_planning rdfs:label "Decision-theoretic planning"@en,
        "decision-theoretic planning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Research Field"@en .

askg-data:Entity-methods rdfs:label "methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pltlstra rdfs:label "pltlstr(a)"@en,
        "pltlstr**(A)"@en ;
    askg-onto:entityType "Method"@en,
        "Model"@en,
        "Tool"@en .

askg-data:Entity-policies rdfs:label "policies"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Model"@en,
        "Result"@en .

askg-data:Entity-s1 rdfs:label "(s'1)"@en,
        "s'1"@en,
        "s1"@en,
        "s1**"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Domain"@en .

askg-data:Entity-state rdfs:label "state"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Domain"@en .

askg-data:Entity-states rdfs:label "states"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Domain"@en,
        "Metric"@en .

askg-data:Entity-thiebaux_s rdfs:label "Thi´ebaux, S."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-uncertainty rdfs:label "Uncertainty"@en,
        "uncertainty"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en .

askg-data:Entity-%CF%86 rdfs:label "φ"@en,
        "φ'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bf rdfs:label "Bf"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "System"@en .

askg-data:Entity-c rdfs:label "C"@en,
        "C++"@en,
        "C."@en,
        "c"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Condition"@en,
        "Metric"@en,
        "Paper"@en,
        "Software"@en .

askg-data:Entity-lao rdfs:label "LAO*"@en,
        "LAO∗"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-m rdfs:label "M"@en,
        "m"@en,
        "≈M"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-mdps rdfs:label "MDPs"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Model"@en .

askg-data:Entity-natural_language_processing rdfs:label "Natural Language Processing"@en ;
    askg-onto:entityType "Domain"@en,
        "Method"@en,
        "Research Field"@en .

askg-data:Entity-organization rdfs:label "Organization"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-planning rdfs:label "Planning"@en,
        "planning"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Research Field"@en .

askg-data:Entity-problems rdfs:label "problems"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-response_formula rdfs:label "Response Formula"@en,
        "response formula"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-reward_function_specification rdfs:label "reward function specification"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-search_control_knowledge rdfs:label "search control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-software rdfs:label "Software"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-solution_method rdfs:label "solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structured_solution_methods rdfs:label "Structured solution methods"@en,
        "structured solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-t rdfs:label "T"@en,
        "T∅"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-tensorflow rdfs:label "TensorFlow"@en ;
    askg-onto:entityType "Software"@en,
        "Tool"@en .

askg-data:Entity-blind_minimality rdfs:label "Blind minimality"@en,
        "blind minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_networks rdfs:label "Neural Networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-optimal_policy rdfs:label "optimal policy"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-passengers rdfs:label "passengers"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-reward_formula rdfs:label "reward formula"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-s_ rdfs:label "S ′"@en,
        "S ∗"@en,
        "s ′"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-false rdfs:label "false"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en .

askg-data:Entity-formula rdfs:label "Formula"@en,
        "formula"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-prog rdfs:label "$Prog"@en,
        "Prog"@en,
        "Prog**"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-reward_formulae rdfs:label "reward formulae"@en,
        "reward** formulae"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-s0 rdfs:label "s0"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Domain"@en,
        "Metric"@en,
        "Model"@en .

askg-data:Entity-translation rdfs:label "Translation"@en,
        "translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a rdfs:label "$a$"@en,
        "A"@en,
        "A'"@en,
        "a"@en,
        "a'"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Domain"@en .

askg-data:Entity-condition rdfs:label "Condition"@en,
        "condition"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-finding rdfs:label "Finding"@en,
        "finding"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-person rdfs:label "Person"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-research rdfs:label "Research"@en,
        "research"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en,
        "Study"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-non-markovian_rewards rdfs:label "non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en .

askg-data:Entity-policy rdfs:label "Policy"@en,
        "policy"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Theory"@en .

askg-data:Entity-r rdfs:label "R"@en,
        "R**"@en,
        "r"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-algorithm rdfs:label "Algorithm"@en,
        "algorithm"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-behaviours rdfs:label "behaviours"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-formulae rdfs:label "formulae"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-g rdfs:label "G."@en,
        "g"@en,
        "g'"@en,
        "¬g"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en,
        "Model"@en,
        "Person"@en .

askg-data:Entity-b rdfs:label "B"@en,
        "B'"@en,
        "B′"@en,
        "b"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Condition"@en,
        "Model"@en .

askg-data:Entity-domain rdfs:label "Domain"@en,
        "domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-e-state rdfs:label "e-state"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Domain"@en .

askg-data:Entity-nmrdps rdfs:label "NMRDPs"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Model"@en .

askg-data:Entity-q rdfs:label "Q"@en,
        "q"@en,
        "¬q"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en .

askg-data:Entity-solution_methods rdfs:label "solution methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-study rdfs:label "Study"@en,
        "study"@en ;
    askg-onto:entityType "Concept"@en,
        "Study"@en .

askg-data:Entity-system rdfs:label "System"@en,
        "system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-experiment rdfs:label "Experiment"@en,
        "experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-pltlsim rdfs:label "pltlsim"@en,
        "pltlsim**"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en,
        "Model"@en,
        "Tool"@en .

askg-data:Entity-triple rdfs:label "triple"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Method"@en,
        "Model"@en,
        "Research Field"@en,
        "Study"@en,
        "Technology"@en,
        "Theory"@en .

askg-data:Entity-bacchus_et_al rdfs:label "Bacchus et al."@en ;
    askg-onto:entityType "Author"@en,
        "Paper"@en,
        "Person"@en,
        "Research Group"@en .

askg-data:Entity-conference rdfs:label "Conference"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Research Field"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-pltl rdfs:label "PLTL"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en,
        "Research Field"@en,
        "Theory"@en .

askg-data:Entity-rewards rdfs:label "rewards"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Metric"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Method"@en,
        "Model"@en,
        "Research Area"@en,
        "Research Field"@en .

askg-data:Entity-concept rdfs:label "Concept"@en,
        "concept"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Research Field"@en,
        "Theory"@en .

askg-data:Entity-d rdfs:label "D"@en,
        "D'"@en,
        "D**"@en,
        "D′"@en,
        "D′′"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en,
        "Domain"@en,
        "Model"@en .

askg-data:Entity-s rdfs:label "S"@en,
        "S'"@en,
        "S*"@en,
        "S."@en,
        "S′"@en,
        "S∗"@en,
        "s"@en,
        "s'"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Condition"@en,
        "Domain"@en,
        "Metric"@en,
        "Person"@en,
        "Research Field"@en .

askg-data:Entity-tool rdfs:label "Tool"@en,
        "tool"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-author rdfs:label "Author"@en,
        "author"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en .

askg-data:Entity-%CE%B3 rdfs:label "Γ"@en,
        "Γ**"@en,
        "Γ′"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Paper"@en,
        "Publication"@en,
        "Research Field"@en,
        "Technology"@en .

askg-data:Entity-%CE%B3i rdfs:label "(Γ,i)"@en,
        "[Γ(i)]"@en,
        "Γ(i)"@en,
        "Γ(i**)"@en,
        "Γ**i"@en,
        "Γi"@en,
        "Γi**"@en,
        "Γ′(i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e-states rdfs:label "e-states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltlmin rdfs:label "pltlmin"@en,
        "pltlmin**"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-p rdfs:label "P"@en,
        "p"@en,
        "¬p"@en,
        "¬⊖p"@en,
        "¬⊖⊖p"@en,
        "⊖p"@en,
        "⊖⊖p"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Dataset"@en,
        "Metric"@en,
        "Paper"@en .

askg-data:Entity-nmrdp rdfs:label "NMRDP"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "System"@en,
        "Theory"@en .

askg-data:Entity-proc rdfs:label "Proc."@en ;
    askg-onto:entityType "Concept"@en,
        "Paper"@en,
        "Publication"@en .

askg-data:Entity-pltlstr rdfs:label "pltlstr"@en,
        "pltlstr**"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en,
        "Tool"@en .

askg-data:Entity-reward rdfs:label "Reward"@en,
        "reward"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en,
        "Result"@en .

askg-data:Entity-research_field rdfs:label "Research Field"@en,
        "research field"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity- rdfs:label "$"@en,
        "'$'"@en,
        "?"@en,
        "¬$"@en,
        "∆"@en,
        "≡"@en,
        "⊖"@en,
        "⊟"@en,
        "⊤"@en,
        "⊥"@en,
        "⊥**"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Domain"@en,
        "Metric"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-model rdfs:label "Model"@en,
        "model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "System"@en .

askg-data:Entity-nmrdpp rdfs:label "NMRDPP"@en,
        "nmrdpp"@en,
        "nmrdpp**"@en ;
    askg-onto:entityType "Framework"@en,
        "Model"@en,
        "Software"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-paper rdfs:label "Paper"@en ;
    askg-onto:entityType "Concept"@en,
        "Paper"@en,
        "Publication"@en .

askg-data:Entity-fltl rdfs:label "$FLTL"@en,
        "FLTL"@en,
        "fltl"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Domain"@en,
        "Method"@en,
        "Model"@en,
        "System"@en,
        "Technique"@en,
        "Theory"@en,
        "Tool"@en .

askg-data:Entity-f rdfs:label "F"@en,
        "f"@en,
        "f**"@en,
        "||F||"@en,
        "¬f"@en,
        "⊖f"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en,
        "Metric"@en,
        "Model"@en .

askg-data:Entity-publication rdfs:label "Publication"@en,
        "publication"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-mdp rdfs:label "MDP"@en,
        "mdp"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en,
        "Method"@en,
        "Model"@en .

