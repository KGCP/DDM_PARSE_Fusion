@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-305358d7d24f2bf4 a askg-onto:Paper ;
    rdfs:label "305358d7d24f2bf4"@en ;
    dc:title "305358d7d24f2bf4"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-305358d7d24f2bf4-Section-1,
        askg-data:Paper-305358d7d24f2bf4-Section-10,
        askg-data:Paper-305358d7d24f2bf4-Section-11,
        askg-data:Paper-305358d7d24f2bf4-Section-12,
        askg-data:Paper-305358d7d24f2bf4-Section-13,
        askg-data:Paper-305358d7d24f2bf4-Section-14,
        askg-data:Paper-305358d7d24f2bf4-Section-15,
        askg-data:Paper-305358d7d24f2bf4-Section-16,
        askg-data:Paper-305358d7d24f2bf4-Section-17,
        askg-data:Paper-305358d7d24f2bf4-Section-18,
        askg-data:Paper-305358d7d24f2bf4-Section-19,
        askg-data:Paper-305358d7d24f2bf4-Section-2,
        askg-data:Paper-305358d7d24f2bf4-Section-20,
        askg-data:Paper-305358d7d24f2bf4-Section-21,
        askg-data:Paper-305358d7d24f2bf4-Section-22,
        askg-data:Paper-305358d7d24f2bf4-Section-3,
        askg-data:Paper-305358d7d24f2bf4-Section-4,
        askg-data:Paper-305358d7d24f2bf4-Section-5,
        askg-data:Paper-305358d7d24f2bf4-Section-6,
        askg-data:Paper-305358d7d24f2bf4-Section-7,
        askg-data:Paper-305358d7d24f2bf4-Section-8,
        askg-data:Paper-305358d7d24f2bf4-Section-9 .

askg-data:Entity-%09exteqwalpha rdfs:label "$	ext{eq:walpha}$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09exti_jt%09extbfx_it rdfs:label "$	ext{I}_{j}^{t}(	extbf{x}_{i}^{t})$"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-%09extit%09extbfx_it rdfs:label "${	ext{I}}^{t}(	extbf{x}_{i}^{t})$"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-%09extm_jt%09extbfx_it rdfs:label "$	ext{M}_{j}^{t}(	extbf{x}_{i}^{t})$"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-%CE%B21__09_and_%CE%B22__0999 rdfs:label "β1 = 0.9 and β2 = 0.999"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-%CF%89 rdfs:label "Ω"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0 rdfs:label "0*"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-001 rdfs:label "0.01"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-0159 rdfs:label "0.159"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0167 rdfs:label "0.167"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0174 rdfs:label "0.174"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0184 rdfs:label "0.184"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0329 rdfs:label "0.329"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0345 rdfs:label "0.345"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0357 rdfs:label "0.357"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0373 rdfs:label "0.373"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0471 rdfs:label "0.471"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-0668 rdfs:label "0.668"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-1 rdfs:label "1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1-kitti rdfs:label "1-KITTI"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-1-scannet rdfs:label "1-ScanNet"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-10 rdfs:label "10"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-11 rdfs:label "11"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-12 rdfs:label "12"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-13 rdfs:label "13"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-16gb rdfs:label "16GB"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-1995 rdfs:label "1995"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1997 rdfs:label "1997"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_13 rdfs:label "1, 2 [13]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_14 rdfs:label "1, 2 [14]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_19 rdfs:label "1, 2 [19]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_25 rdfs:label "1, 2 [25]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_3 rdfs:label "1, 2 [3]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_3_5_6_21 rdfs:label "1, 2, 3, 5, 6 [21]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1_2_6_7_10_12_13_30 rdfs:label "1, 2, 6, 7, 10, 12, 13 [30]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1_2_7 rdfs:label "1, 2 [7]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1__v_ta1u rdfs:label "1 + v TA−1u"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2005 rdfs:label "2005"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-2007 rdfs:label "2007"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2013 rdfs:label "2013"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-24 rdfs:label "24"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-28 rdfs:label "28"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-29 rdfs:label "[29]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2_16 rdfs:label "2 [16]"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-2_17 rdfs:label "2 [17]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2d-to-3d_video_conversion rdfs:label "2d-to-3d video conversion"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-30 rdfs:label "30"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-30000_training_pairs rdfs:label "30000 training pairs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-32 rdfs:label "32"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-3_8_29 rdfs:label "3, 8 [29]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-3_8_9_a rdfs:label "3, 8 [9] A"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-3d_geometric_prior rdfs:label "3D geometric prior"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3d_model rdfs:label "3D model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-3d_object_shape rdfs:label "3D object shape"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3d_point rdfs:label "3D point"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3d_rotation_and_translation rdfs:label "3D rotation and translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3d_rotation_translation_and_camera_intrinsics rdfs:label "3D rotation, translation and camera intrinsics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3d_scene_model rdfs:label "3D scene model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-3d_video_stabilization rdfs:label "3d video stabilization"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-3d_view_synthesis rdfs:label "3d view synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-4-pixel_neighborhood rdfs:label "4-pixel neighborhood"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-44 rdfs:label "44"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-5 rdfs:label "5"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-5000_test_pairs rdfs:label "5000 test pairs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-577584 rdfs:label "577–584"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-5_12 rdfs:label "5 [12]"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-5_15 rdfs:label "5 [15]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-5_22 rdfs:label "5 [22]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-5_6_2 rdfs:label "5, 6 [2]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-6 rdfs:label "6"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-6_10 rdfs:label "6 [10]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-6_20 rdfs:label "6 [20]"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-6_28 rdfs:label "6 [28]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-8_11 rdfs:label "8 [11]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-a__uvt rdfs:label "A + uvT"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_broader_range_of_problems rdfs:label "a broader range of problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_concept_in_projective_geometry rdfs:label "a concept in projective geometry"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-a_model_for_predicting_new_views_from_imagery rdfs:label "a model for predicting new views from imagery"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_researcher rdfs:label "a researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-a_single_image rdfs:label "a single image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_type_of rdfs:label "a type of"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-achanta_a rdfs:label "Achanta, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-acm rdfs:label "ACM"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-acm_pressaddison-wesley_publishing_co rdfs:label "ACM Press/Addison-Wesley Publishing Co."@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-acm_transactions_on_graphics_tog rdfs:label "ACM transactions on graphics (TOG)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-adam_solver rdfs:label "ADAM solver"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-additional_results rdfs:label "additional results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-adversarial_training rdfs:label "Adversarial Training"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-agarwala rdfs:label "Agarwala"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-alexnet rdfs:label "AlexNet"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-all_its_pixels rdfs:label "all its pixels"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-an_illustration rdfs:label "an illustration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-anjyo rdfs:label "Anjyo"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-any_significant_improvement rdfs:label "any significant improvement"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-appearance rdfs:label "appearance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-appearance_variations rdfs:label "appearance variations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approximate_representation_of_the_3d_scene_structure rdfs:label "approximate representation of the 3D scene structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arai rdfs:label "Arai"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-arbelaez_r rdfs:label "Arbelaez, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-architectures rdfs:label "architectures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-area rdfs:label "Area"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-arxiv14091556 rdfs:label "arXiv:1409.1556"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv160200328 rdfs:label "arXiv:1602.00328"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv160903677 rdfs:label "arXiv:1609.03677"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-arxiv170407813 rdfs:label "arXiv:1704.07813"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-arxiv_preprint_arxiv170407813 rdfs:label "arXiv preprint arXiv:1704.07813"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-australia rdfs:label "Australia"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-automatic_photo_pop-up rdfs:label "Automatic photo pop-up"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-autonomous_driving rdfs:label "autonomous driving"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average_normal_estimate rdfs:label "average normal estimate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-axis-aligned_box rdfs:label "axis-aligned box"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-backpropagation rdfs:label "backpropagation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-baseline rdfs:label "baseline"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-behavior rdfs:label "behavior"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-berg rdfs:label "Berg"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bicubic_interpolation rdfs:label "bicubic interpolation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-bilinear_interpolations rdfs:label "Bilinear Interpolations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-binary_tensor_encoding_segmentation_masks rdfs:label "binary tensor encoding segmentation masks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-biological_entity rdfs:label "Biological Entity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bishop rdfs:label "Bishop"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-blue_blocks rdfs:label "blue blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blur_arising_from_combining_multiple_warped_images rdfs:label "blur arising from combining multiple warped images"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-blurry rdfs:label "blurry"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-bmvc rdfs:label "BMVC"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-box_coordinates rdfs:label "box coordinates"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-branches rdfs:label "branches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-brostow rdfs:label "Brostow"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-brown_n rdfs:label "Brown, N."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-brox rdfs:label "Brox"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-buildings rdfs:label "buildings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-c_x_j__c_y_j_ rdfs:label "(c x j , c y j )"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-caffe rdfs:label "Caffe"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-cambridge_university_press rdfs:label "Cambridge university press"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-camera_intrinsic_parameters rdfs:label "camera intrinsic parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-camera_motion rdfs:label "camera motion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-candidate_new_view_images rdfs:label "candidate new view images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-candidate_synthesized_images rdfs:label "candidate synthesized images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-candidate_synthesized_views rdfs:label "candidate synthesized views"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-carneiro rdfs:label "Carneiro"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cascaded_refinement_networks rdfs:label "cascaded refinement networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-cecs_anu rdfs:label "CECS, ANU"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-central_part rdfs:label "central part"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ceylan rdfs:label "Ceylan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chang_m rdfs:label "Chang, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chaurasia_s rdfs:label "Chaurasia, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-chemical_entity rdfs:label "Chemical Entity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-chen rdfs:label "Chen"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-city rdfs:label "City"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classes rdfs:label "classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-coarse_structure rdfs:label "coarse structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-code rdfs:label "code"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-column_vectors rdfs:label "column vectors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-combining_the_intensities_of_nearby_transformed_locations rdfs:label "combining the intensities of nearby transformed locations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compact_regions rdfs:label "compact regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complete_feature_maps rdfs:label "complete feature maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complex_real-world_scenes rdfs:label "complex, real-world scenes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complex_scenes_with_rich_structure_and_dynamic_objects rdfs:label "complex scenes with rich structure and dynamic objects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computer_vision_and_pattern_recognition rdfs:label "Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-computer_vision_and_pattern_recognition_cvpr rdfs:label "Computer Vision and Pattern Recognition (CVPR)"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-computer_vision_systems rdfs:label "computer vision systems"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-conference_on_computer_vision_and_pattern_recognition rdfs:label "Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-constant rdfs:label "constant"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-contentpreserving_warps rdfs:label "Contentpreserving warps"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-context_of_comparison rdfs:label "context of comparison"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-convolution rdfs:label "convolution"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-convolutional_network rdfs:label "convolutional network"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-convolutional_neural_network rdfs:label "convolutional neural network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-convolutional_neural_networks_cnns rdfs:label "Convolutional Neural Networks (CNNs)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-correspondence rdfs:label "correspondence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-corresponding_normal rdfs:label "corresponding normal"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-covid-19 rdfs:label "COVID-19"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-csiro rdfs:label "CSIRO"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-cvlab rdfs:label "CVLAB"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-cvlab_epfl rdfs:label "CVLAB, EPFL"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-d_j rdfs:label "d_j"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-dai_a rdfs:label "Dai, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-data61 rdfs:label "Data61"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-data_analysis_software rdfs:label "data analysis software"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-data_analysis_tools rdfs:label "Data Analysis Tools"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-data_representation rdfs:label "data representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_science rdfs:label "Data Science"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_splits rdfs:label "data splits"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-deconvolutions rdfs:label "deconvolutions"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-deep3d rdfs:label "Deep3d"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-deep_architecture rdfs:label "deep architecture"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_convolutional_inverse_graphics_network rdfs:label "Deep convolutional inverse graphics network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_convolutional_neural_networks rdfs:label "deep convolutional neural networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-deep_learning_framework rdfs:label "deep learning framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-deep_learning_paradigm rdfs:label "deep learning paradigm"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-deep_view_morphing rdfs:label "Deep view morphing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deepstereo rdfs:label "Deepstereo"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-dense_depth_maps rdfs:label "dense depth maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth-based_baseline rdfs:label "depth-based baseline"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-depth-branch rdfs:label "Depth-branch"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-depth_and_ego-motion rdfs:label "depth and ego-motion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_and_normal rdfs:label "depth and normal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_and_normal_branch_parameters rdfs:label "depth and normal branch parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_and_normal_prediction rdfs:label "Depth and Normal Prediction"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-depth_branch rdfs:label "depth branch"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-depth_estimate rdfs:label "depth estimate"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-depth_estimates rdfs:label "depth estimates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_map rdfs:label "depth map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_maps rdfs:label "depth maps"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-depth_networks rdfs:label "depth networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-depth_or_normal_prediction rdfs:label "depth or normal prediction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_streams rdfs:label "depth streams"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-depth_synthesis rdfs:label "Depth synthesis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-derek_hoiem rdfs:label "Derek Hoiem"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-desired_relative_pose rdfs:label "desired relative pose"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different rdfs:label "different"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_stages rdfs:label "different stages"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_viewpoint rdfs:label "different viewpoint"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-differentiable rdfs:label "differentiable"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-disparity rdfs:label "disparity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-displacements rdfs:label "displacements"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-displacements_of_the_pixels rdfs:label "displacements of the pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distorted_local_structures rdfs:label "distorted local structures"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-diverse_scene_types rdfs:label "diverse scene types"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-divide-and-conquer_strategy rdfs:label "divide-and-conquer strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-division_by_0 rdfs:label "division by 0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dna_sequencing_technology rdfs:label "DNA sequencing technology"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-dosovitskiy rdfs:label "Dosovitskiy"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-drettakis rdfs:label "Drettakis"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-duchene_o rdfs:label "Duchene, O."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-dx rdfs:label "d(x)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e rdfs:label "E."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-each_surface rdfs:label "each surface"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-eccv rdfs:label "ECCV"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-educational_institution rdfs:label "Educational Institution"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-eigen rdfs:label "Eigen"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-encoder-decoder_refinement rdfs:label "encoder-decoder refinement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-encoder-decoder_refinement_network rdfs:label "encoder-decoder refinement network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-encoder-decoder_structure rdfs:label "encoder-decoder structure"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-epfl rdfs:label "EPFL"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-eqs rdfs:label "Eqs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-est-nor rdfs:label "est-Nor"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimated_depth_and_normal_map rdfs:label "estimated depth and normal map"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-estimated_normal rdfs:label "estimated normal"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-estimated_normals rdfs:label "estimated normals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimated_one rdfs:label "estimated one"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimated_target_images rdfs:label "estimated target images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-estimation rdfs:label "estimation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-evidence rdfs:label "evidence"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-exact_integer_pixel_coordinates rdfs:label "exact, integer pixel coordinates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-failure_cases rdfs:label "failure cases"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-farhadi rdfs:label "Farhadi"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-feature rdfs:label "feature"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feature_1_loss rdfs:label "feature `1 loss"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-feature_vectors rdfs:label "feature vectors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-features rdfs:label "features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-features_at_every_pixel rdfs:label "features at every pixel"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-field_of_study rdfs:label "Field of Study"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-figs rdfs:label "Figs"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-figure_10 rdfs:label "Figure 10"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-figure_11 rdfs:label "Figure 11"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_15 rdfs:label "Figure 15"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-figure_2 rdfs:label "Figure 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_3 rdfs:label "Figure 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_4 rdfs:label "Figure 4"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_7 rdfs:label "Figure 7"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-final_depth_network rdfs:label "final depth network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-final_novel_view_synthesis_results rdfs:label "final novel view synthesis results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-fine-tuned_network rdfs:label "fine-tuned network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-first_3_parameters rdfs:label "first 3 parameters"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-first_4_convolutional_blocks_of_vgg16 rdfs:label "first 4 convolutional blocks of VGG16"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-first_author rdfs:label "first author"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-first_image rdfs:label "first image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fitzgibbon rdfs:label "Fitzgibbon"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fixed_depth_and_normal_branches rdfs:label "fixed depth and normal branches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flow rdfs:label "flow"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flow_of_each_pixel rdfs:label "flow of each pixel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-flynn_i rdfs:label "Flynn, I."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-foreground rdfs:label "foreground"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-formula rdfs:label "formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formulation rdfs:label "formulation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-forward_warping_strategy rdfs:label "forward warping strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-frame_number rdfs:label "frame number"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-fritz rdfs:label "Fritz"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fua rdfs:label "Fua"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fullyconvolutional_architectures rdfs:label "fullyconvolutional architectures"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-funkhouser rdfs:label "Funkhouser"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-furukawa rdfs:label "Furukawa"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-garg_g rdfs:label "Garg, G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-geiger_p rdfs:label "Geiger, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-gene_expression_analysis rdfs:label "gene expression analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-general_pose_variations rdfs:label "general pose variations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-generating_an_image_of_one_view_from_that_of_the_other_in_a_stereo_setup rdfs:label "generating an image of one view from that of the other in a stereo setup"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-generative_adversarial_network rdfs:label "generative adversarial network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-generative_adversarial_networks rdfs:label "Generative Adversarial Networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-generator_of_20 rdfs:label "generator of [20]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-genome_editing rdfs:label "genome editing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometric_constraints rdfs:label "geometric constraints"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometric_cues rdfs:label "geometric cues"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometric_structure rdfs:label "geometric structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometric_transformations rdfs:label "geometric transformations"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-geometry-aware_deep_architecture rdfs:label "geometry-aware deep architecture"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-geometry-aware_deep_learning_framework rdfs:label "geometry-aware deep learning framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-geometry-aware_deep_learning_strategy rdfs:label "geometry-aware deep learning strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-geometry-based_view_synthesis rdfs:label "Geometry-based view synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gleicher_h rdfs:label "Gleicher, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-global_heatmap rdfs:label "global heatmap"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-godard_o rdfs:label "Godard, O."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-google rdfs:label "Google"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-gradient_of_the_inverse_homography rdfs:label "gradient of the inverse homography"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-graphical_models rdfs:label "Graphical Models"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-green_blocks rdfs:label "green blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ground-truth_depth_maps rdfs:label "ground-truth depth maps"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-ground-truth_visibility_maps rdfs:label "ground-truth visibility maps"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-ground_truth rdfs:label "ground truth"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-groundtruth_depth_maps rdfs:label "groundtruth depth maps"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-h1 rdfs:label "H−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h_1 rdfs:label "H˜ −1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h__w__m rdfs:label "h × w × m"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h_j rdfs:label "H_j"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-halber_t rdfs:label "Halber, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hariharan_p rdfs:label "Hariharan, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-heat_map rdfs:label "heat map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hebert rdfs:label "Hebert"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hidden_factors rdfs:label "hidden factors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-highly_detailed_models rdfs:label "highly detailed models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-highquality_synthetic_views rdfs:label "highquality synthetic views"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-hoiem_a rdfs:label "Hoiem, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-homogeneous_coordinates rdfs:label "homogeneous coordinates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-homography-based_approach rdfs:label "homography-based approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-homography_for_region_j rdfs:label "homography for region j"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-horry_k-i rdfs:label "Horry, K.-I."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-human_beings rdfs:label "Human beings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hyper-columns rdfs:label "Hyper-columns"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-i rdfs:label "I"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-i_hat_jtf_x_it rdfs:label "I_hat_{j}^{t}({f x}_{i}^{t})"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-iccv rdfs:label "ICCV"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-image-based_rendering_system rdfs:label "image-based rendering system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-image_pair rdfs:label "image pair"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_pixels rdfs:label "image pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_sequence rdfs:label "image sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-image_transformation rdfs:label "image transformation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-imageto-image_translation rdfs:label "imageto-image translation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-indoor_segmentation rdfs:label "Indoor segmentation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-inference_from_rgbd_images rdfs:label "inference from rgbd images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-influence_of_the_quality_of_the_depth_and_normal_estimates_and_of_learning_the_selection_maps rdfs:label "influence of the quality of the depth and normal estimates and of learning the selection maps"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-initial_seed_region rdfs:label "initial seed region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_seed_regions rdfs:label "initial seed regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_synthesized_view rdfs:label "initial synthesized view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inner_product rdfs:label "inner product"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input rdfs:label "input"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_and_novel_views rdfs:label "input and novel views"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_image_i_s rdfs:label "input image I s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_source_image rdfs:label "input source image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_views rdfs:label "input views"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inputtarget_pairs rdfs:label "inputtarget pairs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-instance rdfs:label "instance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-intensity rdfs:label "intensity"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-intensity_of_pixels rdfs:label "intensity of pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-intensity_value rdfs:label "intensity value"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-inverse_depth rdfs:label "inverse depth"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inverse_image_warping rdfs:label "Inverse Image Warping"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-inverse_of_homographies rdfs:label "inverse of homographies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inverse_of_the_homography rdfs:label "inverse of the homography"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inverse_warping rdfs:label "inverse warping"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-inverse_warping_procedure rdfs:label "inverse warping procedure"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-is rdfs:label "I^{s}"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-jaderberg_k rdfs:label "Jaderberg, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ji_j rdfs:label "Ji, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-k-means rdfs:label "K-means"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-k_%09ildeh-1_k-1 rdfs:label "K 	ilde{H}^{-1} K^{-1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kavukcuoglu rdfs:label "Kavukcuoglu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kh_1k1 rdfs:label "KH˜ −1K−1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kiiti rdfs:label "KIITI"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_odometry_dataset rdfs:label "KITTI odometry dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_test_set rdfs:label "KITTI test set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-kitti_vision_benchmark_suite rdfs:label "kitti vision benchmark suite"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-kohli rdfs:label "Kohli"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-koltun rdfs:label "Koltun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kr_-_t__ntk-1 rdfs:label "K(R - t * n^T)K^{-1}"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-kr_-_t_n_jtk-1 rdfs:label "K(R - t n_j^T)K^{-1}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kulkarni_w rdfs:label "Kulkarni, W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-kwon_m rdfs:label "Kwon, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-l rdfs:label "L."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-large-scale_image_recognition rdfs:label "large-scale image recognition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-large_memory rdfs:label "large memory"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-large_rotations rdfs:label "large rotations"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-larger_planar_and_semantically-coherent_regions rdfs:label "larger planar and semantically-coherent regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-larger_planes_of_semantically_and_visually_coherent_pixels rdfs:label "larger planes of semantically and visually coherent pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-larger_tree_regions rdfs:label "larger tree regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning rdfs:label "learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-learning-based_approaches rdfs:label "learning-based approaches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-learning-based_segmentation_masks rdfs:label "learning-based segmentation masks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-lecun rdfs:label "LeCun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-left-right_consistency rdfs:label "left-right consistency"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lenz rdfs:label "Lenz"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lf rdfs:label "Lf"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-likelihood_of_the_pixels rdfs:label "likelihood of the pixels"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-liu_m rdfs:label "Liu, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-local_geometric_structures rdfs:label "local geometric structures"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-local_geometric_structures_of_the_scene rdfs:label "local geometric structures of the scene"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-local_homographies rdfs:label "local homographies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-location_x rdfs:label "location x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-locations rdfs:label "locations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss rdfs:label "loss"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-loss_function rdfs:label "loss function"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-low-resolution_heat_map rdfs:label "low-resolution heat map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lowe rdfs:label "Lowe"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-lp rdfs:label "Lp"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lt__lp__%CE%BBlf rdfs:label "Lt = Lp + λLf"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lucchi_p rdfs:label "Lucchi, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-m%CB%86_t_j_x_t_i_ rdfs:label "Mˆ t j (x t i )"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-m__16 rdfs:label "m = 16"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-m_planar_region_masks rdfs:label "m planar region masks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-m_seed_regions rdfs:label "m seed regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-m_selection_maps rdfs:label "m selection maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ma rdfs:label "Ma"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mac_aodha rdfs:label "Mac Aodha"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-machine_learning_algorithms rdfs:label "Machine Learning Algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-masks rdfs:label "masks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-matrix_of_camera_intrinsic_parameters_k rdfs:label "matrix of camera intrinsic parameters K"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mcfarland rdfs:label "McFarland"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mcmillan rdfs:label "McMillan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mean_pixel_1_error rdfs:label "mean pixel 1 error"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mean_pixel_1_error_as_a_loss rdfs:label "mean pixel 1 error as a loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-mean_pixel_1_error_metric rdfs:label "mean pixel 1 error metric"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-memory_consumption rdfs:label "memory consumption"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-miaomiao_liu rdfs:label "Miaomiao Liu"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mini-batches rdfs:label "mini-batches"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-minion rdfs:label "MinION"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-missing_parts_of_the_synthesized_images rdfs:label "missing parts of the synthesized images"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-missing_pixels rdfs:label "missing pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mit rdfs:label "MIT"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-mj rdfs:label "Mj"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-modeling_geometry rdfs:label "modeling geometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-more_realistic_novel_views rdfs:label "more realistic novel views"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-more_realistic_predictions rdfs:label "more realistic predictions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-motion rdfs:label "motion"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-motion_of_different_regions rdfs:label "motion of different regions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-multi-scale_convolutional_architecture rdfs:label "multi-scale convolutional architecture"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-multi-view_3d_models rdfs:label "Multi-view 3d models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-multi-view_3d_reconstruction_techniques rdfs:label "multi-view 3D reconstruction techniques"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multi-view_stereo rdfs:label "multi-view stereo"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multiple_images rdfs:label "multiple images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiple_planes rdfs:label "multiple planes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiple_synthesized_candidates rdfs:label "multiple synthesized candidates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiple_views rdfs:label "multiple views"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-multiview_stereo rdfs:label "multiview stereo"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-multiview_stereopsis rdfs:label "multiview stereopsis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n_t_j_q rdfs:label "−n¯ T j Q"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-n_training_samples rdfs:label "N training samples"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-nathan_silberman rdfs:label "Nathan Silberman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-natural_language_processing rdfs:label "Natural Language Processing"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-natural_results rdfs:label "natural results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-nature rdfs:label "Nature"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-neighboring_views rdfs:label "neighboring views"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neulander_j rdfs:label "Neulander, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-neural_networks rdfs:label "Neural Networks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-new_pose rdfs:label "new pose"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-new_region-aware_geometric_transform_network rdfs:label "new region-aware geometric transform network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-new_theory rdfs:label "New Theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-new_viewpoint rdfs:label "new viewpoint"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nguyen_t rdfs:label "Nguyen, T."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-nie%C3%9Fner rdfs:label "Nießner"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-njn_d_j rdfs:label "n¯j/n¯ d j"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-noise rdfs:label "noise"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normal rdfs:label "normal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normal_and_depth_estimates rdfs:label "normal and depth estimates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normal_approximation rdfs:label "normal approximation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normal_estimate_at_location_x rdfs:label "normal estimate at location x"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-normal_loss rdfs:label "normal loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-normal_maps rdfs:label "normal maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normal_networks rdfs:label "normal networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-normal_prediction_accuracy rdfs:label "normal prediction accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-normal_streams rdfs:label "normal streams"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normalized_transformed_mask rdfs:label "normalized transformed mask"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-normals_in_the_input_image rdfs:label "normals in the input image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-not_relying_on rdfs:label "not relying on"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-notions_of_geometry rdfs:label "notions of geometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-novel rdfs:label "novel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-novel_view_accuracy rdfs:label "novel view accuracy"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-novel_view_image rdfs:label "novel view image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-novel_view_prediction rdfs:label "Novel View Prediction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-numerical_recipes_3rd_edition rdfs:label "Numerical recipes 3rd edition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-nvidia_corporation rdfs:label "NVIDIA Corporation"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-nvidia_tesla_p100 rdfs:label "NVIDIA Tesla P100"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-nx rdfs:label "n(x)"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-nyu-v2 rdfs:label "NYU-v2"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-o rdfs:label "O."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-object rdfs:label "object"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-object_segmentation_and_fine-grained_localization rdfs:label "object segmentation and fine-grained localization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-obtaining_a_complete_image rdfs:label "obtaining a complete image"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-occlusions rdfs:label "occlusions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-operation rdfs:label "operation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-operations rdfs:label "operations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimization rdfs:label "optimization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-our_baseline rdfs:label "our baseline"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-our_implementation rdfs:label "our implementation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-ours rdfs:label "Ours"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-ours-_full rdfs:label "Ours- Full"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-outdoor_kitti rdfs:label "outdoor KITTI"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-oxford_nanopore_technologies rdfs:label "Oxford Nanopore Technologies"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-p rdfs:label "P."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-pair_of_images rdfs:label "pair of images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pairs rdfs:label "pairs"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-parameters rdfs:label "parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parameters_w__wdwnws rdfs:label "parameters W = {Wd,Wn,Ws}"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-park_j rdfs:label "Park, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-partial_scene rdfs:label "partial scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-parts_of_the_road_trees_sky_and_buildings rdfs:label "parts of the road, trees, sky, and buildings"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-philbin rdfs:label "Philbin"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-photographic_image_synthesis rdfs:label "Photographic image synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-piece-wise_planar_representation rdfs:label "piece-wise planar representation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pixel-wise_depth rdfs:label "pixel-wise depth"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel-wise_depth_and_normal_estimates rdfs:label "pixel-wise depth and normal estimates"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel-wise_depth_and_normals rdfs:label "pixel-wise depth and normals"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pixel-wise_probability rdfs:label "pixel-wise probability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel-wise_selection_maps rdfs:label "pixel-wise selection maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel_appearance rdfs:label "pixel appearance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel_location rdfs:label "pixel location"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixel_x rdfs:label "pixel x"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixels_correspondences rdfs:label "pixels correspondences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixels_of_the_input_image rdfs:label "pixels of the input image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pixels_of_the_new_view rdfs:label "pixels of the new view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-planar_region rdfs:label "planar region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-plane-based_content_preserving_warps rdfs:label "Plane-based content preserving warps"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-plane-sweep_volume rdfs:label "plane-sweep volume"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-plane-sweep_volumes rdfs:label "plane-sweep volumes"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-plane_parameters rdfs:label "plane parameters"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-planes rdfs:label "planes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-plausible_image-based_navigation rdfs:label "plausible image-based navigation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-plenoptic_modeling rdfs:label "Plenoptic modeling"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-point_q rdfs:label "point Q"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ponce rdfs:label "Ponce"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-pooled_features rdfs:label "pooled features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pose rdfs:label "pose"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-predicted_depth rdfs:label "predicted depth"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-predicted_depth_maps rdfs:label "predicted depth maps"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-predicted_images rdfs:label "predicted images"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-predicted_ones rdfs:label "predicted ones"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-predicted_selection_maps rdfs:label "predicted selection maps"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-prediction rdfs:label "prediction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-predictions_of_our_depth_stream rdfs:label "predictions of our depth stream"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-press rdfs:label "Press"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-problem_of_novel_view_synthesis_from_a_single_image rdfs:label "problem of novel view synthesis from a single image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proceedings rdfs:label "Proceedings"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-proceedings_of_the_22nd_annual_conference_on_computer_graphics_and_interactive_techniques rdfs:label "Proceedings of the 22nd annual conference on Computer graphics and interactive techniques"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-proceedings_of_the_24th_annual_conference_on_computer_graphics_and_interactive_techniques rdfs:label "Proceedings of the 24th annual conference on Computer graphics and interactive techniques"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-purple_blocks rdfs:label "purple blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-qualitative_comparison rdfs:label "qualitative comparison"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-quantitative_evaluation rdfs:label "Quantitative evaluation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-quantum_computing rdfs:label "Quantum Computing"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-question_answering rdfs:label "Question Answering"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r_-_t__nt rdfs:label "R - t * n^T"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-readiness rdfs:label "readiness"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-real-world_scene rdfs:label "real-world scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-realistic rdfs:label "realistic"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-realistic_novel_view rdfs:label "realistic novel view"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-realistic_predictions rdfs:label "realistic predictions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-region rdfs:label "region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-region-aware_geometric-transformation_network rdfs:label "region-aware geometric-transformation network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-region-aware_geometric_transform_network rdfs:label "region-aware geometric transform network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-region_j rdfs:label "region j"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regionaware_geometric-transform_network rdfs:label "regionaware geometric-transform network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-reid rdfs:label "Reid"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-reid_p rdfs:label "Reid, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-reinforcement_learning rdfs:label "Reinforcement Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relative_depth_error_of_0236 rdfs:label "relative depth error of 0.236"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-relative_error_of_0274 rdfs:label "relative error of 0.274"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-relative_pose_p rdfs:label "relative pose P"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relative_rotation_matrix_r rdfs:label "relative rotation matrix R"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relu rdfs:label "ReLU"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-rematas_c rdfs:label "Rematas, C."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-research_findings rdfs:label "research findings"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-research_on_machine_learning_techniques rdfs:label "Research on machine learning techniques"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-research_paper rdfs:label "Research Paper"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-researchgate rdfs:label "ResearchGate"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-respectively rdfs:label "respectively"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-results_of_our_approach rdfs:label "results of our approach"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-rgb_value rdfs:label "RGB value"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-ritschel_m rdfs:label "Ritschel, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-rna-seq rdfs:label "RNA-seq"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-rotation_matrix rdfs:label "rotation matrix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rt__rtthatntrt1-hatntrtt rdfs:label "R^{T} + (R^{T}t\\hat{n}^{T}R^{T})/(1-\\hat{n}^{T}R^{T}t)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s rdfs:label "S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-same_as_in_20 rdfs:label "same as in [20]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-savarese rdfs:label "Savarese"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-savva_m rdfs:label "Savva, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-scientific_collaboration rdfs:label "scientific collaboration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scientific_computing rdfs:label "scientific computing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scientific_research rdfs:label "scientific research"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_312 rdfs:label "Section 3.1.2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-section_4 rdfs:label "Section 4"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-seed_and_selmap rdfs:label "Seed and SelMap"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-seed_region_mask rdfs:label "seed region mask"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-seed_region_masks rdfs:label "seed region masks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-segment rdfs:label "segment"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-segmentation_seed_region_masks_m rdfs:label "segmentation seed region masks M"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-segmented_image_regions rdfs:label "segmented image regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-selection_network_parameters rdfs:label "selection network parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-semantic-based_priors rdfs:label "semantic-based priors"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-semantic_labels rdfs:label "semantic labels"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-sentiment_analysis rdfs:label "Sentiment Analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_all_pixel_locations rdfs:label "set of all pixel locations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_homographies rdfs:label "set of homographies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_m_planar_surfaces rdfs:label "set of m planar surfaces"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_soft_selection_masks rdfs:label "set of soft selection masks"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-shaji_k rdfs:label "Shaji, K."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-shanghaitech_university rdfs:label "ShanghaiTech University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-shape rdfs:label "shape"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-shared_network_parameters rdfs:label "shared network parameters"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sharper_results rdfs:label "sharper results"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-simonyan rdfs:label "Simonyan"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-simonyan_a rdfs:label "Simonyan, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-simple_3d_models rdfs:label "simple 3D models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-single-image_depth_and_normal_prediction rdfs:label "single-image depth and normal prediction"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-single-image_novel_view_synthesis_problem rdfs:label "single-image novel view synthesis problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single-image_novel_view_synthesis_process rdfs:label "single-image novel view synthesis process"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-single-image_view_synthesis rdfs:label "single-image view synthesis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-single-object_novel_view_synthesis rdfs:label "single-object novel view synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single-object_view_synthesis rdfs:label "single-object view synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single_images rdfs:label "single images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single_view_depth_estimation rdfs:label "single view depth estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-slic rdfs:label "SLIC"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-slic_superpixel rdfs:label "SLIC superpixel"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-smith_a rdfs:label "Smith, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-soft_selection_map rdfs:label "soft selection map"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-sorkine-hornung rdfs:label "Sorkine-Hornung"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-source_image rdfs:label "source image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-source_location rdfs:label "source location"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-source_pixel_x_s rdfs:label "source pixel x s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparse_ground-truth_depth_maps rdfs:label "sparse ground-truth depth maps"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-sparse_points rdfs:label "sparse points"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-spatial_transformer_networks rdfs:label "Spatial transformer networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-spidery_mesh_interface rdfs:label "spidery mesh interface"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-square_root rdfs:label "square root"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stage-wise_manner rdfs:label "stage-wise manner"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stages rdfs:label "stages"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-of-the-art_appearance_flow_baseline rdfs:label "state-of-the-art appearance flow baseline"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-of-the-art_method rdfs:label "state-of-the-art method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-of-the-art_methods rdfs:label "state-of-the-art methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-of-the-art_performance rdfs:label "state-of-the-art performance"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-state-of-the-art_single-image_novel_view_synthesis_techniques rdfs:label "state-of-the-art single-image novel view synthesis techniques"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-state-of-the-art_single-image_view_synthesis_algorithm rdfs:label "state-of-the-art single-image view synthesis algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-state-of-the-art_superpixel_methods rdfs:label "state-of-the-art superpixel methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-statistical_principles rdfs:label "Statistical Principles"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stereo_framework rdfs:label "stereo framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-stereo_matching_cost rdfs:label "stereo matching cost"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-stereo_view_synthesis rdfs:label "stereo view synthesis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structure-from-motion rdfs:label "structure-from-motion"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-sub-gradient rdfs:label "(sub)-gradient"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sun_j rdfs:label "Sun, J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-superpixel rdfs:label "superpixel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-supplementary_material rdfs:label "supplementary material"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-surface_normals rdfs:label "surface normals"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-susstrunk rdfs:label "Susstrunk"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-synthesis_process rdfs:label "synthesis process"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-synthesized_image rdfs:label "synthesized image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-synthesized_views rdfs:label "synthesized views"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-table_2 rdfs:label "Table 2"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-table_3 rdfs:label "Table 3"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-target_intensity_value rdfs:label "target intensity value"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-target_pixel_location rdfs:label "target pixel location"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-target_pose rdfs:label "target pose"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tatarchenko_a rdfs:label "Tatarchenko, A."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-tenenbaum rdfs:label "Tenenbaum"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-testing rdfs:label "testing"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-text_classification rdfs:label "Text Classification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-that rdfs:label "that"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_binary_mask_corresponding_to_the_j_th_segment rdfs:label "the binary mask corresponding to the j th segment"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-the_entire_network rdfs:label "the entire network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-the_experiments_section rdfs:label "the experiments section"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_first_4_blocks rdfs:label "the first 4 blocks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_input_view rdfs:label "the input view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_novel_view rdfs:label "the novel view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_scenario_where_a_single_image_is_available_to_synthesize_a_novel_view rdfs:label "the scenario where a single image is available to synthesize a novel view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_third_to_seventh_rows rdfs:label "the third to seventh rows"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-theorem_1 rdfs:label "Theorem 1"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-this rdfs:label "This"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_approach rdfs:label "this approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-this_method rdfs:label "this method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-this_plane rdfs:label "this plane"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_geometric_classes rdfs:label "three geometric classes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-titan_x rdfs:label "Titan X"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-torr rdfs:label "Torr"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-training rdfs:label "training"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_and_test_pair rdfs:label "training and test pair"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-training_code rdfs:label "training code"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-training_data rdfs:label "training data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_sequences rdfs:label "training sequences"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_set rdfs:label "training set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-training_validation_and_test_splits rdfs:label "training, validation and test splits"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-transformation-grounded_image_generation_network rdfs:label "Transformation-grounded image generation network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-transformation-grounded_network rdfs:label "transformation-grounded network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-transformed_masks rdfs:label "transformed masks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transformers rdfs:label "Transformers"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-translation_vector_t rdfs:label "translation vector t"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-triple_data rdfs:label "triple data"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-triples rdfs:label "triples"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-true_target_image rdfs:label "true target image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tulsiani_w rdfs:label "Tulsiani, W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-tuytelaars rdfs:label "Tuytelaars"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-two_datasets rdfs:label "two datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-two_images rdfs:label "two images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_views rdfs:label "two views"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-typical_failure_cases rdfs:label "typical failure cases"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-u rdfs:label "u"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-undefined rdfs:label "undefined"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-underlying_scene_structure rdfs:label "underlying scene structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uniform_weights rdfs:label "uniform weights"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unit_norm rdfs:label "unit norm"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-university_of_oxford rdfs:label "University of Oxford"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-unknown rdfs:label "unknown"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unrealistic rdfs:label "unrealistic"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-unrealistic_artifacts rdfs:label "unrealistic artifacts"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-unreliable_regions rdfs:label "unreliable regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-unspecified_publication rdfs:label "unspecified publication"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-unsupervised_cnn rdfs:label "Unsupervised cnn"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-unsupervised_learning rdfs:label "Unsupervised learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-unsupervised_monocular_depth_estimation rdfs:label "Unsupervised monocular depth estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-urban_kitti_odometry_dataset rdfs:label "urban KITTI odometry dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-urtasun rdfs:label "Urtasun"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-user rdfs:label "user"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-value rdfs:label "value"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-vanishing_points rdfs:label "vanishing points"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-variational_auto-encoder rdfs:label "variational auto-encoder"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-vector rdfs:label "vector"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-very_deep_convolutional_networks rdfs:label "Very deep convolutional networks"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-vgg16 rdfs:label "VGG16"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-video rdfs:label "video"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-video_sequences rdfs:label "video sequences"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-video_stabilization rdfs:label "video stabilization"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-view_interpolation rdfs:label "view interpolation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-view_interpolation_task rdfs:label "view interpolation task"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-view_synthesis_from_a_single_image rdfs:label "view synthesis from a single image"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-visibility rdfs:label "visibility"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visibility_constraints rdfs:label "visibility constraints"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visibility_map rdfs:label "visibility map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-visual_representation rdfs:label "visual representation"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-visualisation_of_estimated_depth_and_normal_maps rdfs:label "visualisation of estimated depth and normal maps"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-visually_more_realistic_predictions rdfs:label "visually more realistic predictions"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-warped_input_images rdfs:label "warped input images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-warped_selection_masks rdfs:label "warped selection masks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-warping_strategy rdfs:label "warping strategy"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-weakly-supervised_depth_prediction_methods rdfs:label "weakly-supervised depth prediction methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-weights rdfs:label "weights"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-what rdfs:label "what"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-whitney_p rdfs:label "Whitney, P."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-woodford_i rdfs:label "Woodford, I."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-x rdfs:label "X"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_s rdfs:label "x s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-x_s_ij rdfs:label "x s i,j"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-xie_r rdfs:label "Xie, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-xuming_he rdfs:label "Xuming He"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yang_e rdfs:label "Yang, E."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-yumer_d rdfs:label "Yumer, D."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-z rdfs:label "Z"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zbontar rdfs:label "Zbontar"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhou_h rdfs:label "Zhou, H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhou_m rdfs:label "Zhou, M."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-zhou_s rdfs:label "Zhou, S."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Paper-305358d7d24f2bf4-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "Geometry-Aware Deep Network For Single-Image Novel View Synthesis"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-11,
        askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-12 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "| Miaomiao Liu | Xuming He | Mathieu Salzmann | |---------------------|-------------------------|--------------------| | CECS, ANU | ShanghaiTech University | CVLAB, EPFL | | Canberra, Australia | Shanghai, China | |"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-11-Sentence-111 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Miaomiao Liu | Xuming He | Mathieu Salzmann | |---------------------|-------------------------|--------------------| | CECS, ANU | ShanghaiTech University | CVLAB, EPFL | | Canberra, Australia | Shanghai, China | |"@en ;
    askg-onto:inSentence "| Miaomiao Liu | Xuming He | Mathieu Salzmann | |---------------------|-------------------------|--------------------| | CECS, ANU | ShanghaiTech University | CVLAB, EPFL | | Canberra, Australia | Shanghai, China | |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cecs_anu,
        askg-data:Entity-cvlab_epfl,
        askg-data:Entity-mathieu_salzmann,
        askg-data:Entity-miaomiao_liu,
        askg-data:Entity-shanghaitech_university,
        askg-data:Entity-xuming_he .

askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-12 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Mathieu Salzmann CVLAB, EPFL miaomiao.liu@anu.edu.au hexm@shanghaitech.edu.cn mathieu.salzmann@epfl.ch"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-12-Sentence-121 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-1-Paragraph-12-Sentence-121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Mathieu Salzmann CVLAB, EPFL miaomiao.liu@anu.edu.au hexm@shanghaitech.edu.cn mathieu.salzmann@epfl.ch"@en ;
    askg-onto:inSentence "Mathieu Salzmann CVLAB, EPFL miaomiao.liu@anu.edu.au hexm@shanghaitech.edu.cn mathieu.salzmann@epfl.ch"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cvlab,
        askg-data:Entity-epfl,
        askg-data:Entity-mathieu_salzmann .

askg-data:Paper-305358d7d24f2bf4-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "4. Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-101,
        askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-102 ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-101 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We evaluate our approach both quantitatively and qualitatively on the challenging urban KITTI odometry dataset [9], which depicts complex scenes with rich structure and dynamic objects, and on the large indoor scene ScanNet dataset [4], which covers diverse scene types. We compare our approach with the state-of-the-art single-image view synthesis algorithm of [29] for real-world scenes1."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-101-Sentence-1011,
        askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-101-Sentence-1012 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-101-Sentence-1011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We evaluate our approach both quantitatively and qualitatively on the challenging urban KITTI odometry dataset [9], which depicts complex scenes with rich structure and dynamic objects, and on the large indoor scene ScanNet dataset [4], which covers diverse scene types."@en ;
    askg-onto:inSentence "We evaluate our approach both quantitatively and qualitatively on the challenging urban KITTI odometry dataset [9], which depicts complex scenes with rich structure and dynamic objects, and on the large indoor scene ScanNet dataset [4], which covers diverse scene types."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complex_scenes_with_rich_structure_and_dynamic_objects,
        askg-data:Entity-diverse_scene_types,
        askg-data:Entity-scannet_dataset,
        askg-data:Entity-urban_kitti_odometry_dataset .

askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-101-Sentence-1012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We compare our approach with the state-of-the-art single-image view synthesis algorithm of [29] for real-world scenes1."@en ;
    askg-onto:inSentence "We compare our approach with the state-of-the-art single-image view synthesis algorithm of [29] for real-world scenes1."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_approach,
        askg-data:Entity-real-world_scenes,
        askg-data:Entity-state-of-the-art_single-image_view_synthesis_algorithm .

askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-102 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Furthermore, we also report the results of a depth-based baseline consisting of using the predictions of our depth stream warped to the new pose, followed by bicubic interpolation to obtain a complete image."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-102-Sentence-1021 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-10-Paragraph-102-Sentence-1021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Furthermore, we also report the results of a depth-based baseline consisting of using the predictions of our depth stream warped to the new pose, followed by bicubic interpolation to obtain a complete image."@en ;
    askg-onto:inSentence "Furthermore, we also report the results of a depth-based baseline consisting of using the predictions of our depth stream warped to the new pose, followed by bicubic interpolation to obtain a complete image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bicubic_interpolation,
        askg-data:Entity-depth-based_baseline,
        askg-data:Entity-new_pose,
        askg-data:Entity-obtaining_a_complete_image,
        askg-data:Entity-predictions_of_our_depth_stream .

askg-data:Paper-305358d7d24f2bf4-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "4.1. Experimental Setup"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-114,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "KITTI Dataset. For the comparison with [29] to be fair, we adopt the same data splits as them. Namely, we use the video sequences with index 0 to 8 as training set, and 9 to 10 as test set. We then generate our training and test pair in the following way, similar to that of [29]: For each image in a sequence, we randomly sample a frame number for the input image and for the target image such that they are separated by at most ±10 frames."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1112,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1113,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1114 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "KITTI Dataset."@en ;
    askg-onto:inSentence "KITTI Dataset."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-kitti_dataset .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For the comparison with [29] to be fair, we adopt the same data splits as them."@en ;
    askg-onto:inSentence "For the comparison with [29] to be fair, we adopt the same data splits as them."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_splits,
        askg-data:Entity-them .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Namely, we use the video sequences with index 0 to 8 as training set, and 9 to 10 as test set."@en ;
    askg-onto:inSentence "Namely, we use the video sequences with index 0 to 8 as training set, and 9 to 10 as test set."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-test_set,
        askg-data:Entity-training_set,
        askg-data:Entity-video_sequences .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-111-Sentence-1114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We then generate our training and test pair in the following way, similar to that of [29]: For each image in a sequence, we randomly sample a frame number for the input image and for the target image such that they are separated by at most ±10 frames."@en ;
    askg-onto:inSentence "We then generate our training and test pair in the following way, similar to that of [29]: For each image in a sequence, we randomly sample a frame number for the input image and for the target image such that they are separated by at most ±10 frames."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-frame_number,
        askg-data:Entity-image,
        askg-data:Entity-image_sequence,
        askg-data:Entity-input_image,
        askg-data:Entity-target_image,
        askg-data:Entity-training_and_test_pair .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Figure 5. Encoder-decoder network for depth or normal prediction on KITTI. Both our depth and normal streams make use of this architecture. However, they rely on different parameters."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1121,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1122,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1123,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1124 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 5."@en ;
    askg-onto:inSentence "Figure 5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Encoder-decoder network for depth or normal prediction on KITTI."@en ;
    askg-onto:inSentence "Encoder-decoder network for depth or normal prediction on KITTI."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_or_normal_prediction,
        askg-data:Entity-encoder-decoder_network,
        askg-data:Entity-kitti .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Both our depth and normal streams make use of this architecture."@en ;
    askg-onto:inSentence "Both our depth and normal streams make use of this architecture."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architecture,
        askg-data:Entity-depth_streams,
        askg-data:Entity-normal_streams .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-112-Sentence-1124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, they rely on different parameters."@en ;
    askg-onto:inSentence "However, they rely on different parameters."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different,
        askg-data:Entity-parameters .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "ScanNet Dataset. We make use of the training, validation and test splits provided with ScanNet. In particular, we use 405 training sequences to learn our model and 312 sequences from the test set for testing. We form the inputtarget pairs in the same manner as for KITTI. In total, we use 30000 training pairs and 5000 test pairs."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1131,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1132,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1133,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1134,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1135 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "ScanNet Dataset."@en ;
    askg-onto:inSentence "ScanNet Dataset."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-scannet_dataset .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We make use of the training, validation and test splits provided with ScanNet."@en ;
    askg-onto:inSentence "We make use of the training, validation and test splits provided with ScanNet."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scannet,
        askg-data:Entity-training_validation_and_test_splits .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In particular, we use 405 training sequences to learn our model and 312 sequences from the test set for testing."@en ;
    askg-onto:inSentence "In particular, we use 405 training sequences to learn our model and 312 sequences from the test set for testing."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-test_set,
        askg-data:Entity-testing,
        askg-data:Entity-training_sequences .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We form the inputtarget pairs in the same manner as for KITTI."@en ;
    askg-onto:inSentence "We form the inputtarget pairs in the same manner as for KITTI."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inputtarget_pairs,
        askg-data:Entity-kitti .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-113-Sentence-1135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In total, we use 30000 training pairs and 5000 test pairs."@en ;
    askg-onto:inSentence "In total, we use 30000 training pairs and 5000 test pairs."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-30000_training_pairs,
        askg-data:Entity-5000_test_pairs,
        askg-data:Entity-pairs .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-114 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "We resize the images from both datasets to 224×224×3."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-114-Sentence-1141 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-114-Sentence-1141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We resize the images from both datasets to 224×224×3."@en ;
    askg-onto:inSentence "We resize the images from both datasets to 224×224×3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-images .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "to match that of [29]. To obtain the segmentation masks, we first oversegment each image into 400 SLIC [1] superpixels and cluster them into m = 16 regions, as described in Section 3.1.2. This represents a good trade-off between the accuracy of our piece-wise planar representation on the training data and the memory consumption of our method. In practice, this proved sufficient to yield realistic novel views."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1151,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1152,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1153,
        askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1154 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "to match that of [29]."@en ;
    askg-onto:inSentence "to match that of [29]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-29,
        askg-data:Entity-that .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To obtain the segmentation masks, we first oversegment each image into 400 SLIC [1] superpixels and cluster them into m = 16 regions, as described in Section 3.1.2."@en ;
    askg-onto:inSentence "To obtain the segmentation masks, we first oversegment each image into 400 SLIC [1] superpixels and cluster them into m = 16 regions, as described in Section 3.1.2."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-m__16,
        askg-data:Entity-regions,
        askg-data:Entity-slic_superpixels .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This represents a good trade-off between the accuracy of our piece-wise planar representation on the training data and the memory consumption of our method."@en ;
    askg-onto:inSentence "This represents a good trade-off between the accuracy of our piece-wise planar representation on the training data and the memory consumption of our method."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-memory_consumption,
        askg-data:Entity-method,
        askg-data:Entity-piece-wise_planar_representation,
        askg-data:Entity-training_data .

askg-data:Paper-305358d7d24f2bf4-Section-11-Paragraph-115-Sentence-1154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In practice, this proved sufficient to yield realistic novel views."@en ;
    askg-onto:inSentence "In practice, this proved sufficient to yield realistic novel views."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-novel_views,
        askg-data:Entity-realistic .

askg-data:Paper-305358d7d24f2bf4-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "4.2. Training Procedure"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-123,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-124,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-126,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-128,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-129 ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We train our model in a stage-wise manner: First, the depth and normal branches, then the selection network given fixed depth and normal branches, and finally the refinement network while rest of the framework is fixed. We tried to then fine-tune the entire network end-to-end, but did not observe any significant improvement. Training the depth and normal networks. For the indoor ScanNet dataset, we were able to directly use the network of [5], which predicts both depth and normals. This network was pre-trained on NYU-v2 [19], and we simply fine-tuned it on our data. In particular, since ScanNet does not provide ground-truth normals, we fit a plane to each SLIC superpixel, and assigned the corresponding normal to all its pixels. The fine-tuned network yields a relative depth error of 0.236. We do not report the normal error, since the ground-truth normals were obtained from the depth maps."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1211,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1212,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1213,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1214,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1215,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1216,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1217,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1218 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We train our model in a stage-wise manner: First, the depth and normal branches, then the selection network given fixed depth and normal branches, and finally the refinement network while rest of the framework is fixed."@en ;
    askg-onto:inSentence "We train our model in a stage-wise manner: First, the depth and normal branches, then the selection network given fixed depth and normal branches, and finally the refinement network while rest of the framework is fixed."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-branches,
        askg-data:Entity-fixed_depth_and_normal_branches,
        askg-data:Entity-framework,
        askg-data:Entity-model,
        askg-data:Entity-network,
        askg-data:Entity-refinement_network,
        askg-data:Entity-stage-wise_manner .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We tried to then fine-tune the entire network end-to-end, but did not observe any significant improvement."@en ;
    askg-onto:inSentence "We tried to then fine-tune the entire network end-to-end, but did not observe any significant improvement."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_significant_improvement,
        askg-data:Entity-the_entire_network .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Training the depth and normal networks."@en ;
    askg-onto:inSentence "Training the depth and normal networks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_networks,
        askg-data:Entity-normal_networks .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For the indoor ScanNet dataset, we were able to directly use the network of [5], which predicts both depth and normals."@en ;
    askg-onto:inSentence "For the indoor ScanNet dataset, we were able to directly use the network of [5], which predicts both depth and normals."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network,
        askg-data:Entity-scannet_dataset .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This network was pre-trained on NYU-v2 [19], and we simply fine-tuned it on our data."@en ;
    askg-onto:inSentence "This network was pre-trained on NYU-v2 [19], and we simply fine-tuned it on our data."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-network,
        askg-data:Entity-nyu-v2 .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In particular, since ScanNet does not provide ground-truth normals, we fit a plane to each SLIC superpixel, and assigned the corresponding normal to all its pixels."@en ;
    askg-onto:inSentence "In particular, since ScanNet does not provide ground-truth normals, we fit a plane to each SLIC superpixel, and assigned the corresponding normal to all its pixels."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_its_pixels,
        askg-data:Entity-corresponding_normal,
        askg-data:Entity-ground-truth_normals,
        askg-data:Entity-scannet,
        askg-data:Entity-slic_superpixel .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The fine-tuned network yields a relative depth error of 0.236."@en ;
    askg-onto:inSentence "The fine-tuned network yields a relative depth error of 0.236."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fine-tuned_network,
        askg-data:Entity-relative_depth_error_of_0236 .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-121-Sentence-1218 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We do not report the normal error, since the ground-truth normals were obtained from the depth maps."@en ;
    askg-onto:inSentence "We do not report the normal error, since the ground-truth normals were obtained from the depth maps."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_maps,
        askg-data:Entity-ground-truth_normals .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Note that we analyze the influence of the depth and normal prediction accuracy on our final novel view synthesis results in our results section. Training the selection network. The selection network takes the predicted depth and normals, together with the image, relative pose and seed regions, as input to synthesize the novel view. Since we do not have ground-truth labels for the selection maps, we therefore directly trained the selection network using the mean pixel `1 error as a loss. Training the refinement network. The refinement network aims to improve an initial synthesized view. We train it using the loss of Eq. 10, with λ = 0.01."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12101,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12102,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12103,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12104,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12105,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12106,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12107,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12108 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Note that we analyze the influence of the depth and normal prediction accuracy on our final novel view synthesis results in our results section."@en ;
    askg-onto:inSentence "Note that we analyze the influence of the depth and normal prediction accuracy on our final novel view synthesis results in our results section."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth,
        askg-data:Entity-final_novel_view_synthesis_results,
        askg-data:Entity-normal_prediction_accuracy .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Training the selection network."@en ;
    askg-onto:inSentence "Training the selection network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12103 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The selection network takes the predicted depth and normals, together with the image, relative pose and seed regions, as input to synthesize the novel view."@en ;
    askg-onto:inSentence "The selection network takes the predicted depth and normals, together with the image, relative pose and seed regions, as input to synthesize the novel view."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-normals,
        askg-data:Entity-novel_view,
        askg-data:Entity-predicted_depth,
        askg-data:Entity-relative_pose,
        askg-data:Entity-seed_regions,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12104 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Since we do not have ground-truth labels for the selection maps, we therefore directly trained the selection network using the mean pixel `1 error as a loss."@en ;
    askg-onto:inSentence "Since we do not have ground-truth labels for the selection maps, we therefore directly trained the selection network using the mean pixel `1 error as a loss."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mean_pixel_1_error_as_a_loss,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12105 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Training the refinement network."@en ;
    askg-onto:inSentence "Training the refinement network."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-model,
        askg-data:Entity-refinement_network .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12106 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The refinement network aims to improve an initial synthesized view."@en ;
    askg-onto:inSentence "The refinement network aims to improve an initial synthesized view."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_synthesized_view,
        askg-data:Entity-refinement_network .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12107 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We train it using the loss of Eq."@en ;
    askg-onto:inSentence "We train it using the loss of Eq."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eq,
        askg-data:Entity-loss .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1210-Sentence-12108 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "10, with λ = 0.01."@en ;
    askg-onto:inSentence "10, with λ = 0.01."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB,
        askg-data:Entity-001 .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "We implemented our model in tensorflow and trained it on two NVIDIA Tesla P100, each with 16GB memory. We used mini-batches of size 10, and employed the ADAM solver with a learning rate of 0.0001,and the default values β1 = 0.9 and β2 = 0.999. We will make our code publicly available upon acceptance of the paper."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211-Sentence-12111,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211-Sentence-12112,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211-Sentence-12113 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211-Sentence-12111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We implemented our model in tensorflow and trained it on two NVIDIA Tesla P100, each with 16GB memory."@en ;
    askg-onto:inSentence "We implemented our model in tensorflow and trained it on two NVIDIA Tesla P100, each with 16GB memory."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-16gb,
        askg-data:Entity-model,
        askg-data:Entity-nvidia_tesla_p100,
        askg-data:Entity-tensorflow .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211-Sentence-12112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We used mini-batches of size 10, and employed the ADAM solver with a learning rate of 0.0001,and the default values β1 = 0.9 and β2 = 0.999."@en ;
    askg-onto:inSentence "We used mini-batches of size 10, and employed the ADAM solver with a learning rate of 0.0001,and the default values β1 = 0.9 and β2 = 0.999."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%B21__09_and_%CE%B22__0999,
        askg-data:Entity-00001,
        askg-data:Entity-10,
        askg-data:Entity-adam_solver,
        askg-data:Entity-mini-batches .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-1211-Sentence-12113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We will make our code publicly available upon acceptance of the paper."@en ;
    askg-onto:inSentence "We will make our code publicly available upon acceptance of the paper."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-code,
        askg-data:Entity-paper .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For KITTI, we were unfortunately unable to train an equivalent model from scratch. Therefore, we relied on the simpler encoder-decoder network of Fig. 5, which is more compact and easier to train. To this end, we made use of the `1 loss for the inverse depth and of the negative inner product as a normal loss. Note that KITTI only provides sparse ground-truth depth maps. While this is sufficient to train the depth branch, it does not allow us to generate groundtruth normals as in ScanNet. To this end, we used the stereo framework of [27] to generate dense depth maps, which we"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1221,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1222,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1223,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1224,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1225,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1226,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1227 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For KITTI, we were unfortunately unable to train an equivalent model from scratch."@en ;
    askg-onto:inSentence "For KITTI, we were unfortunately unable to train an equivalent model from scratch."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti,
        askg-data:Entity-model .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Therefore, we relied on the simpler encoder-decoder network of Fig."@en ;
    askg-onto:inSentence "Therefore, we relied on the simpler encoder-decoder network of Fig."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_network,
        askg-data:Entity-model .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "5, which is more compact and easier to train."@en ;
    askg-onto:inSentence "5, which is more compact and easier to train."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5 .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To this end, we made use of the `1 loss for the inverse depth and of the negative inner product as a normal loss."@en ;
    askg-onto:inSentence "To this end, we made use of the `1 loss for the inverse depth and of the negative inner product as a normal loss."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_loss,
        askg-data:Entity-inner_product,
        askg-data:Entity-inverse_depth,
        askg-data:Entity-normal_loss .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Note that KITTI only provides sparse ground-truth depth maps."@en ;
    askg-onto:inSentence "Note that KITTI only provides sparse ground-truth depth maps."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti,
        askg-data:Entity-sparse_ground-truth_depth_maps .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1226 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "While this is sufficient to train the depth branch, it does not allow us to generate groundtruth normals as in ScanNet."@en ;
    askg-onto:inSentence "While this is sufficient to train the depth branch, it does not allow us to generate groundtruth normals as in ScanNet."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scannet,
        askg-data:Entity-training .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-122-Sentence-1227 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "To this end, we used the stereo framework of [27] to generate dense depth maps, which we"@en ;
    askg-onto:inSentence "To this end, we used the stereo framework of [27] to generate dense depth maps, which we"^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dense_depth_maps,
        askg-data:Entity-stereo_framework .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-123 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "1Note that, as discussed in Section 2, the transformation-grounded network of [20] focuses on single-object novel view synthesis."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-123-Sentence-1231 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-123-Sentence-1231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1Note that, as discussed in Section 2, the transformation-grounded network of [20] focuses on single-object novel view synthesis."@en ;
    askg-onto:inSentence "1Note that, as discussed in Section 2, the transformation-grounded network of [20] focuses on single-object novel view synthesis."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-single-object_novel_view_synthesis,
        askg-data:Entity-transformation-grounded_network .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-124 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-124-Sentence-1241 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-124-Sentence-1241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:inSentence "![6_image_0.png](6_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-company,
        askg-data:Entity-data_analysis_tools,
        askg-data:Entity-data_visualization,
        askg-data:Entity-dataset,
        askg-data:Entity-machine_learning_algorithms,
        askg-data:Entity-model,
        askg-data:Entity-new_theory,
        askg-data:Entity-publication,
        askg-data:Entity-quantum_computing,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-software,
        askg-data:Entity-statistical_principles,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Figure 6. **Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results. This is noticeable, for instance, by looking at the bottom right part of the first image and at the buildings in the other images."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125-Sentence-1251,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125-Sentence-1252,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125-Sentence-1253 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125-Sentence-1251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 6."@en ;
    askg-onto:inSentence "Figure 6."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_representation .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125-Sentence-1252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."@en ;
    askg-onto:inSentence "**Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow,
        askg-data:Entity-appearance_flow_method,
        askg-data:Entity-artifacts,
        askg-data:Entity-more_realistic_results,
        askg-data:Entity-our_approach .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-125-Sentence-1253 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This is noticeable, for instance, by looking at the bottom right part of the first image and at the buildings in the other images."@en ;
    askg-onto:inSentence "This is noticeable, for instance, by looking at the bottom right part of the first image and at the buildings in the other images."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-buildings,
        askg-data:Entity-first_image .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-126 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "| Method | `1\\-KITTI | `1\\-ScanNet | |----------------|-------------|---------------| | App. flow [29] | 0.471 | \\- | | Depth\\-branch | 0.668 | 0.217 | | Ours\\-Geo | 0.340 | 0.167 | | Ours\\-Full | 0.345 | 0.176 |"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-126-Sentence-1261,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-126-Sentence-1262 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-126-Sentence-1261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| Method | `1\\-KITTI | `1\\-ScanNet | |----------------|-------------|---------------| | App."@en ;
    askg-onto:inSentence "| Method | `1\\-KITTI | `1\\-ScanNet | |----------------|-------------|---------------| | App."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1-kitti,
        askg-data:Entity-1-scannet,
        askg-data:Entity-method .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-126-Sentence-1262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "flow [29] | 0.471 | \\- | | Depth\\-branch | 0.668 | 0.217 | | Ours\\-Geo | 0.340 | 0.167 | | Ours\\-Full | 0.345 | 0.176 |"@en ;
    askg-onto:inSentence "flow [29] | 0.471 | \\- | | Depth\\-branch | 0.668 | 0.217 | | Ours\\-Geo | 0.340 | 0.167 | | Ours\\-Full | 0.345 | 0.176 |"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0340,
        askg-data:Entity-0345,
        askg-data:Entity-0471,
        askg-data:Entity-0668,
        askg-data:Entity-depth-branch,
        askg-data:Entity-flow,
        askg-data:Entity-ours-full,
        askg-data:Entity-ours-geo .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Table 1. **Quantitative evaluation on KITTI and ScanNet.** We compare our approach with the state-of-the-art method of [29] and our baseline based on our depth estimates. Our approach signif-"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127-Sentence-1271,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127-Sentence-1272,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127-Sentence-1273 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127-Sentence-1271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 1."@en ;
    askg-onto:inSentence "Table 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127-Sentence-1272 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Quantitative evaluation on KITTI and ScanNet.** We compare our approach with the state-of-the-art method of [29] and our baseline based on our depth estimates."@en ;
    askg-onto:inSentence "**Quantitative evaluation on KITTI and ScanNet.** We compare our approach with the state-of-the-art method of [29] and our baseline based on our depth estimates."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_estimates,
        askg-data:Entity-kitti,
        askg-data:Entity-our_approach,
        askg-data:Entity-our_baseline,
        askg-data:Entity-quantitative_evaluation,
        askg-data:Entity-scannet,
        askg-data:Entity-state-of-the-art_method .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-127-Sentence-1273 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our approach signif-"@en ;
    askg-onto:inSentence "Our approach signif-"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_approach .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-128 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "icantly outperforms the baselines, thus achieving state-of-the-art performance on these datasets."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-128-Sentence-1281 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-128-Sentence-1281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "icantly outperforms the baselines, thus achieving state-of-the-art performance on these datasets."@en ;
    askg-onto:inSentence "icantly outperforms the baselines, thus achieving state-of-the-art performance on these datasets."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-datasets,
        askg-data:Entity-state-of-the-art_performance .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-129 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "used, in turn, to obtain normal maps using superpixels. The final depth network yields a relative error of 0.274."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-129-Sentence-1291,
        askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-129-Sentence-1292 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-129-Sentence-1291 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "used, in turn, to obtain normal maps using superpixels."@en ;
    askg-onto:inSentence "used, in turn, to obtain normal maps using superpixels."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-normal_maps,
        askg-data:Entity-superpixels .

askg-data:Paper-305358d7d24f2bf4-Section-12-Paragraph-129-Sentence-1292 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The final depth network yields a relative error of 0.274."@en ;
    askg-onto:inSentence "The final depth network yields a relative error of 0.274."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-final_depth_network,
        askg-data:Entity-relative_error_of_0274 .

askg-data:Paper-305358d7d24f2bf4-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "4.3. Results"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1310,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-133,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-134,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-135,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-136,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-138,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Table 1, we compare our approach, both without (Ours-Geo) and with (Ours-Full) refinement network, with the state-of-the-art appearance flow technique of [29] on KITTI and ScanNet, based on the mean pixel `1 error metric. Note that our approach outperforms the baseline that uses our depth estimates, without explicitly modeling the scene structure, by a large margin. This evidences the importance of accounting for 3D scene structure. Our approach also significantly outperforms the state-of-the-art appearance flow method on KITTI.2 This again shows the benefits of modeling geometry, as done by our region-aware geometric-transform network. Interestingly, the refinement network tends to slightly degrade the novel view accuracy."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1312,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1313,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1314,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1315 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Table 1, we compare our approach, both without (Ours-Geo) and with (Ours-Full) refinement network, with the state-of-the-art appearance flow technique of [29] on KITTI and ScanNet, based on the mean pixel `1 error metric."@en ;
    askg-onto:inSentence "In Table 1, we compare our approach, both without (Ours-Geo) and with (Ours-Full) refinement network, with the state-of-the-art appearance flow technique of [29] on KITTI and ScanNet, based on the mean pixel `1 error metric."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti,
        askg-data:Entity-mean_pixel_1_error_metric,
        askg-data:Entity-our_approach,
        askg-data:Entity-scannet,
        askg-data:Entity-state-of-the-art_appearance_flow_technique .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that our approach outperforms the baseline that uses our depth estimates, without explicitly modeling the scene structure, by a large margin."@en ;
    askg-onto:inSentence "Note that our approach outperforms the baseline that uses our depth estimates, without explicitly modeling the scene structure, by a large margin."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-baseline .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This evidences the importance of accounting for 3D scene structure."@en ;
    askg-onto:inSentence "This evidences the importance of accounting for 3D scene structure."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_scene_structure,
        askg-data:Entity-evidence .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our approach also significantly outperforms the state-of-the-art appearance flow method on KITTI.2 This again shows the benefits of modeling geometry, as done by our region-aware geometric-transform network."@en ;
    askg-onto:inSentence "Our approach also significantly outperforms the state-of-the-art appearance flow method on KITTI.2 This again shows the benefits of modeling geometry, as done by our region-aware geometric-transform network."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow_method,
        askg-data:Entity-kitti,
        askg-data:Entity-modeling_geometry,
        askg-data:Entity-region-aware_geometric-transform_network .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-131-Sentence-1315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Interestingly, the refinement network tends to slightly degrade the novel view accuracy."@en ;
    askg-onto:inSentence "Interestingly, the refinement network tends to slightly degrade the novel view accuracy."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-novel_view_accuracy,
        askg-data:Entity-refinement_network .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1310 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "tion map and selection map overlaid on the input image, showing that the corresponding region is close to planar. Red indicates a high likelihood for a pixel to belong to the plane defined by the seed region and blue to a low likelihood."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1310-Sentence-13101,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1310-Sentence-13102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1310-Sentence-13101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "tion map and selection map overlaid on the input image, showing that the corresponding region is close to planar."@en ;
    askg-onto:inSentence "tion map and selection map overlaid on the input image, showing that the corresponding region is close to planar."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planar,
        askg-data:Entity-region .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1310-Sentence-13102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Red indicates a high likelihood for a pixel to belong to the plane defined by the seed region and blue to a low likelihood."@en ;
    askg-onto:inSentence "Red indicates a high likelihood for a pixel to belong to the plane defined by the seed region and blue to a low likelihood."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pixel,
        askg-data:Entity-plane,
        askg-data:Entity-plane_defined_by_the_seed_region,
        askg-data:Entity-seed_region .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "In Fig. 13, we illustrate what the selection network learns. To this end, we show the initial seed region overlaid with input image, and the likelihood of the pixels to be associated to this plane, predicted by the selection network. From the examples, we can see that the selection network extends the initial seed regions to larger planes of semantically and visually coherent pixels, such as a larger tree regions."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13111,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13112,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13113,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13114 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Fig."@en ;
    askg-onto:inSentence "In Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "13, we illustrate what the selection network learns."@en ;
    askg-onto:inSentence "13, we illustrate what the selection network learns."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-selection_network,
        askg-data:Entity-what .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To this end, we show the initial seed region overlaid with input image, and the likelihood of the pixels to be associated to this plane, predicted by the selection network."@en ;
    askg-onto:inSentence "To this end, we show the initial seed region overlaid with input image, and the likelihood of the pixels to be associated to this plane, predicted by the selection network."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_seed_region,
        askg-data:Entity-input_image,
        askg-data:Entity-likelihood_of_the_pixels,
        askg-data:Entity-pixels,
        askg-data:Entity-selection_network,
        askg-data:Entity-this_plane .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-1311-Sentence-13114 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "From the examples, we can see that the selection network extends the initial seed regions to larger planes of semantically and visually coherent pixels, such as a larger tree regions."@en ;
    askg-onto:inSentence "From the examples, we can see that the selection network extends the initial seed regions to larger planes of semantically and visually coherent pixels, such as a larger tree regions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_seed_regions,
        askg-data:Entity-larger_planes_of_semantically_and_visually_coherent_pixels,
        askg-data:Entity-larger_tree_regions,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "However, when looking at the qualitative comparison in Figs. 1, 6 and 7, we can see that our complete model (Ours- Full) yields more realistic novel views than both Ours-Geo and appearance flow [29]. Note that, by not leveraging structure, appearance flow yields to unrealistic artifacts. By contrast, the results of our approach that exploits 3D geometry look more natural. This, for instance, can be observed"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1321,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1322,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1323,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1324,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1325 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "However, when looking at the qualitative comparison in Figs."@en ;
    askg-onto:inSentence "However, when looking at the qualitative comparison in Figs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finding,
        askg-data:Entity-qualitative_comparison .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "1, 6 and 7, we can see that our complete model (Ours- Full) yields more realistic novel views than both Ours-Geo and appearance flow [29]."@en ;
    askg-onto:inSentence "1, 6 and 7, we can see that our complete model (Ours- Full) yields more realistic novel views than both Ours-Geo and appearance flow [29]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow,
        askg-data:Entity-more_realistic_novel_views,
        askg-data:Entity-ours-_full,
        askg-data:Entity-ours-geo .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Note that, by not leveraging structure, appearance flow yields to unrealistic artifacts."@en ;
    askg-onto:inSentence "Note that, by not leveraging structure, appearance flow yields to unrealistic artifacts."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow,
        askg-data:Entity-unrealistic_artifacts .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "By contrast, the results of our approach that exploits 3D geometry look more natural."@en ;
    askg-onto:inSentence "By contrast, the results of our approach that exploits 3D geometry look more natural."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-natural_results,
        askg-data:Entity-our_approach .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-132-Sentence-1325 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This, for instance, can be observed"@en ;
    askg-onto:inSentence "This, for instance, can be observed"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-instance,
        askg-data:Entity-this .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-133 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "2Note that, because the training code for appearance flow is not available, we had to re-implement it, and despite confirming that our implementation was correct using the KITTI dataset, we were unable to make training converge on ScanNet."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-133-Sentence-1331 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-133-Sentence-1331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2Note that, because the training code for appearance flow is not available, we had to re-implement it, and despite confirming that our implementation was correct using the KITTI dataset, we were unable to make training converge on ScanNet."@en ;
    askg-onto:inSentence "2Note that, because the training code for appearance flow is not available, we had to re-implement it, and despite confirming that our implementation was correct using the KITTI dataset, we were unable to make training converge on ScanNet."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow,
        askg-data:Entity-kitti_dataset,
        askg-data:Entity-our_implementation,
        askg-data:Entity-scannet,
        askg-data:Entity-training_code .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-134 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-134-Sentence-1341 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-134-Sentence-1341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![7_image_0.png](7_image_0.png)"@en ;
    askg-onto:inSentence "![7_image_0.png](7_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bert,
        askg-data:Entity-company,
        askg-data:Entity-covid-19,
        askg-data:Entity-crispr,
        askg-data:Entity-data_science,
        askg-data:Entity-deep_learning,
        askg-data:Entity-disease,
        askg-data:Entity-field,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-neural_networks,
        askg-data:Entity-openai,
        askg-data:Entity-publication,
        askg-data:Entity-research_paper,
        askg-data:Entity-software,
        askg-data:Entity-stanford_university,
        askg-data:Entity-technology,
        askg-data:Entity-tensorflow,
        askg-data:Entity-theory,
        askg-data:Entity-university,
        askg-data:Entity-university_of_california .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-135 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Figure 7. **Qualitative results of our approach on ScanNet.**"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-135-Sentence-1351,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-135-Sentence-1352 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-135-Sentence-1351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 7."@en ;
    askg-onto:inSentence "Figure 7."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-figure_7 .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-135-Sentence-1352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Qualitative results of our approach on ScanNet.**"@en ;
    askg-onto:inSentence "**Qualitative results of our approach on ScanNet.**"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_approach,
        askg-data:Entity-scannet .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-136 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "| gtDep | gtNor | estDep | estNor | Seed | SelMap | `1 | |---------|---------|----------|----------|--------|----------|-------| | ✓ | ✓ | ✗ | ✗ | ✓ | ✗ | 0.357 | | ✓ | ✓ | ✗ | ✗ | ✗ | ✓ | 0.329 | | ✗ | ✗ | ✓ | ✓ | ✓ | ✗ | 0.373 | | ✗ | ✗ | ✓ | ✓ | ✗ | ✓ | 0.340 |"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-136-Sentence-1361 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-136-Sentence-1361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| gtDep | gtNor | estDep | estNor | Seed | SelMap | `1 | |---------|---------|----------|----------|--------|----------|-------| | ✓ | ✓ | ✗ | ✗ | ✓ | ✗ | 0.357 | | ✓ | ✓ | ✗ | ✗ | ✗ | ✓ | 0.329 | | ✗ | ✗ | ✓ | ✓ | ✓ | ✗ | 0.373 | | ✗ | ✗ | ✓ | ✓ | ✗ | ✓ | 0.340 |"@en ;
    askg-onto:inSentence "| gtDep | gtNor | estDep | estNor | Seed | SelMap | `1 | |---------|---------|----------|----------|--------|----------|-------| | ✓ | ✓ | ✗ | ✗ | ✓ | ✗ | 0.357 | | ✓ | ✓ | ✗ | ✗ | ✗ | ✓ | 0.329 | | ✗ | ✗ | ✓ | ✓ | ✓ | ✗ | 0.373 | | ✗ | ✗ | ✓ | ✓ | ✗ | ✓ | 0.340 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0329,
        askg-data:Entity-0340,
        askg-data:Entity-0357,
        askg-data:Entity-0373,
        askg-data:Entity-estdep,
        askg-data:Entity-estnor,
        askg-data:Entity-gtdep,
        askg-data:Entity-gtnor .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Table 2. Influence of the quality of the depth and normal estimates and of learning the selection maps on KITTI. From left to right: gtDep and gtNor denote the ground-truth depth and normals, respectively; estDep and estNor denote the estimated depth and normals, respectively; Seed and SelMap denote the hardsegmentations corresponding to the seed region and the selection maps obtained with our selection network, respectively."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137-Sentence-1371,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137-Sentence-1372,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137-Sentence-1373 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137-Sentence-1371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 2."@en ;
    askg-onto:inSentence "Table 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_2,
        askg-data:Entity-triple_data .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137-Sentence-1372 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Influence of the quality of the depth and normal estimates and of learning the selection maps on KITTI."@en ;
    askg-onto:inSentence "Influence of the quality of the depth and normal estimates and of learning the selection maps on KITTI."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti,
        askg-data:Entity-quality_of_the_depth_and_normal_estimates .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-137-Sentence-1373 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "From left to right: gtDep and gtNor denote the ground-truth depth and normals, respectively; estDep and estNor denote the estimated depth and normals, respectively; Seed and SelMap denote the hardsegmentations corresponding to the seed region and the selection maps obtained with our selection network, respectively."@en ;
    askg-onto:inSentence "From left to right: gtDep and gtNor denote the ground-truth depth and normals, respectively; estDep and estNor denote the estimated depth and normals, respectively; Seed and SelMap denote the hardsegmentations corresponding to the seed region and the selection maps obtained with our selection network, respectively."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-estdep,
        askg-data:Entity-estimated_depth,
        askg-data:Entity-estimated_normals,
        askg-data:Entity-estnor,
        askg-data:Entity-ground-truth_depth,
        askg-data:Entity-ground-truth_normals,
        askg-data:Entity-gtdep,
        askg-data:Entity-gtnor,
        askg-data:Entity-hard-segmentations,
        askg-data:Entity-seed,
        askg-data:Entity-selection_maps,
        askg-data:Entity-selection_network,
        askg-data:Entity-selmap .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-138 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "by looking at the bottom-right corner of the first image in Fig. 6, where we better model the shape of the object, and at the buildings in the other images."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-138-Sentence-1381,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-138-Sentence-1382 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-138-Sentence-1381 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "by looking at the bottom-right corner of the first image in Fig."@en ;
    askg-onto:inSentence "by looking at the bottom-right corner of the first image in Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-image .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-138-Sentence-1382 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "6, where we better model the shape of the object, and at the buildings in the other images."@en ;
    askg-onto:inSentence "6, where we better model the shape of the object, and at the buildings in the other images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-object,
        askg-data:Entity-shape .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "In Table 2, we analyze the influence of the quality of the depth and normal estimates, and the effect of learning the selection maps. In particular, we compare the error obtained when using the ground-truth depth and normals instead of the predicted ones, and when using the seed regions as 'hard' segmentation masks instead of the learnt selection maps. In both cases, the best results are obtained by using the ground-truth depth and normals in conjunction with our selection maps, followed by using the estimated depth and normals with our selection maps. This shows (i) the importance of learning the combination of the multiple synthesized candidates; and (ii) that the results of our approach will further improve as progress in single-image depth and normal prediction is made. A similar table for ScanNet is provided in the supplementary material."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1391,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1392,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1393,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1394,
        askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1395 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1391 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Table 2, we analyze the influence of the quality of the depth and normal estimates, and the effect of learning the selection maps."@en ;
    askg-onto:inSentence "In Table 2, we analyze the influence of the quality of the depth and normal estimates, and the effect of learning the selection maps."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-quality_of_the_depth_and_normal_estimates,
        askg-data:Entity-selection_maps .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1392 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In particular, we compare the error obtained when using the ground-truth depth and normals instead of the predicted ones, and when using the seed regions as 'hard' segmentation masks instead of the learnt selection maps."@en ;
    askg-onto:inSentence "In particular, we compare the error obtained when using the ground-truth depth and normals instead of the predicted ones, and when using the seed regions as 'hard' segmentation masks instead of the learnt selection maps."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_depth,
        askg-data:Entity-learnt_selection_maps,
        askg-data:Entity-predicted_ones,
        askg-data:Entity-seed_regions,
        askg-data:Entity-segmentation_masks .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1393 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In both cases, the best results are obtained by using the ground-truth depth and normals in conjunction with our selection maps, followed by using the estimated depth and normals with our selection maps."@en ;
    askg-onto:inSentence "In both cases, the best results are obtained by using the ground-truth depth and normals in conjunction with our selection maps, followed by using the estimated depth and normals with our selection maps."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-estimated_depth,
        askg-data:Entity-ground-truth_depth,
        askg-data:Entity-normals,
        askg-data:Entity-selection_maps .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1394 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This shows (i) the importance of learning the combination of the multiple synthesized candidates; and (ii) that the results of our approach will further improve as progress in single-image depth and normal prediction is made."@en ;
    askg-onto:inSentence "This shows (i) the importance of learning the combination of the multiple synthesized candidates; and (ii) that the results of our approach will further improve as progress in single-image depth and normal prediction is made."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-multiple_synthesized_candidates,
        askg-data:Entity-results_of_our_approach,
        askg-data:Entity-single-image_depth_and_normal_prediction .

askg-data:Paper-305358d7d24f2bf4-Section-13-Paragraph-139-Sentence-1395 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "A similar table for ScanNet is provided in the supplementary material."@en ;
    askg-onto:inSentence "A similar table for ScanNet is provided in the supplementary material."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scannet,
        askg-data:Entity-supplementary_material .

askg-data:Paper-305358d7d24f2bf4-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "5. Conclusion"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141,
        askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-142 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We have introduced a geometry-aware deep learning framework for novel view synthesis from a single image. Our approach models the scene with a fixed number of planes, and learns to predict homographies, which, in conjunction with a predicted selection map and a desired relative pose, let us generate the novel view. Our experiments on the challenging KIITI and ScanNet datasets have demonstrated the benefits of our approach; by leveraging 3D geometry, our method yields predictions that better match the scene structure, and thus outperforms the state-of-the-art single-image novel view synthesis techniques. Training the depth branch of our framework currently relies on groundtruth depth maps. In the future, we will investigate the use of weakly-supervised depth prediction methods [8, 10, 28] that only exploit two views to perform this task."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1411,
        askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1412,
        askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1413,
        askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1414,
        askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1415 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We have introduced a geometry-aware deep learning framework for novel view synthesis from a single image."@en ;
    askg-onto:inSentence "We have introduced a geometry-aware deep learning framework for novel view synthesis from a single image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometry-aware_deep_learning_framework,
        askg-data:Entity-novel_view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Our approach models the scene with a fixed number of planes, and learns to predict homographies, which, in conjunction with a predicted selection map and a desired relative pose, let us generate the novel view."@en ;
    askg-onto:inSentence "Our approach models the scene with a fixed number of planes, and learns to predict homographies, which, in conjunction with a predicted selection map and a desired relative pose, let us generate the novel view."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-desired_relative_pose,
        askg-data:Entity-fixed_number_of_planes,
        askg-data:Entity-homographies,
        askg-data:Entity-novel_view,
        askg-data:Entity-predicted_selection_map,
        askg-data:Entity-scene .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our experiments on the challenging KIITI and ScanNet datasets have demonstrated the benefits of our approach; by leveraging 3D geometry, our method yields predictions that better match the scene structure, and thus outperforms the state-of-the-art single-image novel view synthesis techniques."@en ;
    askg-onto:inSentence "Our experiments on the challenging KIITI and ScanNet datasets have demonstrated the benefits of our approach; by leveraging 3D geometry, our method yields predictions that better match the scene structure, and thus outperforms the state-of-the-art single-image novel view synthesis techniques."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-experiments,
        askg-data:Entity-kiiti,
        askg-data:Entity-our_method,
        askg-data:Entity-predictions,
        askg-data:Entity-scannet,
        askg-data:Entity-scene_structure,
        askg-data:Entity-state-of-the-art_single-image_novel_view_synthesis_techniques .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Training the depth branch of our framework currently relies on groundtruth depth maps."@en ;
    askg-onto:inSentence "Training the depth branch of our framework currently relies on groundtruth depth maps."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_branch,
        askg-data:Entity-groundtruth_depth_maps .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-141-Sentence-1415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "In the future, we will investigate the use of weakly-supervised depth prediction methods [8, 10, 28] that only exploit two views to perform this task."@en ;
    askg-onto:inSentence "In the future, we will investigate the use of weakly-supervised depth prediction methods [8, 10, 28] that only exploit two views to perform this task."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-two_views,
        askg-data:Entity-weakly-supervised_depth_prediction_methods .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-142 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Acknowledgments This work was done when the first author was working in Data61, CSIRO, Australia.The Titan X used for this research was donated by the NVIDIA Corporation."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-142-Sentence-1421 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-14-Paragraph-142-Sentence-1421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Acknowledgments This work was done when the first author was working in Data61, CSIRO, Australia.The Titan X used for this research was donated by the NVIDIA Corporation."@en ;
    askg-onto:inSentence "Acknowledgments This work was done when the first author was working in Data61, CSIRO, Australia.The Titan X used for this research was donated by the NVIDIA Corporation."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-australia,
        askg-data:Entity-company,
        askg-data:Entity-csiro,
        askg-data:Entity-data61,
        askg-data:Entity-first_author,
        askg-data:Entity-nvidia_corporation,
        askg-data:Entity-research,
        askg-data:Entity-titan_x .

askg-data:Paper-305358d7d24f2bf4-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "References"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "[1] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Susstrunk. Slic superpixels compared to state-of-the-art ¨ superpixel methods. *IEEE transactions on pattern analysis* and machine intelligence, 34(11):2274–2282, 2012. 5, 6 [2] G. Chaurasia, S. Duchene, O. Sorkine-Hornung, and G. Drettakis. Depth synthesis and local warps for plausible image-based navigation. ACM Transactions on Graphics (TOG), 32(3):30, 2013. 1, 2 [3] Q. Chen and V. Koltun. Photographic image synthesis with cascaded refinement networks. In *ICCV*, 2017. 6 [4] A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, and M. Nießner. Scannet: Richly-annotated 3d reconstructions of indoor scenes. In *Proc. Computer Vision and Pattern* Recognition (CVPR), IEEE, 2017. 2, 6 [5] D. Eigen and R. Fergus. Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture. In Proceedings of the IEEE International Conference on Computer Vision, pages 2650–2658, 2015. 6 [6] J. Flynn, I. Neulander, J. Philbin, and N. Snavely. Deepstereo: Learning to predict new views from the world's imagery. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5515–5524, 2016. 1, 2 [7] Y. Furukawa and J. Ponce. Accurate, dense, and robust multiview stereopsis. IEEE transactions on pattern analysis and machine intelligence, 32(8):1362–1376, 2010. 2 [8] R. Garg, G. Carneiro, and I. Reid. Unsupervised cnn for single view depth estimation: Geometry to the rescue. In European Conference on Computer Vision, pages 740–756. Springer, 2016. 3, 8 [9] A. Geiger, P. Lenz, and R. Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR), 2012. 2, 6 [10] C. Godard, O. Mac Aodha, and G. J. Brostow. Unsupervised monocular depth estimation with left-right consistency. arXiv preprint arXiv:1609.03677, 2016. 8 [11] B. Hariharan, P. Arbelaez, R. Girshick, and J. Malik. Hyper- ´ columns for object segmentation and fine-grained localization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 447–456, 2015. 5 [12] D. Hoiem, A. A. Efros, and M. Hebert. Automatic photo pop-up. *ACM transactions on graphics (TOG)*, 24(3):577– 584, 2005. 1, 2 [13] Y. Horry, K.-I. Anjyo, and K. Arai. Tour into the picture: using a spidery mesh interface to make animation from a single image. In *Proceedings of the 24th annual conference on* Computer graphics and interactive techniques, pages 225– 232. ACM Press/Addison-Wesley Publishing Co., 1997. 1, 2 [14] M. Jaderberg, K. Simonyan, A. Zisserman, and K. Kavukcuoglu. Spatial transformer networks. In Advances in Neural Information Processing Systems, pages 2017–2025, 2015. 5 [15] D. Ji, J. Kwon, M. McFarland, and S. Savarese. Deep view morphing. In Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, 2017. 2 [16] T. D. Kulkarni, W. F. Whitney, P. Kohli, and J. Tenenbaum."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1511,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15110,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151100,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151101,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151102,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151103,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151104,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151105,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151106,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151107,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151108,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151109,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15111,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151110,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151111,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151112,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151113,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15112,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15113,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15114,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15115,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15116,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15117,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15118,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15119,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1512,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15120,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15121,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15122,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15123,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15124,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15125,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15126,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15127,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15128,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15129,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1513,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15130,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15131,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15132,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15133,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15134,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15135,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15136,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15137,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15138,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15139,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1514,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15140,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15141,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15142,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15143,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15144,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15145,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15146,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15147,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15148,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15149,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1515,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15150,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15151,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15152,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15153,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15154,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15155,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15156,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15157,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15158,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15159,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1516,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15160,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15161,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15162,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15163,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15164,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15165,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15166,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15167,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15168,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15169,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1517,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15170,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15171,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15172,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15173,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15174,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15175,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15176,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15177,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15178,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15179,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1518,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15180,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15181,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15182,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15183,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15184,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15185,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15186,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15187,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15188,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15189,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1519,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15190,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15191,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15192,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15193,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15194,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15195,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15196,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15197,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15198,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15199 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[1] R."@en ;
    askg-onto:inSentence "[1] R."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-r .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "5, 6 [2] G."@en ;
    askg-onto:inSentence "5, 6 [2] G."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_6_2,
        askg-data:Entity-g .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151100 a askg-onto:Sentence ;
    rdfs:label "Sentence 100"@en ;
    domo:Text "Ji, J."@en ;
    askg-onto:inSentence "Ji, J."^^xsd:string ;
    askg-onto:index "100"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ji_j,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151101 a askg-onto:Sentence ;
    rdfs:label "Sentence 101"@en ;
    domo:Text "Kwon, M."@en ;
    askg-onto:inSentence "Kwon, M."^^xsd:string ;
    askg-onto:index "101"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kwon_m,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151102 a askg-onto:Sentence ;
    rdfs:label "Sentence 102"@en ;
    domo:Text "McFarland, and S."@en ;
    askg-onto:inSentence "McFarland, and S."^^xsd:string ;
    askg-onto:index "102"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mcfarland,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151103 a askg-onto:Sentence ;
    rdfs:label "Sentence 103"@en ;
    domo:Text "Savarese."@en ;
    askg-onto:inSentence "Savarese."^^xsd:string ;
    askg-onto:index "103"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-savarese .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151104 a askg-onto:Sentence ;
    rdfs:label "Sentence 104"@en ;
    domo:Text "Deep view morphing."@en ;
    askg-onto:inSentence "Deep view morphing."^^xsd:string ;
    askg-onto:index "104"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_view_morphing,
        askg-data:Entity-technique .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151105 a askg-onto:Sentence ;
    rdfs:label "Sentence 105"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "105"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151106 a askg-onto:Sentence ;
    rdfs:label "Sentence 106"@en ;
    domo:Text "Computer Vision and Pattern Recognition (CVPR), IEEE, 2017."@en ;
    askg-onto:inSentence "Computer Vision and Pattern Recognition (CVPR), IEEE, 2017."^^xsd:string ;
    askg-onto:index "106"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision_and_pattern_recognition_cvpr,
        askg-data:Entity-cvpr,
        askg-data:Entity-ieee,
        askg-data:Entity-organization,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151107 a askg-onto:Sentence ;
    rdfs:label "Sentence 107"@en ;
    domo:Text "2 [16] T."@en ;
    askg-onto:inSentence "2 [16] T."^^xsd:string ;
    askg-onto:index "107"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2_16,
        askg-data:Entity-t .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151108 a askg-onto:Sentence ;
    rdfs:label "Sentence 108"@en ;
    domo:Text "D."@en ;
    askg-onto:inSentence "D."^^xsd:string ;
    askg-onto:index "108"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151109 a askg-onto:Sentence ;
    rdfs:label "Sentence 109"@en ;
    domo:Text "Kulkarni, W."@en ;
    askg-onto:inSentence "Kulkarni, W."^^xsd:string ;
    askg-onto:index "109"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kulkarni_w,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Chaurasia, S."@en ;
    askg-onto:inSentence "Chaurasia, S."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chaurasia_s,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151110 a askg-onto:Sentence ;
    rdfs:label "Sentence 110"@en ;
    domo:Text "F."@en ;
    askg-onto:inSentence "F."^^xsd:string ;
    askg-onto:index "110"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-f,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151111 a askg-onto:Sentence ;
    rdfs:label "Sentence 111"@en ;
    domo:Text "Whitney, P."@en ;
    askg-onto:inSentence "Whitney, P."^^xsd:string ;
    askg-onto:index "111"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-whitney_p .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151112 a askg-onto:Sentence ;
    rdfs:label "Sentence 112"@en ;
    domo:Text "Kohli, and J."@en ;
    askg-onto:inSentence "Kohli, and J."^^xsd:string ;
    askg-onto:index "112"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kohli,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-151113 a askg-onto:Sentence ;
    rdfs:label "Sentence 113"@en ;
    domo:Text "Tenenbaum."@en ;
    askg-onto:inSentence "Tenenbaum."^^xsd:string ;
    askg-onto:index "113"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-tenenbaum .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Duchene, O."@en ;
    askg-onto:inSentence "Duchene, O."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-duchene_o,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Sorkine-Hornung, and G."@en ;
    askg-onto:inSentence "Sorkine-Hornung, and G."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-person,
        askg-data:Entity-sorkine-hornung .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Drettakis."@en ;
    askg-onto:inSentence "Drettakis."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-drettakis,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Depth synthesis and local warps for plausible image-based navigation."@en ;
    askg-onto:inSentence "Depth synthesis and local warps for plausible image-based navigation."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_synthesis,
        askg-data:Entity-plausible_image-based_navigation .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "ACM Transactions on Graphics (TOG), 32(3):30, 2013."@en ;
    askg-onto:inSentence "ACM Transactions on Graphics (TOG), 32(3):30, 2013."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2013,
        askg-data:Entity-3,
        askg-data:Entity-30,
        askg-data:Entity-32,
        askg-data:Entity-acm_transactions_on_graphics,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15117 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "1, 2 [3] Q."@en ;
    askg-onto:inSentence "1, 2 [3] Q."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_3,
        askg-data:Entity-q .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15118 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Chen and V."@en ;
    askg-onto:inSentence "Chen and V."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chen,
        askg-data:Entity-person,
        askg-data:Entity-v .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15119 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Koltun."@en ;
    askg-onto:inSentence "Koltun."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-koltun,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Achanta, A."@en ;
    askg-onto:inSentence "Achanta, A."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achanta_a,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15120 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Photographic image synthesis with cascaded refinement networks."@en ;
    askg-onto:inSentence "Photographic image synthesis with cascaded refinement networks."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cascaded_refinement_networks,
        askg-data:Entity-photographic_image_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15121 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "In *ICCV*, 2017."@en ;
    askg-onto:inSentence "In *ICCV*, 2017."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-iccv,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15122 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "6 [4] A."@en ;
    askg-onto:inSentence "6 [4] A."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6,
        askg-data:Entity-a .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15123 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Dai, A."@en ;
    askg-onto:inSentence "Dai, A."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dai_a,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15124 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "X."@en ;
    askg-onto:inSentence "X."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-x .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15125 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Chang, M."@en ;
    askg-onto:inSentence "Chang, M."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-chang_m,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15126 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Savva, M."@en ;
    askg-onto:inSentence "Savva, M."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-savva_m,
        askg-data:Entity-unspecified_publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15127 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Halber, T."@en ;
    askg-onto:inSentence "Halber, T."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-halber_t,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15128 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "Funkhouser, and M."@en ;
    askg-onto:inSentence "Funkhouser, and M."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-funkhouser,
        askg-data:Entity-m,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15129 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Nießner."@en ;
    askg-onto:inSentence "Nießner."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nie%C3%9Fner,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Shaji, K."@en ;
    askg-onto:inSentence "Shaji, K."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-shaji_k .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15130 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "Scannet: Richly-annotated 3d reconstructions of indoor scenes."@en ;
    askg-onto:inSentence "Scannet: Richly-annotated 3d reconstructions of indoor scenes."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-scannet .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15131 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "In *Proc."@en ;
    askg-onto:inSentence "In *Proc."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15132 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "Computer Vision and Pattern* Recognition (CVPR), IEEE, 2017."@en ;
    askg-onto:inSentence "Computer Vision and Pattern* Recognition (CVPR), IEEE, 2017."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-computer_vision_and_pattern_recognition,
        askg-data:Entity-cvpr,
        askg-data:Entity-ieee .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15133 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "2, 6 [5] D."@en ;
    askg-onto:inSentence "2, 6 [5] D."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15134 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "Eigen and R."@en ;
    askg-onto:inSentence "Eigen and R."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eigen,
        askg-data:Entity-person,
        askg-data:Entity-r,
        askg-data:Entity-software .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15135 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Fergus."@en ;
    askg-onto:inSentence "Fergus."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fergus,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15136 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture."@en ;
    askg-onto:inSentence "Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth,
        askg-data:Entity-multi-scale_convolutional_architecture,
        askg-data:Entity-semantic_labels,
        askg-data:Entity-surface_normals .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15137 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "In Proceedings of the IEEE International Conference on Computer Vision, pages 2650–2658, 2015."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE International Conference on Computer Vision, pages 2650–2658, 2015."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15138 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "6 [6] J."@en ;
    askg-onto:inSentence "6 [6] J."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15139 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "Flynn, I."@en ;
    askg-onto:inSentence "Flynn, I."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-flynn_i,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Smith, A."@en ;
    askg-onto:inSentence "Smith, A."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-smith_a .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15140 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "Neulander, J."@en ;
    askg-onto:inSentence "Neulander, J."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-neulander_j,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15141 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Philbin, and N."@en ;
    askg-onto:inSentence "Philbin, and N."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-philbin .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15142 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "Snavely."@en ;
    askg-onto:inSentence "Snavely."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-snavely .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15143 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "Deepstereo: Learning to predict new views from the world's imagery."@en ;
    askg-onto:inSentence "Deepstereo: Learning to predict new views from the world's imagery."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_model_for_predicting_new_views_from_imagery,
        askg-data:Entity-deepstereo .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15144 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5515–5524, 2016."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5515–5524, 2016."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-proceedings,
        askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15145 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "1, 2 [7] Y."@en ;
    askg-onto:inSentence "1, 2 [7] Y."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_7,
        askg-data:Entity-y .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15146 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "Furukawa and J."@en ;
    askg-onto:inSentence "Furukawa and J."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-furukawa,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15147 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "Ponce."@en ;
    askg-onto:inSentence "Ponce."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-ponce .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15148 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "Accurate, dense, and robust multiview stereopsis."@en ;
    askg-onto:inSentence "Accurate, dense, and robust multiview stereopsis."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-multiview_stereopsis .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15149 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "IEEE transactions on pattern analysis and machine intelligence, 32(8):1362–1376, 2010."@en ;
    askg-onto:inSentence "IEEE transactions on pattern analysis and machine intelligence, 32(8):1362–1376, 2010."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Lucchi, P."@en ;
    askg-onto:inSentence "Lucchi, P."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lucchi_p,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15150 a askg-onto:Sentence ;
    rdfs:label "Sentence 50"@en ;
    domo:Text "2 [8] R."@en ;
    askg-onto:inSentence "2 [8] R."^^xsd:string ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2,
        askg-data:Entity-r .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15151 a askg-onto:Sentence ;
    rdfs:label "Sentence 51"@en ;
    domo:Text "Garg, G."@en ;
    askg-onto:inSentence "Garg, G."^^xsd:string ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-garg_g,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15152 a askg-onto:Sentence ;
    rdfs:label "Sentence 52"@en ;
    domo:Text "Carneiro, and I."@en ;
    askg-onto:inSentence "Carneiro, and I."^^xsd:string ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-carneiro,
        askg-data:Entity-i .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15153 a askg-onto:Sentence ;
    rdfs:label "Sentence 53"@en ;
    domo:Text "Reid."@en ;
    askg-onto:inSentence "Reid."^^xsd:string ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-reid .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15154 a askg-onto:Sentence ;
    rdfs:label "Sentence 54"@en ;
    domo:Text "Unsupervised cnn for single view depth estimation: Geometry to the rescue."@en ;
    askg-onto:inSentence "Unsupervised cnn for single view depth estimation: Geometry to the rescue."^^xsd:string ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometry,
        askg-data:Entity-method,
        askg-data:Entity-single_view_depth_estimation,
        askg-data:Entity-unsupervised_cnn .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15155 a askg-onto:Sentence ;
    rdfs:label "Sentence 55"@en ;
    domo:Text "In European Conference on Computer Vision, pages 740–756."@en ;
    askg-onto:inSentence "In European Conference on Computer Vision, pages 740–756."^^xsd:string ;
    askg-onto:index "55"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-european_conference_on_computer_vision,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15156 a askg-onto:Sentence ;
    rdfs:label "Sentence 56"@en ;
    domo:Text "Springer, 2016."@en ;
    askg-onto:inSentence "Springer, 2016."^^xsd:string ;
    askg-onto:index "56"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-springer .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15157 a askg-onto:Sentence ;
    rdfs:label "Sentence 57"@en ;
    domo:Text "3, 8 [9] A."@en ;
    askg-onto:inSentence "3, 8 [9] A."^^xsd:string ;
    askg-onto:index "57"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_8_9_a,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15158 a askg-onto:Sentence ;
    rdfs:label "Sentence 58"@en ;
    domo:Text "Geiger, P."@en ;
    askg-onto:inSentence "Geiger, P."^^xsd:string ;
    askg-onto:index "58"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geiger_p,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15159 a askg-onto:Sentence ;
    rdfs:label "Sentence 59"@en ;
    domo:Text "Lenz, and R."@en ;
    askg-onto:inSentence "Lenz, and R."^^xsd:string ;
    askg-onto:index "59"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lenz,
        askg-data:Entity-person,
        askg-data:Entity-r .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Fua, and S."@en ;
    askg-onto:inSentence "Fua, and S."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fua,
        askg-data:Entity-person,
        askg-data:Entity-s .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15160 a askg-onto:Sentence ;
    rdfs:label "Sentence 60"@en ;
    domo:Text "Urtasun."@en ;
    askg-onto:inSentence "Urtasun."^^xsd:string ;
    askg-onto:index "60"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-urtasun .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15161 a askg-onto:Sentence ;
    rdfs:label "Sentence 61"@en ;
    domo:Text "Are we ready for autonomous driving?"@en ;
    askg-onto:inSentence "Are we ready for autonomous driving?"^^xsd:string ;
    askg-onto:index "61"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-autonomous_driving,
        askg-data:Entity-readiness .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15162 a askg-onto:Sentence ;
    rdfs:label "Sentence 62"@en ;
    domo:Text "the kitti vision benchmark suite."@en ;
    askg-onto:inSentence "the kitti vision benchmark suite."^^xsd:string ;
    askg-onto:index "62"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_vision_benchmark_suite,
        askg-data:Entity-platform .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15163 a askg-onto:Sentence ;
    rdfs:label "Sentence 63"@en ;
    domo:Text "In Conference on Computer Vision and Pattern Recognition (CVPR), 2012."@en ;
    askg-onto:inSentence "In Conference on Computer Vision and Pattern Recognition (CVPR), 2012."^^xsd:string ;
    askg-onto:index "63"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-cvpr,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15164 a askg-onto:Sentence ;
    rdfs:label "Sentence 64"@en ;
    domo:Text "2, 6 [10] C."@en ;
    askg-onto:inSentence "2, 6 [10] C."^^xsd:string ;
    askg-onto:index "64"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6_10,
        askg-data:Entity-c .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15165 a askg-onto:Sentence ;
    rdfs:label "Sentence 65"@en ;
    domo:Text "Godard, O."@en ;
    askg-onto:inSentence "Godard, O."^^xsd:string ;
    askg-onto:index "65"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-godard_o,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15166 a askg-onto:Sentence ;
    rdfs:label "Sentence 66"@en ;
    domo:Text "Mac Aodha, and G."@en ;
    askg-onto:inSentence "Mac Aodha, and G."^^xsd:string ;
    askg-onto:index "66"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-mac_aodha,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15167 a askg-onto:Sentence ;
    rdfs:label "Sentence 67"@en ;
    domo:Text "J."@en ;
    askg-onto:inSentence "J."^^xsd:string ;
    askg-onto:index "67"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15168 a askg-onto:Sentence ;
    rdfs:label "Sentence 68"@en ;
    domo:Text "Brostow."@en ;
    askg-onto:inSentence "Brostow."^^xsd:string ;
    askg-onto:index "68"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brostow,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15169 a askg-onto:Sentence ;
    rdfs:label "Sentence 69"@en ;
    domo:Text "Unsupervised monocular depth estimation with left-right consistency."@en ;
    askg-onto:inSentence "Unsupervised monocular depth estimation with left-right consistency."^^xsd:string ;
    askg-onto:index "69"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-left-right_consistency,
        askg-data:Entity-method,
        askg-data:Entity-unsupervised_monocular_depth_estimation .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1517 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Susstrunk."@en ;
    askg-onto:inSentence "Susstrunk."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-susstrunk .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15170 a askg-onto:Sentence ;
    rdfs:label "Sentence 70"@en ;
    domo:Text "arXiv preprint arXiv:1609.03677, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1609.03677, 2016."^^xsd:string ;
    askg-onto:index "70"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-article,
        askg-data:Entity-arxiv160903677,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15171 a askg-onto:Sentence ;
    rdfs:label "Sentence 71"@en ;
    domo:Text "8 [11] B."@en ;
    askg-onto:inSentence "8 [11] B."^^xsd:string ;
    askg-onto:index "71"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8_11,
        askg-data:Entity-b .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15172 a askg-onto:Sentence ;
    rdfs:label "Sentence 72"@en ;
    domo:Text "Hariharan, P."@en ;
    askg-onto:inSentence "Hariharan, P."^^xsd:string ;
    askg-onto:index "72"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hariharan_p,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15173 a askg-onto:Sentence ;
    rdfs:label "Sentence 73"@en ;
    domo:Text "Arbelaez, R."@en ;
    askg-onto:inSentence "Arbelaez, R."^^xsd:string ;
    askg-onto:index "73"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arbelaez_r,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15174 a askg-onto:Sentence ;
    rdfs:label "Sentence 74"@en ;
    domo:Text "Girshick, and J."@en ;
    askg-onto:inSentence "Girshick, and J."^^xsd:string ;
    askg-onto:index "74"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-girshick,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15175 a askg-onto:Sentence ;
    rdfs:label "Sentence 75"@en ;
    domo:Text "Malik."@en ;
    askg-onto:inSentence "Malik."^^xsd:string ;
    askg-onto:index "75"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-malik,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15176 a askg-onto:Sentence ;
    rdfs:label "Sentence 76"@en ;
    domo:Text "Hyper- ´ columns for object segmentation and fine-grained localization."@en ;
    askg-onto:inSentence "Hyper- ´ columns for object segmentation and fine-grained localization."^^xsd:string ;
    askg-onto:index "76"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hyper-columns,
        askg-data:Entity-object_segmentation_and_fine-grained_localization .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15177 a askg-onto:Sentence ;
    rdfs:label "Sentence 77"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 447–456, 2015."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 447–456, 2015."^^xsd:string ;
    askg-onto:index "77"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15178 a askg-onto:Sentence ;
    rdfs:label "Sentence 78"@en ;
    domo:Text "5 [12] D."@en ;
    askg-onto:inSentence "5 [12] D."^^xsd:string ;
    askg-onto:index "78"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_12,
        askg-data:Entity-d .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15179 a askg-onto:Sentence ;
    rdfs:label "Sentence 79"@en ;
    domo:Text "Hoiem, A."@en ;
    askg-onto:inSentence "Hoiem, A."^^xsd:string ;
    askg-onto:index "79"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hoiem_a,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1518 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Slic superpixels compared to state-of-the-art ¨ superpixel methods."@en ;
    askg-onto:inSentence "Slic superpixels compared to state-of-the-art ¨ superpixel methods."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-slic_superpixels,
        askg-data:Entity-state-of-the-art_superpixel_methods .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15180 a askg-onto:Sentence ;
    rdfs:label "Sentence 80"@en ;
    domo:Text "A."@en ;
    askg-onto:inSentence "A."^^xsd:string ;
    askg-onto:index "80"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-framework,
        askg-data:Entity-institution,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-platform,
        askg-data:Entity-research_group,
        askg-data:Entity-software,
        askg-data:Entity-technology,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15181 a askg-onto:Sentence ;
    rdfs:label "Sentence 81"@en ;
    domo:Text "Efros, and M."@en ;
    askg-onto:inSentence "Efros, and M."^^xsd:string ;
    askg-onto:index "81"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-efros,
        askg-data:Entity-m,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15182 a askg-onto:Sentence ;
    rdfs:label "Sentence 82"@en ;
    domo:Text "Hebert."@en ;
    askg-onto:inSentence "Hebert."^^xsd:string ;
    askg-onto:index "82"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hebert,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15183 a askg-onto:Sentence ;
    rdfs:label "Sentence 83"@en ;
    domo:Text "Automatic photo pop-up."@en ;
    askg-onto:inSentence "Automatic photo pop-up."^^xsd:string ;
    askg-onto:index "83"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-automatic_photo_pop-up,
        askg-data:Entity-technology .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15184 a askg-onto:Sentence ;
    rdfs:label "Sentence 84"@en ;
    domo:Text "*ACM transactions on graphics (TOG)*, 24(3):577– 584, 2005."@en ;
    askg-onto:inSentence "*ACM transactions on graphics (TOG)*, 24(3):577– 584, 2005."^^xsd:string ;
    askg-onto:index "84"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2005,
        askg-data:Entity-24,
        askg-data:Entity-3,
        askg-data:Entity-577584,
        askg-data:Entity-acm_transactions_on_graphics_tog,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15185 a askg-onto:Sentence ;
    rdfs:label "Sentence 85"@en ;
    domo:Text "1, 2 [13] Y."@en ;
    askg-onto:inSentence "1, 2 [13] Y."^^xsd:string ;
    askg-onto:index "85"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_13,
        askg-data:Entity-y .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15186 a askg-onto:Sentence ;
    rdfs:label "Sentence 86"@en ;
    domo:Text "Horry, K.-I."@en ;
    askg-onto:inSentence "Horry, K.-I."^^xsd:string ;
    askg-onto:index "86"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-horry_k-i,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15187 a askg-onto:Sentence ;
    rdfs:label "Sentence 87"@en ;
    domo:Text "Anjyo, and K."@en ;
    askg-onto:inSentence "Anjyo, and K."^^xsd:string ;
    askg-onto:index "87"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-anjyo,
        askg-data:Entity-k,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15188 a askg-onto:Sentence ;
    rdfs:label "Sentence 88"@en ;
    domo:Text "Arai."@en ;
    askg-onto:inSentence "Arai."^^xsd:string ;
    askg-onto:index "88"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arai,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15189 a askg-onto:Sentence ;
    rdfs:label "Sentence 89"@en ;
    domo:Text "Tour into the picture: using a spidery mesh interface to make animation from a single image."@en ;
    askg-onto:inSentence "Tour into the picture: using a spidery mesh interface to make animation from a single image."^^xsd:string ;
    askg-onto:index "89"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-single_image,
        askg-data:Entity-spidery_mesh_interface .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-1519 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "*IEEE transactions on pattern analysis* and machine intelligence, 34(11):2274–2282, 2012."@en ;
    askg-onto:inSentence "*IEEE transactions on pattern analysis* and machine intelligence, 34(11):2274–2282, 2012."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15190 a askg-onto:Sentence ;
    rdfs:label "Sentence 90"@en ;
    domo:Text "In *Proceedings of the 24th annual conference on* Computer graphics and interactive techniques, pages 225– 232."@en ;
    askg-onto:inSentence "In *Proceedings of the 24th annual conference on* Computer graphics and interactive techniques, pages 225– 232."^^xsd:string ;
    askg-onto:index "90"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings_of_the_24th_annual_conference_on_computer_graphics_and_interactive_techniques,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15191 a askg-onto:Sentence ;
    rdfs:label "Sentence 91"@en ;
    domo:Text "ACM Press/Addison-Wesley Publishing Co., 1997."@en ;
    askg-onto:inSentence "ACM Press/Addison-Wesley Publishing Co., 1997."^^xsd:string ;
    askg-onto:index "91"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1997,
        askg-data:Entity-acm_pressaddison-wesley_publishing_co .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15192 a askg-onto:Sentence ;
    rdfs:label "Sentence 92"@en ;
    domo:Text "1, 2 [14] M."@en ;
    askg-onto:inSentence "1, 2 [14] M."^^xsd:string ;
    askg-onto:index "92"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_14,
        askg-data:Entity-m .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15193 a askg-onto:Sentence ;
    rdfs:label "Sentence 93"@en ;
    domo:Text "Jaderberg, K."@en ;
    askg-onto:inSentence "Jaderberg, K."^^xsd:string ;
    askg-onto:index "93"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jaderberg_k,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15194 a askg-onto:Sentence ;
    rdfs:label "Sentence 94"@en ;
    domo:Text "Simonyan, A."@en ;
    askg-onto:inSentence "Simonyan, A."^^xsd:string ;
    askg-onto:index "94"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-simonyan_a .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15195 a askg-onto:Sentence ;
    rdfs:label "Sentence 95"@en ;
    domo:Text "Zisserman, and K."@en ;
    askg-onto:inSentence "Zisserman, and K."^^xsd:string ;
    askg-onto:index "95"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-person,
        askg-data:Entity-zisserman .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15196 a askg-onto:Sentence ;
    rdfs:label "Sentence 96"@en ;
    domo:Text "Kavukcuoglu."@en ;
    askg-onto:inSentence "Kavukcuoglu."^^xsd:string ;
    askg-onto:index "96"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kavukcuoglu,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15197 a askg-onto:Sentence ;
    rdfs:label "Sentence 97"@en ;
    domo:Text "Spatial transformer networks."@en ;
    askg-onto:inSentence "Spatial transformer networks."^^xsd:string ;
    askg-onto:index "97"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_type_of,
        askg-data:Entity-spatial_transformer_networks .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15198 a askg-onto:Sentence ;
    rdfs:label "Sentence 98"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pages 2017–2025, 2015."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pages 2017–2025, 2015."^^xsd:string ;
    askg-onto:index "98"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-151-Sentence-15199 a askg-onto:Sentence ;
    rdfs:label "Sentence 99"@en ;
    domo:Text "5 [15] D."@en ;
    askg-onto:inSentence "5 [15] D."^^xsd:string ;
    askg-onto:index "99"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_15,
        askg-data:Entity-d .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Deep convolutional inverse graphics network. In Advances in Neural Information Processing Systems, pages 2539–2547, 2015. 2 [17] F. Liu, M. Gleicher, H. Jin, and A. Agarwala. Contentpreserving warps for 3d video stabilization. ACM Transactions on Graphics (TOG), 28(3):44, 2009. 1 [18] L. McMillan and G. Bishop. Plenoptic modeling: An imagebased rendering system. In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, pages 39–46. ACM, 1995. 1, 2 [19] P. K. Nathan Silberman, Derek Hoiem and R. Fergus. Indoor segmentation and support inference from rgbd images. In ECCV, 2012. 6 [20] E. Park, J. Yang, E. Yumer, D. Ceylan, and A. C."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1521,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15210,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15211,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15212,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15213,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15214,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15215,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15216,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15217,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15218,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15219,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1522,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15220,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15221,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15222,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15223,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15224,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15225,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15226,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15227,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1523,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1524,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1525,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1526,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1527,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1528,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1529 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Deep convolutional inverse graphics network."@en ;
    askg-onto:inSentence "Deep convolutional inverse graphics network."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_convolutional_inverse_graphics_network,
        askg-data:Entity-model .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15210 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "1 [18] L."@en ;
    askg-onto:inSentence "1 [18] L."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-l,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15211 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "McMillan and G."@en ;
    askg-onto:inSentence "McMillan and G."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-mcmillan .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15212 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Bishop."@en ;
    askg-onto:inSentence "Bishop."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bishop,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15213 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Plenoptic modeling: An imagebased rendering system."@en ;
    askg-onto:inSentence "Plenoptic modeling: An imagebased rendering system."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image-based_rendering_system,
        askg-data:Entity-plenoptic_modeling .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15214 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, pages 39–46."@en ;
    askg-onto:inSentence "In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, pages 39–46."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings_of_the_22nd_annual_conference_on_computer_graphics_and_interactive_techniques,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15215 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "ACM, 1995."@en ;
    askg-onto:inSentence "ACM, 1995."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1995,
        askg-data:Entity-acm .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15216 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "1, 2 [19] P."@en ;
    askg-onto:inSentence "1, 2 [19] P."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_19,
        askg-data:Entity-p .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15217 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "K."@en ;
    askg-onto:inSentence "K."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15218 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Nathan Silberman, Derek Hoiem and R."@en ;
    askg-onto:inSentence "Nathan Silberman, Derek Hoiem and R."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-derek_hoiem,
        askg-data:Entity-nathan_silberman,
        askg-data:Entity-r,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15219 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Fergus."@en ;
    askg-onto:inSentence "Fergus."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fergus,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In Advances in Neural Information Processing Systems, pages 2539–2547, 2015."@en ;
    askg-onto:inSentence "In Advances in Neural Information Processing Systems, pages 2539–2547, 2015."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-advances_in_neural_information_processing_systems,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15220 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Indoor segmentation and support inference from rgbd images."@en ;
    askg-onto:inSentence "Indoor segmentation and support inference from rgbd images."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-indoor_segmentation,
        askg-data:Entity-inference_from_rgbd_images .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15221 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "In ECCV, 2012."@en ;
    askg-onto:inSentence "In ECCV, 2012."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eccv .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15222 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "6 [20] E."@en ;
    askg-onto:inSentence "6 [20] E."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6_20,
        askg-data:Entity-e .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15223 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Park, J."@en ;
    askg-onto:inSentence "Park, J."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-park_j,
        askg-data:Entity-research_on_machine_learning_techniques .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15224 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Yang, E."@en ;
    askg-onto:inSentence "Yang, E."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-yang_e .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15225 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Yumer, D."@en ;
    askg-onto:inSentence "Yumer, D."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-yumer_d .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15226 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Ceylan, and A."@en ;
    askg-onto:inSentence "Ceylan, and A."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ceylan,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-15227 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "C."@en ;
    askg-onto:inSentence "C."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1523 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "2 [17] F."@en ;
    askg-onto:inSentence "2 [17] F."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2_17,
        askg-data:Entity-f .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1524 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Liu, M."@en ;
    askg-onto:inSentence "Liu, M."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-liu_m,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1525 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Gleicher, H."@en ;
    askg-onto:inSentence "Gleicher, H."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-gleicher_h .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1526 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Jin, and A."@en ;
    askg-onto:inSentence "Jin, and A."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-jin,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1527 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Agarwala."@en ;
    askg-onto:inSentence "Agarwala."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-agarwala,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1528 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Contentpreserving warps for 3d video stabilization."@en ;
    askg-onto:inSentence "Contentpreserving warps for 3d video stabilization."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_video_stabilization,
        askg-data:Entity-contentpreserving_warps .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-152-Sentence-1529 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "ACM Transactions on Graphics (TOG), 28(3):44, 2009."@en ;
    askg-onto:inSentence "ACM Transactions on Graphics (TOG), 28(3):44, 2009."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-28,
        askg-data:Entity-3,
        askg-data:Entity-44,
        askg-data:Entity-acm_transactions_on_graphics,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Berg. Transformation-grounded image generation network for novel 3d view synthesis. In *CVPR*, 2017. 1, 2, 3, 5, 6 [21] W. H. Press. Numerical recipes 3rd edition: The art of scientific computing. Cambridge university press, 2007. 5 [22] K. Rematas, C. Nguyen, T. Ritschel, M. Fritz, and T. Tuytelaars. Novel views of objects from a single image. arXiv preprint arXiv:1602.00328, 2016. 2 [23] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 4 [24] M. Tatarchenko, A. Dosovitskiy, and T. Brox. Multi-view 3d models from single images with a convolutional network. In European Conference on Computer Vision, pages 322–337. Springer, 2016. 1, 2 [25] O. J. Woodford, I. D. Reid, P. H. Torr, and A. W. Fitzgibbon."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1531,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15310,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15311,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15312,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15313,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15314,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15315,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15316,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15317,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15318,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15319,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1532,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15320,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15321,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15322,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15323,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15324,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15325,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15326,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15327,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15328,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15329,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1533,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15330,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15331,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15332,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15333,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15334,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15335,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15336,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15337,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1534,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1535,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1536,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1537,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1538,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1539 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Berg."@en ;
    askg-onto:inSentence "Berg."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-berg,
        askg-data:Entity-university_of_california .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15310 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Rematas, C."@en ;
    askg-onto:inSentence "Rematas, C."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-rematas_c .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15311 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Nguyen, T."@en ;
    askg-onto:inSentence "Nguyen, T."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nguyen_t,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15312 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Ritschel, M."@en ;
    askg-onto:inSentence "Ritschel, M."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ritschel_m,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15313 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Fritz, and T."@en ;
    askg-onto:inSentence "Fritz, and T."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fritz,
        askg-data:Entity-t .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15314 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Tuytelaars."@en ;
    askg-onto:inSentence "Tuytelaars."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-tuytelaars .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15315 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Novel views of objects from a single image."@en ;
    askg-onto:inSentence "Novel views of objects from a single image."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_single_image,
        askg-data:Entity-novel_views .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15316 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "arXiv preprint arXiv:1602.00328, 2016."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1602.00328, 2016."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-arxiv160200328,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15317 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "2 [23] K."@en ;
    askg-onto:inSentence "2 [23] K."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15318 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Simonyan and A."@en ;
    askg-onto:inSentence "Simonyan and A."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-simonyan .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15319 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "Zisserman."@en ;
    askg-onto:inSentence "Zisserman."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-zisserman .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Transformation-grounded image generation network for novel 3d view synthesis."@en ;
    askg-onto:inSentence "Transformation-grounded image generation network for novel 3d view synthesis."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_view_synthesis,
        askg-data:Entity-transformation-grounded_image_generation_network .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15320 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Very deep convolutional networks for large-scale image recognition."@en ;
    askg-onto:inSentence "Very deep convolutional networks for large-scale image recognition."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-large-scale_image_recognition,
        askg-data:Entity-very_deep_convolutional_networks .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15321 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "arXiv preprint arXiv:1409.1556, 2014."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1409.1556, 2014."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arxiv14091556,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15322 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "4 [24] M."@en ;
    askg-onto:inSentence "4 [24] M."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-m,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15323 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "Tatarchenko, A."@en ;
    askg-onto:inSentence "Tatarchenko, A."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-tatarchenko_a .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15324 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Dosovitskiy, and T."@en ;
    askg-onto:inSentence "Dosovitskiy, and T."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dosovitskiy,
        askg-data:Entity-person,
        askg-data:Entity-t .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15325 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Brox."@en ;
    askg-onto:inSentence "Brox."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brox,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15326 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Multi-view 3d models from single images with a convolutional network."@en ;
    askg-onto:inSentence "Multi-view 3d models from single images with a convolutional network."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_network,
        askg-data:Entity-multi-view_3d_models,
        askg-data:Entity-single_images .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15327 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "In European Conference on Computer Vision, pages 322–337."@en ;
    askg-onto:inSentence "In European Conference on Computer Vision, pages 322–337."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-european_conference_on_computer_vision,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15328 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "Springer, 2016."@en ;
    askg-onto:inSentence "Springer, 2016."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-springer .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15329 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "1, 2 [25] O."@en ;
    askg-onto:inSentence "1, 2 [25] O."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_25,
        askg-data:Entity-o .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In *CVPR*, 2017."@en ;
    askg-onto:inSentence "In *CVPR*, 2017."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-cvpr .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15330 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "J."@en ;
    askg-onto:inSentence "J."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15331 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "Woodford, I."@en ;
    askg-onto:inSentence "Woodford, I."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-woodford_i .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15332 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "D."@en ;
    askg-onto:inSentence "D."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15333 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "Reid, P."@en ;
    askg-onto:inSentence "Reid, P."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-reid_p .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15334 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "H."@en ;
    askg-onto:inSentence "H."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15335 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Torr, and A."@en ;
    askg-onto:inSentence "Torr, and A."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-torr .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15336 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "W."@en ;
    askg-onto:inSentence "W."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-unknown,
        askg-data:Entity-w .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-15337 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "Fitzgibbon."@en ;
    askg-onto:inSentence "Fitzgibbon."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fitzgibbon,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "1, 2, 3, 5, 6 [21] W."@en ;
    askg-onto:inSentence "1, 2, 3, 5, 6 [21] W."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_3_5_6_21,
        askg-data:Entity-w .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1535 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "H."@en ;
    askg-onto:inSentence "H."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1536 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Press."@en ;
    askg-onto:inSentence "Press."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-organization,
        askg-data:Entity-press .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1537 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Numerical recipes 3rd edition: The art of scientific computing."@en ;
    askg-onto:inSentence "Numerical recipes 3rd edition: The art of scientific computing."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-numerical_recipes_3rd_edition,
        askg-data:Entity-publication,
        askg-data:Entity-scientific_computing .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1538 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Cambridge university press, 2007."@en ;
    askg-onto:inSentence "Cambridge university press, 2007."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2007,
        askg-data:Entity-cambridge_university_press .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-153-Sentence-1539 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "5 [22] K."@en ;
    askg-onto:inSentence "5 [22] K."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5_22,
        askg-data:Entity-k .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "On new view synthesis using multiview stereo. In *BMVC*, pages 1–10, 2007. 1 [26] J. Xie, R. Girshick, and A. Farhadi. Deep3d: Fully automatic 2d-to-3d video conversion with deep convolutional neural networks. In European Conference on Computer Vision, pages 842–857. Springer, 2016. 3 [27] J. Zbontar and Y. LeCun. Computing the stereo matching cost with a convolutional neural network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1592–1599, 2015. 6 [28] T. Zhou, M. Brown, N. Snavely, and D. G. Lowe. Unsupervised learning of depth and ego-motion from video. arXiv preprint arXiv:1704.07813, 2017. 3, 8 [29] T. Zhou, S. Tulsiani, W. Sun, J. Malik, and A. A. Efros. View synthesis by appearance flow. In *European Conference on* Computer Vision, pages 286–301. Springer, 2016. 1, 2, 6, 7, 10, 12, 13 [30] Z. Zhou, H. Jin, and Y. Ma. Plane-based content preserving warps for video stabilization. In *Proceedings of the IEEE* Conference on Computer Vision and Pattern Recognition, pages 2299–2306, 2013. 1, 2"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1541,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15410,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15411,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15412,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15413,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15414,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15415,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15416,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15417,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15418,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15419,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1542,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15420,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15421,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15422,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15423,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15424,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15425,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15426,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15427,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15428,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15429,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1543,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15430,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15431,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15432,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15433,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15434,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15435,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15436,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15437,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15438,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15439,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1544,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1545,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1546,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1547,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1548,
        askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1549 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "On new view synthesis using multiview stereo."@en ;
    askg-onto:inSentence "On new view synthesis using multiview stereo."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-multiview_stereo,
        askg-data:Entity-view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15410 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "3 [27] J."@en ;
    askg-onto:inSentence "3 [27] J."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15411 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Zbontar and Y."@en ;
    askg-onto:inSentence "Zbontar and Y."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-y,
        askg-data:Entity-zbontar .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15412 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "LeCun."@en ;
    askg-onto:inSentence "LeCun."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lecun,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15413 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Computing the stereo matching cost with a convolutional neural network."@en ;
    askg-onto:inSentence "Computing the stereo matching cost with a convolutional neural network."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_neural_network,
        askg-data:Entity-stereo_matching_cost .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15414 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1592–1599, 2015."@en ;
    askg-onto:inSentence "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1592–1599, 2015."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15415 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "6 [28] T."@en ;
    askg-onto:inSentence "6 [28] T."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-6_28,
        askg-data:Entity-t .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15416 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Zhou, M."@en ;
    askg-onto:inSentence "Zhou, M."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhou_m .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15417 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Brown, N."@en ;
    askg-onto:inSentence "Brown, N."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-brown_n,
        askg-data:Entity-scientist .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15418 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Snavely, and D."@en ;
    askg-onto:inSentence "Snavely, and D."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-snavely .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15419 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "G."@en ;
    askg-onto:inSentence "G."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1542 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In *BMVC*, pages 1–10, 2007."@en ;
    askg-onto:inSentence "In *BMVC*, pages 1–10, 2007."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bmvc,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15420 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Lowe."@en ;
    askg-onto:inSentence "Lowe."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lowe,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15421 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Unsupervised learning of depth and ego-motion from video."@en ;
    askg-onto:inSentence "Unsupervised learning of depth and ego-motion from video."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_and_ego-motion,
        askg-data:Entity-method,
        askg-data:Entity-unsupervised_learning,
        askg-data:Entity-video .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15422 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "arXiv preprint arXiv:1704.07813, 2017."@en ;
    askg-onto:inSentence "arXiv preprint arXiv:1704.07813, 2017."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2017,
        askg-data:Entity-article,
        askg-data:Entity-arxiv170407813,
        askg-data:Entity-arxiv_preprint,
        askg-data:Entity-arxiv_preprint_arxiv170407813,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15423 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "3, 8 [29] T."@en ;
    askg-onto:inSentence "3, 8 [29] T."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_8_29,
        askg-data:Entity-t .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15424 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "Zhou, S."@en ;
    askg-onto:inSentence "Zhou, S."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhou_s .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15425 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "Tulsiani, W."@en ;
    askg-onto:inSentence "Tulsiani, W."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-person,
        askg-data:Entity-tulsiani_w .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15426 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Sun, J."@en ;
    askg-onto:inSentence "Sun, J."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication,
        askg-data:Entity-sun_j .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15427 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Malik, and A."@en ;
    askg-onto:inSentence "Malik, and A."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-malik,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15428 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "A."@en ;
    askg-onto:inSentence "A."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-database,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-system,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15429 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Efros."@en ;
    askg-onto:inSentence "Efros."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-efros,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1543 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "1 [26] J."@en ;
    askg-onto:inSentence "1 [26] J."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15430 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "View synthesis by appearance flow."@en ;
    askg-onto:inSentence "View synthesis by appearance flow."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow,
        askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15431 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "In *European Conference on* Computer Vision, pages 286–301."@en ;
    askg-onto:inSentence "In *European Conference on* Computer Vision, pages 286–301."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-european_conference_on_computer_vision,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15432 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "Springer, 2016."@en ;
    askg-onto:inSentence "Springer, 2016."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-springer .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15433 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "1, 2, 6, 7, 10, 12, 13 [30] Z."@en ;
    askg-onto:inSentence "1, 2, 6, 7, 10, 12, 13 [30] Z."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_2_6_7_10_12_13_30,
        askg-data:Entity-z .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15434 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "Zhou, H."@en ;
    askg-onto:inSentence "Zhou, H."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-zhou_h .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15435 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Jin, and Y."@en ;
    askg-onto:inSentence "Jin, and Y."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-jin,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15436 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "Ma."@en ;
    askg-onto:inSentence "Ma."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ma,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15437 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "Plane-based content preserving warps for video stabilization."@en ;
    askg-onto:inSentence "Plane-based content preserving warps for video stabilization."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-plane-based_content_preserving_warps,
        askg-data:Entity-video_stabilization .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15438 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "In *Proceedings of the IEEE* Conference on Computer Vision and Pattern Recognition, pages 2299–2306, 2013."@en ;
    askg-onto:inSentence "In *Proceedings of the IEEE* Conference on Computer Vision and Pattern Recognition, pages 2299–2306, 2013."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-15439 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "1, 2"@en ;
    askg-onto:inSentence "1, 2"^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1,
        askg-data:Entity-2,
        askg-data:Entity-framework,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1544 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Xie, R."@en ;
    askg-onto:inSentence "Xie, R."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-scientist,
        askg-data:Entity-xie_r .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1545 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Girshick, and A."@en ;
    askg-onto:inSentence "Girshick, and A."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-girshick .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1546 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Farhadi."@en ;
    askg-onto:inSentence "Farhadi."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-farhadi,
        askg-data:Entity-person .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1547 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Deep3d: Fully automatic 2d-to-3d video conversion with deep convolutional neural networks."@en ;
    askg-onto:inSentence "Deep3d: Fully automatic 2d-to-3d video conversion with deep convolutional neural networks."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2d-to-3d_video_conversion,
        askg-data:Entity-deep3d,
        askg-data:Entity-deep_convolutional_neural_networks .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1548 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In European Conference on Computer Vision, pages 842–857."@en ;
    askg-onto:inSentence "In European Conference on Computer Vision, pages 842–857."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-european_conference_on_computer_vision,
        askg-data:Entity-publication .

askg-data:Paper-305358d7d24f2bf4-Section-15-Paragraph-154-Sentence-1549 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Springer, 2016."@en ;
    askg-onto:inSentence "Springer, 2016."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2016,
        askg-data:Entity-springer .

askg-data:Paper-305358d7d24f2bf4-Section-16 a askg-onto:Section ;
    rdfs:label "Section 16"@en ;
    domo:Text "6. Sherman-Morrison Formula"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1610,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1611,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-162,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-163,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-164,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-165,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-166,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-167,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-169 ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We first provide more detail for the Sherman-Morrison formula, which allows us to explicitly compute the inverse of homographies. The Sherman-Morrison formula can be stated as follows: Theorem 1 Assume A is invertible, and u and v are column vectors. Furthermore, assume 1 + v TA−1u 6= 0*. Given*"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1611,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1612,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1613,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1614 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We first provide more detail for the Sherman-Morrison formula, which allows us to explicitly compute the inverse of homographies."@en ;
    askg-onto:inSentence "We first provide more detail for the Sherman-Morrison formula, which allows us to explicitly compute the inverse of homographies."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inverse_of_homographies,
        askg-data:Entity-sherman-morrison_formula .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The Sherman-Morrison formula can be stated as follows: Theorem 1 Assume A is invertible, and u and v are column vectors."@en ;
    askg-onto:inSentence "The Sherman-Morrison formula can be stated as follows: Theorem 1 Assume A is invertible, and u and v are column vectors."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-column_vectors,
        askg-data:Entity-invertible,
        askg-data:Entity-sherman-morrison_formula,
        askg-data:Entity-theorem_1,
        askg-data:Entity-u,
        askg-data:Entity-v .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, assume 1 + v TA−1u 6= 0*."@en ;
    askg-onto:inSentence "Furthermore, assume 1 + v TA−1u 6= 0*."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0,
        askg-data:Entity-1__v_ta1u .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-161-Sentence-1614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Given*"@en ;
    askg-onto:inSentence "Given*"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-organization,
        askg-data:Entity-research_field,
        askg-data:Entity-research_group,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1610 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Re-introducing K, and following the standard rule for matrix product inversion, lets us write the inverse H−1as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1610-Sentence-16101 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1610-Sentence-16101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Re-introducing K, and following the standard rule for matrix product inversion, lets us write the inverse H−1as"@en ;
    askg-onto:inSentence "Re-introducing K, and following the standard rule for matrix product inversion, lets us write the inverse H−1as"^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1611 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "$$\\mathbf{H}^{-1}=\\mathbf{K}\\mathbf{\\tilde{H}}^{-1}\\mathbf{K}^{-1}.$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1611-Sentence-16111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-1611-Sentence-16111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{H}^{-1}=\\mathbf{K}\\mathbf{\\tilde{H}}^{-1}\\mathbf{K}^{-1}.$$"@en ;
    askg-onto:inSentence "$$\\mathbf{H}^{-1}=\\mathbf{K}\\mathbf{\\tilde{H}}^{-1}\\mathbf{K}^{-1}.$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h-1,
        askg-data:Entity-k_%09ildeh-1_k-1 .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-162 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "$$\\mathbf{B}=\\mathbf{A}+\\mathbf{u}\\mathbf{v}^{\\mathrm{{T}}},$$ $ad\\;as$ B = A + uvT, (11) the inverse B−1*can be obtained as*"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-162-Sentence-1621 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-162-Sentence-1621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{B}=\\mathbf{A}+\\mathbf{u}\\mathbf{v}^{\\mathrm{{T}}},$$ $ad\\;as$ B = A + uvT, (11) the inverse B−1*can be obtained as*"@en ;
    askg-onto:inSentence "$$\\mathbf{B}=\\mathbf{A}+\\mathbf{u}\\mathbf{v}^{\\mathrm{{T}}},$$ $ad\\;as$ B = A + uvT, (11) the inverse B−1*can be obtained as*"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a__uvt,
        askg-data:Entity-b .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-163 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$\\mathbf{B}^{-1}=\\mathbf{A}^{-1}-{\\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^{\\mathrm{{T}}}\\mathbf{A}^{-1}}{1+\\mathbf{v}^{\\mathrm{{T}}}\\mathbf{A}^{-1}\\mathbf{u}}}.$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-163-Sentence-1631 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-163-Sentence-1631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{B}^{-1}=\\mathbf{A}^{-1}-{\\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^{\\mathrm{{T}}}\\mathbf{A}^{-1}}{1+\\mathbf{v}^{\\mathrm{{T}}}\\mathbf{A}^{-1}\\mathbf{u}}}.$$"@en ;
    askg-onto:inSentence "$$\\mathbf{B}^{-1}=\\mathbf{A}^{-1}-{\\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^{\\mathrm{{T}}}\\mathbf{A}^{-1}}{1+\\mathbf{v}^{\\mathrm{{T}}}\\mathbf{A}^{-1}\\mathbf{u}}}.$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-164 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text ". (12) In our context, the homography is defined as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-164-Sentence-1641,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-164-Sentence-1642 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-164-Sentence-1641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "."@en ;
    askg-onto:inSentence "."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-organization,
        askg-data:Entity-person,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-164-Sentence-1642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "(12) In our context, the homography is defined as"@en ;
    askg-onto:inSentence "(12) In our context, the homography is defined as"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_concept_in_projective_geometry,
        askg-data:Entity-homography .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-165 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\mathbf{H}=\\mathbf{K}(\\mathbf{R}-\\mathbf{t}{\\bar{\\mathbf{n}}}^{\\mathrm{T}})\\mathbf{K}^{-1}.$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-165-Sentence-1651 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-165-Sentence-1651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{H}=\\mathbf{K}(\\mathbf{R}-\\mathbf{t}{\\bar{\\mathbf{n}}}^{\\mathrm{T}})\\mathbf{K}^{-1}.$$"@en ;
    askg-onto:inSentence "$$\\mathbf{H}=\\mathbf{K}(\\mathbf{R}-\\mathbf{t}{\\bar{\\mathbf{n}}}^{\\mathrm{T}})\\mathbf{K}^{-1}.$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h,
        askg-data:Entity-kr_-_t__ntk-1 .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-166 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Let us first ignore K and concentrate on the central part"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-166-Sentence-1661 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-166-Sentence-1661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Let us first ignore K and concentrate on the central part"@en ;
    askg-onto:inSentence "Let us first ignore K and concentrate on the central part"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-central_part,
        askg-data:Entity-k .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-167 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$${\\bar{\\mathbf{H}}}=\\mathbf{R}-\\mathbf{t}{\\bar{\\mathbf{n}}}^{\\mathrm{T}}\\ ,$$ $\\left(13\\right)$."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-167-Sentence-1671 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-167-Sentence-1671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\bar{\\mathbf{H}}}=\\mathbf{R}-\\mathbf{t}{\\bar{\\mathbf{n}}}^{\\mathrm{T}}\\ ,$$ $\\left(13\\right)$."@en ;
    askg-onto:inSentence "$${\\bar{\\mathbf{H}}}=\\mathbf{R}-\\mathbf{t}{\\bar{\\mathbf{n}}}^{\\mathrm{T}}\\ ,$$ $\\left(13\\right)$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h,
        askg-data:Entity-r_-_t__nt .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "T , (13) where R is a rotation matrix and is thus invertible, i.e., R−1 = RT. Therefore, Eq. 13 satisfies the conditions of B in Eq. 11, and the inverse H˜ −1can be written as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1681,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1682,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1683,
        askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1684 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "T , (13) where R is a rotation matrix and is thus invertible, i.e., R−1 = RT."@en ;
    askg-onto:inSentence "T , (13) where R is a rotation matrix and is thus invertible, i.e., R−1 = RT."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-invertible,
        askg-data:Entity-r,
        askg-data:Entity-rotation_matrix .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1682 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Therefore, Eq."@en ;
    askg-onto:inSentence "Therefore, Eq."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-eq .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1683 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "13 satisfies the conditions of B in Eq."@en ;
    askg-onto:inSentence "13 satisfies the conditions of B in Eq."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-13,
        askg-data:Entity-b .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-168-Sentence-1684 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "11, and the inverse H˜ −1can be written as"@en ;
    askg-onto:inSentence "11, and the inverse H˜ −1can be written as"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-11,
        askg-data:Entity-h_1 .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-169 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$$\\hat{\\mathbf{H}}^{-1}=\\mathbf{R}^{\\mathrm{T}}+{\\frac{\\mathbf{R}^{\\mathrm{T}}\\mathbf{t}\\mathbf{\\hat{n}}^{\\mathrm{T}}\\mathbf{R}^{\\mathrm{T}}}{1-\\mathbf{\\hat{n}}^{\\mathrm{T}}\\mathbf{R}^{\\mathrm{T}}\\mathbf{t}}}\\ .$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-169-Sentence-1691 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-16-Paragraph-169-Sentence-1691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\hat{\\mathbf{H}}^{-1}=\\mathbf{R}^{\\mathrm{T}}+{\\frac{\\mathbf{R}^{\\mathrm{T}}\\mathbf{t}\\mathbf{\\hat{n}}^{\\mathrm{T}}\\mathbf{R}^{\\mathrm{T}}}{1-\\mathbf{\\hat{n}}^{\\mathrm{T}}\\mathbf{R}^{\\mathrm{T}}\\mathbf{t}}}\\ .$$"@en ;
    askg-onto:inSentence "$$\\hat{\\mathbf{H}}^{-1}=\\mathbf{R}^{\\mathrm{T}}+{\\frac{\\mathbf{R}^{\\mathrm{T}}\\mathbf{t}\\mathbf{\\hat{n}}^{\\mathrm{T}}\\mathbf{R}^{\\mathrm{T}}}{1-\\mathbf{\\hat{n}}^{\\mathrm{T}}\\mathbf{R}^{\\mathrm{T}}\\mathbf{t}}}\\ .$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h-1,
        askg-data:Entity-rt__rtthatntrt1-hatntrtt .

askg-data:Paper-305358d7d24f2bf4-Section-17 a askg-onto:Section ;
    rdfs:label "Section 17"@en ;
    domo:Text "7. Experiments"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171 ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In this section, we provide additional results on the two datasets. We further illustrate the m = 16 synthesized images obtained from the homographies generated by our method, and show additional examples of the selection maps our network predicts. We then provide the visualisation of our estimated depth and normal maps for KITTI dataset and discuss failure cases of our approach."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171-Sentence-1711,
        askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171-Sentence-1712,
        askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171-Sentence-1713 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171-Sentence-1711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this section, we provide additional results on the two datasets."@en ;
    askg-onto:inSentence "In this section, we provide additional results on the two datasets."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_results,
        askg-data:Entity-two_datasets .

askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171-Sentence-1712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We further illustrate the m = 16 synthesized images obtained from the homographies generated by our method, and show additional examples of the selection maps our network predicts."@en ;
    askg-onto:inSentence "We further illustrate the m = 16 synthesized images obtained from the homographies generated by our method, and show additional examples of the selection maps our network predicts."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-our_method,
        askg-data:Entity-our_network,
        askg-data:Entity-selection_maps,
        askg-data:Entity-synthesized_images .

askg-data:Paper-305358d7d24f2bf4-Section-17-Paragraph-171-Sentence-1713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We then provide the visualisation of our estimated depth and normal maps for KITTI dataset and discuss failure cases of our approach."@en ;
    askg-onto:inSentence "We then provide the visualisation of our estimated depth and normal maps for KITTI dataset and discuss failure cases of our approach."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_dataset,
        askg-data:Entity-visualisation_of_estimated_depth_and_normal_maps .

askg-data:Paper-305358d7d24f2bf4-Section-18 a askg-onto:Section ;
    rdfs:label "Section 18"@en ;
    domo:Text "7.1. Additional Results"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-182,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-184,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-185,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-186,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187 ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We provide additional qualitative results on the KITTI dataset in Figs. 9, and 10 and on the ScanNet dataset in Fig. 11. As those in the main paper, they clearly illustrate the benefits of our approach over the state-of-the-art appearance flow baseline [29]; specifically, accounting for geometry lets us produce much more realistic novel views. Note also that our complete approach (Ours-Full), with the refinement network, typically yields sharper results than our basic framework without refinement (Ours-Geo). This can be seen, e.g., in the third to seventh rows of Fig. 9."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1811,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1812,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1813,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1814,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1815,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1816,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1817 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We provide additional qualitative results on the KITTI dataset in Figs."@en ;
    askg-onto:inSentence "We provide additional qualitative results on the KITTI dataset in Figs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figs,
        askg-data:Entity-kitti_dataset .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "9, and 10 and on the ScanNet dataset in Fig."@en ;
    askg-onto:inSentence "9, and 10 and on the ScanNet dataset in Fig."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-scannet .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "11."@en ;
    askg-onto:inSentence "11."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As those in the main paper, they clearly illustrate the benefits of our approach over the state-of-the-art appearance flow baseline [29]; specifically, accounting for geometry lets us produce much more realistic novel views."@en ;
    askg-onto:inSentence "As those in the main paper, they clearly illustrate the benefits of our approach over the state-of-the-art appearance flow baseline [29]; specifically, accounting for geometry lets us produce much more realistic novel views."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approach,
        askg-data:Entity-geometry,
        askg-data:Entity-realistic_novel_views,
        askg-data:Entity-state-of-the-art_appearance_flow_baseline .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Note also that our complete approach (Ours-Full), with the refinement network, typically yields sharper results than our basic framework without refinement (Ours-Geo)."@en ;
    askg-onto:inSentence "Note also that our complete approach (Ours-Full), with the refinement network, typically yields sharper results than our basic framework without refinement (Ours-Geo)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ours-full,
        askg-data:Entity-ours-geo .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1816 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This can be seen, e.g., in the third to seventh rows of Fig."@en ;
    askg-onto:inSentence "This can be seen, e.g., in the third to seventh rows of Fig."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-the_third_to_seventh_rows .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-181-Sentence-1817 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "9."@en ;
    askg-onto:inSentence "9."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-database,
        askg-data:Entity-framework,
        askg-data:Entity-institution,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-system,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-182 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "| gtDep | estDep | estNor | Seed | SelMap | `1 | |---------|----------|----------|--------|----------|-------| | ✓ | ✗ | ✓ | ✓ | ✗ | 0.174 | | ✓ | ✗ | ✓ | ✗ | ✓ | 0.159 | | ✗ | ✓ | ✓ | ✓ | ✗ | 0.184 | | ✗ | ✓ | ✓ | ✗ | ✓ | 0.167 |"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-182-Sentence-1821 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-182-Sentence-1821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| gtDep | estDep | estNor | Seed | SelMap | `1 | |---------|----------|----------|--------|----------|-------| | ✓ | ✗ | ✓ | ✓ | ✗ | 0.174 | | ✓ | ✗ | ✓ | ✗ | ✓ | 0.159 | | ✗ | ✓ | ✓ | ✓ | ✗ | 0.184 | | ✗ | ✓ | ✓ | ✗ | ✓ | 0.167 |"@en ;
    askg-onto:inSentence "| gtDep | estDep | estNor | Seed | SelMap | `1 | |---------|----------|----------|--------|----------|-------| | ✓ | ✗ | ✓ | ✓ | ✗ | 0.174 | | ✓ | ✗ | ✓ | ✗ | ✓ | 0.159 | | ✗ | ✓ | ✓ | ✓ | ✗ | 0.184 | | ✗ | ✓ | ✓ | ✗ | ✓ | 0.167 |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0159,
        askg-data:Entity-0167,
        askg-data:Entity-0174,
        askg-data:Entity-0184,
        askg-data:Entity-estdep,
        askg-data:Entity-estnor,
        askg-data:Entity-gtdep,
        askg-data:Entity-seed .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Table 3. Influence of the quality of the depth and normal estimates and of learning the selection maps on ScanNet. From left to right: gtDep denotes the ground-truth depth; estDep and est- Nor denote the estimated depth and normal, respectively; Seed and SelMap denote the hard-segmentations corresponding to the seed regions and the selection map obtained with our selection network,"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183-Sentence-1831,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183-Sentence-1832,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183-Sentence-1833 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183-Sentence-1831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Table 3."@en ;
    askg-onto:inSentence "Table 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-table_3,
        askg-data:Entity-triples .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183-Sentence-1832 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Influence of the quality of the depth and normal estimates and of learning the selection maps on ScanNet."@en ;
    askg-onto:inSentence "Influence of the quality of the depth and normal estimates and of learning the selection maps on ScanNet."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-quality_of_the_depth_and_normal_estimates,
        askg-data:Entity-scannet .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-183-Sentence-1833 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "From left to right: gtDep denotes the ground-truth depth; estDep and est- Nor denote the estimated depth and normal, respectively; Seed and SelMap denote the hard-segmentations corresponding to the seed regions and the selection map obtained with our selection network,"@en ;
    askg-onto:inSentence "From left to right: gtDep denotes the ground-truth depth; estDep and est- Nor denote the estimated depth and normal, respectively; Seed and SelMap denote the hard-segmentations corresponding to the seed regions and the selection map obtained with our selection network,"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-est-nor,
        askg-data:Entity-estdep,
        askg-data:Entity-estimated_depth,
        askg-data:Entity-estimated_normal,
        askg-data:Entity-ground-truth_depth,
        askg-data:Entity-gtdep,
        askg-data:Entity-hard-segmentations,
        askg-data:Entity-seed,
        askg-data:Entity-seed_and_selmap,
        askg-data:Entity-selection_map,
        askg-data:Entity-selection_network,
        askg-data:Entity-selmap .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-184 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "$$(11)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-184-Sentence-1841 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-184-Sentence-1841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(11)$$"@en ;
    askg-onto:inSentence "$$(11)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-article,
        askg-data:Entity-author,
        askg-data:Entity-biological_entity,
        askg-data:Entity-cell_type,
        askg-data:Entity-chemical_entity,
        askg-data:Entity-company,
        askg-data:Entity-concept,
        askg-data:Entity-condition,
        askg-data:Entity-database,
        askg-data:Entity-dataset,
        askg-data:Entity-device,
        askg-data:Entity-disease,
        askg-data:Entity-domain,
        askg-data:Entity-equipment,
        askg-data:Entity-experiment,
        askg-data:Entity-field,
        askg-data:Entity-finding,
        askg-data:Entity-framework,
        askg-data:Entity-gene,
        askg-data:Entity-idea,
        askg-data:Entity-index,
        askg-data:Entity-institution,
        askg-data:Entity-measure,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-molecule,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-paradigm,
        askg-data:Entity-person,
        askg-data:Entity-platform,
        askg-data:Entity-protein,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_field,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-result,
        askg-data:Entity-scientist,
        askg-data:Entity-score,
        askg-data:Entity-study,
        askg-data:Entity-symptom,
        askg-data:Entity-system,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-185 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "respectively."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-185-Sentence-1851 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-185-Sentence-1851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "respectively."@en ;
    askg-onto:inSentence "respectively."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-context_of_comparison,
        askg-data:Entity-respectively .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-186 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$(12)^{\\frac{1}{2}}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-186-Sentence-1861 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-186-Sentence-1861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(12)^{\\frac{1}{2}}$$"@en ;
    askg-onto:inSentence "$$(12)^{\\frac{1}{2}}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-12,
        askg-data:Entity-square_root .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "In Table 3, we analyze the influence of the quality of the depth and normal estimates and of learning the selection maps on ScanNet. Note that, compared to Table 2 in the main paper which shows a similar analysis for KITTI, we eliminated the factor 'gtNor' because it is computed from 'gtDep'. In essence, the behavior is the same as for KITTI. The best results are obtained with the ground-truth depth maps, which leaves room for our method to improve as progress in depth estimation is made. More importantly, our learnt selection maps give a significant boost to our results, whether using ground-truth depth or estimated one."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1871,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1872,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1873,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1874,
        askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1875 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Table 3, we analyze the influence of the quality of the depth and normal estimates and of learning the selection maps on ScanNet."@en ;
    askg-onto:inSentence "In Table 3, we analyze the influence of the quality of the depth and normal estimates and of learning the selection maps on ScanNet."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-influence_of_the_quality_of_the_depth_and_normal_estimates_and_of_learning_the_selection_maps,
        askg-data:Entity-scannet .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1872 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that, compared to Table 2 in the main paper which shows a similar analysis for KITTI, we eliminated the factor 'gtNor' because it is computed from 'gtDep'."@en ;
    askg-onto:inSentence "Note that, compared to Table 2 in the main paper which shows a similar analysis for KITTI, we eliminated the factor 'gtNor' because it is computed from 'gtDep'."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1873 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In essence, the behavior is the same as for KITTI."@en ;
    askg-onto:inSentence "In essence, the behavior is the same as for KITTI."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behavior,
        askg-data:Entity-kitti .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1874 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The best results are obtained with the ground-truth depth maps, which leaves room for our method to improve as progress in depth estimation is made."@en ;
    askg-onto:inSentence "The best results are obtained with the ground-truth depth maps, which leaves room for our method to improve as progress in depth estimation is made."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_estimation,
        askg-data:Entity-ground-truth_depth_maps,
        askg-data:Entity-our_method .

askg-data:Paper-305358d7d24f2bf4-Section-18-Paragraph-187-Sentence-1875 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "More importantly, our learnt selection maps give a significant boost to our results, whether using ground-truth depth or estimated one."@en ;
    askg-onto:inSentence "More importantly, our learnt selection maps give a significant boost to our results, whether using ground-truth depth or estimated one."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learnt_selection_maps,
        askg-data:Entity-results .

askg-data:Paper-305358d7d24f2bf4-Section-19 a askg-onto:Section ;
    rdfs:label "Section 19"@en ;
    domo:Text "7.2. Synthesized Candidate Images"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191 ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Fig. 12, we show the synthesized images obtained from our m = 16 predicted homographies for one input image. When compared with the ground-truth novel view, we can see that different homographies account for the motion of different regions in the image. For instance, the homography corresponding to the top-left image accounts for the motion of the road. By contrast, the homography corresponding to the bottom-right image models the motion of the buildings. Correctly combining these images then allows us to obtain a realistic novel view, as shown in the top row of Fig. 12."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1911,
        askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1912,
        askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1913,
        askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1914,
        askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1915,
        askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1916,
        askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1917 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Fig."@en ;
    askg-onto:inSentence "In Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-visual_representation .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "12, we show the synthesized images obtained from our m = 16 predicted homographies for one input image."@en ;
    askg-onto:inSentence "12, we show the synthesized images obtained from our m = 16 predicted homographies for one input image."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-predicted_homographies,
        askg-data:Entity-synthesized_images .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "When compared with the ground-truth novel view, we can see that different homographies account for the motion of different regions in the image."@en ;
    askg-onto:inSentence "When compared with the ground-truth novel view, we can see that different homographies account for the motion of different regions in the image."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-image,
        askg-data:Entity-motion,
        askg-data:Entity-regions .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For instance, the homography corresponding to the top-left image accounts for the motion of the road."@en ;
    askg-onto:inSentence "For instance, the homography corresponding to the top-left image accounts for the motion of the road."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-motion_of_the_road .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1915 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "By contrast, the homography corresponding to the bottom-right image models the motion of the buildings."@en ;
    askg-onto:inSentence "By contrast, the homography corresponding to the bottom-right image models the motion of the buildings."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-motion_of_the_buildings .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1916 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Correctly combining these images then allows us to obtain a realistic novel view, as shown in the top row of Fig."@en ;
    askg-onto:inSentence "Correctly combining these images then allows us to obtain a realistic novel view, as shown in the top row of Fig."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-images,
        askg-data:Entity-realistic_novel_view .

askg-data:Paper-305358d7d24f2bf4-Section-19-Paragraph-191-Sentence-1917 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "12."@en ;
    askg-onto:inSentence "12."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company,
        askg-data:Entity-concept,
        askg-data:Entity-educational_institution,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-publication,
        askg-data:Entity-research,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "Abstract"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21,
        askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "This paper tackles the problem of novel view synthesis from a single image. In particular, we target real-world scenes with rich geometric structure, a challenging task due to the large appearance variations of such scenes and the lack of simple 3D models to represent them. Modern, learning-based approaches mostly focus on appearance to synthesize novel views and thus tend to generate predictions that are inconsistent with the underlying scene structure."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21-Sentence-211,
        askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21-Sentence-212,
        askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21-Sentence-213 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This paper tackles the problem of novel view synthesis from a single image."@en ;
    askg-onto:inSentence "This paper tackles the problem of novel view synthesis from a single image."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper,
        askg-data:Entity-problem_of_novel_view_synthesis_from_a_single_image .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21-Sentence-212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In particular, we target real-world scenes with rich geometric structure, a challenging task due to the large appearance variations of such scenes and the lack of simple 3D models to represent them."@en ;
    askg-onto:inSentence "In particular, we target real-world scenes with rich geometric structure, a challenging task due to the large appearance variations of such scenes and the lack of simple 3D models to represent them."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_variations,
        askg-data:Entity-geometric_structure,
        askg-data:Entity-real-world_scenes,
        askg-data:Entity-simple_3d_models .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-21-Sentence-213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Modern, learning-based approaches mostly focus on appearance to synthesize novel views and thus tend to generate predictions that are inconsistent with the underlying scene structure."@en ;
    askg-onto:inSentence "Modern, learning-based approaches mostly focus on appearance to synthesize novel views and thus tend to generate predictions that are inconsistent with the underlying scene structure."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance,
        askg-data:Entity-learning-based_approaches,
        askg-data:Entity-novel_views,
        askg-data:Entity-predictions,
        askg-data:Entity-underlying_scene_structure .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "By contrast, in this paper, we propose to exploit the 3D geometry of the scene to synthesize a novel view. Specifically, we approximate a real-world scene by a fixed number of planes, and learn to predict a set of homographies and their corresponding region masks to transform the input image into a novel view. To this end, we develop a new region-aware geometric transform network that performs these multiple tasks in a common framework. Our results on the outdoor KITTI and the indoor ScanNet datasets demonstrate the effectiveness of our network in generating highquality synthetic views that respect the scene geometry, thus outperforming the state-of-the-art methods."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-221,
        askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-222,
        askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-223,
        askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-224 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "By contrast, in this paper, we propose to exploit the 3D geometry of the scene to synthesize a novel view."@en ;
    askg-onto:inSentence "By contrast, in this paper, we propose to exploit the 3D geometry of the scene to synthesize a novel view."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-novel_view .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Specifically, we approximate a real-world scene by a fixed number of planes, and learn to predict a set of homographies and their corresponding region masks to transform the input image into a novel view."@en ;
    askg-onto:inSentence "Specifically, we approximate a real-world scene by a fixed number of planes, and learn to predict a set of homographies and their corresponding region masks to transform the input image into a novel view."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fixed_number_of_planes,
        askg-data:Entity-input_image,
        askg-data:Entity-novel_view,
        askg-data:Entity-real-world_scene,
        askg-data:Entity-region_masks,
        askg-data:Entity-set_of_homographies .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To this end, we develop a new region-aware geometric transform network that performs these multiple tasks in a common framework."@en ;
    askg-onto:inSentence "To this end, we develop a new region-aware geometric transform network that performs these multiple tasks in a common framework."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-new_region-aware_geometric_transform_network,
        askg-data:Entity-region-aware_geometric_transform_network .

askg-data:Paper-305358d7d24f2bf4-Section-2-Paragraph-22-Sentence-224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Our results on the outdoor KITTI and the indoor ScanNet datasets demonstrate the effectiveness of our network in generating highquality synthetic views that respect the scene geometry, thus outperforming the state-of-the-art methods."@en ;
    askg-onto:inSentence "Our results on the outdoor KITTI and the indoor ScanNet datasets demonstrate the effectiveness of our network in generating highquality synthetic views that respect the scene geometry, thus outperforming the state-of-the-art methods."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-highquality_synthetic_views,
        askg-data:Entity-our_network,
        askg-data:Entity-outdoor_kitti,
        askg-data:Entity-scannet,
        askg-data:Entity-state-of-the-art_methods .

askg-data:Paper-305358d7d24f2bf4-Section-20 a askg-onto:Section ;
    rdfs:label "Section 20"@en ;
    domo:Text "7.3. Selection Maps"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201 ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Fig. 13, we provide additional results from our selection network. While our seed regions typically cover only parts of the road, trees, sky, and buildings, our predicted selection maps can extend them to larger planar and semantically-coherent regions."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201-Sentence-2011,
        askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201-Sentence-2012,
        askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201-Sentence-2013 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201-Sentence-2011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Fig."@en ;
    askg-onto:inSentence "In Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig .

askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201-Sentence-2012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "13, we provide additional results from our selection network."@en ;
    askg-onto:inSentence "13, we provide additional results from our selection network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-results,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-20-Paragraph-201-Sentence-2013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "While our seed regions typically cover only parts of the road, trees, sky, and buildings, our predicted selection maps can extend them to larger planar and semantically-coherent regions."@en ;
    askg-onto:inSentence "While our seed regions typically cover only parts of the road, trees, sky, and buildings, our predicted selection maps can extend them to larger planar and semantically-coherent regions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-larger_planar_and_semantically-coherent_regions,
        askg-data:Entity-parts_of_the_road_trees_sky_and_buildings,
        askg-data:Entity-predicted_selection_maps,
        askg-data:Entity-seed_regions .

askg-data:Paper-305358d7d24f2bf4-Section-21 a askg-onto:Section ;
    rdfs:label "Section 21"@en ;
    domo:Text "7.4. Depth And Normal Prediction"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211 ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Fig. 14, we provide the visualisation of the estimated depth and normal map from our network for sampled images from KITTI test set. It shows that our estimation can well capture the scene structure compared with the ground truth."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211-Sentence-2111,
        askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211-Sentence-2112,
        askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211-Sentence-2113 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211-Sentence-2111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Fig."@en ;
    askg-onto:inSentence "In Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-an_illustration,
        askg-data:Entity-fig .

askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211-Sentence-2112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "14, we provide the visualisation of the estimated depth and normal map from our network for sampled images from KITTI test set."@en ;
    askg-onto:inSentence "14, we provide the visualisation of the estimated depth and normal map from our network for sampled images from KITTI test set."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-estimated_depth_and_normal_map,
        askg-data:Entity-kitti_test_set .

askg-data:Paper-305358d7d24f2bf4-Section-21-Paragraph-211-Sentence-2113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "It shows that our estimation can well capture the scene structure compared with the ground truth."@en ;
    askg-onto:inSentence "It shows that our estimation can well capture the scene structure compared with the ground truth."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-estimation,
        askg-data:Entity-ground_truth,
        askg-data:Entity-scene_structure .

askg-data:Paper-305358d7d24f2bf4-Section-22 a askg-onto:Section ;
    rdfs:label "Section 22"@en ;
    domo:Text "7.5. Failure Cases"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-221,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2211,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2213,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2214,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2215,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-222,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-223,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-224,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-225,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-226,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-227,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-228,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-229 ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-221 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "In Fig. 15, we show typical failure cases of our approach."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-221-Sentence-2211,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-221-Sentence-2212 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-221-Sentence-2211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In Fig."@en ;
    askg-onto:inSentence "In Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-fig .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-221-Sentence-2212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "15, we show typical failure cases of our approach."@en ;
    askg-onto:inSentence "15, we show typical failure cases of our approach."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_approach,
        askg-data:Entity-typical_failure_cases .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Figure 12. **Synthesized images from the 16 estimated homographies.** In the top row, we show the input image, the ground-truth novel view and the results of our complete model (Ours-Full) and of our model without refinement (Ours-Geo). The remaining images correspond to images synthesized with our estimated homographies. Note that different homographies correctly account for the motion of different regions between the input and novel view. For instance, the top-left image models the motion of the road, while the bottom-right one accounts for the motion of the buildings."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22101,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22102,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22103,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22104,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22105 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 12."@en ;
    askg-onto:inSentence "Figure 12."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Synthesized images from the 16 estimated homographies.** In the top row, we show the input image, the ground-truth novel view and the results of our complete model (Ours-Full) and of our model without refinement (Ours-Geo)."@en ;
    askg-onto:inSentence "**Synthesized images from the 16 estimated homographies.** In the top row, we show the input image, the ground-truth novel view and the results of our complete model (Ours-Full) and of our model without refinement (Ours-Geo)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_novel_view,
        askg-data:Entity-image,
        askg-data:Entity-input_image,
        askg-data:Entity-model,
        askg-data:Entity-ours-full,
        askg-data:Entity-ours-geo,
        askg-data:Entity-view .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22103 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The remaining images correspond to images synthesized with our estimated homographies."@en ;
    askg-onto:inSentence "The remaining images correspond to images synthesized with our estimated homographies."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-images .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22104 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Note that different homographies correctly account for the motion of different regions between the input and novel view."@en ;
    askg-onto:inSentence "Note that different homographies correctly account for the motion of different regions between the input and novel view."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-motion_of_different_regions .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2210-Sentence-22105 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For instance, the top-left image models the motion of the road, while the bottom-right one accounts for the motion of the buildings."@en ;
    askg-onto:inSentence "For instance, the top-left image models the motion of the road, while the bottom-right one accounts for the motion of the buildings."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-motion_of_the_buildings,
        askg-data:Entity-motion_of_the_road .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2211 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2211-Sentence-22111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2211-Sentence-22111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![15_image_0.png](15_image_0.png)"@en ;
    askg-onto:inSentence "![15_image_0.png](15_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company,
        askg-data:Entity-device,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "Figure 13. **Sample seed regions and predicted selection maps in the input view.** From left to right: seed region, predicted selection map and predicted selection map overlaid on the input image. Red indicates a high likelihood for a pixel to belong to the plane defined by the seed region and blue a low likelihood."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212-Sentence-22121,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212-Sentence-22122,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212-Sentence-22123 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212-Sentence-22121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 13."@en ;
    askg-onto:inSentence "Figure 13."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212-Sentence-22122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Sample seed regions and predicted selection maps in the input view.** From left to right: seed region, predicted selection map and predicted selection map overlaid on the input image."@en ;
    askg-onto:inSentence "**Sample seed regions and predicted selection maps in the input view.** From left to right: seed region, predicted selection map and predicted selection map overlaid on the input image."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_image,
        askg-data:Entity-input_view,
        askg-data:Entity-predicted_selection_map,
        askg-data:Entity-seed_region .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2212-Sentence-22123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Red indicates a high likelihood for a pixel to belong to the plane defined by the seed region and blue a low likelihood."@en ;
    askg-onto:inSentence "Red indicates a high likelihood for a pixel to belong to the plane defined by the seed region and blue a low likelihood."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pixel,
        askg-data:Entity-plane,
        askg-data:Entity-plane_defined_by_the_seed_region,
        askg-data:Entity-seed_region .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2213 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "![16_image_0.png](16_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2213-Sentence-22131 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2213-Sentence-22131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![16_image_0.png](16_image_0.png)"@en ;
    askg-onto:inSentence "![16_image_0.png](16_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adversarial_training,
        askg-data:Entity-alexnet,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning,
        askg-data:Entity-generative_adversarial_networks,
        askg-data:Entity-graphical_models,
        askg-data:Entity-imagenet,
        askg-data:Entity-method,
        askg-data:Entity-mit,
        askg-data:Entity-model,
        askg-data:Entity-pytorch,
        askg-data:Entity-software,
        askg-data:Entity-stanford_university,
        askg-data:Entity-tensorflow,
        askg-data:Entity-university,
        askg-data:Entity-university_of_california_berkeley .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2214 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "![17_image_0.png](17_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2214-Sentence-22141 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2214-Sentence-22141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![17_image_0.png](17_image_0.png)"@en ;
    askg-onto:inSentence "![17_image_0.png](17_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company,
        askg-data:Entity-data,
        askg-data:Entity-database,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-theory,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2215 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Figure 15. **Failure cases of our approach on KITTI.** Typical failures correspond to moving objects, or hallucination of large portions of the image (e.g., due to backward motion), in which case our approach tends to generate background instead of foreground objects."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2215-Sentence-22151,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2215-Sentence-22152 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2215-Sentence-22151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 15."@en ;
    askg-onto:inSentence "Figure 15."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_15,
        askg-data:Entity-research_findings .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-2215-Sentence-22152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Failure cases of our approach on KITTI.** Typical failures correspond to moving objects, or hallucination of large portions of the image (e.g., due to backward motion), in which case our approach tends to generate background instead of foreground objects."@en ;
    askg-onto:inSentence "**Failure cases of our approach on KITTI.** Typical failures correspond to moving objects, or hallucination of large portions of the image (e.g., due to backward motion), in which case our approach tends to generate background instead of foreground objects."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-background,
        askg-data:Entity-foreground_objects,
        askg-data:Entity-kitti,
        askg-data:Entity-moving_objects,
        askg-data:Entity-our_approach .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-222 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The failure cases are mainly due to i) moving objects, whose locations cannot be explained by camera motion (see the first row); 2) the need to hallucinate large portions of the image (e.g., because of backward motion), in which case our method tends to generate background and miss foreground objects (see the last two examples)."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-222-Sentence-2221 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-222-Sentence-2221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The failure cases are mainly due to i) moving objects, whose locations cannot be explained by camera motion (see the first row); 2) the need to hallucinate large portions of the image (e.g., because of backward motion), in which case our method tends to generate background and miss foreground objects (see the last two examples)."@en ;
    askg-onto:inSentence "The failure cases are mainly due to i) moving objects, whose locations cannot be explained by camera motion (see the first row); 2) the need to hallucinate large portions of the image (e.g., because of backward motion), in which case our method tends to generate background and miss foreground objects (see the last two examples)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-background,
        askg-data:Entity-camera_motion,
        askg-data:Entity-failure_cases,
        askg-data:Entity-foreground_objects,
        askg-data:Entity-moving_objects,
        askg-data:Entity-our_method .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-223 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![11_image_0.png](11_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-223-Sentence-2231 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-223-Sentence-2231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![11_image_0.png](11_image_0.png)"@en ;
    askg-onto:inSentence "![11_image_0.png](11_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-software,
        askg-data:Entity-technique,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-224 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "Figure 9. **Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-224-Sentence-2241,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-224-Sentence-2242 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-224-Sentence-2241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 9."@en ;
    askg-onto:inSentence "Figure 9."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-224-Sentence-2242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."@en ;
    askg-onto:inSentence "**Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow_method,
        askg-data:Entity-kitti,
        askg-data:Entity-more_realistic_results,
        askg-data:Entity-our_approach .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-225 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-225-Sentence-2251 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-225-Sentence-2251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![12_image_0.png](12_image_0.png)"@en ;
    askg-onto:inSentence "![12_image_0.png](12_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-caffe,
        askg-data:Entity-company,
        askg-data:Entity-convolutional_neural_networks,
        askg-data:Entity-dataset,
        askg-data:Entity-deep_learning,
        askg-data:Entity-framework,
        askg-data:Entity-google,
        askg-data:Entity-imagenet,
        askg-data:Entity-machine_learning,
        askg-data:Entity-method,
        askg-data:Entity-model,
        askg-data:Entity-openai,
        askg-data:Entity-pytorch,
        askg-data:Entity-reinforcement_learning,
        askg-data:Entity-stanford_university,
        askg-data:Entity-tensorflow,
        askg-data:Entity-university,
        askg-data:Entity-university_of_california .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-226 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Figure 10. **Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-226-Sentence-2261,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-226-Sentence-2262 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-226-Sentence-2261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 10."@en ;
    askg-onto:inSentence "Figure 10."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-figure_10 .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-226-Sentence-2262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."@en ;
    askg-onto:inSentence "**Qualitative comparison of our approach with the appearance flow method of [29] on KITTI.** While appearance flow yields artifacts, our approach, which reasons about 3D geometry, yields more realistic results."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-appearance_flow,
        askg-data:Entity-appearance_flow_method,
        askg-data:Entity-artifacts,
        askg-data:Entity-more_realistic_results,
        askg-data:Entity-our_approach .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-227 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-227-Sentence-2271 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-227-Sentence-2271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![13_image_0.png](13_image_0.png)"@en ;
    askg-onto:inSentence "![13_image_0.png](13_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bert,
        askg-data:Entity-field_of_study,
        askg-data:Entity-model,
        askg-data:Entity-natural_language_processing,
        askg-data:Entity-pytorch,
        askg-data:Entity-question_answering,
        askg-data:Entity-sentiment_analysis,
        askg-data:Entity-software,
        askg-data:Entity-stanford_university,
        askg-data:Entity-tensorflow,
        askg-data:Entity-text_classification,
        askg-data:Entity-transformers,
        askg-data:Entity-university,
        askg-data:Entity-university_of_california_berkeley .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-228 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Figure 11. Qualitative results of our approach on ScanNet."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-228-Sentence-2281,
        askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-228-Sentence-2282 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-228-Sentence-2281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 11."@en ;
    askg-onto:inSentence "Figure 11."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_11 .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-228-Sentence-2282 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Qualitative results of our approach on ScanNet."@en ;
    askg-onto:inSentence "Qualitative results of our approach on ScanNet."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_approach,
        askg-data:Entity-scannet .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-229 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-229-Sentence-2291 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-22-Paragraph-229-Sentence-2291 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![14_image_0.png](14_image_0.png)"@en ;
    askg-onto:inSentence "![14_image_0.png](14_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-crispr,
        askg-data:Entity-deep_learning,
        askg-data:Entity-gene_expression_analysis,
        askg-data:Entity-genome_editing,
        askg-data:Entity-machine_learning,
        askg-data:Entity-nature,
        askg-data:Entity-researchgate,
        askg-data:Entity-rna-seq,
        askg-data:Entity-scientific_collaboration,
        askg-data:Entity-scientific_research,
        askg-data:Entity-university_of_california_berkeley .

askg-data:Paper-305358d7d24f2bf4-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "1. Introduction"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-31,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-310,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-33,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-34,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-36,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-37,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39 ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-31 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Human beings can easily hallucinate what a scene would look like from a different viewpoint, or, for a dynamic scene, in the near future. Automatically performing such a *novel view synthesis*, however, remains a challenging task for computer vision systems."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-31-Sentence-311,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-31-Sentence-312 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-31-Sentence-311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Human beings can easily hallucinate what a scene would look like from a different viewpoint, or, for a dynamic scene, in the near future."@en ;
    askg-onto:inSentence "Human beings can easily hallucinate what a scene would look like from a different viewpoint, or, for a dynamic scene, in the near future."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-human_beings,
        askg-data:Entity-scene .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-31-Sentence-312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Automatically performing such a *novel view synthesis*, however, remains a challenging task for computer vision systems."@en ;
    askg-onto:inSentence "Automatically performing such a *novel view synthesis*, however, remains a challenging task for computer vision systems."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision_systems,
        askg-data:Entity-method,
        askg-data:Entity-novel_view_synthesis,
        askg-data:Entity-system .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-310 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "We demonstrate the effectiveness of our approach on the challenging KITTI odometry dataset [9] and ScanNet [4], depicting complex urban outdoor scenes and indoor scenes, respectively. Thanks to our geometry-based reasoning, our method not only outperforms the state-of-the-art appearance flow technique of [29] quantitatively, but also yields visually more realistic predictions."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-310-Sentence-3101,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-310-Sentence-3102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-310-Sentence-3101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We demonstrate the effectiveness of our approach on the challenging KITTI odometry dataset [9] and ScanNet [4], depicting complex urban outdoor scenes and indoor scenes, respectively."@en ;
    askg-onto:inSentence "We demonstrate the effectiveness of our approach on the challenging KITTI odometry dataset [9] and ScanNet [4], depicting complex urban outdoor scenes and indoor scenes, respectively."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kitti_odometry_dataset,
        askg-data:Entity-our_approach,
        askg-data:Entity-scannet .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-310-Sentence-3102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Thanks to our geometry-based reasoning, our method not only outperforms the state-of-the-art appearance flow technique of [29] quantitatively, but also yields visually more realistic predictions."@en ;
    askg-onto:inSentence "Thanks to our geometry-based reasoning, our method not only outperforms the state-of-the-art appearance flow technique of [29] quantitatively, but also yields visually more realistic predictions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-our_method,
        askg-data:Entity-state-of-the-art_appearance_flow_technique,
        askg-data:Entity-visually_more_realistic_predictions .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Over the past two decades, the most popular approach to synthesizing new views has been to reconstruct an exact or approximate 3D scene model from multiple views [30, 17, 18, 25, 2]. By contrast, view synthesis from a single image, which can be applied to a broader range of problems, has received much less attention. To overcome the lack of depth information, early methods have proposed to leverage semantic-based priors [12] and geometric cues, such as vanishing points [13], which, while effective, tend to be less robust than their multi-view counterparts."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32-Sentence-321,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32-Sentence-322,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32-Sentence-323 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32-Sentence-321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Over the past two decades, the most popular approach to synthesizing new views has been to reconstruct an exact or approximate 3D scene model from multiple views [30, 17, 18, 25, 2]."@en ;
    askg-onto:inSentence "Over the past two decades, the most popular approach to synthesizing new views has been to reconstruct an exact or approximate 3D scene model from multiple views [30, 17, 18, 25, 2]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_scene_model,
        askg-data:Entity-multiple_views .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32-Sentence-322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "By contrast, view synthesis from a single image, which can be applied to a broader range of problems, has received much less attention."@en ;
    askg-onto:inSentence "By contrast, view synthesis from a single image, which can be applied to a broader range of problems, has received much less attention."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_broader_range_of_problems,
        askg-data:Entity-view_synthesis_from_a_single_image .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-32-Sentence-323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To overcome the lack of depth information, early methods have proposed to leverage semantic-based priors [12] and geometric cues, such as vanishing points [13], which, while effective, tend to be less robust than their multi-view counterparts."@en ;
    askg-onto:inSentence "To overcome the lack of depth information, early methods have proposed to leverage semantic-based priors [12] and geometric cues, such as vanishing points [13], which, while effective, tend to be less robust than their multi-view counterparts."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometric_cues,
        askg-data:Entity-semantic-based_priors .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-33 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Inspired by the recent deep learning revolution in computer vision, several works have proposed to exploit Deep"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-33-Sentence-331 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-33-Sentence-331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Inspired by the recent deep learning revolution in computer vision, several works have proposed to exploit Deep"@en ;
    askg-onto:inSentence "Inspired by the recent deep learning revolution in computer vision, several works have proposed to exploit Deep"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computer_vision,
        askg-data:Entity-deep_learning .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-34 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![0_image_0.png](0_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-34-Sentence-341 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-34-Sentence-341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![0_image_0.png](0_image_0.png)"@en ;
    askg-onto:inSentence "![0_image_0.png](0_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_analysis_software,
        askg-data:Entity-device,
        askg-data:Entity-dna_sequencing_technology,
        askg-data:Entity-minion,
        askg-data:Entity-oxford_nanopore_technologies,
        askg-data:Entity-software,
        askg-data:Entity-technology,
        askg-data:Entity-university,
        askg-data:Entity-university_of_oxford .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "[29] Ours Figure 1. **Novel view synthesis from a single image.** Given an input image of the scene and a relative pose, we seek to predict a new image of the scene observed from this new viewpoint. To this end, and in contrast with state-of-the-art methods, we propose to explicitly rely on 3D geometry within a deep learning paradigm. As a consequence, and as evidenced by our results, our predictions better respect the scene structure and are thus more realistic."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-351,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-352,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-353,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-354 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[29] Ours Figure 1."@en ;
    askg-onto:inSentence "[29] Ours Figure 1."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ours .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Novel view synthesis from a single image.** Given an input image of the scene and a relative pose, we seek to predict a new image of the scene observed from this new viewpoint."@en ;
    askg-onto:inSentence "**Novel view synthesis from a single image.** Given an input image of the scene and a relative pose, we seek to predict a new image of the scene observed from this new viewpoint."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-new_viewpoint,
        askg-data:Entity-novel_view_synthesis,
        askg-data:Entity-scene .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-353 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To this end, and in contrast with state-of-the-art methods, we propose to explicitly rely on 3D geometry within a deep learning paradigm."@en ;
    askg-onto:inSentence "To this end, and in contrast with state-of-the-art methods, we propose to explicitly rely on 3D geometry within a deep learning paradigm."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-deep_learning_paradigm .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-35-Sentence-354 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As a consequence, and as evidenced by our results, our predictions better respect the scene structure and are thus more realistic."@en ;
    askg-onto:inSentence "As a consequence, and as evidenced by our results, our predictions better respect the scene structure and are thus more realistic."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-predictions,
        askg-data:Entity-results,
        askg-data:Entity-scene_structure .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-36 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Convolutional Neural Networks (CNNs) to tackle the novel view synthesis problem [6, 24, 29]. Whether predicting image pixels directly [24], plane-sweep volumes [6], appearance flow [29], or appearance flow, visibility and the intensity of pixels that were not in the input view [20], these methods, in essence, all aim to solely leverage appearance to predict the flow of each pixel from the input view to the novel view without exploiting the flow of the other pixels."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-36-Sentence-361,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-36-Sentence-362 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-36-Sentence-361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Convolutional Neural Networks (CNNs) to tackle the novel view synthesis problem [6, 24, 29]."@en ;
    askg-onto:inSentence "Convolutional Neural Networks (CNNs) to tackle the novel view synthesis problem [6, 24, 29]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolutional_neural_networks_cnns,
        askg-data:Entity-novel_view_synthesis_problem .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-36-Sentence-362 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Whether predicting image pixels directly [24], plane-sweep volumes [6], appearance flow [29], or appearance flow, visibility and the intensity of pixels that were not in the input view [20], these methods, in essence, all aim to solely leverage appearance to predict the flow of each pixel from the input view to the novel view without exploiting the flow of the other pixels."@en ;
    askg-onto:inSentence "Whether predicting image pixels directly [24], plane-sweep volumes [6], appearance flow [29], or appearance flow, visibility and the intensity of pixels that were not in the input view [20], these methods, in essence, all aim to solely leverage appearance to predict the flow of each pixel from the input view to the novel view without exploiting the flow of the other pixels."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow,
        askg-data:Entity-flow_of_each_pixel,
        askg-data:Entity-image_pixels,
        askg-data:Entity-intensity_of_pixels,
        askg-data:Entity-plane-sweep_volumes,
        askg-data:Entity-visibility .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-37 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "As such, as shown in Fig. 1, they tend to generate artefacts, such as distorted local structures in the synthesized images."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-37-Sentence-371,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-37-Sentence-372 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-37-Sentence-371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As such, as shown in Fig."@en ;
    askg-onto:inSentence "As such, as shown in Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-37-Sentence-372 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "1, they tend to generate artefacts, such as distorted local structures in the synthesized images."@en ;
    askg-onto:inSentence "1, they tend to generate artefacts, such as distorted local structures in the synthesized images."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artefacts,
        askg-data:Entity-distorted_local_structures .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "In this paper, we propose to explicitly account for 3D geometry, and thus respect 3D scene structure, in the singleimage novel view synthesis process. To this end, we approximate the scene by a fixed number of planes, and learn to predict corresponding homographies that, once applied to the input image, generate a set of candidate images for the novel view. We then learn to predict a selection map corresponding to each homography, which, after warping, is used to combine the candidate images to generate the novel view. In essence, our homography-based approach enforces 1 geometric constraints on the flow field, thus modeling scene structure. Our approach can be thought of as a divide-andconquer strategy that allows us to encode a 3D geometric prior while learning the image transformation."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-381,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-382,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-383,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-384,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-385 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-381 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this paper, we propose to explicitly account for 3D geometry, and thus respect 3D scene structure, in the singleimage novel view synthesis process."@en ;
    askg-onto:inSentence "In this paper, we propose to explicitly account for 3D geometry, and thus respect 3D scene structure, in the singleimage novel view synthesis process."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-3d_scene_structure,
        askg-data:Entity-single-image_novel_view_synthesis_process .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-382 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To this end, we approximate the scene by a fixed number of planes, and learn to predict corresponding homographies that, once applied to the input image, generate a set of candidate images for the novel view."@en ;
    askg-onto:inSentence "To this end, we approximate the scene by a fixed number of planes, and learn to predict corresponding homographies that, once applied to the input image, generate a set of candidate images for the novel view."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-candidate_images,
        askg-data:Entity-fixed_number_of_planes,
        askg-data:Entity-homographies,
        askg-data:Entity-novel_view,
        askg-data:Entity-scene .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-383 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We then learn to predict a selection map corresponding to each homography, which, after warping, is used to combine the candidate images to generate the novel view."@en ;
    askg-onto:inSentence "We then learn to predict a selection map corresponding to each homography, which, after warping, is used to combine the candidate images to generate the novel view."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-candidate_images,
        askg-data:Entity-homography,
        askg-data:Entity-novel_view,
        askg-data:Entity-selection_map .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-384 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In essence, our homography-based approach enforces 1 geometric constraints on the flow field, thus modeling scene structure."@en ;
    askg-onto:inSentence "In essence, our homography-based approach enforces 1 geometric constraints on the flow field, thus modeling scene structure."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometric_constraints,
        askg-data:Entity-homography-based_approach,
        askg-data:Entity-scene_structure .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-38-Sentence-385 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Our approach can be thought of as a divide-andconquer strategy that allows us to encode a 3D geometric prior while learning the image transformation."@en ;
    askg-onto:inSentence "Our approach can be thought of as a divide-andconquer strategy that allows us to encode a 3D geometric prior while learning the image transformation."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometric_prior,
        askg-data:Entity-approach,
        askg-data:Entity-divide-and-conquer_strategy,
        askg-data:Entity-image_transformation .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "To achieve this, we develop a novel deep architecture consisting of two subnetworks. The first one estimates pixel-wise depth and normals in the input image, which, in conjunction with the relative pose between the input and novel views, are then used to estimate one homography for each planar region in the scene. These homographies then let us produce a set of warped input images. The second subnetwork aims to predict a pixel-wise probability, or selection map encoding to which homography each input pixel should be associated. These maps are then warped with the corresponding predicted homographies, and the novel view is generated by combining the warped input images according to the warped selection maps. To account for pixels not in the input view and potential blur arising from the combination of multiple warped images, inspired by [20], we further propose to refine the synthesized image with an encoder-decoder network with skip connections. As evidenced by Fig. 1, our complete framework yields realistic-looking novel views."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-391,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-392,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-393,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-394,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-395,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-396,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-397,
        askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-398 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-391 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To achieve this, we develop a novel deep architecture consisting of two subnetworks."@en ;
    askg-onto:inSentence "To achieve this, we develop a novel deep architecture consisting of two subnetworks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_architecture,
        askg-data:Entity-two_subnetworks .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-392 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The first one estimates pixel-wise depth and normals in the input image, which, in conjunction with the relative pose between the input and novel views, are then used to estimate one homography for each planar region in the scene."@en ;
    askg-onto:inSentence "The first one estimates pixel-wise depth and normals in the input image, which, in conjunction with the relative pose between the input and novel views, are then used to estimate one homography for each planar region in the scene."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-input_image,
        askg-data:Entity-normals_in_the_input_image,
        askg-data:Entity-pixel-wise_depth,
        askg-data:Entity-planar_region,
        askg-data:Entity-relative_pose,
        askg-data:Entity-scene .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-393 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "These homographies then let us produce a set of warped input images."@en ;
    askg-onto:inSentence "These homographies then let us produce a set of warped input images."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-394 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The second subnetwork aims to predict a pixel-wise probability, or selection map encoding to which homography each input pixel should be associated."@en ;
    askg-onto:inSentence "The second subnetwork aims to predict a pixel-wise probability, or selection map encoding to which homography each input pixel should be associated."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-input_pixel,
        askg-data:Entity-pixel-wise_probability,
        askg-data:Entity-selection_map,
        askg-data:Entity-subnetwork .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-395 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "These maps are then warped with the corresponding predicted homographies, and the novel view is generated by combining the warped input images according to the warped selection maps."@en ;
    askg-onto:inSentence "These maps are then warped with the corresponding predicted homographies, and the novel view is generated by combining the warped input images according to the warped selection maps."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-maps,
        askg-data:Entity-predicted_homographies,
        askg-data:Entity-view,
        askg-data:Entity-warped_input_images,
        askg-data:Entity-warped_selection_maps .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-396 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "To account for pixels not in the input view and potential blur arising from the combination of multiple warped images, inspired by [20], we further propose to refine the synthesized image with an encoder-decoder network with skip connections."@en ;
    askg-onto:inSentence "To account for pixels not in the input view and potential blur arising from the combination of multiple warped images, inspired by [20], we further propose to refine the synthesized image with an encoder-decoder network with skip connections."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_network,
        askg-data:Entity-skip_connections,
        askg-data:Entity-synthesized_image .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-397 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "As evidenced by Fig."@en ;
    askg-onto:inSentence "As evidenced by Fig."^^xsd:string ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-3-Paragraph-39-Sentence-398 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "1, our complete framework yields realistic-looking novel views."@en ;
    askg-onto:inSentence "1, our complete framework yields realistic-looking novel views."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-framework,
        askg-data:Entity-novel_views .

askg-data:Paper-305358d7d24f2bf4-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "2. Related Work"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-45,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Over the years, two main classes of methods have been proposed to address the novel view synthesis problem: those that rely on geometry, and the more recent ones that exploit deep learning. Below, we review the methods belonging to these two classes. Geometry-based view synthesis. Originally, the most popular approach to view synthesis consisted of explicitly modeling 3D information, via either a detailed 3D model, or an approximate representation of the 3D scene structure. This idea was introduced in [18] more than two decades ago, by relying on multi-view stereo and a warping strategy. With the impressive progress of multi-view 3D reconstruction techniques [7], highly detailed models can be obtained, and novel views generated by making use of the target pose given as input. In complex scenes, however, this process remains challenging due to, e.g., occlusions leading to holes in the 3D models. In this context, [2] first reconstructs a partial scene from multiple images, and then synthesizes depth to fill in the missing pixels and correct the unreliable regions. Instead of relying on dense reconstruction, [30] leverages sparse points obtained from structurefrom-motion in conjunction with segmented image regions, each of which is assumed to be planar and associated to a homography to warp the input image. While effective in their context, these methods are inapplicable to the scenario where a single image is available to synthesize a novel view."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-4110,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-413,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-414,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-415,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-416,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-417,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-418,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-419 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Over the years, two main classes of methods have been proposed to address the novel view synthesis problem: those that rely on geometry, and the more recent ones that exploit deep learning."@en ;
    askg-onto:inSentence "Over the years, two main classes of methods have been proposed to address the novel view synthesis problem: those that rely on geometry, and the more recent ones that exploit deep learning."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deep_learning,
        askg-data:Entity-geometry,
        askg-data:Entity-methods,
        askg-data:Entity-novel_view_synthesis_problem .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-4110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "While effective in their context, these methods are inapplicable to the scenario where a single image is available to synthesize a novel view."@en ;
    askg-onto:inSentence "While effective in their context, these methods are inapplicable to the scenario where a single image is available to synthesize a novel view."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-the_scenario_where_a_single_image_is_available_to_synthesize_a_novel_view .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Below, we review the methods belonging to these two classes."@en ;
    askg-onto:inSentence "Below, we review the methods belonging to these two classes."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classes,
        askg-data:Entity-methods .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Geometry-based view synthesis."@en ;
    askg-onto:inSentence "Geometry-based view synthesis."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometry-based_view_synthesis,
        askg-data:Entity-method .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Originally, the most popular approach to view synthesis consisted of explicitly modeling 3D information, via either a detailed 3D model, or an approximate representation of the 3D scene structure."@en ;
    askg-onto:inSentence "Originally, the most popular approach to view synthesis consisted of explicitly modeling 3D information, via either a detailed 3D model, or an approximate representation of the 3D scene structure."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_information,
        askg-data:Entity-3d_model,
        askg-data:Entity-approximate_representation_of_the_3d_scene_structure,
        askg-data:Entity-view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-415 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This idea was introduced in [18] more than two decades ago, by relying on multi-view stereo and a warping strategy."@en ;
    askg-onto:inSentence "This idea was introduced in [18] more than two decades ago, by relying on multi-view stereo and a warping strategy."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-multi-view_stereo,
        askg-data:Entity-warping_strategy .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-416 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "With the impressive progress of multi-view 3D reconstruction techniques [7], highly detailed models can be obtained, and novel views generated by making use of the target pose given as input."@en ;
    askg-onto:inSentence "With the impressive progress of multi-view 3D reconstruction techniques [7], highly detailed models can be obtained, and novel views generated by making use of the target pose given as input."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-highly_detailed_models,
        askg-data:Entity-multi-view_3d_reconstruction_techniques,
        askg-data:Entity-novel_views,
        askg-data:Entity-target_pose .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-417 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "In complex scenes, however, this process remains challenging due to, e.g., occlusions leading to holes in the 3D models."@en ;
    askg-onto:inSentence "In complex scenes, however, this process remains challenging due to, e.g., occlusions leading to holes in the 3D models."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_models,
        askg-data:Entity-occlusions .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-418 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In this context, [2] first reconstructs a partial scene from multiple images, and then synthesizes depth to fill in the missing pixels and correct the unreliable regions."@en ;
    askg-onto:inSentence "In this context, [2] first reconstructs a partial scene from multiple images, and then synthesizes depth to fill in the missing pixels and correct the unreliable regions."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth,
        askg-data:Entity-missing_pixels,
        askg-data:Entity-multiple_images,
        askg-data:Entity-partial_scene,
        askg-data:Entity-unreliable_regions .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-41-Sentence-419 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Instead of relying on dense reconstruction, [30] leverages sparse points obtained from structurefrom-motion in conjunction with segmented image regions, each of which is assumed to be planar and associated to a homography to warp the input image."@en ;
    askg-onto:inSentence "Instead of relying on dense reconstruction, [30] leverages sparse points obtained from structurefrom-motion in conjunction with segmented image regions, each of which is assumed to be planar and associated to a homography to warp the input image."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-segmented_image_regions,
        askg-data:Entity-sparse_points,
        askg-data:Entity-structure-from-motion .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Only little work has been done to leverage geometry for single-image novel view synthesis. In particular, [13] models the scene as an axis-aligned box, and requires a user to annotate the box coordinates, vanishing points and foreground to be able to render the model from a different viewpoint. In [12], the image is labeled into three geometric classes, which defines an approximate scene structure that can be rendered from a new viewpoint. These methods, however, only model a very coarse structure of the scene, and therefore cannot yield realistic novel views. By contrast, the recent work of [22] leverages a large collection of 3D models to infer the one closest to an input image. While effective for individual objects, this approach does not translate well to complex, real-world scenes with rich structures and dynamic motion, such as urban ones."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-421,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-422,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-423,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-424,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-425,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-426 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Only little work has been done to leverage geometry for single-image novel view synthesis."@en ;
    askg-onto:inSentence "Only little work has been done to leverage geometry for single-image novel view synthesis."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometry,
        askg-data:Entity-single-image_novel_view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In particular, [13] models the scene as an axis-aligned box, and requires a user to annotate the box coordinates, vanishing points and foreground to be able to render the model from a different viewpoint."@en ;
    askg-onto:inSentence "In particular, [13] models the scene as an axis-aligned box, and requires a user to annotate the box coordinates, vanishing points and foreground to be able to render the model from a different viewpoint."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-axis-aligned_box,
        askg-data:Entity-box_coordinates,
        askg-data:Entity-different_viewpoint,
        askg-data:Entity-foreground,
        askg-data:Entity-model,
        askg-data:Entity-scene,
        askg-data:Entity-user,
        askg-data:Entity-vanishing_points .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In [12], the image is labeled into three geometric classes, which defines an approximate scene structure that can be rendered from a new viewpoint."@en ;
    askg-onto:inSentence "In [12], the image is labeled into three geometric classes, which defines an approximate scene structure that can be rendered from a new viewpoint."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-three_geometric_classes .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-424 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These methods, however, only model a very coarse structure of the scene, and therefore cannot yield realistic novel views."@en ;
    askg-onto:inSentence "These methods, however, only model a very coarse structure of the scene, and therefore cannot yield realistic novel views."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-coarse_structure,
        askg-data:Entity-methods,
        askg-data:Entity-realistic_novel_views .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-425 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "By contrast, the recent work of [22] leverages a large collection of 3D models to infer the one closest to an input image."@en ;
    askg-onto:inSentence "By contrast, the recent work of [22] leverages a large collection of 3D models to infer the one closest to an input image."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_models,
        askg-data:Entity-input_image .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-42-Sentence-426 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "While effective for individual objects, this approach does not translate well to complex, real-world scenes with rich structures and dynamic motion, such as urban ones."@en ;
    askg-onto:inSentence "While effective for individual objects, this approach does not translate well to complex, real-world scenes with rich structures and dynamic motion, such as urban ones."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complex_real-world_scenes,
        askg-data:Entity-this_approach .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "View synthesis from CNNs. With the advent of deep learning in computer vision, CNNs have recently been investigated to generate novel views. In particular, [6] proposes to synthesize the novel image from neighboring views. To this end, a plane-sweep volume, encoding a set of possible image appearances, was used as input to a network whose goal was to select the correct pixel appearance in the volume. This framework, however, requires a large memory and was only evaluated for view interpolation. Similarly, [15] tackles the view interpolation task from a pair of images, but aims to learn to rectify the two images and predict pixels correspondences. The novel view is generated by fusing the pixels of the image pair using the estimated correspondence. In contrast to these methods, we focus on single-image view synthesis."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-431,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-432,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-433,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-434,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-435,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-436,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-437,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-438 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "View synthesis from CNNs."@en ;
    askg-onto:inSentence "View synthesis from CNNs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnns,
        askg-data:Entity-view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-432 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "With the advent of deep learning in computer vision, CNNs have recently been investigated to generate novel views."@en ;
    askg-onto:inSentence "With the advent of deep learning in computer vision, CNNs have recently been investigated to generate novel views."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cnns,
        askg-data:Entity-computer_vision,
        askg-data:Entity-deep_learning,
        askg-data:Entity-novel_views .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-433 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In particular, [6] proposes to synthesize the novel image from neighboring views."@en ;
    askg-onto:inSentence "In particular, [6] proposes to synthesize the novel image from neighboring views."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-neighboring_views .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-434 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To this end, a plane-sweep volume, encoding a set of possible image appearances, was used as input to a network whose goal was to select the correct pixel appearance in the volume."@en ;
    askg-onto:inSentence "To this end, a plane-sweep volume, encoding a set of possible image appearances, was used as input to a network whose goal was to select the correct pixel appearance in the volume."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network,
        askg-data:Entity-pixel_appearance,
        askg-data:Entity-plane-sweep_volume .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-435 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This framework, however, requires a large memory and was only evaluated for view interpolation."@en ;
    askg-onto:inSentence "This framework, however, requires a large memory and was only evaluated for view interpolation."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-framework,
        askg-data:Entity-large_memory,
        askg-data:Entity-view_interpolation .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-436 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Similarly, [15] tackles the view interpolation task from a pair of images, but aims to learn to rectify the two images and predict pixels correspondences."@en ;
    askg-onto:inSentence "Similarly, [15] tackles the view interpolation task from a pair of images, but aims to learn to rectify the two images and predict pixels correspondences."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pair_of_images,
        askg-data:Entity-pixels_correspondences,
        askg-data:Entity-two_images,
        askg-data:Entity-view_interpolation_task .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-437 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The novel view is generated by fusing the pixels of the image pair using the estimated correspondence."@en ;
    askg-onto:inSentence "The novel view is generated by fusing the pixels of the image pair using the estimated correspondence."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-correspondence,
        askg-data:Entity-image_pair,
        askg-data:Entity-pixels .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-43-Sentence-438 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "In contrast to these methods, we focus on single-image view synthesis."@en ;
    askg-onto:inSentence "In contrast to these methods, we focus on single-image view synthesis."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-single-image_view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "In this context, [16] trains a variational auto-encoder to decouple the image into hidden factors, constrained to correspond to viewpoint and lighting conditions. While this network can generate an image from a new viewpoint by manipulating the hidden factors, it is mostly restricted to small rotations. In [24], an encoder-decoder network is trained to directly synthesize the pixels of the new view from the input image and the relative pose. While this network was shown to handle large rotations, the predicted images are typically blurry. Instead of directly synthesizing the image, [29] proposes to predict the displacements of the pixels from the input view to the new one, named the appearance flow. While this method yields sharper results, by predicting the displacements in a pixel-wise manner, it doesn't account for the scene structure, and thus, as illustrated in Fig. 1, introduces unrealistic artefacts. The recent work of [20] builds upon appearance flow by additionally predicting a visibility map, whose goal is to reflect the visibility constraints arising from a 3D object shape. During"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-441,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-442,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-443,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-444,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-445,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-446,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-447,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-448,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-449 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In this context, [16] trains a variational auto-encoder to decouple the image into hidden factors, constrained to correspond to viewpoint and lighting conditions."@en ;
    askg-onto:inSentence "In this context, [16] trains a variational auto-encoder to decouple the image into hidden factors, constrained to correspond to viewpoint and lighting conditions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hidden_factors,
        askg-data:Entity-variational_auto-encoder .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-442 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While this network can generate an image from a new viewpoint by manipulating the hidden factors, it is mostly restricted to small rotations."@en ;
    askg-onto:inSentence "While this network can generate an image from a new viewpoint by manipulating the hidden factors, it is mostly restricted to small rotations."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-network .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-443 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In [24], an encoder-decoder network is trained to directly synthesize the pixels of the new view from the input image and the relative pose."@en ;
    askg-onto:inSentence "In [24], an encoder-decoder network is trained to directly synthesize the pixels of the new view from the input image and the relative pose."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_network,
        askg-data:Entity-pixels_of_the_new_view,
        askg-data:Entity-relative_pose .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-444 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "While this network was shown to handle large rotations, the predicted images are typically blurry."@en ;
    askg-onto:inSentence "While this network was shown to handle large rotations, the predicted images are typically blurry."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blurry,
        askg-data:Entity-large_rotations,
        askg-data:Entity-network,
        askg-data:Entity-predicted_images .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-445 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Instead of directly synthesizing the image, [29] proposes to predict the displacements of the pixels from the input view to the new one, named the appearance flow."@en ;
    askg-onto:inSentence "Instead of directly synthesizing the image, [29] proposes to predict the displacements of the pixels from the input view to the new one, named the appearance flow."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-appearance_flow,
        askg-data:Entity-displacements_of_the_pixels,
        askg-data:Entity-input_view,
        askg-data:Entity-new_view .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-446 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "While this method yields sharper results, by predicting the displacements in a pixel-wise manner, it doesn't account for the scene structure, and thus, as illustrated in Fig."@en ;
    askg-onto:inSentence "While this method yields sharper results, by predicting the displacements in a pixel-wise manner, it doesn't account for the scene structure, and thus, as illustrated in Fig."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-displacements,
        askg-data:Entity-scene_structure,
        askg-data:Entity-sharper_results,
        askg-data:Entity-this_method .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-447 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "1, introduces unrealistic artefacts."@en ;
    askg-onto:inSentence "1, introduces unrealistic artefacts."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artefacts,
        askg-data:Entity-unrealistic .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-448 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "The recent work of [20] builds upon appearance flow by additionally predicting a visibility map, whose goal is to reflect the visibility constraints arising from a 3D object shape."@en ;
    askg-onto:inSentence "The recent work of [20] builds upon appearance flow by additionally predicting a visibility map, whose goal is to reflect the visibility constraints arising from a 3D object shape."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_object_shape,
        askg-data:Entity-appearance_flow,
        askg-data:Entity-visibility_constraints,
        askg-data:Entity-visibility_map .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-44-Sentence-449 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "During"@en ;
    askg-onto:inSentence "During"^^xsd:string ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-45 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Figure 2. **Our region-aware geometric-transform network.** To tackle the single-image novel view synthesis problem, we develop a"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-45-Sentence-451,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-45-Sentence-452 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-45-Sentence-451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 2."@en ;
    askg-onto:inSentence "Figure 2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-figure_2 .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-45-Sentence-452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Our region-aware geometric-transform network.** To tackle the single-image novel view synthesis problem, we develop a"@en ;
    askg-onto:inSentence "**Our region-aware geometric-transform network.** To tackle the single-image novel view synthesis problem, we develop a"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-region-aware_geometric-transform_network,
        askg-data:Entity-single-image_novel_view_synthesis_problem .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "![2_image_0.png](2_image_0.png) geometry-aware deep architecture consisting of two subnetworks. Given an input image, the first one predicts pixel-wise depth and normal maps. These predictions are then used in conjunction with segmentation masks obtained from the image and the desired relative pose to generate a fixed number of homographies, which are in turn employed to produce warped images. The second subnetwork predicts pixel-wise selection maps that associate each input pixel with one homography. These maps are warped by their respective homographies, and the novel view is obtained by combining the warped images according to the warped selection maps."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-461,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-462,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-463,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-464,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-465 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![2_image_0.png](2_image_0.png) geometry-aware deep architecture consisting of two subnetworks."@en ;
    askg-onto:inSentence "![2_image_0.png](2_image_0.png) geometry-aware deep architecture consisting of two subnetworks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometry-aware_deep_architecture,
        askg-data:Entity-two_subnetworks .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given an input image, the first one predicts pixel-wise depth and normal maps."@en ;
    askg-onto:inSentence "Given an input image, the first one predicts pixel-wise depth and normal maps."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_image,
        askg-data:Entity-pixel-wise_depth_and_normal_maps .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-463 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "These predictions are then used in conjunction with segmentation masks obtained from the image and the desired relative pose to generate a fixed number of homographies, which are in turn employed to produce warped images."@en ;
    askg-onto:inSentence "These predictions are then used in conjunction with segmentation masks obtained from the image and the desired relative pose to generate a fixed number of homographies, which are in turn employed to produce warped images."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-image,
        askg-data:Entity-predictions,
        askg-data:Entity-segmentation_masks,
        askg-data:Entity-warped_images .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-464 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The second subnetwork predicts pixel-wise selection maps that associate each input pixel with one homography."@en ;
    askg-onto:inSentence "The second subnetwork predicts pixel-wise selection maps that associate each input pixel with one homography."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-input_pixel,
        askg-data:Entity-pixel-wise_selection_maps,
        askg-data:Entity-subnetwork .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-46-Sentence-465 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "These maps are warped by their respective homographies, and the novel view is obtained by combining the warped images according to the warped selection maps."@en ;
    askg-onto:inSentence "These maps are warped by their respective homographies, and the novel view is obtained by combining the warped images according to the warped selection maps."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-maps,
        askg-data:Entity-view,
        askg-data:Entity-warped_images,
        askg-data:Entity-warped_selection_maps .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "training, the ground-truth visibility maps are obtained by making use of 3D CAD models of the objects of interest. While this indeed exploits 3D geometry, at test time, the synthesis process neither explicitly encodes notions of geometry nor preserves local geometric structures in the new image. Furthermore, its use of 3D CAD models makes this approach better-suited to single-object view synthesis than to tackling complex real-world scenes."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47-Sentence-471,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47-Sentence-472,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47-Sentence-473 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47-Sentence-471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "training, the ground-truth visibility maps are obtained by making use of 3D CAD models of the objects of interest."@en ;
    askg-onto:inSentence "training, the ground-truth visibility maps are obtained by making use of 3D CAD models of the objects of interest."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_cad_models,
        askg-data:Entity-ground-truth_visibility_maps .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47-Sentence-472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While this indeed exploits 3D geometry, at test time, the synthesis process neither explicitly encodes notions of geometry nor preserves local geometric structures in the new image."@en ;
    askg-onto:inSentence "While this indeed exploits 3D geometry, at test time, the synthesis process neither explicitly encodes notions of geometry nor preserves local geometric structures in the new image."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-local_geometric_structures,
        askg-data:Entity-notions_of_geometry,
        askg-data:Entity-synthesis_process .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-47-Sentence-473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, its use of 3D CAD models makes this approach better-suited to single-object view synthesis than to tackling complex real-world scenes."@en ;
    askg-onto:inSentence "Furthermore, its use of 3D CAD models makes this approach better-suited to single-object view synthesis than to tackling complex real-world scenes."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_cad_models,
        askg-data:Entity-single-object_view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "By contrast, here, we explicitly leverage 3D geometry during the synthesis of the novel view, by developing a deep learning framework that exploits the notion of local homographies. As illustrated by Fig. 1, our geometry-aware deep learning strategy yields realistic predictions that better reflect the scene structure."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48-Sentence-481,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48-Sentence-482,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48-Sentence-483 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48-Sentence-481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "By contrast, here, we explicitly leverage 3D geometry during the synthesis of the novel view, by developing a deep learning framework that exploits the notion of local homographies."@en ;
    askg-onto:inSentence "By contrast, here, we explicitly leverage 3D geometry during the synthesis of the novel view, by developing a deep learning framework that exploits the notion of local homographies."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-deep_learning_framework,
        askg-data:Entity-local_homographies,
        askg-data:Entity-novel_view .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48-Sentence-482 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As illustrated by Fig."@en ;
    askg-onto:inSentence "As illustrated by Fig."^^xsd:string ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-48-Sentence-483 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "1, our geometry-aware deep learning strategy yields realistic predictions that better reflect the scene structure."@en ;
    askg-onto:inSentence "1, our geometry-aware deep learning strategy yields realistic predictions that better reflect the scene structure."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometry-aware_deep_learning_strategy,
        askg-data:Entity-realistic_predictions .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Note that some work has focused on the specific case of stereo view synthesis, that is, generating an image of one view from that of the other in a stereo setup [26]. While effective, this does not generalize to arbitrary novel views, since not all 3D information can be explained by disparity. Furthermore, view synthesis has been employed as supervision for depth estimation [8, 28]. However, novel views generated from predicted depth maps are typically highly incomplete, and, while suitable for depth estimation, not realistic-looking. Here, we focus on synthesizing realistic novel views with general pose variations."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-491,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-492,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-493,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-494,
        askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-495 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Note that some work has focused on the specific case of stereo view synthesis, that is, generating an image of one view from that of the other in a stereo setup [26]."@en ;
    askg-onto:inSentence "Note that some work has focused on the specific case of stereo view synthesis, that is, generating an image of one view from that of the other in a stereo setup [26]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generating_an_image_of_one_view_from_that_of_the_other_in_a_stereo_setup,
        askg-data:Entity-stereo_view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-492 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While effective, this does not generalize to arbitrary novel views, since not all 3D information can be explained by disparity."@en ;
    askg-onto:inSentence "While effective, this does not generalize to arbitrary novel views, since not all 3D information can be explained by disparity."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_information,
        askg-data:Entity-disparity .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-493 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, view synthesis has been employed as supervision for depth estimation [8, 28]."@en ;
    askg-onto:inSentence "Furthermore, view synthesis has been employed as supervision for depth estimation [8, 28]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_estimation,
        askg-data:Entity-view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-494 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, novel views generated from predicted depth maps are typically highly incomplete, and, while suitable for depth estimation, not realistic-looking."@en ;
    askg-onto:inSentence "However, novel views generated from predicted depth maps are typically highly incomplete, and, while suitable for depth estimation, not realistic-looking."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-novel_views,
        askg-data:Entity-predicted_depth_maps .

askg-data:Paper-305358d7d24f2bf4-Section-4-Paragraph-49-Sentence-495 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Here, we focus on synthesizing realistic novel views with general pose variations."@en ;
    askg-onto:inSentence "Here, we focus on synthesizing realistic novel views with general pose variations."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-general_pose_variations,
        askg-data:Entity-realistic_novel_views .

askg-data:Paper-305358d7d24f2bf4-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "3. Our Approach"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Our goal is to explicitly leverage information about the 3D scene structure to perform single-image novel view synthesis. To this end, we assume that the scene can be represented with multiple planes and learn to predict their respective homographies, which let us generate a set of candidate images in the new view. We additionally learn to estimate selection maps corresponding to the homographies, which encode to which homography each input pixel should be associated. Warping these maps and using them in conjunction with the candidate new view images lets us synthesize the novel view. We then complete the regions that were unseen in the input view, and thus cannot be synthesized with this strategy, using an encoder-decoder network similar to the generator of [20]. Below, we first introduce our regionaware geometric-transform network, and then discuss this encoder-decoder refinement."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-511,
        askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-512,
        askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-513,
        askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-514,
        askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-515,
        askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-516 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our goal is to explicitly leverage information about the 3D scene structure to perform single-image novel view synthesis."@en ;
    askg-onto:inSentence "Our goal is to explicitly leverage information about the 3D scene structure to perform single-image novel view synthesis."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_scene_structure,
        askg-data:Entity-single-image_novel_view_synthesis .

askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To this end, we assume that the scene can be represented with multiple planes and learn to predict their respective homographies, which let us generate a set of candidate images in the new view."@en ;
    askg-onto:inSentence "To this end, we assume that the scene can be represented with multiple planes and learn to predict their respective homographies, which let us generate a set of candidate images in the new view."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-candidate_images,
        askg-data:Entity-homographies,
        askg-data:Entity-multiple_planes,
        askg-data:Entity-new_view,
        askg-data:Entity-scene .

askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We additionally learn to estimate selection maps corresponding to the homographies, which encode to which homography each input pixel should be associated."@en ;
    askg-onto:inSentence "We additionally learn to estimate selection maps corresponding to the homographies, which encode to which homography each input pixel should be associated."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-input_pixel,
        askg-data:Entity-selection_maps .

askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-514 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Warping these maps and using them in conjunction with the candidate new view images lets us synthesize the novel view."@en ;
    askg-onto:inSentence "Warping these maps and using them in conjunction with the candidate new view images lets us synthesize the novel view."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-candidate_new_view_images,
        askg-data:Entity-maps,
        askg-data:Entity-novel_view .

askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-515 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We then complete the regions that were unseen in the input view, and thus cannot be synthesized with this strategy, using an encoder-decoder network similar to the generator of [20]."@en ;
    askg-onto:inSentence "We then complete the regions that were unseen in the input view, and thus cannot be synthesized with this strategy, using an encoder-decoder network similar to the generator of [20]."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_network,
        askg-data:Entity-generator_of_20 .

askg-data:Paper-305358d7d24f2bf4-Section-5-Paragraph-51-Sentence-516 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Below, we first introduce our regionaware geometric-transform network, and then discuss this encoder-decoder refinement."@en ;
    askg-onto:inSentence "Below, we first introduce our regionaware geometric-transform network, and then discuss this encoder-decoder refinement."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_refinement,
        askg-data:Entity-regionaware_geometric-transform_network .

askg-data:Paper-305358d7d24f2bf4-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "3.1. Region-Aware Geometric-Transform Network"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-610,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-611,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-613,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-614,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-615,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-617,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-618,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-620,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-621,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-623,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-625,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-627,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-63,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-65,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-66,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-67,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-68,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-69 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "To learn to predict a novel view from a single image while exploiting the 3D geometry of the scene, we develop the network shown in Fig. 2. This architecture consists of two subnetworks. The bottom one first predicts pixel-wise depth and normals from a single image in two independent streams. These predictions are then used, together with region masks extracted from the input image and the relative pose between the input view and the novel one, to compute multiple homographies, which we employ to warp the input image, thus generating candidate synthesized views. The second subnetwork, at the top of Fig. 2, predicts selection masks indicating, for each pixel, to which homography it should be associated. We then compute the novel view by assembling the candidate synthesized images according to the warped selection masks. Below, we describe these different stages in more detail. Depth and Normal Prediction. We use standard fullyconvolutional architectures to predict pixel-wise depth and normal maps separately. The details of these architectures are provided in the experiments section. Generating Homographies. Since we represent the scene as a set of m planar surfaces, a novel view can be obtained by applying one homography to each surface. For one plane, a homography can be computed from its depth and normal, given the desired relative pose, i.e., 3D rotation and translation, and camera intrinsic parameters. To model m different planes, we make use of a segmentation of the input image into m regions, referred to as *seed regions* and described in Section 3.1.2, to pool the above-mentioned pixel-wise depth and normal estimates."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-611,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6110,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6111,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6112,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6113,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6114,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6115,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6116,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-612,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-613,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-614,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-615,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-616,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-617,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-618,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-619 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To learn to predict a novel view from a single image while exploiting the 3D geometry of the scene, we develop the network shown in Fig."@en ;
    askg-onto:inSentence "To learn to predict a novel view from a single image while exploiting the 3D geometry of the scene, we develop the network shown in Fig."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_geometry,
        askg-data:Entity-network .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Depth and Normal Prediction."@en ;
    askg-onto:inSentence "Depth and Normal Prediction."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_and_normal_prediction,
        askg-data:Entity-method .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "We use standard fullyconvolutional architectures to predict pixel-wise depth and normal maps separately."@en ;
    askg-onto:inSentence "We use standard fullyconvolutional architectures to predict pixel-wise depth and normal maps separately."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fullyconvolutional_architectures,
        askg-data:Entity-pixel-wise_depth_and_normal_maps .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "The details of these architectures are provided in the experiments section."@en ;
    askg-onto:inSentence "The details of these architectures are provided in the experiments section."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architectures,
        askg-data:Entity-the_experiments_section .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Generating Homographies."@en ;
    askg-onto:inSentence "Generating Homographies."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "Since we represent the scene as a set of m planar surfaces, a novel view can be obtained by applying one homography to each surface."@en ;
    askg-onto:inSentence "Since we represent the scene as a set of m planar surfaces, a novel view can be obtained by applying one homography to each surface."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-each_surface,
        askg-data:Entity-homography,
        askg-data:Entity-scene,
        askg-data:Entity-set_of_m_planar_surfaces .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "For one plane, a homography can be computed from its depth and normal, given the desired relative pose, i.e., 3D rotation and translation, and camera intrinsic parameters."@en ;
    askg-onto:inSentence "For one plane, a homography can be computed from its depth and normal, given the desired relative pose, i.e., 3D rotation and translation, and camera intrinsic parameters."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_rotation_and_translation,
        askg-data:Entity-camera_intrinsic_parameters,
        askg-data:Entity-depth_and_normal,
        askg-data:Entity-homography,
        askg-data:Entity-relative_pose .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-6116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "To model m different planes, we make use of a segmentation of the input image into m regions, referred to as *seed regions* and described in Section 3.1.2, to pool the above-mentioned pixel-wise depth and normal estimates."@en ;
    askg-onto:inSentence "To model m different planes, we make use of a segmentation of the input image into m regions, referred to as *seed regions* and described in Section 3.1.2, to pool the above-mentioned pixel-wise depth and normal estimates."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_image,
        askg-data:Entity-m_regions,
        askg-data:Entity-pixel-wise_depth_and_normal_estimates,
        askg-data:Entity-section_312,
        askg-data:Entity-seed_regions .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "2."@en ;
    askg-onto:inSentence "2."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-technique,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This architecture consists of two subnetworks."@en ;
    askg-onto:inSentence "This architecture consists of two subnetworks."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-architecture,
        askg-data:Entity-two_subnetworks .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The bottom one first predicts pixel-wise depth and normals from a single image in two independent streams."@en ;
    askg-onto:inSentence "The bottom one first predicts pixel-wise depth and normals from a single image in two independent streams."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pixel-wise_depth_and_normals,
        askg-data:Entity-single_image .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "These predictions are then used, together with region masks extracted from the input image and the relative pose between the input view and the novel one, to compute multiple homographies, which we employ to warp the input image, thus generating candidate synthesized views."@en ;
    askg-onto:inSentence "These predictions are then used, together with region masks extracted from the input image and the relative pose between the input view and the novel one, to compute multiple homographies, which we employ to warp the input image, thus generating candidate synthesized views."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-candidate_synthesized_views,
        askg-data:Entity-homographies,
        askg-data:Entity-input_image,
        askg-data:Entity-input_view,
        askg-data:Entity-novel_view,
        askg-data:Entity-pose,
        askg-data:Entity-predictions,
        askg-data:Entity-region_masks .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-616 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The second subnetwork, at the top of Fig."@en ;
    askg-onto:inSentence "The second subnetwork, at the top of Fig."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fig,
        askg-data:Entity-subnetwork .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-617 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "2, predicts selection masks indicating, for each pixel, to which homography it should be associated."@en ;
    askg-onto:inSentence "2, predicts selection masks indicating, for each pixel, to which homography it should be associated."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2,
        askg-data:Entity-homography,
        askg-data:Entity-selection_masks .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-618 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "We then compute the novel view by assembling the candidate synthesized images according to the warped selection masks."@en ;
    askg-onto:inSentence "We then compute the novel view by assembling the candidate synthesized images according to the warped selection masks."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-candidate_synthesized_images,
        askg-data:Entity-warped_selection_masks .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-61-Sentence-619 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Below, we describe these different stages in more detail."@en ;
    askg-onto:inSentence "Below, we describe these different stages in more detail."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_stages,
        askg-data:Entity-stages .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-610 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "Finally, let n˜j = n¯j/n¯ d j. Given the relative rotation matrix R and translation vector t between the input and novel views, the homography for region j can be expressed as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-610-Sentence-6101,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-610-Sentence-6102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-610-Sentence-6101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Finally, let n˜j = n¯j/n¯ d j."@en ;
    askg-onto:inSentence "Finally, let n˜j = n¯j/n¯ d j."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nj,
        askg-data:Entity-njn_d_j .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-610-Sentence-6102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given the relative rotation matrix R and translation vector t between the input and novel views, the homography for region j can be expressed as"@en ;
    askg-onto:inSentence "Given the relative rotation matrix R and translation vector t between the input and novel views, the homography for region j can be expressed as"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography_for_region_j,
        askg-data:Entity-input_and_novel_views,
        askg-data:Entity-relative_rotation_matrix_r,
        askg-data:Entity-translation_vector_t .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-611 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "$$\\mathbf{H}_{j}=\\mathbf{K}(\\mathbf{R}-\\mathbf{t}{\\hat{\\mathbf{n}}}_{j}^{T})\\mathbf{K}^{-1}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-611-Sentence-6111 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-611-Sentence-6111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\mathbf{H}_{j}=\\mathbf{K}(\\mathbf{R}-\\mathbf{t}{\\hat{\\mathbf{n}}}_{j}^{T})\\mathbf{K}^{-1}$$"@en ;
    askg-onto:inSentence "$$\\mathbf{H}_{j}=\\mathbf{K}(\\mathbf{R}-\\mathbf{t}{\\hat{\\mathbf{n}}}_{j}^{T})\\mathbf{K}^{-1}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h_j,
        askg-data:Entity-kr_-_t_n_jtk-1 .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "This lets us compute a homography for every seed region. Inverse Image Warping. Each resulting homography can be applied to the pixels of the input (source) image. For each source pixel x s, this can be written as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6121,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6122,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6123,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6124 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This lets us compute a homography for every seed region."@en ;
    askg-onto:inSentence "This lets us compute a homography for every seed region."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-seed_region .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Inverse Image Warping."@en ;
    askg-onto:inSentence "Inverse Image Warping."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inverse_image_warping,
        askg-data:Entity-method .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Each resulting homography can be applied to the pixels of the input (source) image."@en ;
    askg-onto:inSentence "Each resulting homography can be applied to the pixels of the input (source) image."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-input_image,
        askg-data:Entity-pixels_of_the_input_image,
        askg-data:Entity-source_image .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-612-Sentence-6124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For each source pixel x s, this can be written as"@en ;
    askg-onto:inSentence "For each source pixel x s, this can be written as"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-source_pixel_x_s,
        askg-data:Entity-x_s .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-613 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "$$\\lambda\\tilde{\\mathbf{x}}_{j}^{t}=\\mathbf{H}_{j}\\tilde{\\mathbf{x}}^{s}\\ ,$$ s, (4) with x˜ sthe pixel location in homogeneous coordinates, and λ the corresponding scalar. While the result of this operation will indeed correspond to a location in the target image (ignoring the fact that some will lie outside the image"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-613-Sentence-6131,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-613-Sentence-6132 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-613-Sentence-6131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\lambda\\tilde{\\mathbf{x}}_{j}^{t}=\\mathbf{H}_{j}\\tilde{\\mathbf{x}}^{s}\\ ,$$ s, (4) with x˜ sthe pixel location in homogeneous coordinates, and λ the corresponding scalar."@en ;
    askg-onto:inSentence "$$\\lambda\\tilde{\\mathbf{x}}_{j}^{t}=\\mathbf{H}_{j}\\tilde{\\mathbf{x}}^{s}\\ ,$$ s, (4) with x˜ sthe pixel location in homogeneous coordinates, and λ the corresponding scalar."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CE%BB,
        askg-data:Entity-homogeneous_coordinates,
        askg-data:Entity-pixel_location .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-613-Sentence-6132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While the result of this operation will indeed correspond to a location in the target image (ignoring the fact that some will lie outside the image"@en ;
    askg-onto:inSentence "While the result of this operation will indeed correspond to a location in the target image (ignoring the fact that some will lie outside the image"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-location,
        askg-data:Entity-operation,
        askg-data:Entity-result,
        askg-data:Entity-target_image .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-614 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "$$(1)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-614-Sentence-6141 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-614-Sentence-6141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(1)$$"@en ;
    askg-onto:inSentence "$$(1)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-city,
        askg-data:Entity-finding,
        askg-data:Entity-method,
        askg-data:Entity-organization,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-615 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "Figure 3. **Selection Network.** Instead of using hard segmentation"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-615-Sentence-6151,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-615-Sentence-6152 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-615-Sentence-6151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 3."@en ;
    askg-onto:inSentence "Figure 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data_visualization,
        askg-data:Entity-figure_3 .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-615-Sentence-6152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Selection Network.** Instead of using hard segmentation"@en ;
    askg-onto:inSentence "**Selection Network.** Instead of using hard segmentation"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 16"@en ;
    domo:Text "![3_image_0.png](3_image_0.png) masks to combine the candidate synthesized images, we train a network to generate a set of soft selection masks. The network structure follows that of the first 4 blocks of VGG16. We maxpool the corresponding 4 feature maps according to the seed masks and concatenate the resulting 4 feature vectors in a hypercolumn feature. We then convolve this hypercolumn feature with the concatenated complete feature maps at low resolution, which yields one global heatmap that we upsample to the original image size."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6161,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6162,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6163,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6164 ;
    askg-onto:index "16"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6161 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![3_image_0.png](3_image_0.png) masks to combine the candidate synthesized images, we train a network to generate a set of soft selection masks."@en ;
    askg-onto:inSentence "![3_image_0.png](3_image_0.png) masks to combine the candidate synthesized images, we train a network to generate a set of soft selection masks."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-network,
        askg-data:Entity-set_of_soft_selection_masks .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6162 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The network structure follows that of the first 4 blocks of VGG16."@en ;
    askg-onto:inSentence "The network structure follows that of the first 4 blocks of VGG16."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-the_first_4_blocks,
        askg-data:Entity-vgg16 .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6163 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We maxpool the corresponding 4 feature maps according to the seed masks and concatenate the resulting 4 feature vectors in a hypercolumn feature."@en ;
    askg-onto:inSentence "We maxpool the corresponding 4 feature maps according to the seed masks and concatenate the resulting 4 feature vectors in a hypercolumn feature."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feature_maps,
        askg-data:Entity-feature_vectors,
        askg-data:Entity-hypercolumn_feature .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-616-Sentence-6164 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We then convolve this hypercolumn feature with the concatenated complete feature maps at low resolution, which yields one global heatmap that we upsample to the original image size."@en ;
    askg-onto:inSentence "We then convolve this hypercolumn feature with the concatenated complete feature maps at low resolution, which yields one global heatmap that we upsample to the original image size."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complete_feature_maps,
        askg-data:Entity-global_heatmap,
        askg-data:Entity-hypercolumn_feature,
        askg-data:Entity-original_image_size .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-617 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 17"@en ;
    domo:Text "Note that we normalize the pooled features and complete feature maps along the feature dimension."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-617-Sentence-6171 ;
    askg-onto:index "17"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-617-Sentence-6171 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Note that we normalize the pooled features and complete feature maps along the feature dimension."@en ;
    askg-onto:inSentence "Note that we normalize the pooled features and complete feature maps along the feature dimension."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feature_maps,
        askg-data:Entity-pooled_features .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-618 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 18"@en ;
    domo:Text "range), these locations will not correspond to exact, integer pixel coordinates. In our context of generating a novel view, this would significantly complicate the task of obtaining the intensity value at each target pixel, which would require combining the intensities of nearby transformed locations, whose number would vary for each target pixel."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-618-Sentence-6181,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-618-Sentence-6182 ;
    askg-onto:index "18"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-618-Sentence-6181 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "range), these locations will not correspond to exact, integer pixel coordinates."@en ;
    askg-onto:inSentence "range), these locations will not correspond to exact, integer pixel coordinates."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-exact_integer_pixel_coordinates,
        askg-data:Entity-locations .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-618-Sentence-6182 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In our context of generating a novel view, this would significantly complicate the task of obtaining the intensity value at each target pixel, which would require combining the intensities of nearby transformed locations, whose number would vary for each target pixel."@en ;
    askg-onto:inSentence "In our context of generating a novel view, this would significantly complicate the task of obtaining the intensity value at each target pixel, which would require combining the intensities of nearby transformed locations, whose number would vary for each target pixel."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-combining_the_intensities_of_nearby_transformed_locations,
        askg-data:Entity-intensity_value .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 19"@en ;
    domo:Text "To address this, instead of following a forward warping strategy (from source image to target image), we rely on an inverse warping (from target image to source image). Specifically, for every target pixel location x t i, we obtain the corresponding source location by relying on the inverse homography H−1 jas x˜ s i,j ∝ H−1 j x˜ t i. We then compute the target intensity value at pixel x tiby bilinear interpolation as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619-Sentence-6191,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619-Sentence-6192,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619-Sentence-6193 ;
    askg-onto:index "19"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619-Sentence-6191 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To address this, instead of following a forward warping strategy (from source image to target image), we rely on an inverse warping (from target image to source image)."@en ;
    askg-onto:inSentence "To address this, instead of following a forward warping strategy (from source image to target image), we rely on an inverse warping (from target image to source image)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-forward_warping_strategy,
        askg-data:Entity-inverse_warping,
        askg-data:Entity-method .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619-Sentence-6192 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Specifically, for every target pixel location x t i, we obtain the corresponding source location by relying on the inverse homography H−1 jas x˜ s i,j ∝ H−1 j x˜ t i."@en ;
    askg-onto:inSentence "Specifically, for every target pixel location x t i, we obtain the corresponding source location by relying on the inverse homography H−1 jas x˜ s i,j ∝ H−1 j x˜ t i."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inverse_homography,
        askg-data:Entity-source_location,
        askg-data:Entity-target_pixel_location .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-619-Sentence-6193 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We then compute the target intensity value at pixel x tiby bilinear interpolation as"@en ;
    askg-onto:inSentence "We then compute the target intensity value at pixel x tiby bilinear interpolation as"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bilinear_interpolation,
        askg-data:Entity-pixel_x,
        askg-data:Entity-target_intensity_value .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "More specifically, let M be an h × w × m binary tensor encoding m segmentation masks obtained from the h × w input image I s. Furthermore, let us denote by Mj the binary mask corresponding to the j th segment. Assuming that each segment is planar, we approximate its normal as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62-Sentence-621,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62-Sentence-622,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62-Sentence-623 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "More specifically, let M be an h × w × m binary tensor encoding m segmentation masks obtained from the h × w input image I s."@en ;
    askg-onto:inSentence "More specifically, let M be an h × w × m binary tensor encoding m segmentation masks obtained from the h × w input image I s."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-binary_tensor_encoding_segmentation_masks,
        askg-data:Entity-h__w__m,
        askg-data:Entity-input_image_i_s,
        askg-data:Entity-m,
        askg-data:Entity-segmentation_masks .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62-Sentence-622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Furthermore, let us denote by Mj the binary mask corresponding to the j th segment."@en ;
    askg-onto:inSentence "Furthermore, let us denote by Mj the binary mask corresponding to the j th segment."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mj,
        askg-data:Entity-the_binary_mask_corresponding_to_the_j_th_segment .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-62-Sentence-623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Assuming that each segment is planar, we approximate its normal as"@en ;
    askg-onto:inSentence "Assuming that each segment is planar, we approximate its normal as"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-normal,
        askg-data:Entity-normal_approximation,
        askg-data:Entity-planar,
        askg-data:Entity-segment .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-620 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 20"@en ;
    domo:Text "$$({\\mathfrak{I}})$$ $$\\hat{I}_{j}^{t}({\\bf x}_{i}^{t})=\\sum_{q\\in o_{j}^{i}}I^{s}(1-|x_{i,j}^{s}-x_{q,j}^{s}|,1-|y_{i,j}^{s}-y_{q,j}^{s}|)\\,\\tag{5}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-620-Sentence-6201 ;
    askg-onto:index "20"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-620-Sentence-6201 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$({\\mathfrak{I}})$$ $$\\hat{I}_{j}^{t}({\\bf x}_{i}^{t})=\\sum_{q\\in o_{j}^{i}}I^{s}(1-|x_{i,j}^{s}-x_{q,j}^{s}|,1-|y_{i,j}^{s}-y_{q,j}^{s}|)\\,\\tag{5}$$"@en ;
    askg-onto:inSentence "$$({\\mathfrak{I}})$$ $$\\hat{I}_{j}^{t}({\\bf x}_{i}^{t})=\\sum_{q\\in o_{j}^{i}}I^{s}(1-|x_{i,j}^{s}-x_{q,j}^{s}|,1-|y_{i,j}^{s}-y_{q,j}^{s}|)\\,\\tag{5}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-i_hat_jtf_x_it,
        askg-data:Entity-is .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-621 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 21"@en ;
    domo:Text "where I sis the input source image, and o i jdenotes the 4pixel neighborhood of x s i,j , which itself is predicted by the inverse homography."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-621-Sentence-6211 ;
    askg-onto:index "21"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-621-Sentence-6211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where I sis the input source image, and o i jdenotes the 4pixel neighborhood of x s i,j , which itself is predicted by the inverse homography."@en ;
    askg-onto:inSentence "where I sis the input source image, and o i jdenotes the 4pixel neighborhood of x s i,j , which itself is predicted by the inverse homography."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4-pixel_neighborhood,
        askg-data:Entity-input_source_image,
        askg-data:Entity-inverse_homography,
        askg-data:Entity-x_s_ij .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 22"@en ;
    domo:Text "$\\eqref{eq:walpha}$. Selection Network. As discussed below, we generate the novel view by assembling the m candidate target images obtained as described above. To this end, we develop a selection network to predict m planar region masks from the input image and seed region masks (Section 3.1.2). More precisely, for each seed region, we aim to predict a soft selection map indicating the likelihood for every input pixel to be associated to the corresponding homography."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6221,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6222,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6223,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6224,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6225 ;
    askg-onto:index "22"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\eqref{eq:walpha}$."@en ;
    askg-onto:inSentence "$\\eqref{eq:walpha}$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09exteqwalpha,
        askg-data:Entity-equation .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Selection Network."@en ;
    askg-onto:inSentence "Selection Network."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-framework,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As discussed below, we generate the novel view by assembling the m candidate target images obtained as described above."@en ;
    askg-onto:inSentence "As discussed below, we generate the novel view by assembling the m candidate target images obtained as described above."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-novel_view .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To this end, we develop a selection network to predict m planar region masks from the input image and seed region masks (Section 3.1.2)."@en ;
    askg-onto:inSentence "To this end, we develop a selection network to predict m planar region masks from the input image and seed region masks (Section 3.1.2)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_image,
        askg-data:Entity-m_planar_region_masks,
        askg-data:Entity-seed_region_masks,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-622-Sentence-6225 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "More precisely, for each seed region, we aim to predict a soft selection map indicating the likelihood for every input pixel to be associated to the corresponding homography."@en ;
    askg-onto:inSentence "More precisely, for each seed region, we aim to predict a soft selection map indicating the likelihood for every input pixel to be associated to the corresponding homography."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-input_pixel,
        askg-data:Entity-seed_region,
        askg-data:Entity-soft_selection_map .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-623 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 23"@en ;
    domo:Text "Specifically, the structure of our selection network follows that of the first 4 convolutional blocks of VGG16 [23]."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-623-Sentence-6231 ;
    askg-onto:index "23"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-623-Sentence-6231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Specifically, the structure of our selection network follows that of the first 4 convolutional blocks of VGG16 [23]."@en ;
    askg-onto:inSentence "Specifically, the structure of our selection network follows that of the first 4 convolutional blocks of VGG16 [23]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_4_convolutional_blocks_of_vgg16,
        askg-data:Entity-selection_network .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 24"@en ;
    domo:Text "As shown in Fig 3, each seed region mask is used to maxpool the corresponding 4 feature maps. We then concatenate the resulting 4 features to form a hypercolumn [11] feature, which we convolve with the concatenated complete feature maps at the lower resolution. This yields a lowresolution heat map, which we upsample to the original image size. The resulting heat map indicates a notion of similarity between the features at every pixel and the one pooled over the seed region. This procedure is performed individually for the m seed regions, but using shared network parameters. Note that the resulting m selection maps are defined in the input view, and we thus apply our inverse warping procedure to compute them in the novel view."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6241,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6242,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6243,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6244,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6245,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6246 ;
    askg-onto:index "24"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As shown in Fig 3, each seed region mask is used to maxpool the corresponding 4 feature maps."@en ;
    askg-onto:inSentence "As shown in Fig 3, each seed region mask is used to maxpool the corresponding 4 feature maps."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feature_maps,
        askg-data:Entity-seed_region_mask .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We then concatenate the resulting 4 features to form a hypercolumn [11] feature, which we convolve with the concatenated complete feature maps at the lower resolution."@en ;
    askg-onto:inSentence "We then concatenate the resulting 4 features to form a hypercolumn [11] feature, which we convolve with the concatenated complete feature maps at the lower resolution."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-convolution,
        askg-data:Entity-feature,
        askg-data:Entity-feature_maps,
        askg-data:Entity-hypercolumn_feature .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6243 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This yields a lowresolution heat map, which we upsample to the original image size."@en ;
    askg-onto:inSentence "This yields a lowresolution heat map, which we upsample to the original image size."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-low-resolution_heat_map,
        askg-data:Entity-original_image_size .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6244 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The resulting heat map indicates a notion of similarity between the features at every pixel and the one pooled over the seed region."@en ;
    askg-onto:inSentence "The resulting heat map indicates a notion of similarity between the features at every pixel and the one pooled over the seed region."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-features,
        askg-data:Entity-features_at_every_pixel,
        askg-data:Entity-heat_map,
        askg-data:Entity-seed_region .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6245 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This procedure is performed individually for the m seed regions, but using shared network parameters."@en ;
    askg-onto:inSentence "This procedure is performed individually for the m seed regions, but using shared network parameters."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-m_seed_regions,
        askg-data:Entity-shared_network_parameters .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-624-Sentence-6246 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Note that the resulting m selection maps are defined in the input view, and we thus apply our inverse warping procedure to compute them in the novel view."@en ;
    askg-onto:inSentence "Note that the resulting m selection maps are defined in the input view, and we thus apply our inverse warping procedure to compute them in the novel view."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inverse_warping_procedure,
        askg-data:Entity-m_selection_maps,
        askg-data:Entity-the_input_view,
        askg-data:Entity-the_novel_view,
        askg-data:Entity-them .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-625 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 25"@en ;
    domo:Text "Novel View Prediction. Given the selection maps {M˜j}, we first compute a normalized transformed mask for the"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-625-Sentence-6251,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-625-Sentence-6252 ;
    askg-onto:index "25"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-625-Sentence-6251 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Novel View Prediction."@en ;
    askg-onto:inSentence "Novel View Prediction."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-novel_view_prediction .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-625-Sentence-6252 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given the selection maps {M˜j}, we first compute a normalized transformed mask for the"@en ;
    askg-onto:inSentence "Given the selection maps {M˜j}, we first compute a normalized transformed mask for the"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-normalized_transformed_mask,
        askg-data:Entity-selection_maps .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 26"@en ;
    domo:Text "novel view as Mˆ t j (x t i ) = P q∈o ij M˜j (1 − |x s i,j − x sq,j |, 1 − |y s i,j − y sq,j |) + Pm k=1 P q∈o ik (M˜k(1 − |x s i,k − x s q,k|)(1 − |y si, k − y s q,k|) + ) (6) Note that the resulting transformed masks are not binary, but rather provide weights to combine the m estimated target images. To account for the fact that some pixels will be warped outside the input image with all m homographies, we make use of a small constant , which prevents division by 0 in the normalization process and yields uniform weights for such pixels. In our experiments, we set = 0.0001. We compute the novel view as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6261,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6262,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6263,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6264 ;
    askg-onto:index "26"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6261 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "novel view as Mˆ t j (x t i ) = P q∈o ij M˜j (1 − |x s i,j − x sq,j |, 1 − |y s i,j − y sq,j |) + Pm k=1 P q∈o ik (M˜k(1 − |x s i,k − x s q,k|)(1 − |y si, k − y s q,k|) + ) (6) Note that the resulting transformed masks are not binary, but rather provide weights to combine the m estimated target images."@en ;
    askg-onto:inSentence "novel view as Mˆ t j (x t i ) = P q∈o ij M˜j (1 − |x s i,j − x sq,j |, 1 − |y s i,j − y sq,j |) + Pm k=1 P q∈o ik (M˜k(1 − |x s i,k − x s q,k|)(1 − |y si, k − y s q,k|) + ) (6) Note that the resulting transformed masks are not binary, but rather provide weights to combine the m estimated target images."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-estimated_target_images,
        askg-data:Entity-m%CB%86_t_j_x_t_i_,
        askg-data:Entity-transformed_masks,
        askg-data:Entity-weights .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6262 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To account for the fact that some pixels will be warped outside the input image with all m homographies, we make use of a small constant , which prevents division by 0 in the normalization process and yields uniform weights for such pixels."@en ;
    askg-onto:inSentence "To account for the fact that some pixels will be warped outside the input image with all m homographies, we make use of a small constant , which prevents division by 0 in the normalization process and yields uniform weights for such pixels."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-constant,
        askg-data:Entity-division_by_0,
        askg-data:Entity-homographies,
        askg-data:Entity-input_image,
        askg-data:Entity-pixels,
        askg-data:Entity-uniform_weights .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6263 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In our experiments, we set = 0.0001."@en ;
    askg-onto:inSentence "In our experiments, we set = 0.0001."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-00001,
        askg-data:Entity-experiments .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-626-Sentence-6264 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We compute the novel view as"@en ;
    askg-onto:inSentence "We compute the novel view as"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-novel,
        askg-data:Entity-view .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-627 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 27"@en ;
    domo:Text "$${\\hat{I}}^{t}(\\mathbf{x}_{i}^{t})=\\sum_{j=1}^{m}{\\hat{I}}_{j}^{t}(\\mathbf{x}_{i}^{t})\\cdot{\\hat{M}}_{j}^{t}(\\mathbf{x}_{i}^{t})\\ .$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-627-Sentence-6271 ;
    askg-onto:index "27"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-627-Sentence-6271 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\hat{I}}^{t}(\\mathbf{x}_{i}^{t})=\\sum_{j=1}^{m}{\\hat{I}}_{j}^{t}(\\mathbf{x}_{i}^{t})\\cdot{\\hat{M}}_{j}^{t}(\\mathbf{x}_{i}^{t})\\ .$$"@en ;
    askg-onto:inSentence "$${\\hat{I}}^{t}(\\mathbf{x}_{i}^{t})=\\sum_{j=1}^{m}{\\hat{I}}_{j}^{t}(\\mathbf{x}_{i}^{t})\\cdot{\\hat{M}}_{j}^{t}(\\mathbf{x}_{i}^{t})\\ .$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%09exti_jt%09extbfx_it,
        askg-data:Entity-%09extit%09extbfx_it,
        askg-data:Entity-%09extm_jt%09extbfx_it .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 28"@en ;
    domo:Text "Note that some of the pixels in the output view will be mapped outside the input image by all homographies. In the simplest version of our approach, we fill in the intensity of each such pixel by using the value at the nearest pixel in the input image. In Section 3.2, we introduce a refinement network that produces more realistic predictions."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628-Sentence-6281,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628-Sentence-6282,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628-Sentence-6283 ;
    askg-onto:index "28"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628-Sentence-6281 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Note that some of the pixels in the output view will be mapped outside the input image by all homographies."@en ;
    askg-onto:inSentence "Note that some of the pixels in the output view will be mapped outside the input image by all homographies."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homographies,
        askg-data:Entity-input_image,
        askg-data:Entity-pixels .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628-Sentence-6282 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the simplest version of our approach, we fill in the intensity of each such pixel by using the value at the nearest pixel in the input image."@en ;
    askg-onto:inSentence "In the simplest version of our approach, we fill in the intensity of each such pixel by using the value at the nearest pixel in the input image."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-input,
        askg-data:Entity-intensity,
        askg-data:Entity-pixel,
        askg-data:Entity-value .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-628-Sentence-6283 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In Section 3.2, we introduce a refinement network that produces more realistic predictions."@en ;
    askg-onto:inSentence "In Section 3.2, we introduce a refinement network that produces more realistic predictions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-more_realistic_predictions,
        askg-data:Entity-refinement_network .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$\\bar{\\mathbf{n}}_{j}={\\frac{\\sum_{\\mathbf{x}\\in\\Omega}M_{j}(\\mathbf{x})\\cdot\\mathbf{n}(\\mathbf{x})}{\\sum_{\\mathbf{x}\\in\\Omega}M_{j}(\\mathbf{x})}}\\ ,$$ , (1) where Ω denotes the set of all pixel locations, and n(x) corresponds to the normal estimate at location x. We then normalize n¯j to have unit norm."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-63-Sentence-631,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-63-Sentence-632 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\bar{\\mathbf{n}}_{j}={\\frac{\\sum_{\\mathbf{x}\\in\\Omega}M_{j}(\\mathbf{x})\\cdot\\mathbf{n}(\\mathbf{x})}{\\sum_{\\mathbf{x}\\in\\Omega}M_{j}(\\mathbf{x})}}\\ ,$$ , (1) where Ω denotes the set of all pixel locations, and n(x) corresponds to the normal estimate at location x."@en ;
    askg-onto:inSentence "$$\\bar{\\mathbf{n}}_{j}={\\frac{\\sum_{\\mathbf{x}\\in\\Omega}M_{j}(\\mathbf{x})\\cdot\\mathbf{n}(\\mathbf{x})}{\\sum_{\\mathbf{x}\\in\\Omega}M_{j}(\\mathbf{x})}}\\ ,$$ , (1) where Ω denotes the set of all pixel locations, and n(x) corresponds to the normal estimate at location x."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%CF%89,
        askg-data:Entity-normal_estimate_at_location_x,
        askg-data:Entity-nx,
        askg-data:Entity-set_of_all_pixel_locations .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-63-Sentence-632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We then normalize n¯j to have unit norm."@en ;
    askg-onto:inSentence "We then normalize n¯j to have unit norm."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nj,
        askg-data:Entity-unit_norm .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "A plane with normal n¯j can be defined by a vector , such that any 3D point Q on the plane satisfies n¯ T j Q + ¯n d j = 0. While our average normal estimate provides us with the first 3 parameters, we still need to compute n¯ d j. To this end, let us consider the center of region j, with coordinates (c x j , c y j ). We approximate the depth at the center location as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-641,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-642,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-643,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-644 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A plane with normal n¯j can be defined by a vector , such that any 3D point Q on the plane satisfies n¯ T j Q + ¯n d j = 0."@en ;
    askg-onto:inSentence "A plane with normal n¯j can be defined by a vector , such that any 3D point Q on the plane satisfies n¯ T j Q + ¯n d j = 0."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-equation,
        askg-data:Entity-plane,
        askg-data:Entity-point_q,
        askg-data:Entity-vector .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-642 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While our average normal estimate provides us with the first 3 parameters, we still need to compute n¯ d j."@en ;
    askg-onto:inSentence "While our average normal estimate provides us with the first 3 parameters, we still need to compute n¯ d j."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_normal_estimate,
        askg-data:Entity-first_3_parameters,
        askg-data:Entity-n_d_j,
        askg-data:Entity-undefined .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-643 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To this end, let us consider the center of region j, with coordinates (c x j , c y j )."@en ;
    askg-onto:inSentence "To this end, let us consider the center of region j, with coordinates (c x j , c y j )."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c_x_j__c_y_j_,
        askg-data:Entity-region_j .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-64-Sentence-644 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We approximate the depth at the center location as"@en ;
    askg-onto:inSentence "We approximate the depth at the center location as"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-center_location,
        askg-data:Entity-depth .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-65 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\bar{d}_{j}=\\frac{\\sum_{{\\bf x}\\in\\Omega}M_{j}({\\bf x})\\cdot d({\\bf x})}{\\sum_{{\\bf x}\\in\\Omega}M_{j}({\\bf x})}\\;,\\tag{2}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-65-Sentence-651 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-65-Sentence-651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\bar{d}_{j}=\\frac{\\sum_{{\\bf x}\\in\\Omega}M_{j}({\\bf x})\\cdot d({\\bf x})}{\\sum_{{\\bf x}\\in\\Omega}M_{j}({\\bf x})}\\;,\\tag{2}$$"@en ;
    askg-onto:inSentence "$$\\bar{d}_{j}=\\frac{\\sum_{{\\bf x}\\in\\Omega}M_{j}({\\bf x})\\cdot d({\\bf x})}{\\sum_{{\\bf x}\\in\\Omega}M_{j}({\\bf x})}\\;,\\tag{2}$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d_j .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-66 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "where d(x) corresponds to the depth estimate at location x. This allows us to increase robustness to noise in the predicted depth map compared to directly using d(c x j, c y j)."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-66-Sentence-661,
        askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-66-Sentence-662 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-66-Sentence-661 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where d(x) corresponds to the depth estimate at location x."@en ;
    askg-onto:inSentence "where d(x) corresponds to the depth estimate at location x."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_estimate,
        askg-data:Entity-dx,
        askg-data:Entity-location,
        askg-data:Entity-location_x .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-66-Sentence-662 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This allows us to increase robustness to noise in the predicted depth map compared to directly using d(c x j, c y j)."@en ;
    askg-onto:inSentence "This allows us to increase robustness to noise in the predicted depth map compared to directly using d(c x j, c y j)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_map,
        askg-data:Entity-noise .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-67 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "Given the matrix of camera intrinsic parameters K, the corresponding 3D point can be expressed as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-67-Sentence-671 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-67-Sentence-671 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Given the matrix of camera intrinsic parameters K, the corresponding 3D point can be expressed as"@en ;
    askg-onto:inSentence "Given the matrix of camera intrinsic parameters K, the corresponding 3D point can be expressed as"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_point,
        askg-data:Entity-matrix_of_camera_intrinsic_parameters_k .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-68 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "$${\\bf Q}=\\bar{d}_{j}{\\bf K}^{-1}(c_{j}^{x},c_{j}^{y},1)^{T}\\;.$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-68-Sentence-681 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-68-Sentence-681 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$${\\bf Q}=\\bar{d}_{j}{\\bf K}^{-1}(c_{j}^{x},c_{j}^{y},1)^{T}\\;.$$"@en ;
    askg-onto:inSentence "$${\\bf Q}=\\bar{d}_{j}{\\bf K}^{-1}(c_{j}^{x},c_{j}^{y},1)^{T}\\;.$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-q .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-69 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "By making use of the plane constraint, we can estimate the last parameter n¯ d j as n¯ d j = −n¯ T j Q."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-69-Sentence-691 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-6-Paragraph-69-Sentence-691 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "By making use of the plane constraint, we can estimate the last parameter n¯ d j as n¯ d j = −n¯ T j Q."@en ;
    askg-onto:inSentence "By making use of the plane constraint, we can estimate the last parameter n¯ d j as n¯ d j = −n¯ T j Q."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n_d_j,
        askg-data:Entity-n_t_j_q .

askg-data:Paper-305358d7d24f2bf4-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "3.1.1 Learning"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-72,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-74,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-76,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-77,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-78 ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The novel view predicted using Eq. 7 is a function of the homographies, which themselves are functions of the normal and depth estimates, and of the selection masks, which in turn depend on the depth and normal branch parameters Wd,Wn, and selection network parameters Ws, respectively. Altogether, the prediction can then be thought of as a function of the parameters W = {Wd,Wn,Ws} given an input image I s, and a relative pose P, encompassing the 3D rotation, translation and camera intrinsics, and the segmentation seed region masks M."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71-Sentence-711,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71-Sentence-712,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71-Sentence-713 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71-Sentence-711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The novel view predicted using Eq."@en ;
    askg-onto:inSentence "The novel view predicted using Eq."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-eq,
        askg-data:Entity-view .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71-Sentence-712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "7 is a function of the homographies, which themselves are functions of the normal and depth estimates, and of the selection masks, which in turn depend on the depth and normal branch parameters Wd,Wn, and selection network parameters Ws, respectively."@en ;
    askg-onto:inSentence "7 is a function of the homographies, which themselves are functions of the normal and depth estimates, and of the selection masks, which in turn depend on the depth and normal branch parameters Wd,Wn, and selection network parameters Ws, respectively."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-depth_and_normal_branch_parameters,
        askg-data:Entity-homographies,
        askg-data:Entity-normal_and_depth_estimates,
        askg-data:Entity-selection_masks,
        askg-data:Entity-selection_network_parameters .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-71-Sentence-713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Altogether, the prediction can then be thought of as a function of the parameters W = {Wd,Wn,Ws} given an input image I s, and a relative pose P, encompassing the 3D rotation, translation and camera intrinsics, and the segmentation seed region masks M."@en ;
    askg-onto:inSentence "Altogether, the prediction can then be thought of as a function of the parameters W = {Wd,Wn,Ws} given an input image I s, and a relative pose P, encompassing the 3D rotation, translation and camera intrinsics, and the segmentation seed region masks M."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3d_rotation_translation_and_camera_intrinsics,
        askg-data:Entity-parameters_w__wdwnws,
        askg-data:Entity-prediction,
        askg-data:Entity-relative_pose_p,
        askg-data:Entity-segmentation_mask,
        askg-data:Entity-segmentation_seed_region_masks_m .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-72 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "All the operations described above are differentiable."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-72-Sentence-721 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-72-Sentence-721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "All the operations described above are differentiable."@en ;
    askg-onto:inSentence "All the operations described above are differentiable."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-differentiable,
        askg-data:Entity-operations .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The least obvious cases are the bilinear interpolations of Eqs. 5 and 6, and the use of the inverse homography. For the former ones, we refer the reader to [14], who showed that the (sub)-gradient of bilinear interpolation with respect to W, could be efficiently computed. For the latter case, we propose to exploit the Sherman-Morrison formula [21], provided in the supplementary material, to avoid having to explicitly compute the inverse of the homography."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-731,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-732,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-733,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-734 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The least obvious cases are the bilinear interpolations of Eqs."@en ;
    askg-onto:inSentence "The least obvious cases are the bilinear interpolations of Eqs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bilinear_interpolations,
        askg-data:Entity-eqs .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-732 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "5 and 6, and the use of the inverse homography."@en ;
    askg-onto:inSentence "5 and 6, and the use of the inverse homography."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-inverse_homography,
        askg-data:Entity-method .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-733 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For the former ones, we refer the reader to [14], who showed that the (sub)-gradient of bilinear interpolation with respect to W, could be efficiently computed."@en ;
    askg-onto:inSentence "For the former ones, we refer the reader to [14], who showed that the (sub)-gradient of bilinear interpolation with respect to W, could be efficiently computed."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bilinear_interpolation,
        askg-data:Entity-sub-gradient .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-73-Sentence-734 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For the latter case, we propose to exploit the Sherman-Morrison formula [21], provided in the supplementary material, to avoid having to explicitly compute the inverse of the homography."@en ;
    askg-onto:inSentence "For the latter case, we propose to exploit the Sherman-Morrison formula [21], provided in the supplementary material, to avoid having to explicitly compute the inverse of the homography."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-homography,
        askg-data:Entity-sherman-morrison_formula .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-74 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "In our context, this formula lets us express the inverse of the homography analytically as follows. Let"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-74-Sentence-741,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-74-Sentence-742 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-74-Sentence-741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "In our context, this formula lets us express the inverse of the homography analytically as follows."@en ;
    askg-onto:inSentence "In our context, this formula lets us express the inverse of the homography analytically as follows."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula,
        askg-data:Entity-inverse_of_the_homography .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-74-Sentence-742 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Let"@en ;
    askg-onto:inSentence "Let"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-area,
        askg-data:Entity-article,
        askg-data:Entity-author,
        askg-data:Entity-cell_type,
        askg-data:Entity-company,
        askg-data:Entity-concept,
        askg-data:Entity-condition,
        askg-data:Entity-data,
        askg-data:Entity-database,
        askg-data:Entity-dataset,
        askg-data:Entity-device,
        askg-data:Entity-disease,
        askg-data:Entity-domain,
        askg-data:Entity-equipment,
        askg-data:Entity-experiment,
        askg-data:Entity-field,
        askg-data:Entity-finding,
        askg-data:Entity-framework,
        askg-data:Entity-gene,
        askg-data:Entity-idea,
        askg-data:Entity-index,
        askg-data:Entity-institution,
        askg-data:Entity-measure,
        askg-data:Entity-method,
        askg-data:Entity-metric,
        askg-data:Entity-model,
        askg-data:Entity-molecule,
        askg-data:Entity-organization,
        askg-data:Entity-paper,
        askg-data:Entity-paradigm,
        askg-data:Entity-person,
        askg-data:Entity-platform,
        askg-data:Entity-protein,
        askg-data:Entity-publication,
        askg-data:Entity-research_area,
        askg-data:Entity-research_group,
        askg-data:Entity-researcher,
        askg-data:Entity-result,
        askg-data:Entity-scientist,
        askg-data:Entity-score,
        askg-data:Entity-study,
        askg-data:Entity-symptom,
        askg-data:Entity-system,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-theory,
        askg-data:Entity-tool,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "$$\\tilde{\\bf H}^{-1}={\\bf R}^{\\rm T}+\\frac{{\\bf R}^{\\rm T}{\\bf t}{\\bf n}^{\\rm T}{\\bf R}^{\\rm T}}{1-{\\bf n}^{\\rm T}{\\bf R}^{\\rm T}{\\bf t}}.\\tag{8}$$ . Then, we have H−1 = KH˜ −1K−1. This formulation makes it easy to compute the gradient of the inverse homography w.r.t. the estimated depth and normals, and thus to train our model using backpropagation."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-751,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-752,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-753,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-754 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\tilde{\\bf H}^{-1}={\\bf R}^{\\rm T}+\\frac{{\\bf R}^{\\rm T}{\\bf t}{\\bf n}^{\\rm T}{\\bf R}^{\\rm T}}{1-{\\bf n}^{\\rm T}{\\bf R}^{\\rm T}{\\bf t}}.\\tag{8}$$ ."@en ;
    askg-onto:inSentence "$$\\tilde{\\bf H}^{-1}={\\bf R}^{\\rm T}+\\frac{{\\bf R}^{\\rm T}{\\bf t}{\\bf n}^{\\rm T}{\\bf R}^{\\rm T}}{1-{\\bf n}^{\\rm T}{\\bf R}^{\\rm T}{\\bf t}}.\\tag{8}$$ ."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h-1 .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-752 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Then, we have H−1 = KH˜ −1K−1."@en ;
    askg-onto:inSentence "Then, we have H−1 = KH˜ −1K−1."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-h1,
        askg-data:Entity-kh_1k1 .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-753 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This formulation makes it easy to compute the gradient of the inverse homography w.r.t."@en ;
    askg-onto:inSentence "This formulation makes it easy to compute the gradient of the inverse homography w.r.t."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulation,
        askg-data:Entity-gradient_of_the_inverse_homography .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-75-Sentence-754 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "the estimated depth and normals, and thus to train our model using backpropagation."@en ;
    askg-onto:inSentence "the estimated depth and normals, and thus to train our model using backpropagation."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-backpropagation,
        askg-data:Entity-model .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-76 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "To this end, we make use of an `1 loss between the true target image and the estimated one. Given N training samples, learning can then be expressed as"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-76-Sentence-761,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-76-Sentence-762 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-76-Sentence-761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "To this end, we make use of an `1 loss between the true target image and the estimated one."@en ;
    askg-onto:inSentence "To this end, we make use of an `1 loss between the true target image and the estimated one."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1_loss,
        askg-data:Entity-estimated_one,
        askg-data:Entity-true_target_image .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-76-Sentence-762 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given N training samples, learning can then be expressed as"@en ;
    askg-onto:inSentence "Given N training samples, learning can then be expressed as"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-learning,
        askg-data:Entity-n_training_samples .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-77 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "$$\\min_{\\bf W}\\frac{1}{N}\\sum_{i=1}^{N}\\|I_{i}^{t}-\\hat{I}_{i}^{t}(I_{i}^{s},P_{i},M_{i},{\\bf W})\\|_{1}\\,\\tag{9}$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-77-Sentence-771 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-77-Sentence-771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\min_{\\bf W}\\frac{1}{N}\\sum_{i=1}^{N}\\|I_{i}^{t}-\\hat{I}_{i}^{t}(I_{i}^{s},P_{i},M_{i},{\\bf W})\\|_{1}\\,\\tag{9}$$"@en ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-78 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "where I t iis the ground-truth novel view, and where, with a slight abuse of notation, we denote the segmentation mask for sample i as Mi. More details about optimization are provided in Section 4."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-78-Sentence-781,
        askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-78-Sentence-782 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-78-Sentence-781 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where I t iis the ground-truth novel view, and where, with a slight abuse of notation, we denote the segmentation mask for sample i as Mi."@en ;
    askg-onto:inSentence "where I t iis the ground-truth novel view, and where, with a slight abuse of notation, we denote the segmentation mask for sample i as Mi."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ground-truth_novel_view,
        askg-data:Entity-segmentation_mask .

askg-data:Paper-305358d7d24f2bf4-Section-7-Paragraph-78-Sentence-782 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "More details about optimization are provided in Section 4."@en ;
    askg-onto:inSentence "More details about optimization are provided in Section 4."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optimization,
        askg-data:Entity-section_4 .

askg-data:Paper-305358d7d24f2bf4-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "3.1.2 Obtaining Seed Regions"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-81,
        askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "$$(T)$$"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-81-Sentence-811 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$(T)$$"@en ;
    askg-onto:inSentence "$$(T)$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-company,
        askg-data:Entity-finding,
        askg-data:Entity-institution,
        askg-data:Entity-method,
        askg-data:Entity-platform,
        askg-data:Entity-publication,
        askg-data:Entity-research_group,
        askg-data:Entity-software,
        askg-data:Entity-study,
        askg-data:Entity-technique,
        askg-data:Entity-technology,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Throughout our framework, we assume to be given m segmentation masks as input, corresponding to the m planes we use to represent the scene. To extract these masks, we make use of the following simple, yet effective strategy. We first over-segment the image into superpixels using SLIC [1]. For each superpixel, we then extract its RGB value and center location as features and use *K-means* to cluster the superpixels into m regions. This strategy has the advantage over learning-based segmentation masks of generating compact regions, which are better suited to estimating the corresponding plane parameters. Furthermore, as evidenced by our experiments, it allows us to obtain accurate synthesized views that respect the scenes 3D structure."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-821,
        askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-822,
        askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-823,
        askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-824,
        askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-825,
        askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-826 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Throughout our framework, we assume to be given m segmentation masks as input, corresponding to the m planes we use to represent the scene."@en ;
    askg-onto:inSentence "Throughout our framework, we assume to be given m segmentation masks as input, corresponding to the m planes we use to represent the scene."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planes,
        askg-data:Entity-segmentation_masks .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To extract these masks, we make use of the following simple, yet effective strategy."@en ;
    askg-onto:inSentence "To extract these masks, we make use of the following simple, yet effective strategy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-masks,
        askg-data:Entity-strategy .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We first over-segment the image into superpixels using SLIC [1]."@en ;
    askg-onto:inSentence "We first over-segment the image into superpixels using SLIC [1]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-image,
        askg-data:Entity-slic,
        askg-data:Entity-superpixels .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-824 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For each superpixel, we then extract its RGB value and center location as features and use *K-means* to cluster the superpixels into m regions."@en ;
    askg-onto:inSentence "For each superpixel, we then extract its RGB value and center location as features and use *K-means* to cluster the superpixels into m regions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-center_location,
        askg-data:Entity-k-means,
        askg-data:Entity-m_regions,
        askg-data:Entity-rgb_value,
        askg-data:Entity-superpixel,
        askg-data:Entity-superpixels .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-825 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This strategy has the advantage over learning-based segmentation masks of generating compact regions, which are better suited to estimating the corresponding plane parameters."@en ;
    askg-onto:inSentence "This strategy has the advantage over learning-based segmentation masks of generating compact regions, which are better suited to estimating the corresponding plane parameters."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compact_regions,
        askg-data:Entity-learning-based_segmentation_masks,
        askg-data:Entity-plane_parameters .

askg-data:Paper-305358d7d24f2bf4-Section-8-Paragraph-82-Sentence-826 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Furthermore, as evidenced by our experiments, it allows us to obtain accurate synthesized views that respect the scenes 3D structure."@en ;
    askg-onto:inSentence "Furthermore, as evidenced by our experiments, it allows us to obtain accurate synthesized views that respect the scenes 3D structure."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-synthesized_views .

askg-data:Paper-305358d7d24f2bf4-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "3.2. Refinement Network"@en ;
    askg-onto:hasParagraph askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-92,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-93,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Our region-aware geometric-transformation network produces a novel view image that preserves the local geometric structures of the scene. While geometric transformations can synthesize regions that appear both in the input and novel views, it cannot handle the regions that are only present in the novel view, i.e., that were hidden in the input view. To address this, inspired by [20], we make use of the encoder-decoder refinement network depicted by Fig. 4."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-911,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-912,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-913,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-914 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our region-aware geometric-transformation network produces a novel view image that preserves the local geometric structures of the scene."@en ;
    askg-onto:inSentence "Our region-aware geometric-transformation network produces a novel view image that preserves the local geometric structures of the scene."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-local_geometric_structures_of_the_scene,
        askg-data:Entity-novel_view_image,
        askg-data:Entity-region-aware_geometric-transformation_network .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "While geometric transformations can synthesize regions that appear both in the input and novel views, it cannot handle the regions that are only present in the novel view, i.e., that were hidden in the input view."@en ;
    askg-onto:inSentence "While geometric transformations can synthesize regions that appear both in the input and novel views, it cannot handle the regions that are only present in the novel view, i.e., that were hidden in the input view."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geometric_transformations,
        askg-data:Entity-input_view,
        askg-data:Entity-input_views,
        askg-data:Entity-novel_view,
        askg-data:Entity-novel_views,
        askg-data:Entity-regions .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To address this, inspired by [20], we make use of the encoder-decoder refinement network depicted by Fig."@en ;
    askg-onto:inSentence "To address this, inspired by [20], we make use of the encoder-decoder refinement network depicted by Fig."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_refinement_network,
        askg-data:Entity-fig .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-91-Sentence-914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "4."@en ;
    askg-onto:inSentence "4."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-organization,
        askg-data:Entity-university .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-92 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "While the structure of this network is the same as in [20], we make use of a different, simpler loss function to train it."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-92-Sentence-921 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-92-Sentence-921 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "While the structure of this network is the same as in [20], we make use of a different, simpler loss function to train it."@en ;
    askg-onto:inSentence "While the structure of this network is the same as in [20], we make use of a different, simpler loss function to train it."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-loss_function,
        askg-data:Entity-network,
        askg-data:Entity-same_as_in_20 .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-93 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Figure 4. **Refinement Network.** Our refinement network adopts"@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-93-Sentence-931,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-93-Sentence-932 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-93-Sentence-931 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Figure 4."@en ;
    askg-onto:inSentence "Figure 4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-figure_4 .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-93-Sentence-932 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "**Refinement Network.** Our refinement network adopts"@en ;
    askg-onto:inSentence "**Refinement Network.** Our refinement network adopts"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-refinement_network .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "![5_image_0.png](5_image_0.png) an encoder-decoder structure with skip connections. The blue blocks denote convolutions with stride two followed by batch normalization and leaky ReLU. The green blocks denote convolutions with stride one followed by batch normalization and leaky ReLU. The purple blocks denote deconvolutions followed by batch normalization and ReLU."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-941,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-942,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-943,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-944 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-941 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![5_image_0.png](5_image_0.png) an encoder-decoder structure with skip connections."@en ;
    askg-onto:inSentence "![5_image_0.png](5_image_0.png) an encoder-decoder structure with skip connections."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-encoder-decoder_structure,
        askg-data:Entity-skip_connections .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-942 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The blue blocks denote convolutions with stride two followed by batch normalization and leaky ReLU."@en ;
    askg-onto:inSentence "The blue blocks denote convolutions with stride two followed by batch normalization and leaky ReLU."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-blue_blocks,
        askg-data:Entity-convolutions,
        askg-data:Entity-leaky_relu .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-943 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The green blocks denote convolutions with stride one followed by batch normalization and leaky ReLU."@en ;
    askg-onto:inSentence "The green blocks denote convolutions with stride one followed by batch normalization and leaky ReLU."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-convolutions,
        askg-data:Entity-green_blocks,
        askg-data:Entity-leaky_relu .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-94-Sentence-944 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The purple blocks denote deconvolutions followed by batch normalization and ReLU."@en ;
    askg-onto:inSentence "The purple blocks denote deconvolutions followed by batch normalization and ReLU."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-batch_normalization,
        askg-data:Entity-deconvolutions,
        askg-data:Entity-purple_blocks,
        askg-data:Entity-relu .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "Specifically, let Lp denote the mean pixel `1 error. We then define the loss of our refinement network as Lt = Lp + λLf , (10) where Lf is a feature `1 loss. That is, it corresponds to an `1 loss between features extracted from a fixed VGG-19 network, pre-trained for classification on ImageNet. In particular, we concatenate features from the 'conv1 2', 'conv2 2', 'conv3 2', 'conv4 2' and 'conv5 2' layers of VGG-19. This strategy has proven effective in [3] in the context of imageto-image translation. In particular, it has the advantage over [20] of not relying on a generative adversarial network, which are known to be hard to train. As shown in our results, this refinement network not only hallucinates the missing parts of the synthesized images, but it also removes the blur arising from combining multiple warped images."@en ;
    askg-onto:hasSentence askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-951,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-952,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-953,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-954,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-955,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-956,
        askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-957 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-951 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Specifically, let Lp denote the mean pixel `1 error."@en ;
    askg-onto:inSentence "Specifically, let Lp denote the mean pixel `1 error."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lp,
        askg-data:Entity-mean_pixel_1_error .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-952 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We then define the loss of our refinement network as Lt = Lp + λLf , (10) where Lf is a feature `1 loss."@en ;
    askg-onto:inSentence "We then define the loss of our refinement network as Lt = Lp + λLf , (10) where Lf is a feature `1 loss."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feature_1_loss,
        askg-data:Entity-lf,
        askg-data:Entity-lt__lp__%CE%BBlf,
        askg-data:Entity-refinement_network .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-953 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "That is, it corresponds to an `1 loss between features extracted from a fixed VGG-19 network, pre-trained for classification on ImageNet."@en ;
    askg-onto:inSentence "That is, it corresponds to an `1 loss between features extracted from a fixed VGG-19 network, pre-trained for classification on ImageNet."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-imagenet,
        askg-data:Entity-model,
        askg-data:Entity-vgg-19 .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-954 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In particular, we concatenate features from the 'conv1 2', 'conv2 2', 'conv3 2', 'conv4 2' and 'conv5 2' layers of VGG-19."@en ;
    askg-onto:inSentence "In particular, we concatenate features from the 'conv1 2', 'conv2 2', 'conv3 2', 'conv4 2' and 'conv5 2' layers of VGG-19."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-vgg-19 .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-955 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This strategy has proven effective in [3] in the context of imageto-image translation."@en ;
    askg-onto:inSentence "This strategy has proven effective in [3] in the context of imageto-image translation."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-imageto-image_translation,
        askg-data:Entity-strategy .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-956 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In particular, it has the advantage over [20] of not relying on a generative adversarial network, which are known to be hard to train."@en ;
    askg-onto:inSentence "In particular, it has the advantage over [20] of not relying on a generative adversarial network, which are known to be hard to train."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-generative_adversarial_network,
        askg-data:Entity-not_relying_on .

askg-data:Paper-305358d7d24f2bf4-Section-9-Paragraph-95-Sentence-957 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "As shown in our results, this refinement network not only hallucinates the missing parts of the synthesized images, but it also removes the blur arising from combining multiple warped images."@en ;
    askg-onto:inSentence "As shown in our results, this refinement network not only hallucinates the missing parts of the synthesized images, but it also removes the blur arising from combining multiple warped images."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blur_arising_from_combining_multiple_warped_images,
        askg-data:Entity-missing_parts_of_the_synthesized_images,
        askg-data:Entity-refinement_network .

askg-data:Entity-%CE%BB rdfs:label "λ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-00001 rdfs:label "0.0001"@en ;
    askg-onto:entityType "Metric"@en,
        "Rate"@en .

askg-data:Entity-0340 rdfs:label "0.340"@en ;
    askg-onto:entityType "Rate"@en .

askg-data:Entity-1_loss rdfs:label "1 loss"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-3d_cad_models rdfs:label "3D CAD models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-3d_information rdfs:label "3D information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3d_models rdfs:label "3D models"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-acm_transactions_on_graphics rdfs:label "ACM Transactions on Graphics"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-advances_in_neural_information_processing_systems rdfs:label "Advances in Neural Information Processing Systems"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-algorithm rdfs:label "Algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-architecture rdfs:label "architecture"@en ;
    askg-onto:entityType "Concept"@en,
        "Framework"@en .

askg-data:Entity-artefacts rdfs:label "artefacts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-artifacts rdfs:label "artifacts"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-background rdfs:label "background"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-bert rdfs:label "BERT"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-bilinear_interpolation rdfs:label "bilinear interpolation"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-c rdfs:label "C."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-cell_type rdfs:label "Cell Type"@en ;
    askg-onto:entityType "Cell Type"@en .

askg-data:Entity-center_location rdfs:label "center location"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-cnns rdfs:label "CNNs"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-computer_vision rdfs:label "computer vision"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-condition rdfs:label "Condition"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-convolutional_neural_networks rdfs:label "Convolutional Neural Networks"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-convolutions rdfs:label "convolutions"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-crispr rdfs:label "CRISPR"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-datasets rdfs:label "datasets"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-depth_estimation rdfs:label "depth estimation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain rdfs:label "Domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-efros rdfs:label "Efros"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-equation rdfs:label "equation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-equipment rdfs:label "Equipment"@en ;
    askg-onto:entityType "Equipment"@en .

askg-data:Entity-experiment rdfs:label "Experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-f rdfs:label "F"@en,
        "F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-fergus rdfs:label "Fergus"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-foreground_objects rdfs:label "foreground objects"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-gene rdfs:label "Gene"@en ;
    askg-onto:entityType "Gene"@en .

askg-data:Entity-girshick rdfs:label "Girshick"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-ground-truth_novel_view rdfs:label "ground-truth novel view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gtnor rdfs:label "gtNor"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-hard-segmentations rdfs:label "hard-segmentations"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-idea rdfs:label "Idea"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ieee rdfs:label "IEEE"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-ieee_transactions_on_pattern_analysis_and_machine_intelligence rdfs:label "IEEE transactions on pattern analysis and machine intelligence"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-index rdfs:label "Index"@en ;
    askg-onto:entityType "Index"@en .

askg-data:Entity-invertible rdfs:label "invertible"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-jin rdfs:label "Jin"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-leaky_relu rdfs:label "leaky ReLU"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-learnt_selection_maps rdfs:label "learnt selection maps"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-location rdfs:label "location"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-m_regions rdfs:label "m regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-malik rdfs:label "Malik"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-mathieu_salzmann rdfs:label "Mathieu Salzmann"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-measure rdfs:label "Measure"@en ;
    askg-onto:entityType "Measure"@en .

askg-data:Entity-molecule rdfs:label "Molecule"@en ;
    askg-onto:entityType "Molecule"@en .

askg-data:Entity-motion_of_the_buildings rdfs:label "motion of the buildings"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-motion_of_the_road rdfs:label "motion of the road"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-moving_objects rdfs:label "moving objects"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-n_d_j rdfs:label "n¯ d j"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-new_view rdfs:label "new view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nj rdfs:label "n¯j"@en,
        "n˜j"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-normals rdfs:label "normals"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-novel_view_synthesis_problem rdfs:label "novel view synthesis problem"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-openai rdfs:label "OpenAI"@en ;
    askg-onto:entityType "Company"@en,
        "Organization"@en .

askg-data:Entity-original_image_size rdfs:label "original image size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-our_network rdfs:label "our network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-paradigm rdfs:label "Paradigm"@en ;
    askg-onto:entityType "Paradigm"@en .

askg-data:Entity-pixel-wise_depth_and_normal_maps rdfs:label "pixel-wise depth and normal maps"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-planar rdfs:label "planar"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-plane_defined_by_the_seed_region rdfs:label "plane defined by the seed region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-predicted_homographies rdfs:label "predicted homographies"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-predicted_selection_map rdfs:label "predicted selection map"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proc rdfs:label "Proc."@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-proceedings_of_the_ieee_conference_on_computer_vision_and_pattern_recognition rdfs:label "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-protein rdfs:label "Protein"@en ;
    askg-onto:entityType "Protein"@en .

askg-data:Entity-q rdfs:label "Q"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-real-world_scenes rdfs:label "real-world scenes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-region-aware_geometric-transform_network rdfs:label "region-aware geometric-transform network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-region_masks rdfs:label "region masks"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-research rdfs:label "Research"@en,
        "research"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Field"@en .

askg-data:Entity-research_field rdfs:label "Research Field"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-score rdfs:label "Score"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-segmentation_mask rdfs:label "segmentation mask"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-selection_masks rdfs:label "selection masks"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-selmap rdfs:label "SelMap"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single-image_novel_view_synthesis rdfs:label "single-image novel view synthesis"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-single_image rdfs:label "single image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-skip_connections rdfs:label "skip connections"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-slic_superpixels rdfs:label "SLIC superpixels"@en,
        "Slic superpixels"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-snavely rdfs:label "Snavely"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-state-of-the-art_appearance_flow_technique rdfs:label "state-of-the-art appearance flow technique"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-strategy rdfs:label "strategy"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-symptom rdfs:label "Symptom"@en ;
    askg-onto:entityType "Symptom"@en .

askg-data:Entity-synthesized_images rdfs:label "synthesized images"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-target_image rdfs:label "target image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-test_set rdfs:label "test set"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-them rdfs:label "them"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-v rdfs:label "V."@en,
        "v"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-vgg-19 rdfs:label "VGG-19"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-w rdfs:label "W"@en,
        "W."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-warped_images rdfs:label "warped images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-warped_selection_maps rdfs:label "warped selection maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-zisserman rdfs:label "Zisserman"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-2 rdfs:label "2"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Publication"@en .

askg-data:Entity-3 rdfs:label "3"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-3d_scene_structure rdfs:label "3D scene structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approach rdfs:label "approach"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-author rdfs:label "Author"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-b rdfs:label "B"@en,
        "B."@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Model"@en .

askg-data:Entity-batch_normalization rdfs:label "batch normalization"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-candidate_images rdfs:label "candidate images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data_visualization rdfs:label "Data Visualization"@en,
        "data visualization"@en ;
    askg-onto:entityType "Finding"@en,
        "Tool"@en .

askg-data:Entity-disease rdfs:label "Disease"@en ;
    askg-onto:entityType "Disease"@en .

askg-data:Entity-eq rdfs:label "Eq"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-estimated_depth rdfs:label "estimated depth"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Metric"@en .

askg-data:Entity-estnor rdfs:label "estNor"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-experiments rdfs:label "experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-field rdfs:label "Field"@en ;
    askg-onto:entityType "Research Field"@en .

askg-data:Entity-fixed_number_of_planes rdfs:label "fixed number of planes"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-ground-truth_normals rdfs:label "ground-truth normals"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-h-1 rdfs:label "H^{-1}"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-hypercolumn_feature rdfs:label "hypercolumn feature"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ieee_conference_on_computer_vision_and_pattern_recognition rdfs:label "IEEE Conference on Computer Vision and Pattern Recognition"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-imagenet rdfs:label "ImageNet"@en ;
    askg-onto:entityType "Database"@en,
        "Dataset"@en .

askg-data:Entity-images rdfs:label "images"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inverse_homography rdfs:label "inverse homography"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-maps rdfs:label "maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-metric rdfs:label "Metric"@en ;
    askg-onto:entityType "Metric"@en .

askg-data:Entity-more_realistic_results rdfs:label "more realistic results"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-novel_view_synthesis rdfs:label "novel view synthesis"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-ours-full rdfs:label "Ours-Full"@en ;
    askg-onto:entityType "Framework"@en,
        "Model"@en .

askg-data:Entity-pixel rdfs:label "pixel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-plane rdfs:label "plane"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pytorch rdfs:label "PyTorch"@en ;
    askg-onto:entityType "Platform"@en,
        "Software"@en,
        "Technology"@en .

askg-data:Entity-quality_of_the_depth_and_normal_estimates rdfs:label "quality of the depth and normal estimates"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en .

askg-data:Entity-realistic_novel_views rdfs:label "realistic novel views"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regions rdfs:label "regions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research_area rdfs:label "Research Area"@en ;
    askg-onto:entityType "Research Area"@en .

askg-data:Entity-researcher rdfs:label "Researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-result rdfs:label "Result"@en,
        "result"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-results rdfs:label "results"@en ;
    askg-onto:entityType "Finding"@en,
        "Result"@en .

askg-data:Entity-scannet_dataset rdfs:label "ScanNet Dataset"@en,
        "ScanNet dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-seed rdfs:label "Seed"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-selection_map rdfs:label "selection map"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-sherman-morrison_formula rdfs:label "Sherman-Morrison formula"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-subnetwork rdfs:label "subnetwork"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-superpixels rdfs:label "superpixels"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-two_subnetworks rdfs:label "two subnetworks"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-university_of_california rdfs:label "University of California"@en ;
    askg-onto:entityType "Organization"@en,
        "University"@en .

askg-data:Entity-university_of_california_berkeley rdfs:label "University of California, Berkeley"@en ;
    askg-onto:entityType "Organization"@en,
        "University"@en .

askg-data:Entity-y rdfs:label "Y"@en,
        "Y."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-2017 rdfs:label "2017"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-appearance_flow_method rdfs:label "appearance flow method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-arxiv_preprint rdfs:label "arXiv preprint"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-cvpr rdfs:label "CVPR"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-depth rdfs:label "depth"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Metric"@en .

askg-data:Entity-device rdfs:label "Device"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-estdep rdfs:label "estDep"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-european_conference_on_computer_vision rdfs:label "European Conference on Computer Vision"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-feature_maps rdfs:label "feature maps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geometry rdfs:label "Geometry"@en,
        "geometry"@en ;
    askg-onto:entityType "Concept"@en,
        "Theory"@en .

askg-data:Entity-ground-truth_depth rdfs:label "ground-truth depth"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Metric"@en .

askg-data:Entity-gtdep rdfs:label "gtDep"@en ;
    askg-onto:entityType "Concept"@en,
        "Metric"@en .

askg-data:Entity-h rdfs:label "H"@en,
        "H."@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Person"@en .

askg-data:Entity-input_pixel rdfs:label "input pixel"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_view rdfs:label "input view"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-kitti_dataset rdfs:label "KITTI Dataset"@en,
        "KITTI dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-ours-geo rdfs:label "Ours-Geo"@en ;
    askg-onto:entityType "Framework"@en,
        "Model"@en .

askg-data:Entity-paper rdfs:label "Paper"@en,
        "paper"@en ;
    askg-onto:entityType "Paper"@en,
        "Publication"@en .

askg-data:Entity-pixels rdfs:label "pixels"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relative_pose rdfs:label "relative pose"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-seed_regions rdfs:label "seed regions"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-segmentation_masks rdfs:label "segmentation masks"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Result"@en .

askg-data:Entity-springer rdfs:label "Springer"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-stanford_university rdfs:label "Stanford University"@en ;
    askg-onto:entityType "Organization"@en,
        "University"@en .

askg-data:Entity-theory rdfs:label "Theory"@en ;
    askg-onto:entityType "Theory"@en .

askg-data:Entity-d rdfs:label "D."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en,
        "Publication"@en .

askg-data:Entity-database rdfs:label "Database"@en ;
    askg-onto:entityType "Database"@en .

askg-data:Entity-encoder-decoder_network rdfs:label "Encoder-decoder network"@en,
        "encoder-decoder network"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-g rdfs:label "G"@en,
        "G."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-institution rdfs:label "Institution"@en ;
    askg-onto:entityType "Institution"@en .

askg-data:Entity-j rdfs:label "J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-m rdfs:label "M"@en,
        "M."@en ;
    askg-onto:entityType "Model"@en,
        "Person"@en .

askg-data:Entity-methods rdfs:label "methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-our_method rdfs:label "our method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-platform rdfs:label "Platform"@en ;
    askg-onto:entityType "Concept"@en,
        "Platform"@en .

askg-data:Entity-predictions rdfs:label "predictions"@en ;
    askg-onto:entityType "Finding"@en,
        "Model"@en .

askg-data:Entity-scene_structure rdfs:label "scene structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-system rdfs:label "System"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-t rdfs:label "T."@en ;
    askg-onto:entityType "Person"@en,
        "Publication"@en .

askg-data:Entity-tensorflow rdfs:label "TensorFlow"@en,
        "tensorflow"@en ;
    askg-onto:entityType "Framework"@en,
        "Platform"@en,
        "Software"@en,
        "Technology"@en .

askg-data:Entity-view rdfs:label "View"@en,
        "view"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-view_synthesis rdfs:label "View synthesis"@en,
        "view synthesis"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-a rdfs:label "A"@en,
        "A."@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en,
        "Publication"@en .

askg-data:Entity-k rdfs:label "K"@en,
        "K."@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-r rdfs:label "R"@en,
        "R."@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Person"@en,
        "Software"@en .

askg-data:Entity-seed_region rdfs:label "seed region"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-selection_maps rdfs:label "selection maps"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Result"@en .

askg-data:Entity-2016 rdfs:label "2016"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-article rdfs:label "Article"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en,
        "deep learning"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "Technology"@en .

askg-data:Entity-tool rdfs:label "Tool"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-finding rdfs:label "Finding"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-novel_views rdfs:label "Novel views"@en,
        "novel views"@en ;
    askg-onto:entityType "Concept"@en,
        "Finding"@en,
        "Model"@en .

askg-data:Entity-refinement_network rdfs:label "Refinement Network"@en,
        "refinement network"@en ;
    askg-onto:entityType "Concept"@en,
        "Framework"@en,
        "Model"@en .

askg-data:Entity-scene rdfs:label "scene"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-technique rdfs:label "Technique"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-3d_geometry rdfs:label "3D geometry"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-appearance_flow rdfs:label "appearance flow"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Model"@en .

askg-data:Entity-network rdfs:label "network"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en,
        "System"@en,
        "Technology"@en .

askg-data:Entity-study rdfs:label "Study"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-company rdfs:label "Company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-data rdfs:label "Data"@en,
        "data"@en ;
    askg-onto:entityType "Dataset"@en,
        "Finding"@en .

askg-data:Entity-fig rdfs:label "Fig"@en,
        "Fig."@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-framework rdfs:label "Framework"@en,
        "framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-software rdfs:label "Software"@en ;
    askg-onto:entityType "Software"@en .

askg-data:Entity-concept rdfs:label "Concept"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-novel_view rdfs:label "novel view"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-image rdfs:label "Image"@en,
        "image"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kitti rdfs:label "KITTI"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-our_approach rdfs:label "Our approach"@en,
        "our approach"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-selection_network rdfs:label "Selection Network"@en,
        "selection network"@en ;
    askg-onto:entityType "Concept"@en,
        "Framework"@en,
        "Method"@en,
        "Model"@en,
        "System"@en .

askg-data:Entity-technology rdfs:label "Technology"@en ;
    askg-onto:entityType "Concept"@en,
        "Technology"@en .

askg-data:Entity-input_image rdfs:label "input image"@en ;
    askg-onto:entityType "Concept"@en,
        "Dataset"@en .

askg-data:Entity-organization rdfs:label "Organization"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-homography rdfs:label "homography"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-research_group rdfs:label "Research Group"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-homographies rdfs:label "Homographies"@en,
        "homographies"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-scannet rdfs:label "ScanNet"@en,
        "Scannet"@en ;
    askg-onto:entityType "Dataset"@en,
        "Platform"@en .

askg-data:Entity-model rdfs:label "Model"@en,
        "model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-university rdfs:label "University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Metric"@en .

askg-data:Entity-scientist rdfs:label "Scientist"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-publication rdfs:label "Publication"@en ;
    askg-onto:entityType "Measure"@en,
        "Metric"@en,
        "Publication"@en .

askg-data:Entity-person rdfs:label "Person"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

