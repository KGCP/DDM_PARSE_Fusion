@prefix askg-data: <https://www.anu.edu.au/data/scholarly/> .
@prefix askg-onto: <https://www.anu.edu.au/onto/scholarly#> .
@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix domo: <http://example.org/domo/> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

askg-data:Paper-0ecbd8a3379fdc37 a askg-onto:Paper ;
    rdfs:label "0ecbd8a3379fdc37"@en ;
    dc:title "0ecbd8a3379fdc37"^^xsd:string ;
    askg-onto:hasSection askg-data:Paper-0ecbd8a3379fdc37-Section-1,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18,
        askg-data:Paper-0ecbd8a3379fdc37-Section-2,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8,
        askg-data:Paper-0ecbd8a3379fdc37-Section-9 .

askg-data:Entity-%0Aoperatornamelim_ntoinfty%0A rdfs:label """
\\operatorname*{lim}_{n\\to\\infty}
"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-05 rdfs:label "0.5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-0___u_l rdfs:label "0¢ = ¢ U .l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1 rdfs:label "¢1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-12935-622001 rdfs:label "129:35-62,2001"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1960 rdfs:label "1960"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1__n__12 rdfs:label "1 ::; n ::; 12"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1jio rdfs:label "1Jio"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-1r rdfs:label "1r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2 rdfs:label "¢2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-2000 rdfs:label "2000"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2001 rdfs:label "2001"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2003 rdfs:label "2003"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2n_states rdfs:label "2n states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-3_times_that_of_the_nmrop rdfs:label "3 times that of the NMROP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-4pltlsim rdfs:label "4PLTLSIM"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-5-tuple_s_s0_a_pr_r rdfs:label "5-tuple (S, s0, A, Pr, R)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-500mb_of_ram rdfs:label "500MB of ram"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-81 rdfs:label "81/!"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-8_modality rdfs:label "8 modality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-8k rdfs:label "8k"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-_e_sub_ rdfs:label "¢' E Sub( )"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-_to_hold_now rdfs:label "¢ to hold now"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a%0Aprimes%0Aprime rdfs:label """A^{
prime}(s^{
prime})"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a71_oi_g__ rdfs:label "A7�1 Oi (g _"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a7s rdfs:label "A(7(s'))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_formula rdfs:label "a formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_long_sequence_of_events rdfs:label "a long sequence of events"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_real rdfs:label "a real"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_set_of_pairs rdfs:label "a set of pairs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_simple_characterisation_of_a_range_of_translations rdfs:label "a simple characterisation of a range of translations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-a_straightforward_semantics_of_non-markovian_rewards rdfs:label "a straightforward semantics of non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-aaai-02 rdfs:label "AAAI-02"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-achievement rdfs:label "achievement"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-achievement_of_c rdfs:label "achievement of �c"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-action_specification rdfs:label "action specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-action_specification_trees rdfs:label "action specification trees"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-actions rdfs:label "actions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-actual_execution_sequences rdfs:label "actual execution sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-additional_information rdfs:label "additional information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-additional_preprocessing rdfs:label "additional preprocessing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-admissible_heuristic rdfs:label "admissible heuristic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ai rdfs:label "ai"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-algebraic_decision_diagrams rdfs:label "algebraic decision diagrams"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_propositions rdfs:label "all propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_propositions_pi_1__j__i_to_false rdfs:label "all propositions Pi, 1 ::; j < i to false"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-all_states_in_s rdfs:label "all states in S"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-an_off-line_preprocessing_phase rdfs:label "an off-line preprocessing phase"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-analysis_of_rewards rdfs:label "analysis of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-any_sequence_of_states_feasible_under_the_generated_policies rdfs:label "any sequence of states feasible under the generated policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ar rdfs:label "A(r)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-arcs rdfs:label "arcs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-artificial_domains rdfs:label "artificial domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-as rdfs:label "A'(s')"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-availability_of_good_heuristics rdfs:label "availability of good heuristics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-average_run_time rdfs:label "average run time"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-averages_of_the_running_times rdfs:label "averages of the running times"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bacchus_and_kabanza rdfs:label "Bacchus and Kabanza"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-bacchus_et_al_1996 rdfs:label "Bacchus et al., 1996"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-bacchus_et_al_1996_bacchus_et_al_1997_thiebaux_et_al_2002 rdfs:label "[Bacchus et al., 1996; Bacchus et al., 1997; Thiebaux et al., 2002]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-bdd_representation rdfs:label "BDD representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-behavioural_distinctions rdfs:label "behavioural distinctions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-behaviours rdfs:label "behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-best_case_behaviour_of_spud_d rdfs:label "best case behaviour of SPUD D"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-better_performance_than_pltlsim rdfs:label "better performance than PLTLSIM"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-blind_minimal_equivalent_mop rdfs:label "blind minimal equivalent MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blindness rdfs:label "blindness"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bonet rdfs:label "Bonet"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bottleneck rdfs:label "bottleneck"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-boutilier_r rdfs:label "Boutilier, R."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-bushiness_of_the_internal_part_of_the_adds rdfs:label "bushiness of the internal part of the ADDs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bushiness_of_their_leaves rdfs:label "bushiness of their leaves"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cambridge_ma rdfs:label "Cambridge, MA"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-certain_rewards rdfs:label "certain rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-charles_grelton rdfs:label "Charles Grelton"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-cited_approaches rdfs:label "cited approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-claim rdfs:label "claim"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-class_of_mop_solution_methods rdfs:label "class of MOP solution methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classical_dynamic_programming_methods rdfs:label "classical dynamic programming methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-classical_propositional_logic_formula rdfs:label "classical propositional logic formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-classical_solution_method rdfs:label "classical solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-com-plete rdfs:label "COM-PLETE"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-command_c rdfs:label "command c"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compact_representation rdfs:label "compact representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-compact_representation_with_new_temporal_variables rdfs:label "compact representation with new temporal variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-company rdfs:label "company"@en ;
    askg-onto:entityType "Company"@en .

askg-data:Entity-complete rdfs:label "COMPLETE"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-complete_domain rdfs:label "COMPLETE domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-computer_sciences_laboratory rdfs:label "Computer Sciences Laboratory"@en ;
    askg-onto:entityType "Research Group"@en .

askg-data:Entity-computing_l rdfs:label "computing l"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-computing_the_labels_l__s_for_each_states rdfs:label "computing the labels l ( s) for each states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-concepts rdfs:label "concepts"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-constant rdfs:label "constant"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-context_of_domains_of_more_practical_interest rdfs:label "context of domains of more practical interest"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-control-knowledge rdfs:label "control-knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-control_knowledge_formulae rdfs:label "Control knowledge formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-counterexamples rdfs:label "counterexamples"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-crude_translation rdfs:label "crude translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-cudd_library rdfs:label "CUDD library"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-cudd_package rdfs:label "CUDD package"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-current_reward rdfs:label "current reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_truth_of_all_reward_formulae rdfs:label "current truth of all reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_values rdfs:label "current values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_values_of_formulae_in_t rdfs:label "current values of formulae in T"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-d rdfs:label "D"@en,
        "D'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-d_c__ rdfs:label "D( c _"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-data rdfs:label "data"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-david_price rdfs:label "David Price"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-deadline_goals rdfs:label "deadline goals"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dearden rdfs:label "Dearden"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-decision_process_with_non-markovian_rewards rdfs:label "decision process with non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_processes_with_non-markovian_rewards rdfs:label "decision processes with Non-Markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-deep_learning rdfs:label "Deep Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-definitions rdfs:label "Definitions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degree rdfs:label "degree"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degree_of_structure rdfs:label "degree of structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degree_of_structure_or_uncertainty rdfs:label "degree of structure or uncertainty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-degree_of_uncertainty rdfs:label "degree of uncertainty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-device rdfs:label "Device"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different rdfs:label "different"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_languages rdfs:label "different languages"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_mdp_representations rdfs:label "different MDP representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_target rdfs:label "different target"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-discounting_factor rdfs:label "discounting factor"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distant_rewards rdfs:label "distant rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-distinct_phases rdfs:label "distinct phases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain-specific_heuristics rdfs:label "domain-specific heuristics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain_features rdfs:label "domain features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_analyses rdfs:label "dynamic analyses"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_aspects rdfs:label "dynamic aspects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_irrelevance rdfs:label "dynamic irrelevance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_programming rdfs:label "Dynamic Programming"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_programming_method rdfs:label "dynamic programming method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-dynamics_and_reward rdfs:label "dynamics and reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e-states_reachable_from_the_start_state rdfs:label "e-states reachable from the start state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e_c_and_its_subformulae rdfs:label "e' c and its subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e_ptsub rdfs:label "E PTSub()"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-each_action rdfs:label "each action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effect rdfs:label "effect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effective rdfs:label "effective"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effects rdfs:label "effects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-effort rdfs:label "effort"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-en rdfs:label "en¢"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-evasive rdfs:label "evasive"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-events rdfs:label "events"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-every_sequence_of_sw rdfs:label "every sequence of sw"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-excessive_memory_requirements rdfs:label "excessive memory requirements"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-expanded_states rdfs:label "expanded states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expectation rdfs:label "expectation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expected_future_rewards rdfs:label "expected future rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-expensive_preprocessing rdfs:label "expensive preprocessing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiment rdfs:label "experiment"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-experimental_investigation rdfs:label "experimental investigation"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-explicit_assignments_to_propositions rdfs:label "explicit assignments to propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-explicit_exploration rdfs:label "explicit exploration"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-extended_state_space rdfs:label "extended state space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-extra_complexity rdfs:label "extra complexity"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fact rdfs:label "fact"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-factor_exponential_in_the_length_of_the_formula rdfs:label "factor exponential in the length of the formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-factored_markov_decision_processes rdfs:label "factored markov decision processes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-family_of_nmrdp_solution_methods rdfs:label "family of NMRDP solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-family_of_probability_distributions rdfs:label "family of probability distributions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fastest_and_slowest_methods rdfs:label "fastest and slowest methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-feasible_e-state_sequences rdfs:label "feasible e-state sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feasible_state_sequences rdfs:label "feasible state sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-features rdfs:label "features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feng_2002 rdfs:label "Feng, 2002"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-feng_and_hansen rdfs:label "Feng and Hansen"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-figure_3 rdfs:label "Figure 3"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figure_5 rdfs:label "Figure 5"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figures_8_and_9 rdfs:label "Figures 8 and 9"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-figures_i_and_2 rdfs:label "Figures I and 2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-findings rdfs:label "findings"@en ;
    askg-onto:entityType "Finding"@en .

askg-data:Entity-finite_sequence rdfs:label "finite sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_sequence_fi_ending_with_ri__s rdfs:label "finite sequence f(i) ending with ri = s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_sequences_of_states rdfs:label "finite sequences of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_set_of_actions rdfs:label "finite set of actions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-finite_set_of_fully_observable_states rdfs:label "finite set of fully observable states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_n_steps rdfs:label "first n steps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_of_their_kind rdfs:label "first of their kind"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-first_report rdfs:label "First report"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-first_row rdfs:label "first row"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fixed_reward rdfs:label "fixed reward"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-fixpoint_equation rdfs:label "fixpoint equation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fl_tl_translation rdfs:label "FL TL translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl_formula rdfs:label "FLTL formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl_semantics rdfs:label "FLTL semantics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl_translation rdfs:label "FLTL translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formal_semantics rdfs:label "formal semantics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-formula_8k_jj rdfs:label "formula 8k <jJ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-four_hand-coded_domains rdfs:label "four hand-coded domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-framework rdfs:label "framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-fully_connected_reflexive_domain rdfs:label "fully connected reflexive domain"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-fully_markovian_decision_process_mop rdfs:label "fully Markovian decision process (MOP)"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-function_7 rdfs:label "function 7"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-future-oriented_logics rdfs:label "future-oriented logics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_operators rdfs:label "future operators"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_rewards rdfs:label "future rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-future_work rdfs:label "future work"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g_1_gk_c rdfs:label "g 1\\ Gk c"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g_1_v71_gi_c rdfs:label "g 1\\ v7�1 Gi c"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g__enc rdfs:label "g !\\ enc"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gain rdfs:label "gain"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gamma rdfs:label "\\Gamma"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gammai rdfs:label "\\Gamma(i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-geffner rdfs:label "Geffner"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-general_observations rdfs:label "general observations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gf rdfs:label "G<f;"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gignc rdfs:label "gi\\Gnc"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gnulinux_2420 rdfs:label "GNU/Linux 2.4.20"@en ;
    askg-onto:entityType "Platform"@en .

askg-data:Entity-goal rdfs:label "goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-gold-_szmidt rdfs:label "Gold- szmidt"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-graph rdfs:label "graph"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-graphs rdfs:label "graphs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-h rdfs:label "H."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-haddawy rdfs:label "Haddawy"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hand-coded_domain rdfs:label "hand-coded domain"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hanks rdfs:label "Hanks"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-hansen_2002 rdfs:label "Hansen, 2002"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-heuristic_forward_search_solution_methods rdfs:label "heuristic forward search solution methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-heuristic_search rdfs:label "heuristic search"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-heuristic_value rdfs:label "heuristic value"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-history rdfs:label "history"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-history_distinctions rdfs:label "history distinctions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hoey_et_al_1999 rdfs:label "[Hoey et al., 1999]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-hoey_r rdfs:label "Hoey, R."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-how_far_into_the_future_they_occur rdfs:label "how far into the future they occur"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-howard rdfs:label "Howard"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-howard_1960 rdfs:label "[Howard, 1960]"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-httpwwwcsubccaspiderstaubinspudd rdfs:label "http://www.cs.ubc.ca/spider/staubin/Spudd/"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hu rdfs:label "Hu"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-icaps-03 rdfs:label "ICAPS-03"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-ijcai-95 rdfs:label "IJCAI-95"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-immediate_reward_for_being_in_state_s rdfs:label "immediate reward for being in state s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-implementation rdfs:label "implementation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-implementation_and_experimental_comparison rdfs:label "implementation and experimental comparison"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-improvement rdfs:label "improvement"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-inappropriateness_of_methods rdfs:label "(in)appropriateness of methods"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-influence_of_factors rdfs:label "influence of factors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-information rdfs:label "information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_e-state rdfs:label "initial e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-initial_states rdfs:label "Initial states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-inprocaaai-97 rdfs:label "InProc.AAAI-97"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-input rdfs:label "input"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-input_language rdfs:label "input language"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevance rdfs:label "irrelevance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevance_of_the_goal rdfs:label "irrelevance of the goal"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevance_of_the_trigger rdfs:label "irrelevance of the trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevance_of_variables_to_particular_policies rdfs:label "irrelevance of variables to particular policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-irrelevant_variables rdfs:label "irrelevant variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-is rdfs:label "is"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-its_states_and_transitions rdfs:label "its states and transitions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-itself rdfs:label "itself"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-j rdfs:label "J."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-john_slaney rdfs:label "John Slaney"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-k rdfs:label "k"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-k_additional_bits_of_information rdfs:label "k additional bits of information"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-k_iterations rdfs:label "k iterations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-k_steps rdfs:label "k steps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-kr-92 rdfs:label "KR-92"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-labeled_rtdp rdfs:label "Labeled RTDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-labelled_rtdp rdfs:label "labelled RTDP"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-labelled_rtop rdfs:label "labelled RTOP"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-lack_of_structure rdfs:label "Lack of structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-language rdfs:label "language"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-largemdp rdfs:label "largeMDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-last_row rdfs:label "last row"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-leaves rdfs:label "leaves"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-length rdfs:label "length"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-length_of_the_formula rdfs:label "length of the formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-length_of_the_temporal_reward_formula rdfs:label "length of the temporal reward formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lim_ne_i0n%CE%B2ir%CE%B3_i%CF%80%CE%B3_0s_0 rdfs:label "lim_{n→∞}E[∑_{i=0}^{n}β^{i}R(Γ_{i})|π,Γ_{0}=s_{0}]"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_temporal_logic_of_the_past rdfs:label "linear temporal logic of the past"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-linear_temporal_logic_with_past_operators_pltl rdfs:label "linear temporal logic with past operators (PLTL)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-literature rdfs:label "literature"@en ;
    askg-onto:entityType "Corpus"@en .

askg-data:Entity-ls rdfs:label "l(s)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-machine_learning rdfs:label "Machine Learning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mai-96 rdfs:label "MAI-96"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-main_ideas rdfs:label "main ideas"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-many_elements_with_identical_rewards rdfs:label "many elements with identical rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mapping_7 rdfs:label "mapping 7"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-markov_processes rdfs:label "Markov Processes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mdp_size rdfs:label "MDP size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mdp_solution_method rdfs:label "MDP solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mdp_solution_methods rdfs:label "MDP solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-measuring_the_size_of_the_generated_mdp rdfs:label "measuring the size of the generated MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mechanisms rdfs:label "mechanisms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-method_performance rdfs:label "method performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-methods_based_on_pltl rdfs:label "methods based on PLTL"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mit_press rdfs:label "MIT Press"@en ;
    askg-onto:entityType "Organization"@en .

askg-data:Entity-mmx rdfs:label "MMX"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-model rdfs:label "model"@en ;
    askg-onto:entityType "Model"@en .

askg-data:Entity-modem_processor_features rdfs:label "modem processor features"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-mop_d rdfs:label "MOP D'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mop_size rdfs:label "MOP size"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mop_solution_method rdfs:label "MOP solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-mops rdfs:label "MOPs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mtl rdfs:label "MTL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mtl-matrix_template_library rdfs:label "MTL-Matrix Template Library"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-much_cheaper_way rdfs:label "much cheaper way"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n__6 rdfs:label "n = 6"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n__6_propositions rdfs:label "n = 6 propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n__r rdfs:label "n * r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n_propositions rdfs:label "n propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-n_propositions_pi rdfs:label "n propositions Pi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-natural_number rdfs:label "natural number"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-negation_normal_form_propositional_logic rdfs:label "negation normal form propositional logic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-neural_network rdfs:label "Neural Network"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-next_state rdfs:label "next state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdp_approaches rdfs:label "NMRDP approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdp_d rdfs:label "NMRDP D"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdp_planner rdfs:label "NMRDP Planner"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-nmrdp_state_s rdfs:label "NMRDP state s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmropp rdfs:label "NMROPP"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-nodes rdfs:label "nodes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-completely_connected rdfs:label "non-completely connected"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-non-markovian_decision_processes rdfs:label "non-markovian decision processes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-markovian_reward_functions rdfs:label "non-Markovian reward functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-stationary_policy rdfs:label "non-stationary policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-structured_algorithms rdfs:label "non-structured algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-non-zero_probabilities rdfs:label "Non-zero probabilities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-zero_probability rdfs:label "non-zero probability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-notation rdfs:label "Notation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_iterations rdfs:label "number of iterations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-number_of_rewards_and_propositions rdfs:label "number of rewards and propositions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-observation rdfs:label "observation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-off-line_expansion rdfs:label "off-line expansion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-off-line_preprocessing_phase rdfs:label "off-line preprocessing phase"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-ok_g rdfs:label "ok g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-on-line rdfs:label "on-line"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-one rdfs:label "one"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-one_point_or_another rdfs:label "one point or another"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ones rdfs:label "ones"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-operator rdfs:label "operator"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-operators_g_and_s rdfs:label "operators G and S"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimal_solution rdfs:label "optimal solution"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optimally rdfs:label "optimally"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-optional rdfs:label "optional"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-order_of_events rdfs:label "order of events"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-original_nmrop rdfs:label "original NMROP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-p rdfs:label "<P"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pages_501-510 rdfs:label "pages 501-510"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paper rdfs:label "paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-papers rdfs:label "papers"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-part_of_the_control_knowledge rdfs:label "part of the control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-past-oriented_ones rdfs:label "past-oriented ones"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-past_behaviours rdfs:label "past behaviours"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-paths_leading_to_the_e-state rdfs:label "paths leading to the e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-patterns rdfs:label "patterns"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pentium4_26ghz rdfs:label "Pentium4 2.6GHz"@en ;
    askg-onto:entityType "Device"@en .

askg-data:Entity-performance_results rdfs:label "Performance results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-pij rdfs:label "Pi,j"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pis rdfs:label "PiS"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pl_tl-_str rdfs:label "PL TL- STR"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pl_tlmin rdfs:label "PL TLMIN"@en ;
    askg-onto:entityType "Tool"@en .

askg-data:Entity-planning rdfs:label "planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl-_str rdfs:label "PLTL- STR"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl-_stra rdfs:label "PLTL- STR(A)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_based_algorithms rdfs:label "PLTL based algorithms"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-pltl_formula rdfs:label "PLTL formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltl_methods rdfs:label "PLTL methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-pltl_representation_of_rewards rdfs:label "PLTL representation of rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltlstr_translation rdfs:label "PLTLSTR translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pn rdfs:label "Pn"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policies rdfs:label "policies"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policy_construction rdfs:label "policy construction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-poorly_with_reward_on_spudd-expon rdfs:label "poorly with reward on SPUDD-EXPON"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-possible_previous_values rdfs:label "possible previous values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-possibly_infinite_state_sequence rdfs:label "possibly infinite state sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-possibly_infinite_state_sequences rdfs:label "possibly infinite state sequences"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-post-hoc_minimisation_of_the_mdp rdfs:label "post-hoc minimisation of the MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-powerful rdfs:label "powerful"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-practical_abilities_of_the_methods rdfs:label "practical abilities of the methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-prefix rdfs:label "prefix"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prefix_r__i_-_1 rdfs:label "prefix r ( i - 1)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-presence_of_rewards_irrelevant_to_the_optimal_policy rdfs:label "presence of rewards irrelevant to the optimal policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-previous_values rdfs:label "previous values"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probabilistic_effects rdfs:label "probabilistic effects"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probabilities rdfs:label "probabilities"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probability rdfs:label "probability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-probability_function rdfs:label "probability function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-problem_features rdfs:label "problem features"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-process rdfs:label "process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prog_s rdfs:label "Prog(¢, s)"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-prog_s_i__e_ rdfs:label "{$Prog(¢, s) I ¢ E }"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-properties_i_and_2 rdfs:label "properties (I) and (2)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-property rdfs:label "property"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposition rdfs:label "proposition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposition_pi_to_true rdfs:label "Proposition Pi to true"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-propositional_logic rdfs:label "propositional logic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-propositions_pi_1__j__i rdfs:label "Propositions Pi, 1 ::; j < i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prvln rdfs:label "prvln"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-prvout rdfs:label "prvOut"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ptsub rdfs:label "PTSub"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-questions rdfs:label "questions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r_0 rdfs:label "r 0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-r_increases rdfs:label "r increases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-ra_howard rdfs:label "R.A. Howard"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-random_problems rdfs:label "random problems"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-range_of_statistics_about_performance rdfs:label "range of statistics about performance"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-reachability_analysis rdfs:label "reachability analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachability_in_the_space_of_e-states rdfs:label "reachability in the space of e-states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachable_e-state_space rdfs:label "reachable e-state space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reader rdfs:label "reader"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-real rdfs:label "real"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-real-time_dynamic_programming rdfs:label "real-time dynamic programming"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-real_value_r rdfs:label "real value r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recipe rdfs:label "recipe"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-recovered_laboriously rdfs:label "recovered laboriously"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reference_implementation rdfs:label "reference implementation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regjj_s rdfs:label "Reg(<jJ, s)"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-regression_of_jj_through_s rdfs:label "regression of <jJ through s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relative_performance rdfs:label "relative performance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-relative_success rdfs:label "relative success"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-relevance rdfs:label "relevance"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-representing_decision_diagrams rdfs:label "representing decision diagrams"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-research rdfs:label "research"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-resp rdfs:label "resp"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_and_value_functions rdfs:label "reward and value functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_formulae_iij rdfs:label "reward formulae IIJ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_history-independent rdfs:label "reward history-independent"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_scheme rdfs:label "reward scheme"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_specification rdfs:label "reward specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_specifications rdfs:label "reward specifications"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_specified_using_formulae rdfs:label "reward specified using formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_types_inducing_a_small_mop rdfs:label "reward types inducing a small MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_values rdfs:label "reward values"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-rewarded rdfs:label "rewarded"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewarded_from_the_moment__holds_onwards rdfs:label "rewarded from the moment ¢ holds onwards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewarded_now rdfs:label "rewarded now"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewarding_behaviors rdfs:label "Rewarding behaviors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewards_specified_as_long_sequences_of_events rdfs:label "rewards specified as long sequences of events"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-risk rdfs:label "risk"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rnn rdfs:label "RNN"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rrfi rdfs:label "rr(f(i))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rs rdfs:label "R(s)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rs_%CF%86 rdfs:label "r(s_Φ"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-run-times rdfs:label "run-times"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-run_time rdfs:label "run time"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-runtime rdfs:label "runtime"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_0%0Aprime rdfs:label """s_{0}^{
prime}"""@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_to_a rdfs:label "S* to A"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-search_control_knowledge rdfs:label "search control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_leading_to_that_estate rdfs:label "sequence leading to that estate"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence_s0 rdfs:label "sequence (s0)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_1ji0 rdfs:label "set 1Ji0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_actions rdfs:label "set of actions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_all_subformulae_in_sub_ rdfs:label "set of all subformulae in Sub( )"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_finite_sequences_of_states rdfs:label "set of finite sequences of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_fltl_formulae rdfs:label "set of $FLTL formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_pairs rdfs:label "set of pairs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_reward_formulae rdfs:label "set of reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_states rdfs:label "set of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_of_subformulae rdfs:label "set of subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_sub_ci_of_subformulae_of_the_reward_formulae rdfs:label "set Sub( ci>) of subformulae of the reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set_t_of_temporal_variables rdfs:label "set T of temporal variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sets_labelling_the_respective_e-states rdfs:label "sets labelling the respective e-states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-simple_mop rdfs:label "simple MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-single_system rdfs:label "single system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-situation rdfs:label "situation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-size_increase rdfs:label "size increase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-size_of_the_generated_mop rdfs:label "size of the generated MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-size_of_the_minimal_equivalent_mop rdfs:label "size of the minimal equivalent MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-slaney rdfs:label "Slaney"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-small_as_feasible rdfs:label "small as feasible"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-small_enough rdfs:label "small enough"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-small_equivalent_mdp rdfs:label "small equivalent MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-smallest_equivalent_mop_achievable_by_any_on-line_translation rdfs:label "smallest equivalent MOP achievable by any on-line translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-solution_method rdfs:label "solution method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-solving rdfs:label "solving"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-some rdfs:label "some"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-some_of_the_variables rdfs:label "some of the variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sophisticated_translation rdfs:label "sophisticated translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-space rdfs:label "space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sparse_matrix_operations rdfs:label "sparse matrix operations"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-specification_of_actions_initial_states_rewards_and_control-knowledge rdfs:label "specification of actions, initial states, rewards, and control-knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spud_d rdfs:label "SPUD D"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spudd-expon_states rdfs:label "SPUDD-EXPON states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spudd_algorithm rdfs:label "SPUDD algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-spudd_system rdfs:label "SPUDD system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-spudo rdfs:label "SPUDO"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-sse rdfs:label "SSE"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-st-aubin_a rdfs:label "St-Aubin, A."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-stage_i rdfs:label "stage i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stage_n rdfs:label "stage n"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-standard_fltl_semantics rdfs:label "standard FLTL semantics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-start_e-state rdfs:label "start e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-start_state rdfs:label "start state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_case rdfs:label "state-based case"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_lao rdfs:label "state-based LAO*"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-state-based_mdp_representations rdfs:label "state-based MDP representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_representation rdfs:label "state-based representation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_solution_methods rdfs:label "state-based solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_value_iteration rdfs:label "state-based value iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state-based_value_or_policy_iteration rdfs:label "state-based value or policy iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state_encountered rdfs:label "state encountered"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_of_index_i_in_r rdfs:label "state of index i in r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_of_the_nmrdp rdfs:label "state of the NMRDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_one_before_the_last rdfs:label "state one before the last"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_sequence_r rdfs:label "state sequence r"@en,
        "state sequence r'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_sequence_ri rdfs:label "state sequence r(i)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state_variables rdfs:label "state variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-statebased_methods rdfs:label "statebased methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-statebased_pltl_approaches rdfs:label "statebased PLTL approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-states_of_the_nmrdp rdfs:label "states of the NMRDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-static rdfs:label "static"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-static_analysis rdfs:label "static analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-steps rdfs:label "steps"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stochastic_planning_using_decision_diagrams rdfs:label "stochastic planning using decision diagrams"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structure_in_the_transition_model rdfs:label "structure in the transition model"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structure_of_the_reward_formulae rdfs:label "structure of the reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structured_algorithms rdfs:label "structured algorithms"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structured_method rdfs:label "structured method"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structured_methods rdfs:label "structured methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structured_mop rdfs:label "structured MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-study rdfs:label "study"@en ;
    askg-onto:entityType "Study"@en .

askg-data:Entity-subformula_set_i rdfs:label "subformula set i"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-subset_of_s rdfs:label "subset of S*"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-successor_s rdfs:label "successor s"@en,
        "successor s'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-successor_s_of_s rdfs:label "successor s' of s"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-successors_of_any_e-state rdfs:label "successors of any e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sum_of_expected_future_rewards rdfs:label "sum of expected future rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-supporting_libraries rdfs:label "supporting libraries"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sw rdfs:label "sw"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sylvie_thiebaux rdfs:label "Sylvie Thiebaux"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-symbolic_lao_search rdfs:label "Symbolic LAO* search"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-symbolic_techniques rdfs:label "symbolic techniques"@en ;
    askg-onto:entityType "Technique"@en .

askg-data:Entity-systematic rdfs:label "systematic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-table_i rdfs:label "Table I"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-target_mop rdfs:label "target MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-technology rdfs:label "technology"@en ;
    askg-onto:entityType "Technology"@en .

askg-data:Entity-temporal_logic rdfs:label "temporal logic"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_subformulae rdfs:label "temporal subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_subformulae_ptsub_ rdfs:label "temporal subformulae PTSub( )"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-text rdfs:label "text"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-that_direction rdfs:label "that direction"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_australian_national_university rdfs:label "The Australian National University"@en ;
    askg-onto:entityType "University"@en .

askg-data:Entity-the_desired_behaviour rdfs:label "the desired behaviour"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_discounted_cumulative_reward_over_an_infinite_horizon rdfs:label "the discounted cumulative reward over an infinite horizon"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_entire_equivalent_mdp rdfs:label "the entire equivalent MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_fastest rdfs:label "the fastest"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-the_first_step_towards_filling_this_gap rdfs:label "the first step towards filling this gap"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_first_two rdfs:label "The first two"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_generated_mdp rdfs:label "the generated MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_last_result rdfs:label "the last result"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-the_least_number_of_states rdfs:label "the least number of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_number_of_states rdfs:label "the number of states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_previous_state rdfs:label "the previous state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_result rdfs:label "the result"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-the_reward rdfs:label "the reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_reward_requires_tracking_a_long_sequence_of_events rdfs:label "the reward requires tracking a long sequence of events"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_state_of_the_art rdfs:label "the state of the art"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_sum_of_the_lengths_of_the_formulae rdfs:label "the sum of the lengths of the formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_trigger rdfs:label "the trigger"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-the_trigger_c_is_unreachable rdfs:label "the trigger c is unreachable"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-these rdfs:label "These"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-they rdfs:label "they"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-thiebaux_f rdfs:label "Thiebaux, F."@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-this_effect rdfs:label "this effect"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_structure rdfs:label "this structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-three_cited_papers rdfs:label "three cited papers"@en ;
    askg-onto:entityType "Article"@en .

askg-data:Entity-ti rdfs:label "T(i)'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-time_spent_in_solving_the_resulting_mop rdfs:label "time spent in solving the resulting MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-time_spent_in_the_translation rdfs:label "time spent in the translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tool rdfs:label "Tool"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transitions rdfs:label "transitions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-translation_algorithm rdfs:label "translation algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-translation_into_an_equivalent_mdp rdfs:label "translation into an equivalent MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-translationsolution_tradeoff rdfs:label "translation/solution tradeoff"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-tree rdfs:label "tree"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trends rdfs:label "trends"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trigger rdfs:label "trigger"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trigger_condition_c rdfs:label "trigger condition c"@en ;
    askg-onto:entityType "Condition"@en .

askg-data:Entity-triggering_condition rdfs:label "triggering condition"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_minimality rdfs:label "true minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_or_false rdfs:label "true or false"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true_with_probability_in__1 rdfs:label "true with probability i/(n + 1)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-truth_value_of_1_v_2 rdfs:label "truth value of ¢1 V ¢2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-turn-off_action rdfs:label "turn-off action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-turn-on rdfs:label "turn-on"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-turn-on-p rdfs:label "turn-on-p"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-turnoff rdfs:label "turnoff"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_cases rdfs:label "two cases"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-two_iterations_through_the_formula rdfs:label "two iterations through the formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-type rdfs:label "type"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-type_of_representations rdfs:label "type of representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-uai-02 rdfs:label "UAI-02"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-uai-99 rdfs:label "UAI-99"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-unreachable rdfs:label "unreachable"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-useful_discussions rdfs:label "useful discussions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-using_the_latter rdfs:label "using the latter"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-utility_functions rdfs:label "Utility functions"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-v%CF%80 rdfs:label "V(π)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-value_or_policy_iteration rdfs:label "value or policy iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-value_r rdfs:label "value r"@en ;
    askg-onto:entityType "Score"@en .

askg-data:Entity-valuer rdfs:label "valuer"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-variables rdfs:label "variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-variants rdfs:label "variants"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-various_approaches rdfs:label "various approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-various_factors rdfs:label "various factors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vi_rr rdfs:label "Vi R'(r;)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-vrr rdfs:label "V(rr)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-we rdfs:label "we"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-what_must_have_been_true_previously_for_jj_to_be_true_now rdfs:label "what must have been true previously for <jJ to be true now"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-year rdfs:label "Year"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-zilberstein rdfs:label "Zilberstein"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Paper-0ecbd8a3379fdc37-Section-1 a askg-onto:Section ;
    rdfs:label "Section 1"@en ;
    domo:Text "Implementation And Comparison Of Solution Methods For Decision Processes With Non-Markovian Rewards"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-11,
        askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-12 ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-11 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "``` Charles Grelton, David Price, and Sylvie Thiebaux Computer Sciences Laboratory The Australian National University Canberra, ACT, Australia {charlesg,davidp,thiebaux}®csl.anu.edu.au"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-11-Sentence-111 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-11-Sentence-111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "``` Charles Grelton, David Price, and Sylvie Thiebaux Computer Sciences Laboratory The Australian National University Canberra, ACT, Australia {charlesg,davidp,thiebaux}®csl.anu.edu.au"@en ;
    askg-onto:inSentence "``` Charles Grelton, David Price, and Sylvie Thiebaux Computer Sciences Laboratory The Australian National University Canberra, ACT, Australia {charlesg,davidp,thiebaux}®csl.anu.edu.au"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-charles_grelton,
        askg-data:Entity-computer_sciences_laboratory,
        askg-data:Entity-david_price,
        askg-data:Entity-researcher,
        askg-data:Entity-sylvie_thiebaux,
        askg-data:Entity-the_australian_national_university .

askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-12 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "```"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-12-Sentence-121 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-1-Paragraph-12-Sentence-121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "```"@en ;
    askg-onto:inSentence "```"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-concept,
        askg-data:Entity-dataset,
        askg-data:Entity-method,
        askg-data:Entity-triple .

askg-data:Paper-0ecbd8a3379fdc37-Section-10 a askg-onto:Section ;
    rdfs:label "Section 10"@en ;
    domo:Text "4.1 Preliminary Remarks"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102 ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Clearly, FLTL and PLTLSTR(A) have great potential for exploiting domain-specific heuristics and control-knowledge; PLTLMIN less so. To avoid obscuring the results, we therefore refrained from incorporating these features in the experiments. When running LAO*, the heuristic value of a state was the crudest possible (the sum of all reward values in the problem). Performance results should be interpreted in this light - they do not necessarily reflect the practical abilities of the methods that can exploit these features."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1011,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1012,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1013,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1014 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1011 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Clearly, FLTL and PLTLSTR(A) have great potential for exploiting domain-specific heuristics and control-knowledge; PLTLMIN less so."@en ;
    askg-onto:inSentence "Clearly, FLTL and PLTLSTR(A) have great potential for exploiting domain-specific heuristics and control-knowledge; PLTLMIN less so."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain-specific_heuristics,
        askg-data:Entity-fltl,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstra .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1012 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "To avoid obscuring the results, we therefore refrained from incorporating these features in the experiments."@en ;
    askg-onto:inSentence "To avoid obscuring the results, we therefore refrained from incorporating these features in the experiments."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-features .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1013 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "When running LAO*, the heuristic value of a state was the crudest possible (the sum of all reward values in the problem)."@en ;
    askg-onto:inSentence "When running LAO*, the heuristic value of a state was the crudest possible (the sum of all reward values in the problem)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-heuristic_value,
        askg-data:Entity-lao,
        askg-data:Entity-reward_values,
        askg-data:Entity-state .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-101-Sentence-1014 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Performance results should be interpreted in this light - they do not necessarily reflect the practical abilities of the methods that can exploit these features."@en ;
    askg-onto:inSentence "Performance results should be interpreted in this light - they do not necessarily reflect the practical abilities of the methods that can exploit these features."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-performance_results,
        askg-data:Entity-practical_abilities_of_the_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We begin with some general observations. One question raised above was whether the gain during the expansion phase is worth the expensive preprocessing performed by PLTLMIN, i.e. whether PLTLMIN typically outperforms PLTLSIM. We can definitively answer this question: up to pathological exceptions, preprocessing pays. We found that expansion was the bottleneck, and that post-hoc minimisation of the MDP produced by PLTLSIM did not help much. PLTLSIM is therefore of little or no practical interest, and we decided not to report results on its performance, as it is often an order of magnitude worse than that of PLTLMIN. Unsurprisingly, we also found that PLTLSTR would typically scale to larger state spaces, inevitably leading it to outperform state-based methods. However, this effect is not uniform: structured solution methods sometimes impose excessive memory requirements which makes them uncompetitive in certain cases, for example where en¢, for large n, features as a reward formula."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1021,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1022,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1023,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1024,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1025,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1026,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1027,
        askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1028 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1021 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We begin with some general observations."@en ;
    askg-onto:inSentence "We begin with some general observations."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-general_observations,
        askg-data:Entity-some .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1022 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "One question raised above was whether the gain during the expansion phase is worth the expensive preprocessing performed by PLTLMIN, i.e."@en ;
    askg-onto:inSentence "One question raised above was whether the gain during the expansion phase is worth the expensive preprocessing performed by PLTLMIN, i.e."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-preprocessing .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1023 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "whether PLTLMIN typically outperforms PLTLSIM."@en ;
    askg-onto:inSentence "whether PLTLMIN typically outperforms PLTLSIM."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-pltlsim .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1024 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We can definitively answer this question: up to pathological exceptions, preprocessing pays."@en ;
    askg-onto:inSentence "We can definitively answer this question: up to pathological exceptions, preprocessing pays."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-preprocessing,
        askg-data:Entity-question .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1025 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "We found that expansion was the bottleneck, and that post-hoc minimisation of the MDP produced by PLTLSIM did not help much."@en ;
    askg-onto:inSentence "We found that expansion was the bottleneck, and that post-hoc minimisation of the MDP produced by PLTLSIM did not help much."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expansion,
        askg-data:Entity-mdp,
        askg-data:Entity-pltlsim,
        askg-data:Entity-post-hoc_minimisation_of_the_mdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1026 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "PLTLSIM is therefore of little or no practical interest, and we decided not to report results on its performance, as it is often an order of magnitude worse than that of PLTLMIN."@en ;
    askg-onto:inSentence "PLTLSIM is therefore of little or no practical interest, and we decided not to report results on its performance, as it is often an order of magnitude worse than that of PLTLMIN."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-better_performance_than_pltlsim,
        askg-data:Entity-performance,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlsim .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1027 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Unsurprisingly, we also found that PLTLSTR would typically scale to larger state spaces, inevitably leading it to outperform state-based methods."@en ;
    askg-onto:inSentence "Unsurprisingly, we also found that PLTLSTR would typically scale to larger state spaces, inevitably leading it to outperform state-based methods."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-state-based_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-10-Paragraph-102-Sentence-1028 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "However, this effect is not uniform: structured solution methods sometimes impose excessive memory requirements which makes them uncompetitive in certain cases, for example where en¢, for large n, features as a reward formula."@en ;
    askg-onto:inSentence "However, this effect is not uniform: structured solution methods sometimes impose excessive memory requirements which makes them uncompetitive in certain cases, for example where en¢, for large n, features as a reward formula."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-en,
        askg-data:Entity-excessive_memory_requirements,
        askg-data:Entity-reward_formula,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-11 a askg-onto:Section ;
    rdfs:label "Section 11"@en ;
    domo:Text "4.2 D Omains"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-111,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113 ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-111 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Experiments were performed on four hand-coded domains (propositions + dynamics) and on random domains. Each hand-coded domain has n propositions Pi, and a dynamics which makes every state possible and eventually reachable from the initial state in which all propositions are false."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-111-Sentence-1111,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-111-Sentence-1112 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-111-Sentence-1111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Experiments were performed on four hand-coded domains (propositions + dynamics) and on random domains."@en ;
    askg-onto:inSentence "Experiments were performed on four hand-coded domains (propositions + dynamics) and on random domains."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-experiments,
        askg-data:Entity-four_hand-coded_domains,
        askg-data:Entity-random_domains .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-111-Sentence-1112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Each hand-coded domain has n propositions Pi, and a dynamics which makes every state possible and eventually reachable from the initial state in which all propositions are false."@en ;
    askg-onto:inSentence "Each hand-coded domain has n propositions Pi, and a dynamics which makes every state possible and eventually reachable from the initial state in which all propositions are false."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_propositions,
        askg-data:Entity-hand-coded_domain,
        askg-data:Entity-initial_state,
        askg-data:Entity-n_propositions_pi,
        askg-data:Entity-state .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The first two such domains, SPUDD-LINEAR and SPUDD- EXPON were discussed in [Hoey et al., 1999]; the two others are our own. The intention of SPUDD-LINEAR was to take advantage of the best case behaviour of SPUD D. For each proposition Pi, it has an action ai which sets Pi to true and all propositions Pi, 1 ::; j < i to false. SPUDD- EXPON, was used in [Hoey et al., 1999] to demonstrate the worst case behaviour of SPUDD. For each proposition Pi, it has an action ai which sets Pi to true only when all propositions Pi, 1 ::; j < i are true (and sets Pi to false otherwise), and sets the latter propositions to false. The third domain, called ON/OFF, has one \"turn-on\" and one \"turnoff'' action per proposition. The \"turn-on-p;\" action only probabilistically succeeds in setting Pi to true when Pi was false. The turn-off action is similar. The fourth domain, called COMPLETE, is a fully connected reflexive domain."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1121,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1122,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1123,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1124,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1125,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1126,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1127,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1128,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1129 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The first two such domains, SPUDD-LINEAR and SPUDD- EXPON were discussed in [Hoey et al., 1999]; the two others are our own."@en ;
    askg-onto:inSentence "The first two such domains, SPUDD-LINEAR and SPUDD- EXPON were discussed in [Hoey et al., 1999]; the two others are our own."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1999,
        askg-data:Entity-domain,
        askg-data:Entity-hoey_et_al,
        askg-data:Entity-spudd-expon,
        askg-data:Entity-spudd-linear .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1122 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The intention of SPUDD-LINEAR was to take advantage of the best case behaviour of SPUD D."@en ;
    askg-onto:inSentence "The intention of SPUDD-LINEAR was to take advantage of the best case behaviour of SPUD D."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-best_case_behaviour_of_spud_d,
        askg-data:Entity-spud_d,
        askg-data:Entity-spudd-linear .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1123 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For each proposition Pi, it has an action ai which sets Pi to true and all propositions Pi, 1 ::; j < i to false."@en ;
    askg-onto:inSentence "For each proposition Pi, it has an action ai which sets Pi to true and all propositions Pi, 1 ::; j < i to false."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_ai,
        askg-data:Entity-all_propositions_pi_1__j__i_to_false,
        askg-data:Entity-proposition_pi,
        askg-data:Entity-proposition_pi_to_true .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1124 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "SPUDD- EXPON, was used in [Hoey et al., 1999] to demonstrate the worst case behaviour of SPUDD."@en ;
    askg-onto:inSentence "SPUDD- EXPON, was used in [Hoey et al., 1999] to demonstrate the worst case behaviour of SPUDD."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hoey_et_al_1999,
        askg-data:Entity-spudd-expon .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1125 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For each proposition Pi, it has an action ai which sets Pi to true only when all propositions Pi, 1 ::; j < i are true (and sets Pi to false otherwise), and sets the latter propositions to false."@en ;
    askg-onto:inSentence "For each proposition Pi, it has an action ai which sets Pi to true only when all propositions Pi, 1 ::; j < i are true (and sets Pi to false otherwise), and sets the latter propositions to false."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_ai,
        askg-data:Entity-false,
        askg-data:Entity-pi_to_true,
        askg-data:Entity-proposition_pi,
        askg-data:Entity-propositions_pi_1__j__i,
        askg-data:Entity-true .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1126 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "The third domain, called ON/OFF, has one \"turn-on\" and one \"turnoff'' action per proposition."@en ;
    askg-onto:inSentence "The third domain, called ON/OFF, has one \"turn-on\" and one \"turnoff'' action per proposition."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain,
        askg-data:Entity-onoff,
        askg-data:Entity-turn-on,
        askg-data:Entity-turnoff .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1127 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "The \"turn-on-p;\" action only probabilistically succeeds in setting Pi to true when Pi was false."@en ;
    askg-onto:inSentence "The \"turn-on-p;\" action only probabilistically succeeds in setting Pi to true when Pi was false."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-false,
        askg-data:Entity-pi,
        askg-data:Entity-true,
        askg-data:Entity-turn-on-p .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1128 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "The turn-off action is similar."@en ;
    askg-onto:inSentence "The turn-off action is similar."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-turn-off_action .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-112-Sentence-1129 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "The fourth domain, called COMPLETE, is a fully connected reflexive domain."@en ;
    askg-onto:inSentence "The fourth domain, called COMPLETE, is a fully connected reflexive domain."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-complete,
        askg-data:Entity-fully_connected_reflexive_domain .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "For each proposition Pi there is an action ai which sets Pi to true with probability i/(n + 1) (and to false otherwise) and Pi, j \\# i to true or false with probability 0.5. Note that ai can cause a transition to any of the 2n states. Random domains of size n also involve n propositions. The method for generating their dynamics is out of the scope of this paper, but let us just mention that we are able to generate random dynamics exhibiting a given degree of \"structure\" and a given degree of uncertainty. Lack of structure essentially measures the bushiness of the internal part of the ADDs representing the actions, and uncertainty measures the bushiness of their leaves."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1131,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1132,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1133,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1134,
        askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1135 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For each proposition Pi there is an action ai which sets Pi to true with probability i/(n + 1) (and to false otherwise) and Pi, j \\# i to true or false with probability 0.5."@en ;
    askg-onto:inSentence "For each proposition Pi there is an action ai which sets Pi to true with probability i/(n + 1) (and to false otherwise) and Pi, j \\# i to true or false with probability 0.5."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-05,
        askg-data:Entity-action_ai,
        askg-data:Entity-pi,
        askg-data:Entity-pi_to_true,
        askg-data:Entity-pij,
        askg-data:Entity-probability,
        askg-data:Entity-proposition_pi,
        askg-data:Entity-true_or_false,
        askg-data:Entity-true_with_probability_in__1 .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Note that ai can cause a transition to any of the 2n states."@en ;
    askg-onto:inSentence "Note that ai can cause a transition to any of the 2n states."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2n_states,
        askg-data:Entity-ai .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1133 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Random domains of size n also involve n propositions."@en ;
    askg-onto:inSentence "Random domains of size n also involve n propositions."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n_propositions,
        askg-data:Entity-random_domains .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1134 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The method for generating their dynamics is out of the scope of this paper, but let us just mention that we are able to generate random dynamics exhibiting a given degree of \"structure\" and a given degree of uncertainty."@en ;
    askg-onto:inSentence "The method for generating their dynamics is out of the scope of this paper, but let us just mention that we are able to generate random dynamics exhibiting a given degree of \"structure\" and a given degree of uncertainty."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-structure,
        askg-data:Entity-uncertainty .

askg-data:Paper-0ecbd8a3379fdc37-Section-11-Paragraph-113-Sentence-1135 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Lack of structure essentially measures the bushiness of the internal part of the ADDs representing the actions, and uncertainty measures the bushiness of their leaves."@en ;
    askg-onto:inSentence "Lack of structure essentially measures the bushiness of the internal part of the ADDs representing the actions, and uncertainty measures the bushiness of their leaves."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bushiness_of_the_internal_part_of_the_adds,
        askg-data:Entity-bushiness_of_their_leaves,
        askg-data:Entity-lack_of_structure,
        askg-data:Entity-uncertainty .

askg-data:Paper-0ecbd8a3379fdc37-Section-12 a askg-onto:Section ;
    rdfs:label "Section 12"@en ;
    domo:Text "4.3 Influence Of Dynamics"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-121,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-124 ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-121 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The interaction between dynamics and reward certainly affects the performance of the different approaches, though not so strikingly as other factors such as the reward type (see below). We found that under the same reward scheme, varying the degree of structure or uncertainty did not generally change the relative success of the different approaches."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-121-Sentence-1211,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-121-Sentence-1212 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-121-Sentence-1211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The interaction between dynamics and reward certainly affects the performance of the different approaches, though not so strikingly as other factors such as the reward type (see below)."@en ;
    askg-onto:inSentence "The interaction between dynamics and reward certainly affects the performance of the different approaches, though not so strikingly as other factors such as the reward type (see below)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_approaches,
        askg-data:Entity-dynamics,
        askg-data:Entity-dynamics_and_reward,
        askg-data:Entity-performance,
        askg-data:Entity-reward,
        askg-data:Entity-reward_type .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-121-Sentence-1212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "We found that under the same reward scheme, varying the degree of structure or uncertainty did not generally change the relative success of the different approaches."@en ;
    askg-onto:inSentence "We found that under the same reward scheme, varying the degree of structure or uncertainty did not generally change the relative success of the different approaches."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-degree_of_structure_or_uncertainty,
        askg-data:Entity-different_approaches,
        askg-data:Entity-relative_success,
        askg-data:Entity-reward_scheme .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For instance, Figures I and 2 show the average run time of the methods as a function of the degree of structure, resp. degree of uncertainty, for random problems of size n = 6 and reward en.., e T (the state encountered at stage n is rewarded, regardless of its properties 7). Run-time increases slightly with both degrees, but there is no significant change in relative performance. These are typical of the graphs we obtain for other rewards."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1221,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1222,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1223,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1224 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1221 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For instance, Figures I and 2 show the average run time of the methods as a function of the degree of structure, resp."@en ;
    askg-onto:inSentence "For instance, Figures I and 2 show the average run time of the methods as a function of the degree of structure, resp."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-average_run_time,
        askg-data:Entity-degree_of_structure,
        askg-data:Entity-figures_i_and_2 .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1222 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "degree of uncertainty, for random problems of size n = 6 and reward en.., e T (the state encountered at stage n is rewarded, regardless of its properties 7)."@en ;
    askg-onto:inSentence "degree of uncertainty, for random problems of size n = 6 and reward en.., e T (the state encountered at stage n is rewarded, regardless of its properties 7)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-degree_of_uncertainty,
        askg-data:Entity-n__6,
        askg-data:Entity-random_problems,
        askg-data:Entity-reward,
        askg-data:Entity-stage_n,
        askg-data:Entity-state_encountered .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1223 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Run-time increases slightly with both degrees, but there is no significant change in relative performance."@en ;
    askg-onto:inSentence "Run-time increases slightly with both degrees, but there is no significant change in relative performance."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-relative_performance,
        askg-data:Entity-run-time .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-122-Sentence-1224 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "These are typical of the graphs we obtain for other rewards."@en ;
    askg-onto:inSentence "These are typical of the graphs we obtain for other rewards."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-graphs,
        askg-data:Entity-rewards .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Clearly, counterexamples to this observation exist. These are most notable in cases of extreme dynamics, for instance with the SPUDD-EXPON domain. Although for small values of n, such as n = 6, PLTLSTR approaches are faster than the others in handling the reward en.., e T for virtually any type of dynamics we encountered, they perform very poorly with that reward on SPUDD-EXPON. This is explained by the fact that only a small fraction of SPUDD- EXPON states are reachable in the first n steps. After n steps, FL TL immediately recognises that reward is of no consequence, because the formula has progressed to T."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1231,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1232,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1233,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1234,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1235 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1231 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Clearly, counterexamples to this observation exist."@en ;
    askg-onto:inSentence "Clearly, counterexamples to this observation exist."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-counterexamples,
        askg-data:Entity-observation .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1232 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "These are most notable in cases of extreme dynamics, for instance with the SPUDD-EXPON domain."@en ;
    askg-onto:inSentence "These are most notable in cases of extreme dynamics, for instance with the SPUDD-EXPON domain."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain,
        askg-data:Entity-spudd-expon .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1233 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Although for small values of n, such as n = 6, PLTLSTR approaches are faster than the others in handling the reward en.., e T for virtually any type of dynamics we encountered, they perform very poorly with that reward on SPUDD-EXPON."@en ;
    askg-onto:inSentence "Although for small values of n, such as n = 6, PLTLSTR approaches are faster than the others in handling the reward en.., e T for virtually any type of dynamics we encountered, they perform very poorly with that reward on SPUDD-EXPON."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-others,
        askg-data:Entity-pltlstr,
        askg-data:Entity-poorly_with_reward_on_spudd-expon,
        askg-data:Entity-reward,
        askg-data:Entity-spudd-expon .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1234 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This is explained by the fact that only a small fraction of SPUDD- EXPON states are reachable in the first n steps."@en ;
    askg-onto:inSentence "This is explained by the fact that only a small fraction of SPUDD- EXPON states are reachable in the first n steps."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-first_n_steps,
        askg-data:Entity-spudd-expon_states .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-123-Sentence-1235 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "After n steps, FL TL immediately recognises that reward is of no consequence, because the formula has progressed to T."@en ;
    askg-onto:inSentence "After n steps, FL TL immediately recognises that reward is of no consequence, because the formula has progressed to T."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-formula,
        askg-data:Entity-reward,
        askg-data:Entity-t .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-124 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "PLTLMIN discovers this fact only after expensive preprocessing. PLTLSTR, on the other hand, remains concerned by the prospect of reward, just as PLTLSIM would."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-124-Sentence-1241,
        askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-124-Sentence-1242 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-124-Sentence-1241 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "PLTLMIN discovers this fact only after expensive preprocessing."@en ;
    askg-onto:inSentence "PLTLMIN discovers this fact only after expensive preprocessing."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fact,
        askg-data:Entity-pltlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-12-Paragraph-124-Sentence-1242 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "PLTLSTR, on the other hand, remains concerned by the prospect of reward, just as PLTLSIM would."@en ;
    askg-onto:inSentence "PLTLSTR, on the other hand, remains concerned by the prospect of reward, just as PLTLSIM would."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstr,
        askg-data:Entity-reward .

askg-data:Paper-0ecbd8a3379fdc37-Section-13 a askg-onto:Section ;
    rdfs:label "Section 13"@en ;
    domo:Text "4.4 Influence Of Reward Types"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131 ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The type of reward appears to have a stronger influence on performance than dynamics. This is unsurprising, as the reward type significantly affects the size of the generated MOP: certain rewards only make the size of the minimal equivalent MOP increase by a constant number of states or a constant factor, while others make it increase by a factor exponential in the length of the formula. Table I illustrates this. The third column reports the size of the minimal equivalent MOP induced by the formulae on the left hand side.8 A legitimate question is whether there is a direct correlation between size increase and (in)appropriateness of the different methods. For instance, we might expect the statebased methods to do particularly well in conjunction with reward types inducing a small MOP and otherwise badly in comparison with structured methods. Interestingly, this is not always the case. For instance, in Table I whose last two columns report the fastest and slowest methods over the range of hand-coded domains where 1 ::; n ::; 12, the first row contradicts that expectation. Moreover, although PLTLSTR is fastest in the last row, for larger values of n (not represented in the table), it aborts through lack of memory, unlike the other methods. The most obvious observations arising out of these experiments is that PLTLSTR is nearly always the fastest-until it runs out of memory. P erhaps the most interesting results are those in the second row, which expose the inability of methods based on PLTL to deal with rewards specified as long sequences of events. In converting the reward formula to a set of subformulae, they lose information about the order of events, which then has to be recovered laboriously by reasoning. $FLTL progression in contrast takes the events one at a time, preserving the relevant structure at each step. Further experimentation led us to observe that all PLTL based algorithms perform poorly where reward is specified using formulae of the form ek¢, Vf=1 ei ¢,and i\\f=l e i ¢(¢ has been true k steps ago, within the last k steps, or at all the last k steps)."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1311,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13110,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13111,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13112,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13113,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1312,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1313,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1314,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1315,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1316,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1317,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1318,
        askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1319 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The type of reward appears to have a stronger influence on performance than dynamics."@en ;
    askg-onto:inSentence "The type of reward appears to have a stronger influence on performance than dynamics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-performance,
        askg-data:Entity-reward .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "P erhaps the most interesting results are those in the second row, which expose the inability of methods based on PLTL to deal with rewards specified as long sequences of events."@en ;
    askg-onto:inSentence "P erhaps the most interesting results are those in the second row, which expose the inability of methods based on PLTL to deal with rewards specified as long sequences of events."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods_based_on_pltl,
        askg-data:Entity-rewards_specified_as_long_sequences_of_events .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "In converting the reward formula to a set of subformulae, they lose information about the order of events, which then has to be recovered laboriously by reasoning."@en ;
    askg-onto:inSentence "In converting the reward formula to a set of subformulae, they lose information about the order of events, which then has to be recovered laboriously by reasoning."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-information,
        askg-data:Entity-order_of_events,
        askg-data:Entity-recovered_laboriously,
        askg-data:Entity-reward_formula,
        askg-data:Entity-set_of_subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "$FLTL progression in contrast takes the events one at a time, preserving the relevant structure at each step."@en ;
    askg-onto:inSentence "$FLTL progression in contrast takes the events one at a time, preserving the relevant structure at each step."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-events,
        askg-data:Entity-fltl_progression .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-13113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "Further experimentation led us to observe that all PLTL based algorithms perform poorly where reward is specified using formulae of the form ek¢, Vf=1 ei ¢,and i\\f=l e i ¢(¢ has been true k steps ago, within the last k steps, or at all the last k steps)."@en ;
    askg-onto:inSentence "Further experimentation led us to observe that all PLTL based algorithms perform poorly where reward is specified using formulae of the form ek¢, Vf=1 ei ¢,and i\\f=l e i ¢(¢ has been true k steps ago, within the last k steps, or at all the last k steps)."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_based_algorithms,
        askg-data:Entity-reward_specified_using_formulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This is unsurprising, as the reward type significantly affects the size of the generated MOP: certain rewards only make the size of the minimal equivalent MOP increase by a constant number of states or a constant factor, while others make it increase by a factor exponential in the length of the formula."@en ;
    askg-onto:inSentence "This is unsurprising, as the reward type significantly affects the size of the generated MOP: certain rewards only make the size of the minimal equivalent MOP increase by a constant number of states or a constant factor, while others make it increase by a factor exponential in the length of the formula."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-certain_rewards,
        askg-data:Entity-factor_exponential_in_the_length_of_the_formula,
        askg-data:Entity-others,
        askg-data:Entity-reward_type,
        askg-data:Entity-size_of_the_generated_mop,
        askg-data:Entity-size_of_the_minimal_equivalent_mop .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1313 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Table I illustrates this."@en ;
    askg-onto:inSentence "Table I illustrates this."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-this .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1314 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The third column reports the size of the minimal equivalent MOP induced by the formulae on the left hand side.8 A legitimate question is whether there is a direct correlation between size increase and (in)appropriateness of the different methods."@en ;
    askg-onto:inSentence "The third column reports the size of the minimal equivalent MOP induced by the formulae on the left hand side.8 A legitimate question is whether there is a direct correlation between size increase and (in)appropriateness of the different methods."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-inappropriateness_of_methods,
        askg-data:Entity-mop,
        askg-data:Entity-size_increase .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1315 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For instance, we might expect the statebased methods to do particularly well in conjunction with reward types inducing a small MOP and otherwise badly in comparison with structured methods."@en ;
    askg-onto:inSentence "For instance, we might expect the statebased methods to do particularly well in conjunction with reward types inducing a small MOP and otherwise badly in comparison with structured methods."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward_types_inducing_a_small_mop,
        askg-data:Entity-statebased_methods,
        askg-data:Entity-structured_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1316 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Interestingly, this is not always the case."@en ;
    askg-onto:inSentence "Interestingly, this is not always the case."^^xsd:string ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1317 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "For instance, in Table I whose last two columns report the fastest and slowest methods over the range of hand-coded domains where 1 ::; n ::; 12, the first row contradicts that expectation."@en ;
    askg-onto:inSentence "For instance, in Table I whose last two columns report the fastest and slowest methods over the range of hand-coded domains where 1 ::; n ::; 12, the first row contradicts that expectation."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1__n__12,
        askg-data:Entity-expectation,
        askg-data:Entity-fastest_and_slowest_methods,
        askg-data:Entity-first_row,
        askg-data:Entity-hand-coded_domains,
        askg-data:Entity-table_i .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1318 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Moreover, although PLTLSTR is fastest in the last row, for larger values of n (not represented in the table), it aborts through lack of memory, unlike the other methods."@en ;
    askg-onto:inSentence "Moreover, although PLTLSTR is fastest in the last row, for larger values of n (not represented in the table), it aborts through lack of memory, unlike the other methods."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-last_row,
        askg-data:Entity-pltlstr .

askg-data:Paper-0ecbd8a3379fdc37-Section-13-Paragraph-131-Sentence-1319 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "The most obvious observations arising out of these experiments is that PLTLSTR is nearly always the fastest-until it runs out of memory."@en ;
    askg-onto:inSentence "The most obvious observations arising out of these experiments is that PLTLSTR is nearly always the fastest-until it runs out of memory."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-the_fastest .

askg-data:Paper-0ecbd8a3379fdc37-Section-14 a askg-onto:Section ;
    rdfs:label "Section 14"@en ;
    domo:Text "4.5 Influence Of Syntax"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-141,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-142,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-143,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-144,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146 ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-141 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "Unsurprisingly, we find that the syntax used to express rewards, which affects the length of the formula, has a major influence on the run time. A typical example of this effect"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-141-Sentence-1411,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-141-Sentence-1412 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-141-Sentence-1411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Unsurprisingly, we find that the syntax used to express rewards, which affects the length of the formula, has a major influence on the run time."@en ;
    askg-onto:inSentence "Unsurprisingly, we find that the syntax used to express rewards, which affects the length of the formula, has a major influence on the run time."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-length_of_the_formula,
        askg-data:Entity-rewards,
        askg-data:Entity-run_time,
        askg-data:Entity-syntax .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-141-Sentence-1412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A typical example of this effect"@en ;
    askg-onto:inSentence "A typical example of this effect"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effect,
        askg-data:Entity-this_effect .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-142 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "8The figures are not necessarily valid for non-completely connected NMRDPs. Unfortunately, even for completely connected domains, there does not appear to be a much cheaper way to determine the MDP size than to generate it and count states."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-142-Sentence-1421,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-142-Sentence-1422 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-142-Sentence-1421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "8The figures are not necessarily valid for non-completely connected NMRDPs."@en ;
    askg-onto:inSentence "8The figures are not necessarily valid for non-completely connected NMRDPs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdps,
        askg-data:Entity-non-completely_connected .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-142-Sentence-1422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Unfortunately, even for completely connected domains, there does not appear to be a much cheaper way to determine the MDP size than to generate it and count states."@en ;
    askg-onto:inSentence "Unfortunately, even for completely connected domains, there does not appear to be a much cheaper way to determine the MDP size than to generate it and count states."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_size,
        askg-data:Entity-much_cheaper_way .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-143 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-143-Sentence-1431 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-143-Sentence-1431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "![6_image_0.png](6_image_0.png)"@en ;
    askg-onto:inSentence "![6_image_0.png](6_image_0.png)"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_intelligence,
        askg-data:Entity-deep_learning,
        askg-data:Entity-machine_learning,
        askg-data:Entity-neural_network,
        askg-data:Entity-rnn .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-144 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "| | Table 1· Influence of reward type on MOP size and method performance | | | | | | |------------------------------------------|------------------------------------------------------------------------|----------------|-------|------|------------------|----------------| | type | tormula | SIZe | | | fastest | slowest | | first time all PiS | (1\\i=IPi), !\\ (• 8 0 /\\i=l pi) | | l l l | l | PLTLSTR(A) | PLTLMIN | | Pis in sequence from start state | (Ai=l 8' pi)!\\ Gn• 8 T | g(� l | l� | l l | FLTL | PLTLSTR | | two consecutive PiS all Pis n times ago | v��,'(GPi !\\pi+,) Gn Af\\-t Pi | O(n:j//s/ 0(2n | | / l | PLTLSTR PLTLSTR | FLTL PLTLMIN |"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-144-Sentence-1441 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-144-Sentence-1441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "| | Table 1· Influence of reward type on MOP size and method performance | | | | | | |------------------------------------------|------------------------------------------------------------------------|----------------|-------|------|------------------|----------------| | type | tormula | SIZe | | | fastest | slowest | | first time all PiS | (1\\i=IPi), !\\ (• 8 0 /\\i=l pi) | | l l l | l | PLTLSTR(A) | PLTLMIN | | Pis in sequence from start state | (Ai=l 8' pi)!\\ Gn• 8 T | g(� l | l� | l l | FLTL | PLTLSTR | | two consecutive PiS all Pis n times ago | v��,'(GPi !\\pi+,) Gn Af\\-t Pi | O(n:j//s/ 0(2n | | / l | PLTLSTR PLTLSTR | FLTL PLTLMIN |"@en ;
    askg-onto:inSentence "| | Table 1· Influence of reward type on MOP size and method performance | | | | | | |------------------------------------------|------------------------------------------------------------------------|----------------|-------|------|------------------|----------------| | type | tormula | SIZe | | | fastest | slowest | | first time all PiS | (1\\i=IPi), !\\ (• 8 0 /\\i=l pi) | | l l l | l | PLTLSTR(A) | PLTLMIN | | Pis in sequence from start state | (Ai=l 8' pi)!\\ Gn• 8 T | g(� l | l� | l l | FLTL | PLTLSTR | | two consecutive PiS all Pis n times ago | v��,'(GPi !\\pi+,) Gn Af\\-t Pi | O(n:j//s/ 0(2n | | / l | PLTLSTR PLTLSTR | FLTL PLTLMIN |"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-method,
        askg-data:Entity-method_performance,
        askg-data:Entity-mop_size,
        askg-data:Entity-pis,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstra,
        askg-data:Entity-reward_type,
        askg-data:Entity-sequence .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "is captured in Figure 3. This graph demonstrates how reexpressing prvOut =: en(i\\�1Pi) as prvln =: /\\?=1 en Pi, thereby creating n times more temporal subformulae, alters the running time of all PLTL methods. FL TL is affected too as $FLTL progression requires two iterations through the formula. The graph represents the averages of the running times over all the methods, for the COMPLETE domain."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1451,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1452,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1453,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1454 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "is captured in Figure 3."@en ;
    askg-onto:inSentence "is captured in Figure 3."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figure_3 .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This graph demonstrates how reexpressing prvOut =: en(i\\�1Pi) as prvln =: /\\?=1 en Pi, thereby creating n times more temporal subformulae, alters the running time of all PLTL methods."@en ;
    askg-onto:inSentence "This graph demonstrates how reexpressing prvOut =: en(i\\�1Pi) as prvln =: /\\?=1 en Pi, thereby creating n times more temporal subformulae, alters the running time of all PLTL methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_methods,
        askg-data:Entity-prvln,
        askg-data:Entity-prvout,
        askg-data:Entity-temporal_subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1453 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "FL TL is affected too as $FLTL progression requires two iterations through the formula."@en ;
    askg-onto:inSentence "FL TL is affected too as $FLTL progression requires two iterations through the formula."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-fltl_progression,
        askg-data:Entity-two_iterations_through_the_formula .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-145-Sentence-1454 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The graph represents the averages of the running times over all the methods, for the COMPLETE domain."@en ;
    askg-onto:inSentence "The graph represents the averages of the running times over all the methods, for the COMPLETE domain."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-averages_of_the_running_times,
        askg-data:Entity-complete_domain,
        askg-data:Entity-graph,
        askg-data:Entity-methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Our most serious concern in relation to the PLTL approaches is their handling of reward specifications containing multiple reward elements. Most notably we found that PLTLMIN does not necessarily produce the minimal equivalent MOP in this situation. To demonstrate, we consider the set of reward formulae {2, ... , <Pn }, each associated with the same real value r. Given this, PLTL approaches will distinguish unnecessarily between past behaviours which lead to identical future rewards. This may occur when the reward at an e-state is determined by the truth value of ¢1 V ¢2. This formula does not necessarily require e-states that distinguish between the cases in which {¢1 = T,¢2 = _i} and {¢1 = _i,¢2 = T} hold; however, given the above specification, PLTLMIN shall make this distinction. For example, taking ¢; = Gpi, Figure 4 shows that FL TL leads to an MOP whose size is at most 3 times that of the NMROP. In contrast, the relative size of the MOP produced by PLTLMIN is linear in n, the number of rewards and propositions. These results are obtained with all hand-coded domains except SPUDD-EXPON. Figure 5 shows the run-times as a function of n for COM- PLETE. FL TL dominates and is only overtaken by PLTL- STR(A) for large values of n, when the MOP becomes too large for explicit exploration to be practical. To obtain the minimal equivalent MOP using PL TLMIN, a bloated reward specification of the form { 8 V?=1 (Pi A'J=1.i\\#i 'Pi) : r, ... , 8 /\\�1 Pi : n * r} is necessary, which, by virtue of its exponential length, is not an adequate solution."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1461,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14610,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14611,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14612,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14613,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14614,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1462,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1463,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1464,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1465,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1466,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1467,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1468,
        askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1469 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Our most serious concern in relation to the PLTL approaches is their handling of reward specifications containing multiple reward elements."@en ;
    askg-onto:inSentence "Our most serious concern in relation to the PLTL approaches is their handling of reward specifications containing multiple reward elements."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_approaches,
        askg-data:Entity-reward_specifications .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14610 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "These results are obtained with all hand-coded domains except SPUDD-EXPON."@en ;
    askg-onto:inSentence "These results are obtained with all hand-coded domains except SPUDD-EXPON."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hand-coded_domains,
        askg-data:Entity-spudd-expon .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14611 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Figure 5 shows the run-times as a function of n for COM- PLETE."@en ;
    askg-onto:inSentence "Figure 5 shows the run-times as a function of n for COM- PLETE."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-com-plete,
        askg-data:Entity-figure_5,
        askg-data:Entity-n,
        askg-data:Entity-run-times .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14612 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "FL TL dominates and is only overtaken by PLTL- STR(A) for large values of n, when the MOP becomes too large for explicit exploration to be practical."@en ;
    askg-onto:inSentence "FL TL dominates and is only overtaken by PLTL- STR(A) for large values of n, when the MOP becomes too large for explicit exploration to be practical."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-explicit_exploration,
        askg-data:Entity-fl_tl,
        askg-data:Entity-n,
        askg-data:Entity-pltl-_stra .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14613 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "To obtain the minimal equivalent MOP using PL TLMIN, a bloated reward specification of the form { 8 V?=1 (Pi A'J=1.i\\#i 'Pi) : r, ..."@en ;
    askg-onto:inSentence "To obtain the minimal equivalent MOP using PL TLMIN, a bloated reward specification of the form { 8 V?=1 (Pi A'J=1.i\\#i 'Pi) : r, ..."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mop,
        askg-data:Entity-pl_tlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-14614 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text ", 8 /\\�1 Pi : n * r} is necessary, which, by virtue of its exponential length, is not an adequate solution."@en ;
    askg-onto:inSentence ", 8 /\\�1 Pi : n * r} is necessary, which, by virtue of its exponential length, is not an adequate solution."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-n__r,
        askg-data:Entity-pi .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1462 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Most notably we found that PLTLMIN does not necessarily produce the minimal equivalent MOP in this situation."@en ;
    askg-onto:inSentence "Most notably we found that PLTLMIN does not necessarily produce the minimal equivalent MOP in this situation."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-minimal_equivalent_mop,
        askg-data:Entity-pltlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1463 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To demonstrate, we consider the set of reward formulae {2, ..."@en ;
    askg-onto:inSentence "To demonstrate, we consider the set of reward formulae {2, ..."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-reward_formulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1464 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text ", <Pn }, each associated with the same real value r."@en ;
    askg-onto:inSentence ", <Pn }, each associated with the same real value r."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pn,
        askg-data:Entity-real_value_r .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1465 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Given this, PLTL approaches will distinguish unnecessarily between past behaviours which lead to identical future rewards."@en ;
    askg-onto:inSentence "Given this, PLTL approaches will distinguish unnecessarily between past behaviours which lead to identical future rewards."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_rewards,
        askg-data:Entity-past_behaviours,
        askg-data:Entity-pltl_approaches .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1466 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This may occur when the reward at an e-state is determined by the truth value of ¢1 V ¢2."@en ;
    askg-onto:inSentence "This may occur when the reward at an e-state is determined by the truth value of ¢1 V ¢2."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-truth_value_of_1_v_2 .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1467 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "This formula does not necessarily require e-states that distinguish between the cases in which {¢1 = T,¢2 = _i} and {¢1 = _i,¢2 = T} hold; however, given the above specification, PLTLMIN shall make this distinction."@en ;
    askg-onto:inSentence "This formula does not necessarily require e-states that distinguish between the cases in which {¢1 = T,¢2 = _i} and {¢1 = _i,¢2 = T} hold; however, given the above specification, PLTLMIN shall make this distinction."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-pltlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1468 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "For example, taking ¢; = Gpi, Figure 4 shows that FL TL leads to an MOP whose size is at most 3 times that of the NMROP."@en ;
    askg-onto:inSentence "For example, taking ¢; = Gpi, Figure 4 shows that FL TL leads to an MOP whose size is at most 3 times that of the NMROP."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-3_times_that_of_the_nmrop,
        askg-data:Entity-fl_tl,
        askg-data:Entity-mop,
        askg-data:Entity-nmrop .

askg-data:Paper-0ecbd8a3379fdc37-Section-14-Paragraph-146-Sentence-1469 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "In contrast, the relative size of the MOP produced by PLTLMIN is linear in n, the number of rewards and propositions."@en ;
    askg-onto:inSentence "In contrast, the relative size of the MOP produced by PLTLMIN is linear in n, the number of rewards and propositions."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mop,
        askg-data:Entity-n,
        askg-data:Entity-number_of_rewards_and_propositions,
        askg-data:Entity-pltlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-15 a askg-onto:Section ;
    rdfs:label "Section 15"@en ;
    domo:Text "4.6 Influence Of Reachability"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-152,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155 ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "All approaches claim to have some ability to ignore variables which are irrelevant because the condition they track is unreachable: PLTLMIN detects them through preprocessing, PLTLSTR exploits the ability of structured solution methods to ignore them, and FL TL ignores them when progression never exposes them. However, given that the mechanisms for avoiding irrelevance are so different, we expect corresponding differences in their effects. On experimental investigation, we found that the differences in performance are best illustrated by looking at guard formulae, which assert that if a trigger condition c is reached then"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151-Sentence-1511,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151-Sentence-1512,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151-Sentence-1513 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151-Sentence-1511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "All approaches claim to have some ability to ignore variables which are irrelevant because the condition they track is unreachable: PLTLMIN detects them through preprocessing, PLTLSTR exploits the ability of structured solution methods to ignore them, and FL TL ignores them when progression never exposes them."@en ;
    askg-onto:inSentence "All approaches claim to have some ability to ignore variables which are irrelevant because the condition they track is unreachable: PLTLMIN detects them through preprocessing, PLTLSTR exploits the ability of structured solution methods to ignore them, and FL TL ignores them when progression never exposes them."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-irrelevant_variables,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151-Sentence-1512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, given that the mechanisms for avoiding irrelevance are so different, we expect corresponding differences in their effects."@en ;
    askg-onto:inSentence "However, given that the mechanisms for avoiding irrelevance are so different, we expect corresponding differences in their effects."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effects,
        askg-data:Entity-mechanisms .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-151-Sentence-1513 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "On experimental investigation, we found that the differences in performance are best illustrated by looking at guard formulae, which assert that if a trigger condition c is reached then"@en ;
    askg-onto:inSentence "On experimental investigation, we found that the differences in performance are best illustrated by looking at guard formulae, which assert that if a trigger condition c is reached then"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guard_formulae,
        askg-data:Entity-trigger_condition_c .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-152 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "####"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-152-Sentence-1521 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-152-Sentence-1521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "####"@en ;
    askg-onto:inSentence "####"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-triple .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "a reward will be received upon achievement of the goal g in, resp. within, k steps. In PLTL, this is written g 1\\ Gk c, resp. g 1\\ v7�1 Gi c, and in $FLTL, D(c _, ok(g _, $)), resp. D( c _, A7�1 Oi (g _, $))."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1531,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1532,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1533,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1534,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1535 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "a reward will be received upon achievement of the goal g in, resp."@en ;
    askg-onto:inSentence "a reward will be received upon achievement of the goal g in, resp."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal_g,
        askg-data:Entity-reward .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "within, k steps."@en ;
    askg-onto:inSentence "within, k steps."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-k_steps,
        askg-data:Entity-steps .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In PLTL, this is written g 1\\ Gk c, resp."@en ;
    askg-onto:inSentence "In PLTL, this is written g 1\\ Gk c, resp."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-g_1_gk_c,
        askg-data:Entity-pltl .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "g 1\\ v7�1 Gi c, and in $FLTL, D(c _, ok(g _, $)), resp."@en ;
    askg-onto:inSentence "g 1\\ v7�1 Gi c, and in $FLTL, D(c _, ok(g _, $)), resp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-g_1_v71_gi_c .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-153-Sentence-1535 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "D( c _, A7�1 Oi (g _, $))."@en ;
    askg-onto:inSentence "D( c _, A7�1 Oi (g _, $))."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a71_oi_g__,
        askg-data:Entity-d_c__ .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "W here the goal g is unreachable, PLTL approaches perform well. As it is always false, g does not lead to behavioural distinctions. On the other hand, while constructing the MDP, FL TL considers the successive progressions of ok g without being able to detect that it is unreachable until it actually fails to happen. This is exactly what the blindness of blind minimality amounts to. Figure 6 illustrates the difference in performance as a function of the number n of propositions involved in the SPUDD-LINEAR domain, when the reward is of the form gi\\Gnc, with g unreachable."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1541,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1542,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1543,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1544,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1545 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "W here the goal g is unreachable, PLTL approaches perform well."@en ;
    askg-onto:inSentence "W here the goal g is unreachable, PLTL approaches perform well."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal_g,
        askg-data:Entity-pltl_approaches .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1542 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As it is always false, g does not lead to behavioural distinctions."@en ;
    askg-onto:inSentence "As it is always false, g does not lead to behavioural distinctions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behavioural_distinctions,
        askg-data:Entity-g .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1543 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "On the other hand, while constructing the MDP, FL TL considers the successive progressions of ok g without being able to detect that it is unreachable until it actually fails to happen."@en ;
    askg-onto:inSentence "On the other hand, while constructing the MDP, FL TL considers the successive progressions of ok g without being able to detect that it is unreachable until it actually fails to happen."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-mdp,
        askg-data:Entity-ok_g .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1544 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This is exactly what the blindness of blind minimality amounts to."@en ;
    askg-onto:inSentence "This is exactly what the blindness of blind minimality amounts to."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-blindness .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-154-Sentence-1545 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Figure 6 illustrates the difference in performance as a function of the number n of propositions involved in the SPUDD-LINEAR domain, when the reward is of the form gi\\Gnc, with g unreachable."@en ;
    askg-onto:inSentence "Figure 6 illustrates the difference in performance as a function of the number n of propositions involved in the SPUDD-LINEAR domain, when the reward is of the form gi\\Gnc, with g unreachable."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-domain,
        askg-data:Entity-g,
        askg-data:Entity-gignc,
        askg-data:Entity-reward,
        askg-data:Entity-spudd-linear,
        askg-data:Entity-unreachable .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "FL TL shines when the trigger c is unreachable: the formula will always progress to itself, and the goal, however complicated, is never tracked in the generated MDP. In this situation PLTL approaches still consider e\"' c and its subformulae, only to discover, after expensive preprocessing for PLTLMIN, after reachability analysis for PLTLSTR(A), and never for PLTLSTR, that these are irrelevant. This is illustrated in Figure 7, again with SPUDD-LINEAR and a reward of the form g 1\\ Gnc, with c unreachable."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155-Sentence-1551,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155-Sentence-1552,
        askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155-Sentence-1553 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155-Sentence-1551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "FL TL shines when the trigger c is unreachable: the formula will always progress to itself, and the goal, however complicated, is never tracked in the generated MDP."@en ;
    askg-onto:inSentence "FL TL shines when the trigger c is unreachable: the formula will always progress to itself, and the goal, however complicated, is never tracked in the generated MDP."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-itself,
        askg-data:Entity-the_formula,
        askg-data:Entity-the_generated_mdp,
        askg-data:Entity-the_goal,
        askg-data:Entity-the_trigger_c_is_unreachable .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155-Sentence-1552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In this situation PLTL approaches still consider e\"' c and its subformulae, only to discover, after expensive preprocessing for PLTLMIN, after reachability analysis for PLTLSTR(A), and never for PLTLSTR, that these are irrelevant."@en ;
    askg-onto:inSentence "In this situation PLTL approaches still consider e\"' c and its subformulae, only to discover, after expensive preprocessing for PLTLMIN, after reachability analysis for PLTLSTR(A), and never for PLTLSTR, that these are irrelevant."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-e_c_and_its_subformulae,
        askg-data:Entity-expensive_preprocessing,
        askg-data:Entity-pltl_approaches,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstr,
        askg-data:Entity-pltlstra,
        askg-data:Entity-reachability_analysis .

askg-data:Paper-0ecbd8a3379fdc37-Section-15-Paragraph-155-Sentence-1553 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This is illustrated in Figure 7, again with SPUDD-LINEAR and a reward of the form g 1\\ Gnc, with c unreachable."@en ;
    askg-onto:inSentence "This is illustrated in Figure 7, again with SPUDD-LINEAR and a reward of the form g 1\\ Gnc, with c unreachable."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-spudd-linear,
        askg-data:Entity-tool .

askg-data:Paper-0ecbd8a3379fdc37-Section-16 a askg-onto:Section ;
    rdfs:label "Section 16"@en ;
    domo:Text "4.7 Dynamic Irrelevance"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163 ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "[Bacchus et a!., 1997; Thiebaux et a!., 2002] claim that one advantage of PLTLSTR and FLTL over PLTLMIN and PLTLSIM is that the former perform a dynamic analysis of rewards capable of detecting irrelevance of variables to particular policies, e.g. to the optimal policy. Our experiments confirm this claim. However, as for reachability, whether the goal or the triggering condition in a guard formula becomes irrelevant plays an important role in determining whether a PLTLSTR or FLTL approach should be taken: PLTLSTR is able to dynamically ignore the goal, while FL TL is able to dynamically ignore the trigger."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1611,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1612,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1613,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1614 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[Bacchus et a!., 1997; Thiebaux et a!., 2002] claim that one advantage of PLTLSTR and FLTL over PLTLMIN and PLTLSIM is that the former perform a dynamic analysis of rewards capable of detecting irrelevance of variables to particular policies, e.g."@en ;
    askg-onto:inSentence "[Bacchus et a!., 1997; Thiebaux et a!., 2002] claim that one advantage of PLTLSTR and FLTL over PLTLMIN and PLTLSIM is that the former perform a dynamic analysis of rewards capable of detecting irrelevance of variables to particular policies, e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_analysis_of_rewards,
        askg-data:Entity-fltl,
        askg-data:Entity-irrelevance_of_variables_to_particular_policies,
        askg-data:Entity-pltlmin,
        askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstr .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "to the optimal policy."@en ;
    askg-onto:inSentence "to the optimal policy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-optimal_policy .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Our experiments confirm this claim."@en ;
    askg-onto:inSentence "Our experiments confirm this claim."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-claim,
        askg-data:Entity-experiments .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-161-Sentence-1614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "However, as for reachability, whether the goal or the triggering condition in a guard formula becomes irrelevant plays an important role in determining whether a PLTLSTR or FLTL approach should be taken: PLTLSTR is able to dynamically ignore the goal, while FL TL is able to dynamically ignore the trigger."@en ;
    askg-onto:inSentence "However, as for reachability, whether the goal or the triggering condition in a guard formula becomes irrelevant plays an important role in determining whether a PLTLSTR or FLTL approach should be taken: PLTLSTR is able to dynamically ignore the goal, while FL TL is able to dynamically ignore the trigger."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-pltlstr,
        askg-data:Entity-the_goal,
        askg-data:Entity-the_trigger .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "This is illustrated in Figures 8 and 9. In both figures, the domain considered is ON/OFF with n = 6 propositions, the guard formula is g !\\ enc as before, here with both g and c achievable. This guard formula is assigned a fixed reward. To study the effect of dynamic irrelevance of the goal, in Figure 8, achievement of �g is rewarded by the valuer (i.e."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1621,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1622,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1623,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1624 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This is illustrated in Figures 8 and 9."@en ;
    askg-onto:inSentence "This is illustrated in Figures 8 and 9."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-figures_8_and_9,
        askg-data:Entity-this .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In both figures, the domain considered is ON/OFF with n = 6 propositions, the guard formula is g !\\ enc as before, here with both g and c achievable."@en ;
    askg-onto:inSentence "In both figures, the domain considered is ON/OFF with n = 6 propositions, the guard formula is g !\\ enc as before, here with both g and c achievable."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-g,
        askg-data:Entity-g__enc,
        askg-data:Entity-guard_formula,
        askg-data:Entity-n__6_propositions,
        askg-data:Entity-onoff .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This guard formula is assigned a fixed reward."@en ;
    askg-onto:inSentence "This guard formula is assigned a fixed reward."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fixed_reward,
        askg-data:Entity-guard_formula .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-162-Sentence-1624 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "To study the effect of dynamic irrelevance of the goal, in Figure 8, achievement of �g is rewarded by the valuer (i.e."@en ;
    askg-onto:inSentence "To study the effect of dynamic irrelevance of the goal, in Figure 8, achievement of �g is rewarded by the valuer (i.e."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievement,
        askg-data:Entity-valuer .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "we have �g : r in PLTL). In Figure 9, on the other hand, we study the effect of dynamic irrelevance of the trigger and achievement of �c is rewarded by the value r. Both figures show the runtime of the methods as r increases. Achieving the goal, resp. the trigger, is made less attractive as r increases up to the point where the guard formula becomes irrelevant under the optimal policy. When this happens, the run-time of PLTLSTR resp. FL TL, exhibits an abrupt but durable improvement. The figures show that FL TL is able to pick up irrelevance of the trigger, while PLTLSTR is able to exploit irrelevance of the goal. As expected, PLTLMIN whose analysis is static does not pick up either and performs consistently badly."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1631,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1632,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1633,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1634,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1635,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1636,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1637,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1638,
        askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1639 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "we have �g : r in PLTL)."@en ;
    askg-onto:inSentence "we have �g : r in PLTL)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl,
        askg-data:Entity-r .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1632 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In Figure 9, on the other hand, we study the effect of dynamic irrelevance of the trigger and achievement of �c is rewarded by the value r."@en ;
    askg-onto:inSentence "In Figure 9, on the other hand, we study the effect of dynamic irrelevance of the trigger and achievement of �c is rewarded by the value r."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-achievement_of_c,
        askg-data:Entity-dynamic_irrelevance,
        askg-data:Entity-value_r .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1633 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Both figures show the runtime of the methods as r increases."@en ;
    askg-onto:inSentence "Both figures show the runtime of the methods as r increases."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-runtime .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1634 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Achieving the goal, resp."@en ;
    askg-onto:inSentence "Achieving the goal, resp."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal,
        askg-data:Entity-resp .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1635 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "the trigger, is made less attractive as r increases up to the point where the guard formula becomes irrelevant under the optimal policy."@en ;
    askg-onto:inSentence "the trigger, is made less attractive as r increases up to the point where the guard formula becomes irrelevant under the optimal policy."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-guard_formula,
        askg-data:Entity-optimal_policy,
        askg-data:Entity-r_increases,
        askg-data:Entity-trigger .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1636 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "When this happens, the run-time of PLTLSTR resp."@en ;
    askg-onto:inSentence "When this happens, the run-time of PLTLSTR resp."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlstr,
        askg-data:Entity-run-time .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1637 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "FL TL, exhibits an abrupt but durable improvement."@en ;
    askg-onto:inSentence "FL TL, exhibits an abrupt but durable improvement."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-improvement .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1638 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "The figures show that FL TL is able to pick up irrelevance of the trigger, while PLTLSTR is able to exploit irrelevance of the goal."@en ;
    askg-onto:inSentence "The figures show that FL TL is able to pick up irrelevance of the trigger, while PLTLSTR is able to exploit irrelevance of the goal."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-irrelevance_of_the_goal,
        askg-data:Entity-irrelevance_of_the_trigger,
        askg-data:Entity-pltlstr .

askg-data:Paper-0ecbd8a3379fdc37-Section-16-Paragraph-163-Sentence-1639 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "As expected, PLTLMIN whose analysis is static does not pick up either and performs consistently badly."@en ;
    askg-onto:inSentence "As expected, PLTLMIN whose analysis is static does not pick up either and performs consistently badly."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-static .

askg-data:Paper-0ecbd8a3379fdc37-Section-17 a askg-onto:Section ;
    rdfs:label "Section 17"@en ;
    domo:Text "5 Conclusion A Nd Future Work"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-173 ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "NMRDPP proved a useful tool in the experimental analysis of approaches for decision processes with Non-Markovian rewards. Both the system and the analysis are the first of their kind. We were able to identify a number of general trends in the behaviours of the methods and to provide advice concerning which are best suited to certain circumstances. We found PLTLSTR and FL TL preferable to statebased PLTL approaches in most cases. If one insists on using the latter, we strongly recommend preprocessing. In all cases, attention should be paid to the syntax of the reward formulae and in particular to minimising its length. FL TL is the technique of choice when the reward requires tracking a long sequence of events or when the desired behaviour is composed of many elements with identical rewards. For guard formulae, we advise the use ofPLTLSTR if the probability of reaching the goal is low or achieving it is very risky, and conversely, of FL TL if the probability of reaching the triggering condition is low or if reaching it is very risky."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1711,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1712,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1713,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1714,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1715,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1716,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1717,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1718 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "NMRDPP proved a useful tool in the experimental analysis of approaches for decision processes with Non-Markovian rewards."@en ;
    askg-onto:inSentence "NMRDPP proved a useful tool in the experimental analysis of approaches for decision processes with Non-Markovian rewards."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_processes_with_non-markovian_rewards,
        askg-data:Entity-nmrdpp .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Both the system and the analysis are the first of their kind."@en ;
    askg-onto:inSentence "Both the system and the analysis are the first of their kind."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-first_of_their_kind,
        askg-data:Entity-system .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We were able to identify a number of general trends in the behaviours of the methods and to provide advice concerning which are best suited to certain circumstances."@en ;
    askg-onto:inSentence "We were able to identify a number of general trends in the behaviours of the methods and to provide advice concerning which are best suited to certain circumstances."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-trends .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We found PLTLSTR and FL TL preferable to statebased PLTL approaches in most cases."@en ;
    askg-onto:inSentence "We found PLTLSTR and FL TL preferable to statebased PLTL approaches in most cases."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-pltlstr,
        askg-data:Entity-statebased_pltl_approaches .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "If one insists on using the latter, we strongly recommend preprocessing."@en ;
    askg-onto:inSentence "If one insists on using the latter, we strongly recommend preprocessing."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-preprocessing,
        askg-data:Entity-using_the_latter .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1716 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In all cases, attention should be paid to the syntax of the reward formulae and in particular to minimising its length."@en ;
    askg-onto:inSentence "In all cases, attention should be paid to the syntax of the reward formulae and in particular to minimising its length."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-length,
        askg-data:Entity-reward_formulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1717 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "FL TL is the technique of choice when the reward requires tracking a long sequence of events or when the desired behaviour is composed of many elements with identical rewards."@en ;
    askg-onto:inSentence "FL TL is the technique of choice when the reward requires tracking a long sequence of events or when the desired behaviour is composed of many elements with identical rewards."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_long_sequence_of_events,
        askg-data:Entity-fl_tl,
        askg-data:Entity-many_elements_with_identical_rewards,
        askg-data:Entity-the_desired_behaviour,
        askg-data:Entity-the_reward,
        askg-data:Entity-the_reward_requires_tracking_a_long_sequence_of_events .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-171-Sentence-1718 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "For guard formulae, we advise the use ofPLTLSTR if the probability of reaching the goal is low or achieving it is very risky, and conversely, of FL TL if the probability of reaching the triggering condition is low or if reaching it is very risky."@en ;
    askg-onto:inSentence "For guard formulae, we advise the use ofPLTLSTR if the probability of reaching the goal is low or achieving it is very risky, and conversely, of FL TL if the probability of reaching the triggering condition is low or if reaching it is very risky."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-guard_formulae,
        askg-data:Entity-pltlstr,
        askg-data:Entity-triggering_condition .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "For obvious reasons, this first report has focused on artificial domains. It remains to be seen what form these results take in the context of domains of more practical interest. Another topic for future work is to exploit our findings to design improved NMRDP solution methods."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172-Sentence-1721,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172-Sentence-1722,
        askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172-Sentence-1723 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172-Sentence-1721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For obvious reasons, this first report has focused on artificial domains."@en ;
    askg-onto:inSentence "For obvious reasons, this first report has focused on artificial domains."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-artificial_domains,
        askg-data:Entity-first_report .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172-Sentence-1722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "It remains to be seen what form these results take in the context of domains of more practical interest."@en ;
    askg-onto:inSentence "It remains to be seen what form these results take in the context of domains of more practical interest."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-context_of_domains_of_more_practical_interest,
        askg-data:Entity-results .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-172-Sentence-1723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Another topic for future work is to exploit our findings to design improved NMRDP solution methods."@en ;
    askg-onto:inSentence "Another topic for future work is to exploit our findings to design improved NMRDP solution methods."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-findings,
        askg-data:Entity-nmrdp_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-173 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Acknowledgements Thanks to John Slaney for useful discussions."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-173-Sentence-1731 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-17-Paragraph-173-Sentence-1731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Acknowledgements Thanks to John Slaney for useful discussions."@en ;
    askg-onto:inSentence "Acknowledgements Thanks to John Slaney for useful discussions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-john_slaney,
        askg-data:Entity-useful_discussions .

askg-data:Paper-0ecbd8a3379fdc37-Section-18 a askg-onto:Section ;
    rdfs:label "Section 18"@en ;
    domo:Text "References"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-182 ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "``` [Bacchus et al., 1996] F. Bacchus, C. Boutilier, and A. Grove. Rewarding behaviors. In Proc. MAI-96, pages 1160-1167, 1996. [Bacchus et al., 1997] F. Bacchus, C. Boutilier, and A. Grove. Structured solution methods for non-markovian decision processes. InProc.AAAI-97, pages 112-117,1997. [Bacchus and Kabanza, 2000] F. Bacchus and F. Kabanza. Us- ing temporal logic to express search control knowledge for planning. Artificial Intelligence, 116(1-2), 2000. [Bonet and Geffner, 2003] B. Bonet and H. Geffner. Labeled RTDP: Improving the convergence of real-time dynamic programming. In Proc. ICAPS-03, 2003. [Boutilier et al., 1995] C. Boutilier, R. Dearden, and M. Gold- szmidt. Exploiting structure in policy construction. In Proc. IJCAI-95, pages 1104-1 Ill, 1995. [Feng and Hansen, 2002] Z. Feng and E. Hansen. Symbolic LAO* search for factored markov decision processes. In Proc. AAAI-02, 2002. [Haddawy and Hanks, 1992] P. Haddawy and S. Hanks. Repre- sentations for decision-theoretic planning: Utility functions and deadline goals. In Proc. KR-92, pages 71-82, 1992. [Hansen and Zilberstein, 2001] E. Hansen and S. Zilberstein. LAO*: A heuristic search algorithm that finds solutions with loops. Artificial Intelligence, 129:35-62,2001. [Hoey et al., 1999] J. Hoey, R. St-Aubin, A. Hu, and C. Boutilier. SPUDD: stochastic planning using decision diagrams. In Proc. UAI-99, 1999. SPUDD is available from http://www.cs.ubc.ca/spider/staubin/Spudd/. [Howard, 1960] R.A. Howard. Dynamic Programming and Markov Processes. MIT P ress, Cambridge, MA, 1960. [Thiebaux et al., 2002] S. Thiebaux, F. Kabanza, and J. Slaney. Anytime state-based solution methods for decision pro· cesses with non-markovian rewards. In Proc. UAI-02, pages 501-510,2002."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1811,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18110,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18111,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18112,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18113,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18114,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18115,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18116,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18117,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18118,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18119,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1812,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18120,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18121,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18122,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18123,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18124,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18125,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18126,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18127,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18128,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18129,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1813,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18130,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18131,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18132,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18133,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18134,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18135,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18136,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18137,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18138,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18139,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1814,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18140,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18141,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18142,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18143,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18144,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18145,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18146,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18147,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18148,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18149,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1815,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18150,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18151,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18152,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18153,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18154,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18155,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18156,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18157,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18158,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18159,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1816,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18160,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18161,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18162,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18163,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18164,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18165,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18166,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18167,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18168,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1817,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1818,
        askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1819 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "``` [Bacchus et al., 1996] F."@en ;
    askg-onto:inSentence "``` [Bacchus et al., 1996] F."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996,
        askg-data:Entity-bacchus_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18110 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "Boutilier, and A."@en ;
    askg-onto:inSentence "Boutilier, and A."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-author,
        askg-data:Entity-boutilier .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18111 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "Grove."@en ;
    askg-onto:inSentence "Grove."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-grove,
        askg-data:Entity-platform .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18112 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "Structured solution methods for non-markovian decision processes."@en ;
    askg-onto:inSentence "Structured solution methods for non-markovian decision processes."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-markovian_decision_processes,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18113 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "InProc.AAAI-97, pages 112-117,1997."@en ;
    askg-onto:inSentence "InProc.AAAI-97, pages 112-117,1997."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1997,
        askg-data:Entity-inprocaaai-97,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18114 a askg-onto:Sentence ;
    rdfs:label "Sentence 14"@en ;
    domo:Text "[Bacchus and Kabanza, 2000] F."@en ;
    askg-onto:inSentence "[Bacchus and Kabanza, 2000] F."^^xsd:string ;
    askg-onto:index "14"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2000,
        askg-data:Entity-bacchus,
        askg-data:Entity-bacchus_and_kabanza,
        askg-data:Entity-kabanza .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18115 a askg-onto:Sentence ;
    rdfs:label "Sentence 15"@en ;
    domo:Text "Bacchus and F."@en ;
    askg-onto:inSentence "Bacchus and F."^^xsd:string ;
    askg-onto:index "15"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus,
        askg-data:Entity-f .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18116 a askg-onto:Sentence ;
    rdfs:label "Sentence 16"@en ;
    domo:Text "Kabanza."@en ;
    askg-onto:inSentence "Kabanza."^^xsd:string ;
    askg-onto:index "16"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kabanza,
        askg-data:Entity-platform .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18117 a askg-onto:Sentence ;
    rdfs:label "Sentence 17"@en ;
    domo:Text "Us- ing temporal logic to express search control knowledge for planning."@en ;
    askg-onto:inSentence "Us- ing temporal logic to express search control knowledge for planning."^^xsd:string ;
    askg-onto:index "17"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-planning,
        askg-data:Entity-search_control_knowledge,
        askg-data:Entity-temporal_logic .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18118 a askg-onto:Sentence ;
    rdfs:label "Sentence 18"@en ;
    domo:Text "Artificial Intelligence, 116(1-2), 2000."@en ;
    askg-onto:inSentence "Artificial Intelligence, 116(1-2), 2000."^^xsd:string ;
    askg-onto:index "18"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-artificial_intelligence .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18119 a askg-onto:Sentence ;
    rdfs:label "Sentence 19"@en ;
    domo:Text "[Bonet and Geffner, 2003] B."@en ;
    askg-onto:inSentence "[Bonet and Geffner, 2003] B."^^xsd:string ;
    askg-onto:index "19"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2003,
        askg-data:Entity-bonet_and_geffner .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Bacchus, C."@en ;
    askg-onto:inSentence "Bacchus, C."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_c .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18120 a askg-onto:Sentence ;
    rdfs:label "Sentence 20"@en ;
    domo:Text "Bonet and H."@en ;
    askg-onto:inSentence "Bonet and H."^^xsd:string ;
    askg-onto:index "20"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bonet,
        askg-data:Entity-h .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18121 a askg-onto:Sentence ;
    rdfs:label "Sentence 21"@en ;
    domo:Text "Geffner."@en ;
    askg-onto:inSentence "Geffner."^^xsd:string ;
    askg-onto:index "21"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-geffner,
        askg-data:Entity-researcher .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18122 a askg-onto:Sentence ;
    rdfs:label "Sentence 22"@en ;
    domo:Text "Labeled RTDP: Improving the convergence of real-time dynamic programming."@en ;
    askg-onto:inSentence "Labeled RTDP: Improving the convergence of real-time dynamic programming."^^xsd:string ;
    askg-onto:index "22"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-labeled_rtdp,
        askg-data:Entity-real-time_dynamic_programming .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18123 a askg-onto:Sentence ;
    rdfs:label "Sentence 23"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "23"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18124 a askg-onto:Sentence ;
    rdfs:label "Sentence 24"@en ;
    domo:Text "ICAPS-03, 2003."@en ;
    askg-onto:inSentence "ICAPS-03, 2003."^^xsd:string ;
    askg-onto:index "24"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-icaps-03,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18125 a askg-onto:Sentence ;
    rdfs:label "Sentence 25"@en ;
    domo:Text "[Boutilier et al., 1995] C."@en ;
    askg-onto:inSentence "[Boutilier et al., 1995] C."^^xsd:string ;
    askg-onto:index "25"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1995,
        askg-data:Entity-boutilier_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18126 a askg-onto:Sentence ;
    rdfs:label "Sentence 26"@en ;
    domo:Text "Boutilier, R."@en ;
    askg-onto:inSentence "Boutilier, R."^^xsd:string ;
    askg-onto:index "26"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-boutilier_r .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18127 a askg-onto:Sentence ;
    rdfs:label "Sentence 27"@en ;
    domo:Text "Dearden, and M."@en ;
    askg-onto:inSentence "Dearden, and M."^^xsd:string ;
    askg-onto:index "27"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-dearden .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18128 a askg-onto:Sentence ;
    rdfs:label "Sentence 28"@en ;
    domo:Text "Gold- szmidt."@en ;
    askg-onto:inSentence "Gold- szmidt."^^xsd:string ;
    askg-onto:index "28"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gold-_szmidt .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18129 a askg-onto:Sentence ;
    rdfs:label "Sentence 29"@en ;
    domo:Text "Exploiting structure in policy construction."@en ;
    askg-onto:inSentence "Exploiting structure in policy construction."^^xsd:string ;
    askg-onto:index "29"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-policy_construction,
        askg-data:Entity-structure .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1813 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Boutilier, and A."@en ;
    askg-onto:inSentence "Boutilier, and A."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-author,
        askg-data:Entity-boutilier .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18130 a askg-onto:Sentence ;
    rdfs:label "Sentence 30"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "30"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18131 a askg-onto:Sentence ;
    rdfs:label "Sentence 31"@en ;
    domo:Text "IJCAI-95, pages 1104-1 Ill, 1995."@en ;
    askg-onto:inSentence "IJCAI-95, pages 1104-1 Ill, 1995."^^xsd:string ;
    askg-onto:index "31"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1995,
        askg-data:Entity-ijcai-95,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18132 a askg-onto:Sentence ;
    rdfs:label "Sentence 32"@en ;
    domo:Text "[Feng and Hansen, 2002] Z."@en ;
    askg-onto:inSentence "[Feng and Hansen, 2002] Z."^^xsd:string ;
    askg-onto:index "32"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feng,
        askg-data:Entity-feng_2002,
        askg-data:Entity-hansen,
        askg-data:Entity-hansen_2002 .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18133 a askg-onto:Sentence ;
    rdfs:label "Sentence 33"@en ;
    domo:Text "Feng and E."@en ;
    askg-onto:inSentence "Feng and E."^^xsd:string ;
    askg-onto:index "33"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-e,
        askg-data:Entity-feng .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18134 a askg-onto:Sentence ;
    rdfs:label "Sentence 34"@en ;
    domo:Text "Hansen."@en ;
    askg-onto:inSentence "Hansen."^^xsd:string ;
    askg-onto:index "34"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hansen,
        askg-data:Entity-person .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18135 a askg-onto:Sentence ;
    rdfs:label "Sentence 35"@en ;
    domo:Text "Symbolic LAO* search for factored markov decision processes."@en ;
    askg-onto:inSentence "Symbolic LAO* search for factored markov decision processes."^^xsd:string ;
    askg-onto:index "35"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-concept,
        askg-data:Entity-factored_markov_decision_processes,
        askg-data:Entity-symbolic_lao_search .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18136 a askg-onto:Sentence ;
    rdfs:label "Sentence 36"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "36"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18137 a askg-onto:Sentence ;
    rdfs:label "Sentence 37"@en ;
    domo:Text "AAAI-02, 2002."@en ;
    askg-onto:inSentence "AAAI-02, 2002."^^xsd:string ;
    askg-onto:index "37"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002,
        askg-data:Entity-aaai-02,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18138 a askg-onto:Sentence ;
    rdfs:label "Sentence 38"@en ;
    domo:Text "[Haddawy and Hanks, 1992] P."@en ;
    askg-onto:inSentence "[Haddawy and Hanks, 1992] P."^^xsd:string ;
    askg-onto:index "38"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1992,
        askg-data:Entity-haddawy_and_hanks .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18139 a askg-onto:Sentence ;
    rdfs:label "Sentence 39"@en ;
    domo:Text "Haddawy and S."@en ;
    askg-onto:inSentence "Haddawy and S."^^xsd:string ;
    askg-onto:index "39"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-haddawy,
        askg-data:Entity-s .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1814 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Grove."@en ;
    askg-onto:inSentence "Grove."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-grove .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18140 a askg-onto:Sentence ;
    rdfs:label "Sentence 40"@en ;
    domo:Text "Hanks."@en ;
    askg-onto:inSentence "Hanks."^^xsd:string ;
    askg-onto:index "40"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hanks,
        askg-data:Entity-person .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18141 a askg-onto:Sentence ;
    rdfs:label "Sentence 41"@en ;
    domo:Text "Repre- sentations for decision-theoretic planning: Utility functions and deadline goals."@en ;
    askg-onto:inSentence "Repre- sentations for decision-theoretic planning: Utility functions and deadline goals."^^xsd:string ;
    askg-onto:index "41"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-deadline_goals,
        askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-utility_functions .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18142 a askg-onto:Sentence ;
    rdfs:label "Sentence 42"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "42"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18143 a askg-onto:Sentence ;
    rdfs:label "Sentence 43"@en ;
    domo:Text "KR-92, pages 71-82, 1992."@en ;
    askg-onto:inSentence "KR-92, pages 71-82, 1992."^^xsd:string ;
    askg-onto:index "43"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-kr-92,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18144 a askg-onto:Sentence ;
    rdfs:label "Sentence 44"@en ;
    domo:Text "[Hansen and Zilberstein, 2001] E."@en ;
    askg-onto:inSentence "[Hansen and Zilberstein, 2001] E."^^xsd:string ;
    askg-onto:index "44"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2001,
        askg-data:Entity-hansen_and_zilberstein .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18145 a askg-onto:Sentence ;
    rdfs:label "Sentence 45"@en ;
    domo:Text "Hansen and S."@en ;
    askg-onto:inSentence "Hansen and S."^^xsd:string ;
    askg-onto:index "45"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-hansen,
        askg-data:Entity-s .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18146 a askg-onto:Sentence ;
    rdfs:label "Sentence 46"@en ;
    domo:Text "Zilberstein."@en ;
    askg-onto:inSentence "Zilberstein."^^xsd:string ;
    askg-onto:index "46"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-zilberstein .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18147 a askg-onto:Sentence ;
    rdfs:label "Sentence 47"@en ;
    domo:Text "LAO*: A heuristic search algorithm that finds solutions with loops."@en ;
    askg-onto:inSentence "LAO*: A heuristic search algorithm that finds solutions with loops."^^xsd:string ;
    askg-onto:index "47"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-heuristic_search_algorithm,
        askg-data:Entity-lao .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18148 a askg-onto:Sentence ;
    rdfs:label "Sentence 48"@en ;
    domo:Text "Artificial Intelligence, 129:35-62,2001."@en ;
    askg-onto:inSentence "Artificial Intelligence, 129:35-62,2001."^^xsd:string ;
    askg-onto:index "48"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-12935-622001,
        askg-data:Entity-artificial_intelligence .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18149 a askg-onto:Sentence ;
    rdfs:label "Sentence 49"@en ;
    domo:Text "[Hoey et al., 1999] J."@en ;
    askg-onto:inSentence "[Hoey et al., 1999] J."^^xsd:string ;
    askg-onto:index "49"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hoey_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1815 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Rewarding behaviors."@en ;
    askg-onto:inSentence "Rewarding behaviors."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concept,
        askg-data:Entity-rewarding_behaviors .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18150 a askg-onto:Sentence ;
    rdfs:label "Sentence 50"@en ;
    domo:Text "Hoey, R."@en ;
    askg-onto:inSentence "Hoey, R."^^xsd:string ;
    askg-onto:index "50"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-hoey_r .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18151 a askg-onto:Sentence ;
    rdfs:label "Sentence 51"@en ;
    domo:Text "St-Aubin, A."@en ;
    askg-onto:inSentence "St-Aubin, A."^^xsd:string ;
    askg-onto:index "51"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-publication,
        askg-data:Entity-st-aubin_a .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18152 a askg-onto:Sentence ;
    rdfs:label "Sentence 52"@en ;
    domo:Text "Hu, and C."@en ;
    askg-onto:inSentence "Hu, and C."^^xsd:string ;
    askg-onto:index "52"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-hu .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18153 a askg-onto:Sentence ;
    rdfs:label "Sentence 53"@en ;
    domo:Text "Boutilier."@en ;
    askg-onto:inSentence "Boutilier."^^xsd:string ;
    askg-onto:index "53"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-boutilier,
        askg-data:Entity-scientist .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18154 a askg-onto:Sentence ;
    rdfs:label "Sentence 54"@en ;
    domo:Text "SPUDD: stochastic planning using decision diagrams."@en ;
    askg-onto:inSentence "SPUDD: stochastic planning using decision diagrams."^^xsd:string ;
    askg-onto:index "54"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-spudd,
        askg-data:Entity-stochastic_planning_using_decision_diagrams .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18155 a askg-onto:Sentence ;
    rdfs:label "Sentence 55"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "55"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18156 a askg-onto:Sentence ;
    rdfs:label "Sentence 56"@en ;
    domo:Text "UAI-99, 1999."@en ;
    askg-onto:inSentence "UAI-99, 1999."^^xsd:string ;
    askg-onto:index "56"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1999,
        askg-data:Entity-publication,
        askg-data:Entity-uai-99,
        askg-data:Entity-year .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18157 a askg-onto:Sentence ;
    rdfs:label "Sentence 57"@en ;
    domo:Text "SPUDD is available from http://www.cs.ubc.ca/spider/staubin/Spudd/."@en ;
    askg-onto:inSentence "SPUDD is available from http://www.cs.ubc.ca/spider/staubin/Spudd/."^^xsd:string ;
    askg-onto:index "57"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-httpwwwcsubccaspiderstaubinspudd,
        askg-data:Entity-spudd .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18158 a askg-onto:Sentence ;
    rdfs:label "Sentence 58"@en ;
    domo:Text "[Howard, 1960] R.A."@en ;
    askg-onto:inSentence "[Howard, 1960] R.A."^^xsd:string ;
    askg-onto:index "58"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-howard_1960,
        askg-data:Entity-ra_howard .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18159 a askg-onto:Sentence ;
    rdfs:label "Sentence 59"@en ;
    domo:Text "Howard."@en ;
    askg-onto:inSentence "Howard."^^xsd:string ;
    askg-onto:index "59"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-howard,
        askg-data:Entity-person .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1816 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18160 a askg-onto:Sentence ;
    rdfs:label "Sentence 60"@en ;
    domo:Text "Dynamic Programming and Markov Processes."@en ;
    askg-onto:inSentence "Dynamic Programming and Markov Processes."^^xsd:string ;
    askg-onto:index "60"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_programming,
        askg-data:Entity-markov_processes .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18161 a askg-onto:Sentence ;
    rdfs:label "Sentence 61"@en ;
    domo:Text "MIT P ress, Cambridge, MA, 1960."@en ;
    askg-onto:inSentence "MIT P ress, Cambridge, MA, 1960."^^xsd:string ;
    askg-onto:index "61"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1960,
        askg-data:Entity-cambridge_ma,
        askg-data:Entity-mit_press .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18162 a askg-onto:Sentence ;
    rdfs:label "Sentence 62"@en ;
    domo:Text "[Thiebaux et al., 2002] S."@en ;
    askg-onto:inSentence "[Thiebaux et al., 2002] S."^^xsd:string ;
    askg-onto:index "62"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-thiebaux_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18163 a askg-onto:Sentence ;
    rdfs:label "Sentence 63"@en ;
    domo:Text "Thiebaux, F."@en ;
    askg-onto:inSentence "Thiebaux, F."^^xsd:string ;
    askg-onto:index "63"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-thiebaux_f .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18164 a askg-onto:Sentence ;
    rdfs:label "Sentence 64"@en ;
    domo:Text "Kabanza, and J."@en ;
    askg-onto:inSentence "Kabanza, and J."^^xsd:string ;
    askg-onto:index "64"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-j,
        askg-data:Entity-kabanza .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18165 a askg-onto:Sentence ;
    rdfs:label "Sentence 65"@en ;
    domo:Text "Slaney."@en ;
    askg-onto:inSentence "Slaney."^^xsd:string ;
    askg-onto:index "65"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_researcher,
        askg-data:Entity-slaney .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18166 a askg-onto:Sentence ;
    rdfs:label "Sentence 66"@en ;
    domo:Text "Anytime state-based solution methods for decision pro· cesses with non-markovian rewards."@en ;
    askg-onto:inSentence "Anytime state-based solution methods for decision pro· cesses with non-markovian rewards."^^xsd:string ;
    askg-onto:index "66"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_processes,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-state-based_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18167 a askg-onto:Sentence ;
    rdfs:label "Sentence 67"@en ;
    domo:Text "In Proc."@en ;
    askg-onto:inSentence "In Proc."^^xsd:string ;
    askg-onto:index "67"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-proc,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-18168 a askg-onto:Sentence ;
    rdfs:label "Sentence 68"@en ;
    domo:Text "UAI-02, pages 501-510,2002."@en ;
    askg-onto:inSentence "UAI-02, pages 501-510,2002."^^xsd:string ;
    askg-onto:index "68"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002,
        askg-data:Entity-pages_501-510,
        askg-data:Entity-publication,
        askg-data:Entity-uai-02 .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1817 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "MAI-96, pages 1160-1167, 1996."@en ;
    askg-onto:inSentence "MAI-96, pages 1160-1167, 1996."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mai-96,
        askg-data:Entity-publication .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1818 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "[Bacchus et al., 1997] F."@en ;
    askg-onto:inSentence "[Bacchus et al., 1997] F."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1997,
        askg-data:Entity-bacchus_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-181-Sentence-1819 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "Bacchus, C."@en ;
    askg-onto:inSentence "Bacchus, C."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-bacchus_c .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-182 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "```"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-182-Sentence-1821 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-18-Paragraph-182-Sentence-1821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "```"@en ;
    askg-onto:inSentence "```"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-article,
        askg-data:Entity-company,
        askg-data:Entity-concept,
        askg-data:Entity-dataset,
        askg-data:Entity-experiment,
        askg-data:Entity-method,
        askg-data:Entity-publication,
        askg-data:Entity-research,
        askg-data:Entity-researcher,
        askg-data:Entity-scientist,
        askg-data:Entity-study,
        askg-data:Entity-technology,
        askg-data:Entity-triple .

askg-data:Paper-0ecbd8a3379fdc37-Section-2 a askg-onto:Section ;
    rdfs:label "Section 2"@en ;
    domo:Text "Abstract"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21 ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "This paper examines a number of solution methods for decision processes with non-Markovian rewards (NMRDPs). Tlu::y all t:xploit a temporal logic specification of the reward function to automatically translate the NMROP into an equivalent Markov decision process (MOP) amenable to well-known MOP solution methods. They differ however in the representation of the target MOP and the class of MOP solution methods to which they are suited. As a result, they adopt different temporal logics and different translations. Unfortunately, no implementation of these methods nor experimental let alone comparative results have ever been reported. This paper is the first step towards filling this gap. We describe an integrated system for solving NMRDPs which implements these methods and several variants under a common interface; we use it to compare the various approaches and identify certain problem features favouring one over the other."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-211,
        askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-212,
        askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-213,
        askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-214,
        askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-215,
        askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-216,
        askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-217 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-211 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This paper examines a number of solution methods for decision processes with non-Markovian rewards (NMRDPs)."@en ;
    askg-onto:inSentence "This paper examines a number of solution methods for decision processes with non-Markovian rewards (NMRDPs)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_processes,
        askg-data:Entity-nmrdps,
        askg-data:Entity-non-markovian_rewards,
        askg-data:Entity-solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-212 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Tlu::y all t:xploit a temporal logic specification of the reward function to automatically translate the NMROP into an equivalent Markov decision process (MOP) amenable to well-known MOP solution methods."@en ;
    askg-onto:inSentence "Tlu::y all t:xploit a temporal logic specification of the reward function to automatically translate the NMROP into an equivalent Markov decision process (MOP) amenable to well-known MOP solution methods."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-markov_decision_process,
        askg-data:Entity-mop_solution_methods,
        askg-data:Entity-nmrop,
        askg-data:Entity-reward_function,
        askg-data:Entity-temporal_logic_specification .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-213 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "They differ however in the representation of the target MOP and the class of MOP solution methods to which they are suited."@en ;
    askg-onto:inSentence "They differ however in the representation of the target MOP and the class of MOP solution methods to which they are suited."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-class_of_mop_solution_methods,
        askg-data:Entity-mop,
        askg-data:Entity-mop_solution_methods,
        askg-data:Entity-target_mop .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-214 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As a result, they adopt different temporal logics and different translations."@en ;
    askg-onto:inSentence "As a result, they adopt different temporal logics and different translations."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_temporal_logics,
        askg-data:Entity-different_translations,
        askg-data:Entity-they .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-215 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Unfortunately, no implementation of these methods nor experimental let alone comparative results have ever been reported."@en ;
    askg-onto:inSentence "Unfortunately, no implementation of these methods nor experimental let alone comparative results have ever been reported."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-results .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-216 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This paper is the first step towards filling this gap."@en ;
    askg-onto:inSentence "This paper is the first step towards filling this gap."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-the_first_step_towards_filling_this_gap,
        askg-data:Entity-this_paper .

askg-data:Paper-0ecbd8a3379fdc37-Section-2-Paragraph-21-Sentence-217 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "We describe an integrated system for solving NMRDPs which implements these methods and several variants under a common interface; we use it to compare the various approaches and identify certain problem features favouring one over the other."@en ;
    askg-onto:inSentence "We describe an integrated system for solving NMRDPs which implements these methods and several variants under a common interface; we use it to compare the various approaches and identify certain problem features favouring one over the other."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-integrated_system,
        askg-data:Entity-methods,
        askg-data:Entity-one,
        askg-data:Entity-problem_features,
        askg-data:Entity-variants,
        askg-data:Entity-various_approaches .

askg-data:Paper-0ecbd8a3379fdc37-Section-3 a askg-onto:Section ;
    rdfs:label "Section 3"@en ;
    domo:Text "1 Introduction"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-31,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-35,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-36,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-38 ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-31 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "A decision process in which rewards depend on the sequence of states passed through rather than merely on the current state is called a decision process with non- Markovian rewards (NMROP). In decision-theoretic planning, where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states, NMRDPs form a more natural model than the commonly adopted fully Markovian decision process (MOP) model [Haddawy and Hanks, 1992; Bacchus et al., 1996]."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-31-Sentence-311,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-31-Sentence-312 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-31-Sentence-311 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A decision process in which rewards depend on the sequence of states passed through rather than merely on the current state is called a decision process with non- Markovian rewards (NMROP)."@en ;
    askg-onto:inSentence "A decision process in which rewards depend on the sequence of states passed through rather than merely on the current state is called a decision process with non- Markovian rewards (NMROP)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_process,
        askg-data:Entity-decision_process_with_non-markovian_rewards .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-31-Sentence-312 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In decision-theoretic planning, where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states, NMRDPs form a more natural model than the commonly adopted fully Markovian decision process (MOP) model [Haddawy and Hanks, 1992; Bacchus et al., 1996]."@en ;
    askg-onto:inSentence "In decision-theoretic planning, where many desirable behaviours are more naturally expressed as properties of execution sequences rather than as properties of states, NMRDPs form a more natural model than the commonly adopted fully Markovian decision process (MOP) model [Haddawy and Hanks, 1992; Bacchus et al., 1996]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1992,
        askg-data:Entity-1996,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-decision-theoretic_planning,
        askg-data:Entity-fully_markovian_decision_process_mop,
        askg-data:Entity-haddawy_and_hanks,
        askg-data:Entity-nmrdps .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The more tractable solution methods developed for MOPs do not directly apply to NMRDPs. However, a number of solution methods for NMRDPs have been proposed in the literature [Bacchus et al., 1996; Bacchus et al., 1997; Thiebaux et al., 2002]. These all start with a temporal logic specification of the non-Markovian reward function, which they exploit to automatically translate the NMRDP into an equivalent MOP which is solved using efficient MOP solution methods. The states of this MOP result from augmenting those of the original NMROP with extra information capturing enough history to make the reward Markovian."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-321,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-322,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-323,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-324 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-321 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The more tractable solution methods developed for MOPs do not directly apply to NMRDPs."@en ;
    askg-onto:inSentence "The more tractable solution methods developed for MOPs do not directly apply to NMRDPs."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mops,
        askg-data:Entity-nmrdps,
        askg-data:Entity-solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-322 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, a number of solution methods for NMRDPs have been proposed in the literature [Bacchus et al., 1996; Bacchus et al., 1997; Thiebaux et al., 2002]."@en ;
    askg-onto:inSentence "However, a number of solution methods for NMRDPs have been proposed in the literature [Bacchus et al., 1996; Bacchus et al., 1997; Thiebaux et al., 2002]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-bacchus_et_al_1996_bacchus_et_al_1997_thiebaux_et_al_2002,
        askg-data:Entity-literature,
        askg-data:Entity-nmrdps,
        askg-data:Entity-thiebaux_et_al,
        askg-data:Entity-thiebaux_et_al_2002 .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-323 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "These all start with a temporal logic specification of the non-Markovian reward function, which they exploit to automatically translate the NMRDP into an equivalent MOP which is solved using efficient MOP solution methods."@en ;
    askg-onto:inSentence "These all start with a temporal logic specification of the non-Markovian reward function, which they exploit to automatically translate the NMRDP into an equivalent MOP which is solved using efficient MOP solution methods."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mop,
        askg-data:Entity-mop_solution_methods,
        askg-data:Entity-nmrdp,
        askg-data:Entity-non-markovian_reward_function,
        askg-data:Entity-temporal_logic_specification .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-32-Sentence-324 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The states of this MOP result from augmenting those of the original NMROP with extra information capturing enough history to make the reward Markovian."@en ;
    askg-onto:inSentence "The states of this MOP result from augmenting those of the original NMROP with extra information capturing enough history to make the reward Markovian."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-markovian,
        askg-data:Entity-mop,
        askg-data:Entity-original_nmrop,
        askg-data:Entity-reward .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "Naturally, there is a tradeoff between the effort spent in the translation, e.g. in producing a small equivalent MDP without many irrelevant history distinctions, and the effort required to solve it. Appropriate resolution of this tradeoff depends on the type of representations and solution methods envisioned for the MDP. For instance, structured representations and solution methods which have some ability to ignore irrelevant information may cope with a crude translation, while state-based (flat) representations and methods will require a more sophisticated translation producing an MOP as small as feasible."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-331,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-332,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-333,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-334 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-331 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Naturally, there is a tradeoff between the effort spent in the translation, e.g."@en ;
    askg-onto:inSentence "Naturally, there is a tradeoff between the effort spent in the translation, e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-effort,
        askg-data:Entity-translation .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-332 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "in producing a small equivalent MDP without many irrelevant history distinctions, and the effort required to solve it."@en ;
    askg-onto:inSentence "in producing a small equivalent MDP without many irrelevant history distinctions, and the effort required to solve it."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-small_equivalent_mdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-333 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Appropriate resolution of this tradeoff depends on the type of representations and solution methods envisioned for the MDP."@en ;
    askg-onto:inSentence "Appropriate resolution of this tradeoff depends on the type of representations and solution methods envisioned for the MDP."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-solution_methods,
        askg-data:Entity-tradeoff,
        askg-data:Entity-type_of_representations .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-33-Sentence-334 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For instance, structured representations and solution methods which have some ability to ignore irrelevant information may cope with a crude translation, while state-based (flat) representations and methods will require a more sophisticated translation producing an MOP as small as feasible."@en ;
    askg-onto:inSentence "For instance, structured representations and solution methods which have some ability to ignore irrelevant information may cope with a crude translation, while state-based (flat) representations and methods will require a more sophisticated translation producing an MOP as small as feasible."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-crude_translation,
        askg-data:Entity-mop,
        askg-data:Entity-small_as_feasible,
        askg-data:Entity-solution_methods,
        askg-data:Entity-sophisticated_translation,
        askg-data:Entity-state-based_methods,
        askg-data:Entity-state-based_representations,
        askg-data:Entity-structured_representations .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "W hile the approaches [Bacchus et al., 1996; Bacchus et al., 1997; Thiebaux et al., 2002] are all based on translation into an equivalent MDP, they target different MDP representations and solution methods. Specifically, [Bacchus et al., 1996] targets state-based representations and classical solution methods such as value or policy iteration [Howard, 1960]. [Thiebaux et al., 2002] also considers state-based representation but targets heuristic search methods such as LAO* [Hansen and Zilberstein, 2001] or labelled RTOP [Bonet and Geffner, 2003]. Finally, [Bacchus et al., 1997] considers structured representations and solution methods such as structured policy iteration or SPUDO [Boutilier et al., 1995; Hoey et al., 1999]."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-341,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-342,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-343,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-344 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-341 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "W hile the approaches [Bacchus et al., 1996; Bacchus et al., 1997; Thiebaux et al., 2002] are all based on translation into an equivalent MDP, they target different MDP representations and solution methods."@en ;
    askg-onto:inSentence "W hile the approaches [Bacchus et al., 1996; Bacchus et al., 1997; Thiebaux et al., 2002] are all based on translation into an equivalent MDP, they target different MDP representations and solution methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-different_mdp_representations,
        askg-data:Entity-mdp,
        askg-data:Entity-solution_methods,
        askg-data:Entity-translation_into_an_equivalent_mdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-342 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Specifically, [Bacchus et al., 1996] targets state-based representations and classical solution methods such as value or policy iteration [Howard, 1960]."@en ;
    askg-onto:inSentence "Specifically, [Bacchus et al., 1996] targets state-based representations and classical solution methods such as value or policy iteration [Howard, 1960]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-classical_solution_method,
        askg-data:Entity-policy_iteration,
        askg-data:Entity-state-based_representations,
        askg-data:Entity-value_iteration .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-343 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "[Thiebaux et al., 2002] also considers state-based representation but targets heuristic search methods such as LAO* [Hansen and Zilberstein, 2001] or labelled RTOP [Bonet and Geffner, 2003]."@en ;
    askg-onto:inSentence "[Thiebaux et al., 2002] also considers state-based representation but targets heuristic search methods such as LAO* [Hansen and Zilberstein, 2001] or labelled RTOP [Bonet and Geffner, 2003]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bonet_and_geffner,
        askg-data:Entity-hansen_and_zilberstein,
        askg-data:Entity-heuristic_search_methods,
        askg-data:Entity-labelled_rtop,
        askg-data:Entity-lao,
        askg-data:Entity-state-based_representation,
        askg-data:Entity-thiebaux_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-34-Sentence-344 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Finally, [Bacchus et al., 1997] considers structured representations and solution methods such as structured policy iteration or SPUDO [Boutilier et al., 1995; Hoey et al., 1999]."@en ;
    askg-onto:inSentence "Finally, [Bacchus et al., 1997] considers structured representations and solution methods such as structured policy iteration or SPUDO [Boutilier et al., 1995; Hoey et al., 1999]."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-boutilier_et_al,
        askg-data:Entity-hoey_et_al,
        askg-data:Entity-solution_methods,
        askg-data:Entity-spudo,
        askg-data:Entity-structured_policy_iteration,
        askg-data:Entity-structured_representations .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-35 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "These different targets lead the three approaches to resolve the translation/solution tradeoff differently, and in turn, to adopt different temporal logics, as appropriate. For instance, both [Bacchus et al., 1996; Bacchus et al., 1997] use linear temporal logic with past operators (PLTL), as this yields a straightforward semantics of non-Markovian rewards, and lends itself to a simple characterisation of a range of translations, from the crudest to the finest."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-35-Sentence-351,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-35-Sentence-352 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-35-Sentence-351 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "These different targets lead the three approaches to resolve the translation/solution tradeoff differently, and in turn, to adopt different temporal logics, as appropriate."@en ;
    askg-onto:inSentence "These different targets lead the three approaches to resolve the translation/solution tradeoff differently, and in turn, to adopt different temporal logics, as appropriate."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_temporal_logics,
        askg-data:Entity-three_approaches,
        askg-data:Entity-translationsolution_tradeoff .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-35-Sentence-352 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For instance, both [Bacchus et al., 1996; Bacchus et al., 1997] use linear temporal logic with past operators (PLTL), as this yields a straightforward semantics of non-Markovian rewards, and lends itself to a simple characterisation of a range of translations, from the crudest to the finest."@en ;
    askg-onto:inSentence "For instance, both [Bacchus et al., 1996; Bacchus et al., 1997] use linear temporal logic with past operators (PLTL), as this yields a straightforward semantics of non-Markovian rewards, and lends itself to a simple characterisation of a range of translations, from the crudest to the finest."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_simple_characterisation_of_a_range_of_translations,
        askg-data:Entity-a_straightforward_semantics_of_non-markovian_rewards,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-linear_temporal_logic_with_past_operators_pltl .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-36 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "[Thiebaux et al., 2002], on the other hand, relies on a more complex extension of LTL with future operators ($FLTL), as it naturally leads to a style of translation suited to the needs of heuristic search methods."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-36-Sentence-361 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-36-Sentence-361 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[Thiebaux et al., 2002], on the other hand, relies on a more complex extension of LTL with future operators ($FLTL), as it naturally leads to a style of translation suited to the needs of heuristic search methods."@en ;
    askg-onto:inSentence "[Thiebaux et al., 2002], on the other hand, relies on a more complex extension of LTL with future operators ($FLTL), as it naturally leads to a style of translation suited to the needs of heuristic search methods."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002,
        askg-data:Entity-fltl,
        askg-data:Entity-heuristic_search_methods,
        askg-data:Entity-ltl,
        askg-data:Entity-thiebaux_et_al,
        askg-data:Entity-translation .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "The three cited papers agree that the most important item for future work is the implementation and experimental comparison of the respective approaches, with a view to identifying the features that favour one over the other. This paper is the first step in that direction. We start with a review of NMRDPs and of the three approaches. We then describe NMROPP (NMRDP Planner), an integrated system which implements, under a single interface, a family of NMRDP solution methods based on the cited approaches, and reports a range of statistics about their performance."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-371,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-372,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-373,
        askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-374 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-371 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The three cited papers agree that the most important item for future work is the implementation and experimental comparison of the respective approaches, with a view to identifying the features that favour one over the other."@en ;
    askg-onto:inSentence "The three cited papers agree that the most important item for future work is the implementation and experimental comparison of the respective approaches, with a view to identifying the features that favour one over the other."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-future_work,
        askg-data:Entity-implementation_and_experimental_comparison,
        askg-data:Entity-three_cited_papers .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-372 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This paper is the first step in that direction."@en ;
    askg-onto:inSentence "This paper is the first step in that direction."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-that_direction,
        askg-data:Entity-this_paper .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-373 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We start with a review of NMRDPs and of the three approaches."@en ;
    askg-onto:inSentence "We start with a review of NMRDPs and of the three approaches."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-nmrdps,
        askg-data:Entity-three_approaches .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-37-Sentence-374 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We then describe NMROPP (NMRDP Planner), an integrated system which implements, under a single interface, a family of NMRDP solution methods based on the cited approaches, and reports a range of statistics about their performance."@en ;
    askg-onto:inSentence "We then describe NMROPP (NMRDP Planner), an integrated system which implements, under a single interface, a family of NMRDP solution methods based on the cited approaches, and reports a range of statistics about their performance."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cited_approaches,
        askg-data:Entity-family_of_nmrdp_solution_methods,
        askg-data:Entity-integrated_system,
        askg-data:Entity-nmrdp_planner,
        askg-data:Entity-nmrdp_solution_methods,
        askg-data:Entity-nmropp,
        askg-data:Entity-range_of_statistics_about_performance .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-38 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "We use this system to compare their behaviours under the influence of various factors such as the structure and degree of uncertainty in the dynamics, the cla�s of rewards and the syntax used to describe them, reachability, and relevance of reward� to the optimal policy."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-38-Sentence-381 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-3-Paragraph-38-Sentence-381 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We use this system to compare their behaviours under the influence of various factors such as the structure and degree of uncertainty in the dynamics, the cla�s of rewards and the syntax used to describe them, reachability, and relevance of reward� to the optimal policy."@en ;
    askg-onto:inSentence "We use this system to compare their behaviours under the influence of various factors such as the structure and degree of uncertainty in the dynamics, the cla�s of rewards and the syntax used to describe them, reachability, and relevance of reward� to the optimal policy."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-behaviours,
        askg-data:Entity-degree,
        askg-data:Entity-optimal_policy,
        askg-data:Entity-policy,
        askg-data:Entity-reachability,
        askg-data:Entity-relevance,
        askg-data:Entity-reward,
        askg-data:Entity-rewards,
        askg-data:Entity-structure,
        askg-data:Entity-syntax,
        askg-data:Entity-system,
        askg-data:Entity-uncertainty,
        askg-data:Entity-various_factors .

askg-data:Paper-0ecbd8a3379fdc37-Section-4 a askg-onto:Section ;
    rdfs:label "Section 4"@en ;
    domo:Text "2 Nmrdp Solution Method S 2.1 Mdps, Nmrdps, Equivalence"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-410,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-412,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-413,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-43,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-44,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-46,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-48,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-49 ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We start with some notation and definitions. Given a finite set S of states, we write S* for the set of finite sequences of states overS, and sw for the set of possibly infinite state sequences. Where T' stands for a possibly infinite state sequence in sw and i is a natural number, by T;' we mean the state of index i in r, and by T(i)' we mean the prefix (fo, ... ,f;) E S* off."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-411,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-412,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-413,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-414 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-411 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We start with some notation and definitions."@en ;
    askg-onto:inSentence "We start with some notation and definitions."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-definitions,
        askg-data:Entity-notation .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-412 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Given a finite set S of states, we write S* for the set of finite sequences of states overS, and sw for the set of possibly infinite state sequences."@en ;
    askg-onto:inSentence "Given a finite set S of states, we write S* for the set of finite sequences of states overS, and sw for the set of possibly infinite state sequences."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finite_sequences_of_states,
        askg-data:Entity-possibly_infinite_state_sequences,
        askg-data:Entity-s,
        askg-data:Entity-states,
        askg-data:Entity-sw .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-413 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Where T' stands for a possibly infinite state sequence in sw and i is a natural number, by T;' we mean the state of index i in r, and by T(i)' we mean the prefix (fo, ..."@en ;
    askg-onto:inSentence "Where T' stands for a possibly infinite state sequence in sw and i is a natural number, by T;' we mean the state of index i in r, and by T(i)' we mean the prefix (fo, ..."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-i,
        askg-data:Entity-natural_number,
        askg-data:Entity-possibly_infinite_state_sequence,
        askg-data:Entity-prefix,
        askg-data:Entity-state_of_index_i_in_r,
        askg-data:Entity-t,
        askg-data:Entity-ti .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-41-Sentence-414 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text ",f;) E S* off."@en ;
    askg-onto:inSentence ",f;) E S* off."^^xsd:string ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-410 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 10"@en ;
    domo:Text "2. For all s' E S', A'(s') = A(7(s'))."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-410-Sentence-4101,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-410-Sentence-4102 ;
    askg-onto:index "10"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-410-Sentence-4101 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2."@en ;
    askg-onto:inSentence "2."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-triple .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-410-Sentence-4102 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For all s' E S', A'(s') = A(7(s'))."@en ;
    askg-onto:inSentence "For all s' E S', A'(s') = A(7(s'))."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a7s,
        askg-data:Entity-as,
        askg-data:Entity-s .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 11"@en ;
    domo:Text "$\\mathfrak{or}$ all $\\mathfrak{r}(s_{\\Phi}$. 3. For all s1, s2 E S, if there is a E A(s1) such that"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411-Sentence-4111,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411-Sentence-4112,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411-Sentence-4113 ;
    askg-onto:index "11"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411-Sentence-4111 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$\\mathfrak{or}$ all $\\mathfrak{r}(s_{\\Phi}$."@en ;
    askg-onto:inSentence "$\\mathfrak{or}$ all $\\mathfrak{r}(s_{\\Phi}$."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-r,
        askg-data:Entity-rs_%CF%86 .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411-Sentence-4112 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "3."@en ;
    askg-onto:inSentence "3."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dataset,
        askg-data:Entity-triple .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-411-Sentence-4113 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For all s1, s2 E S, if there is a E A(s1) such that"@en ;
    askg-onto:inSentence "For all s1, s2 E S, if there is a E A(s1) such that"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-s,
        askg-data:Entity-s1,
        askg-data:Entity-s2 .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-412 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 12"@en ;
    domo:Text "Pr( s1, a, s2) > 0, then for all s� E S' such that 7(sD=s1, there exist� a unique s;ES' , 7(s;)=s2, such that for all a E A'( sD, Pr' ( s�, a, s;) = Pr( s1, a, s2)."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-412-Sentence-4121 ;
    askg-onto:index "12"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-412-Sentence-4121 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Pr( s1, a, s2) > 0, then for all s� E S' such that 7(sD=s1, there exist� a unique s;ES' , 7(s;)=s2, such that for all a E A'( sD, Pr' ( s�, a, s;) = Pr( s1, a, s2)."@en ;
    askg-onto:inSentence "Pr( s1, a, s2) > 0, then for all s� E S' such that 7(sD=s1, there exist� a unique s;ES' , 7(s;)=s2, such that for all a E A'( sD, Pr' ( s�, a, s;) = Pr( s1, a, s2)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-pr,
        askg-data:Entity-probability_function,
        askg-data:Entity-s,
        askg-data:Entity-s1,
        askg-data:Entity-s2,
        askg-data:Entity-set,
        askg-data:Entity-set_of_actions,
        askg-data:Entity-state .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-413 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 13"@en ;
    domo:Text "4. For any feasible1 state sequence r for D and any fea�ible state sequence r' for D' such that r 0 = so and Vi 7(f;) = f;, we have: Vi R'(r;) = R(f(i))."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-413-Sentence-4131,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-413-Sentence-4132 ;
    askg-onto:index "13"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-413-Sentence-4131 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4."@en ;
    askg-onto:inSentence "4."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-data,
        askg-data:Entity-triple .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-413-Sentence-4132 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "For any feasible1 state sequence r for D and any fea�ible state sequence r' for D' such that r 0 = so and Vi 7(f;) = f;, we have: Vi R'(r;) = R(f(i))."@en ;
    askg-onto:inSentence "For any feasible1 state sequence r for D and any fea�ible state sequence r' for D' such that r 0 = so and Vi 7(f;) = f;, we have: Vi R'(r;) = R(f(i))."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-d,
        askg-data:Entity-r_0,
        askg-data:Entity-rfi,
        askg-data:Entity-so,
        askg-data:Entity-state_sequence_r,
        askg-data:Entity-vi_rr .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 14"@en ;
    domo:Text "Items 1-3 ensure that there is a bijection between fea�ib1e state sequences in the NMRDP and fea�ible e-state sequences in the equivalent MOP. Therefore, a stationary policy for the MOP can be reinterpreted a� a non-stationary policy for the NMRDP. Furthermore, item 4 ensures that the two policies have identical values, and that consequently, solving an NMRDP optimally reduces to producing an equivalent MDP and solving it optimally [Bacchus et a!., 1996]."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414-Sentence-4141,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414-Sentence-4142,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414-Sentence-4143 ;
    askg-onto:index "14"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414-Sentence-4141 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Items 1-3 ensure that there is a bijection between fea�ib1e state sequences in the NMRDP and fea�ible e-state sequences in the equivalent MOP."@en ;
    askg-onto:inSentence "Items 1-3 ensure that there is a bijection between fea�ib1e state sequences in the NMRDP and fea�ible e-state sequences in the equivalent MOP."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-feasible_e-state_sequences,
        askg-data:Entity-feasible_state_sequences .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414-Sentence-4142 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Therefore, a stationary policy for the MOP can be reinterpreted a� a non-stationary policy for the NMRDP."@en ;
    askg-onto:inSentence "Therefore, a stationary policy for the MOP can be reinterpreted a� a non-stationary policy for the NMRDP."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mop,
        askg-data:Entity-nmrdp,
        askg-data:Entity-non-stationary_policy,
        askg-data:Entity-stationary_policy .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-414-Sentence-4143 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Furthermore, item 4 ensures that the two policies have identical values, and that consequently, solving an NMRDP optimally reduces to producing an equivalent MDP and solving it optimally [Bacchus et a!., 1996]."@en ;
    askg-onto:inSentence "Furthermore, item 4 ensures that the two policies have identical values, and that consequently, solving an NMRDP optimally reduces to producing an equivalent MDP and solving it optimally [Bacchus et a!., 1996]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-mdp,
        askg-data:Entity-nmrdp,
        askg-data:Entity-optimally .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 15"@en ;
    domo:Text "When solving NMRDPs in this setting, the central issue is to choose a language for compactly representing non- Markovian reward functions and a translation algorithm which is adapted to the needs of the MOP representations and solution methods we are targeting. In particular, this choice should enable an appropriate resolution of the tradeoff between the time spent in the translation and the time spent in solving the resulting MOP. The three approaches we consider have different target�, for which different languages and translations are appropriate. We now present the main ideas behind these approaches. For details, the reader is referred to the respective papers."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4151,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4152,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4153,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4154,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4155 ;
    askg-onto:index "15"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4151 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "When solving NMRDPs in this setting, the central issue is to choose a language for compactly representing non- Markovian reward functions and a translation algorithm which is adapted to the needs of the MOP representations and solution methods we are targeting."@en ;
    askg-onto:inSentence "When solving NMRDPs in this setting, the central issue is to choose a language for compactly representing non- Markovian reward functions and a translation algorithm which is adapted to the needs of the MOP representations and solution methods we are targeting."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-language,
        askg-data:Entity-mop_representations,
        askg-data:Entity-nmrdps,
        askg-data:Entity-non-markovian_reward_functions,
        askg-data:Entity-solution_methods,
        askg-data:Entity-translation_algorithm .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4152 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In particular, this choice should enable an appropriate resolution of the tradeoff between the time spent in the translation and the time spent in solving the resulting MOP."@en ;
    askg-onto:inSentence "In particular, this choice should enable an appropriate resolution of the tradeoff between the time spent in the translation and the time spent in solving the resulting MOP."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-time_spent_in_solving_the_resulting_mop,
        askg-data:Entity-time_spent_in_the_translation,
        askg-data:Entity-tradeoff .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4153 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The three approaches we consider have different target�, for which different languages and translations are appropriate."@en ;
    askg-onto:inSentence "The three approaches we consider have different target�, for which different languages and translations are appropriate."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_languages,
        askg-data:Entity-different_target,
        askg-data:Entity-different_translations,
        askg-data:Entity-three_approaches .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4154 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "We now present the main ideas behind these approaches."@en ;
    askg-onto:inSentence "We now present the main ideas behind these approaches."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-main_ideas .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-415-Sentence-4155 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For details, the reader is referred to the respective papers."@en ;
    askg-onto:inSentence "For details, the reader is referred to the respective papers."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-papers,
        askg-data:Entity-reader .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "We take a Markov decision process to be a 5-tuple (S, s0, A, Pr, R), where S is a finite set of fully observable states, s0 E S is the initial state, A is a finite set of actions (A( s) denotes the subset of actions applicable in s E S), {Pr( s, a, •) / s E S, a E A( s)} is a family of probability distributions overS such that Pr(s, a, s') is the probability of being in state s' after performing action a in states, and R : S >-> R is a reward function such that R( s) is the immediate reward for being in state s. A stationary policy for an MOP is a function 1r: S >->A, such that rr(s) E A(s) is the action to be executed in stateS. The value V(rr) of the policy, which we seek to maximise, is the sum of the expected future rewards, discounted by how far into the future they occur:"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42-Sentence-421,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42-Sentence-422,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42-Sentence-423 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42-Sentence-421 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We take a Markov decision process to be a 5-tuple (S, s0, A, Pr, R), where S is a finite set of fully observable states, s0 E S is the initial state, A is a finite set of actions (A( s) denotes the subset of actions applicable in s E S), {Pr( s, a, •) / s E S, a E A( s)} is a family of probability distributions overS such that Pr(s, a, s') is the probability of being in state s' after performing action a in states, and R : S >-> R is a reward function such that R( s) is the immediate reward for being in state s."@en ;
    askg-onto:inSentence "We take a Markov decision process to be a 5-tuple (S, s0, A, Pr, R), where S is a finite set of fully observable states, s0 E S is the initial state, A is a finite set of actions (A( s) denotes the subset of actions applicable in s E S), {Pr( s, a, •) / s E S, a E A( s)} is a family of probability distributions overS such that Pr(s, a, s') is the probability of being in state s' after performing action a in states, and R : S >-> R is a reward function such that R( s) is the immediate reward for being in state s."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-5-tuple_s_s0_a_pr_r,
        askg-data:Entity-a,
        askg-data:Entity-family_of_probability_distributions,
        askg-data:Entity-finite_set_of_actions,
        askg-data:Entity-finite_set_of_fully_observable_states,
        askg-data:Entity-immediate_reward_for_being_in_state_s,
        askg-data:Entity-initial_state,
        askg-data:Entity-markov_decision_process,
        askg-data:Entity-pr,
        askg-data:Entity-r,
        askg-data:Entity-reward_function,
        askg-data:Entity-rs,
        askg-data:Entity-s,
        askg-data:Entity-s0 .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42-Sentence-422 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "A stationary policy for an MOP is a function 1r: S >->A, such that rr(s) E A(s) is the action to be executed in stateS."@en ;
    askg-onto:inSentence "A stationary policy for an MOP is a function 1r: S >->A, such that rr(s) E A(s) is the action to be executed in stateS."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action,
        askg-data:Entity-concept,
        askg-data:Entity-function,
        askg-data:Entity-mop,
        askg-data:Entity-states,
        askg-data:Entity-stationary_policy .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-42-Sentence-423 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The value V(rr) of the policy, which we seek to maximise, is the sum of the expected future rewards, discounted by how far into the future they occur:"@en ;
    askg-onto:inSentence "The value V(rr) of the policy, which we seek to maximise, is the sum of the expected future rewards, discounted by how far into the future they occur:"^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expected_future_rewards,
        askg-data:Entity-how_far_into_the_future_they_occur,
        askg-data:Entity-sum_of_expected_future_rewards,
        askg-data:Entity-vrr .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-43 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "$$\\operatorname{by\\,occu}.$$ $$V(\\pi)=\\operatorname*{lim}_{n\\to\\infty}\\operatorname{E}\\left[\\,\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma_{i})\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-43-Sentence-431 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-43-Sentence-431 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\operatorname{by\\,occu}.$$ $$V(\\pi)=\\operatorname*{lim}_{n\\to\\infty}\\operatorname{E}\\left[\\,\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma_{i})\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:inSentence "$$\\operatorname{by\\,occu}.$$ $$V(\\pi)=\\operatorname*{lim}_{n\\to\\infty}\\operatorname{E}\\left[\\,\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma_{i})\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-lim_ne_i0n%CE%B2ir%CE%B3_i%CF%80%CE%B3_0s_0,
        askg-data:Entity-v%CF%80 .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-44 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "where 0 :::; ,6 :::; 1 is the discounting factor controlling the contribution of distant rewards."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-44-Sentence-441 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-44-Sentence-441 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "where 0 :::; ,6 :::; 1 is the discounting factor controlling the contribution of distant rewards."@en ;
    askg-onto:inSentence "where 0 :::; ,6 :::; 1 is the discounting factor controlling the contribution of distant rewards."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0,
        askg-data:Entity-discounting_factor,
        askg-data:Entity-distant_rewards .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "A decision process with non-Markovian rewards is identical to an MOP except that the domain of the reward function is s•. The idea is that if the process ha� pa�sed through state sequence r( i) up to stage i, then the reward R(f( i)) is received at stage i. Like the reward function, a policy for an NMRDP depends on history, and is a mapping from S* to A with rr(f( i)) E A(r ;) . As before, the value of 1r is the expectation of the discounted cumulative reward over an infinite horizon:"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-451,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-452,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-453,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-454 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-451 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "A decision process with non-Markovian rewards is identical to an MOP except that the domain of the reward function is s•."@en ;
    askg-onto:inSentence "A decision process with non-Markovian rewards is identical to an MOP except that the domain of the reward function is s•."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-decision_process,
        askg-data:Entity-mop,
        askg-data:Entity-reward_function,
        askg-data:Entity-s .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-452 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The idea is that if the process ha� pa�sed through state sequence r( i) up to stage i, then the reward R(f( i)) is received at stage i."@en ;
    askg-onto:inSentence "The idea is that if the process ha� pa�sed through state sequence r( i) up to stage i, then the reward R(f( i)) is received at stage i."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-process,
        askg-data:Entity-reward,
        askg-data:Entity-rfi,
        askg-data:Entity-stage_i,
        askg-data:Entity-state_sequence_ri .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-453 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Like the reward function, a policy for an NMRDP depends on history, and is a mapping from S* to A with rr(f( i)) E A(r ;) ."@en ;
    askg-onto:inSentence "Like the reward function, a policy for an NMRDP depends on history, and is a mapping from S* to A with rr(f( i)) E A(r ;) ."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-ar,
        askg-data:Entity-history,
        askg-data:Entity-nmrdp,
        askg-data:Entity-policy,
        askg-data:Entity-rrfi,
        askg-data:Entity-s_to_a .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-45-Sentence-454 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "As before, the value of 1r is the expectation of the discounted cumulative reward over an infinite horizon:"@en ;
    askg-onto:inSentence "As before, the value of 1r is the expectation of the discounted cumulative reward over an infinite horizon:"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1r,
        askg-data:Entity-the_discounted_cumulative_reward_over_an_infinite_horizon .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-46 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "$$\\operatorname*{lim}_{n\\to\\infty}\\operatorname{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma(i))\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-46-Sentence-461 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-46-Sentence-461 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$\\operatorname*{lim}_{n\\to\\infty}\\operatorname{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma(i))\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"@en ;
    askg-onto:inSentence "$$\\operatorname*{lim}_{n\\to\\infty}\\operatorname{E}\\left[\\sum_{i=0}^{n}\\beta^{i}R(\\Gamma(i))\\mid\\pi,\\Gamma_{0}=s_{0}\\right]$$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-%0Aoperatornamelim_ntoinfty%0A,
        askg-data:Entity-e,
        askg-data:Entity-gamma,
        askg-data:Entity-gammai,
        askg-data:Entity-pi,
        askg-data:Entity-r,
        askg-data:Entity-s_0 .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "The solution methods considered here operate by translating an NMRDP into an equivalent MOP with an extended state space [Bacchus et a!., 19961. The states in this MOP, which, for clarity, we will sometimes call expanded states (e-states, for short), augment the states of the NMRDP by encoding additional information sufficient to make the reward history-independent. For instance, if we only want to reward the very first achievement of goal g in an NMRDP, the states of an equivalent MOP would carry at most one extra bit of information recording whether g ha� already been true. In the following, we see an e-state as labelled by a state of the NMRDP (via the function 7 below) and by historical information. The dynamics of NMRDP s being Markovian, the actions and their probabilistic effects in the MOP are exactly those of the NMRDP."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-471,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-472,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-473,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-474,
        askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-475 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-471 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The solution methods considered here operate by translating an NMRDP into an equivalent MOP with an extended state space [Bacchus et a!., 19961."@en ;
    askg-onto:inSentence "The solution methods considered here operate by translating an NMRDP into an equivalent MOP with an extended state space [Bacchus et a!., 19961."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-1996,
        askg-data:Entity-bacchus_et_al,
        askg-data:Entity-extended_state_space,
        askg-data:Entity-mop,
        askg-data:Entity-nmrdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-472 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The states in this MOP, which, for clarity, we will sometimes call expanded states (e-states, for short), augment the states of the NMRDP by encoding additional information sufficient to make the reward history-independent."@en ;
    askg-onto:inSentence "The states in this MOP, which, for clarity, we will sometimes call expanded states (e-states, for short), augment the states of the NMRDP by encoding additional information sufficient to make the reward history-independent."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_information,
        askg-data:Entity-expanded_states,
        askg-data:Entity-reward_history-independent,
        askg-data:Entity-states_of_the_nmrdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-473 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For instance, if we only want to reward the very first achievement of goal g in an NMRDP, the states of an equivalent MOP would carry at most one extra bit of information recording whether g ha� already been true."@en ;
    askg-onto:inSentence "For instance, if we only want to reward the very first achievement of goal g in an NMRDP, the states of an equivalent MOP would carry at most one extra bit of information recording whether g ha� already been true."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-goal_g,
        askg-data:Entity-mop,
        askg-data:Entity-nmrdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-474 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In the following, we see an e-state as labelled by a state of the NMRDP (via the function 7 below) and by historical information."@en ;
    askg-onto:inSentence "In the following, we see an e-state as labelled by a state of the NMRDP (via the function 7 below) and by historical information."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-function_7,
        askg-data:Entity-nmrdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-47-Sentence-475 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The dynamics of NMRDP s being Markovian, the actions and their probabilistic effects in the MOP are exactly those of the NMRDP."@en ;
    askg-onto:inSentence "The dynamics of NMRDP s being Markovian, the actions and their probabilistic effects in the MOP are exactly those of the NMRDP."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actions,
        askg-data:Entity-markovian,
        askg-data:Entity-mop,
        askg-data:Entity-nmrdp,
        askg-data:Entity-probabilistic_effects .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-48 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Formally, MOP D' = (S', s�, A' , Pr', R' ) is equivalent to NMRDP D = (S, so, A, Pr, R) if there exist� a mapping 7 : S' >-> S such that:"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-48-Sentence-481 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-48-Sentence-481 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Formally, MOP D' = (S', s�, A' , Pr', R' ) is equivalent to NMRDP D = (S, so, A, Pr, R) if there exist� a mapping 7 : S' >-> S such that:"@en ;
    askg-onto:inSentence "Formally, MOP D' = (S', s�, A' , Pr', R' ) is equivalent to NMRDP D = (S, so, A, Pr, R) if there exist� a mapping 7 : S' >-> S such that:"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mapping_7,
        askg-data:Entity-mop_d,
        askg-data:Entity-nmrdp_d,
        askg-data:Entity-s .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-49 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "$$1.\\ \\tau(s_{0}^{\\prime})=s_{0}.$$ $$A^{\\prime}(s^{\\prime})=A($$"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-49-Sentence-491 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-4-Paragraph-49-Sentence-491 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "$$1.\\ \\tau(s_{0}^{\\prime})=s_{0}.$$ $$A^{\\prime}(s^{\\prime})=A($$"@en ;
    askg-onto:inSentence "$$1.\\ \\tau(s_{0}^{\\prime})=s_{0}.$$ $$A^{\\prime}(s^{\\prime})=A($$"^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a,
        askg-data:Entity-a%0Aprimes%0Aprime,
        askg-data:Entity-s_0,
        askg-data:Entity-s_0%0Aprime .

askg-data:Paper-0ecbd8a3379fdc37-Section-5 a askg-onto:Section ;
    rdfs:label "Section 5"@en ;
    domo:Text "2.2 Pltlsimp And Pltlmin"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-51,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-52,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59 ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:level "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-51 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "[Bacchus et a!., 1996] targets state-based MDP representations. The equivalent MOP is first entirely generated-this involves the enumeration of all its states and transitions."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-51-Sentence-511,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-51-Sentence-512 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-51-Sentence-511 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[Bacchus et a!., 1996] targets state-based MDP representations."@en ;
    askg-onto:inSentence "[Bacchus et a!., 1996] targets state-based MDP representations."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-state-based_mdp_representations .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-51-Sentence-512 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The equivalent MOP is first entirely generated-this involves the enumeration of all its states and transitions."@en ;
    askg-onto:inSentence "The equivalent MOP is first entirely generated-this involves the enumeration of all its states and transitions."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-its_states_and_transitions,
        askg-data:Entity-mop .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-52 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "Then, it is solved using dynamic programming method� such as value or policy iteration. Since these methods are very sensitive to the number of states, attention is paid to producing a minimal equivalent MOP (with the lea�t number of states)."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-52-Sentence-521,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-52-Sentence-522 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-52-Sentence-521 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Then, it is solved using dynamic programming method� such as value or policy iteration."@en ;
    askg-onto:inSentence "Then, it is solved using dynamic programming method� such as value or policy iteration."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_programming_method,
        askg-data:Entity-value_or_policy_iteration .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-52-Sentence-522 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Since these methods are very sensitive to the number of states, attention is paid to producing a minimal equivalent MOP (with the lea�t number of states)."@en ;
    askg-onto:inSentence "Since these methods are very sensitive to the number of states, attention is paid to producing a minimal equivalent MOP (with the lea�t number of states)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-methods,
        askg-data:Entity-minimal_equivalent_mop,
        askg-data:Entity-the_least_number_of_states,
        askg-data:Entity-the_number_of_states .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "The language chosen to represent rewards is a linear temporal logic of the past (PLTL). The syntax of PLTL is that of propositional logic, augmented with the operators G (previously) and S (since). Wherea� a classical propositional logic formula denotes a set of states (a subset of S), a PLTL formula denotes a set of finite sequences of states (a subset of S*). A formula without temporal modality expresses a property that must be true of the current state, i.e., the last state of the finite sequence. G<f; specifies that <P hold� in"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-531,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-532,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-533,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-534,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-535 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-531 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The language chosen to represent rewards is a linear temporal logic of the past (PLTL)."@en ;
    askg-onto:inSentence "The language chosen to represent rewards is a linear temporal logic of the past (PLTL)."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-linear_temporal_logic_of_the_past,
        askg-data:Entity-rewards .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-532 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The syntax of PLTL is that of propositional logic, augmented with the operators G (previously) and S (since)."@en ;
    askg-onto:inSentence "The syntax of PLTL is that of propositional logic, augmented with the operators G (previously) and S (since)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-operators_g_and_s,
        askg-data:Entity-pltl,
        askg-data:Entity-propositional_logic .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-533 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Wherea� a classical propositional logic formula denotes a set of states (a subset of S), a PLTL formula denotes a set of finite sequences of states (a subset of S*)."@en ;
    askg-onto:inSentence "Wherea� a classical propositional logic formula denotes a set of states (a subset of S), a PLTL formula denotes a set of finite sequences of states (a subset of S*)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classical_propositional_logic_formula,
        askg-data:Entity-pltl_formula,
        askg-data:Entity-set_of_finite_sequences_of_states,
        askg-data:Entity-set_of_states .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-534 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "A formula without temporal modality expresses a property that must be true of the current state, i.e., the last state of the finite sequence."@en ;
    askg-onto:inSentence "A formula without temporal modality expresses a property that must be true of the current state, i.e., the last state of the finite sequence."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_state,
        askg-data:Entity-finite_sequence,
        askg-data:Entity-formula,
        askg-data:Entity-property .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-53-Sentence-535 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "G<f; specifies that <P hold� in"@en ;
    askg-onto:inSentence "G<f; specifies that <P hold� in"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-gf,
        askg-data:Entity-p .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "1 All transitions along the sequence have non-zero probability. the previous state (the state one before the last). We will write 8k (k times ago), for k iterations of the 8 modality. denote the set of reward formulae IIJ a new formula Reg(¢, s) called the regression of <jJ through s. Regression has the property that <jJ is true of a finite sequence f(i) ending with ri = s iffReg(<jJ, s) is true of the prefix r ( i - 1). That is, Reg(¢, s) represents what must have been true previously for <jJ to be true now."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-541,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-542,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-543,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-544,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-545,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-546 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-541 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "1 All transitions along the sequence have non-zero probability."@en ;
    askg-onto:inSentence "1 All transitions along the sequence have non-zero probability."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-zero_probability,
        askg-data:Entity-transitions .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-542 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "the previous state (the state one before the last)."@en ;
    askg-onto:inSentence "the previous state (the state one before the last)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-state_one_before_the_last,
        askg-data:Entity-the_previous_state .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-543 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "We will write 8k (k times ago), for k iterations of the 8 modality."@en ;
    askg-onto:inSentence "We will write 8k (k times ago), for k iterations of the 8 modality."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-8_modality,
        askg-data:Entity-8k,
        askg-data:Entity-k,
        askg-data:Entity-k_iterations .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-544 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "denote the set of reward formulae IIJ a new formula Reg(¢, s) called the regression of <jJ through s."@en ;
    askg-onto:inSentence "denote the set of reward formulae IIJ a new formula Reg(¢, s) called the regression of <jJ through s."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-regression_of_jj_through_s,
        askg-data:Entity-reward_formulae_iij .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-545 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Regression has the property that <jJ is true of a finite sequence f(i) ending with ri = s iffReg(<jJ, s) is true of the prefix r ( i - 1)."@en ;
    askg-onto:inSentence "Regression has the property that <jJ is true of a finite sequence f(i) ending with ri = s iffReg(<jJ, s) is true of the prefix r ( i - 1)."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-finite_sequence_fi_ending_with_ri__s,
        askg-data:Entity-prefix_r__i_-_1,
        askg-data:Entity-regjj_s,
        askg-data:Entity-regression .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-54-Sentence-546 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "That is, Reg(¢, s) represents what must have been true previously for <jJ to be true now."@en ;
    askg-onto:inSentence "That is, Reg(¢, s) represents what must have been true previously for <jJ to be true now."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reg_s,
        askg-data:Entity-what_must_have_been_true_previously_for_jj_to_be_true_now .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "The translation exploits the PLTL representation of rewards as follows. Each e-state in the generated MOP is labelled with a set 1Ji ) of subformulae of the reward formulae in (and their negations)? The subformulae in \\)i must be ( 1) true of the paths leading to the e-state, and (2) sufficient to determine the current truth of all reward formulae in , as this is needed to compute the current reward."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55-Sentence-551,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55-Sentence-552,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55-Sentence-553 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55-Sentence-551 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The translation exploits the PLTL representation of rewards as follows."@en ;
    askg-onto:inSentence "The translation exploits the PLTL representation of rewards as follows."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltl_representation_of_rewards,
        askg-data:Entity-translation .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55-Sentence-552 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Each e-state in the generated MOP is labelled with a set 1Ji ) of subformulae of the reward formulae in (and their negations)?"@en ;
    askg-onto:inSentence "Each e-state in the generated MOP is labelled with a set 1Ji ) of subformulae of the reward formulae in (and their negations)?"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-mop,
        askg-data:Entity-reward_formulae,
        askg-data:Entity-subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-55-Sentence-553 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The subformulae in \\)i must be ( 1) true of the paths leading to the e-state, and (2) sufficient to determine the current truth of all reward formulae in , as this is needed to compute the current reward."@en ;
    askg-onto:inSentence "The subformulae in \\)i must be ( 1) true of the paths leading to the e-state, and (2) sufficient to determine the current truth of all reward formulae in , as this is needed to compute the current reward."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_reward,
        askg-data:Entity-current_truth_of_all_reward_formulae,
        askg-data:Entity-paths_leading_to_the_e-state,
        askg-data:Entity-subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "Ideally the \\)is should also be (3) small enough to enable just that, i.e. they should not contain subformulae which draw history distinctions which are irrelevant to determining the reward at one point or another. Note however that in the worst-case, the number of distinctions needed, even in the minimal equivalent MOP, may be exponential in IIII· This happens for instance with the formula 8k <jJ, which requires k additional bits of information memorising the truth of <P over the last k steps."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56-Sentence-561,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56-Sentence-562,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56-Sentence-563 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56-Sentence-561 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Ideally the \\)is should also be (3) small enough to enable just that, i.e."@en ;
    askg-onto:inSentence "Ideally the \\)is should also be (3) small enough to enable just that, i.e."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-is,
        askg-data:Entity-small_enough .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56-Sentence-562 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "they should not contain subformulae which draw history distinctions which are irrelevant to determining the reward at one point or another."@en ;
    askg-onto:inSentence "they should not contain subformulae which draw history distinctions which are irrelevant to determining the reward at one point or another."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-history_distinctions,
        askg-data:Entity-one_point_or_another,
        askg-data:Entity-reward,
        askg-data:Entity-subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-56-Sentence-563 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Note however that in the worst-case, the number of distinctions needed, even in the minimal equivalent MOP, may be exponential in IIII· This happens for instance with the formula 8k <jJ, which requires k additional bits of information memorising the truth of <P over the last k steps."@en ;
    askg-onto:inSentence "Note however that in the worst-case, the number of distinctions needed, even in the minimal equivalent MOP, may be exponential in IIII· This happens for instance with the formula 8k <jJ, which requires k additional bits of information memorising the truth of <P over the last k steps."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formula_8k_jj,
        askg-data:Entity-k_additional_bits_of_information .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "For the choice of the 1Jis, [Bacchus et al., 1996] considers two cases. In the simple case, which we call PLTLSIM, an MOP obeying properties (I) and (2) is produced by simply labelling each e-state with the set of all subformulae in Sub( ) which are true of the sequence leading to that estate. This MOP is generated forward, starting from the initial e-state labelled with s0 and with the set 1Ji0 ) of all subformulae which are true of the sequence (s0). The successors of any e-state labelled by NMRDP state s and subformula set \\)i are generated as follows: each of them is labelled by a successor s' of s in the NMRDP and by the set of subformulae { ¢' E Sub( ) I 1Ji f= Reg(¢', s')}."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-571,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-572,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-573,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-574 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-571 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For the choice of the 1Jis, [Bacchus et al., 1996] considers two cases."@en ;
    askg-onto:inSentence "For the choice of the 1Jis, [Bacchus et al., 1996] considers two cases."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-two_cases .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-572 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In the simple case, which we call PLTLSIM, an MOP obeying properties (I) and (2) is produced by simply labelling each e-state with the set of all subformulae in Sub( ) which are true of the sequence leading to that estate."@en ;
    askg-onto:inSentence "In the simple case, which we call PLTLSIM, an MOP obeying properties (I) and (2) is produced by simply labelling each e-state with the set of all subformulae in Sub( ) which are true of the sequence leading to that estate."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-mop,
        askg-data:Entity-pltlsim,
        askg-data:Entity-properties_i_and_2,
        askg-data:Entity-sequence_leading_to_that_estate,
        askg-data:Entity-set_of_all_subformulae_in_sub_ .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-573 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "This MOP is generated forward, starting from the initial e-state labelled with s0 and with the set 1Ji0 ) of all subformulae which are true of the sequence (s0)."@en ;
    askg-onto:inSentence "This MOP is generated forward, starting from the initial e-state labelled with s0 and with the set 1Ji0 ) of all subformulae which are true of the sequence (s0)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-initial_e-state,
        askg-data:Entity-mop,
        askg-data:Entity-s0,
        askg-data:Entity-sequence_s0,
        askg-data:Entity-set_1ji0,
        askg-data:Entity-subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-57-Sentence-574 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The successors of any e-state labelled by NMRDP state s and subformula set \\)i are generated as follows: each of them is labelled by a successor s' of s in the NMRDP and by the set of subformulae { ¢' E Sub( ) I 1Ji f= Reg(¢', s')}."@en ;
    askg-onto:inSentence "The successors of any e-state labelled by NMRDP state s and subformula set \\)i are generated as follows: each of them is labelled by a successor s' of s in the NMRDP and by the set of subformulae { ¢' E Sub( ) I 1Ji f= Reg(¢', s')}."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-_e_sub_,
        askg-data:Entity-e-state,
        askg-data:Entity-nmrdp_state_s,
        askg-data:Entity-reg_s,
        askg-data:Entity-subformula_set_i,
        askg-data:Entity-subformulae,
        askg-data:Entity-successor_s,
        askg-data:Entity-successors_of_any_e-state .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Unfortunately, this simple MOP is far from minimal. Although it could be postprocessed for minimisation before the MOP solution method is invoked, the above expansion may still constitute a serious bottleneck. Therefore, [Bacchus et al., 1996] considers a more complex two-phase translation, which we call PLTLMIN, capable of producing an MOP also satisfying property (3). Here, a preprocessing phase iterates over all states in S, and computes, for each state s, a set l(s) of subformulae, where the function l is the solution of the fixpoint equation l(s) = { U {Reg(¢',s')} I¢' E l(s'),s' is a successor ofs}."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-581,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-582,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-583,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-584 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-581 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Unfortunately, this simple MOP is far from minimal."@en ;
    askg-onto:inSentence "Unfortunately, this simple MOP is far from minimal."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mop,
        askg-data:Entity-simple_mop .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-582 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Although it could be postprocessed for minimisation before the MOP solution method is invoked, the above expansion may still constitute a serious bottleneck."@en ;
    askg-onto:inSentence "Although it could be postprocessed for minimisation before the MOP solution method is invoked, the above expansion may still constitute a serious bottleneck."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bottleneck,
        askg-data:Entity-expansion,
        askg-data:Entity-mop_solution_method .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-583 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Therefore, [Bacchus et al., 1996] considers a more complex two-phase translation, which we call PLTLMIN, capable of producing an MOP also satisfying property (3)."@en ;
    askg-onto:inSentence "Therefore, [Bacchus et al., 1996] considers a more complex two-phase translation, which we call PLTLMIN, capable of producing an MOP also satisfying property (3)."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-mop,
        askg-data:Entity-pltlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-58-Sentence-584 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Here, a preprocessing phase iterates over all states in S, and computes, for each state s, a set l(s) of subformulae, where the function l is the solution of the fixpoint equation l(s) = { U {Reg(¢',s')} I¢' E l(s'),s' is a successor ofs}."@en ;
    askg-onto:inSentence "Here, a preprocessing phase iterates over all states in S, and computes, for each state s, a set l(s) of subformulae, where the function l is the solution of the fixpoint equation l(s) = { U {Reg(¢',s')} I¢' E l(s'),s' is a successor ofs}."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fixpoint_equation,
        askg-data:Entity-ls,
        askg-data:Entity-s .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "Only subformulae in l ( s) will be candidates for inclusion in the sets labelling the respective e-states labelled with s. That is, the subsequent expansion phase will be as above, but taking 1Jio ) and¢' ). As the subformulae in l ( s) are exactly those that are relevant to the way actual execution sequences starting from e-states labelled with s are rewarded, this leads the expansion phase to produce a minimal equivalent MOP. In the worst case, computing this l requires a space, and a number of iterations through S, exponential in 1111- Hence the question arises of whether the gain during the expansion phase is worth the extra complexity of the preprocessing phase. This is one of the questions we will try to answer."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-591,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-592,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-593,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-594,
        askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-595 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-591 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Only subformulae in l ( s) will be candidates for inclusion in the sets labelling the respective e-states labelled with s."@en ;
    askg-onto:inSentence "Only subformulae in l ( s) will be candidates for inclusion in the sets labelling the respective e-states labelled with s."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-sets_labelling_the_respective_e-states,
        askg-data:Entity-subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-592 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "That is, the subsequent expansion phase will be as above, but taking 1Jio ) and¢' )."@en ;
    askg-onto:inSentence "That is, the subsequent expansion phase will be as above, but taking 1Jio ) and¢' )."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-1jio .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-593 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As the subformulae in l ( s) are exactly those that are relevant to the way actual execution sequences starting from e-states labelled with s are rewarded, this leads the expansion phase to produce a minimal equivalent MOP."@en ;
    askg-onto:inSentence "As the subformulae in l ( s) are exactly those that are relevant to the way actual execution sequences starting from e-states labelled with s are rewarded, this leads the expansion phase to produce a minimal equivalent MOP."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-actual_execution_sequences,
        askg-data:Entity-e-states,
        askg-data:Entity-expansion_phase,
        askg-data:Entity-minimal_equivalent_mop,
        askg-data:Entity-s,
        askg-data:Entity-subformulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-594 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "In the worst case, computing this l requires a space, and a number of iterations through S, exponential in 1111- Hence the question arises of whether the gain during the expansion phase is worth the extra complexity of the preprocessing phase."@en ;
    askg-onto:inSentence "In the worst case, computing this l requires a space, and a number of iterations through S, exponential in 1111- Hence the question arises of whether the gain during the expansion phase is worth the extra complexity of the preprocessing phase."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computing_l,
        askg-data:Entity-expansion_phase,
        askg-data:Entity-extra_complexity,
        askg-data:Entity-gain,
        askg-data:Entity-number_of_iterations,
        askg-data:Entity-preprocessing_phase,
        askg-data:Entity-s,
        askg-data:Entity-space .

askg-data:Paper-0ecbd8a3379fdc37-Section-5-Paragraph-59-Sentence-595 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This is one of the questions we will try to answer."@en ;
    askg-onto:inSentence "This is one of the questions we will try to answer."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-questions,
        askg-data:Entity-we .

askg-data:Paper-0ecbd8a3379fdc37-Section-6 a askg-onto:Section ;
    rdfs:label "Section 6"@en ;
    domo:Text "2.3 Pltl Struct"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-63,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-64,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65 ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The approach in [Bacchus et al., 1997], which we call PLTLSTR, targets structured MOP representations: the transition model, policies, reward and value functions are represented in a compact form, e.g. as trees or algebraic decision diagrams (ADDs). [Boutilier et al., 1995; Hoey et al., 1999]. For instance, the probability of a given proposition (state variable) being true after the execution of an action is specified by a tree whose leaves are labelled with probabilities, whose nodes are labelled with the state variables on whose previous values the given variable depends, and whose arcs are labelled by the possible previous values (Tor _i) of these variables. The translation amounts to augmenting the compact representation of the transition model with new temporal variables together with the compact representation of (I) their dynamics, e.g. as a tree over the previous values of the relevant variables, and (2) of the non-Markovian reward function in terms of the variables' current values. Then, structured solution methods such as structured policy iteration or the SPUDD algorithm are run on the resulting structured MOP. Neither the translation nor the solution methods explicitly enumerates states."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-611,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-612,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-613,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-614,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-615,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-616,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-617,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-618 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-611 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The approach in [Bacchus et al., 1997], which we call PLTLSTR, targets structured MOP representations: the transition model, policies, reward and value functions are represented in a compact form, e.g."@en ;
    askg-onto:inSentence "The approach in [Bacchus et al., 1997], which we call PLTLSTR, targets structured MOP representations: the transition model, policies, reward and value functions are represented in a compact form, e.g."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al,
        askg-data:Entity-mop_representations,
        askg-data:Entity-pltlstr,
        askg-data:Entity-policies,
        askg-data:Entity-reward_and_value_functions,
        askg-data:Entity-transition_model .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-612 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "as trees or algebraic decision diagrams (ADDs)."@en ;
    askg-onto:inSentence "as trees or algebraic decision diagrams (ADDs)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algebraic_decision_diagrams,
        askg-data:Entity-trees .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-613 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "[Boutilier et al., 1995; Hoey et al., 1999]."@en ;
    askg-onto:inSentence "[Boutilier et al., 1995; Hoey et al., 1999]."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-article,
        askg-data:Entity-boutilier_et_al,
        askg-data:Entity-hoey_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-614 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For instance, the probability of a given proposition (state variable) being true after the execution of an action is specified by a tree whose leaves are labelled with probabilities, whose nodes are labelled with the state variables on whose previous values the given variable depends, and whose arcs are labelled by the possible previous values (Tor _i) of these variables."@en ;
    askg-onto:inSentence "For instance, the probability of a given proposition (state variable) being true after the execution of an action is specified by a tree whose leaves are labelled with probabilities, whose nodes are labelled with the state variables on whose previous values the given variable depends, and whose arcs are labelled by the possible previous values (Tor _i) of these variables."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-arcs,
        askg-data:Entity-leaves,
        askg-data:Entity-nodes,
        askg-data:Entity-possible_previous_values,
        askg-data:Entity-previous_values,
        askg-data:Entity-probabilities,
        askg-data:Entity-proposition,
        askg-data:Entity-state_variables,
        askg-data:Entity-tree .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-615 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "The translation amounts to augmenting the compact representation of the transition model with new temporal variables together with the compact representation of (I) their dynamics, e.g."@en ;
    askg-onto:inSentence "The translation amounts to augmenting the compact representation of the transition model with new temporal variables together with the compact representation of (I) their dynamics, e.g."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-compact_representation_with_new_temporal_variables,
        askg-data:Entity-transition_model .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-616 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "as a tree over the previous values of the relevant variables, and (2) of the non-Markovian reward function in terms of the variables' current values."@en ;
    askg-onto:inSentence "as a tree over the previous values of the relevant variables, and (2) of the non-Markovian reward function in terms of the variables' current values."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_values,
        askg-data:Entity-non-markovian_reward_function,
        askg-data:Entity-reward_function,
        askg-data:Entity-variables .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-617 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Then, structured solution methods such as structured policy iteration or the SPUDD algorithm are run on the resulting structured MOP."@en ;
    askg-onto:inSentence "Then, structured solution methods such as structured policy iteration or the SPUDD algorithm are run on the resulting structured MOP."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-spudd_algorithm,
        askg-data:Entity-structured_mop,
        askg-data:Entity-structured_policy_iteration,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-61-Sentence-618 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Neither the translation nor the solution methods explicitly enumerates states."@en ;
    askg-onto:inSentence "Neither the translation nor the solution methods explicitly enumerates states."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-solution_methods,
        askg-data:Entity-states,
        askg-data:Entity-translation .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The PLTLSTR translation can be seen as a symbolic version of PLTLSIM. The set T of added temporal variables contains the purely temporal subformulae PTSub( ) of the reward formulae in , to which the 8 modality is prepended (unless already there): T = { 81/! I ¢ E PTSub( ), ¢ ¥ 81/!'} U { 81/! I 81/! E PTSub()}. Thus, by repeatedly applying the equivalence ¢1 S ¢2 = ¢2 V (¢1 A 0(r/>l S ¢2)) to any subformula in PTSub( ), we can express its current value, and hence that of reward formulae, as a function"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-621,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-622,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-623,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-624,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-625,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-626 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-621 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The PLTLSTR translation can be seen as a symbolic version of PLTLSIM."@en ;
    askg-onto:inSentence "The PLTLSTR translation can be seen as a symbolic version of PLTLSIM."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlsim,
        askg-data:Entity-pltlstr_translation .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-622 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The set T of added temporal variables contains the purely temporal subformulae PTSub( ) of the reward formulae in , to which the 8 modality is prepended (unless already there): T = { 81/!"@en ;
    askg-onto:inSentence "The set T of added temporal variables contains the purely temporal subformulae PTSub( ) of the reward formulae in , to which the 8 modality is prepended (unless already there): T = { 81/!"^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-reward_formulae,
        askg-data:Entity-t,
        askg-data:Entity-temporal_subformulae_ptsub_,
        askg-data:Entity-temporal_variables .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-623 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "I ¢ E PTSub( ), ¢ ¥ 81/!'} U { 81/!"@en ;
    askg-onto:inSentence "I ¢ E PTSub( ), ¢ ¥ 81/!'} U { 81/!"^^xsd:string ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-624 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "I 81/!"@en ;
    askg-onto:inSentence "I 81/!"^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-81,
        askg-data:Entity-i .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-625 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "E PTSub()}."@en ;
    askg-onto:inSentence "E PTSub()}."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e_ptsub,
        askg-data:Entity-function .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-62-Sentence-626 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "Thus, by repeatedly applying the equivalence ¢1 S ¢2 = ¢2 V (¢1 A 0(r/>l S ¢2)) to any subformula in PTSub( ), we can express its current value, and hence that of reward formulae, as a function"@en ;
    askg-onto:inSentence "Thus, by repeatedly applying the equivalence ¢1 S ¢2 = ¢2 V (¢1 A 0(r/>l S ¢2)) to any subformula in PTSub( ), we can express its current value, and hence that of reward formulae, as a function"^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-function,
        askg-data:Entity-ptsub,
        askg-data:Entity-reward_formulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-63 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "2The size II <P II of a set of reward formulae <P is measured as the sum of the lengths of the formulae in <P."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-63-Sentence-631 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-63-Sentence-631 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "2The size II <P II of a set of reward formulae <P is measured as the sum of the lengths of the formulae in <P."@en ;
    askg-onto:inSentence "2The size II <P II of a set of reward formulae <P is measured as the sum of the lengths of the formulae in <P."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-set_of_reward_formulae,
        askg-data:Entity-the_sum_of_the_lengths_of_the_formulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-64 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "3Given a set F of formulae, we write F for FU{ •f If E F} of the current values of formulae in T and state variables, as required by the compact representation of the transition model."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-64-Sentence-641 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-64-Sentence-641 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "3Given a set F of formulae, we write F for FU{ •f If E F} of the current values of formulae in T and state variables, as required by the compact representation of the transition model."@en ;
    askg-onto:inSentence "3Given a set F of formulae, we write F for FU{ •f If E F} of the current values of formulae in T and state variables, as required by the compact representation of the transition model."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_values_of_formulae_in_t,
        askg-data:Entity-f,
        askg-data:Entity-transition_model .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "As with PLTLSIM, the underlying MOP is far from minimal-the encoded history features do not even vary from one state to the next. However, size is not as problematic as with state-based approaches, because structured solution methods do not enumerate states and are able to dynamically ignore some of the variables that become irrelevant during policy construction. For instance, when solving the MOP, they may be able to determine that some temporal variables have become irrelevant because the situation they track, although possible in principle, is too risky to be realised under a good policy. This dynamic analysis of rewards contrasts with the static analysis in [Bacchus et a!., 1996] which must encode enough history to determine the reward at all reachable futures under any policy. One question that arises is that of the circumstances under which this analysis of irrelevance by structured solution methods, especially the dynamic aspects, is really effective. This is another question this paper will try to address."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-651,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-652,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-653,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-654,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-655,
        askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-656 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-651 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "As with PLTLSIM, the underlying MOP is far from minimal-the encoded history features do not even vary from one state to the next."@en ;
    askg-onto:inSentence "As with PLTLSIM, the underlying MOP is far from minimal-the encoded history features do not even vary from one state to the next."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mop,
        askg-data:Entity-pltlsim .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-652 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "However, size is not as problematic as with state-based approaches, because structured solution methods do not enumerate states and are able to dynamically ignore some of the variables that become irrelevant during policy construction."@en ;
    askg-onto:inSentence "However, size is not as problematic as with state-based approaches, because structured solution methods do not enumerate states and are able to dynamically ignore some of the variables that become irrelevant during policy construction."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-some_of_the_variables,
        askg-data:Entity-states,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-653 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For instance, when solving the MOP, they may be able to determine that some temporal variables have become irrelevant because the situation they track, although possible in principle, is too risky to be realised under a good policy."@en ;
    askg-onto:inSentence "For instance, when solving the MOP, they may be able to determine that some temporal variables have become irrelevant because the situation they track, although possible in principle, is too risky to be realised under a good policy."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mop,
        askg-data:Entity-policy,
        askg-data:Entity-risk,
        askg-data:Entity-situation,
        askg-data:Entity-temporal_variables .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-654 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "This dynamic analysis of rewards contrasts with the static analysis in [Bacchus et a!., 1996] which must encode enough history to determine the reward at all reachable futures under any policy."@en ;
    askg-onto:inSentence "This dynamic analysis of rewards contrasts with the static analysis in [Bacchus et a!., 1996] which must encode enough history to determine the reward at all reachable futures under any policy."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bacchus_et_al_1996,
        askg-data:Entity-dynamic_analysis_of_rewards,
        askg-data:Entity-static_analysis .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-655 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "One question that arises is that of the circumstances under which this analysis of irrelevance by structured solution methods, especially the dynamic aspects, is really effective."@en ;
    askg-onto:inSentence "One question that arises is that of the circumstances under which this analysis of irrelevance by structured solution methods, especially the dynamic aspects, is really effective."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis,
        askg-data:Entity-dynamic_aspects,
        askg-data:Entity-effective,
        askg-data:Entity-irrelevance,
        askg-data:Entity-structured_solution_methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-6-Paragraph-65-Sentence-656 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "This is another question this paper will try to address."@en ;
    askg-onto:inSentence "This is another question this paper will try to address."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-paper,
        askg-data:Entity-question .

askg-data:Paper-0ecbd8a3379fdc37-Section-7 a askg-onto:Section ;
    rdfs:label "Section 7"@en ;
    domo:Text "2.4 Fltl"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-73,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-74,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-76,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77 ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:level "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The approach in [Thiebaux et a!., 2002], which we call FL TL, considers state-based representations of the equivalent MOP and targets heuristic forward search solution methods such as LAO* or labelled RTDP. Starting from a compact representation of the MOP and an admissible heuristic, these methods need only explicitly generate and explore a fraction of the state space to produce an optimal solution. To gain maximum benefit from these methods, the translation into MOP must avoid generating states and e-states that the method would not generate. Therefore, the FLTL translation operates entirely on-line: the solution method is given full control of which parts of the MOP are generated and explored. This contrasts with PLTLMIN, which requires an off-line preprocessing phase iterating through all states in S."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-711,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-712,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-713,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-714,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-715 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-711 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The approach in [Thiebaux et a!., 2002], which we call FL TL, considers state-based representations of the equivalent MOP and targets heuristic forward search solution methods such as LAO* or labelled RTDP."@en ;
    askg-onto:inSentence "The approach in [Thiebaux et a!., 2002], which we call FL TL, considers state-based representations of the equivalent MOP and targets heuristic forward search solution methods such as LAO* or labelled RTDP."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-heuristic_forward_search_solution_methods,
        askg-data:Entity-labelled_rtdp,
        askg-data:Entity-lao,
        askg-data:Entity-state-based_representations,
        askg-data:Entity-thiebaux_et_al_2002 .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-712 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Starting from a compact representation of the MOP and an admissible heuristic, these methods need only explicitly generate and explore a fraction of the state space to produce an optimal solution."@en ;
    askg-onto:inSentence "Starting from a compact representation of the MOP and an admissible heuristic, these methods need only explicitly generate and explore a fraction of the state space to produce an optimal solution."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-admissible_heuristic,
        askg-data:Entity-compact_representation,
        askg-data:Entity-methods,
        askg-data:Entity-mop,
        askg-data:Entity-optimal_solution,
        askg-data:Entity-state_space .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-713 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "To gain maximum benefit from these methods, the translation into MOP must avoid generating states and e-states that the method would not generate."@en ;
    askg-onto:inSentence "To gain maximum benefit from these methods, the translation into MOP must avoid generating states and e-states that the method would not generate."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-states,
        askg-data:Entity-methods,
        askg-data:Entity-mop,
        askg-data:Entity-states .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-714 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Therefore, the FLTL translation operates entirely on-line: the solution method is given full control of which parts of the MOP are generated and explored."@en ;
    askg-onto:inSentence "Therefore, the FLTL translation operates entirely on-line: the solution method is given full control of which parts of the MOP are generated and explored."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_translation,
        askg-data:Entity-mop,
        askg-data:Entity-on-line,
        askg-data:Entity-solution_method .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-71-Sentence-715 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This contrasts with PLTLMIN, which requires an off-line preprocessing phase iterating through all states in S."@en ;
    askg-onto:inSentence "This contrasts with PLTLMIN, which requires an off-line preprocessing phase iterating through all states in S."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-all_states_in_s,
        askg-data:Entity-an_off-line_preprocessing_phase,
        askg-data:Entity-off-line_preprocessing_phase,
        askg-data:Entity-pltlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "[Thiebaux et a!., 2002] notes that when using PLTL to specify rewards, there does not seem to be a way of designing an on-line translation producing an MDP of acceptable size.4 Instead, [Thiebaux et a!., 2002] adopts a variant of LTL with .fUture operators called $FLTL. The syntax is that of negation normal form propositional logic augmented with the constant $ (rewarded) and the operators 0 (next) and U (weak until). As in PLTL, a $FLTL formula represents a subset of S*- see [Thiebaux et a!., 2002] for a formal semantics 5. But given the forward looking character of the language, it is best to see a formula as a recipe for distributing rewards, starting from the current state (i.e., the first state of the rest of the sequence). Informally,$ means that we get rewarded now. 0¢ means that ¢ holds in the next state, and ¢1 U ¢2 means that ¢1 will be true from now on until ¢2 becomes true, if ever. From U , one can define 0¢ = ¢ U .l, meaning that ¢ will always be true."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-721,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-722,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-723,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-724,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-725,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-726,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-727 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-721 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "[Thiebaux et a!., 2002] notes that when using PLTL to specify rewards, there does not seem to be a way of designing an on-line translation producing an MDP of acceptable size.4 Instead, [Thiebaux et a!., 2002] adopts a variant of LTL with .fUture operators called $FLTL."@en ;
    askg-onto:inSentence "[Thiebaux et a!., 2002] notes that when using PLTL to specify rewards, there does not seem to be a way of designing an on-line translation producing an MDP of acceptable size.4 Instead, [Thiebaux et a!., 2002] adopts a variant of LTL with .fUture operators called $FLTL."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-future_operators,
        askg-data:Entity-ltl,
        askg-data:Entity-pltl,
        askg-data:Entity-thiebaux_et_al_2002 .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-722 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The syntax is that of negation normal form propositional logic augmented with the constant $ (rewarded) and the operators 0 (next) and U (weak until)."@en ;
    askg-onto:inSentence "The syntax is that of negation normal form propositional logic augmented with the constant $ (rewarded) and the operators 0 (next) and U (weak until)."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-0,
        askg-data:Entity-constant,
        askg-data:Entity-negation_normal_form_propositional_logic,
        askg-data:Entity-operator,
        askg-data:Entity-syntax,
        askg-data:Entity-u .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-723 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "As in PLTL, a $FLTL formula represents a subset of S*- see [Thiebaux et a!., 2002] for a formal semantics 5."@en ;
    askg-onto:inSentence "As in PLTL, a $FLTL formula represents a subset of S*- see [Thiebaux et a!., 2002] for a formal semantics 5."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_formula,
        askg-data:Entity-formal_semantics,
        askg-data:Entity-subset_of_s,
        askg-data:Entity-thiebaux_et_al .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-724 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "But given the forward looking character of the language, it is best to see a formula as a recipe for distributing rewards, starting from the current state (i.e., the first state of the rest of the sequence)."@en ;
    askg-onto:inSentence "But given the forward looking character of the language, it is best to see a formula as a recipe for distributing rewards, starting from the current state (i.e., the first state of the rest of the sequence)."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-current_state,
        askg-data:Entity-formula,
        askg-data:Entity-recipe,
        askg-data:Entity-rewards,
        askg-data:Entity-sequence .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-725 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Informally,$ means that we get rewarded now."@en ;
    askg-onto:inSentence "Informally,$ means that we get rewarded now."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-rewarded_now .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-726 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "0¢ means that ¢ holds in the next state, and ¢1 U ¢2 means that ¢1 will be true from now on until ¢2 becomes true, if ever."@en ;
    askg-onto:inSentence "0¢ means that ¢ holds in the next state, and ¢1 U ¢2 means that ¢1 will be true from now on until ¢2 becomes true, if ever."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-1,
        askg-data:Entity-2,
        askg-data:Entity-next_state .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-72-Sentence-727 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "From U , one can define 0¢ = ¢ U .l, meaning that ¢ will always be true."@en ;
    askg-onto:inSentence "From U , one can define 0¢ = ¢ U .l, meaning that ¢ will always be true."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-0___u_l,
        askg-data:Entity-u .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-73 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "E.g, O(c-> 0(¢-> 0$) means that following a command c, we will be rewarded from the moment ¢ holds onwards."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-73-Sentence-731 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-73-Sentence-731 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "E.g, O(c-> 0(¢-> 0$) means that following a command c, we will be rewarded from the moment ¢ holds onwards."@en ;
    askg-onto:inSentence "E.g, O(c-> 0(¢-> 0$) means that following a command c, we will be rewarded from the moment ¢ holds onwards."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-command_c,
        askg-data:Entity-rewarded_from_the_moment__holds_onwards .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-74 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "..,q; U ( ¢ 1\\ $) means that we will be rewarded the first time ¢ becomes true. As with PLTL, a reward function is represented by a set of pairs consisting of a formula and a real."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-74-Sentence-741,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-74-Sentence-742 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-74-Sentence-741 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "..,q; U ( ¢ 1\\ $) means that we will be rewarded the first time ¢ becomes true."@en ;
    askg-onto:inSentence "..,q; U ( ¢ 1\\ $) means that we will be rewarded the first time ¢ becomes true."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-rewarded .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-74-Sentence-742 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "As with PLTL, a reward function is represented by a set of pairs consisting of a formula and a real."@en ;
    askg-onto:inSentence "As with PLTL, a reward function is represented by a set of pairs consisting of a formula and a real."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-a_formula,
        askg-data:Entity-a_real,
        askg-data:Entity-a_set_of_pairs,
        askg-data:Entity-reward_function,
        askg-data:Entity-set_of_pairs .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "The translation is based on a variant of progression [Bacchus and Kabanza, 2000], which is to future-oriented logics what regression is to past-oriented ones: $Prog( ¢, s) tells us what must hold next for ¢ to hold now, at the current state s. Each e-state in the equivalent MOP is labelled by a state of the NMRDP and by a set of $FLTL formulae. The initial e-state is labelled with so and the set is labelled by a successor s' of s in the NMRDP and by the set {$Prog(¢, s) I ¢ E } of the progressions of the formulae in through s. Although the MOP produced that way is not minimal, it satisfies a weaker but still interesting notion of minimality, called blind minimality. Intuitively, a blind minimal equivalent MOP is the smallest equivalent MOP achievable by any on-line translation."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-751,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-752,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-753,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-754,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-755 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-751 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The translation is based on a variant of progression [Bacchus and Kabanza, 2000], which is to future-oriented logics what regression is to past-oriented ones: $Prog( ¢, s) tells us what must hold next for ¢ to hold now, at the current state s."@en ;
    askg-onto:inSentence "The translation is based on a variant of progression [Bacchus and Kabanza, 2000], which is to future-oriented logics what regression is to past-oriented ones: $Prog( ¢, s) tells us what must hold next for ¢ to hold now, at the current state s."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-_to_hold_now,
        askg-data:Entity-future-oriented_logics,
        askg-data:Entity-past-oriented_ones,
        askg-data:Entity-prog_s,
        askg-data:Entity-progression,
        askg-data:Entity-regression .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-752 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Each e-state in the equivalent MOP is labelled by a state of the NMRDP and by a set of $FLTL formulae."@en ;
    askg-onto:inSentence "Each e-state in the equivalent MOP is labelled by a state of the NMRDP and by a set of $FLTL formulae."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-set_of_fltl_formulae,
        askg-data:Entity-state_of_the_nmrdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-753 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "The initial e-state is labelled with so and the set is labelled by a successor s' of s in the NMRDP and by the set {$Prog(¢, s) I ¢ E } of the progressions of the formulae in through s."@en ;
    askg-onto:inSentence "The initial e-state is labelled with so and the set is labelled by a successor s' of s in the NMRDP and by the set {$Prog(¢, s) I ¢ E } of the progressions of the formulae in through s."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-e-state,
        askg-data:Entity-formulae,
        askg-data:Entity-prog_s_i__e_,
        askg-data:Entity-s,
        askg-data:Entity-set,
        askg-data:Entity-so,
        askg-data:Entity-successor_s_of_s .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-754 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Although the MOP produced that way is not minimal, it satisfies a weaker but still interesting notion of minimality, called blind minimality."@en ;
    askg-onto:inSentence "Although the MOP produced that way is not minimal, it satisfies a weaker but still interesting notion of minimality, called blind minimality."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-mop .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-75-Sentence-755 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Intuitively, a blind minimal equivalent MOP is the smallest equivalent MOP achievable by any on-line translation."@en ;
    askg-onto:inSentence "Intuitively, a blind minimal equivalent MOP is the smallest equivalent MOP achievable by any on-line translation."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimal_equivalent_mop,
        askg-data:Entity-smallest_equivalent_mop_achievable_by_any_on-line_translation .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-76 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "With FL TL, the structure of the reward formulae is preserved by the translation and exploited by progression."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-76-Sentence-761 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-76-Sentence-761 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "With FL TL, the structure of the reward formulae is preserved by the translation and exploited by progression."@en ;
    askg-onto:inSentence "With FL TL, the structure of the reward formulae is preserved by the translation and exploited by progression."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-progression,
        askg-data:Entity-structure_of_the_reward_formulae,
        askg-data:Entity-translation .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "This contrasts with PLTLSIM which completely loses this structure by considering subformulae individually. One of the purposes of the preprocessing phase in PLTLMIN is to recover this structure. One question that arises is whether the simplicity of the FL TL translation combined with the power of heuristic search compensates for the weakness of blind minimality, or whether the benefits of true minimality as in PLTLMIN outweigh the cost of the preprocessing phase. Furthermore, with FLTL, as with PLTLSTR, the analysis of rewards is performed dynamically, as a function of how the search proceeds. Another question we will try to answer is whether the respective dynamic analyses are equally powerful."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-771,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-772,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-773,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-774,
        askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-775 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-771 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "This contrasts with PLTLSIM which completely loses this structure by considering subformulae individually."@en ;
    askg-onto:inSentence "This contrasts with PLTLSIM which completely loses this structure by considering subformulae individually."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlsim,
        askg-data:Entity-this_structure .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-772 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "One of the purposes of the preprocessing phase in PLTLMIN is to recover this structure."@en ;
    askg-onto:inSentence "One of the purposes of the preprocessing phase in PLTLMIN is to recover this structure."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-preprocessing_phase .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-773 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "One question that arises is whether the simplicity of the FL TL translation combined with the power of heuristic search compensates for the weakness of blind minimality, or whether the benefits of true minimality as in PLTLMIN outweigh the cost of the preprocessing phase."@en ;
    askg-onto:inSentence "One question that arises is whether the simplicity of the FL TL translation combined with the power of heuristic search compensates for the weakness of blind minimality, or whether the benefits of true minimality as in PLTLMIN outweigh the cost of the preprocessing phase."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-blind_minimality,
        askg-data:Entity-concept,
        askg-data:Entity-fl_tl_translation,
        askg-data:Entity-heuristic_search,
        askg-data:Entity-method,
        askg-data:Entity-pltlmin,
        askg-data:Entity-preprocessing_phase,
        askg-data:Entity-true_minimality .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-774 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Furthermore, with FLTL, as with PLTLSTR, the analysis of rewards is performed dynamically, as a function of how the search proceeds."@en ;
    askg-onto:inSentence "Furthermore, with FLTL, as with PLTLSTR, the analysis of rewards is performed dynamically, as a function of how the search proceeds."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-analysis_of_rewards,
        askg-data:Entity-fltl,
        askg-data:Entity-pltlstr,
        askg-data:Entity-search .

askg-data:Paper-0ecbd8a3379fdc37-Section-7-Paragraph-77-Sentence-775 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "Another question we will try to answer is whether the respective dynamic analyses are equally powerful."@en ;
    askg-onto:inSentence "Another question we will try to answer is whether the respective dynamic analyses are equally powerful."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamic_analyses,
        askg-data:Entity-powerful .

askg-data:Paper-0ecbd8a3379fdc37-Section-8 a askg-onto:Section ;
    rdfs:label "Section 8"@en ;
    domo:Text "3 Thenmrdpplanner"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-81,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-83,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-89 ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-81 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "The first step towards a decent comparison of the different approaches is to have a framework that includes them all. The non-Markovian reward decision process planner6, NMRDPP, provides an implementation of the approaches in a common framework, within a single system, and with a common input language."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-81-Sentence-811,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-81-Sentence-812 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-81-Sentence-811 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The first step towards a decent comparison of the different approaches is to have a framework that includes them all."@en ;
    askg-onto:inSentence "The first step towards a decent comparison of the different approaches is to have a framework that includes them all."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-different_approaches,
        askg-data:Entity-framework .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-81-Sentence-812 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The non-Markovian reward decision process planner6, NMRDPP, provides an implementation of the approaches in a common framework, within a single system, and with a common input language."@en ;
    askg-onto:inSentence "The non-Markovian reward decision process planner6, NMRDPP, provides an implementation of the approaches in a common framework, within a single system, and with a common input language."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-common_framework,
        askg-data:Entity-implementation,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-single_system .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 2"@en ;
    domo:Text "The input language enables the specification of actions, initial states, rewards, and control-knowledge. The format for the action specification is essentially the same as in the SPUDD system [Hoey et a!., 1999]. When the input is parsed, the action specification trees are converted into ADDs by the CUDD package. The reward specification is one or more formulae, each associated with a real. These"@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-821,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-822,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-823,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-824,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-825 ;
    askg-onto:index "2"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-821 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The input language enables the specification of actions, initial states, rewards, and control-knowledge."@en ;
    askg-onto:inSentence "The input language enables the specification of actions, initial states, rewards, and control-knowledge."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-input_language,
        askg-data:Entity-specification_of_actions_initial_states_rewards_and_control-knowledge .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-822 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The format for the action specification is essentially the same as in the SPUDD system [Hoey et a!., 1999]."@en ;
    askg-onto:inSentence "The format for the action specification is essentially the same as in the SPUDD system [Hoey et a!., 1999]."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_specification,
        askg-data:Entity-spudd_system .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-823 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "When the input is parsed, the action specification trees are converted into ADDs by the CUDD package."@en ;
    askg-onto:inSentence "When the input is parsed, the action specification trees are converted into ADDs by the CUDD package."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action_specification_trees,
        askg-data:Entity-adds,
        askg-data:Entity-cudd_package,
        askg-data:Entity-input .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-824 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The reward specification is one or more formulae, each associated with a real."@en ;
    askg-onto:inSentence "The reward specification is one or more formulae, each associated with a real."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-formulae,
        askg-data:Entity-real,
        askg-data:Entity-reward_specification .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-82-Sentence-825 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "These"@en ;
    askg-onto:inSentence "These"^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-concepts,
        askg-data:Entity-these .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-83 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 3"@en ;
    domo:Text "4PLTLSIM can be performed entirely on-line, but leads to a largeMDP."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-83-Sentence-831 ;
    askg-onto:index "3"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-83-Sentence-831 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "4PLTLSIM can be performed entirely on-line, but leads to a largeMDP."@en ;
    askg-onto:inSentence "4PLTLSIM can be performed entirely on-line, but leads to a largeMDP."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-4pltlsim,
        askg-data:Entity-largemdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 4"@en ;
    domo:Text "5This is more complex than the standard FLTL semantics. The interpretation of$ is not fixed: $ is made true only when needed to ensure that the formula holds (in the classical FLTL sense of the term) in every sequence of sw. For reasons of readability and space, the text above is deliberately evasive."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84-Sentence-841,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84-Sentence-842,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84-Sentence-843 ;
    askg-onto:index "4"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84-Sentence-841 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "5This is more complex than the standard FLTL semantics."@en ;
    askg-onto:inSentence "5This is more complex than the standard FLTL semantics."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl_semantics,
        askg-data:Entity-standard_fltl_semantics .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84-Sentence-842 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The interpretation of$ is not fixed: $ is made true only when needed to ensure that the formula holds (in the classical FLTL sense of the term) in every sequence of sw."@en ;
    askg-onto:inSentence "The interpretation of$ is not fixed: $ is made true only when needed to ensure that the formula holds (in the classical FLTL sense of the term) in every sequence of sw."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-,
        askg-data:Entity-every_sequence_of_sw,
        askg-data:Entity-the_formula .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-84-Sentence-843 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For reasons of readability and space, the text above is deliberately evasive."@en ;
    askg-onto:inSentence "For reasons of readability and space, the text above is deliberately evasive."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-evasive,
        askg-data:Entity-text .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 5"@en ;
    domo:Text "6http://discus.anu.edu.au/�charlesg/nmrdpp formulae are in either PLTL or $FLTL and are stored as trees by the system. Control knowledge is given in the same language as that chosen for the reward. Control knowledge formulae will have to be verified by any sequence of states feasible under the generated policies. Initial states are simply specified as part of the control knowledge or as explicit assignments to propositions."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-851,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-852,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-853,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-854 ;
    askg-onto:index "5"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-851 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "6http://discus.anu.edu.au/�charlesg/nmrdpp formulae are in either PLTL or $FLTL and are stored as trees by the system."@en ;
    askg-onto:inSentence "6http://discus.anu.edu.au/�charlesg/nmrdpp formulae are in either PLTL or $FLTL and are stored as trees by the system."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fltl,
        askg-data:Entity-formulae,
        askg-data:Entity-pltl,
        askg-data:Entity-system,
        askg-data:Entity-trees .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-852 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Control knowledge is given in the same language as that chosen for the reward."@en ;
    askg-onto:inSentence "Control knowledge is given in the same language as that chosen for the reward."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control_knowledge,
        askg-data:Entity-reward .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-853 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Control knowledge formulae will have to be verified by any sequence of states feasible under the generated policies."@en ;
    askg-onto:inSentence "Control knowledge formulae will have to be verified by any sequence of states feasible under the generated policies."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-any_sequence_of_states_feasible_under_the_generated_policies,
        askg-data:Entity-control_knowledge_formulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-85-Sentence-854 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "Initial states are simply specified as part of the control knowledge or as explicit assignments to propositions."@en ;
    askg-onto:inSentence "Initial states are simply specified as part of the control knowledge or as explicit assignments to propositions."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-explicit_assignments_to_propositions,
        askg-data:Entity-initial_states,
        askg-data:Entity-part_of_the_control_knowledge .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 6"@en ;
    domo:Text "The common framework underlying NMRDPP takes advantage of the fact that NMRDP solution methods can, in general, be divided into the distinct phases of preprocessing, expansion, and solving. The first two are optional. For PLTLSIM, preprocessing computes the set Sub( ci>) of subformulae of the reward formulae. For PLTLMIN, it also includes computing the labels l ( s) for each states. For PLTL- STR, it involves computing the set T of temporal variables as well as the ADDs for their dynamics and for the rewards."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-861,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-862,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-863,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-864,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-865 ;
    askg-onto:index "6"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-861 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "The common framework underlying NMRDPP takes advantage of the fact that NMRDP solution methods can, in general, be divided into the distinct phases of preprocessing, expansion, and solving."@en ;
    askg-onto:inSentence "The common framework underlying NMRDPP takes advantage of the fact that NMRDP solution methods can, in general, be divided into the distinct phases of preprocessing, expansion, and solving."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-common_framework,
        askg-data:Entity-distinct_phases,
        askg-data:Entity-expansion,
        askg-data:Entity-nmrdp_solution_methods,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-preprocessing,
        askg-data:Entity-solving .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-862 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "The first two are optional."@en ;
    askg-onto:inSentence "The first two are optional."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-optional,
        askg-data:Entity-the_first_two .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-863 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "For PLTLSIM, preprocessing computes the set Sub( ci>) of subformulae of the reward formulae."@en ;
    askg-onto:inSentence "For PLTLSIM, preprocessing computes the set Sub( ci>) of subformulae of the reward formulae."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-platform,
        askg-data:Entity-pltlsim,
        askg-data:Entity-preprocessing,
        askg-data:Entity-set_sub_ci_of_subformulae_of_the_reward_formulae .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-864 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "For PLTLMIN, it also includes computing the labels l ( s) for each states."@en ;
    askg-onto:inSentence "For PLTLMIN, it also includes computing the labels l ( s) for each states."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-computing_the_labels_l__s_for_each_states,
        askg-data:Entity-pltlmin .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-86-Sentence-865 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "For PLTL- STR, it involves computing the set T of temporal variables as well as the ADDs for their dynamics and for the rewards."@en ;
    askg-onto:inSentence "For PLTL- STR, it involves computing the set T of temporal variables as well as the ADDs for their dynamics and for the rewards."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-adds,
        askg-data:Entity-dynamics,
        askg-data:Entity-pltl-_str,
        askg-data:Entity-rewards,
        askg-data:Entity-set_t_of_temporal_variables .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 7"@en ;
    domo:Text "FL TL does not require any preprocessing. Expansion is the optional generation of the entire equivalent MDP prior to solving. Whether or not off-line expansion is sensible depends on the MDP solution method used. If state-based value or policy iteration is used, then the MDP needs to be expanded anyway. If, on the other hand, a heuristic search algorithm or structured method is used, it is definitely a bad idea. In our experiments, we often used expansion solely for the purpose of measuring the size of the generated MDP. Solving the MDP can be done using a number of methods. Currently, NMRDPP provides implementations of classical dynamic programming methods, namely state-based value and policy iteration [Howard, 1960], of heuristic search methods: state-based LAO* [Hansen and Zilberstein, 200 I] using either value or policy iteration as a subroutine, and of one structured method, namely SPUDD [Hoey et al., 1999]."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-871,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-872,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-873,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-874,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-875,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-876,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-877,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-878 ;
    askg-onto:index "7"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-871 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "FL TL does not require any preprocessing."@en ;
    askg-onto:inSentence "FL TL does not require any preprocessing."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-fl_tl,
        askg-data:Entity-preprocessing .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-872 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "Expansion is the optional generation of the entire equivalent MDP prior to solving."@en ;
    askg-onto:inSentence "Expansion is the optional generation of the entire equivalent MDP prior to solving."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expansion,
        askg-data:Entity-mdp,
        askg-data:Entity-model,
        askg-data:Entity-the_entire_equivalent_mdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-873 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Whether or not off-line expansion is sensible depends on the MDP solution method used."@en ;
    askg-onto:inSentence "Whether or not off-line expansion is sensible depends on the MDP solution method used."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_solution_method,
        askg-data:Entity-off-line_expansion .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-874 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "If state-based value or policy iteration is used, then the MDP needs to be expanded anyway."@en ;
    askg-onto:inSentence "If state-based value or policy iteration is used, then the MDP needs to be expanded anyway."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-state-based_value_or_policy_iteration .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-875 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "If, on the other hand, a heuristic search algorithm or structured method is used, it is definitely a bad idea."@en ;
    askg-onto:inSentence "If, on the other hand, a heuristic search algorithm or structured method is used, it is definitely a bad idea."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-algorithm,
        askg-data:Entity-heuristic_search_algorithm,
        askg-data:Entity-method,
        askg-data:Entity-structured_method .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-876 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "In our experiments, we often used expansion solely for the purpose of measuring the size of the generated MDP."@en ;
    askg-onto:inSentence "In our experiments, we often used expansion solely for the purpose of measuring the size of the generated MDP."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-expansion,
        askg-data:Entity-measuring_the_size_of_the_generated_mdp .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-877 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Solving the MDP can be done using a number of methods."@en ;
    askg-onto:inSentence "Solving the MDP can be done using a number of methods."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp,
        askg-data:Entity-methods .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-87-Sentence-878 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Currently, NMRDPP provides implementations of classical dynamic programming methods, namely state-based value and policy iteration [Howard, 1960], of heuristic search methods: state-based LAO* [Hansen and Zilberstein, 200 I] using either value or policy iteration as a subroutine, and of one structured method, namely SPUDD [Hoey et al., 1999]."@en ;
    askg-onto:inSentence "Currently, NMRDPP provides implementations of classical dynamic programming methods, namely state-based value and policy iteration [Howard, 1960], of heuristic search methods: state-based LAO* [Hansen and Zilberstein, 200 I] using either value or policy iteration as a subroutine, and of one structured method, namely SPUDD [Hoey et al., 1999]."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-classical_dynamic_programming_methods,
        askg-data:Entity-hoey_et_al,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-policy_iteration,
        askg-data:Entity-spudd,
        askg-data:Entity-state-based_lao,
        askg-data:Entity-state-based_value_iteration,
        askg-data:Entity-value_iteration .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 8"@en ;
    domo:Text "Altogether, the various types of preprocessing, the choice of whether to expand, and the MDP solution methods, give rise to quite a number of NMRDP approaches, including, but not limited to those previously mentioned For instance, we obtain an interesting variant of PLTLSTR, which we call PLTLSTR(A), by considering additional preprocessing, whereby the state space is explored (without explicitly enumerating it) to produce a BDD representation of the e-states reachable from the start state. This is done by starting with a BDD representing the start e-state, and repeatedly applying each action. Non-zero probabilities are converted to ones and the result \"or-ed\" with the last result. When no action adds any reachable e-states to this BDD, we can be sure it represents the reachable e-state space. This is then used as additional control knowledge to restrict the search. It should be noted that without this phase PL TL- STR makes no assumptions about the start state, thus is left at a possible disadvantage. Similar techniques have been used in the symbolic implementation of LAO* [Feng and Hansen, 2002]. Given temporal variables are also included in the BDD, PLTLSTR(A) is able to exploit reachability in the space of e-states as PLTLMIN does in the state-based case. NMRDPP is implemented in C++, and makes use of a number of supporting libraries. In particular, the structured algorithms rely heavily on the CUDD library for representing decision diagrams. The non-structured algorithms make use of the MTL-Matrix Template L ibrary for matrix operations. MTL takes advantage of modem processor features such as MMX and SSE and provides efficient sparse matrix operations. We believe that our implementations of MDP solution methods are comparable with the state of the art .."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-881,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8810,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8811,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8812,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8813,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-882,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-883,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-884,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-885,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-886,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-887,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-888,
        askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-889 ;
    askg-onto:index "8"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-881 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "Altogether, the various types of preprocessing, the choice of whether to expand, and the MDP solution methods, give rise to quite a number of NMRDP approaches, including, but not limited to those previously mentioned For instance, we obtain an interesting variant of PLTLSTR, which we call PLTLSTR(A), by considering additional preprocessing, whereby the state space is explored (without explicitly enumerating it) to produce a BDD representation of the e-states reachable from the start state."@en ;
    askg-onto:inSentence "Altogether, the various types of preprocessing, the choice of whether to expand, and the MDP solution methods, give rise to quite a number of NMRDP approaches, including, but not limited to those previously mentioned For instance, we obtain an interesting variant of PLTLSTR, which we call PLTLSTR(A), by considering additional preprocessing, whereby the state space is explored (without explicitly enumerating it) to produce a BDD representation of the e-states reachable from the start state."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-additional_preprocessing,
        askg-data:Entity-bdd_representation,
        askg-data:Entity-e-states_reachable_from_the_start_state,
        askg-data:Entity-nmrdp_approaches,
        askg-data:Entity-pltlstra,
        askg-data:Entity-state_space .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8810 a askg-onto:Sentence ;
    rdfs:label "Sentence 10"@en ;
    domo:Text "In particular, the structured algorithms rely heavily on the CUDD library for representing decision diagrams."@en ;
    askg-onto:inSentence "In particular, the structured algorithms rely heavily on the CUDD library for representing decision diagrams."^^xsd:string ;
    askg-onto:index "10"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-cudd_library,
        askg-data:Entity-representing_decision_diagrams,
        askg-data:Entity-structured_algorithms .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8811 a askg-onto:Sentence ;
    rdfs:label "Sentence 11"@en ;
    domo:Text "The non-structured algorithms make use of the MTL-Matrix Template L ibrary for matrix operations."@en ;
    askg-onto:inSentence "The non-structured algorithms make use of the MTL-Matrix Template L ibrary for matrix operations."^^xsd:string ;
    askg-onto:index "11"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mtl-matrix_template_library,
        askg-data:Entity-non-structured_algorithms .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8812 a askg-onto:Sentence ;
    rdfs:label "Sentence 12"@en ;
    domo:Text "MTL takes advantage of modem processor features such as MMX and SSE and provides efficient sparse matrix operations."@en ;
    askg-onto:inSentence "MTL takes advantage of modem processor features such as MMX and SSE and provides efficient sparse matrix operations."^^xsd:string ;
    askg-onto:index "12"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mmx,
        askg-data:Entity-modem_processor_features,
        askg-data:Entity-mtl,
        askg-data:Entity-sparse_matrix_operations,
        askg-data:Entity-sse .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-8813 a askg-onto:Sentence ;
    rdfs:label "Sentence 13"@en ;
    domo:Text "We believe that our implementations of MDP solution methods are comparable with the state of the art .."@en ;
    askg-onto:inSentence "We believe that our implementations of MDP solution methods are comparable with the state of the art .."^^xsd:string ;
    askg-onto:index "13"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-mdp_solution_methods,
        askg-data:Entity-the_state_of_the_art .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-882 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "This is done by starting with a BDD representing the start e-state, and repeatedly applying each action."@en ;
    askg-onto:inSentence "This is done by starting with a BDD representing the start e-state, and repeatedly applying each action."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-action,
        askg-data:Entity-bdd,
        askg-data:Entity-each_action,
        askg-data:Entity-start_e-state .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-883 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "Non-zero probabilities are converted to ones and the result \"or-ed\" with the last result."@en ;
    askg-onto:inSentence "Non-zero probabilities are converted to ones and the result \"or-ed\" with the last result."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-non-zero_probabilities,
        askg-data:Entity-ones,
        askg-data:Entity-the_last_result,
        askg-data:Entity-the_result .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-884 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "When no action adds any reachable e-states to this BDD, we can be sure it represents the reachable e-state space."@en ;
    askg-onto:inSentence "When no action adds any reachable e-states to this BDD, we can be sure it represents the reachable e-state space."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-bdd,
        askg-data:Entity-reachable_e-state_space .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-885 a askg-onto:Sentence ;
    rdfs:label "Sentence 5"@en ;
    domo:Text "This is then used as additional control knowledge to restrict the search."@en ;
    askg-onto:inSentence "This is then used as additional control knowledge to restrict the search."^^xsd:string ;
    askg-onto:index "5"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-control_knowledge,
        askg-data:Entity-search .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-886 a askg-onto:Sentence ;
    rdfs:label "Sentence 6"@en ;
    domo:Text "It should be noted that without this phase PL TL- STR makes no assumptions about the start state, thus is left at a possible disadvantage."@en ;
    askg-onto:inSentence "It should be noted that without this phase PL TL- STR makes no assumptions about the start state, thus is left at a possible disadvantage."^^xsd:string ;
    askg-onto:index "6"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pl_tl-_str,
        askg-data:Entity-start_state .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-887 a askg-onto:Sentence ;
    rdfs:label "Sentence 7"@en ;
    domo:Text "Similar techniques have been used in the symbolic implementation of LAO* [Feng and Hansen, 2002]."@en ;
    askg-onto:inSentence "Similar techniques have been used in the symbolic implementation of LAO* [Feng and Hansen, 2002]."^^xsd:string ;
    askg-onto:index "7"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-2002,
        askg-data:Entity-feng_and_hansen,
        askg-data:Entity-lao,
        askg-data:Entity-symbolic_techniques .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-888 a askg-onto:Sentence ;
    rdfs:label "Sentence 8"@en ;
    domo:Text "Given temporal variables are also included in the BDD, PLTLSTR(A) is able to exploit reachability in the space of e-states as PLTLMIN does in the state-based case."@en ;
    askg-onto:inSentence "Given temporal variables are also included in the BDD, PLTLSTR(A) is able to exploit reachability in the space of e-states as PLTLMIN does in the state-based case."^^xsd:string ;
    askg-onto:index "8"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-pltlmin,
        askg-data:Entity-pltlstra,
        askg-data:Entity-reachability_in_the_space_of_e-states,
        askg-data:Entity-state-based_case .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-88-Sentence-889 a askg-onto:Sentence ;
    rdfs:label "Sentence 9"@en ;
    domo:Text "NMRDPP is implemented in C++, and makes use of a number of supporting libraries."@en ;
    askg-onto:inSentence "NMRDPP is implemented in C++, and makes use of a number of supporting libraries."^^xsd:string ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-c,
        askg-data:Entity-nmrdpp,
        askg-data:Entity-supporting_libraries .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-89 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 9"@en ;
    domo:Text "For instance, we found that our implementation of SPUDD is comparable in performance (within a factor of 2) to the reference implementation [Hoey et al., 1999]."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-89-Sentence-891 ;
    askg-onto:index "9"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-8-Paragraph-89-Sentence-891 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "For instance, we found that our implementation of SPUDD is comparable in performance (within a factor of 2) to the reference implementation [Hoey et al., 1999]."@en ;
    askg-onto:inSentence "For instance, we found that our implementation of SPUDD is comparable in performance (within a factor of 2) to the reference implementation [Hoey et al., 1999]."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-author,
        askg-data:Entity-hoey_et_al,
        askg-data:Entity-reference_implementation,
        askg-data:Entity-spudd .

askg-data:Paper-0ecbd8a3379fdc37-Section-9 a askg-onto:Section ;
    rdfs:label "Section 9"@en ;
    domo:Text "4 Experimental Observations"@en ;
    askg-onto:hasParagraph askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91 ;
    askg-onto:index "9"^^xsd:int ;
    askg-onto:level "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91 a askg-onto:Paragraph ;
    rdfs:label "Paragraph 1"@en ;
    domo:Text "We are faced with three substantially different approaches which are not easy to compare, as their performance will depend on domain features as varied as the structure in the transition model, reachability, the type, syntax, and length of the temporal reward formula, the availability of good heuristics and control-knowledge, etc, and on the interactions between these factors. In this section, we try to answer the questions raised above and report an experimental investigation into the influence of some of these factors: dynamics, reward type, syntax, reachability, and presence of rewards irrelevant to the optimal policy. In some cases but not all, we were able to identify systematic patterns. The results were obtained using a Pentium4 2.6GHz GNU/Linux 2.4.20 machine with 500MB of ram."@en ;
    askg-onto:hasSentence askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-911,
        askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-912,
        askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-913,
        askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-914 ;
    askg-onto:index "1"^^xsd:int .

askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-911 a askg-onto:Sentence ;
    rdfs:label "Sentence 1"@en ;
    domo:Text "We are faced with three substantially different approaches which are not easy to compare, as their performance will depend on domain features as varied as the structure in the transition model, reachability, the type, syntax, and length of the temporal reward formula, the availability of good heuristics and control-knowledge, etc, and on the interactions between these factors."@en ;
    askg-onto:inSentence "We are faced with three substantially different approaches which are not easy to compare, as their performance will depend on domain features as varied as the structure in the transition model, reachability, the type, syntax, and length of the temporal reward formula, the availability of good heuristics and control-knowledge, etc, and on the interactions between these factors."^^xsd:string ;
    askg-onto:index "1"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-approaches,
        askg-data:Entity-availability_of_good_heuristics,
        askg-data:Entity-control-knowledge,
        askg-data:Entity-different,
        askg-data:Entity-domain_features,
        askg-data:Entity-factors,
        askg-data:Entity-length_of_the_temporal_reward_formula,
        askg-data:Entity-performance,
        askg-data:Entity-reachability,
        askg-data:Entity-structure_in_the_transition_model,
        askg-data:Entity-syntax,
        askg-data:Entity-type .

askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-912 a askg-onto:Sentence ;
    rdfs:label "Sentence 2"@en ;
    domo:Text "In this section, we try to answer the questions raised above and report an experimental investigation into the influence of some of these factors: dynamics, reward type, syntax, reachability, and presence of rewards irrelevant to the optimal policy."@en ;
    askg-onto:inSentence "In this section, we try to answer the questions raised above and report an experimental investigation into the influence of some of these factors: dynamics, reward type, syntax, reachability, and presence of rewards irrelevant to the optimal policy."^^xsd:string ;
    askg-onto:index "2"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-dynamics,
        askg-data:Entity-experimental_investigation,
        askg-data:Entity-factors,
        askg-data:Entity-influence_of_factors,
        askg-data:Entity-presence_of_rewards_irrelevant_to_the_optimal_policy,
        askg-data:Entity-reachability,
        askg-data:Entity-reward_type,
        askg-data:Entity-syntax .

askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-913 a askg-onto:Sentence ;
    rdfs:label "Sentence 3"@en ;
    domo:Text "In some cases but not all, we were able to identify systematic patterns."@en ;
    askg-onto:inSentence "In some cases but not all, we were able to identify systematic patterns."^^xsd:string ;
    askg-onto:index "3"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-patterns,
        askg-data:Entity-systematic .

askg-data:Paper-0ecbd8a3379fdc37-Section-9-Paragraph-91-Sentence-914 a askg-onto:Sentence ;
    rdfs:label "Sentence 4"@en ;
    domo:Text "The results were obtained using a Pentium4 2.6GHz GNU/Linux 2.4.20 machine with 500MB of ram."@en ;
    askg-onto:inSentence "The results were obtained using a Pentium4 2.6GHz GNU/Linux 2.4.20 machine with 500MB of ram."^^xsd:string ;
    askg-onto:index "4"^^xsd:int ;
    askg-onto:mentions askg-data:Entity-500mb_of_ram,
        askg-data:Entity-device,
        askg-data:Entity-gnulinux_2420,
        askg-data:Entity-pentium4_26ghz,
        askg-data:Entity-platform .

askg-data:Entity-0 rdfs:label "0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1992 rdfs:label "1992"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-1995 rdfs:label "1995"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-1997 rdfs:label "1997"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-1999 rdfs:label "1999"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-a_researcher rdfs:label "a researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-action rdfs:label "action"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-adds rdfs:label "ADDs"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bacchus rdfs:label "Bacchus"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-bacchus_c rdfs:label "Bacchus, C."@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-bdd rdfs:label "BDD"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-bonet_and_geffner rdfs:label "Bonet and Geffner"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-common_framework rdfs:label "common framework"@en ;
    askg-onto:entityType "Framework"@en .

askg-data:Entity-control_knowledge rdfs:label "Control knowledge"@en,
        "control knowledge"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-current_state rdfs:label "current state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision-theoretic_planning rdfs:label "decision-theoretic planning"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_process rdfs:label "decision process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-decision_processes rdfs:label "decision processes"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_temporal_logics rdfs:label "different temporal logics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-different_translations rdfs:label "different translations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamic_analysis_of_rewards rdfs:label "dynamic analysis of rewards"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-e rdfs:label "E"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-expansion_phase rdfs:label "expansion phase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-f rdfs:label "F"@en,
        "F."@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-factors rdfs:label "factors"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-false rdfs:label "false"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-feng rdfs:label "Feng"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-fltl_progression rdfs:label "FLTL progression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-grove rdfs:label "Grove"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-guard_formulae rdfs:label "guard formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-haddawy_and_hanks rdfs:label "Haddawy and Hanks"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-hand-coded_domains rdfs:label "hand-coded domains"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-hansen_and_zilberstein rdfs:label "Hansen and Zilberstein"@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-heuristic_search_algorithm rdfs:label "heuristic search algorithm"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-heuristic_search_methods rdfs:label "heuristic search methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-i rdfs:label "I"@en,
        "i"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-initial_state rdfs:label "initial state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-integrated_system rdfs:label "integrated system"@en ;
    askg-onto:entityType "Concept"@en,
        "System"@en .

askg-data:Entity-ltl rdfs:label "LTL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-markov_decision_process rdfs:label "Markov decision process"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-markovian rdfs:label "Markovian"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mop_representations rdfs:label "MOP representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrop rdfs:label "NMROP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-markovian_reward_function rdfs:label "non-Markovian reward function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-non-markovian_rewards rdfs:label "non-Markovian rewards"@en,
        "non-markovian rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-onoff rdfs:label "ON/OFF"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-others rdfs:label "others"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pi_to_true rdfs:label "Pi to true"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-policy_iteration rdfs:label "policy iteration"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-pr rdfs:label "Pr"@en,
        "Pr'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-progression rdfs:label "progression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-question rdfs:label "question"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-random_domains rdfs:label "Random domains"@en,
        "random domains"@en ;
    askg-onto:entityType "Domain"@en .

askg-data:Entity-reg_s rdfs:label "Reg(¢', s')"@en,
        "Reg(¢, s)"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-regression rdfs:label "Regression"@en,
        "regression"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-results rdfs:label "results"@en ;
    askg-onto:entityType "Result"@en .

askg-data:Entity-reward_formula rdfs:label "reward formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rfi rdfs:label "R(f(i))"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-run-time rdfs:label "Run-time"@en,
        "run-time"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s0 rdfs:label "s0"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s1 rdfs:label "s1"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s2 rdfs:label "s2"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s_0 rdfs:label "s_{0}"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-scientist rdfs:label "Scientist"@en,
        "scientist"@en ;
    askg-onto:entityType "Scientist"@en .

askg-data:Entity-search rdfs:label "search"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-sequence rdfs:label "sequence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-set rdfs:label "set"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-so rdfs:label "so"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_methods rdfs:label "state-based methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-state_space rdfs:label "state space"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-stationary_policy rdfs:label "stationary policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structured_policy_iteration rdfs:label "structured policy iteration"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-structured_representations rdfs:label "structured representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_logic_specification rdfs:label "temporal logic specification"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-temporal_variables rdfs:label "temporal variables"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_formula rdfs:label "the formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-the_goal rdfs:label "the goal"@en ;
    askg-onto:entityType "Concept"@en,
        "Condition"@en .

askg-data:Entity-this rdfs:label "this"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-this_paper rdfs:label "This paper"@en,
        "this paper"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-tradeoff rdfs:label "tradeoff"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-trees rdfs:label "trees"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-true rdfs:label "true"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-u rdfs:label "U"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-value_iteration rdfs:label "value iteration"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Method"@en .

askg-data:Entity-action_ai rdfs:label "action ai"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-approaches rdfs:label "approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-article rdfs:label "Article"@en,
        "article"@en ;
    askg-onto:entityType "Article"@en,
        "Publication"@en .

askg-data:Entity-artificial_intelligence rdfs:label "Artificial Intelligence"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-blind_minimality rdfs:label "blind minimality"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-boutilier rdfs:label "Boutilier"@en ;
    askg-onto:entityType "Person"@en .

askg-data:Entity-boutilier_et_al rdfs:label "Boutilier et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-c rdfs:label "C++"@en,
        "C."@en,
        "c"@en ;
    askg-onto:entityType "Author"@en,
        "Concept"@en,
        "Technology"@en .

askg-data:Entity-dataset rdfs:label "Dataset"@en,
        "dataset"@en ;
    askg-onto:entityType "Dataset"@en .

askg-data:Entity-different_approaches rdfs:label "different approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-dynamics rdfs:label "dynamics"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-e-states rdfs:label "e-states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-experiments rdfs:label "Experiments"@en,
        "experiments"@en ;
    askg-onto:entityType "Experiment"@en .

askg-data:Entity-formula rdfs:label "formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-function rdfs:label "Function"@en,
        "function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-g rdfs:label "g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-goal_g rdfs:label "goal g"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-guard_formula rdfs:label "guard formula"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-hansen rdfs:label "Hansen"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en .

askg-data:Entity-kabanza rdfs:label "Kabanza"@en ;
    askg-onto:entityType "Author"@en,
        "Person"@en,
        "Technology"@en .

askg-data:Entity-minimal_equivalent_mop rdfs:label "minimal equivalent MOP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-mop_solution_methods rdfs:label "MOP solution methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-n rdfs:label "n"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdp_solution_methods rdfs:label "NMRDP solution methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-optimal_policy rdfs:label "optimal policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-person rdfs:label "Person"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-policy rdfs:label "policy"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-preprocessing_phase rdfs:label "preprocessing phase"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-proposition_pi rdfs:label "Proposition Pi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reachability rdfs:label "reachability"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-researcher rdfs:label "Researcher"@en,
        "researcher"@en ;
    askg-onto:entityType "Researcher"@en .

askg-data:Entity-state rdfs:label "state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-state-based_representations rdfs:label "state-based representations"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structure rdfs:label "structure"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-system rdfs:label "system"@en ;
    askg-onto:entityType "System"@en .

askg-data:Entity-t rdfs:label "T"@en,
        "T'"@en,
        "T;'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-thiebaux_et_al_2002 rdfs:label "Thiebaux et al., 2002"@en,
        "[Thiebaux et al., 2002]"@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-three_approaches rdfs:label "three approaches"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-transition_model rdfs:label "transition model"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-uncertainty rdfs:label "Uncertainty"@en,
        "uncertainty"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-1996 rdfs:label "1996"@en ;
    askg-onto:entityType "Publication"@en .

askg-data:Entity-2002 rdfs:label "2002"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-analysis rdfs:label "analysis"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-domain rdfs:label "Domain"@en,
        "domain"@en ;
    askg-onto:entityType "Concept"@en,
        "Domain"@en .

askg-data:Entity-formulae rdfs:label "formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-performance rdfs:label "performance"@en ;
    askg-onto:entityType "Concept"@en,
        "Result"@en .

askg-data:Entity-pi rdfs:label "Pi"@en,
        "\\pi"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-platform rdfs:label "Platform"@en ;
    askg-onto:entityType "Concept"@en,
        "Platform"@en .

askg-data:Entity-pltl_approaches rdfs:label "PLTL approaches"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-r rdfs:label "R"@en,
        "r"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_type rdfs:label "reward type"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spudd rdfs:label "SPUDD"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Tool"@en .

askg-data:Entity-spudd-linear rdfs:label "SPUDD-LINEAR"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-a rdfs:label "A"@en,
        "A'"@en,
        "A("@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-expansion rdfs:label "Expansion"@en,
        "expansion"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-lao rdfs:label "LAO*"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en .

askg-data:Entity-nmrdpp rdfs:label "NMRDPP"@en ;
    askg-onto:entityType "Concept"@en,
        "Platform"@en,
        "System"@en,
        "Tool"@en .

askg-data:Entity-pltl rdfs:label "PLTL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-pltlstra rdfs:label "PLTLSTR(A)"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en .

askg-data:Entity-reward_formulae rdfs:label "reward formulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-reward_function rdfs:label "reward function"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-spudd-expon rdfs:label "SPUDD-EXPON"@en ;
    askg-onto:entityType "Concept"@en,
        "Tool"@en .

askg-data:Entity-states rdfs:label "stateS"@en,
        "states"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-syntax rdfs:label "syntax"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-thiebaux_et_al rdfs:label "Thiebaux et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-translation rdfs:label "translation"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity- rdfs:label "$"@en,
        "¢"@en,
        "¢'"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-algorithm rdfs:label "Algorithm"@en,
        "algorithm"@en ;
    askg-onto:entityType "Algorithm"@en .

askg-data:Entity-hoey_et_al rdfs:label "Hoey et al."@en ;
    askg-onto:entityType "Author"@en,
        "Researcher"@en .

askg-data:Entity-method rdfs:label "Method"@en,
        "method"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-preprocessing rdfs:label "preprocessing"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-rewards rdfs:label "rewards"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-structured_solution_methods rdfs:label "Structured solution methods"@en,
        "structured solution methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en .

askg-data:Entity-triple rdfs:label "triple"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Dataset"@en,
        "Method"@en .

askg-data:Entity-e-state rdfs:label "e-state"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdps rdfs:label "NMRDPs"@en ;
    askg-onto:entityType "Concept"@en,
        "Model"@en .

askg-data:Entity-proc rdfs:label "Proc"@en,
        "Proc."@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-subformulae rdfs:label "subformulae"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-fltl rdfs:label "FLTL"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-nmrdp rdfs:label "NMRDP"@en ;
    askg-onto:entityType "Concept"@en,
        "Framework"@en .

askg-data:Entity-solution_methods rdfs:label "solution methods"@en ;
    askg-onto:entityType "Concept"@en,
        "Method"@en,
        "Technique"@en .

askg-data:Entity-mdp rdfs:label "MDP"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-methods rdfs:label "methods"@en ;
    askg-onto:entityType "Method"@en .

askg-data:Entity-concept rdfs:label "Concept"@en,
        "concept"@en ;
    askg-onto:entityType "Concept"@en,
        "Research Area"@en .

askg-data:Entity-pltlsim rdfs:label "PLTLSIM"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Platform"@en,
        "Tool"@en .

askg-data:Entity-author rdfs:label "Author"@en ;
    askg-onto:entityType "Author"@en,
        "Publication"@en .

askg-data:Entity-reward rdfs:label "reward"@en ;
    askg-onto:entityType "Concept"@en .

askg-data:Entity-s rdfs:label "S"@en,
        "S'"@en,
        "S*"@en,
        "S."@en,
        "s"@en,
        "s'"@en,
        "s•"@en ;
    askg-onto:entityType "Concept"@en,
        "Person"@en .

askg-data:Entity-bacchus_et_al rdfs:label "Bacchus et al."@en ;
    askg-onto:entityType "Author"@en .

askg-data:Entity-fl_tl rdfs:label "FL TL"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Technique"@en,
        "Technology"@en,
        "Tool"@en .

askg-data:Entity-pltlstr rdfs:label "PLTLSTR"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en,
        "Technology"@en,
        "Tool"@en .

askg-data:Entity-publication rdfs:label "Publication"@en,
        "publication"@en ;
    askg-onto:entityType "Concept"@en,
        "Publication"@en .

askg-data:Entity-pltlmin rdfs:label "PLTLMIN"@en ;
    askg-onto:entityType "Algorithm"@en,
        "Concept"@en,
        "Method"@en,
        "Tool"@en .

askg-data:Entity-mop rdfs:label "MOP"@en ;
    askg-onto:entityType "Concept"@en .

